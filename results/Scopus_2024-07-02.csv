title,url,doi,abstract,year,num_pages,paper_type,bibtex
VIRTSI: A novel trust dynamics model enhancing Artificial Intelligence collaboration with human users – Insights from a ChatGPT evaluation study,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194165210&origin=inward,10.1016/j.ins.2024.120759,"AbstractView references

The rapid integration of intelligent processes and methods into information systems in the Artificial Intelligence (AI) era has led to a substantial shift towards autonomous software decision-making. This evolution necessitates robust human oversight, especially in critical domains like Healthcare, Education, and Energy. Human trust in AI plays a vital role in influencing decision-making processes of users interacting with AI. This paper presents VIRTSI (Variability and Impact of Reciprocal Trust States towards Intelligent systems), a novel rigorous computational model for human-AI Interaction. VIRTSI simulates human trust states, spanning from overtrust to distrust, through user modelling. It comprises: 1. A trust dynamics representational model based on Deterministic Finite State Automata (DFAs), illustrating transitions among cognitive trust states in response to AI-generated replies. 2. A trust evaluation model based on Confusion Matrices, originating from machine learning and Accuracy Metrics, providing a quantitative framework for analysing human trust dynamics. As a result, this is the first time that trust dynamics have been thoroughly traced in a representational model and a method has been developed to assess the impact of possibly harmful states like overtrust and distrust. An empirical study on the recently launched Large Language Model of generative AI, ChatGPT (version 3.5), provides a radical underexplored AI-generated platform for evaluating the human-AI interaction through VIRTSI. The study involved 1200 interactions of real users as well as AI experts together with experts in two very different domains of evaluation, namely software engineering and poetry. This study traces trust dynamics and the emerging human-AI interaction, in concrete examples of real user synergies with generative AI. The research reveals the vital role of maintaining normal trust states for optimal human-AI interaction and that both AI and human users need further steps towards this goal. The real-world implications of this research can guide the creation and evaluation of user interfaces with AI and the incorporation of functionalities in the development of generative AI chatbots in terms of trust by providing a new rigorous DFA representational method of trust dynamics and a corresponding new perspective of confusion matrix evaluation method of the dynamics’ impact in the efficiency of human-AI dialogues. © 2024 The Author(s)",2024,4,Article,"@article{2-s2.0-85194165210,
  title={VIRTSI: A novel trust dynamics model enhancing Artificial Intelligence collaboration with human users – Insights from a ChatGPT evaluation study},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Graduate Teacher Education Students Use and Evaluate ChatGPT as an Essay-Writing Tool,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196078419&origin=inward,10.24059/olj.v28i2.4373,"AbstractView references

Artificial intelligence (AI) has been evolving since the mid-twentieth-century when luminaries such as Alan Turing, Herbert Simon, and Marvin Minsky began developing rudimentary AI applications. For decades, AI programs remained pretty much in the realm of computer science and experimental game playing. This changed radically in the 2020s when commercial vendors such as OpenAI and Google developed generative AI programs (ChatGPT and Bard) using large language modelling (LLM). As a result, generative AI is now being considered for use in all walks of life, including education. In spring 2023, when ChatGPT burst into the public psyche, twenty-five education students in the author’s graduate seminar were invited to participate in a qualitative study using ChatGPT as an essay-writing tool. Fifteen accepted the offer. The purpose in doing this was to give students in this seminar the opportunity to use ChatGPT in a supportive environment and to collect qualitative data via descriptive written evaluation and a focus group to comment on their experiences using ChatGPT. All of these students have master’s degrees in education and experience as teachers in New York City schools. Their training and experience give them keen insights into pedagogical practice making them ideally suited to evaluate ChatGPT as an essay-writing tool. This article reports on the results of this study. Key findings indicate that the vast majority of these students had a good experience in using ChatGPT for their essays. Many, especially the secondary school teachers, would use it in their own classes. © 2024, The Online Learning Consortium. All rights reserved.",2024,4,Article,"@article{2-s2.0-85196078419,
  title={Graduate Teacher Education Students Use and Evaluate ChatGPT as an Essay-Writing Tool},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Docimological Quality Analysis of LLM-Generated Multiple Choice Questions in Computer Science and Medicine,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195831080&origin=inward,10.1007/s42979-024-02963-6,"AbstractView references

Assessment is an essential part of education, both for teachers who assess their students as well as learners who may evaluate themselves. Multiple-choice questions (MCQ) are one of the most popular types of knowledge assessment, e.g., in medical education, as they can be automatically graded and can cover a wide range of learning items. However, the creation of high-quality MCQ items is a time-consuming task. The recent advent of Large Language Models (LLM), such as Generative Pre-trained Transformer (GPT), caused a new momentum for automatic question generation solutions. Still, evaluating generated questions according to the best practices for MCQ item writing is needed to ensure docimological quality. In this article, we propose an analysis of the quality of LLM-generated MCQs. We employ zero-shot approaches in two domains, namely computer science and medicine. In the former, we make use of 3 GPT-based services to generate MCQs. In the latter, we developed a plugin for the Moodle learning management system that generates MCQs based on learning material. We compare the generated MCQs against common multiple-choice item writing guidelines. Among the major challenges, we determined that while LLMs are certainly useful in generating MCQs more efficiently, they sometimes create broad items with ambiguous keys or implausible distractors. Human oversight is also necessary to ensure instructional alignment between generated items and course contents. Finally, we propose solutions for AQG developers. © The Author(s) 2024.",2024,4,Article,"@article{2-s2.0-85195831080,
  title={Docimological Quality Analysis of LLM-Generated Multiple Choice Questions in Computer Science and Medicine},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Application of ChatGPT for automated problem reframing across academic domains,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180303050&origin=inward,10.1016/j.caeai.2023.100194,"AbstractView references

This paper explores the potential of large language models, specifically ChatGPT, to reframe problems from probability theory and statistics, making them accessible to students across diverse academic fields including biology, economics, law, and engineering. The aim of this study is to enhance interdisciplinary learning by rendering complex concepts more accessible, relevant, and engaging. We conducted a pilot study using ChatGPT to adapt problems across 17 disciplines, evaluated through expert review. Our results demonstrate the significant potential of ChatGPT in reshaping problems for diverse settings, preserving theoretical meaning in 77.1% of cases, and requiring no or only minor revisions in 74% of cases. An evaluation performed by 23 domain experts revealed that in 73.6% of cases the reframed problem was considered to add educational value compared to a corresponding abstract problem and to represent a real-world scenario in 57.0% of cases. Furthermore, a survey involving 44 Computer Science students revealed a diverse range of preferences between original and reframed problems, underscoring the importance of considering student preferences and learning styles in the design of educational content. The study offers insights into the practicality and efficacy of employing large language models, like ChatGPT, to enhance interdisciplinary education and foster greater student engagement and understanding. © 2023 The Author(s)",2024,4,Article,"@article{2-s2.0-85180303050,
  title={Application of ChatGPT for automated problem reframing across academic domains},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT and Bard Performance on the POSCOMP Exam,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194877629&origin=inward,10.1145/3658271.3658320,"AbstractView references

Context: Modern chatbots, built upon advanced language models, have achieved remarkable proficiency in answering questions across diverse fields. Problem: Understanding the capabilities and limitations of these chatbots is a significant challenge, particularly as they are integrated into different information systems, including those in education. Solution: In this study, we conducted a quantitative assessment of the ability of two prominent chatbots, ChatGPT and Bard, to solve POSCOMP questions. IS Theory: The IS theory used in this work is Information processing theory. Method: We used a total of 271 questions from the last five POSCOMP exams that did not rely on graphic content as our materials. We presented these questions to the two chatbots in two formats: directly as they appeared in the exam and with additional context. In the latter case, the chatbots were informed that they were answering a multiple-choice question from a computing exam. Summary of Results: On average, chatbots outperformed human exam-takers by more than 20%. Interestingly, both chatbots performed better, in average, without additional context added to the prompt. They exhibited similar performance levels, with a slight advantage observed for ChatGPT. Contributions and Impact in the IS area: The primary contribution to the field involves the exploration of the capabilities and limitations of chatbots in addressing computing-related questions. This information is valuable for individuals developing Information Systems with the assistance of such chatbots or those relying on technologies built upon these capabilities. © 2024 ACM.",2024,4,Conference Paper,"@article{2-s2.0-85194877629,
  title={ChatGPT and Bard Performance on the POSCOMP Exam},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194900868&origin=inward,10.1145/3613904.3642377,"AbstractView references

Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM. © 2024 Copyright held by the owner/author(s)",2024,4,Conference Paper,"@article{2-s2.0-85194900868,
  title={Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Co-Designing QickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194892913&origin=inward,10.1145/3613904.3642080,"AbstractView references

Traditional topic-specific communication boards for Augmentative and Alternative Communication (AAC) require manual programming of relevant symbolic vocabulary, which is time-consuming and often impractical even for experienced Speech-Language Pathologists (SLPs). While recent research has demonstrated the potential to automatically generate these boards from photographs using artificial intelligence, there has been no exploration on how to design such tools to support the specific needs of AAC-based language instruction. This paper introduces QuickPic, a mobile AAC application co-designed with SLPs and special educators, aimed at enhancing language learning for non-speaking individuals, such as autistic children. Through a 17-month design process, we uncover the unique design features required to provide timely language support in therapy and special education contexts. We present emerging evidence on the overall satisfaction of SLPs using QuickPic, and on the advantages of large language model-based generation compared to the existing technique for automated vocabulary from photographs for AAC. © 2024 Copyright held by the owner/author(s)",2024,4,Conference Paper,"@article{2-s2.0-85194892913,
  title={Co-Designing QickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194854287&origin=inward,10.1145/3613904.3642229,"AbstractView references

As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children's autonomous Scratch learning: artist's block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist's block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children. © 2024 Copyright held by the owner/author(s)",2024,4,Conference Paper,"@article{2-s2.0-85194854287,
  title={ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194853499&origin=inward,10.1145/3613904.3642349,"AbstractView references

This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs' expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs' knowledge and makes them initiate “why” and “how” questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo's problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo's questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents. © 2024 Copyright held by the owner/author(s)",2024,4,Conference Paper,"@article{2-s2.0-85194853499,
  title={Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194852991&origin=inward,10.1145/3613904.3642773,"AbstractView references

Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student's incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses. © 2024 Copyright held by the owner/author(s)",2024,4,Conference Paper,"@article{2-s2.0-85194852991,
  title={CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Enhancing Programming Error Messages in Real Time with Generative AI,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194193660&origin=inward,10.1145/3613905.3647967,"AbstractView references

Generative AI is changing the way that many disciplines are taught, including computer science. Researchers have shown that generative AI tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using generative AI to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via GPT-4. We extend this work by implementing feedback from ChatGPT for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding generative AI to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that GPT-4 provided. © 2024 Association for Computing Machinery. All rights reserved.",2024,4,Conference Paper,"@article{2-s2.0-85194193660,
  title={Enhancing Programming Error Messages in Real Time with Generative AI},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194192158&origin=inward,10.1145/3613905.3637148,"AbstractView references

In this research paper, we discuss our attempt to teach high school students introductory programming with Python using a custom learning platform that leverages ChatGPT to generate personalized learning materials based on each student's educational background. The platform features topics and subtopics, each supported by prompts for Explanation, Example, Exercise, and Exercise Solution, with a context-setting prompt tailored to individual students' backgrounds while respecting their privacy. The case study brought up compelling insights. Students exhibited heightened engagement, and the lecturers transitioned from being traditional instructors teaching content to becoming mentors who guide students on what to do next, clarifying misunderstandings and addressing potential questions. Furthermore, students gained hands-on programming experience during the learning process, eliminating the traditional post-class experimentation phase. This innovative approach not only enhances traditional CS1 education but also suggests a broader application of Large Language Models (LLMs) for personalized learning across diverse fields, providing tailored instruction and fostering engagement. © 2024 Owner/Author.",2024,4,Conference Paper,"@article{2-s2.0-85194192158,
  title={Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194149646&origin=inward,10.1145/3613905.3650937,"AbstractView references

Recent studies have integrated large language models (LLMs) into diverse educational contexts, including providing adaptive programming hints, a type of feedback focuses on helping students move forward during problem-solving. However, most existing LLM-based hint systems are limited to one single hint type. To investigate whether and how different levels of hints can support students' problem-solving and learning, we conducted a thinkaloud study with 12 novices using the LLM Hint Factory, a system providing four levels of hints from general natural language guidance to concrete code assistance, varying in format and granularity. We discovered that high-level natural language hints alone can be helpless or even misleading, especially when addressing next-step or syntax-related help requests. Adding lower-level hints, like code examples with in-line comments, can better support students. The findings open up future work on customizing help responses from content, format, and granularity levels to accurately identify and meet students' learning needs. © 2024 Association for Computing Machinery. All rights reserved.",2024,4,Conference Paper,"@article{2-s2.0-85194149646,
  title={Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"A comprehensive review on large language models exploring applications, challenges, limitations, and future prospects",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195008648&origin=inward,10.4018/979-8-3693-3502-4.ch002,"AbstractView references

In the realm of computer science and language, large language models (LLMs) stand out as remarkable tools of artificial intelligence (AI). Proficient in deciphering intricate language nuances, LLMs offer sensible responses and find applications in natural language understanding, language translation, and question answering. This chapter delves into the history, creation, training, and multifaceted applications of LLMs. It explores the basics of generative AI, focusing on generative pre-trained transformers (GPT). Examining the evolution of LLMs and their diverse applications in medicine, education, finance, and engineering, the chapter addresses real-world challenges, including ethical concerns, biases, comprehensibility, and computational requirements. It serves as an informative guide for researchers, practitioners, and enthusiasts, elucidating the potential, challenges, and future of LLMs in AI. © 2024, IGI Global. All rights reserved.",2024,23,Book Chapter,"@article{2-s2.0-85195008648,
  title={A comprehensive review on large language models exploring applications, challenges, limitations, and future prospects},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
The Impact of Large Language Models on Programming Education and Student Learning Outcomes,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194184036&origin=inward,10.3390/app14104115,"AbstractView references

Recent advancements in Large Language Models (LLMs) like ChatGPT and Copilot have led to their integration into various educational domains, including software development education. Regular use of LLMs in the learning process is still not well-researched; thus, this paper intends to fill this gap. The paper explores the nuanced impact of informal LLM usage on undergraduate students’ learning outcomes in software development education, focusing on React applications. We carefully designed an experiment involving thirty-two participants over ten weeks where we examined unrestricted but not specifically encouraged LLM use and their correlation with student performance. Our results reveal a significant negative correlation between increased LLM reliance for critical thinking-intensive tasks such as code generation and debugging and lower final grades. Furthermore, a downward trend in final grades is observed with increased average LLM use across all tasks. However, the correlation between the use of LLMs for seeking additional explanations and final grades was not as strong, indicating that LLMs may serve better as a supplementary learning tool. These findings highlight the importance of balancing LLM integration with the cultivation of independent problem-solving skills in programming education. © 2024 by the authors.",2024,4,Article,"@article{2-s2.0-85194184036,
  title={The Impact of Large Language Models on Programming Education and Student Learning Outcomes},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Teamwork Conflict Management Training and Conflict Resolution Practice via Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193912105&origin=inward,10.3390/fi16050177,"AbstractView references

This study implements a conflict management training approach guided by principles of transformative learning and conflict management practice simulated via an LLM. Transformative learning is more effective when learners are engaged mentally and behaviorally in learning experiences. Correspondingly, the conflict management training approach involved a three-step procedure consisting of a learning phase, a practice phase enabled by an LLM, and a reflection phase. Fifty-six students enrolled in a systems development course were exposed to the transformative learning approach to conflict management so they would be better prepared to address any potential conflicts within their teams as they approached a semester-long software development project. The study investigated the following: (1) How did the training and practice affect students’ level of confidence in addressing conflict? (2) Which conflict management styles did students use in the simulated practice? (3) Which strategies did students employ when engaging with the simulated conflict? The findings indicate that: (1) 65% of the students significantly increased in confidence in managing conflict by demonstrating collaborative, compromising, and accommodative approaches; (2) 26% of the students slightly increased in confidence by implementing collaborative and accommodative approaches; and (3) 9% of the students did not increase in confidence, as they were already confident in applying collaborative approaches. The three most frequently used strategies for managing conflict were identifying the root cause of the problem, actively listening, and being specific and objective in explaining their concerns. © 2024 by the authors.",2024,4,Article,"@article{2-s2.0-85193912105,
  title={Teamwork Conflict Management Training and Conflict Resolution Practice via Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Future applications of generative large language models: A data-driven case study on ChatGPT,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189010126&origin=inward,10.1016/j.technovation.2024.103002,"AbstractView references

This study delves into the evolving role of generative Large Language Models (LLMs). We develop a data-driven approach to collect and analyse tasks that users are asking to generative LLMs. Thanks to the focus on tasks this paper contributes to give a quantitative and granular understanding of the potential influence of LLMs in different business areas. Utilizing a dataset comprising over 3.8 million tweets, we identify and cluster 31,747 unique tasks, with a specific case study on ChatGPT. To reach this goal, the proposed method combines two Natural Language Processing (NLP) Techniques, Named Entity Recognition (NER) and BERTopic. The combination makes it possible to collect granular tasks of LLMs (NER) and clusters them in business areas (BERTopic). Our findings reveal a wide spectrum of applications, from programming assistance to creative content generation, highlighting LLM's versatility. The analysis highlighted six emerging areas of application for ChatGPT: human resources, programming, social media, office automation, search engines, education. The study also examines the implications of these findings for innovation management, proposing a research agenda to explore the intersection of the identified areas, with four stages of the innovation process: idea generation, screening/idea selection, development, and diffusion/sales/marketing. © 2024 The Author(s)",2024,4,Article,"@article{2-s2.0-85189010126,
  title={Future applications of generative large language models: A data-driven case study on ChatGPT},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Future of software development with generative AI,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85187214717&origin=inward,10.1007/s10515-024-00426-z,"AbstractView references

Generative AI is regarded as a major disruption to software development. Platforms, repositories, clouds, and the automation of tools and processes have been proven to improve productivity, cost, and quality. Generative AI, with its rapidly expanding capabilities, is a major step forward in this field. As a new key enabling technology, it can be used for many purposes, from creative dimensions to replacing repetitive and manual tasks. The number of opportunities increases with the capabilities of large-language models (LLMs). This has raised concerns about ethics, education, regulation, intellectual property, and even criminal activities. We analyzed the potential of generative AI and LLM technologies for future software development paths. We propose four primary scenarios, model trajectories for transitions between them, and reflect against relevant software development operations. The motivation for this research is clear: the software development industry needs new tools to understand the potential, limitations, and risks of generative AI, as well as guidelines for using it. © The Author(s) 2024.",2024,4,Article,"@article{2-s2.0-85187214717,
  title={Future of software development with generative AI},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
PyDex: Repairing Bugs in Introductory Python Assignments using LLMs,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195798173&origin=inward,10.1145/3649850,"AbstractView references

Students often make mistakes in their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex (a version of GPT), to build an APR system - PyDex - for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate PyDex on 286 real student programs and compare to three baselines, including one that combines a state-of-the-art Python syntax repair engine, BIFI, and a state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that PyDex can fix more programs and produce smaller patches on average. © 2024 Owner/Author.",2024,4,Article,"@article{2-s2.0-85195798173,
  title={PyDex: Repairing Bugs in Introductory Python Assignments using LLMs},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Seven failure points when engineering a retrieval augmented generation system,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196561155&origin=inward,10.1145/3644815.3644945,"AbstractView references

Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.",2024,6,Conference Paper,"@article{2-s2.0-85196561155,
  title={Seven failure points when engineering a retrieval augmented generation system},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Let’s Ask AI About Their Programs: Exploring ChatGPT’s Answers To Program Comprehension Questions,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195511138&origin=inward,10.1145/3639474.3640058,"AbstractView references

Recent research has explored the creation of questions from code submitted by students. These Questions about Learners’ Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students’ learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks. © 2024 Copyright held by the owner/author(s).",2024,12,Conference Paper,"@article{2-s2.0-85195511138,
  title={Let’s Ask AI About Their Programs: Exploring ChatGPT’s Answers To Program Comprehension Questions},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195489262&origin=inward,10.1145/3639474.3640068,"AbstractView references

Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct. In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from LeetCode. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code. © 2024 Copyright held by the owner/author(s).",2024,11,Conference Paper,"@article{2-s2.0-85195489262,
  title={Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
AI-Tutoring in Software Engineering Education Experiences with Large Language Models in Programming Assessments,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195462659&origin=inward,10.1145/3639474.3640061,"AbstractView references

With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences. In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students’ concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI’s role in education. © 2024 Copyright held by the owner/author(s).",2024,11,Conference Paper,"@article{2-s2.0-85195462659,
  title={AI-Tutoring in Software Engineering Education Experiences with Large Language Models in Programming Assessments},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"LLMs Still Can’t Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard’s Capacity to Handle Object-Oriented Programming Assignments",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195457150&origin=inward,10.1145/3639474.3640052,"AbstractView references

Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision. © 2024 Copyright held by the owner/author(s).",2024,8,Conference Paper,"@article{2-s2.0-85195457150,
  title={LLMs Still Can’t Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard’s Capacity to Handle Object-Oriented Programming Assignments},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194836271&origin=inward,10.1145/3639474.3640084,"AbstractView references

Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized solutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art. © 2024 Copyright held by the owner/author(s).",2024,12,Conference Paper,"@article{2-s2.0-85194836271,
  title={Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Generative AI for Customizable Learning Experiences,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190279516&origin=inward,10.3390/su16073034,"AbstractView references

The introduction of accessible generative artificial intelligence opens promising opportunities for the implementation of personalized learning methods in any educational environment. Personalized learning has been conceptualized for a long time, but it has only recently become realistic and truly achievable. In this paper, we propose an affordable and sustainable approach toward personalizing learning materials as part of the complete educational process. We have created a tool within a pre-existing learning management system at a software engineering college that automatically generates learning materials based on the learning outcomes provided by the professor for a particular class. The learning materials were composed in three distinct styles, the initial one being the traditional professor style and the other two variations adopting a pop-culture influence, namely Batman and Wednesday Addams. Each lesson, besides being delivered in three different formats, contained automatically generated multiple-choice questions that students could use to check their progress. This paper contains complete instructions for developing such a tool with the help of large language models using OpenAI’s API and an analysis of the preliminary experiment of its usage performed with the help of 20 college students studying software engineering at a European university. Participation in the study was optional and on voluntary basis. Each student’s tool usage was quantified, and two questionnaires were conducted: one immediately after subject completion and another 6 months later to assess both immediate and long-term effects, perceptions, and preferences. The results indicate that students found the multiple variants of the learning materials really engaging. While predominantly utilizing the traditional variant of the learning materials, they found this approach inspiring, would recommend it to other students, and would like to see it more in classes. The most popular feature were the automatically generated quiz-style tests that they used to assess their understanding. Preliminary evidence suggests that the use of various versions of learning materials leads to an increase in students’ study time, especially for students who have not mastered the topic otherwise. The study’s small sample size of 20 students restricts its ability to generalize its findings, but its results provide useful early insights and lay the groundwork for future research on AI-supported educational strategies. © 2024 by the authors.",2024,4,Article,"@article{2-s2.0-85190279516,
  title={Generative AI for Customizable Learning Experiences},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT and Python programming homework,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182653773&origin=inward,10.1111/dsji.12306,"AbstractView references

Large Language Model (LLM) artificial intelligence tools present a unique challenge for educators who teach programming languages. While LLMs like ChatGPT have been well documented for their ability to complete exams and create prose, there is a noticeable lack of research into their ability to solve problems using high-level programming languages. Like many other university educators, those teaching programming courses would like to detect if students submit assignments generated by an LLM. To investigate grade performance and the likelihood of instructors identifying code generated by artificial intelligence (AI) tools, we compare code generated by students and ChatGPT for introductory Python homework assignments. Our research reveals mixed results on both counts, with ChatGPT performing like a mid-range student on assignments and seasoned instructors struggling to detect AI-generated code. This indicates that although AI-generated results may not always be identifiable, they do not currently yield results approaching those of diligent students. We describe our methodology for selecting and evaluating the code examples, the results of our comparison, and the implications for future classes. We conclude with recommendations for how instructors of programming courses can mitigate student use of LLM tools as well as articulate the inherent value of preserving students’ individual creativity in producing programming languages. © 2024 Decision Sciences Institute.",2024,14,Article,"@article{2-s2.0-85182653773,
  title={ChatGPT and Python programming homework},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Practical Sentiment Analysis for Education: The Power of Student Crowdsourcing,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189644676&origin=inward,10.1609/aaai.v38i21.30356,"AbstractView references

Sentiment analysis provides a promising tool to automatically assess the emotions voiced in written student feedback such as periodically collected unit-of-study reflections. The commonly used dictionary-based approaches are limited to major languages and fail to capture contextual differences. Pretrained large language models have been shown to be biased and online versions raise privacy concerns. Hence, we resort to traditional supervised machine learning (ML) approaches which are designed to overcome these issues by learning from domain-specific labeled data. However, these labels are hard to come by - in our case manually annotating student feedback is prone to bias and time-consuming, especially in high-enrollment courses. In this work, we investigate the use of student crowdsourced labels for supervised sentiment analysis for education. Specifically, we compare crowdsourced and student self-reported labels with human expert annotations and use them in various ML approaches to evaluate the performance on predicting emotions of written student feedback collected from large computer science classes. We find that the random forest model trained with student-crowdsourced labels tremendously improves the identification of reflections with negative sentiment. In addition to our quantitative study, we describe our crowdsourcing experiment which was intentionally designed to be an educational activity in an introduction to data science course. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",2024,9,Conference Paper,"@article{2-s2.0-85189644676,
  title={Practical Sentiment Analysis for Education: The Power of Student Crowdsourcing},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Detecting AI-Generated Code Assignments Using Perplexity of Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189634956&origin=inward,10.1609/aaai.v38i21.30361,"AbstractView references

Large language models like ChatGPT can generate human-like code, posing challenges for programming education as students may be tempted to misuse them on assignments. However, there are currently no robust detectors designed specifically to identify AI-generated code. This is an issue that needs to be addressed to maintain academic integrity while allowing proper utilization of language models. Previous work has explored different approaches to detect AI-generated text, including watermarks, feature analysis, and fine-tuning language models. In this paper, we address the challenge of determining whether a student's code assignment was generated by a language model. First, our proposed method identifies AI-generated code by leveraging targeted masking perturbation paired with comprehensive scoring. Rather than applying a random mask, areas of the code with higher perplexity are more intensely masked. Second, we utilize a fine-tuned CodeBERT to fill in the masked portions, producing subtle modified samples. Then, we integrate the overall perplexity, variation of code line perplexity, and burstiness into a unified score. In this scoring scheme, a higher rank for the original code suggests it's more likely to be AI-generated. This approach stems from the observation that AI-generated codes typically have lower perplexity. Therefore, perturbations often exert minimal influence on them. Conversely, sections of human-composed codes that the model struggles to understand can see their perplexity reduced by such perturbations. Our method outperforms current open-source and commercial text detectors. Specifically, it improves detection of code submissions generated by OpenAI's text-davinci-003, raising average AUC from 0.56 (GPTZero baseline) to 0.87 for our detector. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",2024,8,Conference Paper,"@article{2-s2.0-85189634956,
  title={Detecting AI-Generated Code Assignments Using Perplexity of Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT-Generated Code Assignment Detection Using Perplexity of Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189633186&origin=inward,10.1609/aaai.v38i21.30527,"AbstractView references

In the era of large language models like ChatGPT, maintaining academic integrity in programming education has become challenging due to potential misuse. There's a pressing need for reliable detectors to identify ChatGPT-generated code. While previous studies have tackled model-generated text detection, identifying such code remains uncharted territory. In this paper, we introduce a novel method to discern ChatGPT-generated code. We employ targeted masking perturbation, emphasizing code sections with high perplexity. Fine-tuned CodeBERT is utilized to replace these masked sections, generating subtly perturbed samples. Our scoring system amalgamates overall perplexity, variations in code line perplexity, and burstiness. In this scoring scheme, a higher rank for the original code suggests it's more likely to be ChatGPT-generated. The underlying principle is that code generated by models typically exhibits consistent, low perplexity and reduced burstiness, with its ranking remaining relatively stable even after subtle modifications. In contrast, human-written code, when perturbed, is more likely to produce samples that the model prefers. Our approach significantly outperforms current detectors, especially against OpenAI's text-davinci-003 model, with the average AUC rising from 0.56 (GPTZero baseline) to 0.87. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",2024,2,Conference Paper,"@article{2-s2.0-85189633186,
  title={ChatGPT-Generated Code Assignment Detection Using Perplexity of Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85187557279&origin=inward,10.1145/3636555.3636846,"AbstractView references

Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a ""tutor""model to generate hints - it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a ""student""model to further validate the hint quality - it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library. © 2024 Owner/Author.",2024,12,Conference Paper,"@article{2-s2.0-85187557279,
  title={Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85187550433&origin=inward,10.1145/3636555.3636882,"AbstractView references

AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT's ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education. © 2024 Owner/Author.",2024,7,Conference Paper,"@article{2-s2.0-85187550433,
  title={Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189183730&origin=inward,10.1145/3626253.3635592,"AbstractView references

This study utilizes large language models to extract foundational programming concepts in programming assignments in a CS1 course. We seek to answer the following research questions: RQ1. How effectively can large language models identify knowledge components in a CS1 course from programming assignments? RQ2. Can large language models be used to extract program-level knowledge components, and how can the information be used to identify students' misconceptions? Preliminary results demonstrated a high similarity between course-level knowledge components retrieved from a large language model and that of an expert-generated list. © 2024 Owner/Author.",2024,2,Conference Paper,"@article{2-s2.0-85189183730,
  title={Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
CAET: Code Analysis and Education Tutor,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189161612&origin=inward,10.1145/3626253.3635543,"AbstractView references

The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered. Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course. © 2024 Owner/Author.",2024,2,Conference Paper,"@article{2-s2.0-85189161612,
  title={CAET: Code Analysis and Education Tutor},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"Evaluating Large Language Model Code Generation as an Autograding Mechanism for ""Explain in Plain English"" Questions",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189147391&origin=inward,10.1145/3626253.3635542,"AbstractView references

The ability of students to ""Explain in Plain English""(EiPE) the purpose of code is a critical skill for students in introductory programming courses to develop. EiPE questions serve as both a mechanism for students to develop and demonstrate code comprehension skills. However, evaluating this skill has been challenging as manual grading is time consuming and not easily automated. The process of constructing a prompt for the purposes of code generation for a Large Language Model, such OpenAI's GPT-4, bears a striking resemblance to constructing EiPE responses. In this paper, we explore the potential of using test cases run on code generated by GPT-4 from students' EiPE responses as a grading mechanism for EiPE questions. We applied this proposed grading method to a corpus of EiPE responses collected from past exams, then measured agreement between the results of this grading method and human graders. Overall, we find moderate agreement between the human raters and the results of the unit tests run on the generated code. This appears to be attributable to GPT-4's code generation being more lenient than human graders on low-level descriptions of code. © 2024 Owner/Author.",2024,2,Conference Paper,"@article{2-s2.0-85189147391,
  title={Evaluating Large Language Model Code Generation as an Autograding Mechanism for ""Explain in Plain English"" Questions},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189146522&origin=inward,10.1145/3626253.3635624,"AbstractView references

This study refines Large Language Models (LLMs) prompts to enhance the generation of code tracing questions, where the new expert-guided prompts consider features identified from prior research. Expert evaluations compared new LLM-generated questions against previously preferred ones, revealing improved quality in aspects like complexity and concept coverage. While providing insights into effective question generation and affirming LLMs' potential in educational content creation, the study also contributes an expert-evaluated question dataset to the computing education community. However, generating high-quality reverse tracing questions remains a nuanced challenge, indicating a need for further LLM prompting refinement. © 2024 Owner/Author.",2024,2,Conference Paper,"@article{2-s2.0-85189146522,
  title={Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189142855&origin=inward,10.1145/3626253.3635483,"AbstractView references

Students in introductory computing courses often lack the experience required to effectively identify and resolve errors in their code. For such students, Programming Error Messages (PEMs) are often the first indication of an error, and could provide valuable debugging guidance. However, in many cases, such as with standard C compiler implementations, PEMs are largely unsuitable for novices. Confusing, misleading, and filled with terse language and jargon, these messages instead act as an additional source of difficulty. In this paper, we present DCC Sidekick, which integrates the Debugging C Compiler (DCC) with a Large Language Model (LLM) in a web-based dashboard to produce contextual, accurate guidance conducive to student learning. This dashboard is directly accessible from the output of the compiler, and provides a bird's-eye-view of the program source, compiler output, and a conversational AI interface to help unravel cryptic error messages. We aim to deploy DCC Sidekick to a C-based CS1 cohort at a large higher education institution to investigate how novice students utilise the conversational explanation interface during debugging activities. In this work, we present our experience designing and building DCC Sidekick. © 2024 Owner/Author.",2024,2,Conference Paper,"@article{2-s2.0-85189142855,
  title={DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
My Learnings from Allowing Large Language Models in Introductory Computer Science Classes,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189138134&origin=inward,10.1145/3626253.3635511,"AbstractView references

Many instructors want to allow their students to use large language models (LLMs) in their introductory computer science courses, but they first want to see other instructors' results from doing so before taking on the risk in their own courses. Presented here are the results from allowing students to use LLMs in the second course in a sequence of intensive introductory courses designed to prepare students with a non-computational background for entry into a masters' degree program. We allowed students to use the internet and LLMs (such as ChatGPT or Github Copilot) to help with assignments, with guidelines to avoid plagiarism and encourage learning. We then surveyed students to ask about how they used LLMs, whether they saw others cheating, how they generally used internet-based resources on assignments and exams, and their feedback on the policies. We found that students are overwhelmingly using LLMs (and the internet generally) to learn and code ""better""rather than cheat. These results are intended to be a starting point to spark discussion on the adoption of new technologies in introductory computer science courses. The authors themselves will continue teaching courses with the policy that students should interact with an LLM the way they interact with a person: students are encouraged to discuss and collaborate with it, but copying code from it is considered plagiarism. © 2024 Owner/Author.",2024,2,Conference Paper,"@article{2-s2.0-85189138134,
  title={My Learnings from Allowing Large Language Models in Introductory Computer Science Classes},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189137107&origin=inward,10.1145/3626253.3635606,"AbstractView references

Novice programmers need to write basic code as part of the learning process, but they often face difficulties. To assist struggling students, we recently implemented personalized Parsons problems, which are code puzzles where students arrange blocks of code to solve them, as pop-up scaffolding. Students found them to be more engaging and preferred them for learning, instead of simply receiving the correct answer, such as the response they might get from generative AI tools like ChatGPT. However, a drawback of using Parsons problems as scaffolding is that students may be able to put the code blocks in the correct order without fully understanding the rationale of the correct solution. As a result, the learning benefits of scaffolding are compromised. Can we improve the understanding of personalized Parsons scaffolding by providing textual code explanations? In this poster, we propose a design that incorporates multiple levels of textual explanations for the Parsons problems. This design will be used for future technical evaluations and classroom experiments. These experiments will explore the effectiveness of adding textual explanations to Parsons problems to improve instructional benefits. © 2024 Owner/Author.",2024,2,Conference Paper,"@article{2-s2.0-85189137107,
  title={Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189360811&origin=inward,10.1145/3626252.3630854,"AbstractView references

StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189360811,
  title={Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189349317&origin=inward,10.1145/3626252.3630803,"AbstractView references

This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189349317,
  title={ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189335954&origin=inward,10.1145/3626252.3630828,"AbstractView references

Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process. On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education. © 2024 Owner/Author.",2024,7,Conference Paper,"@article{2-s2.0-85189335954,
  title={A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Evaluating Automatically Generated Contextualised Programming Exercises,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189331780&origin=inward,10.1145/3626252.3630863,"AbstractView references

Introductory programming courses often require students to solve many small programming exercises as part of their learning. Researchers have previously suggested that the context used in the problem description for these exercises is likely to impact student engagement and motivation. Furthermore, supplying programming exercises that use a broad range of contexts or even allowing students to select contexts to personalize their own exercises, may support the interests of a diverse student population. Unfortunately, it is time-consuming for instructors to create large numbers of programming exercises that provide a wide range of contextualized problems. However, recent work has shown that large language models may be able to automate the mass production of programming exercises, reducing the burden on instructors. In this research, we explore the potential of OpenAI's GPT-4 to create high-quality and novel programming exercises that implement various contexts. Finally, through prompt engineering, we compare different prompting strategies used to generate many programming exercises with various contextualized problem descriptions and then evaluate the quality of the exercises generated. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189331780,
  title={Evaluating Automatically Generated Contextualised Programming Exercises},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Software Engineering Education Must Adapt and Evolve for an LLM Environment,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189323139&origin=inward,10.1145/3626252.3630927,"AbstractView references

In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189323139,
  title={Software Engineering Education Must Adapt and Evolve for an LLM Environment},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189322137&origin=inward,10.1145/3626252.3630817,"AbstractView references

As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create ""black box""code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings. © 2024 Owner/Author.",2024,7,Conference Paper,"@article{2-s2.0-85189322137,
  title={CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189316150&origin=inward,10.1145/3626252.3630958,"AbstractView references

The recent emergence of LLM-based code generation models can potentially transform programming education. To pinpoint the current state of research on using LLM-based code generators to support the teaching and learning of programming, we conducted a systematic literature review of 21 papers published since 2018. The review focuses on (1) the teaching and learning practices in programming education that utilized LLM-based code generation models, (2) characteristics and (3) performance indicators of the models, and (4) aspects to consider when utilizing the models in programming education, including the risks and challenges. We found that the most commonly reported uses of LLM-based code generation models for teachers are generating assignments and evaluating student work, while for students, the models function as virtual tutors. We identified that the models exhibit accuracy limitations; generated content often contains minor errors that are manageable by instructors but pose risks for novice learners. Moreover, risks such as academic misconduct and over-reliance on the models are critical when considering integrating these models into education. Overall, LLM-based code generation models can be an assistive tool for both learners and instructors if the risks are mitigated. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189316150,
  title={Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189309863&origin=inward,10.1145/3626252.3630897,"AbstractView references

Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages. © 2024 Owner/Author.",2024,7,Conference Paper,"@article{2-s2.0-85189309863,
  title={Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189305423&origin=inward,10.1145/3626252.3630826,"AbstractView references

The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189305423,
  title={Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189303280&origin=inward,10.1145/3626252.3630938,"AbstractView references

In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had ""a personal tutor.'' Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189303280,
  title={Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"Using GPT-4 to Provide Tiered, Formative Code Feedback",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189297428&origin=inward,10.1145/3626252.3630960,"AbstractView references

Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction. © 2024 Owner/Author.",2024,7,Conference Paper,"@article{2-s2.0-85189297428,
  title={Using GPT-4 to Provide Tiered, Formative Code Feedback},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189289344&origin=inward,10.1145/3626252.3630789,"AbstractView references

As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189289344,
  title={Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Implications of ChatGPT for Data Science Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189289268&origin=inward,10.1145/3626252.3630874,"AbstractView references

ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189289268,
  title={Implications of ChatGPT for Data Science Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189286302&origin=inward,10.1145/3626252.3630784,"AbstractView references

ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85189286302,
  title={Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85188258594&origin=inward,10.1145/3626252.3630880,"AbstractView references

Much of the recent work investigating large language models and AI Code Generation tools in computing education has focused on assessing their capabilities for solving typical programming problems and for generating resources such as code explanations and exercises. If progress is to be made toward the inevitable lasting pedagogical change, there is a need for research that explores the instructor voice, seeking to understand how instructors with a range of experiences plan to adapt. In this paper, we report the results of an interview study involving 12 instructors from Australia, Finland and New Zealand, in which we investigate educators' current practices, concerns, and planned adaptations relating to these tools. Through this empirical study, our goal is to prompt dialogue between researchers and educators to inform new pedagogical strategies in response to the rapidly evolving landscape of AI code generation tools. © 2024 Owner/Author.",2024,7,Conference Paper,"@article{2-s2.0-85188258594,
  title={Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
A Large Scale RCT on Effective Error Messages in CS1,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185816269&origin=inward,10.1145/3626252.3630764,"AbstractView references

In this paper, we evaluate the most effective error message types through a large-scale randomized controlled trial conducted in an open-access, online introductory computer science course with 8,762 students from 146 countries. We assess existing error message enhancement strategies, as well as two novel approaches of our own: (1) generating error messages using OpenAI's GPT in real time and (2) constructing error messages that incorporate the course discussion forum. By examining students' direct responses to error messages, and their behavior throughout the course, we quantitatively evaluate the immediate and longer term efficacy of different error message types. We find that students using GPT generated error messages repeat an error 23.1% less often in the subsequent attempt, and resolve an error in 34.8% fewer additional attempts, compared to students using standard error messages. We also perform an analysis across various demographics to understand any disparities in the impact of different error message types. Our results find no significant difference in the effectiveness of GPT generated error messages for students from varying socioeconomic and demographic backgrounds. Our findings underscore GPT generated error messages as the most helpful error message type, especially as a universally effective intervention across demographics. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85185816269,
  title={A Large Scale RCT on Effective Error Messages in CS1},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
dcc - Help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185805699&origin=inward,10.1145/3626252.3630822,"AbstractView references

In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc - help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc - help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc - help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc - help provides novel opportunities for scaffolding students' introduction to programming. © 2024 ACM.",2024,7,Conference Paper,"@article{2-s2.0-85185805699,
  title={dcc - Help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Solving Proof Block Problems Using Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185719497&origin=inward,10.1145/3626252.3630928,"AbstractView references

Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs. In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future. © 2024 Owner/Author.",2024,7,Conference Paper,"@article{2-s2.0-85185719497,
  title={Solving Proof Block Problems Using Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Prompt Problems: A New Programming Exercise for the Generative AI Era,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184751809&origin=inward,10.1145/3626252.3630909,"AbstractView references

Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging - the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice. © 2024 Owner/Author.",2024,7,Conference Paper,"@article{2-s2.0-85184751809,
  title={Prompt Problems: A New Programming Exercise for the Generative AI Era},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Voice-Controlled Robotics in Early Education: Implementing and Validating Child-Directed Interactions Using a Collaborative Robot and Artificial Intelligence,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85192750799&origin=inward,10.3390/app14062408,"AbstractView references

This article introduces a voice-controlled robotic system for early education, enabling children as young as four to interact with robots using natural voice commands. Recognizing the challenges posed by programming languages and robot theory for young learners, this study leverages recent advancements in artificial intelligence, such as large language models, to make robots more intelligent and easier to use. This innovative approach fosters a natural and intuitive interaction between the child and the robot, effectively removing barriers to access and expanding the educational possibilities of robotics in the classroom. In this context, a software pipeline is proposed that translates voice commands into robot actions. Each component is tested using different deep learning models and cloud services to determine their suitability, with the best ones being selected. Finally, the chosen setup is validated through an integration test involving children aged 4 to 6 years. Preliminary results demonstrate the system’s capability to accurately recognize and execute voice commands, highlighting its potential as a valuable educational tool for early education. © 2024 by the authors.",2024,4,Article,"@article{2-s2.0-85192750799,
  title={Voice-Controlled Robotics in Early Education: Implementing and Validating Child-Directed Interactions Using a Collaborative Robot and Artificial Intelligence},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Computer Science Education in ChatGPT Era: Experiences from an Experiment in a Programming Course for Novice Programmers,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85187912327&origin=inward,10.3390/math12050629,"AbstractView references

The use of large language models with chatbots like ChatGPT has become increasingly popular among students, especially in Computer Science education. However, significant debates exist in the education community on the role of ChatGPT in learning. Therefore, it is critical to understand the potential impact of ChatGPT on the learning, engagement, and overall success of students in classrooms. In this empirical study, we report on a controlled experiment with 182 participants in a first-year undergraduate course on object-oriented programming. Our differential study divided students into two groups, one using ChatGPT and the other not using it for practical programming assignments. The study results showed that the students’ performance is not influenced by ChatGPT usage (no statistical significance between groups with a p-value of 0.730), nor are the grading results of practical assignments (p-value 0.760) and midterm exams (p-value 0.856). Our findings from the controlled experiment suggest that it is safe for novice programmers to use ChatGPT if specific measures and adjustments are adopted in the education process. © 2024 by the authors.",2024,4,Article,"@article{2-s2.0-85187912327,
  title={Computer Science Education in ChatGPT Era: Experiences from an Experiment in a Programming Course for Novice Programmers},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
A Report on the Sixth Workshop on Emerging Software Engineering Education (WESEE 2024),https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186757810&origin=inward,10.1145/3641399.3641436,"AbstractView references

Software engineering is rapidly adapting to meet the demands of contemporary customers and the challenges posed by relentless technological advancements. A well-prepared and highly competent workforce is crucial to propel this evolution, making it a pivotal element for the successful future of software engineering. To instill the art and science of software engineering across diverse age groups, innovative teaching methods must be introduced at all levels of education dissemination. Software engineering stands out as one of the most dynamic subjects in computer science curricula, spanning both undergraduate and postgraduate levels, given the continuous emergence of new software development process models, methods, and tools. A comprehensive software engineering course should encompass various processes, methods, and tools necessary to support large-scale software systems’ development, operation, and maintenance. Moreover, these courses should significantly emphasize developing the interpersonal and communication skills essential for a well-rounded software engineer. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2024,4,Conference Paper,"@article{2-s2.0-85186757810,
  title={A Report on the Sixth Workshop on Emerging Software Engineering Education (WESEE 2024)},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Design criteria for AI-based IT systems,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182981944&origin=inward,10.1007/s11548-024-03064-8,"AbstractView references

Purpose: This editorial relates to a panel discussion during the CARS 2023 congress that addressed the question on how AI-based IT systems should be designed that record and (transparently) display a reproducible path on clinical decision making. Even though the software engineering approach suggested for this endeavor is of a generic nature, it is assumed that the listed design criteria are applicable to IT system development also for the domain of radiology and surgery. Methods: An example of a possible design approach is outlined by illustrating on how to move from data, information, knowledge and models to wisdom-based decision making in the context of a conceptual GPT system design. In all these design steps, the essential requirements for system quality, information quality, and service quality may be realized by following the design cycle as suggested by A.R. Hevner, appropriately applied to AI-based IT systems design. Results: It can be observed that certain state-of-the-art AI algorithms and systems, such as large language models or generative pre-trained transformers (GPTs), are becoming increasingly complex and, therefore, need to be rigorously examined to render them transparent and comprehensible in their usage for all stakeholders involved in health care. Further critical questions that need to be addressed are outlined and complemented with some suggestions, that a possible design framework for a stakeholder specific AI system could be a (modest) GPT based on a small language model. Discussion: A fundamental question for the future remains whether society wants a quasi-wisdom-oriented healthcare system, based on data-driven intelligence with AI, or a human curated wisdom based on model-driven intelligence (with and without AI). Special CARS workshops and think tanks are planned to address this challenging question and possible new direction for assisting selected medical disciplines, e.g., radiology and surgery. © CARS 2024.",2024,6,Editorial,"@article{2-s2.0-85182981944,
  title={Design criteria for AI-based IT systems},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"""It's not like Jarvis, but it's pretty close!"" - Examining ChatGPT's Usage among Undergraduate Students in Computer Science",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182949202&origin=inward,10.1145/3636243.3636257,"AbstractView references

Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2024,10,Conference Paper,"@article{2-s2.0-85182949202,
  title={""It's not like Jarvis, but it's pretty close!"" - Examining ChatGPT's Usage among Undergraduate Students in Computer Science},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Next-Step Hint Generation for Introductory Programming Using Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182947216&origin=inward,10.1145/3636243.3636259,"AbstractView references

Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student's code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2024,10,Conference Paper,"@article{2-s2.0-85182947216,
  title={Next-Step Hint Generation for Introductory Programming Using Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182946993&origin=inward,10.1145/3636243.3636245,"AbstractView references

Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior - in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming. © 2024 Copyright held by the owner/author(s).",2024,8,Conference Paper,"@article{2-s2.0-85182946993,
  title={Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182946916&origin=inward,10.1145/3636243.3636249,"AbstractView references

Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students' use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course (n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools. © 2024 Copyright held by the owner/author(s).",2024,9,Conference Paper,"@article{2-s2.0-85182946916,
  title={Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182943874&origin=inward,10.1145/3636243.3636263,"AbstractView references

Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2024,10,Conference Paper,"@article{2-s2.0-85182943874,
  title={More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182920352&origin=inward,10.1145/3636243.3636247,"AbstractView references

Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2024,10,Conference Paper,"@article{2-s2.0-85182920352,
  title={More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Evaluating LLM-generated Worked Examples in an Introductory Programming Course,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182919169&origin=inward,10.1145/3636243.3636252,"AbstractView references

Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, 'WorkedGen', which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for op-timising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen's value in a range of programming languages, and with more complex questions suitable for more advanced courses. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2024,10,Conference Paper,"@article{2-s2.0-85182919169,
  title={Evaluating LLM-generated Worked Examples in an Introductory Programming Course},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85179252252&origin=inward,10.1145/3636243.3636256,"AbstractView references

There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models (LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts. © 2024 Copyright held by the owner/author(s).",2024,10,Conference Paper,"@article{2-s2.0-85179252252,
  title={A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
The Impact of ChatGPT on Students’ Learning Programming Languages,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196858578&origin=inward,10.1007/978-3-031-61691-4_14,"AbstractView references

This study addresses the gap in understanding the impact of ChatGPT, on Java programming language education. We examined ChatGPT's afinity on undergraduate Information Systems students learning Java through a mixed-methods approach. Quantitatively, we assessed constructs like ChatGPT Prompting Skills, Trust, Objective Values, and their relationship with student satisfaction, revealing mixed effectiveness. Qualitatively, we explored students’ perspectives, uncovering insights into ChatGPT's role in coding support and the nuances of its educational impact. Our findings indicate that while ChatGPT can enhance certain aspects of learning, its effectiveness varies with context and task complexity. Key positive findings from the regression analysis indicated that ChatGPT's prompting skills positively impacted both Objective and Subjective Values, suggesting a significant role in enhancing students’ understanding and engagement with programming concepts. This positive influence extends to the relationship between Subjective Value and Student Satisfaction, highlighting the importance of students’ subjective experiences in their overall satisfaction with learning programming languages. The study contributes to the evolving discourse on AI in education, highlighting the need to integrate LLMs carefully in educational settings. It underscores the importance of aligning AI tools with specific learning objectives and outlines implications for educators and AI developers in optimizing these tools for educational purposes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,13,Conference Paper,"@article{2-s2.0-85196858578,
  title={The Impact of ChatGPT on Students’ Learning Programming Languages},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Exploring Explainability and Transparency in Automated Essay Scoring Systems: A User-Centered Evaluation,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196844294&origin=inward,10.1007/978-3-031-61691-4_18,"AbstractView references

In recent years, rapid advancements in computer science, including increased capabilities of machine learning models like Large Language Models (LLMs) and the accessibility of large datasets, have facilitated the widespread adoption of AI technology, underscoring the need to ethically design and evaluate these technologies with concern for their impact on students and teachers. Specifically, the rise of Automated Essay Scoring (AES) platforms have made it possible to provide real-time feedback and grades for student essays. Despite the increasing development and use of AES platforms, limited research has focused on AI explainability and algorithm transparency and their influence on the usability of these platforms. To address this gap, we conducted a qualitative study on an AI-based essay writing and grading platform, Packback Deep Dives, with a primary focus of exploring the experiences of students and graders. The study aimed to explore the system’s usability related to explainability and transparency and to uncover the resulting implications for users. Participants took part in surveys, semi-structured interviews, and a focus group. The findings reveal several important considerations for evaluating AES systems, including the clarity of feedback and explanations, effectiveness and actionability of feedback and explanations, perceptions and misconceptions of the system, evolving trust in AI judgments, user concerns and fairness perceptions, system efficiency and feedback quality, user interface accessibility and design, and system enhancement design priorities. These proposed key considerations can help guide the development of effective essay feedback and grading tools that prioritize explainability and transparency to improve usability. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,17,Conference Paper,"@article{2-s2.0-85196844294,
  title={Exploring Explainability and Transparency in Automated Essay Scoring Systems: A User-Centered Evaluation},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Potentiality of generative AI tools in higher education: Evaluating ChatGPT's viability as a teaching assistant for introductory programming courses,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196750884&origin=inward,10.3934/steme.2024011,"AbstractView references

With the advent of large language models like ChatGPT, there is interest in leveraging these tools as teaching assistants in higher education. However, important questions remain regarding the effectiveness and appropriateness of AI systems in educational settings. This study evaluated ChatGPT's potential as a teaching assistant for an introductory programming course. We conducted an experimental study where ChatGPT was prompted in response to common student questions and misconceptions from a first-year programming course. This study was conducted over a period of 2 weeks with 20 undergraduate students and 5 faculty members from the department of computer science. ChatGPT's responses were evaluated along several dimensions—accuracy, completeness, pedagogical soundness, and the ability to resolve student confusion by five course faculties through a survey. Additionally, another survey was administered to students in the course to assess their perception of ChatGPT's usefulness after interacting with the tool. The findings suggested that while ChatGPT demonstrated strengths in explaining introductory programming concepts accurately and completely, it showed weaknesses in resolving complex student confusion, adapting responses to individual needs, and providing tailored debugging assistance. This study highlighted key areas needing improvement and provided a basis to develop responsible integration strategies that harness AI to enrich rather than replace human instruction in technical courses. The results, based on the limited sample size and study duration, indicated that ChatGPT has potential as a supplemental teaching aid for core concepts, but also highlighted areas where human instruction may be particularly valuable, such as providing advanced support. Further research with larger samples and longer study periods is needed to assess the generalizability of these findings. © 2024 The Author(s), licensee by AIMS Press.",2024,18,Article,"@article{2-s2.0-85196750884,
  title={Potentiality of generative AI tools in higher education: Evaluating ChatGPT's viability as a teaching assistant for introductory programming courses},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Chat-GPT Based Learning Platform for Creation of Different Attack Model Signatures and Development of Defense Algorithm for Cyberattack Detection,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196739162&origin=inward,10.1109/TLT.2024.3417252,"AbstractView references

Cloud adoption in industrial sectors such as process, manufacturing, healthcare, and finance has been steadily rising, but as it grows the risk of targeted cyberattacks has increased. Hence, effectively defending against such attacks necessitates skilled cybersecurity professionals. Traditional human-based cyber-physical education is resource intensive and faces challenges in keeping pace with rapidly evolving technologies. This research focuses on the main advantages of incorporating Large Language Models (LLMs) into cyber-physical education. The Chat-GPT platform serves as an online tool to educate students on fundamentals, cyberattacks and defense concepts, fostering the development of a new generation cybersecurity experts. The proposed learning approach adheres to the Chat-GPT assisted learn-apply-create model. Responding to prompts provided by the learners, the learning phase engages in conceptual learning, the apply phase involves mathematical modelling of various cyberattacks, and the create phase develops MATLAB program to incorporate attacks into sensor measurements for the experiment and entails developing the necessary attack detection approaches. The effectiveness of the detection method developed by Chat-GPT is assessed in both simulation and real-time scenarios using J-type thermocouple. The impact of the proposed learning platform over traditional learning methods is evaluated through an extensive comparative feedback analysis on the learner&#x0027;s foundational concepts, computational thinking, programming efficacy, and motivation. The study proved that integrating Chat-GPT into engineering education enables students to swiftly learn cyber-physical fundamentals, comprehend and model cyberattacks, create new attack signatures, and contribute to developing detection algorithms. Such integration provides the learners with essential industrial skills crucial in modern industries. IEEE",2024,4,Article,"@article{2-s2.0-85196739162,
  title={Chat-GPT Based Learning Platform for Creation of Different Attack Model Signatures and Development of Defense Algorithm for Cyberattack Detection},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"ChatGPT in veterinary medicine: a practical guidance of generative artificial intelligence in clinics, education, and research",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196619515&origin=inward,10.3389/fvets.2024.1395934,"AbstractView references

ChatGPT, the most accessible generative artificial intelligence (AI) tool, offers considerable potential for veterinary medicine, yet a dedicated review of its specific applications is lacking. This review concisely synthesizes the latest research and practical applications of ChatGPT within the clinical, educational, and research domains of veterinary medicine. It intends to provide specific guidance and actionable examples of how generative AI can be directly utilized by veterinary professionals without a programming background. For practitioners, ChatGPT can extract patient data, generate progress notes, and potentially assist in diagnosing complex cases. Veterinary educators can create custom GPTs for student support, while students can utilize ChatGPT for exam preparation. ChatGPT can aid in academic writing tasks in research, but veterinary publishers have set specific requirements for authors to follow. Despite its transformative potential, careful use is essential to avoid pitfalls like hallucination. This review addresses ethical considerations, provides learning resources, and offers tangible examples to guide responsible implementation. A table of key takeaways was provided to summarize this review. By highlighting potential benefits and limitations, this review equips veterinarians, educators, and researchers to harness the power of ChatGPT effectively. Copyright © 2024 Chu.",2024,4,Short Survey,"@article{2-s2.0-85196619515,
  title={ChatGPT in veterinary medicine: a practical guidance of generative artificial intelligence in clinics, education, and research},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Conceptual Data Normalisation from the Practical View of Using Graph Databases,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196186509&origin=inward,10.1007/978-3-031-61003-5_21,"AbstractView references

This article deals with a practical and synthetic view of conceptual modelling. It suggests four graph database normal forms organised into two levels of conceptual modelling: data and metadata, with room for yet one conceivable graph normal form based on old approaches, such as object-oriented class normalisation and the idea of conceptual symmetry. Attention is also paid to bridging the semantic gap between a database on the server side and a programming language on the client side, which argues for using graph databases as better data sources for business intelligence systems and working with machine learning language models. The authors applied their practical experience in teaching database modelling at a university and many years of experience in software development in Smalltalk, Python, Java, and C#. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,12,Conference Paper,"@article{2-s2.0-85196186509,
  title={Conceptual Data Normalisation from the Practical View of Using Graph Databases},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Enhancing E-Learning Experience Through Embodied AI Tutors in Immersive Virtual Environments: A Multifaceted Approach for Personalized Educational Adaptation,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196174389&origin=inward,10.1007/978-3-031-60609-0_20,"AbstractView references

As digital education transcends traditional boundaries, e-learning experiences are increasingly shaped by cutting-edge technologies like artificial intelligence (AI), virtual reality (VR), and adaptive learning systems. This study examines the integration of AI-driven personalized instruction within immersive VR environments, targeting enhanced learner engagement-a core metric in online education effectiveness. Employing a user-centric design, the research utilizes embodied AI tutors, calibrated to individual learners’ emotional intelligence and cognitive states, within a Python programming curriculum-a key area in computer science education. The methodology relies on intelligent tutoring systems and personalized learning pathways, catering to a diverse participant pool from Virginia Tech. Our data-driven approach, underpinned by the principles of educational psychology and computational pedagogy, indicates that AI-enhanced virtual learning environments significantly elevate user engagement and proficiency in programming education. Although the scope is limited to a single academic institution, the promising results advocate for the scalability of such AI-powered educational tools, with potential implications for distance learning, MOOCs, and lifelong learning platforms. This research contributes to the evolving narrative of smart education and the role of large language models (LLMs) in crafting bespoke educational experiences, suggesting a paradigm shift towards more interactive, personalized e-learning solutions that align with global educational technology trends. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,16,Conference Paper,"@article{2-s2.0-85196174389,
  title={Enhancing E-Learning Experience Through Embodied AI Tutors in Immersive Virtual Environments: A Multifaceted Approach for Personalized Educational Adaptation},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"Automated Analysis of Algorithm Descriptions Quality, Through Large Language Models",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195877099&origin=inward,10.1007/978-3-031-63028-6_20,"AbstractView references

In this paper we propose a method to classify the students’ textual descriptions of algorithms. This work is based on a wealth of data (programming tasks, related algorithm descriptions, and Peer Assessment data), coming from 6 years of use of the system Q2A, in a “Fundamentals of Computer Programming” course, given at first year in our university’s Computer Science curriculum. The descriptions are submitted, as part of the answer to a computer programming task, through Q2A, and are subject to (formative) Peer Assessment. The proposed classification method aims to support the teacher on the analysis of the quite numerous students’ descriptions, in ours as well as in other similar systems. We 1) process the students’ submissions, by topic automated extraction (BERTopic) and by separate Large Language Models, 2) compute their degree of suitability as “algorithm description”, in a scale from BAD to GOOD, and 3) compare the obtained classification with those coming from the teacher’s direct assessment (expert: one of the authors), and from the Peer Assessment. The automated classification does correlate with both the expert classification and the grades given by the peers to the “clarity” of the descriptions. This result is encouraging in view of the production of a Q2A subsystem allowing the teacher to analyse the students’ submissions guided by an automated classification, and ultimately support fully automated grading. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,14,Conference Paper,"@article{2-s2.0-85195877099,
  title={Automated Analysis of Algorithm Descriptions Quality, Through Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Analyzing the Role of Generative AI in Fostering Self-directed Learning Through Structured Prompt Engineering,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195866768&origin=inward,10.1007/978-3-031-63028-6_18,"AbstractView references

This study explores the use of Generative AI, particularly large language models such as ChatGPT, in promoting self-directed learning among beginners in programming and data analysis, in the study structured prompts were employed as a key tool to enhance educational engagement and skill acquisition. To study the impact, Engineering students participated in a controlled environment where they utilized these prompts in conjunction with Generative AI to tackle programming-based data analysis tasks independently. We measured the impact of this method by comparing pre-test and post-test scores, which showed a significant improvement, indicating its effectiveness. Moreover, 45% of novice participants completed all assigned tasks. We also conducted semi-structured interviews and analyzed participant responses to understand the role of prompt engineering in self-directed learning. The analysis revealed that structured prompts and Generative AI motivate students and empower them to learn independently. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,12,Conference Paper,"@article{2-s2.0-85195866768,
  title={Analyzing the Role of Generative AI in Fostering Self-directed Learning Through Structured Prompt Engineering},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Improving LLM Classification of Logical Errors by Integrating Error Relationship into Prompts,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195845148&origin=inward,10.1007/978-3-031-63028-6_8,"AbstractView references

LLMs trained in the understanding of programming syntax are now providing effective assistance to developers and are being used in programming education such as in generation of coding problem examples or providing code explanations. A key aspect of programming education is understanding and dealing with error message. However, ‘logical errors’ in which the program operates against the programmer’s intentions do not receive error messages from the compiler. In this study, building on existing research on programming errors, we first define the types of logical errors that can occur in programming in general. Based on the definition, we propose an effective approach for detecting logical errors with LLMs that makes use of relations among error types in the Chain-of-Thought and Tree-of-Thought prompts. The experimental results indicate that when such logical error descriptions in the prompt are used, the average classification performance is about 21% higher than the ones without them. We also conducted an experiment for exploiting the relations among errors in generating a new logical error dataset using LLMs. As there is very limited dataset for logical errors such benchmark dataset can be very useful for various programming related applications. We expect that our work can assist novice programmers in identifying the causes of code errors and correct them more effectively. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,13,Conference Paper,"@article{2-s2.0-85195845148,
  title={Improving LLM Classification of Logical Errors by Integrating Error Relationship into Prompts},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
First Steps in Constructing an AI-Powered Digital Twin Teacher: Harnessing Large Language Models in a Metaverse Classroom,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195604439&origin=inward,10.1109/VRW62533.2024.00266,"AbstractView references

This study proposes a ground-breaking idea at the intersection of Artificial Intelligence and virtual education: the creation of an AI-powered Digital Twin instructor in a Metaverse-based classroom using Large Language Models. We aim to build a teacher avatar capable of dynamic interactions with students, tailored teaching approaches, and contextual response inside a virtual world. The research aims to address two major issues for both students and teachers: the Digital Twin can provide feedbacks to resolve doubts about course content and material; also, it can improve student management and allow teachers to answer the trickiest questions raised by students. © 2024 IEEE.",2024,2,Conference Paper,"@article{2-s2.0-85195604439,
  title={First Steps in Constructing an AI-Powered Digital Twin Teacher: Harnessing Large Language Models in a Metaverse Classroom},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"When geoscience meets generative AI and large language models: Foundations, trends, and future challenges",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195594534&origin=inward,10.1111/exsy.13654,"AbstractView references

Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance. As one strives for enhanced safety, efficiency, and sustainability, generative AI indeed emerges as a key differentiator and promises a paradigm shift in the field. This article explores the potential applications of generative AI and large language models in geoscience. The recent developments in the field of machine learning and deep learning have enabled the generative model's utility for tackling diverse prediction problems, simulation, and multi-criteria decision-making challenges related to geoscience and Earth system dynamics. This survey discusses several GAI models that have been used in geoscience comprising generative adversarial networks (GANs), physics-informed neural networks (PINNs), and generative pre-trained transformer (GPT)-based structures. These tools have helped the geoscience community in several applications, including (but not limited to) data generation/augmentation, super-resolution, panchromatic sharpening, haze removal, restoration, and land surface changing. Some challenges still remain, such as ensuring physical interpretation, nefarious use cases, and trustworthiness. Beyond that, GAI models show promises to the geoscience community, especially with the support to climate change, urban science, atmospheric science, marine science, and planetary science through their extraordinary ability to data-driven modelling and uncertainty quantification. © 2024 The Author(s). Expert Systems published by John Wiley & Sons Ltd.",2024,4,Article,"@article{2-s2.0-85195594534,
  title={When geoscience meets generative AI and large language models: Foundations, trends, and future challenges},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Generative AI for Productivity in Industry and Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194191340&origin=inward,10.5220/0012736200003708,"AbstractView references

Generative AI tools are the cutting edge solutions of complex AI related problems. While investigating stateof- the-art results related to the effect of GenAI in the literature, one can note that the trends most likely lead to the expectation of a positive effect on the middle and long run. Based on these findings we define 4 productivity gain related hypotheses that we study using two types of methodologies. Namely we perform a survey research related to university-industry collaboration and quantitative studies mainly based on industrial productivity metrics. We have partnered with a major IT services provider - EPAM Systems - to be able to track, validate and analyze the key productivity metrics of software development projects, with and without using GenAI tools. This evaluation is being performed on various stages of the Software Development Lifecycle (SDLC) and on several project roles. Our goal is to measure the productivity increase provided by GenAI tools. Although this research has just started recently, considering that the area has extremely high attention we present some initial findings. Copyright © 2024 by SCITEPRESS - Science and Technology Publications, Lda.",2024,8,Conference Paper,"@article{2-s2.0-85194191340,
  title={Generative AI for Productivity in Industry and Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Automated Program Repair for Introductory Programming Assignments,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194035461&origin=inward,10.1109/TLT.2024.3403710,"AbstractView references

Automatic program repair (APR) tools are valuable for students to assist them with debugging tasks since program repair captures the code modification to make a buggy program pass the given test-suite. However, the process of manually generating catalogs of code modifications is intricate and time-consuming. This article proposes contextual error model repair (CEMR), an automated program repair tool for introductory programming assignments. CEMR is designed to learn program code modifications from incorrect-correct code pairs automatically. Then, it utilizes these code modifications along with CodeBERT, a generative AI, to repair students' new incorrect programs in the same programming assignment. CEMR builds on the observation that code edits performed by students in pairs of incorrect-correct code can be used as input-output examples for learning code modifications. The key idea of CEMR is to leverage the wisdom of the crowd: it uses the existing code modifications of incorrect-correct student code pairs to repair the new incorrect student attempts. We chose three of the most related APR tools, Refazer, Refactory, and AlphaRepair, as the baselines to compare against CEMR. The experimental results demonstrate that, on public and real classroom datasets, CEMR achieves higher repair rates than the baselines. Through further analysis, CEMR has demonstrated promising effectiveness in addressing semantical and logical errors while its performance in fixing syntactical errors is limited. In terms of time for repairing buggy programs, CEMR costs approximately half as much as AlphaRepair requires. We opine that CEMR not only be seen as a program repair method that achieves good results with incorrect-correct code pairs but also be further utilized to generate hints to better assist students in learning programming. © 2008-2011 IEEE.",2024,16,Article,"@article{2-s2.0-85194035461,
  title={Automated Program Repair for Introductory Programming Assignments},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
The Impact of Structured Prompt-Driven Generative AI on Learning Data Analysis in Engineering Students,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193980577&origin=inward,10.5220/0012693000003693,"AbstractView references

This paper investigates the use of Generative AI chatbots, especially large language models like ChatGPT, in enhancing data analysis skills through structured prompts in an educational setting. The study addresses the challenge of deploying AI tools for learners new to programming and data analysis, focusing on the role of structured prompt engineering as a facilitator. In this study Engineering students were trained to adeptly use structured prompts in conjunction with Generative AI, to improve their data analysis skills. The t-test comparing pre-test and post-test scores on programming and data analysis shows a significant difference, indicating learning progress. Additionally, the task completion rate reveals that 45% of novice participants completed tasks using Generative AI and structured prompts. This finding highlights the transformative impact of Generative AI in education, indicating a shift in learning experiences and outcomes. The integration of structured prompts with Generative AI not only aids skill development but also marks a new direction in educational methodologies. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.",2024,8,Conference Paper,"@article{2-s2.0-85193980577,
  title={The Impact of Structured Prompt-Driven Generative AI on Learning Data Analysis in Engineering Students},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Global insights and the impact of generative AI-ChatGPT on multidisciplinary: a systematic review and bibliometric analysis,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193476010&origin=inward,10.1080/09540091.2024.2353630,"AbstractView references

In 2022, OpenAI's unveiling of generative AI Large Language Models (LLMs)- ChatGPT, heralded a significant leap forward in human-machine interaction through cutting-edge AI technologies. With its surging popularity, scholars across various fields have begun to delve into the myriad applications of ChatGPT. While existing literature reviews on LLMs like ChatGPT are available, there is a notable absence of systematic literature reviews (SLRs) and bibliometric analyses assessing the research's multidisciplinary and geographical breadth. This study aims to bridge this gap by synthesising and evaluating how ChatGPT has been integrated into diverse research areas, focussing on its scope and the geographical distribution of studies. Through a systematic review of scholarly articles, we chart the global utilisation of ChatGPT across various scientific domains, exploring its contribution to advancing research paradigms and its adoption trends among different disciplines. Our findings reveal a widespread endorsement of ChatGPT across multiple fields, with significant implementations in healthcare (38.6%), computer science/IT (18.6%), and education/research (17.3%). Moreover, our demographic analysis underscores ChatGPT's global reach and accessibility, indicating participation from 80 unique countries in ChatGPT-related research, with the most frequent countries keyword occurrence, USA (719), China (181), and India (157) leading in contributions. Additionally, our study highlights the leading roles of institutions such as King Saud University, the All India Institute of Medical Sciences, and Taipei Medical University in pioneering ChatGPT research in our dataset. This research not only sheds light on the vast opportunities and challenges posed by ChatGPT in scholarly pursuits but also acts as a pivotal resource for future inquiries. It emphasises that the generative AI (LLM) role is revolutionising every field. The insights provided in this paper are particularly valuable for academics, researchers, and practitioners across various disciplines, as well as policymakers looking to grasp the extensive reach and impact of generative AI technologies like ChatGPT in the global research community. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",2024,4,Review,"@article{2-s2.0-85193476010,
  title={Global insights and the impact of generative AI-ChatGPT on multidisciplinary: a systematic review and bibliometric analysis},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Medical education with large language models in ophthalmology: Custom instructions and enhanced retrieval capabilities,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193318097&origin=inward,10.1136/bjo-2023-325046,"AbstractView references

Foundation models are the next generation of artificial intelligence that has the potential to provide novel use cases for healthcare. Large language models (LLMs), a type of foundation model, are capable of language comprehension and the ability to generate human-like text. Researchers and developers have been tuning LLMs to optimise their performance in specific tasks, such as medical challenge problems. Until recently, tuning required technical programming expertise, but the release of custom generative pre-trained transformers (GPTs) by OpenAI has allowed users to tune their own GPTs with natural language. This has the potential to democratise access to high-quality bespoke LLMs globally. In this review, we provide an overview of LLMs, how they are tuned and how custom GPTs work. We provide three use cases of custom GPTs in ophthalmology to demonstrate the versatility and effectiveness of these tools. First, we present 'EyeTeacher', an educational aid that generates questions from clinical guidelines to facilitate learning. Second, we built 'EyeAssistant', a clinical support tool that is tuned with clinical guidelines to respond to various physician queries. Lastly, we design 'The GPT for GA', which offers clinicians a comprehensive summary of emerging management strategies for geographic atrophy by analysing peer-reviewed documents. The review underscores the significance of custom instructions and information retrieval in tuning GPTs for specific tasks in ophthalmology. We also discuss the evaluation of LLM responses and address critical aspects such as privacy and accountability in their clinical application. Finally, we discuss their potential in ophthalmic education and clinical practice. © Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY. Published by BMJ.",2024,4,Review,"@article{2-s2.0-85193318097,
  title={Medical education with large language models in ophthalmology: Custom instructions and enhanced retrieval capabilities},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Developing Future Computational Thinking in Foundational CS Education: A Case Study From a Liberal Education University in India,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193278986&origin=inward,10.1109/TE.2024.3394060,"AbstractView references

&lt;italic&gt;Contribution: &lt;/italic&gt;This article proposes a new theoretical model with a goal to develop future human computational thinking (CT) in foundational computer science (CS) education. The model blends six critical types of thinking, i.e., logical thinking, systems thinking, sustainable thinking, strategic thinking, creative thinking, and responsible thinking into the design of a first-year undergraduate programming course. The study describes a creative blended pedagogy that embeds the proposed model into the course plan. &lt;italic&gt;Background:&lt;/italic&gt; The emergence of artificial intelligent systems such as large language models from a knowledge provider perspective, coupled with a gradual change in post-pandemic outlook of education challenge the relevance and raises concerns about the future of education. The 21st-century human CT requirements, viz., learning to code (skill) and thinking computationally (competency), will be inadequate in the future. Moreover, there is substantial evidence which shows that most introductory programming courses fail to integrate critical elements like ethics and responsibility as part of the course. &lt;italic&gt;Intended Outcomes:&lt;/italic&gt; The authors anticipate experiential learning models such as this has immense potential to future-proof CS education, as well as make future software engineers responsible citizens. &lt;italic&gt;Application Design:&lt;/italic&gt; The proposed model blends six types of thinking into the design and activities of the course. The underlying theoretical basis of these activities revolve around three key principles: 1) experiential learning; 2) self-reflection; and 3) peer learning. &lt;italic&gt;Findings:&lt;/italic&gt; This case study from a liberal educational institution in India qualitatively shows evidence of students developing six critical elements of thinking that shapes their future CT ability. IEEE",2024,4,Article,"@article{2-s2.0-85193278986,
  title={Developing Future Computational Thinking in Foundational CS Education: A Case Study From a Liberal Education University in India},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Dear ChatGPT - can you teach me how to program an app for laboratory medicine?,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193251497&origin=inward,10.1515/labmed-2024-0034,"AbstractView references

The multifaceted potential of ChatGPT in the medical domain remains underexplored, particularly regarding its application in software development by individuals with a medical background but limited information technology expertise. This study investigates ChatGPT's utility in creating a laboratory medicine application. Despite minimal programming skills, the authors successfully developed an automated intra-assay, inter-device precision test for immunophenotyping with a shiny user interface, facilitated by ChatGPT. While the coding process was expedited, meticulous oversight and error correction by the authors were imperative. These findings highlight the value of large language models such as ChatGPT in code-based application development for automating work processes in a medical context. Particularly noteworthy is the facilitation of these tasks for non-technically trained medical professionals and its potential for digital medical education. © 2024 Walter de Gruyter GmbH. All rights reserved.",2024,4,Article,"@article{2-s2.0-85193251497,
  title={Dear ChatGPT - can you teach me how to program an app for laboratory medicine?},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Evaluation of LLM Tools for Feedback Generation in a Course on Concurrent Programming,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193209573&origin=inward,10.1007/s40593-024-00406-0,"AbstractView references

The emergence of Large Language Models (LLMs) has marked a significant change in education. The appearance of these LLMs and their associated chatbots has yielded several advantages for both students and educators, including their use as teaching assistants for content creation or summarisation. This paper aims to evaluate the capacity of LLMs chatbots to provide feedback on student exercises in a university programming course. The complexity of the programming topic in this study (concurrency) makes the need for feedback to students even more important. The authors conducted an assessment of exercises submitted by students. Then, ChatGPT (from OpenAI) and Bard (from Google) were employed to evaluate each exercise, looking for typical concurrency errors, such as starvation, deadlocks, or race conditions. Compared to the ground-truth evaluations performed by expert teachers, it is possible to conclude that none of these two tools can accurately assess the exercises despite the generally positive reception of LLMs within the educational sector. All attempts result in an accuracy rate of 50%, meaning that both tools have limitations in their ability to evaluate these particular exercises effectively, specifically finding typical concurrency errors. © The Author(s) 2024.",2024,4,Article,"@article{2-s2.0-85193209573,
  title={Evaluation of LLM Tools for Feedback Generation in a Course on Concurrent Programming},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"Advanced Video Transcription And Summarization A Synergy of Langchain, Language Models, And VectorDB with Mozilla Deep Speech",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85192517174&origin=inward,10.1109/ic-ETITE58242.2024.10493791,"AbstractView references

This paper introduces an advanced automated information management system, addressing the critical need for effective transcription and summarization in the face of the burgeoning volume of video data. The study's objective is to overcome the limitations of existing methods, primarily in handling vast video transcriptions and enhancing information retrieval. We propose an innovative integration of Mozilla Deep Speech, LangChain, VectorDB, and Large Language Models (LLMs), aiming to significantly improve the efficiency and accuracy of document-oriented processes in various sectors. Our approach leverages generative AI to transform the way organizations process video content, offering a solution to the lengthy and often challenging transcription tasks that current technologies struggle with. We highlight the potential economic impact, as underscored by a McKinsey study, indicating a substantial contribution of these technologies to various industries, particularly in customer service, sales, marketing, and software development. The methodology encompasses a comprehensive system architecture, utilizing NLP techniques and models like BERT, GPT, and spaCy, addressing the shortcomings of existing approaches with enhanced precision and adaptability. Initial findings demonstrate a transformative improvement in video summarization, providing significant benefits in education, journalism, and accessibility for the hearing impaired. This research not only offers a novel solution to existing challenges in data management but also sets a new standard for the application of generative AI and LLMs in automated information processing. © 2024 IEEE.",2024,4,Conference Paper,"@article{2-s2.0-85192517174,
  title={Advanced Video Transcription And Summarization A Synergy of Langchain, Language Models, And VectorDB with Mozilla Deep Speech},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85192199453&origin=inward,10.1109/TLT.2024.3396735,"AbstractView references

Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local 'lessons learned' database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios. © 2008-2011 IEEE.",2024,16,Article,"@article{2-s2.0-85192199453,
  title={Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Transformative Potentials and Ethical Considerations of AI Tools in Higher Education: Case Studies and Reflections,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85191707452&origin=inward,10.1109/SoutheastCon52093.2024.10500042,"AbstractView references

This paper examines the transformative impact of Artificial Intelligence (AI) tools, especially Large Language Models like ChatGPT, on higher education. Focusing on how AI can enhance and challenge the learning environment, it navigates through the benefits and ethical concerns, such as privacy issues, overreliance on the technology itself, and potential biases. The article's core comprises two practical case studies-one in computer science, where ChatGPT aids in teaching programming, and another in English composition, exploring its role in developing writing skills. In the computer science context, ChatGPT shows how AI can introduce diverse problem-solving approaches and elevate student engagement, with notable improvements in students' comprehension and application of programming techniques. In English composition, the integration of ChatGPT assists in crafting texts, highlighting the balance needed between AI assistance and human critical thinking. Concluding with a call for a balanced approach, the study emphasizes that AI should complement, not substitute, traditional teaching methods. It advocates for a responsible and ethical application of AI in education, underlining the need to integrate technological advancements with fundamental core literacies to elevate the academic experience of all students. © 2024 IEEE.",2024,6,Conference Paper,"@article{2-s2.0-85191707452,
  title={Transformative Potentials and Ethical Considerations of AI Tools in Higher Education: Case Studies and Reflections},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
GPT-4/4V's performance on the Japanese National Medical Licensing Examination,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190874727&origin=inward,10.1080/0142159X.2024.2342545,"AbstractView references

Background: Recent advances in Artificial Intelligence (AI) are changing the medical world, and AI will likely replace many of the actions performed by medical professionals. The overall clinical ability of the AI has been evaluated by its ability to answer a text-based national medical examination. This study uniquely assesses the performance of Open AI's ChatGPT against all Japanese National Medical Licensing Examination (NMLE), including images, illustrations, and pictures. Methods: We obtained the questions of the past six years of the NMLE (112th to 117th) from the Japanese Ministry of Health, Labour and Welfare website. We converted them to JavaScript Object Notation (JSON) format. We created an application programming interface (API) to output correct answers using GPT-4 for questions without images and GPT4-V(ision) or GPT4 console for questions with images. Results: The percentage of image questions was 723/2400 (30.1%) over the past six years. In all years, GPT-4/4V exceeded the minimum score the examinee should score. In total, over the six years, the percentage of correct answers for basic medical knowledge questions was 665/905 (73.5%); for clinical knowledge questions, 1143/1531 (74.7%); and for image questions 497/723 (68.7%), respectively. Conclusions: Regarding medical knowledge, GPT-4/4V met the minimum criteria regardless of whether the questions included images, illustrations, and pictures. Our study sheds light on the potential utility of AI in medical education. © 2024 Informa UK Limited, trading as Taylor & Francis Group.",2024,4,Article,"@article{2-s2.0-85190874727,
  title={GPT-4/4V's performance on the Japanese National Medical Licensing Examination},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Academia and Industry Synergy: Addressing Integrity Challenge in Programming Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190799281&origin=inward,10.5220/0012451000003636,"AbstractView references

This research addresses the profound challenges presented by sophisticated large language models (LLMs) like ChatGPT, especially in the context of educational settings, focusing on computer science and programming instruction. State of the art LLMs are capable of generating solutions for standard exercises that are assigned to students to bolster their analytical and programming skills. However, the ease of using AI to generate programming solutions poses a risk to the educational process and skill development, as it may lead students to depend on these solutions instead of engaging in their own problem-solving efforts. Our study suggests collaborative methods involving computer science educators and AI developers to provide evaluators with tools to distinguish between code produced by ChatGPT and code genuinely created by students. We propose a novel steganography-based technique for watermarking AI-generated code. By implementing this comprehensive strategy and effectively utilizing such technology through the combined efforts of educators, course administrators, and partnerships with AI developers, we believe it is possible to preserve the integrity of programming education in an age increasingly influenced by LLMs capable of generating code. © 2024 by SCITEPRESS - Science and Technology Publications, Lda.",2024,9,Conference Paper,"@article{2-s2.0-85190799281,
  title={Academia and Industry Synergy: Addressing Integrity Challenge in Programming Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"Integrating LLMs in Higher Education, Through Interactive Problem Solving and Tutoring: Algorithmic Approach and Use Cases",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190386396&origin=inward,10.1007/978-3-031-56478-9_21,"AbstractView references

Despite the concerns that recent developments in Large Language Models (LLMs) have raised, they undoubtedly revealed a novel potential of Artificial Intelligence (AI) algorithms in educational environments. Whether they are used for tutoring, in a manner similar to that of Intelligent Tutoring Systems (ITS), or to support assessment design and delivery, their impact in a learning setting is remarkable. In this paper, we propose an interactive tutoring approach, utilizing ChatGPT’s API. By exploiting ChatGPT’s programming interface, we can develop customized interactive problem-solving and tutoring sessions on specific topics of interest. The API’s versatility allows for dynamic interactions, fostering a deeper understanding of subjects taught and effective problem-solving skills. We demonstrate the application of the developed code in an applied educational setting with specific use cases. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,17,Conference Paper,"@article{2-s2.0-85190386396,
  title={Integrating LLMs in Higher Education, Through Interactive Problem Solving and Tutoring: Algorithmic Approach and Use Cases},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190167220&origin=inward,10.1109/TLT.2024.3386095,"AbstractView references

Before interacting with real users, developers must be proficient in human-computer interaction (HCI) so as not to exhaust user patience and availability. For that, substantial training and practice are required, but it is costly to create a variety of high-quality HCI training materials. In this context, chat generative pretrained transformer (ChatGPT) and other chatbots based on large language models (LLMs) offer an opportunity to generate training materials of acceptable quality without foregoing specific human characteristics present in real-world scenarios. Personas is a user-centered design method that encompasses fictitious but believable user archetypes to help designers understand and empathize with their target audience during product design. We conducted an exploratory study on the Personas technique, addressing the validity and believability of interviews designed by HCI trainers and answered by ChatGPT-simulated users, which can be used as training material for persona creation. Specifically, we employed ChatGPT to respond to interviews designed by user experience (UX) experts. Two groups, HCI professors and professionals, then evaluated the validity of the generated materials considering quality, usefulness, UX, and ethics. The results show that both groups rated the interviews as believable and helpful for Personas training. However, some concerns about response repetition and low response variability suggested the need for further research on improved prompt design in order to generate more diverse and well-developed responses. The findings of this study provide insight into how HCI trainers can use ChatGPT to help their students master persona creation skills before working with real users in real-world scenarios for the first time. © 2008-2011 IEEE.",2024,16,Article,"@article{2-s2.0-85190167220,
  title={ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Analysis of ChatGPT Performance in Computer Engineering Exams,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189164499&origin=inward,10.1109/RITA.2024.3381842,"AbstractView references

The appearance of ChatGPT at the end of 2022 was a milestone in the field of Generative Artificial Intelligence. However, it also caused a shock in the academic world. For the first time, a simple interface allowed anyone to access a large language model and use it to generate text. These capabilities have a relevant impact on teaching-learning methodologies and assessment methods. This work aims to obtain an objective measure of ChatGPT's possible performance in solving exams related to computer engineering. For this purpose, it has been tested with actual exams of 15 subjects of the Software Engineering branch of a Spanish university. All the questions of these exams have been extracted and adapted to a text format to obtain an answer. Furthermore, the exams have been rewritten to be corrected by the teaching staff. In light of the results, ChatGPT can achieve relevant performance in these exams; it can pass many questions and problems of different natures in multiple subjects. A detailed study of the results by typology of questions and problems is provided as a fundamental contribution, allowing recommendations to be considered in the design of assessment methods. In addition, an analysis of the impact of the non-deterministic aspect of ChatGPT on the answers to test questions is presented, and the need to use a strategy to reduce this effect for performance analysis is concluded. © 2013 IEEE.",2024,10,Article,"@article{2-s2.0-85189164499,
  title={Analysis of ChatGPT Performance in Computer Engineering Exams},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Students' Experiences of Using ChatGPT in an Undergraduate Programming Course,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85188941721&origin=inward,10.1109/ACCESS.2024.3380909,"AbstractView references

Increasing use of artificial intelligence tools in programming education calls for a deeper understanding of their effect on students' learning. This paper presents a study that investigates the experiences of part-time undergraduate students using ChatGPT in a five-week Java programming course. After each exercise, students provided feedback via anonymous surveys in which they rated different suitability aspects of ChatGPT. The majority viewed ChatGPT positively and suitable for learning programming concepts. However, its suitability for specific implementation tasks received mixed reviews. Students found it easy to adapt ChatGPT's generated code to the exercises' implementation tasks. The students primarily used it for acquiring background knowledge, learning syntax and programming concepts and suggesting suitable algorithms. Yet, some abstained from using it due to concerns to not garner sufficient programming proficiency, retrieving partially incorrect or misleading generated code, preferring an independent working style, or general skepticism about its benefits. Finally, in response to our findings, we also discuss three perspective directions for improving the suitability of LLM chatbots for students in programming education. © 2013 IEEE.",2024,11,Article,"@article{2-s2.0-85188941721,
  title={Students' Experiences of Using ChatGPT in an Undergraduate Programming Course},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Assistant Teaching System for Computer Hardware Courses Based on Large Language Model,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85187778163&origin=inward,10.1007/978-981-97-0730-0_27,"AbstractView references

Recently, Large Language Models (LLMs), represented by ch1ChatGPT, have garnered significant attention in the field of education due to its impressive capabilities in text generation, comprehension, logical reasoning, and conversational abilities. We incorporate LLMs into the theoretical and experiment teaching of our Digital Logic and Computer Organization courses to enhance the teaching process. Specifically, we propose and implement an assistant teaching system consisting of a knowledge-based Question and Answer (Q &A) system and an assistant debugging and checking system. For the theoretical teaching session, the Q &A system utilizes historical Q &A records and ChatGPT to answer students’ questions. This system reduces the repetitive workload for teachers by answering similar questions, and allows students to receive answers in time. For the Field-Programmable Gate Array (FPGA)-based experiment teaching session, the assistant debugging and checking system employ debug assistance module to explain error messages for students. Furthermore, a LLM-generated code checking module assists teachers in detecting academic misconduct among students’ code submissions. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.",2023,13,Conference Paper,"@article{2-s2.0-85187778163,
  title={Assistant Teaching System for Computer Hardware Courses Based on Large Language Model},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer Multiple-Choice Questions for Programming Classes in Higher Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186684747&origin=inward,10.1007/978-3-031-53656-4_8,"AbstractView references

We explore the evolving efficacy of three generative pre-trained transformer (GPT) models in generating answers for multiple-choice questions (MCQ) from introductory and intermediate Python programming courses in higher education. We focus on the differences in capabilities of the models prior to the release of ChatGPT (Nov ’22), at the time of the release, and today (i.e., Aug ’23). Recent studies have established that the abilities of the OpenAI’s GPT models to handle assessments originally designed for humans keep increasing as the newer more capable models are released. However, the qualitative differences in the capabilities and limitations of these models to reason about and/or analyze programming MCQs have been under-explored. We evaluated three OpenAI’s GPT models on formative and summative MCQ assessments from three Python courses (530 questions) focusing on the qualitative differences in the evolving efficacy of the subsequent models. This study provides further evidence and insight into the trajectory of the current developments where there already exists a technology that can be utilized by students to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments. This study could be leveraged by educators and institutions to better understand the recent technological developments in order to adapt the design of programming assessments as well as to fuel the necessary discussions into how assessments in future programming classes should be updated. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,23,Conference Paper,"@article{2-s2.0-85186684747,
  title={From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer Multiple-Choice Questions for Programming Classes in Higher Education},
  author={N/A},
  journal={N/A},
  year={2052},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Examples and tutorials on using Google Colab and Gradio to create online interactive student-learning modules,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186584200&origin=inward,10.1002/cae.22729,"AbstractView references

This work provides online learning modules and instructions on how educators can leverage these technologies to help students learn in a personalized online environment. In particular, we focus on Google Colab, and the features provided by the Gradio Python library to provide interactivity within these modules. The contributions of this work include: (1) Development of a teaching framework using Gradio/Colab that offers automated grading and feedback for both educators and students; (2) Design of a versatile proposal, accommodating beginners with a straightforward interface while addressing the needs of advanced learners; (3) Creation of a comprehensive set of examples tailored for teaching digital logic subjects, with adaptability for application in various computer science areas. (4) A classification of these example learning modules in terms of their learning level for the students; (5) A novel client-server approach based on Colab/Gradio, allowing teachers to manage the main notebook efficiently while providing a lightweight and reliable interface for students. The goal of this work is to further expose educators to the remarkable capabilities that cloud computing brings to online supplemental education, noting that large language models such as ChatGPT complement this work, in that chatbots will be able to guide students in these dynamic simulations. © 2024 Wiley Periodicals LLC.",2024,4,Article,"@article{2-s2.0-85186584200,
  title={Examples and tutorials on using Google Colab and Gradio to create online interactive student-learning modules},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"Comprehensiveness, Accuracy, and Readability of Exercise Recommendations Provided by an AI-Based Chatbot: Mixed Methods Study",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186247690&origin=inward,10.2196/51308,"AbstractView references

Background: Regular physical activity is critical for health and disease prevention. Yet, health care providers and patients face barriers to implement evidence-based lifestyle recommendations. The potential to augment care with the increased availability of artificial intelligence (AI) technologies is limitless; however, the suitability of AI-generated exercise recommendations has yet to be explored. Objective: The purpose of this study was to assess the comprehensiveness, accuracy, and readability of individualized exercise recommendations generated by a novel AI chatbot. Methods: A coding scheme was developed to score AI-generated exercise recommendations across ten categories informed by gold-standard exercise recommendations, including (1) health condition-specific benefits of exercise, (2) exercise preparticipation health screening, (3) frequency, (4) intensity, (5) time, (6) type, (7) volume, (8) progression, (9) special considerations, and (10) references to the primary literature. The AI chatbot was prompted to provide individualized exercise recommendations for 26 clinical populations using an open-source application programming interface. Two independent reviewers coded AI-generated content for each category and calculated comprehensiveness (%) and factual accuracy (%) on a scale of 0%-100%. Readability was assessed using the Flesch-Kincaid formula. Qualitative analysis identified and categorized themes from AI-generated output. Results: AI-generated exercise recommendations were 41.2% (107/260) comprehensive and 90.7% (146/161) accurate, with the majority (8/15, 53%) of inaccuracy related to the need for exercise preparticipation medical clearance. Average readability level of AI-generated exercise recommendations was at the college level (mean 13.7, SD 1.7), with an average Flesch reading ease score of 31.1 (SD 7.7). Several recurring themes and observations of AI-generated output included concern for liability and safety, preference for aerobic exercise, and potential bias and direct discrimination against certain age-based populations and individuals with disabilities. Conclusions: There were notable gaps in the comprehensiveness, accuracy, and readability of AI-generated exercise recommendations. Exercise and health care professionals should be aware of these limitations when using and endorsing AI-based technologies as a tool to support lifestyle change involving exercise. © 2024 JMIR Publications Inc.. All rights reserved.",2024,4,Article,"@article{2-s2.0-85186247690,
  title={Comprehensiveness, Accuracy, and Readability of Exercise Recommendations Provided by an AI-Based Chatbot: Mixed Methods Study},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Large language models: a primer and gastroenterology applications,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186205690&origin=inward,10.1177/17562848241227031,"AbstractView references

Over the past year, the emergence of state-of-the-art large language models (LLMs) in tools like ChatGPT has ushered in a rapid acceleration in artificial intelligence (AI) innovation. These powerful AI models can generate tailored and high-quality text responses to instructions and questions without the need for labor-intensive task-specific training data or complex software engineering. As the technology continues to mature, LLMs hold immense potential for transforming clinical workflows, enhancing patient outcomes, improving medical education, and optimizing medical research. In this review, we provide a practical discussion of LLMs, tailored to gastroenterologists. We highlight the technical foundations of LLMs, emphasizing their key strengths and limitations as well as how to interact with them safely and effectively. We discuss some potential LLM use cases for clinical gastroenterology practice, education, and research. Finally, we review critical barriers to implementation and ongoing work to address these issues. This review aims to equip gastroenterologists with a foundational understanding of LLMs to facilitate a more active clinician role in the development and implementation of this rapidly emerging technology. © The Author(s), 2024.
Large language models in gastroenterology: a simplified overview for clinicians This text discusses the recent advancements in large language models (LLMs), like ChatGPT, which have significantly advanced artificial intelligence. These models can create specific, high-quality text responses without needing extensive training data or complex programming. They show great promise in transforming various aspects of clinical healthcare, particularly in improving patient care, medical education, and research. This article focuses on how LLMs can be applied in the field of gastroenterology. It explains the technical aspects of LLMs, their strengths and weaknesses, and how to use them effectively and safely. The text also explores how LLMs could be used in clinical practice, education, and research in gastroenterology. Finally, it discusses the challenges in implementing these models and the ongoing efforts to overcome them, aiming to provide gastroenterologists with the basic knowledge needed to engage more actively in the development and use of this emerging technology. © The Author(s), 2024.",2024,4,Review,"@article{2-s2.0-85186205690,
  title={Large language models: a primer and gastroenterology applications},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
A Qualitative Assessment of ChatGPT Generated Code in the Computer Science Curriculum,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185711696&origin=inward,10.1007/978-3-031-53022-7_5,"AbstractView references

The emergence of Large Language Models and their deployment in systems such as ChatGPT are poised to have a major impact on STEM education, particularly Computer Science. These generative large language models can produce program code as well as human language output. This has potentially serious implications for computer science programs and pedagogy. This work provides a qualitative assessment sample code generated by ChatGPT, as an example of an LLM explores implications for computing pedagogy.... © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",2024,11,Conference Paper,"@article{2-s2.0-85185711696,
  title={A Qualitative Assessment of ChatGPT Generated Code in the Computer Science Curriculum},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Training AI Model that Suggests Python Code from Student Requests in Natural Language,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185477197&origin=inward,10.2197/ipsjjip.32.69,"AbstractView references

Programming is a creative activity, but it can be difficult to learn due to constant updates, poorly maintained documentation, and unexpected errors. One reason for the difficulties is the shortage of programming teachers, which often leaves students unable to get help when they need it, even for simple questions. Many unanswered questions are a barrier to improving programming skills for creative purposes. The purpose of this paper is to address this issue by exploring whether an AI-based system can help reduce the difficulties faced by students. Recent advancements in deep learning technology have made it easier for teachers to train AI models that can learn from their own experiences in the classroom, including the types of questions, requests, and difficulties that students encounter. We have developed an AI model that can translate Python code from Japanese by using machine translation techniques and large language models. We have integrated this model into a learning assistant system that suggests code to students when they express their programming intentions. In this paper, we present our experiences in developing and deploying this AI-based assistant in the classroom, as well as the feedback we have received from students. By sharing our initial experiences, we aim to envision the potential of educational AI development for the future. © 2024 Information Processing Society of Japan.",2024,8,Article,"@article{2-s2.0-85185477197,
  title={Training AI Model that Suggests Python Code from Student Requests in Natural Language},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Detecting AI assisted submissions in introductory programming via code anomaly,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185132151&origin=inward,10.1007/s10639-024-12520-6,"AbstractView references

Artificial Intelligence (AI) can foster education but can also be misused to breach academic integrity. Large language models like ChatGPT are able to generate solutions for individual assessments that are expected to be completed independently. There are a number of automated detectors for AI assisted work. However, most of them are not dedicated to programming and/or they rely on existing student submissions (i.e., the learning approach). This paper presents a straightforward detector for AI assisted code, relying on code anomaly. No existing student submissions are needed. The detector employs 34 features covering constants, data structures, branches, loops, functions, and others. According to our evaluation on three data sets, the detector and its normalized variation are effective with 89% top-K precision. However, allowing discussion among colleagues and access to the internet might reduce the effectiveness by 25%. The effectiveness is further reduced by about the same amount when AI assistance is only used on some tasks, not the whole submissions. Although our detectors should be used with caution due to the limitations, it sufficiently shows that code anomaly can be distinctive for identifying AI assisted work. Instructors can start looking for the code anomaly among the submissions for such identification. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.",2024,4,Article,"@article{2-s2.0-85185132151,
  title={Detecting AI assisted submissions in introductory programming via code anomaly},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Practical Application of AI and Large Language Models in Software Engineering Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184992259&origin=inward,10.14569/IJACSA.2024.0150168,"AbstractView references

Subjects with limited application in the software industry like AI have recently received tremendous boon due to the development and raise of publicity of LLMs. LLM-powered software has a wide array of practical applications that must be taught to Software Engineering students, so that they can be relevant in the field. The speed of technological change is extremely fast, and university curriculums must include those changes. Renewing and creating new methodologies and workshops is a difficult task to complete successfully in such a dynamic environment full of cutting-edge technologies. This paper aims to showcase our approach to using LLM-powered software for AI generated images, like Stable diffusion and code generation tools like ChatGPT in workshops for two relevant subjects - Analysis of Software Requirements and Specifications, as well as Artificial Intelligence. A comparison between the different available LLMs that generate images is made, and the choice between them is explained. Student feedback is shown and a general positive and motivational impact is noted during and after the workshop. A brief introduction that covers the subjects where AI is applied is made. The proposed solutions for several uses of AI in the field of higher education, more specifically software engineering, are presented. Several workshops have been made and included in the curriculum. The results of their application have been noted and an analysis is made. More propositions on further development based on the gained experience, feedback and retrieved data are made. Conclusions are made on the application of AI in higher education and different ways to utilize such tools are presented. © (2024), (Science and Information Organization). All Rights Reserved.",2024,7,Article,"@article{2-s2.0-85184992259,
  title={Practical Application of AI and Large Language Models in Software Engineering Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Performance of Large Language Models in a Computer Science Degree Program,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184298297&origin=inward,10.1007/978-3-031-50485-3_40,"AbstractView references

Large language models such as ChatGPT-3.5 and GPT-4.0 are ubiquitous and dominate the current discourse. Their transformative capabilities have led to a paradigm shift in how we interact with and utilize (text-based) information. Each day, new possibilities to leverage the capabilities of these models emerge. This paper presents findings on the performance of different large language models in a university of applied sciences’ undergraduate computer science degree program. Our primary objective is to assess the effectiveness of these models within the curriculum by employing them as educational aids. By prompting the models with lecture material, exercise tasks, and past exams, we aim to evaluate their proficiency across different computer science domains. We showcase the strong performance of current large language models while highlighting limitations and constraints within the context of such a degree program. We found that ChatGPT-3.5 averaged 79.9% of the total score in 10 tested modules, BingAI achieved 68.4%, and LLaMa, in the 65 billion parameter variant, 20%. Despite these convincing results, even GPT-4.0 would not pass the degree program - due to limitations in mathematical calculations. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",1948,16,Conference Paper,"@article{2-s2.0-85184298297,
  title={Performance of Large Language Models in a Computer Science Degree Program},
  author={N/A},
  journal={N/A},
  year={1948},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT as a Fullstack Web Developer - Early Results,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85181976399&origin=inward,10.1007/978-3-031-48550-3_20,"AbstractView references

The arrival of ChatGPT has caused a lot of turbulence also in the field of software engineering in the past few months. Little is empirically known about the capabilities of ChatGPT to actually implement a complete system rather than a few code snippets. This paper reports the first-hand experiences from a graduate level student project where a real-life software platform for financial sector was implemented from the scratch by using ChatGPT for all possible software engineering tasks. The main conclusions drawn are as follows: 1) these findings demonstrate the potential for ChatGPT to be integrated into the software engineering workflow, 2) it can be used for creating a base for new components and for dividing coding tasks into smaller pieces, and 3) noticeable enhancements in ChatGPT-4, compared to ChatGPT-3.5, indicate superior working memory and the ability to continue incomplete responses, thereby leading to more coherent and less repetitive dialogues. © 2024, The Author(s).",2024,9,Conference Paper,"@article{2-s2.0-85181976399,
  title={ChatGPT as a Fullstack Web Developer - Early Results},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Enhancing Image Comprehension for Computer Science Visual Question Answering,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180752876&origin=inward,10.1007/978-981-99-8429-9_39,"AbstractView references

Computer science visual question answering is a fundamental task in the intelligent education. However, current models have poor performance in this task. There are mainly two issues in these models. Firstly, they cannot accurately capture the fine-grained objects and relations in images. Secondly, these models lack the computer domain knowledge. To address the issues, we propose an Image Comprehension Enhancing Model. Specifically, it uses object detection technique to capture fine-grained features of images and utilizes Optical Character Recognition (OCR) to transform fine-grained features into the text information. The model adopts the text information to prompt the large language model, which generates the image caption with the computer domain knowledge. The fine-grained features and image caption can enhance the model’s image comprehension and compensate the lack of knowledge. Additionally, the model utilizes the cross-modal attention mechanism to integrate the image features and fine-grained features of the image with the text features. The experimental results on the CSDQA dataset demonstrate that our proposed model outperforms the baselines, and the accuracy improves at least 4.80%. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",2024,12,Conference Paper,"@article{2-s2.0-85180752876,
  title={Enhancing Image Comprehension for Computer Science Visual Question Answering},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Towards LLM-Based System Migration in Language-Driven Engineering,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180157925&origin=inward,10.1007/978-3-031-49252-5_14,"AbstractView references

In this paper we show how our approach of extending Language Driven Engineering (LDE) with natural language-based code generation supports system migration: The characteristic decomposition of LDE into tasks that are solved with dedicated domain-specific languages divides the migration tasks into portions adequate to apply LLM-based code generation. We illustrate this effect by migrating a low-code/no-code generator for point-and-click adventures from JavaScript to TypeScript in a way that maintains an important property: generated web applications can automatically be validated via automata learning and model analysis by design. In particular, this allows to easily test the correctness of migration by learning the difference automaton for the generated products of the source and the target system of the migration. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.",2024,10,Conference Paper,"@article{2-s2.0-85180157925,
  title={Towards LLM-Based System Migration in Language-Driven Engineering},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
The Robots are Here: Navigating the Generative AI Revolution in Computing Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85177810142&origin=inward,10.1145/3623762.3633499,"AbstractView references

Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving. There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms. © 2023 Copyright held by the owner/author(s).",2023,52,Conference Paper,"@article{2-s2.0-85177810142,
  title={The Robots are Here: Navigating the Generative AI Revolution in Computing Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180957035&origin=inward,10.1145/3628162,"AbstractView references

With the immense interest in ChatGPT worldwide, education has seen a mix of both excitement and skepticism. To properly evaluate its impact on education, it is crucial to understand how far it can help students without prior knowledge answer assessment questions. This study aims to address this question as well as the impact of the question type. We conducted multiple experiments with computer engineering students (experiment group: n = 41 to 56), who were asked to use ChatGPT to answer previous test questions before learning about the related topics. Their scores were then compared with the scores of previous-term students who answered the same questions in a quiz or exam setting (control group: n = 24 to 61). The results showed a wide range of effect sizes, from −2.55 to 1.23, depending on the question type and content. The experiment group performed best answering code analysis and conceptual questions but struggled with code completion and questions that involved images. However, the performance in code generation tasks was inconsistent. Overall, the ChatGPT group’s answers lagged slightly behind the control group’s answers with an effect size of −0.16. We conclude that ChatGPT, at least in the field of this study, is not yet ready to rely on by students who do not have sufficient background to evaluate generated answers. We suggest that educators try using ChatGPT and educate students on effective questioning techniques and how to assess the generated responses. This study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development. © 2023 Copyright held by the owner/author(s).",2023,4,Article,"@article{2-s2.0-85180957035,
  title={Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Evaluating Copilot on CS1 Code Writing Problems with Suppressed Specifications,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180417465&origin=inward,10.1145/3627217.3627235,"AbstractView references

Code writing problems in introductory programming (CS1) courses typically ask students to write simple functions or programs based on detailed natural-language specifications. These details can be leveraged by large language models (LLMs), accessible to students via tools such as GitHub Copilot, to generate solutions that are often correct. CS1 instructors who are unwilling or unable to prohibit such usage must consider variants of traditional code writing problems that align with their learning objectives but are more difficult for LLMs to solve. Since LLMs are sensitive to the level of details in their prompts, it is natural to consider variants where details are progressively trimmed from the specifications of traditional code writing problems, and consequent ambiguities are clarified via examples. We consider an extreme variant, where all natural language is suppressed except for meaningful names of functions and their arguments. We evaluate the performance of Copilot on suppressed specification versions of 153 such problems drawn from the CodeCheck repository. If Copilot initially fails to generate a correct solution, we augment each suppressed specification with as few clarifying examples as possible to obtain a correct solution. Copilot solves 134 problems (87%) with just 0.7 examples on average, requiring no examples in 78 instances. Thus, modifying traditional code-writing problems by merely trimming specification details is unlikely to thwart sophisticated LLMs such as GitHub Copilot. © 2023 ACM.",2023,4,Conference Paper,"@article{2-s2.0-85180417465,
  title={Evaluating Copilot on CS1 Code Writing Problems with Suppressed Specifications},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180412902&origin=inward,10.1145/3627217.3627233,"AbstractView references

When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30 buggy student solutions across 6 code-writing problems. First, in a study with 5 undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30 buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations. © 2023 ACM.",2023,6,Conference Paper,"@article{2-s2.0-85180412902,
  title={Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"ChatGPT one year on: who is using it, how and why?",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85178232959&origin=inward,10.1038/d41586-023-03798-6,"AbstractView references

In just a year, ChatGPT has permeated scientific research. Seven scientists reveal what they have learnt about how the chatbot should — and shouldn’t — be used. [Figure not available: see fulltext.]. © 2023, Springer Nature Limited.",2023,3,Note,"@article{2-s2.0-85178232959,
  title={ChatGPT one year on: who is using it, how and why?},
  author={N/A},
  journal={N/A},
  year={7990},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Unleashing the potential: Positive impacts of generative AI on learning and teaching,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182290018&origin=inward,10.4018/979-8-3693-0074-9.ch002,"AbstractView references

Generative artificial intelligence, anchored by large language models (LLMs), is significantly altering the educational landscape. This chapter examines the impact of generative AI on education, illustrating its capability to create personalized content and transform learning environments. Despite concerns over academic dishonesty facilitated by LLMs, the chapter argues against a regressive stance and advocates for the constructive integration of AI into educational practices. By drawing on theories of learning, the chapter elucidates the pedagogical implications of generative AI and describes specific use cases in language learning, computer science, and mathematics. Highlighting both the potential and limitations of this emerging technology, the chapter posits that generative AI is not merely a disruptive force, but a revolutionary tool poised to redefine the methodologies of teaching and learning. © 2024, IGI Global.",2023,15,Book Chapter,"@article{2-s2.0-85182290018,
  title={Unleashing the potential: Positive impacts of generative AI on learning and teaching},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Always Provide Context: The Effects of Code Context on Programming Error Message Enhancement,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180801618&origin=inward,10.1145/3576882.3617909,"AbstractView references

Programming error messages (PEMs) are notoriously difficult for novice programmers to utilise. Many efforts have been made to enhance PEMs such that they are reworded to explain problems in terms that novices can understand. However, the effectiveness of these efforts to enhance PEMs has been weak or inconclusive. This work seeks to determine the role that code context has on programming error message enhancement. Erroneous Java code written by novices was sampled from the Blackbox Mini dataset. The erroneous code was presented to expert raters with four different PEM variants: javac (control), Decaf - an error message enhancing IDE - and two variants generated using GPT-4: one that enhanced just the javac error message alone, and one that incorporates the code context in the prompt. We find that providing code context to LLMs increases the likelihood of correct explanations for underlying errors, produces more specific fixes for erroneous programs, and produces fixes that are more likely to be correct. In large language models, the community now has a resource that is capable of taking code context into account, to the benefit of novice programmers. © 2023 Owner/Author.",2023,7,Conference Paper,"@article{2-s2.0-85180801618,
  title={Always Provide Context: The Effects of Code Context on Programming Error Message Enhancement},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Teaching Students To Use Programming Error Messages,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180005666&origin=inward,10.1145/3617650.3624950,"AbstractView references

Research shows many students struggle to use programming error and warning messages effectively. Instead of using these messages as aids to debug and fix their code, some students have negative emotional reactions to seeing 'angry red text'. Not utilizing programming error and warning messages effectively, or at all, increases the difficulty of learning to program. As compiler messages can vary by programming language and/or development environment, lessons on reading them are not typically included in mainstream educational materials. We believe this gap can be filled and that students can learn to use error messages to their advantage. Further, we believe that teaching students how to read and use error messages can have a significant impact on the learning experience for novice programmers. The goal of this working group is to develop educational materials to teach students to use programming error messages, and evaluate the use of these materials. An additional goal is to investigate the role that large language models may play in the interpretation of error messages in the educational environment. We will produce guidelines for developing educational materials and strategies informed by feedback obtained from the community and our experimentation. © 2023 Owner/Author.",2023,2,Conference Paper,"@article{2-s2.0-85180005666,
  title={Teaching Students To Use Programming Error Messages},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Exploring the Potential of GPT-4 in Automated Mentoring for Programming Courses,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180004577&origin=inward,10.1145/3617650.3624946,"AbstractView references

This research proposes an AI-assisted mentoring system for programming education, leveraging the advanced capabilities of OpenAI's GPT-4. We aim to validate students' pseudocode or algorithmic approaches to Python programming problems within the context of a Tier-1 institution in India, where the high student-to-mentor ratio presents unique challenges. The proposed system aspires to alleviate the pressures of the current mentoring system, providing a more accessible, responsive, and effective educational support system. © 2023 Owner/Author.",2023,4,Conference Paper,"@article{2-s2.0-85180004577,
  title={Exploring the Potential of GPT-4 in Automated Mentoring for Programming Courses},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Qualitative Research Methods for Large Language Models: Conducting Semi-Structured Interviews with ChatGPT and BARD on Computer Science Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180688010&origin=inward,10.3390/informatics10040078,"AbstractView references

In the current era of artificial intelligence, large language models such as ChatGPT and BARD are being increasingly used for various applications, such as language translation, text generation, and human-like conversation. The fact that these models consist of large amounts of data, including many different opinions and perspectives, could introduce the possibility of a new qualitative research approach: Due to the probabilistic character of their answers, “interviewing” these large language models could give insights into public opinions in a way that otherwise only interviews with large groups of subjects could deliver. However, it is not yet clear if qualitative content analysis research methods can be applied to interviews with these models. Evaluating the applicability of qualitative research methods to interviews with large language models could foster our understanding of their abilities and limitations. In this paper, we examine the applicability of qualitative content analysis research methods to interviews with ChatGPT in English, ChatGPT in German, and BARD in English on the relevance of computer science in K-12 education, which was used as an exemplary topic. We found that the answers produced by these models strongly depended on the provided context, and the same model could produce heavily differing results for the same questions. From these results and the insights throughout the process, we formulated guidelines for conducting and analyzing interviews with large language models. Our findings suggest that qualitative content analysis research methods can indeed be applied to interviews with large language models, but with careful consideration of contextual factors that may affect the responses produced by these models. The guidelines we provide can aid researchers and practitioners in conducting more nuanced and insightful interviews with large language models. From an overall view of our results, we generally do not recommend using interviews with large language models for research purposes, due to their highly unpredictable results. However, we suggest using these models as exploration tools for gaining different perspectives on research topics and for testing interview guidelines before conducting real-world interviews. © 2023 by the authors.",2023,4,Article,"@article{2-s2.0-85180688010,
  title={Qualitative Research Methods for Large Language Models: Conducting Semi-Structured Interviews with ChatGPT and BARD on Computer Science Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Educating Augmented Programmers,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85177833523&origin=inward,10.1109/MC.2023.3313325,"AbstractView references

There is an artificial intelligence-based technology that has the potential to augment the work of human programmers. This article discusses some capabilities built around generative artificial intelligence and large language models that impact programming education. © 1970-2012 IEEE.",2023,5,Note,"@article{2-s2.0-85177833523,
  title={Educating Augmented Programmers},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT and large language models in academia: opportunities and challenges,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85165261615&origin=inward,10.1186/s13040-023-00339-9,"AbstractView references

The introduction of large language models (LLMs) that allow iterative “chat” in late 2022 is a paradigm shift that enables generation of text often indistinguishable from that written by humans. LLM-based chatbots have immense potential to improve academic work efficiency, but the ethical implications of their fair use and inherent bias must be considered. In this editorial, we discuss this technology from the academic’s perspective with regard to its limitations and utility for academic writing, education, and programming. We end with our stance with regard to using LLMs and chatbots in academia, which is summarized as (1) we must find ways to effectively use them, (2) their use does not constitute plagiarism (although they may produce plagiarized text), (3) we must quantify their bias, (4) users must be cautious of their poor accuracy, and (5) the future is bright for their application to research and as an academic tool. © 2023, The Author(s).",2023,4,Editorial,"@article{2-s2.0-85165261615,
  title={ChatGPT and large language models in academia: opportunities and challenges},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173838298&origin=inward,10.1145/3617367,"AbstractView references

Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2023,4,Article,"@article{2-s2.0-85173838298,
  title={“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT has entered the classroom: how LLMs could transform education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85176593400&origin=inward,10.1038/d41586-023-03507-3,"AbstractView references

Researchers, educators and companies are experimenting with ways to turn flawed but famous large language models into trustworthy, accurate ‘thought partners’ for learning. [Figure not available: see fulltext.]. © 2023, Springer Nature Limited.",2023,4,Note,"@article{2-s2.0-85176593400,
  title={ChatGPT has entered the classroom: how LLMs could transform education},
  author={N/A},
  journal={N/A},
  year={7987},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Why teachers should explore ChatGPT’s potential — despite the risks,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85176558665&origin=inward,10.1038/d41586-023-03505-5,"AbstractView references

[No abstract available]",2023,2,Editorial,"@article{2-s2.0-85176558665,
  title={Why teachers should explore ChatGPT’s potential — despite the risks},
  author={N/A},
  journal={N/A},
  year={7987},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper),https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185532603&origin=inward,10.1145/3631802.3631816,"AbstractView references

We introduce the Explorotron Visual Studio Code extension for guided and independent code exploration and learning. Explorotron is a continuation of earlier work to explore how we can enable small organisations with limited resources to provide pedagogically sound learning experiences in programming. We situate Explorotron in the field of Computing Education Research (CER) and envision it to initiate a discussion around different topics, including how to balance the optimisation between the researcher-student-teacher trifecta that is inherent in CER, how to ethically and responsibly use large language models (LLMs) in the independent learning and exploration by students, and how to define better learning sessions over coding content that students obtained on their own. We further reflect on the question raised by Begel and Ko whether technology should “structure learning for learners” or whether learners should “be taught how to structure their own independent learning” outside of the classroom. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2023,4,Conference Paper,"@article{2-s2.0-85185532603,
  title={Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper)},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85179185850&origin=inward,10.1145/3631802.3631830,"AbstractView references

Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students. © 2023 Copyright held by the owner/author(s).",2023,4,Conference Paper,"@article{2-s2.0-85179185850,
  title={CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190385787&origin=inward,10.1145/3634814.3634816,"AbstractView references

Due to their robustness, large language models (LLMs) are being utilized in many fields of study, including programming and education. Notably, they can be used by programmers by interfacing with their IDEs to assist with development, and in education by giving students meaningful and immediate feedback. In this paper, we propose and explore the groundwork of a framework designed to combine these two applications of LLMs. The framework acts as a facilitator between the LLM and the student by reading the student's prompts before filtering and modifying them and sending them to the LLM. The intent is that this will improve the responses from the LLM, thereby improving the student's learning experience. We discuss the framework in detail and analyze the value of individual responses returned from the LLM as a result of our framework. We conclude that the framework causes the LLM to give helpful responses in comparison to how it would respond without the framework. © 2023 Owner/Author.",2023,7,Conference Paper,"@article{2-s2.0-85190385787,
  title={Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85178258738&origin=inward,10.1145/3622780.3623648,"AbstractView references

The impact of ChatGPT has brought both anxiety and anticipation to schools and universities. Exploring a positive method to improve programming skills with ChatGPT is a new and pressing challenge. In pursuit of this goal, we have developed KOGI, a learning support system that integrates ChatGPT into the Jupyter environment. This paper demonstrates how KOGI enables students to receive timely advice from ChatGPT in response to errors and other questions they encounter. We immediately introduced KOGI in our two introductory courses: Algorithms and Data Science. The introduction of KOGI resulted in a significant decrease in the number of unresolved student errors. In addition, we report on student trends observed in the classroom regarding the type and frequency of help requested. Although our findings are preliminary, they are informative for programming instructors interested in using ChatGPT. © 2023 ACM.",2023,10,Conference Paper,"@article{2-s2.0-85178258738,
  title={KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85176250332&origin=inward,10.1145/3585059.3611409,"AbstractView references

This paper argues for the inclusion of tools that utilize Artificial Intelligence (AI) Large Language Models (LLMs) in information technology (IT) undergraduate courses that teach the fundamentals of software. LLM tools have become widely available and disrupt traditional methods for teaching software concepts. Learning objectives are compromised when students submit AI-generated code for a classroom assignment without comprehending or validating the code. Since LLM tools including OpenAI Codex, Copilot by GitHub, and ChatGPT are being used in industry for software development, students need to be familiar with their use without compromising student learning. Incorporating LLM tools into the curriculum prepares students for real-world software development. However, students still need to understand software fundamentals including how to write and debug code. There are many challenges associated with the inclusion of AI tools into the IT curriculum that need to be addressed and mitigated. This paper presents strategies and techniques to integrate student use of LLM tools, assist students' interaction with the tools, and help prepare students for careers that increasingly use AI tools to design, develop, and maintain software. © 2023 Owner/Author.",2023,6,Conference Paper,"@article{2-s2.0-85176250332,
  title={Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT for Teaching and Learning: An Experience from Data Science Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85176215123&origin=inward,10.1145/3585059.3611431,"AbstractView references

ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum. © 2023 Owner/Author.",2023,7,Conference Paper,"@article{2-s2.0-85176215123,
  title={ChatGPT for Teaching and Learning: An Experience from Data Science Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Survey of Causal Inference for Knowledge Graphs and Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184923445&origin=inward,10.3778/j.issn.1673-9418.2307065,"AbstractView references

In recent decades, causal inference has been a significant research topic in various fields, including statistics, computer science, education, public policy, and economics. Most causal inference methods focus on the analysis of sample observational data and text corpora. However, with the emergence of various knowledge graphs and large language models, causal inference tailored to knowledge graphs and large models has gradually become a research hotspot. In this paper, different causal inference methods are classified based on their orientation towards sample observational data, text data, knowledge graphs, and large language models. Within each classification, this paper provides a detailed analysis of classical research works, including their problem definitions, solution methods, contributions, and limitations. Additionally, this paper places particular emphasis on discussing recent advancements in the integration of causal inference methods with knowledge graphs and large language models. Various causal inference methods are analyzed and compared from the perspectives of efficiency and cost, and specific applications of knowledge graphs and large language models in causal inference tasks are summarized. Finally, future development directions of causal inference in combination with knowledge graphs and large models are prospected. © 2023 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.",2023,19,Article,"@article{2-s2.0-85184923445,
  title={Survey of Causal Inference for Knowledge Graphs and Large Language Models},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"""Call me Kiran"" ChatGPT as a Tutoring Chatbot in a Computer Science Course",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180010359&origin=inward,10.1145/3616961.3616974,"AbstractView references

Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students' perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students' learning processes, but does not replace it. © 2023 Owner/Author.",2023,12,Conference Paper,"@article{2-s2.0-85180010359,
  title={""Call me Kiran"" ChatGPT as a Tutoring Chatbot in a Computer Science Course},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
THE CRISIS OF ARTIFICIAL INTELLIGENCE: A NEW DIGITAL HUMANITIES CURRICULUM FOR HUMAN-CENTRED AI,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85178898335&origin=inward,10.3366/ijhac.2023.0310,"AbstractView references

This article outlines what a successful artificial intelligence digital humanities (AI DH) curriculum entails and why it is so critical now. Artificial intelligence is rapidly reshaping our world and is poised to exacerbate long-standing crises including (1) the crisis of higher education and the humanities, (2) the lack of diversity, equity and inclusion (DEI) in computer science and technology fields and (3) the wider social and economic crises facilitated by new technologies. We outline a number of ways in which an AI DH curriculum offers concrete and impactful responses to these many crises. AI DH yields meaningful new avenues of research for the humanities and the humanistic social sciences, and offers new ways that higher education can better prepare students for the world into which they graduate. DEI metrics show how an AI DH curriculum can engage students traditionally underserved by conventional STEM courses. Finally, AI DH educates all students for civic engagement in order to address both the social and economic impacts of emerging AI technologies. This article provides an overview of an AI DH curriculum, the motivating theory behind design decisions, and a detailed look into two sample courses. © Edinburgh University Press 2023.",2023,21,Article,"@article{2-s2.0-85178898335,
  title={THE CRISIS OF ARTIFICIAL INTELLIGENCE: A NEW DIGITAL HUMANITIES CURRICULUM FOR HUMAN-CENTRED AI},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
AI-driven assistants for education and research? A case study on ChatGPT for air transport management,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85171346480&origin=inward,10.1016/j.jairtraman.2023.102483,"AbstractView references

Artificial Intelligence is in the process to transform various parts of the aviation industry, from the reduction of delays and increasing fuel efficiency to better demand prediction models. The latest kid on the block is ChatGPT, a large language model developed by OpenAI, which has made into the news for its mind-blowing ability to create textual content in any structured language. Doing so, ChatGPT has the potential to revolutionize the way we communicate with computers, and it could have a lasting impact on aviation education and research. In this study, we investigate the potential of this impact and, the extent to which it has already materialized, based on a set of graduate student surveys and experiments with ChatGPT. The results of our surveys indicate the interest of students in efficient learning, time saving, and improvement in programming/writing skills. Our experiments on terminology explanation, state-of-the-art identification of selected research tasks as well as programming design, highlight the tradeoffs between benefits and potential risks inherent to the usage of ChatGPT and AI-driven assistants in general. Overall, we believe that our study makes a first contribution to evaluating an exciting new technology which has the potential to revolutionize our aviation system. © 2023",2023,4,Article,"@article{2-s2.0-85171346480,
  title={AI-driven assistants for education and research? A case study on ChatGPT for air transport management},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
AI will transform science — now researchers must tame it,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85172226273&origin=inward,10.1038/d41586-023-02988-6,"AbstractView references

[No abstract available]",2023,4,Editorial,"@article{2-s2.0-85172226273,
  title={AI will transform science — now researchers must tame it},
  author={N/A},
  journal={N/A},
  year={7980},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Evaluating a large language model’s ability to solve programming exercises from an introductory bioinformatics course,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173538194&origin=inward,10.1371/journal.pcbi.1011511,"AbstractView references

Computer programming is a fundamental tool for life scientists, allowing them to carry out essential research tasks. However, despite various educational efforts, learning to write code can be a challenging endeavor for students and researchers in life-sciences disciplines. Recent advances in artificial intelligence have made it possible to translate human-language prompts to functional code, raising questions about whether these technologies can aid (or replace) life scientists’ efforts to write code. Using 184 programming exercises from an introductory-bioinformatics course, we evaluated the extent to which one such tool —OpenAI’s ChatGPT—could successfully complete programming tasks. ChatGPT solved 139 (75.5%) of the exercises on its first attempt. For the remaining exercises, we provided natural-language feedback to the model, prompting it to try different approaches. Within 7 or fewer attempts, ChatGPT solved 179 (97.3%) of the exercises. These findings have implications for life-sciences education and research. Instructors may need to adapt their pedagogical approaches and assessment techniques to account for these new capabilities that are available to the general public. For some programming tasks, researchers may be able to work in collaboration with machine-learning models to produce functional code. Copyright: © 2023 Piccolo et al.",2023,4,Article,"@article{2-s2.0-85173538194,
  title={Evaluating a large language model’s ability to solve programming exercises from an introductory bioinformatics course},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"Decoding ChatGPT: A taxonomy of existing research, current challenges, and possible future directions",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85167397382&origin=inward,10.1016/j.jksuci.2023.101675,"AbstractView references

Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022. It has shown impressive performance in various domains, including passing exams and creative writing. However, challenges and concerns related to biases and trust persist. In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications. We critically analyze the existing literature, identifying common approaches employed in the studies. Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges. We also discuss crucial issues related to ChatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas. Furthermore, we identify potential future directions for ChatGPT research, proposing solutions to current challenges and speculating on expected advancements. By fully leveraging the capabilities of ChatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society. © 2023 The Author(s)",2023,4,Review,"@article{2-s2.0-85167397382,
  title={Decoding ChatGPT: A taxonomy of existing research, current challenges, and possible future directions},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"From ""Ban It Till We Understand It"" to ""Resistance is Futile"": How University Programming Instructors Plan to Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT and GitHub Copilot",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85170635424&origin=inward,10.1145/3568813.3600138,"AbstractView references

Over the past year (2022-2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education. © 2023 Owner/Author.",2023,16,Conference Paper,"@article{2-s2.0-85170635424,
  title={From ""Ban It Till We Understand It"" to ""Resistance is Futile"": How University Programming Instructors Plan to Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT and GitHub Copilot},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85170200108&origin=inward,10.1145/3568813.3600139,"AbstractView references

Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers' help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students' code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education. © 2023 Owner/Author.",2023,13,Conference Paper,"@article{2-s2.0-85170200108,
  title={Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85169462375&origin=inward,10.1145/3568813.3600142,"AbstractView references

This paper studies recent developments in large language models' (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class' assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4's handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments. © 2023 Owner/Author.",2023,15,Conference Paper,"@article{2-s2.0-85169462375,
  title={Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Creative Use of OpenAI in Education: Case Studies from Game Development,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85169072019&origin=inward,10.3390/mti7080081,"AbstractView references

Educators and students have shown significant interest in the potential for generative artificial intelligence (AI) technologies to support student learning outcomes, for example, by offering personalized experiences, 24 h conversational assistance, text editing and help with problem-solving. We review contemporary perspectives on the value of AI as a tool in an educational context and describe our recent research with undergraduate students, discussing why and how we integrated OpenAI tools ChatGPT and Dall-E into the curriculum during the 2022–2023 academic year. A small cohort of games programming students in the School of Computing and Digital Media at London Metropolitan University was given a research and development assignment that explicitly required them to engage with OpenAI. They were tasked with evaluating OpenAI tools in the context of game development, demonstrating a working solution and reporting on their findings. We present five case studies that showcase some of the outputs from the students and we discuss their work. This mode of assessment was both productive and popular, mapping to students’ interests and helping to refine their skills in programming, problem-solving, critical reflection and exploratory design. © 2023 by the authors.",2023,4,Article,"@article{2-s2.0-85169072019,
  title={Creative Use of OpenAI in Education: Case Studies from Game Development},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"“So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85149886538&origin=inward,10.1016/j.ijinfomgt.2023.102642,"AbstractView references

Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts. © 2023 The Authors",2023,4,Article,"@article{2-s2.0-85149886538,
  title={“So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Who Judges the Judge: An Empirical Study on Online Judge Tests,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85166284081&origin=inward,10.1145/3597926.3598060,"AbstractView references

Online Judge platforms play a pivotal role in education, competitive programming, recruitment, career training, and large language model training. They rely on predefined test suites to judge the correctness of submitted solutions. It is therefore important that the solution judgement is reliable and free from potentially misleading false positives (i.e., incorrect solutions that are judged as correct). In this paper, we conduct an empirical study of 939 coding problems with 541,552 solutions, all of which are judged to be correct according to the test suites used by the platform, finding that 43.4% of the problems include false positive solutions (3,440 bugs are revealed in total). We also find that test suites are, nevertheless, of high quality according to widely-studied test effectiveness measurements: 88.2% of false positives have perfect (100%) line coverage, 78.9% have perfect branch coverage, and 32.5% have a perfect mutation score. Our findings indicate that more work is required to weed out false positive solutions and to further improve test suite effectiveness. We have released the detected false positive solutions and the generated test inputs to facilitate future research. © 2023 ACM.",2023,13,Conference Paper,"@article{2-s2.0-85166284081,
  title={Who Judges the Judge: An Empirical Study on Online Judge Tests},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85160214425&origin=inward,10.1016/j.ece.2023.05.001,"AbstractView references

This study highlights the potential benefits of integrating Large Language Models (LLMs) into chemical engineering education. In this study, Chat-GPT, a user-friendly LLM, is used as a problem-solving tool. Chemical engineering education has traditionally focused on fundamental knowledge in the classroom with limited opportunities for hands-on problem-solving. To address this issue, our study proposes an LLMs-assisted problem-solving procedure. This approach promotes critical thinking, enhances problem-solving abilities, and facilitates a deeper understanding of core subjects. Furthermore, incorporating programming into chemical engineering education prepares students with vital Industry 4.0 skills for contemporary industrial practices. During our experimental lecture, we introduced a simple example of building a model to calculate steam turbine cycle efficiency, and assigned projects to students for exploring the possible use of LLMs in solving various aspect of chemical engineering problems. Although it received mixed feedback from students, it was found to be an accessible and practical tool for improving problem-solving efficiency. Analyzing the student projects, we identified five common difficulties and misconceptions and provided helpful suggestions for overcoming them. Our course has limitations regarding using advanced tools and addressing complex problems. We further provide two additional examples to better demonstrate how to integrate LLMs into core courses. We emphasize the importance of universities, professors, and students actively embracing and utilizing LLMs as tools for chemical engineering education. Students must develop critical thinking skills and a thorough understanding of the principles behind LLMs, taking responsibility for their use and creations. This study provides valuable insights for enhancing chemical engineering education's learning experience and outcomes by integrating LLMs. © 2023 Institution of Chemical Engineers",2023,25,Article,"@article{2-s2.0-85160214425,
  title={Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Checking Conformance to a Subset of the Python Language,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85166308355&origin=inward,10.1145/3587103.3594155,"AbstractView references

Introductory courses usually only teach a small subset of a programming language and its library, in order to focus on the general concepts rather than overwhelm students with the syntactic, semantic and API minutiae of a particular language. This paper presents courseware that checks if a program only uses the subset of the Python language and library defined by the instructor. This allows to automatically check that programming examples, exercises and assessments only use the taught constructs. It also helps detect student code with advanced constructs, possibly copied from Q&A sites or generated by large language models. The tool is easy to install, configure and use. It also checks Python code in Jupyter notebooks, a popular format for interactive textbooks and assessment handouts. © 2023 Owner/Author.",2023,2,Conference Paper,"@article{2-s2.0-85166308355,
  title={Checking Conformance to a Subset of the Python Language},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85166290735&origin=inward,10.1145/3587103.3594206,"AbstractView references

The recent advent of highly accurate and scalable large language models (LLMs) has taken the world by storm. From art to essays to computer code, LLMs are producing novel content that until recently was thought only humans could produce. Recent work in computing education has sought to understand the capabilities of LLMs for solving tasks such as writing code, explaining code, creating novel coding assignments, interpreting programming error messages, and more. However, these technologies continue to evolve at an astonishing rate leaving educators little time to adapt. This working group seeks to document the state-of-the-art for code generation LLMs, detail current opportunities and challenges related to their use, and present actionable approaches to integrating them into computing curricula. © 2023 Owner/Author.",2023,2,Conference Paper,"@article{2-s2.0-85166290735,
  title={Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Evaluating the Performance of Code Generation Models for Solving Parsons Problems with Small Prompt Variations,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85166269580&origin=inward,10.1145/3587102.3588805,"AbstractView references

The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems. © 2023 Owner/Author.",2023,7,Conference Paper,"@article{2-s2.0-85166269580,
  title={Evaluating the Performance of Code Generation Models for Solving Parsons Problems with Small Prompt Variations},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
GPT-3 vs Object Oriented Programming Assignments: An Experience Report,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85166249787&origin=inward,10.1145/3587102.3588814,"AbstractView references

Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages. In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work. © 2023 Owner/Author.",2023,7,Conference Paper,"@article{2-s2.0-85166249787,
  title={GPT-3 vs Object Oriented Programming Assignments: An Experience Report},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85166190545&origin=inward,10.1145/3587102.3588852,"AbstractView references

Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course. We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments. © 2023 ACM.",2023,7,Conference Paper,"@article{2-s2.0-85166190545,
  title={Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Comparing Code Explanations Created by Students and Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85164031984&origin=inward,10.1145/3587102.3588785,"AbstractView references

Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n ≈ 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education. © 2023 Owner/Author.",2023,7,Conference Paper,"@article{2-s2.0-85164031984,
  title={Comparing Code Explanations Created by Students and Large Language Models},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Experiences with Remote Examination Formats in Light of GPT-4,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85163528803&origin=inward,10.1145/3593663.3593695,"AbstractView references

Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress. © 2023 Owner/Author.",2023,6,Conference Paper,"@article{2-s2.0-85163528803,
  title={Experiences with Remote Examination Formats in Light of GPT-4},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"ChatGPT for Education and Research: Opportunities, Threats, and Strategies",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85159258213&origin=inward,10.3390/app13095783,"AbstractView references

In recent years, the rise of advanced artificial intelligence technologies has had a profound impact on many fields, including education and research. One such technology is ChatGPT, a powerful large language model developed by OpenAI. This technology offers exciting opportunities for students and educators, including personalized feedback, increased accessibility, interactive conversations, lesson preparation, evaluation, and new ways to teach complex concepts. However, ChatGPT poses different threats to the traditional education and research system, including the possibility of cheating on online exams, human-like text generation, diminished critical thinking skills, and difficulties in evaluating information generated by ChatGPT. This study explores the potential opportunities and threats that ChatGPT poses to overall education from the perspective of students and educators. Furthermore, for programming learning, we explore how ChatGPT helps students improve their programming skills. To demonstrate this, we conducted different coding-related experiments with ChatGPT, including code generation from problem descriptions, pseudocode generation of algorithms from texts, and code correction. The generated codes are validated with an online judge system to evaluate their accuracy. In addition, we conducted several surveys with students and teachers to find out how ChatGPT supports programming learning and teaching. Finally, we present the survey results and analysis. © 2023 by the authors.",2023,4,Article,"@article{2-s2.0-85159258213,
  title={ChatGPT for Education and Research: Opportunities, Threats, and Strategies},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85160005800&origin=inward,10.1145/3544548.3580919,"AbstractView references

AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex. © 2023 ACM.",2023,4,Conference Paper,"@article{2-s2.0-85160005800,
  title={Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85151988830&origin=inward,10.1145/3581754.3584111,"AbstractView references

Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students' sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students' learning needs and provides scaffolding to support their success in introductory computer programming courses. My research includes three studies: a formative study, a user study of an initial prototype, and a computer simulation study with a user study in progress. Both qualitative and quantitative data were collected through surveys, observations, focus group discussions and computer simulation. The preliminary findings suggest that GPT-3-enhanced gamification has great potential in scaffolding introductory programming learning by providing adaptive and personalised feedback, increasing students' sense of belonging, and reducing their anxiety about learning programming. © 2023 Owner/Author.",2023,4,Conference Paper,"@article{2-s2.0-85151988830,
  title={Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Exploring the Potential of Chatbots to Provide Mental Well-being Support for Computer Science Students,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85149779953&origin=inward,10.1145/3545947.3576285,"AbstractView references

Computer Science students are affected by a number of stressors, such as competition, which make it difficult for them to manage their mental well-being and mood. Students are often reluctant to use existing resources for support because they are difficult to access or perceived as ineffective. Conversational agents have shown potential to provide accessible and effective support to improve well-being. In this work, we explore the problem space to identify contexts in which chatbots could be beneficial for students and investigate how different types of chatbot could supplement existing resources provided by universities. © 2022 Owner/Author.",2023,4,Conference Paper,"@article{2-s2.0-85149779953,
  title={Exploring the Potential of Chatbots to Provide Mental Well-being Support for Computer Science Students},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Programming Is Hard - or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85149868810&origin=inward,10.1145/3545945.3569759,"AbstractView references

The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community. © 2023 Owner/Author.",2023,7,Conference Paper,"@article{2-s2.0-85149868810,
  title={Programming Is Hard - or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85149847393&origin=inward,10.1145/3545945.3569823,"GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.",2023,7,Conference Paper,"@article{2-s2.0-85149847393,
  title={Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language},
  author={N/A},
  journal={N/A},
  year={N/A},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85148727616&origin=inward,10.1145/3545945.3569785,"AbstractView references

Advances in natural language processing have resulted in large language models (LLMs) that can generate code and code explanations. In this paper, we report on our experiences generating multiple code explanation types using LLMs and integrating them into an interactive e-book on web software development. Three different types of explanations - a line-by-line explanation, a list of important concepts, and a high-level summary of the code - were created. Students could view explanations by clicking a button next to code snippets, which showed the explanation and asked about its utility. Our results show that all explanation types were viewed by students and that the majority of students perceived the code explanations as helpful to them. However, student engagement varied by code snippet complexity, explanation type, and code snippet length. Drawing on our experiences, we discuss future directions for integrating explanations generated by LLMs into CS classrooms. © 2023 ACM.",2023,7,Conference Paper,"@article{2-s2.0-85148727616,
  title={Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
The Potential of Large Language Models as Tools for Analyzing Student Textual Evaluation: A Differential Analysis Between CS and Non-CS Students,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194134617&origin=inward,10.1109/CEI60616.2023.10527886,"AbstractView references

Research on the analysis of Student Textual Evaluation encounters ongoing challenges. Large language models, as emerging tools in natural language processing, have garnered extensive attention. This study explores the potential of large-scale language models as tools for analyzing student course evaluations on the Coursera platform and compares Computer Science (CS) and non-Computer Science (non-CS) course reviews to investigate variations in student sentiment and thematic content between these two domains. The study adopts a systematic approach to review and analyze student reviews, identifying common sentiments and patterns, and categorizing reviews into relevant evaluation themes. Additionally, the study assesses inter-annotator agreement to validate the accuracy of manual analyses. Experimental findings reveal a strong correlation between large language models and actual course ratings as well as human-analyzed results, suggesting their potential as tools for assessing student course evaluations. Results from the analysis of CS and non-CS course reviews indicate significant disparities in the distribution of thematic content between these two academic domains. © 2023 IEEE.",2023,6,Conference Paper,"@article{2-s2.0-85194134617,
  title={The Potential of Large Language Models as Tools for Analyzing Student Textual Evaluation: A Differential Analysis Between CS and Non-CS Students},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Analysis of Plagiarism via ChatGPT on Domain-Specific Exams,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85191155061&origin=inward,10.1109/CSCE60160.2023.00171,"AbstractView references

This work presents a case study, linguistic analysis and potential prevention methods on the use of large language models (LLM) for generating solutions for exams on cloud computing course that require domain-specific knowledge. The study involves analyzing the responses of three groups of students: a group who used ChatGPT to plagiarize solutions, another group who referred to external non-LLM resources (e.g., web search) to plagiarize solutions, a control group who generated solutions without any external assistance. Results show that solutions from groups that participated in plagiarism tend to be lengthy, use uncommon words, and are similar to each other compared to human-generated solutions. This study not only shows that it is possible to generate legitimate solutions for exams that require extensive domain-specific knowledge using ChatGPT, but also shows some potential signals one can use to detect plagiarism, thus providing potential of promoting academic integrity by curbing unethical use of AI in academic settings. © 2023 IEEE.",2023,8,Conference Paper,"@article{2-s2.0-85191155061,
  title={Analysis of Plagiarism via ChatGPT on Domain-Specific Exams},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Refactoring Programs Using Large Language Models with Few-Shot Examples,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190537096&origin=inward,10.1109/APSEC60848.2023.00025,"A less complex and more straightforward program is a crucial factor that enhances its maintainability and makes writing secure and bug-free programs easier. However, due to its heavy workload and the risks of breaking the working programs, programmers are reluctant to do code refactoring, and thus, it also causes the loss of potential learning experiences. To mitigate this, we demonstrate the application of using a large language model (LLM), GPT-3.5, to suggest less complex versions of the user-written Python program, aiming to encourage users to learn how to write better programs. We propose a method to leverage the prompting with few-shot examples of the LLM by selecting the best-suited code refactoring examples for each target programming problem based on the prior evaluation of prompting with the one-shot example. The quantitative evaluation shows that 95.68% of programs can be refactored by generating 10 candidates each, resulting in a 17.35% reduction in the average cyclomatic complexity and a 25.84% decrease in the average number of lines after filtering only generated programs that are semantically correct. Further-more, the qualitative evaluation shows outstanding capability in code formatting, while unnecessary behaviors such as deleting or translating comments are also observed.",2023,10,Conference Paper,"@article{2-s2.0-85190537096,
  title={Refactoring Programs Using Large Language Models with Few-Shot Examples},
  author={N/A},
  journal={N/A},
  year={N/A},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatPapers: An AI Chatbot for Interacting with Academic Research,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189941104&origin=inward,10.1109/AICS60730.2023.10470521,"AbstractView references

A growing and significant number of computer science related papers are being published; hence it is challenging to keep up with the latest research. This paper describes the development of a large language model (LLM) augmentation chatbot and user interface that provides responses to research queries in the domain of computer science. Around 200,000 computer science research papers from arXiv were embedded, resulting in 11 million vectors (based on 'chunks' from the papers). Each vector is comprised of 384 numbers/dimensions. Technologies used include Langchain, a Vector Database, and Semantic Searching with document / query embeddings. The chatbot was tested using 30 sample questions that could be asked by computer science students across several topics and from different education levels (i.e., BSc, MSc and PhD level). The responses from this chatbot were compared with those from GPT-4. The responses with and without prompting were also compared. Readability metrics (Flesch-Kincaid and Coleman-Liau) were used to compare the responses from this LLM with GPT-4. Retrieval Augmented Generation Assessment (RAGAS), a novel LLM self-evaluation method was used to evaluate the system. We observed that the developed system provides more suitable responses to the user based on the readability level at which the questions were asked. © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85189941104,
  title={ChatPapers: An AI Chatbot for Interacting with Academic Research},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Large Language Models for Software Engineering: Survey and Open Problems,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185604518&origin=inward,10.1109/ICSE-FoSE59343.2023.00008,"AbstractView references

This paper provides a survey of the emerging area of Large Language Models (LLMs) for Software Engineering (SE). It also sets out open research challenges for the application of LLMs to technical problems faced by software engineers. LLMs' emergent properties bring novelty and creativity with applications right across the spectrum of Software Engineering activities including coding, design, requirements, repair, refactoring, performance improvement, documentation and analytics. However, these very same emergent properties also pose significant technical challenges; we need techniques that can reliably weed out incorrect solutions, such as hallucinations. Our survey reveals the pivotal role that hybrid techniques (traditional SE plus LLMs) have to play in the development and deployment of reliable, efficient and effective LLM-based SE. © 2023 IEEE.",2023,23,Conference Paper,"@article{2-s2.0-85185604518,
  title={Large Language Models for Software Engineering: Survey and Open Problems},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Implementing Generative AI and Large Language Models in Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184809261&origin=inward,10.1109/ISAS60782.2023.10391517,"AbstractView references

The recent advancements in Generative AI have been highlighted by the emergence of Large Language Models (LLMs) like ChatGPT. We track this evolution from the initial recurrent neural networks to the development of architectures like Transformers and Generative Pre-trained Transformers (GPT). ChatGPT, with its impressive ability to comprehend, process, and produce natural language, has piqued the interest of educators, students, and institutions within the education sector through its creation of high-quality textual responses.This marks the beginning of a new era in educational possibilities: we emphasize the beneficial effects of ChatGPT in learning environments, noting its utility in programming assistance, its clarity in concept explanation, and its role in enhancing automated learning processes. We also recognize potential drawbacks, including the risks of over-reliance, plagiarism, and the inherent constraints of these models in tackling mathematical and linguistic problem-solving tasks.In exploring the Paradox of Automation, we examine the implications of an over-reliance on AI in education. We seek to understand the importance of preserving critical thinking skills and ensuring that technology serves as a tool for augmenting human capabilities rather than supplanting them. Our analysis acknowledges that, while AI, including ChatGPT, can assist in content generation and problem-solving, it is essential for students to cultivate their abilities in analytical thinking, content verification, and error correction. © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85184809261,
  title={Implementing Generative AI and Large Language Models in Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
AI-Enhanced Auto-Correction of Programming Exercises: How Effective is GPT-3.5?,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85183535998&origin=inward,10.3991/ijep.v13i8.45621,"AbstractView references

Timely formative feedback is considered as one of the most important drivers for effective learning. Delivering timely and individualized feedback is particularly challenging in large classes in higher education. Recently Large Language Models such as GPT-3 became available to the public that showed promising results on various tasks such as code generation and code explanation. This paper investigates the potential of AI in providing personalized code correction and generating feedback. Based on existing student submissions of two different real-world assignments, the correctness of the AI-aided e-assessment as well as the characteristics such as fault localization, correctness of hints, and code style suggestions of the generated feedback are investigated. The results show that 73% of the submissions were correctly identified as either correct or incorrect. In 59% of these cases, GPT-3.5 also successfully generated effective and high-quality feedback. Additionally, GPT-3.5 exhibited weaknesses in its evaluation, including localization of errors that were not the actual errors, or even hallucinated errors. Implications and potential new usage scenarios are discussed. © 2023 by the authors of this article. Published under CC-BY.",2023,17,Article,"@article{2-s2.0-85183535998,
  title={AI-Enhanced Auto-Correction of Programming Exercises: How Effective is GPT-3.5?},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Challenging the Confirmation Bias: Using ChatGPT as a Virtual Peer for Peer Instruction in Computer Programming Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85183057406&origin=inward,10.1109/FIE58773.2023.10343247,"AbstractView references

This paper proposes the implementation of Chat-GPT, a large language model, as a virtual peer for peer instruction in computer programming courses. The authors argue that AI tools, including ChatGPT, can bring benefits such as personalized learning, instant feedback, and active engagement to the classroom. An experiment was conducted with two groups of programming students: one receiving traditional instruction and the other utilizing the ChatGPT-based peer instruction model. Both groups were given the same programming assignments and assessments. The results indicated that the ChatGPT group outperformed the traditionally instructed group, demonstrating better programming skills and a deeper understanding of concepts. The ChatGPT group also reported higher engagement and satisfaction. However, some difficulties were observed when using ChatGPT for more abstract problems. Overall, the study highlights the effectiveness of using ChatGPT as a virtual peer to enhance active learning and student outcomes in computer programming courses, challenging biases regarding AI's potential benefits in education. The authors hope this study encourages educators to embrace AI tools in the classroom and overcome confirmation biases about their impact. © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85183057406,
  title={Challenging the Confirmation Bias: Using ChatGPT as a Virtual Peer for Peer Instruction in Computer Programming Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Generative AI in Computing Education: Perspectives of Students and Instructors,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182997655&origin=inward,10.1109/FIE58773.2023.10343467,"AbstractView references

Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. In the computing education context, these models are being used to generate code, code explanations, and programming exercises. The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms. The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education. However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated. © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85182997655,
  title={Generative AI in Computing Education: Perspectives of Students and Instructors},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Affective Computing: A Topic-Based SER Approach on Collaborative Discussions in Academic Setting,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182997103&origin=inward,10.1109/FIE58773.2023.10342963,"AbstractView references

One of the biggest concerns in the modern day especially in the educational domain centers on the student's mental health. High rates of anxiety and depression have especially brought the attention of researchers in engineering education to apply affective computing to help with students' academic performance. It is known that a person's emotional states cause physiological and physical changes in the body. Emotions may impact facial expression, tone of speech, blood pressure, pulse, etc. Since visual and auditory signals are two variables that can be measured without the need to attach any physical device to the individuals, they are most studied in this field. Speech in particular has been known as a means that transfers much information about the mental and emotional states of the person. Speech Emotion Recognition (SER) is a growing field that has been applied in several domains including engineering education. Recent advancements in AI, Natural Language Understanding (NLU), and Large Language Models (LLM) have significantly streamlined this line of research. In this work which is a continuation of our prior work, we propose a speech analysis model that extracts both the emotions and topics from verbal discussions in a computer science classroom to understand if the expressed emotions were mostly about the course related topics or not. The goal of this research is to develop a tool that helps educators gain insights into the students' emotional states in teamwork and also understand the context of their conversations. We further analyze if the expressed emotions in the verbal class discussions are mostly about the course content or other subjects outside class setting. To expand the emotion analysis module we added a new layer to our developed pipeline by passing the speech data into the ChatGPT API to generate summarized scripts and extract additional classes of emotion. The preliminary results from this study are promising, indicating the potential value of this research direction and its prospects for further development. Application of this model in the educational domain can greatly benefit both educators and students and allows the instructors to make necessary interventions needed to maximize students' positive experiences in team settings while considering their emotional states. © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85182997103,
  title={Affective Computing: A Topic-Based SER Approach on Collaborative Discussions in Academic Setting},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Generating Multiple Choice Questions for Computing Courses Using Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182978399&origin=inward,10.1109/FIE58773.2023.10342898,"AbstractView references

Generating high-quality multiple-choice questions (MCQs) is a time-consuming activity that has led practitioners and researchers to develop community question banks and reuse the same questions from semester to semester. This results in generic MCQs which are not relevant to every course. Template-based methods for generating MCQs require less effort but are similarly limited. At the same time, advances in natural language processing have resulted in large language models (LLMs) that are capable of doing tasks previously reserved for people, such as generating code, code explanations, and programming assignments. In this paper, we investigate whether these generative capabilities of LLMs can be used to craft high-quality M CQs more efficiently, thereby enabling instructors to focus on personalizing MCQs to each course and the associated learning goals. We used two LLMs, GPT-3 and GPT-4, to generate isomorphic MCQs based on MCQs from the Canterbury Question Bank and an Introductory to Low-level C Programming Course. We evaluated the resulting MCQs to assess their ability to generate correct answers based on the question stem, a task that was previously not possible. Finally, we investigate whether there is a correlation between model performance and the discrimination score of the associated MCQ to understand whether low discrimination questions required the model to do more inference and therefore perform poorly. GPT-4 correctly generated the answer for 78.5% of MCQs based only on the question stem. This suggests that instructors could use these models to quickly draft quizzes, such as during a live class, to identify misconceptions in real-time. We also replicate previous findings that GPT-3 performs poorly on answering, or in our case generating, correct answers to MCQs. We also present cases we observed where LLMs struggled to produce correct answers. Finally, we discuss implications for computing education. © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85182978399,
  title={Generating Multiple Choice Questions for Computing Courses Using Large Language Models},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
On ChatGPT: Perspectives from Software Engineering Students,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182504562&origin=inward,10.1109/QRS60937.2023.00028,"AbstractView references

ChatGPT, an increasingly popular Large Language Model (LLM), has found widespread acceptance, especially among the younger generation, who rely on it for various tasks, such as comprehending complex course materials and tackling homework assignments. This surge in interest has drawn the attention of researchers, leading to numerous studies that delve into the advantages and disadvantages of the upcoming LLM dominant era. In our research, we explore the influence of ChatGPT and similar models on the field of software engineering, specifically from the perspective of software engineering students. Our main objective is to gain valuable insights into their usage habits and opinions through a comprehensive survey. The survey encompassed diverse questions, addressing the specific areas where ChatGPT was utilized for assistance and gathering students' reflections on each aspect. We found that ChatGPT has garnered widespread acceptance among software engineering students, with 93% of them utilizing it for their projects. These students expressed satisfaction with the level of assistance provided, and most intend to continue using it as a valuable tool in their work. During our investigation, we also assessed the students' awareness of the underlying technologies behind ChatGPT. Approximately half of the students demonstrated awareness of these technologies, while 38.7% had made extra efforts to explore prompt engineering to enhance ChatGPT's productivity. However, an important finding was that 90.6% of the students reported experiencing hallucinations during their interactions with ChatGPT. These hallucinations were shared as examples, raising significant concerns that warrant further exploration and mitigation. Moreover, we delved into potential improvements and gathered valuable recommendations, which could help ChatGPT to become even more effective and dependable in its applications. © 2023 IEEE.",2023,10,Conference Paper,"@article{2-s2.0-85182504562,
  title={On ChatGPT: Perspectives from Software Engineering Students},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Pre-made Empowering Artificial Intelligence and ChatGPT: The Growing Importance of Human AI-Experts,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182016638&origin=inward,10.1109/IISA59645.2023.10345880,"AbstractView references

This paper investigates the augmented responsibility of human Artificial Intelligence experts in the era of empowered pre-made Artificial Intelligence (AI). The responsible and ethical use of pre-made AI is of paramount importance in this evolving technology. AI systems have the potential to impact numerous aspects of society, ranging from healthcare and finance to education and IoT. The decisions made by AI algorithms can have significant consequences for individuals, communities, and even entire industries. Using a comparison to the way widely available medicines require a prescription from medical doctors, human AI experts assume the role of evaluating, recommending, and overseeing the implementation of AI systems, even when pre-built AI solutions may seem user-friendly on the surface. The paper has explored the expanded responsibilities of human AI experts within two contemporary scenarios involving pre-made AI, encompassing LLMs and ChatGPT. These AI technologies are applied in two principal manners: initially, as standalone AI products readily accessible to a wide audience, and secondly, as elements undergoing exploration for integration into other AI-driven software and Intelligent Information Systems (IIS), with the goal of enhancing natural language processing (NLP) features within user interfaces. In all cases, the expertise of human AI professionals is indispensable, and their role is augmented. These professionals bear an increased responsibility for ensuring the responsible and ethical deployment of AI technologies, with a focus on human-centered design, bias mitigation, validation and accuracy estimation of the results, transparency promotion, and the necessary balance between automation and human oversight. This paper performs a review on pre-made AI and ChatGPT together with custom-based AI and shows that recent advance require an augmented role of human AI experts © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85182016638,
  title={Pre-made Empowering Artificial Intelligence and ChatGPT: The Growing Importance of Human AI-Experts},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Analyzing Scrum Team Impediments Using NLP,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180636896&origin=inward,10.1007/978-3-031-48639-5_4,"AbstractView references

In this research, we focus on the impediments encountered by students in capstone projects following the Scrum methodology. Scrum meeting notes were collected in a dataset to permit Scrum roles and instructors to monitor progress and issues. We identified 9 categories of impediments in this dataset: Android, Coding Skills, Debugging, External Factors, Firebase/Database, Git/GitHub, Teamwork, Time Management, and UI/UX Design. We developed a Large Language Model (LLM) to classify these impediments. Natural Language Processing (NLP) has the potential to support software engineering processes. The novelty of this research is that it attempts to identify impediments faced by students’ Scrum teams with AI and support students and instructors. The relevance of the approach was discussed with subject matter experts (SME) of the industry. The proposed model is useful in both the academic and industry settings, to identify on-the-fly areas that need attention and, if fixed, would increase team productivity. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",2023,14,Conference Paper,"@article{2-s2.0-85180636896,
  title={Analyzing Scrum Team Impediments Using NLP},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
How Useful TutorBot+ is for Teaching and Learning in Programming Courses: a Preliminary Study,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85179006268&origin=inward,10.1109/SCCC59417.2023.10315697,"AbstractView references

Objective: The objective of this paper is to present preliminary work on the development of an EduChatBot tool and the measurement of the effects of its use aimed at providing effective feedback to programming course students. This bot, hereinafter referred to as tutorBot+, was constructed based on chatGPT3.5 and is tasked with assisting and providing timely positive feedback to students in computer science programming courses at UCSC. Methods/Analysis: The proposed method consists of four stages: (1) Immersion in the feedback and Large Language Models (LLMs) topic; (2) Development of tutorBot+ prototypes in both non-conversational and conversational versions; (3) Experiment design; and (4) Intervention and evaluation. The first stage involves a literature review on feedback and learning, the use of intelligent tutors in the educational context, as well as the topics of LLMs and chatGPT. The second and third stages detail the development of tutorBot+ in its two versions, and the final stage lays the foundation for a quasi-experimental study involving students in the curriculum activities of Programming Workshop and Database Workshop, focusing on learning outcomes related to the development of computational thinking skills, and facilitating the use and measurement of the tool's effects. Findings: The preliminary results of this work are promising, as two functional prototypes of tutorBot+ have been developed for both the non-conversational and conversational versions. Additionally, there is ongoing exploration into the possibility of creating a domain-specific model based on pretrained models for programming, integrating tutorBot+ with other platforms, and designing an experiment to measure student performance, motivation, and the tool's effectiveness. © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85179006268,
  title={How Useful TutorBot+ is for Teaching and Learning in Programming Courses: a Preliminary Study},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Prompting Large Language Models to Power Educational Chatbots,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85178634464&origin=inward,10.1007/978-981-99-8385-8_14,"AbstractView references

The recent rise in both popularity and performance of large language models has garnered considerable interest regarding their applicability to education. Technologies like ChatGPT, which can engage in human-like dialog, have already disrupted educational practices given their ability to answer a wide array of questions. Nevertheless, integrating these technologies into learning contexts faces both technological and pedagogical challenges, such as providing appropriate user interfaces and configuring interactions to ensure that conversations stay on topic. To better understand the potential large language models have to power educational chatbots, we propose an architecture to support educational chatbots that can be powered by these models. Using this architecture, we created a chatbot interface that was integrated into a web application aimed at teaching software engineering best practices. The application was then used to conduct a case study comprising a controlled experiment with 26 university software engineering students. Half of the students interacted with a version of the application equipped with the chatbot, while the other half completed the same lesson without the chatbot. While the results of our quantitative analysis did not identify significant differences between conditions, qualitative insights suggest that learners appreciated the chatbot. These results could serve as a starting point to optimize strategies for integrating large language models into pedagogical scenarios. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",2023,20,Conference Paper,"@article{2-s2.0-85178634464,
  title={Prompting Large Language Models to Power Educational Chatbots},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
"Exploring the Role of AI Assistants in Computer Science Education: Methods, Implications, and Instructor Perspectives",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85174478822&origin=inward,10.1109/VL-HCC57772.2023.00018,"AbstractView references

The use of AI assistants, along with the challenges they present, has sparked significant debate within the community of computer science education. While these tools demonstrate the potential to support students' learning and instructors' teaching, they also raise concerns about enabling unethical uses by students. Previous research has suggested various strategies aimed at addressing these issues. However, they concentrate on introductory programming courses and focus on one specific type of problem. The present research evaluated the performance of ChatGPT, a state-of-the-art AI assistant, at solving 187 problems spanning three distinct types that were collected from six undergraduate computer science. The selected courses covered different topics and targeted different program levels. We then explored methods to modify these problems to adapt them to ChatGPT's capabilities to reduce potential misuse by students. Finally, we conducted semi-structured interviews with 11 computer science instructors. The aim was to gather their opinions on our problem modification methods, understand their perspectives on the impact of AI assistants on computer science education, and learn their strategies for adapting their courses to leverage these AI capabilities for educational improvement. The results revealed issues ranging from academic fairness to long-term impact on students' mental models. From our results, we derived design implications and recommended tools to help instructors design and create future course material that could more effectively adapt to AI assistants' capabilities. © 2023 IEEE.",2023,11,Conference Paper,"@article{2-s2.0-85174478822,
  title={Exploring the Role of AI Assistants in Computer Science Education: Methods, Implications, and Instructor Perspectives},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85174404773&origin=inward,10.1109/ICALT58122.2023.00072,"AbstractView references

The recent progress in generative AI models, particularly large language models (LLMs), has brought about a transformation in the field of education. Conversational LLM services, such as Google's Bard and OpenAI's ChatGPT, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. In this paper, we observe ChatGPT to explore how LLM services impact learning and instruction in higher education. First, we mapped the capabilities of the system by reviewing the grey literature on ChatGPT and using the system ourselves for two months. Second, we selected a Bachelor level computer science curriculum from a Finnish university, and examined the impact of ChatGPT on the offered courses. As an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of AI-assisted learning in universities and beyond. © 2023 IEEE.",2023,5,Conference Paper,"@article{2-s2.0-85174404773,
  title={AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
DISCOVERING INSIGHTS IN LEARNING ANALYTICS THROUGH A MIXED-METHODS FRAMEWORK: APPLICATION TO COMPUTER PROGRAMMING EDUCATION,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173949352&origin=inward,10.28945/5182,"AbstractView references

Aim/Purpose This article proposes a framework based on a sequential explanatory mixed-methods design in the learning analytics domain to enhance the models used to support the success of the learning process and the learner. The framework consists of three main phases: (1) quantitative data analysis; (2) qualitative data analysis; and (3) integration and discussion of results. Furthermore, we illus-trated the application of this framework by examining the relationships between learning process metrics and academic performance in the subject of Computer Programming coupled with content analysis of the responses to a students’ per-ception questionnaire of their learning experiences in this subject. Background There is a prevalence of quantitative research designs in learning analytics, which limits the understanding of students’ learning processes. This is due to the abundance and ease of collection of quantitative data in virtual environ-ments and learning management systems compared to qualitative data. Methodology This study uses a mixed-methods, non-experimental, research design. The quan-titative phase of the framework aims to analyze the data to identify behaviors, trends, and relationships between measures using correlation or regression anal-ysis. On the other hand, the qualitative phase of the framework focuses on con-ducting a content analysis of the qualitative data. This framework was applied to historical quantitative and qualitative data from students’ use of an automated feedback and evaluation platform for programming exercises in a programming course at the National University of Colombia during 2019 and 2020. The re-search question of this study is: How can mixed-methods research applied to learning analytics generate a better understanding of the relationships between the variables generated throughout the learning process and the academic per-formance of students in the subject of Computer Programming? Contribution The main contribution of this work is the proposal of a mixed-methods learn-ing analytics framework applicable to computer programming courses, which al-lows for complementing, corroborating, or refuting quantitatively evidenced re-sults with qualitative data and generating hypotheses about possible causes or explanations for student behavior. In addition, the results provide a better un-derstanding of the learning processes in the Computer Programming course at the National University of Colombia. Findings A framework based on sequential explanatory mixed-methods design in the field of learning analytics has been proposed to improve the models used to support the success of the learning process and the learner. The answer to the research question posed corresponds to that the mixed methods effectively complement quantitative and qualitative data. From the analysis of the data of the application of the framework, it appears that the qualitative data, represent-ing the perceptions of the students, generally supported and extended the quan-titative data. The consistency between the two phases allowed us to generate hy-potheses about the possible causes of student behavior and provide a better un-derstanding of the learning processes in the course. Recommendations for Practitioners We suggest implementing the proposed mixed-methods learning analytics framework in various educational contexts and populations. By doing so, practi-tioners can gather more diverse data and insights, which can lead to a better un-derstanding of learning processes in different settings and with different groups of learners. Recommendations for Researchers Researchers can use the proposed approach in their learning analytics projects, usually based exclusively on quantitative data analysis, to complement their re-sults, find explanations for their students’ behaviors, and understand learning processes in depth thanks to the information provided by the complementary analysis of qualitative data. Impact on Society The prevalence of exclusively quantitative research designs in learning analytics can limit our understanding of students’ learning processes. Instead, the mixed-methods approach we propose suggests a more comprehensive approach to learning analytics that includes qualitative data, which can provide deeper in-sight into students’ learning experiences and processes. Ultimately, this can lead to more effective interventions and improvements in teaching and learning practices. Future Research Potential lines of research to continue the work on mixed-method learning ana-lytics methodology include the following: first, implementing the framework on a different population sample, such as students from other universities or other knowledge areas; second, using techniques to correct unbalanced data sets in learning analytics studies; third, analyzing student interactions with the auto-mated grading platform and their academic activities in relation with their activ-ity grades; last, using the findings to design interventions that positively impact academic performance and evaluating the impact statistically through experimental study designs. In the context of introductory programming educa-tion, AI/large language models have the potential to revolutionize teaching by enhancing the learning experience, providing personalized support, and ena-bling more efficient assessment and feedback mechanisms. Future research in this area is to implement the proposed framework on data from an introductory programming course using these models. © (2023), (Informing Science Institute). All Rights Reserved.",2023,34,Article,"@article{2-s2.0-85173949352,
  title={DISCOVERING INSIGHTS IN LEARNING ANALYTICS THROUGH A MIXED-METHODS FRAMEWORK: APPLICATION TO COMPUTER PROGRAMMING EDUCATION},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Recommendations to Create Programming Exercises to Overcome ChatGPT,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173600448&origin=inward,10.1109/CSEET58097.2023.00031,"AbstractView references

Large language models, such as ChatGPT, possess the potential to revolutionize educational practices across various domains. Nonetheless, the deployment of these models can inadvertently foster academic dishonesty due to their facile accessibility. In practical courses like programming, where hands-on experience is crucial for learning, relying solely on ChatGPT can hinder students' ability to engage with the exercises, consequently impeding the attainment of learning outcomes.This paper conducts an experimental analysis of GPT 3.5 and GPT 4, gauging their proficiencies and constraints in resolving a compendium of 22 programming exercises. We discern and categorize exercises based on ChatGPT's ability to furnish viable solutions, alongside those that remain unaddressed. Moreover, an evaluation of the malleability of the solutions proposed by ChatGPT is undertaken. Subsequently, we propound a series of recommendations aimed at curtailing undue dependence on ChatGPT, thereby fostering authentic competency development in programming. The efficaciousness of these recommendations is underpinned by their integration into the design and delivery of an examination as part of the corresponding course. © 2023 IEEE.",2023,5,Conference Paper,"@article{2-s2.0-85173600448,
  title={Recommendations to Create Programming Exercises to Overcome ChatGPT},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
ChatGPT as a Game-Changer for Embedding Emojis in Faculty Feedback,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85172278717&origin=inward,10.1109/CSCE60160.2023.00173,"AbstractView references

This study explores the potential of integrating emojis, and digital pictographs, into faculty feedback to augment student learning outcomes. This additional layer of expressiveness, encouragement, and involvement adds a personal touch to the often distant and virtual student-educator communications, fostering motivation. The study focuses on the impact of emojis on the learning process within the scrutinized Computer Science (CS) Department. Capitalizing on the capabilities of OpenAI's Large Language Model (LLM) ChatGPT-4, its Application Programming Interface (API), and associated tools and third-party plugins, a system that translates text into corresponding emojis and vice versa has been developed. The proposed application offers direct benefits to educators by simplifying the provision of detailed and extensive feedback to students. The primary research question is: Can the appropriate use of emojis, matched with the sentiment of the feedback text, contribute to enhanced student learning outcomes, higher retention rates, and boost the reputation of the educators providing it? Two surveys on the impact of emojis across selected course sections were conducted to answer the question: a pre-survey and a post-survey involving 175 active participants. The results were analyzed, and it was concluded that integrating emojis in faculty feedback, particularly when grading student work, could potentially enhance student learning outcomes and their overall course experience. © 2023 IEEE.",2023,8,Conference Paper,"@article{2-s2.0-85172278717,
  title={ChatGPT as a Game-Changer for Embedding Emojis in Faculty Feedback},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
'We Need To Talk About ChatGPT': The Future of AI and Higher Education,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85168683291&origin=inward,10.1109/SEENG59157.2023.00010,"AbstractView references

On November 30th, 2022, OpenAI released the large language model ChatGPT, an extension of GPT-3. The AI chatbot provides real-time communication in response to users' requests. The quality of ChatGPT's natural speaking answers marks a major shift in how we will use AI-generated information in our day-to-day lives. For a software engineering student, the use cases for ChatGPT are manifold: assessment preparation, translation, and creation of specified source code, to name a few. It can even handle more complex aspects of scientific writing, such as summarizing literature and paraphrasing text. Hence, this position paper addresses the need for discussion of potential approaches for integrating ChatGPT into higher education. Therefore, we focus on articles that address the effects of ChatGPT on higher education in the areas of software engineering and scientific writing. As ChatGPT was only recently released, there have been no peer-reviewed articles on the subject. Thus, we performed a structured grey literature review using Google Scholar to identify preprints of primary studies. In total, five out of 55 preprints are used for our analysis. Furthermore, we held informal discussions and talks with other lecturers and researchers and took into account the authors' test results from using ChatGPT. We present five challenges and three opportunities for the higher education context that emerge from the release of ChatGPT. The main contribution of this paper is a proposal for how to integrate ChatGPT into higher education in four main areas. © 2023 IEEE.",2023,4,Conference Paper,"@article{2-s2.0-85168683291,
  title={'We Need To Talk About ChatGPT': The Future of AI and Higher Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Training Language Models for Programming Feedback Using Automated Repair Tools,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85164915524&origin=inward,10.1007/978-3-031-36272-9_79,"AbstractView references

In introductory programming courses, automated repair tools (ARTs) are used to provide feedback to students struggling with debugging. Most successful ARTs take advantage of context-specific educational data to construct repairs to students’ buggy codes. Recent work in student program repair using large language models (LLMs) has also started to utilize such data. An underexplored area in this field is the use of ARTs in combination with LLMs. In this paper, we propose to transfer the repairing capabilities of existing ARTs to open large language models by finetuning LLMs on ART corrections to buggy codes. We experiment with this approach using three large datasets of Python programs written by novices. Our results suggest that a finetuned LLM provides more reliable and higher-quality repairs than the repair tool used for finetuning the model. This opens venues for further deploying and using educational LLM-based repair techniques. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",2023,6,Conference Paper,"@article{2-s2.0-85164915524,
  title={Training Language Models for Programming Feedback Using Automated Repair Tools},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Automated Program Repair Using Generative Models for Code Infilling,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85164908820&origin=inward,10.1007/978-3-031-36272-9_74,"AbstractView references

In educational settings, automated program repair techniques serve as a feedback mechanism to guide students working on their programming assignments. Recent work has investigated using large language models (LLMs) for program repair. In this area, most of the attention has been focused on using proprietary systems accessible through APIs. However, the limited access and control over these systems remain a block to their adoption and usage in education. The present work studies the repairing capabilities of open large language models. In particular, we focus on a recent family of generative models, which, on top of standard left-to-right program synthesis, can also predict missing spans of code at any position in a program. We experiment with one of these models on four programming datasets and show that we can obtain good repair performance even without additional training. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",2023,6,Conference Paper,"@article{2-s2.0-85164908820,
  title={Automated Program Repair Using Generative Models for Code Infilling},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85162764146&origin=inward,10.1109/COMPSAC57700.2023.00117,"AbstractView references

The recent advancements in Artificial Intelligence, particularly in large language models and generative models, are reshaping the field of software engineering by enabling innovative ways of performing various tasks, such as programming, debugging, and testing. However, few existing works have thoroughly explored the potential of AI in code generation and users' attitudes toward AI-assisted coding tools. This knowledge gap leaves it unclear how AI is transforming software engineering and programming education. This paper presents a scalable crowdsourcing data-driven framework to investigate the code generation performance of generative large language models from diverse perspectives across multiple social media platforms. Specifically, we utilize ChatGPT, a popular generative large language model, as a representative example to reveal its insights and patterns in code generation. First, we propose a hybrid keyword word expansion method that integrates words suggested by topic modeling and expert knowledge to filter relevant social posts of interest on Twitter and Reddit. Then we collect 316K tweets and 3.2K Reddit posts about ChatGPT's code generation, spanning from Dec. 1, 2022 to January 31, 2023. Our data analytics show that ChatGPT has been used in more than 10 programming languages, with Python and JavaScript being the two most popular, for a diverse range of tasks such as code debugging, interview preparation, and academic assignment solving. Surprisingly, our analysis shows that fear is the dominant emotion associated with ChatGPT's code generation, overshadowing emotions of happiness, anger, surprise, and sadness. Furthermore, we construct a ChatGPT prompt and corresponding code dataset by analyzing the screen-shots of ChatGPT code generation shared on social media. This dataset enables us to evaluate the quality of the generated code, and we have released this dataset to the public. We believe the insights gained from our work will provide valuable guidance for future research on AI-powered code generation. © 2023 IEEE.",2023,10,Conference Paper,"@article{2-s2.0-85162764146,
  title={Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Davinci Goes to Bebras: A Study on the Problem Solving Ability of GPT-3,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85160866835&origin=inward,10.5220/0012007500003470,"AbstractView references

In this paper we study the problem-solving ability of the Large Language Model known as GPT-3 (codename DaVinci), by considering its performance in solving tasks proposed in the “Bebras International Challenge on Informatics and Computational Thinking”. In our experiment, GPT-3 was able to answer with a majority of correct answers about one third of the Bebras tasks we submitted to it. The linguistic fluency of GPT-3 is impressive and, at a first reading, its explanations sound coherent, on-topic and authoritative; however the answers it produced are in fact erratic and the explanations often questionable or plainly wrong. The tasks in which the system performs better are those that describe a procedure, asking to execute it on a specific instance of the problem. Tasks solvable with simple, one-step deductive reasoning are more likely to obtain better answers and explanations. Synthesis tasks, or tasks that require a more complex logical consistency get the most incorrect answers. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)",2023,11,Conference Paper,"@article{2-s2.0-85160866835,
  title={Davinci Goes to Bebras: A Study on the Problem Solving Ability of GPT-3},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions About Code,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85150767704&origin=inward,10.5220/0011996900003470,"AbstractView references

We analyzed effectiveness of three generative pre-trained transformer (GPT) models in answering multiple-choice question (MCQ) assessments, often involving short snippets of code, from introductory and intermediate programming courses at the postsecondary level. This emerging technology stirs countless discussions of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming education (e.g., cheating). However, the capabilities of GPT models and their limitations to reason about and/or analyze code in educational settings have been under-explored. We evaluated several OpenAI’s GPT models on formative and summative MCQ assessments from three Python courses (530 questions). We found that MCQs containing code snippets are not answered as successfully as those that only contain natural language. While questions requiring to fill-in a blank in the code or completing a natural language statement about the snippet are handled rather successfully, MCQs that require analysis and/or reasoning about the code (e.g., what is true/false about the snippet, or what is its output) appear to be the most challenging. These findings can be leveraged by educators to adapt their instructional practices and assessments in programming courses, so that GPT becomes a valuable assistant for a learner as opposed to a source of confusion and/or potential hindrance in the learning process. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)",2023,12,Conference Paper,"@article{2-s2.0-85150767704,
  title={Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions About Code},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Prompt text classifications with transformer models! An exemplary introduction to prompt-based learning with large language models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85142666964&origin=inward,10.1080/15391523.2022.2142872,"AbstractView references

This study investigates the potential of automated classification using prompt-based learning approaches with transformer models (large language models trained in an unsupervised manner) for a domain-specific classification task. Prompt-based learning with zero or few shots has the potential to (1) make use of artificial intelligence without sophisticated programming skills and (2) make use of artificial intelligence without fine-tuning models with large amounts of labeled training data. We apply this novel method to perform an experiment using so-called zero-shot classification as a baseline model and a few-shot approach for classification. For comparison, we also fine-tune a language model on the given classification task and conducted a second independent human rating to compare it with the given human ratings from the original study. The used dataset consists of 2,088 email responses to a domain-specific problem-solving task that were manually labeled for their professional communication style. With the novel prompt-based learning approach, we achieved a Cohen’s kappa of.40, while the fine-tuning approach yields a kappa of.59, and the new human rating achieved a kappa of.58 with the original human ratings. However, the classifications from the machine learning models have the advantage that each prediction is provided with a reliability estimate allowing us to identify responses that are difficult to score. We, therefore, argue that response ratings should be based on a reciprocal workflow of machine raters and human raters, where the machine rates easy-to-classify responses and the human raters focus and agree on the responses that are difficult to classify. Further, we believe that this new, more intuitive, prompt-based learning approach will enable more people to use artificial intelligence. © 2022 ISTE.",2023,17,Article,"@article{2-s2.0-85142666964,
  title={Prompt text classifications with transformer models! An exemplary introduction to prompt-based learning with large language models},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Fooling MOSS Detection with Pretrained Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140848572&origin=inward,10.1145/3511808.3557079,"AbstractView references

As artificial intelligence (AI) technologies become increasingly powerful and prominent in society, their misuse is a growing concern. In educational settings, AI technologies could be used by students to cheat on assignments and exams. In this paper we explore whether transformers can be used to solve introductory level programming assignments while bypassing commonly used AI tools to detect similarities between pieces of software. We find that a student using GPT-J [60] can complete introductory level programming assignments without triggering suspicion from MOSS [2], a widely used software similarity and plagiarism detection tool. This holds despite the fact that GPT-J was not trained on the problems in question and is not provided with any examples to work from. We further find that the code written by GPT-J is diverse in structure, lacking any particular tells that future plagiarism detection techniques may use to try to identify algorithmically generated code. We conclude with a discussion of the ethical and educational implications of large language models and directions for future research. © 2022 Owner/Author.",2022,11,Conference Paper,"@article{2-s2.0-85140848572,
  title={Fooling MOSS Detection with Pretrained Language Models},
  author={N/A},
  journal={N/A},
  year={2022},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Generating Diverse Code Explanations using the GPT-3 Large Language Model,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137106608&origin=inward,10.1145/3501709.3544280,"AbstractView references

Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these approaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github's Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs' potential to support learning by explaining numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet.We present a subset of three use cases from our evolving design space of AI Explanations of Code. © 2022 Owner/Author.",2022,3,Conference Paper,"@article{2-s2.0-85137106608,
  title={Generating Diverse Code Explanations using the GPT-3 Large Language Model},
  author={N/A},
  journal={N/A},
  year={2022},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85136515497&origin=inward,10.1145/3501385.3543957,"AbstractView references

This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike. © 2022 ACM.",2022,17,Conference Paper,"@article{2-s2.0-85136515497,
  title={Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models},
  author={N/A},
  journal={N/A},
  year={2022},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85139537385&origin=inward,10.1109/IROS47612.2022.9981810,"AbstractView references

Natural language is the most intuitive medium for us to interact with other people when expressing commands and instructions. However, using language is seldom an easy task when humans need to express their intent towards robots, since most of the current language interfaces require rigid templates with a static set of action targets and commands. In this work, we provide a flexible language-based interface for human-robot collaboration, which allows a user to reshape existing trajectories for an autonomous agent. We take advantage of recent advancements in the field of large language models (BERT and CLIP) to encode the user command, and then combine these features with trajectory information using multi-modal attention transformers. We train the model using imitation learning over a dataset containing robot trajectories modified by language commands, and treat the trajectory generation process as a sequence prediction problem, analogously to how language generation architectures operate. We evaluate the system in multiple simulated trajectory scenarios, and show a significant performance increase of our model over baseline approaches. In addition, our real-world experiments with a robot arm show that users significantly prefer our natural language interface over traditional methods such as kinesthetic teaching or cost-function programming. Our study shows how the field of robotics can take advantage of large pre-trained language models towards creating more intuitive interfaces between robots and machines. Project webpage: https://arthurfenderbucker.github.io/NL_trajectory_reshaper/ © 2022 IEEE.",2022,7,Conference Paper,"@article{2-s2.0-85139537385,
  title={Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers},
  author={N/A},
  journal={N/A},
  year={2022},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}"
