"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"“We Need To Talk About ChatGPT”: The Future of AI and Higher Education","M. Neumann; M. Rauschenberger; E. -M. Schön","University of Applied Sciences and Arts Hannover, Hannover, Germany; University of Applied Sciences Emden/Leer, Emden, Germany; University of Applied Sciences Emden/Leer, Emden, Germany","2023 IEEE/ACM 5th International Workshop on Software Engineering Education for the Next Generation (SEENG)","27 Jul 2023","2023","","","29","32","On November 30th, 2022, OpenAI released the large language model ChatGPT, an extension of GPT-3. The AI chatbot provides real-time communication in response to users’ requests. The quality of ChatGPT’s natural speaking answers marks a major shift in how we will use AI-generated information in our day-to-day lives. For a software engineering student, the use cases for ChatGPT are manifold: assessment preparation, translation, and creation of specified source code, to name a few. It can even handle more complex aspects of scientific writing, such as summarizing literature and paraphrasing text. Hence, this position paper addresses the need for discussion of potential approaches for integrating ChatGPT into higher education. Therefore, we focus on articles that address the effects of ChatGPT on higher education in the areas of software engineering and scientific writing. As ChatGPT was only recently released, there have been no peer-reviewed articles on the subject. Thus, we performed a structured grey literature review using Google Scholar to identify preprints of primary studies. In total, five out of 55 preprints are used for our analysis. Furthermore, we held informal discussions and talks with other lecturers and researchers and took into account the authors’ test results from using ChatGPT. We present five challenges and three opportunities for the higher education context that emerge from the release of ChatGPT. The main contribution of this paper is a proposal for how to integrate ChatGPT into higher education in four main areas.","","979-8-3503-0186-1","10.1109/SEENG59157.2023.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10190438","ChatGPT;GPT-3;large language model;higher education;AI influences;position paper","Manifolds;Source coding;Education;Chatbots;Real-time systems;Internet;Proposals","","39","","15","IEEE","27 Jul 2023","","","IEEE","IEEE Conferences"
"Teaching Plan Generation and Evaluation With GPT-4: Unleashing the Potential of LLM in Instructional Design","B. Hu; L. Zheng; J. Zhu; L. Ding; Y. Wang; X. Gu","School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Education, City University of Macau, Macau, China; Weiyu High School, Shanghai, China; Minhang High School, Shanghai, China; Shanghai Institute of AI for Education, East China Normal University, Shanghai, China; Department of Education Information Technology, East China Normal University, Shanghai, China","IEEE Transactions on Learning Technologies","30 Apr 2024","2024","17","","1471","1485","This study explores and analyzes the specific performance of large language models (LLMs) in instructional design, aiming to unveil their potential strengths and possible weaknesses. Recently, the influence of LLMs has gradually increased in multiple fields, yet exploratory research on their application in education remains relatively scarce. In response to this situation, our research, grounded in pedagogical content knowledge theory, initially formulated an instructional design framework based on mathematical problem chains and corresponding prompt instructions. Subsequently, a comprehensive tool for assessing LLM's instructional design capabilities was developed. Utilizing Generative Pretrained Transformer 4, a high school mathematics teaching plan dataset was generated. Finally, the performance of LLMs in instructional design was evaluated. The evaluation results revealed that the teaching plans generated by LLMs excel in setting instructional objectives, identifying teaching priorities, organizing problem chains and teaching activities, articulating subject content, and selecting methods and strategies. Particularly commendable performance was noted in the modules of statistics and functions. However, there is room for improvement in aspects related to mathematical culture and interdisciplinary assessment, as well as in the geometry and algebra modules. Lastly, this study proposes initiatives, such as LLM prompt-based teacher training and the integration of mathematics-focused LLMs. These suggestions aim to advance personalized instructional design and professional development of teachers, offering educators new insights into the in-depth application of LLMs.","1939-1382","","10.1109/TLT.2024.3384765","National Natural Science Foundation of China(grant numbers:62007008); Natural Science Foundation of Chongqing(grant numbers:CSTB2022NSCQ-MSX0590); East China Normal University Shanghai Institute(grant numbers:202202005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10490240","Automated teaching plan generation;instructional design capabilities;large language models (LLMs);mathematical problem chains;pedagogical content knowledge (PCK)","Education;Mathematics;Mathematical models;Task analysis;Technological innovation;Standards;Knowledge based systems","","","","98","IEEE","3 Apr 2024","","","IEEE","IEEE Journals"
"Exploring the Role of AI Assistants in Computer Science Education: Methods, Implications, and Instructor Perspectives","T. Wang; D. V. Díaz; C. Brown; Y. Chen","Department of Computer Science, Virginia Tech, USA; Department of Computer Science, Virginia Tech, USA; Department of Computer Science, Virginia Tech, USA; Department of Computer Science, Virginia Tech, USA","2023 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)","7 Nov 2023","2023","","","92","102","The use of AI assistants, along with the challenges they present, has sparked significant debate within the community of computer science education. While these tools demonstrate the potential to support students' learning and instructors' teaching, they also raise concerns about enabling unethical uses by students. Previous research has suggested various strategies aimed at addressing these issues. However, they concentrate on introductory programming courses and focus on one specific type of problem. The present research evaluated the performance of ChatGPT, a state-of-the-art AI assistant, at solving 187 problems spanning three distinct types that were collected from six undergraduate computer science. The selected courses covered different topics and targeted different program levels. We then explored methods to modify these problems to adapt them to ChatGPT's capabilities to reduce potential misuse by students. Finally, we conducted semi-structured interviews with 11 computer science instructors. The aim was to gather their opinions on our problem modification methods, understand their perspectives on the impact of AI assistants on computer science education, and learn their strategies for adapting their courses to leverage these AI capabilities for educational improvement. The results revealed issues ranging from academic fairness to long-term impact on students' mental models. From our results, we derived design implications and recommended tools to help instructors design and create future course material that could more effectively adapt to AI assistants' capabilities.","1943-6106","979-8-3503-2946-9","10.1109/VL-HCC57772.2023.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305701","Computer science education;Large language model;ChatGPT;Interview","Visualization;Shape;Computational modeling;Education;Chatbots;Distance measurement;Computer science education","","1","","55","IEEE","7 Nov 2023","","","IEEE","IEEE Conferences"
"Opportunities, Challenges, Strategies, and Reforms for ChatGPT in Higher Education","X. Xie; S. Ding","Journal Editorial Department of Wuhan University of Science and Technology, Wuhan University of Science and Technology, Wuhan, China; College of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan, China","2023 International Conference on Educational Knowledge and Informatization (EKI)","15 Feb 2024","2023","","","14","18","ChatGPT is a powerful large language model developed by OpenAI. It has a profound impact on higher education fields. This technology offers exciting opportunities for students and educators, including personalized feedback, increased accessibility, interactive conversations, lecture preparation, performance evaluation, and new ways to teach complex concepts. At the same time, ChatGPT poses different threats and challenges to the traditional high education system, such as the possibility of cheating on online exams, human-like text generation, diminished critical thinking skills, and difficulties in evaluating information generated by ChatGPT. This paper explores the potential opportunities and challenges that ChatGPT poses in higher education from the perspective of students and educators. In higher education, by understanding these challenges and taking steps to mitigate them, we can then ensure the language models to be used in a responsible and ethical way.","","979-8-3503-3126-4","10.1109/EKI61071.2023.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10430333","ChatGPT;Large Language Model;Higher Education","Performance evaluation;Ethics;Education;Oral communication;Chatbots","","","","14","IEEE","15 Feb 2024","","","IEEE","IEEE Conferences"
"Music Curriculum Research Using a Large Language Model, Cloud Computing and Data Mining Technologies","Y. Shang","Nanchong Vocational and Technical College, Nanchong, China","Journal of Web Engineering","17 Apr 2024","2024","23","2","251","273","This paper presents a method to enhance the scientific nature of the music curriculum model by integrating a large language model, cloud computing and data mining technology for the analysis of the music teaching curriculum model. To maintain the integrity of the mixing matrix while employing the frequency hopping frequency, the paper suggests dividing the mixing matrix into a series of sub-matrices along the vertical time axis. This approach transforms wideband music signal processing into a narrowband processing problem. Additionally, two hybrid matrix estimation algorithms are proposed in this paper using underdetermined conditions. Furthermore, utilizing the estimated mixing matrix and the detected time-frequency support domain, the paper employs the subspace projection algorithm for underdetermined blind separation of music signals in the time-frequency domain. This procedure, along with the integration of the estimated direction of arrival (DoA), enables the completion of frequency-hopping network station music signal sorting. Extensive simulation teaching demonstrates that the music curriculum model proposed in this paper, based on a large language model, cloud computing and data mining technologies, significantly enhances the quality of modern music teaching.","1544-5976","","10.13052/jwe1540-9589.2323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504109","Large language model;cloud computing;data mining;music;curriculum model","Cloud computing;Time-frequency analysis;Direction-of-arrival estimation;Computational modeling;Education;Music;Frequency conversion","","","","18","","17 Apr 2024","","","River Publishers","River Publishers Journals"
"Challenging the Confirmation Bias: Using ChatGPT as a Virtual Peer for Peer Instruction in Computer Programming Education","O. L. Dos Santos; D. Cury","Departamento de Informática, Universidade Federal do Espírito Santo, Vitória, ES, Brazil; Departamento de Informática, Universidade Federal do Espírito Santo, Vitória, ES, Brazil","2023 IEEE Frontiers in Education Conference (FIE)","5 Jan 2024","2023","","","1","7","This paper proposes the implementation of Chat-GPT, a large language model, as a virtual peer for peer instruction in computer programming courses. The authors argue that AI tools, including ChatGPT, can bring benefits such as personalized learning, instant feedback, and active engagement to the classroom. An experiment was conducted with two groups of programming students: one receiving traditional instruction and the other utilizing the ChatGPT-based peer instruction model. Both groups were given the same programming assignments and assessments. The results indicated that the ChatGPT group outperformed the traditionally instructed group, demonstrating better programming skills and a deeper understanding of concepts. The ChatGPT group also reported higher engagement and satisfaction. However, some difficulties were observed when using ChatGPT for more abstract problems. Overall, the study highlights the effectiveness of using ChatGPT as a virtual peer to enhance active learning and student outcomes in computer programming courses, challenging biases regarding AI's potential benefits in education. The authors hope this study encourages educators to embrace AI tools in the classroom and overcome confirmation biases about their impact.","2377-634X","979-8-3503-3642-9","10.1109/FIE58773.2023.10343247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343247","peer instruction;pair programming;artificial intelligence;chatgpt","Codes;Computational modeling;Education;Learning (artificial intelligence);Chatbots;Encoding;Data models","","","","13","IEEE","5 Jan 2024","","","IEEE","IEEE Conferences"
"AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education","S. Laato; B. Morschheuser; J. Hamari; J. Björne","Gamification Group, Tampere University, Tampere, Finland; FAU Erlangen-Nürnberg, Inst. of Information Systems, Nuremberg, Germany; Gamification Group, Tampre University, Tampere, Finland; Dept. of Computing, University of Turku, Turku, Finland","2023 IEEE International Conference on Advanced Learning Technologies (ICALT)","29 Sep 2023","2023","","","226","230","The recent progress in generative AI models, particularly large language models (LLMs), has brought about a transformation in the field of education. Conversational LLM services, such as Google's Bard and OpenAI's ChatGPT, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. In this paper, we observe ChatGPT to explore how LLM services impact learning and instruction in higher education. First, we mapped the capabilities of the system by reviewing the grey literature on ChatGPT and using the system ourselves for two months. Second, we selected a Bachelor level computer science curriculum from a Finnish university, and examined the impact of ChatGPT on the offered courses. As an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of AI-assisted learning in universities and beyond.","2161-377X","979-8-3503-0054-3","10.1109/ICALT58122.2023.00072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260931","ChatGPT;Bard;GPT-4;generative language models;large language models;higher education;learning","Computer science;Codes;Education;Chatbots;Internet;Artificial intelligence","","7","","21","IEEE","29 Sep 2023","","","IEEE","IEEE Conferences"
"Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development","A. Neyem; L. A. González; M. Mendoza; J. P. S. Alcocer; L. Centellas; C. Paredes","Department of Computer Science, Faculty of Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Computer Science, Faculty of Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Computer Science, Faculty of Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Computer Science, Faculty of Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Computer Science, Faculty of Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Computer Science, Faculty of Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile","IEEE Transactions on Learning Technologies","27 May 2024","2024","17","","1639","1654","Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local “lessons learned” database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios.","1939-1382","","10.1109/TLT.2024.3396735","National Center for Artificial Intelligence(grant numbers:FB210017); Chilean National Agency for Research and Development; ANID Scholarship Program DOCTORADO NACIONAL(grant numbers:2021-21212115); Pontificia Universidad Católica de Chile; National Center for Artificial Intelligence(grant numbers:FB210017); Chilean National Agency for Research and Development; ANID Scholarship Program DOCTORADO NACIONAL(grant numbers:2021-21212115); Programa de Inserción Académica 2022, Vicerrectoría Académica y Prorrectoría; ANID Scholarship Program DOCTORADO NACIONAL(grant numbers:2024-21240734); Millennium Institute for Foundational Research on Data(grant numbers:ICN17_002); ANID Fondecyt(grant numbers:1241462); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10518103","Capstone courses;ChatGPT;context-aware learning;generative artificial intelligence (AI);large language models (LLMs);software engineering education","Software;Artificial intelligence;Task analysis;Software engineering;Codes;Chatbots;Knowledge engineering","","","","39","IEEE","3 May 2024","","","IEEE","IEEE Journals"
"Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education","W. H. Pan; M. J. Chok; J. L. S. Wong; Y. X. Shin; Y. S. Poon; Z. Yang; C. Y. Chong; D. Lo; M. K. Lim","School of Information Technology, Monash University Malaysia, Subang Jaya, Malaysia; School of Information Technology, Monash University Malaysia, Subang Jaya, Malaysia; School of Information Technology, Monash University Malaysia, Subang Jaya, Malaysia; School of Information Technology, Monash University Malaysia, Subang Jaya, Malaysia; School of Information Technology, Monash University Malaysia, Subang Jaya, Malaysia; School of Computing and Information Systems, Singapore Management University, Singapore, Singapore; School of Information Technology, Monash University Malaysia, Subang Jaya, Malaysia; School of Computing and Information Systems, Singapore Management University, Singapore, Singapore; School of Information Technology, Monash University Malaysia, Subang Jaya, Malaysia","2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)","19 Jun 2024","2024","","","1","11","Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct. In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.","2832-7578","979-8-4007-0498-7","10.1145/3639474.3640068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554754","Software Engineering Education;AI-Generated Code;AI-Generated Code Detection","Training;Codes;Detectors;Chatbots;Encoding;Programming profession;Software engineering","","","","41","CCBY","19 Jun 2024","","","IEEE","IEEE Conferences"
"ChatGPT as a Game-Changer for Embedding Emojis in Faculty Feedback","E. Kupershtein; Y. Kumar; A. Manikandan; P. Morreale; J. J. Li","Department of Computer Science and Technology, Kean University, Union, NJ, USA; Department of Computer Science and Technology, Kean University, Union, NJ, USA; Department of Computer Science and Technology, Kean University, Union, NJ, USA; Department of Computer Science and Technology, Kean University, Union, NJ, USA; Department of Computer Science and Technology, Kean University, Union, NJ, USA","2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)","9 Apr 2024","2023","","","1039","1046","This study explores the potential of integrating emojis, and digital pictographs, into faculty feedback to augment student learning outcomes. This additional layer of expressiveness, encouragement, and involvement adds a personal touch to the often distant and virtual student-educator communications, fostering motivation. The study focuses on the impact of emojis on the learning process within the scrutinized Computer Science (CS) Department. Capitalizing on the capabilities of OpenAI's Large Language Model (LLM) ChatGPT-4, its Application Programming Interface (API), and associated tools and third-party plugins, a system that translates text into corresponding emojis and vice versa has been developed. The proposed application offers direct benefits to educators by simplifying the provision of detailed and extensive feedback to students. The primary research question is: Can the appropriate use of emojis, matched with the sentiment of the feedback text, contribute to enhanced student learning outcomes, higher retention rates, and boost the reputation of the educators providing it? Two surveys on the impact of emojis across selected course sections were conducted to answer the question: a pre-survey and a post-survey involving 175 active participants. The results were analyzed, and it was concluded that integrating emojis in faculty feedback, particularly when grading student work, could potentially enhance student learning outcomes and their overall course experience.","","979-8-3503-2759-5","10.1109/CSCE60160.2023.00173","NSF(grant numbers:1834620,1928452,2137791); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487568","emojis;Feedback Emojifier;ChatGPT;computer science education;text-to-emoji translation","Surveys;Computer science;Chatbots;Emojis;Application programming interfaces","","1","","38","IEEE","9 Apr 2024","","","IEEE","IEEE Conferences"
"Using LLM Artificial Intelligence Systems as Complex SQL Programming Assistants","P. Pornphol; S. Chittayasothorn","Department of Digital Technology, Phuket Rajabhat University, Phuket, Thailand; School of Engineering, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand","2024 12th International Conference on Information and Education Technology (ICIET)","5 Jun 2024","2024","","","477","481","Learning database programming such as SQL programming is a challenging task when the queries become more complex. SQL is a declarative language based on relational calculus which describes the definition of the query results instead of describing the procedure or steps used to obtain the query result. Tutorial sessions using tutorial assistances are generally required to support the learning of advanced part of the language. Recently generative AI systems demonstrated question answering capabilities including programming codes generation. This paper verifies the SQL code generating capabilities of four generative AI systems: Bing, Bard, ChatGPT, and Copilot and their suitability as SQL programming assistants.","","979-8-3503-7177-2","10.1109/ICIET60671.2024.10542806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10542806","SQL;LLM;database;complex queries","Productivity;Structured Query Language;Codes;Generative AI;Databases;Education;Tutorials","","","","13","IEEE","5 Jun 2024","","","IEEE","IEEE Conferences"
"LLM-Driven SAT Impact on Phishing Defense: A Cross-Sectional Analysis","H. İŞ","Department of Computer Engineering, Batman University, Batman, Turkey","2024 12th International Symposium on Digital Forensics and Security (ISDFS)","15 May 2024","2024","","","1","5","Amidst the growing sophistication of phishing threats that exploit human vulnerabilities, this study investigates the effectiveness of Security Awareness Training (SAT) enhanced by Large Language Models (LLMs). Targeting a diverse group of 1,270 participants, including academicians, officers, and students, it aims to evaluate whether LLM-driven SAT can strengthen phishing defenses and cultivate a more resilient digital environment. Initial assessments revealed a baseline Phish Prone Percentage (PPP) of 18.3%, indicating a pronounced vulnerability across participant groups. The deployment of an LLM-enhanced SAT program, characterized by its adaptive and interactive training modules, led to a significant post-training reduction in PPP to 6.3%. This outcome demonstrates the program's success in mitigating phishing risks and underscores the necessity of evolving SAT strategies to combat the dynamic nature of phishing attacks. The study's findings, illustrating a substantial improvement in phishing defense capabilities through LLM-integrated SAT, advocate for the integration of advanced technologies in cybersecurity education. By effectively lowering phishing vulnerability from 18.3% to 6.3%, this research highlights the critical role of innovative training methodologies in enhancing digital security across varied academic and professional landscapes.","2768-1831","979-8-3503-3036-6","10.1109/ISDFS60797.2024.10527274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10527274","Phishing;Large Language Model(LLM);Cyber Security;Security Awareness Training(SAT);Artificial Intelligence","Training;Phishing;Digital forensics;Organizations;Testing","","","","12","IEEE","15 May 2024","","","IEEE","IEEE Conferences"
"Large Language Models for Software Engineering: Survey and Open Problems","A. Fan; B. Gokkaya; M. Harman; M. Lyubarskiy; S. Sengupta; S. Yoo; J. M. Zhang","Generative AI Team Meta Platforms Inc., New York, NY, USA; PyTorch Team Meta Platforms Inc., Menlo Park, CA, USA; Instagram Product Foundation Meta Platforms Inc., London, UK; Developer Infrastructure Meta Platforms Inc., London, UK; FAIR Meta Platforms Inc., Menlo Park, CA, USA; School of Computing KAIST, Daejeon, Korea; Department of Informatics, King's College London, London, UK","2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE)","4 Mar 2024","2023","","","31","53","This paper provides a survey of the emerging area of Large Language Models (LLMs) for Software Engineering (SE). It also sets out open research challenges for the application of LLMs to technical problems faced by software engineers. LLMs' emergent properties bring novelty and creativity with applications right across the spectrum of Software Engineering activities including coding, design, requirements, repair, refactoring, performance improvement, documentation and analytics. However, these very same emergent properties also pose significant technical challenges; we need techniques that can reliably weed out incorrect solutions, such as hallucinations. Our survey reveals the pivotal role that hybrid techniques (traditional SE plus LLMs) have to play in the development and deployment of reliable, efficient and effective LLM-based SE.","","979-8-3503-2496-9","10.1109/ICSE-FoSE59343.2023.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10449667","Automated Program Repair;Documentation generation;Generative AI;Genetic Improvement;Human-Computer Interaction;Large Language Models;Refactoring;Requirements engineering;Search Based Software Engineering (SBSE);Software Analytics;Software Engineering Education;Software Processes;Software Maintenance and Evolution;Software Testing","Surveys;Maintenance engineering;Reliability engineering;Software;Software reliability;Software engineering;Testing","","12","","236","IEEE","4 Mar 2024","","","IEEE","IEEE Conferences"
"Embodied Intelligence in Mining: Leveraging Multi-modal Large Language Model for Autonomous Driving in Mines","L. Li; Y. Li; X. Zhang; Y. He; J. Yang; B. Tian; Y. Ai; L. Li; A. Nüchter; Z. Xuanyuan","Faculty of Science and Technology, BNU-HKBU United International College, Zhuhai, China; Faculty of Science and Technology, BNU-HKBU United International College, Zhuhai, China; Institution of Automation, Chinese Academy of Sciences, Beijing, China; University of Oxford, Oxford, U.K.; China University of Mining and Technology (Beijing), Beijing, China; Institution of Automation, Chinese Academy of Sciences, Beijing, China; Institution of Automation, Chinese Academy of Sciences, Beijing, China; Purdue University, West Lafayette, IN, USA; Würzburg University, Würzburg, Germany; BNU-HKBU United International College, Zhuhai, Guangdong Provincial Key Laboratory of Interdisciplinary Research and Application for Data Science, China","IEEE Transactions on Intelligent Vehicles","","2024","PP","99","1","4","With computer technology advancing in both software and hardware, the benefits of embodied intelligence are becoming increasingly evident. This robust interactive learning model enables artificial intelligence (AI) to be more flexibly deployed across diverse fields. In recent years, the development of multi-modal large language models (LLMs) has further accelerated the progress of AI, prompting extensive research on how to leverage these advancements to enhance the field of autonomous driving. This perspective believes that embodied intelligence can significantly enhance the application of LLMs, analyzing the new opportunities brought to the mining industry, and emphasizing the potential of their integration to revolutionize various aspects of the field. Meanwhile, This perspective also examines the challenges of deploying embodied agents in mining, while emphasizing their promising future and offering insights into potential research and development avenues.","2379-8904","","10.1109/TIV.2024.3417938","Guangdong Provincial Key Laboratory of Interdisciplinary Research and Application for Data Science, BNU-HKBU United International College(grant numbers:2022B1212010006); Guangdong Higher Education Upgrading Plan with UIC research(grant numbers:R0400001-22,R201902); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10569079","Embodied intelligence;large language model;intelligent mining","Autonomous vehicles;Artificial intelligence;Task analysis;Data mining;Navigation;Visualization;Cognition","","","","","IEEE","24 Jun 2024","","","IEEE","IEEE Early Access Articles"
"Exploring the Potential of Large Language Models to Generate Formative Programming Feedback","N. Kiesler; D. Lohr; H. Keuning","Information Center Education, DIPF Leibniz Institute for Research and Information in Education, Frankfurt am Main, Germany; Computer Science Education, Friedrich-Alexander-University, Erlangen, Germany; Information and Computing Sciences, Utrecht University, Utrecht, The Netherlands","2023 IEEE Frontiers in Education Conference (FIE)","5 Jan 2024","2023","","","1","5","Ever since the emergence of large language models (LLMs) and related applications, such as ChatGPT, its performance and error analysis for programming tasks have been subject to research. In this work-in-progress paper, we explore the potential of such LLMs for computing educators and learners, as we analyze the feedback it generates to a given input containing program code. In particular, we aim at (1) exploring how an LLM like ChatGPT responds to students seeking help with their introductory programming tasks, and (2) identifying feedback types in its responses. To achieve these goals, we used students' programming sequences from a dataset gathered within a CS1 course as input for ChatGPT along with questions required to elicit feedback and correct solutions. The results show that ChatGPT performs reasonably well for some of the introductory programming tasks and student errors, which means that students can potentially benefit. However, educators should provide guidance on how to use the provided feedback, as it can contain misleading information for novices.","2377-634X","979-8-3503-3642-9","10.1109/FIE58773.2023.10343457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343457","ChatGPT;large language models;feedback;feedback types;introductory programming","Analytical models;Codes;Error analysis;Computational modeling;Chatbots;Task analysis;Programming profession","","1","","27","IEEE","5 Jan 2024","","","IEEE","IEEE Conferences"
"Detection of AI-Generated Text Using Large Language Model","M. Prajapati; S. K. Baliarsingh; C. Dora; A. Bhoi; J. Hota; J. P. Mohanty","School of Computer Engineering, KIIT Deemed to be University, Bhubaneswar, India; School of Computer Engineering, KIIT Deemed to be University, Bhubaneswar, India; Department of Electronics & Communication Engineering, Centurion University of Technology and Management, Bhubaneswar, India; Department of Computer Science & Engineering, GITAM Deemed to be University, Visakhapatnam, India; School of Computer Engineering, KIIT Deemed to be University, Bhubaneswar, India; School of Computer Engineering, KIIT Deemed to be University, Bhubaneswar, India","2024 International Conference on Emerging Systems and Intelligent Computing (ESIC)","1 Apr 2024","2024","","","735","740","A large language model (LLM) is a trained deep-learning model that understands and generates text in a human-like fashion. Due to the significant advancements of LLM, it becomes a challenging task to distinguish human-written content from artificial intelligence (AI) generated content. In this work, we leverage the machine learning (ML) models to reliably identify whether an essay is authored by a human being or by an LLM. Concerns about LLMs replacing human tasks, especially in education persist. However, optimism remains for their potential as tools to enhance writing skills. An academic worry is LLMs facilitating plagiarism due to their extensive training in text and code datasets. Using diverse texts and unknown generative models, we replicate typical scenarios to encourage feature learning across models. In a study involving human subjects, we demonstrate that the annotation scheme offered by generative textual likelihood ratio (GLTR) enhances the human detection rate of fake text from 74% to 99% without requiring any previous training. GLTR is open source and publicly deployed, already finding widespread use in detecting generated outputs.","","979-8-3503-4985-6","10.1109/ESIC60604.2024.10481602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10481602","LLM;AI;Machine Learning;ChatGPT;text detection","Training;Representation learning;Generative AI;Current measurement;Plagiarism;Text detection;Writing","","1","","18","IEEE","1 Apr 2024","","","IEEE","IEEE Conferences"
"Prompt-Enhanced Software Vulnerability Detection Using ChatGPT","C. Zhang; H. Liu; J. Zeng; K. Yang; Y. Li; H. Li","Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, School of Informatics, Xiamen University, China; Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, School of Informatics, Xiamen University, China; Alibaba, China; Alibaba, China; Alibaba, China; Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, School of Informatics, Xiamen University, China","2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)","20 Jun 2024","2024","","","276","277","With the increase in software vulnerabilities that cause significant economic and social losses, automatic vulnerability detection has become essential in software development and maintenance. Recently, large language models (LLMs) have received considerable attention due to their stunning intelligence, and some studies consider using ChatGPT for vulnerability detection. However, they do not fully consider the characteristics of LLMs, since their designed questions to ChatGPT are simple without a prompt design tailored for vulnerability detection. This paper launches a study on the performance of software vulnerability detection using ChatGPT with different prompt designs. Firstly, we complement previous work by applying various improvements to the basic prompt. Moreover, we incorporate structural and sequential auxiliary information to improve the prompt design. Moreover, we leverage ChatGPT's ability of memorizing multi-round dialogue to design suitable prompts for vulnerability detection. We conduct extensive experiments on two vulnerability datasets to demonstrate the effectiveness of prompt-enhanced vulnerability detection using ChatGPT.","2574-1934","979-8-4007-0502-1","10.1145/3639478.3643065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554843","software vulnerability detection;prompt engineering;large language model;chatgpt","Economics;Chatbots;Software;Maintenance;Security;Task analysis;Software engineering","","","","4","","20 Jun 2024","","","IEEE","IEEE Conferences"
"Students’ Experiences of Using ChatGPT in an Undergraduate Programming Course","P. Haindl; G. Weinberger","Department of Computer Science and Security, St. Pölten University of Applied Sciences, St. Pölten, Austria; Department of Computer Science and Security, St. Pölten University of Applied Sciences, St. Pölten, Austria","IEEE Access","28 Mar 2024","2024","12","","43519","43529","Increasing use of artificial intelligence tools in programming education calls for a deeper understanding of their effect on students’ learning. This paper presents a study that investigates the experiences of part-time undergraduate students using ChatGPT in a five-week Java programming course. After each exercise, students provided feedback via anonymous surveys in which they rated different suitability aspects of ChatGPT. The majority viewed ChatGPT positively and suitable for learning programming concepts. However, its suitability for specific implementation tasks received mixed reviews. Students found it easy to adapt ChatGPT’s generated code to the exercises’ implementation tasks. The students primarily used it for acquiring background knowledge, learning syntax and programming concepts and suggesting suitable algorithms. Yet, some abstained from using it due to concerns to not garner sufficient programming proficiency, retrieving partially incorrect or misleading generated code, preferring an independent working style, or general skepticism about its benefits. Finally, in response to our findings, we also discuss three perspective directions for improving the suitability of LLM chatbots for students in programming education.","2169-3536","","10.1109/ACCESS.2024.3380909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478015","Programming education;ChatGPT;generative AI;large language models","Chatbots;Codes;Programming profession;Task analysis;Education;Artificial intelligence;Surveys","","","","32","CCBY","22 Mar 2024","","","IEEE","IEEE Journals"
"On ChatGPT: Perspectives from Software Engineering Students","K. Hanifi; O. Cetin; C. Yilmaz","Ericsson Research Turkey, Istanbul, Turkey; Sabanci University, Istanbul, Turkey; Sabanci University, Istanbul, Turkey","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)","25 Dec 2023","2023","","","196","205","ChatGPT, an increasingly popular Large Language Model (LLM), has found widespread acceptance, especially among the younger generation, who rely on it for various tasks, such as comprehending complex course materials and tackling homework assignments. This surge in interest has drawn the attention of researchers, leading to numerous studies that delve into the advantages and disadvantages of the upcoming LLM dominant era. In our research, we explore the influence of ChatGPT and similar models on the field of software engineering, specifically from the perspective of software engineering students. Our main objective is to gain valuable insights into their usage habits and opinions through a comprehensive survey. The survey encompassed diverse questions, addressing the specific areas where ChatGPT was utilized for assistance and gathering students’ reflections on each aspect. We found that ChatGPT has garnered widespread acceptance among software engineering students, with 93% of them utilizing it for their projects. These students expressed satisfaction with the level of assistance provided, and most intend to continue using it as a valuable tool in their work. During our investigation, we also assessed the students’ awareness of the underlying technologies behind ChatGPT. Approximately half of the students demonstrated awareness of these technologies, while 38.7% had made extra efforts to explore prompt engineering to enhance ChatGPT’s productivity. However, an important finding was that 90.6% of the students reported experiencing hallucinations during their interactions with ChatGPT. These hallucinations were shared as examples, raising significant concerns that warrant further exploration and mitigation. Moreover, we delved into potential improvements and gathered valuable recommendations, which could help ChatGPT to become even more effective and dependable in its applications.","2693-9177","979-8-3503-1958-3","10.1109/QRS60937.2023.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366692","ChatGPT;software engineering;academic education;generative AI;Large Language Models","Surveys;Software quality;Chatbots;Reliability engineering;Reflection;Software reliability;Security","","","","29","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"Automated Program Repair for Introductory Programming Assignments","H. Wan; H. Luo; M. Li; X. Luo","State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China","IEEE Transactions on Learning Technologies","11 Jun 2024","2024","17","","1745","1760","Automatic program repair (APR) tools are valuable for students to assist them with debugging tasks since program repair captures the code modification to make a buggy program pass the given test-suite. However, the process of manually generating catalogs of code modifications is intricate and time-consuming. This article proposes contextual error model repair (CEMR), an automated program repair tool for introductory programming assignments. CEMR is designed to learn program code modifications from incorrect–correct code pairs automatically. Then, it utilizes these code modifications along with CodeBERT, a generative AI, to repair students' new incorrect programs in the same programming assignment. CEMR builds on the observation that code edits performed by students in pairs of incorrect–correct code can be used as input–output examples for learning code modifications. The key idea of CEMR is to leverage the wisdom of the crowd: it uses the existing code modifications of incorrect–correct student code pairs to repair the new incorrect student attempts. We chose three of the most related APR tools, Refazer, Refactory, and AlphaRepair, as the baselines to compare against CEMR. The experimental results demonstrate that, on public and real classroom datasets, CEMR achieves higher repair rates than the baselines. Through further analysis, CEMR has demonstrated promising effectiveness in addressing semantical and logical errors while its performance in fixing syntactical errors is limited. In terms of time for repairing buggy programs, CEMR costs approximately half as much as AlphaRepair requires. We opine that CEMR not only be seen as a program repair method that achieves good results with incorrect–correct code pairs but also be further utilized to generate hints to better assist students in learning programming.","1939-1382","","10.1109/TLT.2024.3403710","National Natural Science Foundation of China(grant numbers:61907002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10535720","Large language model;program repair;programming education","Codes;Maintenance engineering;Programming profession;Context modeling;Syntactics;Computer bugs;Problem-solving","","","","44","IEEE","21 May 2024","","","IEEE","IEEE Journals"
"A Deep Understanding Video Q&A System for Film Education in Acting Department","Z. Wu; R. Li; J. Guo; Z. Wang; C. Liang",Hubei Key Laboratory of Multimedia and Network Communication Engineering; Hubei Key Laboratory of Multimedia and Network Communication Engineering; Hubei Key Laboratory of Multimedia and Network Communication Engineering; Hubei Key Laboratory of Multimedia and Network Communication Engineering; Hubei Key Laboratory of Multimedia and Network Communication Engineering,"2023 International Conference on Intelligent Education and Intelligent Research (IEIR)","16 Jan 2024","2023","","","1","7","Recently, advancements in artificial intelligence technology have greatly influenced the field of education, particularly in the area of intelligent homework assistance. However, current approaches are primarily designed for procedural and logical tasks and often lack comprehension abilities. This limitation is particularly evident when it comes to multi-hop and continuous tasks. To address this challenge, the integration of Large Language Model (LLM) has significantly enhanced the capability of AI systems to handle multi-hop and highly interconnected inputs. In this study, we focus on the learning needs of students in Acting Department, specifically their study of movies and the significance of classic movie videos in their learning process. However, assessing deep comprehension of classic movies poses its own challenges. To overcome these challenges, we develop a quiz system utilizing Knowledge Graphs (KG) and LLM to facilitate a deeper understanding of classic films. The generation of video quiz pairs is achieved through the use of Automatic Speech Recognition (ASR) technology, which leverages movie subtitles for question generation. For answering these questions, we employ techniques KG and LLM to process questions and retrieve corresponding answers. The proposed method achieves good performance in Deep Video Understanding (DVU) task of NIST TRECVID, demonstrating its effectiveness.","","979-8-3503-4289-5","10.1109/IEIR59294.2023.10391232","National Natural Science Foundation of China; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10391232","video understanding;Large Language Model;artificial intelligence","Films;Education;Knowledge graphs;NIST;Motion pictures;Task analysis;Artificial intelligence","","","","27","IEEE","16 Jan 2024","","","IEEE","IEEE Conferences"
"ChatPapers: An AI Chatbot for Interacting with Academic Research","M. Dean; R. R. Bond; M. F. McTear; M. D. Mulvenna","School of Computing, Ulster University, Belfast, Northern Ireland; School of Computing, Ulster University, Belfast, Northern Ireland; School of Computing, Ulster University, Belfast, Northern Ireland; School of Computing, Ulster University, Belfast, Northern Ireland","2023 31st Irish Conference on Artificial Intelligence and Cognitive Science (AICS)","20 Mar 2024","2023","","","1","7","A growing and significant number of computer science related papers are being published; hence it is challenging to keep up with the latest research. This paper describes the development of a large language model (LLM) augmentation chatbot and user interface that provides responses to research queries in the domain of computer science. Around 200,000 computer science research papers from arXiv were embedded, resulting in ~11 million vectors (based on ‘chunks’ from the papers). Each vector is comprised of 384 numbers/dimensions. Technologies used include Langchain, a Vector Database, and Semantic Searching with document / query embeddings. The chatbot was tested using 30 sample questions that could be asked by computer science students across several topics and from different education levels (i.e., BSc, MSc and PhD level). The responses from this chatbot were compared with those from GPT-4. The responses with and without prompting were also compared. Readability metrics (Flesch-Kincaid and Coleman-Liau) were used to compare the responses from this LLM with GPT-4. Retrieval Augmented Generation Assessment (RAGAS), a novel LLM self-evaluation method was used to evaluate the system. We observed that the developed system provides more suitable responses to the user based on the readability level at which the questions were asked.","","979-8-3503-6021-9","10.1109/AICS60730.2023.10470521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10470521","large language model;chatbot;retrieval augmented generation;Langchain;vector database;semantic search;GPT-4;Retrieval Augmented Generation Assessment;Readability metrics;Flesch-Kincaid;Coleman-Liau","Computer science;Databases;Semantics;Knowledge based systems;Education;User interfaces;Chatbots","","","","12","IEEE","20 Mar 2024","","","IEEE","IEEE Conferences"
"Analysis of Plagiarism via ChatGPT on Domain-Specific Exams","J. Jo; S. Choi","University of California, Los Angeles; Santa Clara University","2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)","9 Apr 2024","2023","","","1026","1033","This work presents a case study, linguistic analysis and potential prevention methods on the use of large language models (LLM) for generating solutions for exams on cloud computing course that require domain-specific knowledge. The study involves analyzing the responses of three groups of students: a group who used ChatGPT to plagiarize solutions, another group who referred to external non-LLM resources (e.g., web search) to plagiarize solutions, a control group who generated solutions without any external assistance. Results show that solutions from groups that participated in plagiarism tend to be lengthy, use uncommon words, and are similar to each other compared to human-generated solutions. This study not only shows that it is possible to generate legitimate solutions for exams that require extensive domain-specific knowledge using ChatGPT, but also shows some potential signals one can use to detect plagiarism, thus providing potential of promoting academic integrity by curbing unethical use of AI in academic settings.","","979-8-3503-2759-5","10.1109/CSCE60160.2023.00171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487540","Large Language Model;Academic Integrity;Computer Science Education;Plagiarism Detection","Cloud computing;Plagiarism;Computational modeling;Linguistics;Chatbots;Computer science education;Web search","","","","34","IEEE","9 Apr 2024","","","IEEE","IEEE Conferences"
"Refactoring Programs Using Large Language Models with Few-Shot Examples","A. Shirafuji; Y. Oda; J. Suzuki; M. Morishita; Y. Watanobe","University of Aizu, Japan; Tohoku University, Japan; Tohoku University, Japan; NTT Communication Science Laboratories, Japan; University of Aizu, Japan","2023 30th Asia-Pacific Software Engineering Conference (APSEC)","2 Apr 2024","2023","","","151","160","A less complex and more straightforward program is a crucial factor that enhances its maintainability and makes writing secure and bug-free programs easier. However, due to its heavy workload and the risks of breaking the working programs, programmers are reluctant to do code refactoring, and thus, it also causes the loss of potential learning experiences. To mitigate this, we demonstrate the application of using a large language model (LLM), GPT-3.5, to suggest less complex versions of the user-written Python program, aiming to encourage users to learn how to write better programs. We propose a method to leverage the prompting with few-shot examples of the LLM by selecting the best-suited code refactoring examples for each target programming problem based on the prior evaluation of prompting with the one-shot example. The quantitative evaluation shows that 95.68% of programs can be refactored by generating 10 candidates each, resulting in a 17.35% reduction in the average cyclomatic complexity and a 25.84% decrease in the average number of lines after filtering only generated programs that are semantically correct. Further-more, the qualitative evaluation shows outstanding capability in code formatting, while unnecessary behaviors such as deleting or translating comments are also observed.","2640-0715","979-8-3503-4417-2","10.1109/APSEC60848.2023.00025","Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP23H03508); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479398","code refactoring;large language models;few-shot prompting;software complexity;programming education","Measurement;Codes;Filtering;Education;Writing;Programming;Complexity theory","","1","","48","IEEE","2 Apr 2024","","","IEEE","IEEE Conferences"
"The Rise of Generative Artificial Intelligence in Healthcare","M. Kuzlu; Z. Xiao; S. Sarp; F. O. Catak; N. Gurler; O. Guler","Electrical Engineering Technology, Old Dominion University, Norfolk, VA, USA; Computational Operations Research, The College of William and Mary, Williamsburg, VA, USA; Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, VA, USA; Department of Electrical Engineering and Computer Science, University of Stavanger, Rogaland, Norway; eKare, Inc., Fairfax, VA, USA; eKare, Inc., Fairfax, VA, USA","2023 12th Mediterranean Conference on Embedded Computing (MECO)","26 Jun 2023","2023","","","1","4","Generative Artificial Intelligence (GAI) is transforming various fields, including finance, education, marketing, and healthcare. Especially in healthcare, GAI has the potential to revolutionize various aspects, such as medical imaging, drug development, patient care, and treatment planning. Key stakeholders who stand to benefit from these advancements include hospitals, clinics, pharmaceutical companies, medical device manufacturers, and research institutions. However, the implementation of GAI in healthcare presents several challenges, such as ensuring data privacy and security, addressing ethical considerations, maintaining quality and accuracy, adhering to regulatory compliance, and integrating with existing systems. This paper examines the current state of GAI in healthcare, discusses its potential benefits and challenges, and highlights future directions that must be addressed to fully harness the power of GAI in improving patient outcomes and healthcare systems.","2637-9511","979-8-3503-2291-0","10.1109/MECO58584.2023.10155107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155107","Generative AI (GAI);Large Language Model (LLM);Generative Pre-trained Transformer (GPT);AI in Healthcare","Ethics;Data privacy;Medical devices;Hospitals;Medical services;Companies;Transformers","","6","","15","IEEE","26 Jun 2023","","","IEEE","IEEE Conferences"
"Automated Repair of Programs from Large Language Models","Z. Fan; X. Gao; M. Mirchev; A. Roychoudhury; S. H. Tan","National University of Singapore, Singapore; Beihang University, Beijing, China; National University of Singapore, Singapore; National University of Singapore, Singapore; Southern University of Science and Technology, Shenzhen, China","2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)","14 Jul 2023","2023","","","1469","1481","Large language models such as Codex, have shown the capability to produce code for many programming tasks. However, the success rate of existing models is low, especially for complex programming tasks. One of the reasons is that language models lack awareness of program semantics, resulting in incorrect programs, or even programs which do not compile. In this paper, we systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests. The goal is to study whether APR techniques can enhance reliability in the code produced by large language models. Our study revealed that: (1) automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to fix auto-generated code; (2) given bug location information provided by a statistical fault localization approach, the newly released Codex edit mode, which supports editing code, is similar to or better than existing Java repair tools TBar and Recoder in fixing incorrect solutions. By analyzing the experimental results generated by these tools, we provide several suggestions: (1) enhancing APR tools to surpass limitations in patch space (e.g., introducing more flexible fault localization) is desirable; (2) as large language models can derive more fix patterns by training on more data, future APR tools could shift focus from adding more fix patterns to synthesis/semantics based approaches, (3) combination of language models with APR to curate patch ingredients, is worth studying.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172854","Large Language Model;Program Repair","Location awareness;Training;Analytical models;Codes;Semantics;Maintenance engineering;Programming","","25","","53","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas","J. Barambones; C. Moral; A. de Antonio; R. Imbert; L. Martínez-Normand; E. Villalba-Mora","Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain; Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain; Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain; Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain; Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain; Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain","IEEE Transactions on Learning Technologies","30 Apr 2024","2024","17","","1486","1501","Before interacting with real users, developers must be proficient in human–computer interaction (HCI) so as not to exhaust user patience and availability. For that, substantial training and practice are required, but it is costly to create a variety of high-quality HCI training materials. In this context, chat generative pretrained transformer (ChatGPT) and other chatbots based on large language models (LLMs) offer an opportunity to generate training materials of acceptable quality without foregoing specific human characteristics present in real-world scenarios. Personas is a user-centered design method that encompasses fictitious but believable user archetypes to help designers understand and empathize with their target audience during product design. We conducted an exploratory study on the Personas technique, addressing the validity and believability of interviews designed by HCI trainers and answered by ChatGPT-simulated users, which can be used as training material for persona creation. Specifically, we employed ChatGPT to respond to interviews designed by user experience (UX) experts. Two groups, HCI professors and professionals, then evaluated the validity of the generated materials considering quality, usefulness, UX, and ethics. The results show that both groups rated the interviews as believable and helpful for Personas training. However, some concerns about response repetition and low response variability suggested the need for further research on improved prompt design in order to generate more diverse and well-developed responses. The findings of this study provide insight into how HCI trainers can use ChatGPT to help their students master persona creation skills before working with real users in real-world scenarios for the first time.","1939-1382","","10.1109/TLT.2024.3386095","Universidad Politécnica de Madrid(grant numbers:RP2210470068); CIBER—Consorcio Centro de Investigación Biomédica en Red; Instituto de Salud Carlos III; Ministerio de Ciencia e Innovación(grant numbers:CB06/01/0051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494570","Chatbots;computer science education;human–computer interaction (HCI);large language model (LLM);training;user-centered design","Interviews;Training;Chatbots;Surveys;Ethics;Task analysis;Recruitment","","","","27","CCBY","8 Apr 2024","","","IEEE","IEEE Journals"
"Analysis of ChatGPT Performance in Computer Engineering Exams","R. Rodriguez-Echeverría; J. D. Gutiérrez; J. M. Conejero; Á. E. Prieto","Applied Information Technology Research Institute, Universidad de Extremadura, Cáceres, Spain; Department of Electronics and Computing, Universidad de Santiago de Compostela, Lugo, Spain; Applied Information Technology Research Institute, Universidad de Extremadura, Cáceres, Spain; Applied Information Technology Research Institute, Universidad de Extremadura, Cáceres, Spain","IEEE Revista Iberoamericana de Tecnologias del Aprendizaje","13 May 2024","2024","19","","71","80","The appearance of ChatGPT at the end of 2022 was a milestone in the field of Generative Artificial Intelligence. However, it also caused a shock in the academic world. For the first time, a simple interface allowed anyone to access a large language model and use it to generate text. These capabilities have a relevant impact on teaching-learning methodologies and assessment methods. This work aims to obtain an objective measure of ChatGPT’s possible performance in solving exams related to computer engineering. For this purpose, it has been tested with actual exams of 15 subjects of the Software Engineering branch of a Spanish university. All the questions of these exams have been extracted and adapted to a text format to obtain an answer. Furthermore, the exams have been rewritten to be corrected by the teaching staff. In light of the results, ChatGPT can achieve relevant performance in these exams; it can pass many questions and problems of different natures in multiple subjects. A detailed study of the results by typology of questions and problems is provided as a fundamental contribution, allowing recommendations to be considered in the design of assessment methods. In addition, an analysis of the impact of the non-deterministic aspect of ChatGPT on the answers to test questions is presented, and the need to use a strategy to reduce this effect for performance analysis is concluded.","1932-8540","","10.1109/RITA.2024.3381842","Research and Development Project funded by MICIU/AEI/10.13039/501100011033(grant numbers:ID2021-127412OB-I00); FEDER/UE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478897","Artificial intelligence;ChatGPT;education;experiment","Chatbots;Education;Artificial intelligence;Guidelines;Oral communication;Computational modeling;Codes","","","","23","IEEE","25 Mar 2024","","","IEEE","IEEE Journals"
"Engineering, the Profession in Trouble: Lack of Programme Development Standards That Support the AI Chatbot? A System View","M. Tsoeu; R. Maladzi; N. Mthombeni; K. Moloi; T. Mashifana; F. Nemavhola","Electronic and Computer Engineering, Durban University of Technology, Durban, South Africa; Mechanical Engineering, Durban University of Technology, Durban, South Africa; Chemical Engineering, Durban University of Technology, Durban, South Africa; Electrical Power Engineering, Durban University of Technology, Durban, South Africa; Chemical Engineering, University of Johannesburg, Johannesburg, South Africa; Mechanical Engineering, Durban University of Technology, Durban, South Africa","2023 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC)","12 Dec 2023","2023","","","1","6","As the world embraces the transformative potential of artificial intelligence (AI), large language models (LLM), and conversational agents also known as chatbots, the engineering profession stands at a crucial juncture. This paper critically examines the current state of engineering education and its readiness to incorporate AI chatbots effectively. Focusing on the lack of standardized programme development that supports AI chatbots, this paper sheds light on the implications of this gap for engineering education. Standardization is defined as the degree to which educational programmes meet common national and international quality standards. By synthesizing existing literature, this study investigates the challenges, opportunities, and strategies required to bridge this divide and ensure that engineering programmes are adequately equipped to produce graduates who can harness the power of AI chatbots. We found that strong and continuing trends are emerging in the use of AI and chatbots in engineering education and industry. We further noted that current standards from accreditation bodies need to respond to enable AI and chatbot incorporation from curriculum to pedagogical levels of engineering education. Industry-academia partnerships are vital in managing the integration of AI into engineering education.","2837-5025","979-8-3503-1602-5","10.1109/WEEF-GEDC59520.2023.10343985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343985","AI;chatbots;artificial intelligence;education;standards;programmes;development;curricula;accreditation","Knowledge engineering;Industries;Navigation;Focusing;Chatbots;Market research;Accreditation","","","","31","IEEE","12 Dec 2023","","","IEEE","IEEE Conferences"
"Transforming Software Requirements into User Stories with GPT-3.5 -: An AI-Powered Approach","J. U. Oswal; H. T. Kanakia; D. Suktel","Master of Computer Application Department, Sardar Patel Institute of Technology, Mumbai, India; Master of Computer Application Department, Sardar Patel Institute of Technology, Mumbai, India; Master of Computer Application Department, Sardar Patel Institute of Technology, Mumbai, India","2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)","22 Mar 2024","2024","","","913","920","In today's dynamic software development landscape, Agile methodologies have established themselves as essential for organizations striving to swiftly adapt to evolving customer needs and market demands. A cornerstone of the Agile framework is the concept of User Stories, a concise format for expressing software requirements from an end-user perspective. The manual generation of User Stories from unstructured requirement texts proves to be a labor-intensive endeavor, riddled with challenges related to maintaining consistency and adhering to specific organizational practices. This research underscores the profound importance of Agile Methodology in contemporary software development and underscores the critical role that User Stories play within this framework. To address the inherent inefficiencies associated with manual User Story creation, this paper introduces a novel and innovative AI-powered approach that uses the advanced capabilities of the GPT-3.5 language model. This approach facilitates a seamless and efficient transformation of software requirement text into standardized User Stories by studying various prompting techniques. In this research paper the practical implementation of our approach have been illustrated, we have developed an application harnessing the natural language processing capabilities of GPT-3.5 where in the user can enter or upload the requirement text and it will be transformed into user stories.","","979-8-3503-2753-3","10.1109/IDCIoT59759.2024.10467750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467750","Agile;User Story;Generative Pre-Trained Transformers;Data Mining;Large Language Model;Natural Language Processing;Prompt Engineering;Few Shot Prompting;Software Requirements","Standards organizations;Education;Organizations;Manuals;Transformers;Software;Data models","","1","","19","IEEE","22 Mar 2024","","","IEEE","IEEE Conferences"
"UnstrPrompt: Large Language Model Prompt for Driving in Unstructured Scenarios","Y. Li; L. Li; Z. Wu; Z. Bing; Z. Xuanyuan; A. C. Knoll; L. Chen","Faculty of Science and Technology, BNU-HKBU United International College, Zhuhai, China; Faculty of Science and Technology, BNU-HKBU United International College, Zhuhai, China; Institute of Science and Technology for Brain-Inspired Intelligence, Fudan University, Shanghai, China; Department of Informatics, Computer Science, Technische Universität München, Munich, Germany; Faculty of Science and Technology, BNU-HKBU United International College, Zhuhai, China; Department of Informatics, Computer Science, Technische Universität München, Munich, Germany; WAYTOUS Inc., Beijing, China","IEEE Journal of Radio Frequency Identification","14 May 2024","2024","8","","367","375","The integration of language descriptions or prompts with Large Language Models (LLMs) into visual tasks is currently a focal point in the advancement of autonomous driving. This study has showcased notable advancements across various standard datasets. Nevertheless, the progress in integrating language prompts faces challenges in unstructured scenarios, primarily due to the limited availability of paired data. To address this challenge, we introduce a groundbreaking language prompt set called “UnstrPrompt.” This prompt set is derived from three prominent unstructured autonomous driving datasets: IDD, ORFD, and AutoMine, collectively comprising a total of 6K language descriptions. In response to the distinctive features of unstructured scenarios, we have developed a structured approach for prompt generation, encompassing three key components: scene, road, and instance. Additionally, we provide a detailed overview of the language generation process and the validation procedures. We conduct tests on segmentation tasks, and our experiments have demonstrated that text-image fusion can improve accuracy by more than 3% on unstructured data. Additionally, our description architecture outperforms the generic urban architecture by more than 0.1%. This work holds the potential to advance various aspects such as interaction and foundational models in this scenario.","2469-7281","","10.1109/JRFID.2024.3367975","National Key Research and Development Program of China(grant numbers:2022YFB4703700); National Natural Science Foundation of China(grant numbers:62373356); Guangdong Provincial Key Laboratory of Interdisciplinary Research and Application for Data Science, BNU-HKBU United International College(grant numbers:2022B1212010006); Guangdong Higher Education Upgrading Plan with UIC Research(grant numbers:R0400001-22,R201902); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440443","Large language model;unstructured scenarios;segmentation;UnstrPrompt","Task analysis;Visualization;Roads;Autonomous vehicles;Radiofrequency identification;Object detection;Computational modeling","","2","","65","IEEE","20 Feb 2024","","","IEEE","IEEE Journals"
"Using ChatGPT for Homework: Does it Feel Like Cheating? (WIP)","C. R. Bego","Department of Engineering Fundamentals, J. B. Speed School of Engineering, University of Louisville","2023 IEEE Frontiers in Education Conference (FIE)","5 Jan 2024","2023","","","1","4","This WIP paper disseminates the results of an anonymous survey given to first-year engineering students in February of 2023 about ChatGPT, the recently-developed artificial intelligence chatbot. Survey results showed that some engineering students had used ChatGPT to complete their homework assignments. Furthermore, only a few of those who used it for homework felt like they were “cheating,” or acting unethically, by doing so. These results indicate that the higher education community should carefully consider the potential learning benefits and threats of this new tool, as it may be utilized by at least some portion of students on their assignments. Much more work is needed to understand the potential uses, threats, and limitations of large language model chatbots in engineering education.","2377-634X","979-8-3503-3642-9","10.1109/FIE58773.2023.10343397","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343397","AI;ChatGPT;ethics;engineering education","Surveys;Chatbots;Engineering students;Artificial intelligence","","","","7","IEEE","5 Jan 2024","","","IEEE","IEEE Conferences"
"Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse","S. Lee; D. Jung; C. Park; S. Lee; H. Lim","Computer Science and Engineering, Korea University, Seoul, Korea; Computer Science and Engineering, Korea University, Seoul, Korea; Large Language Model Team Upstage, Gyeonggi-do, Korea; Computer Science Technical, University of Darmstadt, Darmstadt, Germany; Computer Science and Engineering, Korea University, Seoul, Korea","2023 IEEE International Conference on Data Mining Workshops (ICDMW)","6 Feb 2024","2023","","","1438","1442","Warning: This paper contains examples of stereotypes that may be offensive or upsetting.We introduce the concept of ""Alternative Speech"" as a new way to directly combat hate speech and complement the limitations of counter-narrative. An alternative speech provides practical alternatives to hate speech in real-world scenarios by offering speech-level corrections to speakers while considering the surrounding context and promoting speakers to reform. Further, an alternative speech can combat hate speech alongside counter-narratives, offering a useful tool to address social issues such as racial discrimination and gender inequality. We propose the new concept and provide detailed guidelines for constructing the necessary dataset. Through discussion, we demonstrate that combining alternative speech and counter-narrative can be a more effective strategy for combating hate speech by complementing specificity and guiding capacity of counter-narrative. This paper presents another perspective for dealing with hate speech, offering viable remedies to complement the constraints of current approaches to mitigating harmful bias.","2375-9259","979-8-3503-8164-1","10.1109/ICDMW60847.2023.00183","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10411543","Hate Speech;Social Bias;Counter-Narrative","Conferences;Hate speech;Diversity reception;Speech enhancement;Data mining;Cultural differences;Guidelines","","","","19","IEEE","6 Feb 2024","","","IEEE","IEEE Conferences"
"Affective Computing: A Topic-Based SER Approach on Collaborative Discussions in Academic Setting","N. Dehbozorgi; M. T. Kunuku","Department of Software Engineering, Kennesaw State University, Marietta, GA, USA; Department of Computer Science, Kennesaw State University, Marietta, GA, USA","2023 IEEE Frontiers in Education Conference (FIE)","5 Jan 2024","2023","","","1","7","One of the biggest concerns in the modern day especially in the educational domain centers on the student's mental health. High rates of anxiety and depression have especially brought the attention of researchers in engineering education to apply affective computing to help with students' academic performance. It is known that a person's emotional states cause physiological and physical changes in the body. Emotions may impact facial expression, tone of speech, blood pressure, pulse, etc. Since visual and auditory signals are two variables that can be measured without the need to attach any physical device to the individuals, they are most studied in this field. Speech in particular has been known as a means that transfers much information about the mental and emotional states of the person. Speech Emotion Recognition (SER) is a growing field that has been applied in several domains including engineering education. Recent advancements in AI, Natural Language Understanding (NLU), and Large Language Models (LLM) have significantly streamlined this line of research. In this work which is a continuation of our prior work, we propose a speech analysis model that extracts both the emotions and topics from verbal discussions in a computer science classroom to understand if the expressed emotions were mostly about the course related topics or not. The goal of this research is to develop a tool that helps educators gain insights into the students' emotional states in teamwork and also understand the context of their conversations. We further analyze if the expressed emotions in the verbal class discussions are mostly about the course content or other subjects outside class setting. To expand the emotion analysis module we added a new layer to our developed pipeline by passing the speech data into the ChatGPT API to generate summarized scripts and extract additional classes of emotion. The preliminary results from this study are promising, indicating the potential value of this research direction and its prospects for further development. Application of this model in the educational domain can greatly benefit both educators and students and allows the instructors to make necessary interventions needed to maximize students' positive experiences in team settings while considering their emotional states.","2377-634X","979-8-3503-3642-9","10.1109/FIE58773.2023.10342963","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342963","Speech Emotion Recognition (SER);Large Language Models (LLM);NLP;Topic modeling;Affective computing;ChatGPT API;Teamwork;Engineering education","Computer science;Analytical models;Emotion recognition;Affective computing;Computational modeling;Pipelines;Chatbots","","","","15","IEEE","5 Jan 2024","","","IEEE","IEEE Conferences"
"ChatGPT: A Comprehensive Review of a Large Language Model","K. S. Kaswan; J. S. Dhatterwal; R. Batra; D. K. Yadav","School of Computing Science and Engineering, Galgotias University, Greater Noida, UP, India; Artificial Intelligence and Data Science, Koneru Lakshmaiah Education Foundation, Guntur, AP, India; Department of Computer Science and Engineering, SGT University, Gurugram, Haryana, India; SCSET, Bennett University, Greater Noida, UP, India","2023 International Conference on Communication, Security and Artificial Intelligence (ICCSAI)","16 Feb 2024","2023","","","738","743","In the evolving landscape of Natural Language Processing (NLP), the emergence of large language models has redefined the boundaries of human-computer interaction. This paper presents an in-depth review of ChatGPT, a pioneering exemplar in this domain. We commence with a thorough discussion on the evolution of NLP techniques and models, culminating in the inception of ChatGPT. The critical examination of pertinent research papers, projects, and benchmarks showcases the progression of large language models in the context of complex language understanding and generation tasks. The primary focus of this paper is to elucidate the intricate methodology underpinning ChatGPT's architecture and technology. We meticulously outline the comprehensive training process encompassing pretraining and fine-tuning phases, shedding light on the nuanced decisions that bolster model performance. The dataset employed for training and validation is delineated, contributing to an informed understanding of the model's capabilities. The user experience and feedback section encapsulates the empirical perspectives of interacting with ChatGPT, elucidating its strengths and limitations. The paper also prognosticates on the challenges and future directions for ChatGPT. The extant limitations are outlined, and plausible avenues for research and development are suggested to propel the model's potential. In conclusion, this review synthesizes the contributions of ChatGPT in the NLP landscape, underscoring its significance in reshaping the frontiers of language-based human-computer interaction. By amalgamating insights from methodology, applications, ethics, and performance, this paper offers a comprehensive compendium of the evolution and impact of ChatGPT in the realm of NLP research and applications.","","979-8-3503-6996-0","10.1109/ICCSAI59793.2023.10421090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10421090","Natural Language Processing;Large Language Model;ChatGPT;Reinforcement Learning Human Feedback;OpenAI","Training;Ethics;Adaptation models;Chatbots;User experience;Task analysis;Context modeling","","","","23","IEEE","16 Feb 2024","","","IEEE","IEEE Conferences"
"Experience Report: Identifying Common Misconceptions and Errors of Novice Programmers with ChatGPT","H. L. Fwa","Singapore Management University, Singapore","2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)","19 Jun 2024","2024","","","233","241","Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.","2832-7578","979-8-4007-0498-7","10.1145/3639474.3640059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554713","LLM;ChatGPT;misconception;programming;errors;cluster;prompts","Training;Adaptation models;Codes;Manuals;Knowledge representation;Syntactics;Chatbots","","","","24","CCBY","19 Jun 2024","","","IEEE","IEEE Conferences"
"Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data","Y. Feng; S. Vanam; M. Cherukupally; W. Zheng; M. Qiu; H. Chen",University of North Texas; University of North Texas; University of North Texas; Argonne National Laboratory; Dakota State University; University of North Texas,"2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)","2 Aug 2023","2023","","","876","885","The recent advancements in Artificial Intelligence, particularly in large language models and generative models, are reshaping the field of software engineering by enabling innovative ways of performing various tasks, such as programming, debugging, and testing. However, few existing works have thoroughly explored the potential of AI in code generation and users’ attitudes toward AI-assisted coding tools. This knowledge gap leaves it unclear how AI is transforming software engineering and programming education. This paper presents a scalable crowdsourcing data-driven framework to investigate the code generation performance of generative large language models from diverse perspectives across multiple social media platforms. Specifically, we utilize ChatGPT, a popular generative large language model, as a representative example to reveal its insights and patterns in code generation. First, we propose a hybrid keyword word expansion method that integrates words suggested by topic modeling and expert knowledge to filter relevant social posts of interest on Twitter and Reddit. Then we collect 316K tweets and 3.2K Reddit posts about ChatGPT’s code generation, spanning from Dec. 1, 2022 to January 31, 2023. Our data analytics show that ChatGPT has been used in more than 10 programming languages, with Python and JavaScript being the two most popular, for a diverse range of tasks such as code debugging, interview preparation, and academic assignment solving. Surprisingly, our analysis shows that fear is the dominant emotion associated with ChatGPT’s code generation, overshadowing emotions of happiness, anger, surprise, and sadness. Furthermore, we construct a ChatGPT prompt and corresponding code dataset by analyzing the screen-shots of ChatGPT code generation shared on social media. This dataset enables us to evaluate the quality of the generated code, and we have released this dataset to the public. We believe the insights gained from our work will provide valuable guidance for future research on AI-powered code generation.","0730-3157","979-8-3503-2697-0","10.1109/COMPSAC57700.2023.00117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196869","ChatGPT;Coding Generation;Software Engineering;Large Language Models (LLMs);Generative Models;Social Media","Codes;Social networking (online);Debugging;Chatbots;Software;Task analysis;Interviews","","19","","31","IEEE","2 Aug 2023","","","IEEE","IEEE Conferences"
"Spectrogram-Based Deep Learning for Flute Audition Assessment and Intelligent Feedback","M. Agarwal; R. Greer","Herricks High School, New Hyde Park, USA; Department of Electrical & Computer Engineering, University of California San Diego, La Jolla, USA","2023 IEEE International Symposium on Multimedia (ISM)","20 Mar 2024","2023","","","238","242","Performers of classical music require a blend of technical precision and artistic expression in their output, and this fusion, often referred to as “musicality,” is considered vital to performance quality. This paper introduces an innovative approach that leverages deep learning and LLMs to simultaneously evaluate and coach musicians using recorded performances on a variety of performance metrics at varying levels of subjectivity. A case study, centered around flute players performing a challenging excerpt from Ravel’s “Daphnis et Chloé,” demonstrates the proposed model’s capabilities. Feedback is generated by a large-language model based on machine-assessed quality, learned from human judgments. The model showcases promise in bridging the gap between technical precision and human expression in classical music performance assessment and provides a foundation for expanding the repertoire of assessed pieces and advancing the integration of AI in classical music education.","","979-8-3503-9576-1","10.1109/ISM59092.2023.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473475","spectrogram analysis;deep learning in music;quality assessment;feedback systems;artificial intelligence in music education","Deep learning;Measurement;Multimedia systems;Music;Artificial intelligence;Spectrogram","","","","7","IEEE","20 Mar 2024","","","IEEE","IEEE Conferences"
"Let's ask AI About Their Programs: Exploring ChatGPT's Answers to Program Comprehension Questions","T. Lehtinen; C. Koutcheme; A. Hellas","Aalto University, Espoo, Finland; Aalto University, Espoo, Finland; Aalto University, Espoo, Finland","2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)","19 Jun 2024","2024","","","221","232","Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.","2832-7578","979-8-4007-0498-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554757","QLCs;large language models;artificial intelligence;introductory programming;program comprehension","Training;Codes;Storms;Source coding;Writing;Data models;Task analysis","","","","55","","19 Jun 2024","","","IEEE","IEEE Conferences"
"AI and Veterinary Medicine: Performance of Large Language Models on the North American Licensing Examination","M. Angel; A. Patel; H. Xing; D. Balsz; C. Arbuckle; D. Bruyette; P. Baldi","Institute for Geomics and Bioinformatics, University of California Irvine, Irvine, USA; Department of Computer Science, University of California Irvine, Irvine, USA; Department of Computer Science, University of California Irvine, Irvine, USA; Internal Medicine, Anivive Life Sciences, Long Beach, USA; Internal Medicine, Anivive Life Sciences, Long Beach, USA; Internal Medicine, Anivive Life Sciences, Long Beach, USA; Department of Computer Science, University of California Irvine, Irvine, USA","2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS)","2 Jan 2024","2023","","","1","4","This study aimed to assess the performance of Large Language Models on the North American Veterinary Licensing Examination (NAVLE) and to analyze the impact of artificial intelligence in the domain of animal healthcare. For this study, a 200-question NAVLE self-assessment sourced from ICVA's website was used to evaluate the performance of three language models: GPT-3, GPT-4, and Bard. Questions involving images were omitted leaving a 164 text-only sample exam. Results were analyzed by comparing generated responses to the answer key, and scores were assigned to evaluate the models' veterinary medical reasoning capabilities. Our results showed that GPT-4 outperformed GPT-3 and Bard, passing the exam with 89 % of the text-only questions correctly. GPT-3 and Bard only achieved an accuracy of 63.4 % and 61 % respectively on the same set of questions. Language models hold promise for enhancing veterinary practices through expanded educational opportunities in the veterinary curriculum, improved diagnostic accuracy, treatment times, and efficiency. However, potential negatives include challenges in changing the current educational paradigm, reduced demand for professionals or paraprofessional concerns surrounding machine-generated decisions. Responsible and ethical integration of language models is crucial in veterinary medicine.","2831-7343","979-8-3503-1890-6","10.1109/SNAMS60348.2023.10375414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10375414","Artificial Intelligence;LLM;ChatGPT;Bard;Veterinary Medicine;Medical Education;Societal Impact","Analytical models;Ethics;Social networking (online);Animals;Medical services;Cognition;Security","","","","24","IEEE","2 Jan 2024","","","IEEE","IEEE Conferences"
"Smart-Infinity: Fast Large Language Model Training using Near-Storage Processing on a Real System","H. Jang; J. Song; J. Jung; J. Park; Y. Kim; J. Lee","Department of Electrical and Computer Engineering, Seoul National University; Department of Electrical and Computer Engineering, Seoul National University; Department of Electrical and Computer Engineering, Seoul National University; Department of Electrical and Computer Engineering, University of Texas at Austin; Department of Computer Science, Yonsei University; Department of Electrical and Computer Engineering, Seoul National University","2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA)","2 Apr 2024","2024","","","345","360","The recent huge advance of Large Language Models (LLMs) is mainly driven by the increase in the number of parameters. This has led to substantial memory capacity requirements, necessitating the use of dozens of GPUs just to meet the capacity. One popular solution to this is storage-offloaded training, which uses host memory and storage as an extended memory hierarchy. However, this obviously comes at the cost of storage bandwidth bottleneck because storage devices have orders of magnitude lower bandwidth compared to that of GPU device memories. Our work, Smart-Infinity, addresses the storage bandwidth bottleneck of storage-offloaded LLM training using near-storage processing devices on a real system. The main component of Smart-Infinity is SmartUpdate, which performs parameter updates on custom near-storage accelerators. We identify that moving parameter updates to the storage side removes most of the storage traffic. In addition, we propose an efficient data transfer handler structure to address the system integration issues for Smart-Infinity. The handler allows overlapping data transfers with fixed memory consumption by reusing the device buffer. Lastly, we propose accelerator-assisted gradient compression/decompression to enhance the scalability of Smart-Infinity. When scaling to multiple near-storage processing devices, the write traffic on the shared channel becomes the bottleneck. To alleviate this, we compress the gradients on the GPU and decompress them on the accelerators. It provides further acceleration from reduced traffic. As a result, Smart-Infinity achieves a significant speedup compared to the baseline. Notably, SmartInfinity is a ready-to-use approach that is fully integrated into PyTorch on a real system. The implementation of Smart-Infinity is available at https://github.com/AIS-SNU/smart-infinity.","2378-203X","979-8-3503-9313-2","10.1109/HPCA57654.2024.00034","National Research Foundation of Korea (NRF)(grant numbers:2022R1C1C1011307,2022R1C1C1008131); Institute of Information & communications Technology Planning & Evaluation (IITP)(grant numbers:IITP2023-RS-2023-00256081); MSIT; Ministry of Education (MOE); National Research Foundation (NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10476401","Processing in-memory/near-memory/in-cache;FPGA: Architectures and accelerators;Large Language Models (LLMs)","Training;Performance evaluation;Scalability;Memory management;Graphics processing units;Bandwidth;System integration","","","","130","IEEE","2 Apr 2024","","","IEEE","IEEE Conferences"
"Probing into the Fairness of Large Language Models: A Case Study of ChatGPT","Y. Li; L. Zhang; Y. Zhang","Department of Computer Science, Rutgers University, NJ, US; Department of Chemical Biology, Rutgers University, NJ, US; Department of Computer Science, Rutgers University, NJ, US","2024 58th Annual Conference on Information Sciences and Systems (CISS)","2 Apr 2024","2024","","","1","6","Understanding and addressing unfairness in LLMs are crucial for responsible AI deployment. However, there is a limited number of quantitative analyses and in-depth studies regarding fairness evaluations in LLMs, especially when applying LLMs to high-stakes fields. This work aims to fill this gap by providing a systematic evaluation of the effectiveness and fairness of LLMs using ChatGPT as a study case. We focus on assessing ChatGPT’s performance in high-takes fields including education, criminology, finance and healthcare. To conduct a thorough evaluation, we consider both group fairness and individual fairness metrics. We also observe the disparities in ChatGPT’s outputs under a set of biased or unbiased prompts. This work contributes to a deeper understanding of LLMs’ fairness performance, facilitates bias mitigation and fosters the development of responsible AI systems. Code and data are open-sourced on GitHub 1.","2837-178X","979-8-3503-6929-8","10.1109/CISS59072.2024.10480206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10480206","Large Language Model;Fairness;ChatGPT","Measurement;Systematics;Codes;Statistical analysis;Education;Finance;Medical services","","","","28","IEEE","2 Apr 2024","","","IEEE","IEEE Conferences"
"Embodied Epistemology: A Meta-Cognitive Exploration of Chatbot-Enabled Document Analysis","A. Ainapure; S. Dhamane; S. Dhage","Computer Engineering, Sardar Patel Institute of Technology, Mumbai, India; Computer Engineering, Sardar Patel Institute of Technology, Mumbai, India; Computer Engineering, Sardar Patel Institute of Technology, Mumbai, India","2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)","22 Jan 2024","2023","","","1","6","In this paper, novel research is presented that constructs a PDF chatbot using ChatGPT 3.5 Turbo and the LLM Model. The framework, chatGPT 3.5, streamlines chatbot creation, enabling scalable AI/LLM applications. The potent LLM Model facilitates text generation, language translation, and original content creation, along with insightful responses to user queries. The approach combines chatGPT 3.5 Turbo and the LLM Model to develop a chatbot proficient in addressing PDF-related inquiries. Utilizing data from uploaded PDFs and the LLM Model, the chatbot generates informative text responses to customer questions. The research relies on the LangChain framework, while a Streamlit based homepage enhances user interactions. This work exemplifies the LangChain and LLM Model’s potential to craft engaging chatbots, adaptable across domains like customer service, education, and research. The chat bot, a valuable resource for addressing product queries, offering educational aid, and providing tutoring, effectively responds to user inquiries about PDF files.","","979-8-3503-1341-3","10.1109/EASCT59475.2023.10392618","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10392618","PDF Chatbot;Langchain;gpt-3.5-turbo;Natural Language Processing;Large Language Model","Adaptation models;Ethics;Text analysis;Customer services;Education;Transfer learning;Refining","","","","17","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"ZDDR: A Zero-Shot Defender for Adversarial Samples Detection and Restoration","M. Chen; G. He; J. Wu","School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China; School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China; School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China","IEEE Access","18 Mar 2024","2024","12","","39081","39094","Natural language processing (NLP) models find extensive applications but face vulnerabilities against adversarial inputs. Traditional defenses lean heavily on supervised detection techniques, which makes them vulnerable to issues arising from training data quality, inherent biases, noise, or adversarial inputs. This study observed common compromises in sentence fluency during aggression. On this basis, the Zero Sample Defender (ZDDR) is introduced for adversarial sample detection and recovery without relying on prior knowledge. ZDDR combines the log probability calculated by the model and the syntactic normative score of a large language model (LLM) to detect adversarial examples. Furthermore, using strategic prompts, ZDDR guides LLM in rephrasing adversarial content, maintaining clarity, structure, and meaning, thereby restoring the sentence from the attack. Benchmarking reveals a 9% improvement in area under receiver operating characteristic curve (AUROC) for adversarial detection over existing techniques. Post-restoration, model classification efficacy surges by 45% compared to the offensive inputs, setting new performance standards against other restoration techniques.","2169-3536","","10.1109/ACCESS.2024.3356568","Doctoral Startup Fund of Jiangxi University of Science and Technology(grant numbers:205200100402); Scientific Research Project of the Jiangxi Provincial Department of Education(grant numbers:GJJ200839); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10410848","Adversarial defense;large language model;natural language processing;model security;prompt engineering","Training;Robustness;Computational modeling;Perturbation methods;Semantics;Natural language processing;Data models;Adversarial machine learning;Detection algorithms","","","","51","CCBYNCND","22 Jan 2024","","","IEEE","IEEE Journals"
"Hallucinations in Large Language Models (LLMs)","G. P. Reddy; Y. V. Pavan Kumar; K. P. Prakash","Kookmin University, Seoul, Republic of Korea; School of Electronics Engineering, VIT-AP University, Amaravati, Andhra Pradesh, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India","2024 IEEE Open Conference of Electrical, Electronic and Information Sciences (eStream)","5 Jun 2024","2024","","","1","6","The recent advancements in neural network architectures, particularly transformers, have played a crucial role in the rapid progress of Large Language Models (LLMs). LLMs are trained on many parameters. By training these parameters on vast amounts of text data, LLMs can learn to generate reactions to a wide variety of prompts. These models have enabled machines to generate new data (human-like), driving significant developments in Natural Language Processing (NLP). They have demonstrated remarkable capabilities in producing new content. Besides their impressive performance, LLMs occasionally generate hallucinatory responses that produce nonsensical or inaccurate information. In simple terms, hallucinations in LLMs happen when the model generates information that may sound believable but is actually wrong. It can make up details or go beyond what it has learned from the training data, resulting in inaccurate output. These hallucinatory responses appear to be authentic but lack grounding in reality. Such hallucinations can include fabrications such as facts, events, or statements that lack support from real-world data. Addressing this issue is important to enhance the reliability of AI-generated content. Hallucinations can be a significant challenge in critical applications such as healthcare, law, etc. In this view, this paper delves into the phenomenon of hallucinations in the context of LLMs. The objective is to understand the causes, explore the implications, and discuss potential strategies for mitigation.","2690-8506","979-8-3503-5241-2","10.1109/eStream61684.2024.10542617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10542617","hallucinations;large language models (LLMs);large language model operations (LLMOps);nonsensical;natural language processing (NLP);transformers","Training;Fabrication;Electric potential;Grounding;Neural networks;Training data;Medical services","","","","21","IEEE","5 Jun 2024","","","IEEE","IEEE Conferences"
"Boosting LLMS with Ontology-Aware Prompt for Ner Data Augmentation","Z. Luo; Y. Wang; W. Ke; R. Qi; Y. Guo; P. Wang","Beijing Institute of Computer Technology and Application, Beijing, China; Beijing Institute of Computer Technology and Application, Beijing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; China Life Property & Casualty Insurance Company Limited, Changsha, China; Beijing Institute of Computer Technology and Application, Beijing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","12361","12365","Named Entity Recognition (NER) data augmentation (DA) aims to improve the performance and generalization capabilities of NER models by generating scalable training data. The key challenge lies in ensuring the generated samples maintain contextual diversity while preserving label consistency. However, existing dominant methods fail to simultaneously satisfy both criteria. Inspired by the extensive generative capabilities of large language models (LLMs), we propose ANGEL, a frAmework integrating the oNtoloGy structure and instructivE prompting within LLMs. Specifically, the hierarchical ontology structure guides prompt ranking, while instructive prompting enhances LLMs’ mastery of domain knowledge, empowering synthetic sample generation and annotation. Experiments show ANGEL surpasses state-of-the-art (SOTA) baselines, conferring absolute F1 increases of 2.86% and 0.93% on two benchmark datasets, respectively.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10446860","National Science Foundation; Southeast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446860","Named Entity Recognition;Data Augmentation;Large language Model;Knowledge Graph","Training data;Speech recognition;Ontologies;Syntactics;Signal processing;Data augmentation;Boosting","","","","23","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"Compositional API Recommendation for Library-Oriented Code Generation","Z. Ma; S. An; B. Xie; Z. Lin","School of Computer Science, Peking University, Key Laboratory of High Conidence Software Technologies, Ministry of Education, Beijing, China; Xi’an Jiaotong University, Xi’an, China; School of Computer Science, Peking University, Key Laboratory of High Conidence Software Technologies, Ministry of Education, Beijing, China; Microsoft Corporation, Beijing, China","2024 IEEE/ACM 32nd International Conference on Program Comprehension (ICPC)","18 Jun 2024","2024","","","87","98","Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task. To address this, we propose CAPIR (Compositional API Recommendation), which adopts a “divide-and-conquer” strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation. To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation). Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines. Specifically, on RAPID’s TorchdataAR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On LOCG’s Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0% to 28.0%.Ccs Concepts • Software and its engineering $\rightarrow$ Search-based software engineering; Software development techniques.","2643-7171","979-8-4007-0586-1","","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556452","API recommendation;code generation;requirements decomposition;large language model","Codes;Software libraries;Training data;Documentation;Benchmark testing;Software;Task analysis","","","","51","","18 Jun 2024","","","IEEE","IEEE Conferences"
"ChatGPT and Large Language Models in Healthcare: Opportunities and Risks","H. Ali; J. Qadir; T. Alam; M. Househ; Z. Shah","Qatar Foundation, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Department of Computer Engineering, Qatar University, Doha, Qatar; Qatar Foundation, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Qatar Foundation, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Qatar Foundation, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar","2023 IEEE International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings)","30 Oct 2023","2023","","","1","4","ChatGPT, a pre-trained large language model (LLM), has the potential to transform healthcare by providing valid clinical insights and reducing doctors’ workload. There are already signs that such tools can be useful for automating the generation of patient discharge reports, clinical vignettes, and radiology reports. Such tools can also capture the vast medical knowledge base as demonstrated by ChatGPT clearing the United States Medical Licensing Examination (USMLE). Such tools promise to make healthcare more accessible, scalable, and efficient, leading to better patient outcomes. However, such tools are far from perfect and well-known to be susceptible to error, misinformation, and bias. In this paper, we review the potential applications of ChatGPT in healthcare and also identify potentials risks that must be addressed before ChatGPT and other LLM tools can be safely adopted in healthcare. First, we offer case studies on using ChatGPT for passing USMLE, identifying prevention methods for cardiovascular disease, generating patient discharge reports, generating clinical vignettes, and generating radiology reports. Second, we present the opportunities that ChatGPT offers in healthcare. By leveraging its language generation and processing capabilities, ChatGPT can streamline and improve a range of healthcare tasks, from digitizing clinical notes and improving the accuracy of diagnosis to revolutionizing medical education and empowering patients with personalized healthcare information. Finally, we reflect on the associated risks and conclude that caution is advised in interpreting the results of ChatGPT as these studies are preliminary and not entirely error-free.","","979-8-3503-2234-7","10.1109/AIBThings58340.2023.10291020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10291020","ChatGPT;Healthcare;Large Language Models;Medical Artificial Intelligence;Natural Language Processing","Adaptation models;Education;Knowledge based systems;Medical services;Transforms;Radiology;Licenses","","","","11","IEEE","30 Oct 2023","","","IEEE","IEEE Conferences"
"Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis","N. Mughal; G. Mujtaba; S. Shaikh; A. Kumar; S. M. Daudpota","Department of Computer Science, Center of Excellence for Robotics, Artificial Intelligence, and Block Chain, Sukkur IBA University, Sukkur, Sindh, Pakistan; Department of Computer Science, Center of Excellence for Robotics, Artificial Intelligence, and Block Chain, Sukkur IBA University, Sukkur, Sindh, Pakistan; Department of Information Security and Communication Technology (IIK), Norwegian University of Science and Technology (NTNU), Gjøvik, Trondheim, Norway; Learners.ai, Toronto, ON, Canada; Department of Computer Science, Sukkur IBA University, Sukkur, Sindh, Pakistan","IEEE Access","2 May 2024","2024","12","","60943","60959","Sentiment analysis is essential for comprehending public opinion, particularly when considering e-commerce and the expansion of online businesses. Early approaches treated sentiment analysis as a document or sentence-level classification problem, lacking the ability to capture nuanced opinions about specific aspects. This limitation was addressed by the development of aspect-based sentiment analysis (ABSA), which links sentiment to specific aspects that are mentioned explicitly or implicitly in the review. ABSA is relatively a recent field of sentiment analysis and the existing models for ABSA face three main challenges, including domain-specificity, reliance on labeled data, and a lack of exploration into the potential of newer large language models (LLMs) such as GPT, PaLM, and T5. Leveraging a diverse set of datasets, including DOTSA, MAMS, and SemEval16, we evaluate the performance of prominent models such as ATAE-LSTM, flan-t5-large-absa, DeBERTa, PaLM, and GPT-3.5-Turbo. Our findings reveal nuanced strengths and weaknesses of these models across different domains, with DeBERTa emerging as consistently high-performing and PaLM demonstrating remarkable competitiveness for aspect term sentiment analysis (ATSA) tasks. In addition, the PaLM demonstrates competitive performance for all the domains that were used in the experiments including the restaurant, hotel, books, clothing, and laptop reviews. Notably, the analysis underscores the models’ domain sensitivity, shedding light on their varying efficacy for both ATSA and ACSA tasks. These insights contribute to a deeper understanding of model applicability and highlight potential areas for improvement in ABSA research and development.","2169-3536","","10.1109/ACCESS.2024.3386969","National Research Program for Universities (NRPU), Higher Education Commission, Pakistan(grant numbers:20-14457/NRPU/R&D/HEC/2021-2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504711","Aspect-based sentiment analysis (ABSA);large language model (LLM);GPT;PaLM;BERT","Sentiment analysis;Analytical models;Task analysis;Reviews;Computational modeling;Transformers;Biological system modeling;Large language models","","","","81","CCBY","17 Apr 2024","","","IEEE","IEEE Journals"
"Clinical Knowledge and Reasoning Abilities of Large Language Models in Pharmacy: A Comparative Study on the NAPLEX Exam","M. Angel; A. Patel; A. Alachkar; P. Baldi","Institute for Genomics and Bioinformatics, University of California Irvine, Irvine, USA; Department of Computer Science, University of California Irvine, Irvine, USA; School of Pharmacy & Pharmaceutical, Sciences University of California Irvine, Irvine, USA; Institute for Genomics and Bioinformatics, University of California Irvine, Irvine, USA","2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS)","2 Jan 2024","2023","","","1","4","This study aims to evaluate the capabilities and limitations of three large language models (LLMs)-GPT-3, GPT-4, and Bard, in the field of pharmacy by assessing their reasoning abilities on a sample of the North American Pharmacist Licensure Examination (NAPLEX). Additionally, we explore the potential impacts of LLMs on pharmacy education and practice. To evaluate the LLMs, we utilized the sample of the NAPLEX exam comprising 137 multiple-choice questions. These questions were presented to GPT-3, GPT-4, and Bard through their respective user interfaces, and the answers generated by the LLMs were subsequently compared with the answer key. The results reveal a notable disparity in the performance of the LLMs. GPT-4 emerged as the top performer, accurately answering 78.8% of the questions. This marked a substantial 11% and 27.7% improvement over Bard and GPT-3, respectively. However, when considering questions that required multiple selections, the performance of each LLM decreased significantly. GPT-4, GPT-3, and Bard could only correctly respond to 53.6%, 13.9%, and 21.4% of such questions, respectively. Among the three LLMs evaluated, GPT-4 was the only model capable of passing the NAPLEX exam. Nevertheless, given the continuous evolution of LLMs, it is reasonable to anticipate that future models will effortlessly excel in this context. This highlights the significant potential of LLMs to influence the field of pharmacy. Hence, we must evaluate both the positive and negative implications associated with the integration of LLMs in pharmacy education and practice.","2831-7343","979-8-3503-1890-6","10.1109/SNAMS60348.2023.10375395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10375395","Artificial Intelligence;LLM;ChatGPT;Bard;Healthcare;Pharmacy","Knowledge engineering;Analytical models;Social networking (online);Education;User interfaces;Cognition;Security","","1","","17","IEEE","2 Jan 2024","","","IEEE","IEEE Conferences"
"Revolutionizing Formative Assessment in STEM Fields: Leveraging AI and NLP Techniques","C. W. Tan; K. Y. Lim","Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology, Kuala Lumpur, Malaysia; Department of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology, Penang, Malaysia","2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","20 Nov 2023","2023","","","1357","1364","Artificial intelligence (AI) has been extensively studied in science, technology, engineering, and mathematics (STEM), but there is a disparity between AI-generated and human-written scientific content. To bridge this gap, a prototype utilizing Natural Language Processing (NLP) techniques and a large language model (LLM) generates assessment questions and evaluates student answers. This formative assessment system offers a user-friendly and scalable solution for higher education educators. It tailors’ assessments to individual students, accommodates varying capabilities, and facilitates performance analysis. Through rigorous evaluation and benchmarking, the prototype ensures alignment with High-Level Performance (HLP) standards. This AI-assisted formative assessment system enhances efficiency and efficacy by providing accurate and timely feedback. It has the potential to significantly improve STEM education through scalable and personalized formative assessment experiences. AI and NLP enable educators to access tailored assessment options, enhancing learning outcomes and the overall educational experience.","2640-0103","979-8-3503-0067-3","10.1109/APSIPAASC58517.2023.10317226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10317226","","Training;Scalability;Education;Prototypes;Optimized production technology;Natural language processing;Time factors","","","","23","IEEE","20 Nov 2023","","","IEEE","IEEE Conferences"
"Empowering Healthcare Professionals and Patients with ChatGPT: Applications and Challenges","F. Mosaiyebzadeh; S. Pouriyeh; R. M. Parizi; M. Han; N. Dehbozorgi; M. Dorodchi; D. M. Batista","Department of Computer Science, University of São Paulo, Brazil; Department of Information and Technology, Kennesaw State University, Marietta, GA, USA; Decentralized Science Lab, Kennesaw State University, Marietta, GA, USA; Zhejiang University, Hangzhou, Zhejiang, China; Department of Software and Game Development, Kennesaw State University, Marietta, GA, USA; Department of Computer Science, UNC Charlotte, Charlotte, USA; Department of Computer Science, University of São Paulo, Brazil","2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)","9 Apr 2024","2023","","","01","07","ChatGPT is a recently developed Large Language Model (LLM) and an effective tool to produce human-like dialogue with users and answering to questions. It is trained on a massive amount of online content and can provide textual answers to questions from several domains, such as healthcare. In this paper, we investigate the application of ChatGPT in the healthcare domain and provide an analysis on its limitations and challenges. While ChatGPT can offer valuable support and information, it is crucial to recognize that it should not be seen as a replacement for the expertise and personalized care provided by healthcare professionals. Instead, its purpose lies in augmenting healthcare services and enhancing access to information. It can be a useful tool for providing general guidelines and educational resources. However, when it comes to medical advice or diagnosis, it is essential to consult qualified healthcare professionals who can consider individual factors, interpret complex medical information, and provide tailored recommendations based on a comprehensive understanding of the patient's situation.","","979-8-3503-2759-5","10.1109/CSCE60160.2023.00233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487439","ChatGPT;Healthcare;Applications;Challenges;Artificial intelligence","Drugs;Data privacy;Telemedicine;Medical services;Chatbots;Real-time systems;Medical diagnostic imaging","","","","43","IEEE","9 Apr 2024","","","IEEE","IEEE Conferences"
"Seven Failure Points When Engineering a Retrieval Augmented Generation System","S. Barnett; S. Kurniawan; S. Thudumu; Z. Brannelly; M. Abdelrazek","Applied Artificial Intelligence Institute, Geelong, Australia; Applied Artificial Intelligence Institute, Geelong, Australia; Applied Artificial Intelligence Institute, Geelong, Australia; Applied Artificial Intelligence Institute, Geelong, Australia; Applied Artificial Intelligence Institute, Geelong, Australia","2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)","18 Jun 2024","2024","","","194","199","Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.CCS CONCEPTS• Software and its engineering → Empirical software validation.","","979-8-4007-0591-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556182","Retrieval Augmented Generation;RAG;SE4AI;Case Study","Semantic search;Education;Information retrieval;Chatbots;Software;Robustness;Task analysis","","","","19","","18 Jun 2024","","","IEEE","IEEE Conferences"
"ChatGPT in IoT Systems: Arduino Case Studies","N. Petrović; S. Koničanin; S. Suljović","Department of Computer Science, Faculty of Electronic Engineering, University of Niš, Niš, Serbia; Department of Computer Science, Faculty of Electronic Engineering, University of Niš, Niš, Serbia; The Academy of Applied Technical Studies Belgrade, Belgrade, Serbia","2023 IEEE 33rd International Conference on Microelectronics (MIEL)","16 Nov 2023","2023","","","1","4","Since the beginning of this year, the novel large language model (LLM) based ChatGPT conversational agent has been in spotlight, due to its comprehensiveness across many fields – from novel writing to playing board games. In this paper, it is explored how it can be leveraged within IoT systems, taking into account both the novel scenarios enabled relying on ChatGPT’s power of question answering and software development as well. As example, two case studies related to Arduino platform are considered: 1) ChatGPT-based predictions on sensor data collected by Arduino 2) model-driven automated Arduino code generation.","2159-1679","979-8-3503-4776-0","10.1109/MIEL58498.2023.10315791","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10315791","","Performance evaluation;Codes;Speech recognition;Writing;Predictive models;Chatbots;Robot sensing systems","","","","9","IEEE","16 Nov 2023","","","IEEE","IEEE Conferences"
"A Transformer-BERT Integrated Model-Based Automatic Conversation Method Under English Context","X. Li; T. Liu; L. Zhang; F. Alqahtani; A. Tolba","Department of Foreign Languages and Literature, Gongqing College of Nanchang University, Jiujiang, China; School of Economics and Management, Gannan University of Science and Technology, Ganzhou, China; Department of Foreign Languages and Literature, Gongqing College of Nanchang University, Jiujiang, China; Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Computer Science, Community College, King Saud University, Riyadh, Saudi Arabia","IEEE Access","23 Apr 2024","2024","12","","55757","55767","The contextual understanding ability in complex conversation scenarios has been a challenging issue, and existing methods mostly failed to possess such characteristics. To bridge such gap, this paper formulates a novel composite large language model to investigate such issue. As a result, taking English context as the scene, a Transformer-BERT integrated model-based automatic conversation model is proposed in this work. Firstly, the unidirectional BERT-based automatic conversation model is improved by introducing attention mechanism. It is expected to enhance feature expression for conversation texts by linking context to identify long-difficult sentences. Besides, a bidirectional Transformer encoder is utilized as the input layer before the BERT encoder. Through the two modules, dynamic language training based on English situational conversations can be completed to build the automatic conversation model. The proposed conversation model is further assessed on massive real-world English language context in terms of conversation performance. The experimental results show that compared with traditional rule-based or machine learning methods, the proposal has significantly improved response quality and fluency in English context. It can more accurately understand context, capture subtle semantic differences, and generate more coherent responses.","2169-3536","","10.1109/ACCESS.2024.3388100","Researchers Supporting Project(grant numbers:RSPD2024R681); King Saud University, Riyadh, Saudi Arabia; Key Project of the 14th Five-Year Plan of Jiangxi Provincial Education Sciencce, in 2023(grant numbers:23ZD046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10497586","Large language model;automatic conversation;semantic context;natural language processing","Oral communication;Context modeling;Transformers;Natural language processing;Task analysis;Semantics;Training;Large language models","","","","31","CCBY","12 Apr 2024","","","IEEE","IEEE Journals"
"Specialized Syntactic Quran Search Engines: Evaluation and Limitations","A. Bakr; A. H. Yousef; T. Arafa","School of Information Technology and Computer Science, Nile University, Giza, Egypt; Egypt University of Informatics Ain Shams University, Cairo, Egypt; School of Information Technology and Computer Science, Nile University, Giza, Egypt","2023 Intelligent Methods, Systems, and Applications (IMSA)","24 Aug 2023","2023","","","269","275","The Quran is the sacred text that provides guidance and teachings to the followers of Islam. This paper aims to analyze and evaluate the limitations of current specialized search engines used for retrieving information from the Quran. Also, this work includes an initial evaluation of Quran search with a large language model (LLM) employing prompt engineering. The study focuses on the syntactic aspect of information retrieval, while acknowledging the necessity of considering the semantic meaning of Quranic words and verses for a more comprehensive analysis. Furthermore, recommendations and guidelines for future research are proposed, stressing the significance of developing syntactic search capabilities to improve the accuracy and relevance of search results.","","979-8-3503-3556-9","10.1109/IMSA58542.2023.10217550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10217550","The Holy Quran;information retrieval;specialized search engines;diacritical search;prompt engineering;OpenAI;ChatGPT","Semantic search;Education;Symbols;Search engines;Syntactics;Reliability;Task analysis","","","","13","IEEE","24 Aug 2023","","","IEEE","IEEE Conferences"
"Selective Propositional Reasoning: A Cognitive Load-Aware Strategy for Enhanced Reasoning","Y. Yue; Y. Lei; W. Shi; Y. Zhou","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China","2023 2nd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE)","21 Feb 2024","2023","","","231","237","Large Language Models (LLMs) have made significant strides across a myriad of domains. While techniques like Chain of Thought have enhanced LLM’s reasoning abilities to some extent, they still fall short in complex reasoning tasks. Drawing parallels with human cognition, there exists a concept of ""cognitive load"" that impacts our efficiency in processing information. Based on this, we hypothesize that LLMs, much like humans, may also be affected by cognitive load during their reasoning processes. Building on this assumption, we postulate that by alleviating the cognitive load LLMs encounter during reasoning, we can augment their overall performance. To this end, we introduce the Selective Propositional Reasoning (SPR) methodology, which is specifically designed to mitigate this cognitive burden. Our experimental results underscore the effectiveness of SPR, evidencing a 6% improvement in overall accuracy. Additionally, the Proposition Pair Enumeration (PPE) strategy further substantiates our cognitive load hypothesis, showcasing a 1.5% overall performance enhancement. Collectively, our findings not only emphasize the potential benefits of addressing cognitive load in LLMs but also bridge the gap between psychological constructs and computational modeling.","","979-8-3503-3144-8","10.1109/CBASE60015.2023.10439142","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439142","Large Language Model;Reasoning;Cognitive Load;Selector;Selective Propositional Reasoning","Personal protective equipment;Technological innovation;Computational modeling;Psychology;Cognitive load;Task analysis;Load modeling","","","","26","IEEE","21 Feb 2024","","","IEEE","IEEE Conferences"
"Chain-of-Thoughts Prompting with Language Models for Accurate Math Problem-Solving","S. C. E. Fung; M. F. Wong; C. W. Tan","Diocesan Girls' School, Hong Kong, China; City University of Hong Kong, Hong Kong, China; Nanyang Technological University, Singapore","2023 IEEE MIT Undergraduate Research Technology Conference (URTC)","24 May 2024","2023","","","1","5","Large Language Models (LLMs) have gained usage across various domains, especially in education. However, the current state-of-the-art LLMs fail in numerical calculations due to their reliance on the pre-trained dataset that does not focus on mathematical oversight. Prompting is crucial to guide LLMs to yield desired outputs for mathematical problems. This paper explores a new Chain-of-Thoughts (CoT) prompting framework, leveraging Python-based tools like LLM Math, LLM symbolic math, and SerpAPI. We also evaluate the existing works with the CoT prompting framework for math problem-solving. Students can utilize this framework to obtain more precise solutions and comprehensive explanations for their queries.","","979-8-3503-0965-2","10.1109/URTC60662.2023.10534945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10534945","Large Language Models;Prompt Engineering;LangChain;Mathematical reasoning;Conversational AI","Education;Mathematical models;Problem-solving","","","","23","IEEE","24 May 2024","","","IEEE","IEEE Conferences"
"How Big Can It Get? A comparative analysis of LLMs in architecture and scaling","R. Yousri; S. Safwat","Software Engineering, Egyptian Chinese University, Cairo, Egypt; Computer science, Egyptian Chinese University, Cairo, Egypt","2023 International Conference on Computer and Applications (ICCA)","23 Jan 2024","2023","","","1","5","Large Language models (LLMs) are increasingly becoming an integral part of our society. They play important roles in education, marketing and healthcare. These models exhibit emergent behavior when scaled, however such scaling might have its disadvantages as well. As a way to combat such disadvantages, new architectures and types of models have been designed. In this paper, we show the different architectural decisions when it comes to building LLMs as well as discuss how big a model needs to be in order to be specialized in a certain area or sector. We show that most specialized models are small in size yet outperform larger models in specific domain tasks.","","979-8-3503-0325-4","10.1109/ICCA59364.2023.10401818","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10401818","Large language models;Transformers;NLP;Specialized models;LLM size","Analytical models;Computational modeling;Computer architecture;Medical services;Transformers;Data models;Task analysis","","","","36","IEEE","23 Jan 2024","","","IEEE","IEEE Conferences"
"Exploring Pre-processing Strategies and Feature Extraction in practical aspect for Effective Spam Detection","H. Singh; S. Sood; H. Maity; Y. Kumar","Chitkara University, Institute of Engineering and Technology Chitkara University, Rajpura, Punjab, India; School of Computer Applications, Lovely Professional University, Punjab, India; Symbiosis Institute of Technology, Nagpur Campus, Symbiosis International (Deemed University), Pune, India; School of Technology, Pandit Deendayal Energy University, Gandhinagar, India","2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)","24 Apr 2024","2024","2","","1","6","With the advent of Large Language Models (LLMs) based ChatGPT, a drastically change has been observed in the areas of Natural Language Processing. LLMs have shown remarkable performance in various natural language processing tasks and applications. This article first presents all the stages (roadmap) towards implementing LLMs, wherein pre-requisite tools and methods for constructing a Large Language Model are discussed. In this connection, required text data pre-processing approaches have been disscused and implemented using the publicly, online available dataset (SMSSpamCollection). By using this dataset,two classes (""ham"" and ""spam"") classification problem has been addressed. In this classification, we first elaborate the working of two text feature extraction techniques, namely, Bag-of-Words (BOW) and Term Frequency-Inverse Document Frequency (TF-IDF) and then train the classifier by using both the features. Testing experiments produced an appreciable accuracy rate 97.22% and 98.47% for BOW and TF-IDF, respectively. Although, classification accuracy is good enough but these extracted features have certain limitations, which are also discussed in this article. In the future, we will explore this work with various neural network architectures, commonly used in LLMs in order to overcome these issues.","","979-8-3503-6052-3","10.1109/IATMSI60426.2024.10502863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10502863","Bag-of-Words;TF-IDF;Spam Classification;text pre-processing;Naive Bayes","Vocabulary;Technological innovation;Semantics;Programming;Feature extraction;Chatbots;Tokenization","","","","15","IEEE","24 Apr 2024","","","IEEE","IEEE Conferences"
"A Comparative Review of GPT-4’s Applications in Medicine and High Decision Making","R. Bitri; M. Ali","Abbe School of Photonics (ASP), Friedrich Schiller University Jena, Jena, Germany; Department of Computer Science, Universiteti Metropolitan Tirana, Tirana, Albania","2023 International Conference on Computing, Networking, Telecommunications & Engineering Sciences Applications (CoNTESA)","11 Jan 2024","2023","","","61","68","This paper provides a comprehensive assessment of GPT-4’s (Generative Pre-trained Transformer – 4) application in the domain of medicine, highlighting its advancements compared to previous models. It delves into the model’s potential, limitations and significant experimental findings - offering a thorough perspective on its rôle in transforming the medical field. Emphasizing the implications of GPT-4’s integration in critical decision-making contexts, the study explores the pivotal rôle of prompt engineering in extracting precise and valuable outputs from extensive language models like GPT-4. By examining prompt design intricacies, the research sheds light on its far-reaching consequences and its direct influence on enhancing GPT-4’s effectiveness, especially its rôle as a medical assistant.","","979-8-3503-8275-4","10.1109/CoNTESA61248.2023.10384948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10384948","bioinformatics;drug discovery;GPT-4;large language model;prompt engineering","Drugs;Biological system modeling;Decision making;Transformers;Bioinformatics;Context modeling","","","","54","IEEE","11 Jan 2024","","","IEEE","IEEE Conferences"
"Multi-Lingual Sentence Alignment with GPT Models","X. Liang; Y. -M. J. Khaw; S. -Y. Liew; T. -P. Tan; D. Qin","Department of Computer Science, Faculty of Information and Communication Technology, Universiti Tunku Abdul Rahman, Kampar, Malaysia; Department of Computer Science, Faculty of Information and Communication Technology, Universiti Tunku Abdul Rahman, Kampar, Malaysia; Department of Computer Science, Faculty of Information and Communication Technology, Universiti Tunku Abdul Rahman, Kampar, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; School of Artificial Intelligence, GuangXi MinZu University, NanNing, China","2023 4th International Conference on Artificial Intelligence and Data Sciences (AiDAS)","23 Oct 2023","2023","","","218","223","This paper investigates sentence alignment technology, an essential element in Natural Language Processing tasks like machine translation, that pairs corresponding sentences within bilingual documents. Despite the existence of standard bilingual alignment corpora, they often fall short in covering low-resource languages and specific domains, underscoring the need for advanced sentence alignment algorithms. We explore the potential of the GPT model for sentence alignment, focusing on aspects like prompt construction, experiment design, and results evaluation. Utilizing the OPUS corpus, our experimental design covers eight commonly used languages in 28 directions. The study reveals that the GPT-aligner outperforms traditional algorithms by 5-30% in most scenarios, with the performance contingent on language, prompting, the GPT system model, and few-shot demonstration strategies. This work illuminates the significant potential of sentence alignment algorithms in the future development of language models.","","979-8-3503-1843-2","10.1109/AiDAS60501.2023.10284652","Ministry of Higher Education (MoHE), through the Fundamental Research(grant numbers:FRGS/1/2022/ICT02/UT AR/02/6); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10284652","Sentence Alignment;Large Language Model;GPT;Neural Machine Translation;Low-resource Languages;Parallel Corpora","Adaptation models;Focusing;Data models;Machine translation;Task analysis;Artificial intelligence;Standards","","","","17","IEEE","23 Oct 2023","","","IEEE","IEEE Conferences"
"ChatGPT-Aided QoS Estimation Le eraging Outage Probability of Mobile Networks Limited by α-η-µ Fading and α-η-µ Co-channel Interference","D. Milić; N. Petrović; D. Milovanović; S. Đorđević; S. Suljović","Faculty of Electronic Engineering, University of Nis, Nis, Serbia; Faculty of Electronic Engineering, University of Nis, Nis, Serbia; Academy of Technical Vocational of Beograd, Beograd, Serbia; Academy of Technical Vocational of Beograd, Beograd, Serbia; Academy of Technical Vocational of Beograd, Beograd, Serbia","2023 16th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS)","16 Nov 2023","2023","","","344","347","In this paper, we analyze the performance of wireless communication system affected by α-η-μ fading in the presence of α-η-μ co-channel interference (CCI) for the receiver with selection combining (SC) with L branches. In the paper, a closed-form expression for the system outage probability (Pout) of the ratio of the received signal and interference (SIR) are derived. Obtained results can be used in performance analysis of wireless communication system which uses diversity technique to reduce fading effects in fading channels. On the other side, in the second part of the paper, we investigate the potential of trending ChatGPT based on Large Language Mode (LLM) for task of QoS estimation, taking into account Pout among model inputs. Finally, the proposed method is compared to traditional machine learning algorithms using Weka in Java programming language.","","979-8-3503-4702-9","10.1109/TELSIKS57806.2023.10316065","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316065","Outage probability;Selection combining;α-η-µ fading;α-η-µ co-channel interference;ChatGPT","Fading channels;Wireless communication;Diversity reception;Estimation;Receivers;Quality of service;Probability","","","","16","IEEE","16 Nov 2023","","","IEEE","IEEE Conferences"
"Multi-Agent RAG Chatbot Architecture for Decision Support in Net-Zero Emission Energy Systems","G. Gamage; N. Mills; D. De Silva; M. Manic; H. Moraliyage; A. Jennings; D. Alahakoon","Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Department of Computer Science, Virginia Commonwealth University, Richmond, USA; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia","2024 IEEE International Conference on Industrial Technology (ICIT)","5 Jun 2024","2024","","","1","6","Modern energy platforms are increasingly leveraging Artificial Intelligence (AI) for effective decision-making and efficient operations. This has led to the development of expansive data spaces that comprise both structured and unstructured energy data in various modalities. Conversational agents with the most recent advancements in Large Language Models (LLM) are primed to facilitate the efficient retrieval of this diverse information for decision support. In this paper, we propose a multi-agent chatbot architecture for decision support in net-zero emissions energy systems, leveraging LLMs and Retrieval-Augmented Generation (RAG). This architecture consists of a Chatbot User Interface (UI), an advanced Natural Language Understanding (NLU) module for precise entity and intent recognition, a robust Chatbot Core with four specialized agents: Observer, Knowledge Retriever, Behavior Analyzer, and Visualizer and Response Construction Module. These components work together to address diverse decision support needs in energy environments, specifically for net zero carbon emissions initiatives that need to consider diverse parameters and large volumes of data. We showcase the chatbot's successful integration and evaluation for decision support in the net-zero emissions energy system of a large tertiary education institution.","2643-2978","979-8-3503-4026-6","10.1109/ICIT58233.2024.10540920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10540920","Retrieval-Augmented Generation;Chatbots;Generative AI;Net Zero Emissions;Microgrid;AI Agents;Multi Agent Architecture","Intent recognition;Net zero;Education;Decision making;Data visualization;Collaboration;Observers","","","","25","IEEE","5 Jun 2024","","","IEEE","IEEE Conferences"
"Automatic and efficient heap data management for Limited Local Memory multicore architectures","K. Bai; A. Shrivastava","Compiler and Microarchitecture Laboratory Arizona State University, Tempe, Arizona, USA; Compiler and Microarchitecture Laboratory Arizona State University, Tempe, Arizona, USA","2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)","4 May 2013","2013","","","593","598","Limited Local Memory (LLM) multi-core architectures substitute cache with scratch pad memories (SPM), and therefore have much lower power consumption. As they lack of automatic memory management, programming on such architectures becomes challenging, in the sense that it requires the programmer/compiler to efficiently manage the limited local memory. Managing heap data of the tasks executing in the cores of an LLM multi-core is an important problem. This paper presents a fully automated and efficient scheme for heap data management. Specifically, we propose i) code transformation for automation of heap management, with seamless support for multi-level pointers, and ii) improved data structures to more efficiently manage unlimited heap data. Experimental results on several benchmarks from MiBench demonstrate an average 43% performance improvement over previous approach [1].","1530-1591","978-3-9815370-0-0","10.7873/DATE.2013.130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6513576","","Memory management;Benchmark testing;Multicore processing;Data structures;Silicon;Program processors","","11","2","29","","4 May 2013","","","IEEE","IEEE Conferences"
"A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges","M. A. K. Raiaan; M. S. H. Mukta; K. Fatema; N. M. Fahad; S. Sakib; M. M. J. Mim; J. Ahmad; M. E. Ali; S. Azam","Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh; LUT School of Engineering Sciences, Lappeenranta-Lahti University of Technology, Lappeenranta, Finland; Faculty of Science and Technology, Charles Darwin University, Casuarina, NT, Australia; Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh; Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh; Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh; Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh; Department of CSE, Bangladesh University of Engineering and Technology (BUET), Dhaka, Bangladesh; Faculty of Science and Technology, Charles Darwin University, Casuarina, NT, Australia","IEEE Access","23 Feb 2024","2024","12","","26839","26874","Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.","2169-3536","","10.1109/ACCESS.2024.3365742","Institute of Advance Research, United International University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433480","Large language models (LLM);natural language processing (NLP);artificial intelligence;transformer;pre-trained models;taxonomy;application","Cognition;Artificial intelligence;Transformers;Training;Taxonomy;Task analysis;Surveys;Natural language processing;Question answering (information retrieval);Information analysis;Linguistics","","5","","187","CCBYNCND","13 Feb 2024","","","IEEE","IEEE Journals"
"Auto-Grading Comprehension on Reference-Student Answer Pairs using the Siamese-based Transformer","M. A. Sayeed; D. Gupta; V. Kanjirangat","Department of Computer Science and Engineering, Amrita School of Computing Bengaluru, Amrita Vishwa Vidyapeetham, India; Department of Computer Science and Engineering, Amrita School of Computing Bengaluru, Amrita Vishwa Vidyapeetham, India; Istituto Dalle Molle di Studi sull’Intelligenza, Artificiale USI/SUPSI Lugano, Switzerland","2024 IEEE 9th International Conference for Convergence in Technology (I2CT)","10 Jun 2024","2024","","","1","8","Students often struggle with comprehension skills, which are critical for success in many areas of life. To sustain the growing demand for online education setups requires sophisticated evaluation tools, beyond meremultiple-choice format to effectively groom students. The research work proposes RC-based grading tools using the Siamese-based Transformer modelon reference-student answer pairs as the reference-based approach. The technique relies on creating a custom Representation QA model as Bi-Encoders in the Siamese-based transformer model. Furthermore, the research work presents the experimental study of the potential of using LLM such as ChatGPT to replace human annotation of reference answers by synthesizing through provided passages and questions. The research work is presented on the standard mocha benchmark dataset.","","979-8-3503-9447-4","10.1109/I2CT61223.2024.10543346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10543346","ASAG;Biencoders;ChatGPT;Reading comprehension;Reference answers;Sentence similarity task Transformers","Annotations;Education;Benchmark testing;Transformers;Chatbots;Task analysis;Standards","","","","34","IEEE","10 Jun 2024","","","IEEE","IEEE Conferences"
"How Good Is ChatGPT at Face Biometrics? A First Look Into Recognition, Soft Biometrics, and Explainability","I. Deandres-Tame; R. Tolosana; R. Vera-Rodriguez; A. Morales; J. Fierrez; J. Ortega-Garcia","Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain; Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain; Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain; Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain; Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain; Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain","IEEE Access","8 Mar 2024","2024","12","","34390","34401","Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society. This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed. As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning). The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics. In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results. ChatGPT could be very valuable to further increase the explainability and transparency of automatic decisions in human scenarios. Experiments are carried out in order to evaluate the performance and robustness of ChatGPT, using popular public benchmarks and comparing the results with state-of-the-art methods in the field. The results achieved in this study show the potential of LLMs such as ChatGPT for face biometrics, especially to enhance explainability. For reproducibility reasons, we release all the code in GitHub.","2169-3536","","10.1109/ACCESS.2024.3370437","INTER-ACTION (PID2021-126521OB-I00 MICINN/FEDER), Cátedra ENIA UAM-VERIDAS en IA Responsable (NextGenerationEU PRTR TSI-100927-2023-2) and R&D Agreement DGGC/ UAM/FUAM for Biometrics and Cybersecurity; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445251","Large language models;ChatGPT;face recognition;soft biometrics;explainability","Chatbots;Face recognition;Task analysis;Image color analysis;Facial features;Estimation;Biological system modeling;Large language models;Biometrics (access control);Explainable AI","","2","","40","CCBYNCND","26 Feb 2024","","","IEEE","IEEE Journals"
"TrumorGPT: Query Optimization and Semantic Reasoning over Networks for Automated Fact-Checking","C. N. Hang; P. -D. Yu; C. W. Tan","Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Applied Mathematics, Chung Yuan Christian University, Taiwan; School of Computer Science and Engineering, Nanyang Technological University, Singapore","2024 58th Annual Conference on Information Sciences and Systems (CISS)","2 Apr 2024","2024","","","1","6","In the age of social media, the rapid spread of misinformation and rumors has led to the emergence of infodemics, where false information poses a significant threat to society. To combat this issue, we introduce TrumorGPT, a novel generative artificial intelligence solution designed for automated fact-checking. TrumorGPT aims to distinguish ""trumors"", which are rumors that turn out to be true, providing a crucial tool in differentiating between mere speculation and verified facts. This framework merges machine learning with natural language processing techniques, leveraging a large language model (LLM) with few-shot learning for knowledge graph construction and semantic reasoning. TrumorGPT addresses the ""hallucination"" issue common in LLMs and the limitations of static training data by incorporating retrieval-augmented generation. This approach involves accessing and utilizing information from regularly updated knowledge graphs that consist of the latest news and information, ensuring that fact-checking of TrumorGPT is based on the most recent data. Accessing updated knowledge graphs greatly enhances the proficiency of TrumorGPT in delivering accurate and reliable information promptly. Evaluating with extensive datasets, TrumorGPT demonstrates superior performance in automated fact-checking. Its ability to effectively conduct automated fact-checking across various platforms marks a critical step forward in the fight against misinformation, enhancing trust and accuracy in the digital information age.","2837-178X","979-8-3503-6929-8","10.1109/CISS59072.2024.10480162","National Science and Technology Council; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10480162","Fact-checking;large language models;retrieval-augmented generation;semantic reasoning;knowledge graph","Social networking (online);Voting;Query processing;Semantics;Training data;Knowledge graphs;Cognition","","","","27","IEEE","2 Apr 2024","","","IEEE","IEEE Conferences"
"Vulnerability of Machine Learning Approaches Applied in IoT-Based Smart Grid: A Review","Z. Zhang; M. Liu; M. Sun; R. Deng; P. Cheng; D. Niyato; M. -Y. Chow; J. Chen","State Key Laboratory of Public Big Data, College of Computer Science and Technology, the Text Computing and Cognitive Intelligence Engineering Research Center of National Education Ministry, and the Guizhou Provincial Key Laboratory of Cryptography and Blockchain Technology, Guizhou University, Guiyang, China; Department of Automatic Control and Systems Engineering, University of Sheffield, Sheffield, U.K.; State Key Laboratory of Industrial Control Technology and the College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology and the College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology and the College of Control Science and Engineering, Zhejiang University, Hangzhou, China; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; UMCSJTU Joint Institute, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Industrial Control Technology and the College of Control Science and Engineering, Zhejiang University, Hangzhou, China","IEEE Internet of Things Journal","22 May 2024","2024","11","11","18951","18975","Machine learning (ML) sees an increasing prevalence of being used in the Internet of Things (IoT)-based smart grid. However, the trustworthiness of ML is a severe issue that must be addressed to accommodate the trend of ML-based smart grid applications (MLsgAPPs). The adversarial distortion injected into the power signal will greatly affect the system’s normal control and operation. Therefore, it is imperative to conduct vulnerability assessment for MLsgAPPs applied in the safety-critical power systems. In this article, we provide a comprehensive review of the recent progress in designing attack and defense methods for MLsgAPPs. Unlike the traditional survey about ML security, this is the first review work about the security of MLsgAPPs that focuses on the characteristics of power systems. We first highlight the specifics for constructing adversarial attacks on MLsgAPPs. Then, the vulnerability of MLsgAPP is analyzed from the perspective of the power system and ML model, respectively. Afterward, a comprehensive survey is conducted to review and compare existing studies about the adversarial attacks on MLsgAPPs in scenarios of generation, transmission, distribution, and consumption, and the countermeasures are reviewed according to the attacks that they defend against. Finally, the future research directions are discussed on the attacker’s and defender’s side, respectively. We also analyze the potential vulnerability of large language model-based (e.g., ChatGPT) smart grid applications. Overall, our purpose is to encourage more researchers to contribute to investigating the adversarial issues of MLsgAPPs.","2327-4662","","10.1109/JIOT.2024.3349381","National Natural Science Foundation of China(grant numbers:62303126,62362008,61833015,62293503,62293502,62293500,62073285,62103371); Natural Science Foundation of Zhejiang Province(grant numbers:LR23F030001,LZ23F030009); Fundamental Research Funds for the Central Universities(grant numbers:226-2022-0010,226-2023-00111); National Research Foundation Singapore and MOE Tier 1(grant numbers:RG87/22); Key Laboratory of CS&AUS of Zhejiang Province; Guizhou Provincial Science and Technology Projects(grant numbers:ZK[2022]149); Guizhou Provincial Research Project (Youth) for Universities(grant numbers:[2022]104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10380506","Adversarial machine learning (ML);physical constraints;power system specifics;smart grid;vulnerability assessment","Power systems;Smart grids;Security;Power system dynamics;Electronic mail;Europe;Perturbation methods","","","","195","IEEE","3 Jan 2024","","","IEEE","IEEE Journals"
"Residual Sketch Learning for a Feature-Importance-Based and Linguistically Interpretable Ensemble Classifier","Z. Bian; J. Zhang; F. -L. Chung; S. Wang","School of Artificial Intelligence (AI) and Computer Science, Jiangnan University, Wuxi, China; School of Artificial Intelligence (AI) and Computer Science, Jiangnan University, Wuxi, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; School of Artificial Intelligence (AI) and Computer Science, Jiangnan University, Wuxi, China","IEEE Transactions on Neural Networks and Learning Systems","","2023","PP","99","1","14","Motivated by both the commonly used “from wholly coarse to locally fine” cognitive behavior and the recent finding that simple yet interpretable linear regression model should be a basic component of a classifier, a novel hybrid ensemble classifier called hybrid Takagi–Sugeno–Kang fuzzy classifier (H-TSK-FC) and its residual sketch learning (RSL) method are proposed. H-TSK-FC essentially shares the virtues of both deep and wide interpretable fuzzy classifiers and simultaneously has both feature-importance-based and linguistic-based interpretabilities. RSL method is featured as follows: 1) a global linear regression subclassifier on all original features of all training samples is generated quickly by the sparse representation-based linear regression subclassifier training procedure to identify/understand the importance of each feature and partition the output residuals of the incorrectly classified training samples into several residual sketches; 2) by using both the enhanced soft subspace clustering method (ESSC) for the linguistically interpretable antecedents of fuzzy rules and the least learning machine (LLM) for the consequents of fuzzy rules on residual sketches, several interpretable Takagi–Sugeno–Kang (TSK) fuzzy subclassifiers are stacked in parallel through residual sketches and accordingly generated to achieve local refinements; and 3) the final predictions are made to further enhance H-TSK-FC’s generalization capability and decide which interpretable prediction route should be used by taking the minimal-distance-based priority for all the constructed subclassifiers. In contrast to existing deep or wide interpretable TSK fuzzy classifiers, benefiting from the use of feature-importance-based interpretability, H-TSK-FC has been experimentally witnessed to have faster running speed and better linguistic interpretability (i.e., fewer rules and/or TSK fuzzy subclassifiers and smaller model complexities) yet keep at least comparable generalization capability.","2162-2388","","10.1109/TNNLS.2023.3242049","National Key Research and Development Project(grant numbers:2022YFE0112400); National Natural Science Foundation of China(grant numbers:U20A20228,61772198,6197071117); Natural Science Foundation of Jiangsu Province(grant numbers:BK20191331); Natural Science Key Research Projects of Jiangsu Education Department(grant numbers:22KJA520009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042180","Deep or wide Takagi–Sugeno–Kang (TSK) fuzzy classifiers;generalization capability;interpretability;linear regression classifier;residual sketch learning (RSL)","Training;Linguistics;Linear regression;Feature extraction;Behavioral sciences;Learning systems;Long short term memory","","","","","IEEE","10 Feb 2023","","","IEEE","IEEE Early Access Articles"
"A Framework for Identifying Diabetic Retinopathy Based on patch attention and lesion location","Z. Xia; H. Hu; W. Li; Q. Jiang; C. Zhu; Z. Zou","School of Computer and communication engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and communication engineering, Changsha University of Science and Technology, Changsha, China; Hunan Province People's Hospital (The First Affiliated Hospital of Hunan Normal University), Changsha, China; School of Computer and communication engineering, Changsha University of Science and Technology, Changsha, China; The College of Literature and Journalism, Central South University Mobile Health Ministry of Education China Mobile Joint Laboratory, Changsha, China; School of Computer Science and Engineering, Central South University, Changsha, China","2023 International Joint Conference on Neural Networks (IJCNN)","2 Aug 2023","2023","","","1","8","In order to solve the problem that the existing methods in the field of diabetic retinopathy (DR) intelligent diagnosis have not fully exploited the effective DR lesion information in the fundus map, as well as the problem that the traditional attention mechanism have not fully explored the influencing factors of different lesion category in DR grading. This paper proposed a diagnostic method that fuses multi-level patch attention and lesion location. The method contains a multi-level patch lesion attention generator (MPAG) and lesion location module (LLM). The MPAG generates a attention map containing the lesion level imformation of different fundus patches, which is weighted with the fundus map and classified by a global network. The LLM is able to indicate lesion and generate a localization-based global attention and increasing the weights of lesion details in the classification network. This paper demonstrated the effectiveness of the proposed method through extensive experiments on the DDR dataset, obtained an accuracy of 0.8064.","2161-4407","978-1-6654-8867-9","10.1109/IJCNN54540.2023.10191557","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10191557","DR diagnosis;deep learning;multi-level patch attention mechanism;lesion localization;DDR dataset","Location awareness;Training;Diabetic retinopathy;Neural networks;Object detection;Medical services;Robustness","","1","","27","IEEE","2 Aug 2023","","","IEEE","IEEE Conferences"
"ChatGPT: More Human-Like Than Computer-Like, but Not Necessarily in a Good Way","A. Azaria","School of Computer Science, Ariel University","2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)","20 Dec 2023","2023","","","468","473","Large language models have been shown to be useful in multiple domains including conversational agents, education, and explainable AI. ChatGPT is a large language model developed by OpenAI as a conversational agent. ChatGPT was trained on data generated by humans and by receiving human feedback. This training process results in a bias toward humans’ traits and preferences. In this paper, we stress multiple biases of ChatGPT, and show that its responses demonstrate many human traits. We begin by showing a very high correlation between the frequency of digits generated by ChatGPT and humans’ favorite numbers, with the most frequent digit generated by ChatGPT, matching humans’ most favorable number, 7. We continue by showing that ChatGPT’s responses in several social experiments are much closer to those of humans’ than to those of fully rational agents. Finally, we show that several cognitive biases, known in humans, are also present in ChatGPT’s responses.","2375-0197","979-8-3503-4273-4","10.1109/ICTAI59109.2023.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356430","Cognitive biases;Rational behavior;ChatGPT","Training;Correlation;Chatbots;Behavioral sciences;Artificial intelligence;Stress","","2","","32","IEEE","20 Dec 2023","","","IEEE","IEEE Conferences"
