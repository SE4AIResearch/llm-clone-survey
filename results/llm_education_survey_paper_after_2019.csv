id,title,bibtex,url,doi,source,year
1,Examples and tutorials on using Google Colab and Gradio to create online interactive student-learning modules,"@article{2-s2.0-85186584200,
  title={Examples and tutorials on using Google Colab and Gradio to create online interactive student-learning modules},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186584200&origin=inward,10.1002/cae.22729,scopus,2024
18,Advanced SXO Techniques," @inbook{Kr_ger_2023, title={Advanced SXO Techniques}, ISBN={9781484292129}, ISSN={2945-7807}, url={http://dx.doi.org/10.1007/978-1-4842-9212-9_4}, DOI={10.1007/978-1-4842-9212-9_4}, booktitle={Design Thinking}, publisher={Apress}, author={Krüger, Zuzanna}, year={2023}, pages={195–232} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9212-9_4,10.1007/978-1-4842-9212-9_4,springer,2023
19,Fundamentals of Natural Language Processing," @inbook{Trivedi_2023, title={Fundamentals of Natural Language Processing}, ISBN={9781484292211}, ISSN={2731-877X}, url={http://dx.doi.org/10.1007/978-1-4842-9221-1_5}, DOI={10.1007/978-1-4842-9221-1_5}, booktitle={Certification Study Companion Series}, publisher={Apress}, author={Trivedi, Krunal S.}, year={2023}, pages={119–180} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9221-1_5,10.1007/978-1-4842-9221-1_5,springer,2023
20,Data," @inbook{Taulli_2023, title={Data: The Fuel for Generative AI}, ISBN={9781484293676}, url={http://dx.doi.org/10.1007/978-1-4842-9367-6_2}, DOI={10.1007/978-1-4842-9367-6_2}, booktitle={Generative AI}, publisher={Apress}, author={Taulli, Tom}, year={2023}, pages={21–45} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9367-6_2,10.1007/978-1-4842-9367-6_2,springer,2023
21,Large Language Models," @inbook{Taulli_2023, title={Large Language Models: How Generative AI Understands Language}, ISBN={9781484293676}, url={http://dx.doi.org/10.1007/978-1-4842-9367-6_5}, DOI={10.1007/978-1-4842-9367-6_5}, booktitle={Generative AI}, publisher={Apress}, author={Taulli, Tom}, year={2023}, pages={93–125} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9367-6_5,10.1007/978-1-4842-9367-6_5,springer,2023
22,The Transformation of Business," @inbook{Taulli_2023, title={The Transformation of Business: Leveraging Generative AI for a Company’s Operations}, ISBN={9781484293676}, url={http://dx.doi.org/10.1007/978-1-4842-9367-6_7}, DOI={10.1007/978-1-4842-9367-6_7}, booktitle={Generative AI}, publisher={Apress}, author={Taulli, Tom}, year={2023}, pages={145–174} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9367-6_7,10.1007/978-1-4842-9367-6_7,springer,2023
23,The Impact on Major Industries," @inbook{Taulli_2023, title={The Impact on Major Industries: A Look at Music, Education, Journalism, Gaming, Healthcare, and Finance}, ISBN={9781484293676}, url={http://dx.doi.org/10.1007/978-1-4842-9367-6_8}, DOI={10.1007/978-1-4842-9367-6_8}, booktitle={Generative AI}, publisher={Apress}, author={Taulli, Tom}, year={2023}, pages={175–188} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9367-6_8,10.1007/978-1-4842-9367-6_8,springer,2023
24,Generating Creativity from Negativity," @inbook{Parra_Pennefather_2023, title={Generating Creativity from Negativity}, ISBN={9781484295793}, ISSN={2945-7807}, url={http://dx.doi.org/10.1007/978-1-4842-9579-3_1}, DOI={10.1007/978-1-4842-9579-3_1}, booktitle={Design Thinking}, publisher={Apress}, author={Parra Pennefather, Patrick}, year={2023}, pages={1–26} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9579-3_1,10.1007/978-1-4842-9579-3_1,springer,2023
25,Use Cases," @inbook{Parra_Pennefather_2023, title={Use Cases}, ISBN={9781484295793}, ISSN={2945-7807}, url={http://dx.doi.org/10.1007/978-1-4842-9579-3_12}, DOI={10.1007/978-1-4842-9579-3_12}, booktitle={Design Thinking}, publisher={Apress}, author={Parra Pennefather, Patrick}, year={2023}, pages={339–385} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9579-3_12,10.1007/978-1-4842-9579-3_12,springer,2023
26,Future Trends in AI and Its Considerations for Business," @inbook{Campos_Zabala_2023, title={Future Trends in AI and Its Considerations for Business}, ISBN={9781484296691}, url={http://dx.doi.org/10.1007/978-1-4842-9669-1_23}, DOI={10.1007/978-1-4842-9669-1_23}, booktitle={Grow Your Business with AI}, publisher={Apress}, author={Campos Zabala, Francisco Javier}, year={2023}, pages={523–547} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9669-1_23,10.1007/978-1-4842-9669-1_23,springer,2023
27,The Practical Concepts of Machine Learning," @inbook{Kashyap_2023, title={The Practical Concepts of Machine Learning}, ISBN={9781484298015}, url={http://dx.doi.org/10.1007/978-1-4842-9801-5_2}, DOI={10.1007/978-1-4842-9801-5_2}, booktitle={Machine Learning for Decision Makers}, publisher={Apress}, author={Kashyap, Patanjali}, year={2023}, month=dec, pages={65–164} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9801-5_2,10.1007/978-1-4842-9801-5_2,springer,2024
28,Understanding AI," @inbook{Taulli_2023, title={Understanding AI: Machine Learning, Deep Learning, and Generative AI}, ISBN={9781484298527}, url={http://dx.doi.org/10.1007/978-1-4842-9852-7_7}, DOI={10.1007/978-1-4842-9852-7_7}, booktitle={ChatGPT and Bard for Business Automation}, publisher={Apress}, author={Taulli, Tom}, year={2023}, pages={107–131} }
",https://link.springer.com/chapter/10.1007/978-1-4842-9852-7_7,10.1007/978-1-4842-9852-7_7,springer,2023
30,So What’s the Plan? Mining Strategic Planning Documents," @inbook{Artemova_2020, title={So What’s the Plan? Mining Strategic Planning Documents}, ISBN={9783030652180}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-030-65218-0_16}, DOI={10.1007/978-3-030-65218-0_16}, booktitle={Digital Transformation and Global Society}, publisher={Springer International Publishing}, author={Artemova, Ekaterina and Batura, Tatiana and Golenkovskaya, Anna and Ivanin, Vitaly and Ivanov, Vladimir and Sarkisyan, Veronika and Smurov, Ivan and Tutubalina, Elena}, year={2020}, pages={208–222} }
",https://link.springer.com/chapter/10.1007/978-3-030-65218-0_16,10.1007/978-3-030-65218-0_16,springer,2020
31,Legal Tech and Lawtech: Towards a Framework for Technological Trends in the Legal Services Industry," @inbook{Harper_2021, title={Legal Tech and Lawtech: Towards a Framework for Technological Trends in the Legal Services Industry}, ISBN={9783030666613}, url={http://dx.doi.org/10.1007/978-3-030-66661-3_11}, DOI={10.1007/978-3-030-66661-3_11}, booktitle={Market Engineering}, publisher={Springer International Publishing}, author={Harper, Ciaran M. and Zhang, S. Sarah}, year={2021}, pages={183–197} }
",https://link.springer.com/chapter/10.1007/978-3-030-66661-3_11,10.1007/978-3-030-66661-3_11,springer,2021
32,Learner Models for MOOC in a Lifelong Learning Context: A Systematic Literature Review," @inbook{Ram_rez_Luelmo_2021, title={Learner Models for MOOC in a Lifelong Learning Context: A Systematic Literature Review}, ISBN={9783030864392}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-030-86439-2_20}, DOI={10.1007/978-3-030-86439-2_20}, booktitle={Computer Supported Education}, publisher={Springer International Publishing}, author={Ramírez Luelmo, Sergio Iván and El Mawas, Nour and Heutte, Jean}, year={2021}, pages={392–415} }
",https://link.springer.com/chapter/10.1007/978-3-030-86439-2_20,10.1007/978-3-030-86439-2_20,springer,2021
33,Exploring Unique App Signature of the Depressed and Non-depressed Through Their Fingerprints on Apps," @inbook{Ahmed_2022, title={Exploring Unique App Signature of the Depressed and Non-depressed Through Their Fingerprints on Apps}, ISBN={9783030991944}, ISSN={1867-822X}, url={http://dx.doi.org/10.1007/978-3-030-99194-4_15}, DOI={10.1007/978-3-030-99194-4_15}, booktitle={Pervasive Computing Technologies for Healthcare}, publisher={Springer International Publishing}, author={Ahmed, Md. Sabbir and Ahmed, Nova}, year={2022}, pages={218–239} }
",https://link.springer.com/chapter/10.1007/978-3-030-99194-4_15,10.1007/978-3-030-99194-4_15,springer,2022
34,The Ethics of Computational Social Science," @inbook{Leslie_2023, title={The Ethics of Computational Social Science}, ISBN={9783031166242}, url={http://dx.doi.org/10.1007/978-3-031-16624-2_4}, DOI={10.1007/978-3-031-16624-2_4}, booktitle={Handbook of Computational Social Science for Policy}, publisher={Springer International Publishing}, author={Leslie, David}, year={2023}, pages={57–104} }
",https://link.springer.com/chapter/10.1007/978-3-031-16624-2_4,10.1007/978-3-031-16624-2_4,springer,2023
35,Resources and Conclusions," @inbook{Guzdial_2022, title={Resources and Conclusions}, ISBN={9783031167195}, ISSN={2573-6493}, url={http://dx.doi.org/10.1007/978-3-031-16719-5_13}, DOI={10.1007/978-3-031-16719-5_13}, booktitle={Synthesis Lectures on Games and Computational Intelligence}, publisher={Springer International Publishing}, author={Guzdial, Matthew and Snodgrass, Sam and Summerville, Adam J.}, year={2022}, pages={215–224} }
",https://link.springer.com/chapter/10.1007/978-3-031-16719-5_13,10.1007/978-3-031-16719-5_13,springer,2022
36,"Influence of Artificial Intelligence in Higher Education; Impact, Risk and Counter Measure"," @inbook{Nipun_2023, title={Influence of Artificial Intelligence in Higher Education; Impact, Risk and Counter Measure}, ISBN={9783031336270}, ISSN={2363-9466}, url={http://dx.doi.org/10.1007/978-3-031-33627-0_7}, DOI={10.1007/978-3-031-33627-0_7}, booktitle={AI, Blockchain and Self-Sovereign Identity in Higher Education}, publisher={Springer Nature Switzerland}, author={Nipun, Musarrat Saberin and Talukder, Md.Simul Hasan and Butt, Usman Javed and Sulaiman, Rejwan Bin}, year={2023}, pages={143–166} }
",https://link.springer.com/chapter/10.1007/978-3-031-33627-0_7,10.1007/978-3-031-33627-0_7,springer,2023
37,"Reflections on Automation, Learnability and Expressiveness in Logic-Based Programming Languages"," @inbook{Tarau_2023, title={Reflections on Automation, Learnability and Expressiveness in Logic-Based Programming Languages}, ISBN={9783031352546}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-35254-6_29}, DOI={10.1007/978-3-031-35254-6_29}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Tarau, Paul}, year={2023}, pages={359–371} }
",https://link.springer.com/chapter/10.1007/978-3-031-35254-6_29,10.1007/978-3-031-35254-6_29,springer,2023
38,"Prolog: Past, Present, and Future"," @inbook{Gupta_2023, title={Prolog: Past, Present, and Future}, ISBN={9783031352546}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-35254-6_4}, DOI={10.1007/978-3-031-35254-6_4}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Gupta, Gopal and Salazar, Elmer and Shakerin, Farhad and Arias, Joaquín and Varanasi, Sarat Chandra and Basu, Kinjal and Wang, Huaduo and Li, Fang and Erbatur, Serdar and Padalkar, Parth and Rajasekharan, Abhiramon and Zeng, Yankai and Carro, Manuel}, year={2023}, pages={48–61} }
",https://link.springer.com/chapter/10.1007/978-3-031-35254-6_4,10.1007/978-3-031-35254-6_4,springer,2023
39,Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification," @inbook{Clavi__2023, title={Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification}, ISBN={9783031353208}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-35320-8_1}, DOI={10.1007/978-3-031-35320-8_1}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Clavié, Benjamin and Ciceu, Alexandru and Naylor, Frederick and Soulié, Guillaume and Brightwell, Thomas}, year={2023}, pages={3–17} }
",https://link.springer.com/chapter/10.1007/978-3-031-35320-8_1,10.1007/978-3-031-35320-8_1,springer,2023
40,Philosophical and Social Realm," @inbook{Aber_ek_2023, title={Philosophical and Social Realm}, ISBN={9783031353314}, url={http://dx.doi.org/10.1007/978-3-031-35331-4_2}, DOI={10.1007/978-3-031-35331-4_2}, booktitle={AI and Cognitive Modelling for Education}, publisher={Springer International Publishing}, author={Aberšek, Boris and Flogie, Andrej and Pesek, Igor}, year={2023}, pages={7–117} }
",https://link.springer.com/chapter/10.1007/978-3-031-35331-4_2,10.1007/978-3-031-35331-4_2,springer,2023
41,Automated Program Repair Using Generative Models for Code Infilling," @inbook{Koutcheme_2023, title={Automated Program Repair Using Generative Models for Code Infilling}, ISBN={9783031362729}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-36272-9_74}, DOI={10.1007/978-3-031-36272-9_74}, booktitle={Artificial Intelligence in Education}, publisher={Springer Nature Switzerland}, author={Koutcheme, Charles and Sarsa, Sami and Leinonen, Juho and Hellas, Arto and Denny, Paul}, year={2023}, pages={798–803} }
",https://link.springer.com/chapter/10.1007/978-3-031-36272-9_74,10.1007/978-3-031-36272-9_74,"springer, scopus",2023
42,Training Language Models for Programming Feedback Using Automated Repair Tools," @inbook{Koutcheme_2023, title={Training Language Models for Programming Feedback Using Automated Repair Tools}, ISBN={9783031362729}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-36272-9_79}, DOI={10.1007/978-3-031-36272-9_79}, booktitle={Artificial Intelligence in Education}, publisher={Springer Nature Switzerland}, author={Koutcheme, Charles}, year={2023}, pages={830–835} }
",https://link.springer.com/chapter/10.1007/978-3-031-36272-9_79,10.1007/978-3-031-36272-9_79,"springer, scopus",2023
43,Four Interactions Between AI and Education: Broadening Our Perspective on What AI Can Offer Education," @inbook{Rismanchian_2023, title={Four Interactions Between AI and Education: Broadening Our Perspective on What AI Can Offer Education}, ISBN={9783031363368}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-36336-8_1}, DOI={10.1007/978-3-031-36336-8_1}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Switzerland}, author={Rismanchian, Sina and Doroudi, Shayan}, year={2023}, pages={1–12} }
",https://link.springer.com/chapter/10.1007/978-3-031-36336-8_1,10.1007/978-3-031-36336-8_1,springer,2023
44,A Software Platform for Evaluating Student Essays in Interdisciplinary Learning with Topic Classification Techniques," @inbook{Yee_2023, title={A Software Platform for Evaluating Student Essays in Interdisciplinary Learning with Topic Classification Techniques}, ISBN={9783031363368}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-36336-8_100}, DOI={10.1007/978-3-031-36336-8_100}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Switzerland}, author={Yee, Bryan Lim Cheng and Hou, Chenyu and Zhu, Gaoxia and Lim, Fun Siong and Lyu, Shengfei and Fan, Xiuyi}, year={2023}, pages={645–651} }
",https://link.springer.com/chapter/10.1007/978-3-031-36336-8_100,10.1007/978-3-031-36336-8_100,springer,2023
45,Empowering Education with LLMs - The Next-Gen Interface and Content Generation," @inbook{Moore_2023, title={Empowering Education with LLMs - The Next-Gen Interface and Content Generation}, ISBN={9783031363368}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-36336-8_4}, DOI={10.1007/978-3-031-36336-8_4}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Switzerland}, author={Moore, Steven and Tong, Richard and Singh, Anjali and Liu, Zitao and Hu, Xiangen and Lu, Yu and Liang, Joleen and Cao, Chen and Khosravi, Hassan and Denny, Paul and Brooks, Chris and Stamper, John}, year={2023}, pages={32–37} }
",https://link.springer.com/chapter/10.1007/978-3-031-36336-8_4,10.1007/978-3-031-36336-8_4,springer,2023
46,The Future of Humans and Language Models," @inbook{Kurpicz_Briki_2023, title={The Future of Humans and Language Models}, ISBN={9783031376900}, url={http://dx.doi.org/10.1007/978-3-031-37690-0_7}, DOI={10.1007/978-3-031-37690-0_7}, booktitle={More than a Chatbot}, publisher={Springer Nature Switzerland}, author={Kurpicz-Briki, Mascha}, year={2023}, pages={115–123} }
",https://link.springer.com/chapter/10.1007/978-3-031-37690-0_7,10.1007/978-3-031-37690-0_7,springer,2023
47,Analyzing the Innovative Potential of Texts Generated by Large Language Models: An Empirical Evaluation," @inbook{Krauss_2023, title={Analyzing the Innovative Potential of Texts Generated by Large Language Models: An Empirical Evaluation}, ISBN={9783031396892}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-39689-2_2}, DOI={10.1007/978-3-031-39689-2_2}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Switzerland}, author={Krauss, Oliver and Jungwirth, Michaela and Elflein, Marius and Sandler, Simone and Altenhofer, Christian and Stoeckl, Andreas}, year={2023}, pages={11–22} }
",https://link.springer.com/chapter/10.1007/978-3-031-39689-2_2,10.1007/978-3-031-39689-2_2,springer,2023
48,"Conversational Process Modelling: State of the Art, Applications, and Implications in Practice"," @inbook{Klievtsova_2023, title={Conversational Process Modelling: State of the Art, Applications, and Implications in Practice}, ISBN={9783031416231}, ISSN={1865-1356}, url={http://dx.doi.org/10.1007/978-3-031-41623-1_19}, DOI={10.1007/978-3-031-41623-1_19}, booktitle={Business Process Management Forum}, publisher={Springer Nature Switzerland}, author={Klievtsova, Nataliia and Benzin, Janik-Vasily and Kampik, Timotheus and Mangler, Juergen and Rinderle-Ma, Stefanie}, year={2023}, pages={319–336} }
",https://link.springer.com/chapter/10.1007/978-3-031-41623-1_19,10.1007/978-3-031-41623-1_19,springer,2023
49,Requirements Engineering for Cyber-Physical Products," @inbook{Fehlmann_2023, title={Requirements Engineering for Cyber-Physical Products: Software Process Improvement for Intelligent Systems}, ISBN={9783031423079}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-42307-9_23}, DOI={10.1007/978-3-031-42307-9_23}, booktitle={Systems, Software and Services Process Improvement}, publisher={Springer Nature Switzerland}, author={Fehlmann, Thomas and Kranich, Eberhard}, year={2023}, pages={329–342} }
",https://link.springer.com/chapter/10.1007/978-3-031-42307-9_23,10.1007/978-3-031-42307-9_23,springer,2023
50,PapagAI: Automated Feedback for Reflective Essays," @inbook{Solopova_2023, title={PapagAI: Automated Feedback for Reflective Essays}, ISBN={9783031426087}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-42608-7_16}, DOI={10.1007/978-3-031-42608-7_16}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Solopova, Veronika and Rostom, Eiad and Cremer, Fritz and Gruszczynski, Adrian and Witte, Sascha and Zhang, Chengming and López, Fernando Ramos and Plößl, Lea and Hofmann, Florian and Romeike, Ralf and Gläser-Zikuda, Michaela and Benzmüller, Christoph and Landgraf, Tim}, year={2023}, pages={198–206} }
",https://link.springer.com/chapter/10.1007/978-3-031-42608-7_16,10.1007/978-3-031-42608-7_16,springer,2023
51,"Large Language Model Assisted Software Engineering: Prospects, Challenges, and a Case Study"," @inbook{Belzner_2023, title={Large Language Model Assisted Software Engineering: Prospects, Challenges, and a Case Study}, ISBN={9783031460029}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-46002-9_23}, DOI={10.1007/978-3-031-46002-9_23}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Belzner, Lenz and Gabor, Thomas and Wirsing, Martin}, year={2023}, month=dec, pages={355–374} }
",https://link.springer.com/chapter/10.1007/978-3-031-46002-9_23,10.1007/978-3-031-46002-9_23,springer,2024
52,Generative AI as a Supportive Tool for Scientific Research," @inbook{Weinberg_2024, title={Generative AI as a Supportive Tool for Scientific Research}, ISBN={9783031462382}, url={http://dx.doi.org/10.1007/978-3-031-46238-2_1}, DOI={10.1007/978-3-031-46238-2_1}, booktitle={Applications of Generative AI}, publisher={Springer International Publishing}, author={Weinberg, Abraham Itzhak}, year={2024}, pages={1–21} }
",https://link.springer.com/chapter/10.1007/978-3-031-46238-2_1,10.1007/978-3-031-46238-2_1,springer,2024
53,The Economics of Generative AI," @inbook{Ivanov_2024, title={The Economics of Generative AI}, ISBN={9783031462382}, url={http://dx.doi.org/10.1007/978-3-031-46238-2_25}, DOI={10.1007/978-3-031-46238-2_25}, booktitle={Applications of Generative AI}, publisher={Springer International Publishing}, author={Ivanov, Stanislav}, year={2024}, pages={491–502} }
",https://link.springer.com/chapter/10.1007/978-3-031-46238-2_25,10.1007/978-3-031-46238-2_25,springer,2024
54,Comparative Quality Analysis of GPT-Based Multiple Choice Question Generation," @inbook{Gr_visse_2023, title={Comparative Quality Analysis of GPT-Based Multiple Choice Question Generation}, ISBN={9783031468131}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-46813-1_29}, DOI={10.1007/978-3-031-46813-1_29}, booktitle={Applied Informatics}, publisher={Springer Nature Switzerland}, author={Grévisse, Christian}, year={2023}, month=oct, pages={435–447} }
",https://link.springer.com/chapter/10.1007/978-3-031-46813-1_29,10.1007/978-3-031-46813-1_29,springer,2024
55,Learning Hierarchical Robot Skills Represented by Behavior Trees from Natural Language," @inbook{Wang_2023, title={Learning Hierarchical Robot Skills Represented by Behavior Trees from Natural Language}, ISBN={9783031468469}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-46846-9_20}, DOI={10.1007/978-3-031-46846-9_20}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Wang, Kaiyi and Zhao, Yongjia and Dai, Shuling and Yang, Minghao and He, Yichen and Zhang, Ning}, year={2023}, month=oct, pages={366–383} }
",https://link.springer.com/chapter/10.1007/978-3-031-46846-9_20,10.1007/978-3-031-46846-9_20,springer,2024
56,State of the Art of Machine Learning," @inbook{Hossain_2023, title={State of the Art of Machine Learning}, ISBN={9783031469909}, url={http://dx.doi.org/10.1007/978-3-031-46990-9_7}, DOI={10.1007/978-3-031-46990-9_7}, booktitle={Machine Learning Crash Course for Engineers}, publisher={Springer International Publishing}, author={Hossain, Eklas}, year={2023}, month=oct, pages={397–443} }
",https://link.springer.com/chapter/10.1007/978-3-031-46990-9_7,10.1007/978-3-031-46990-9_7,springer,2024
57,From nCoder to ChatGPT: From Automated Coding to Refining Human Coding," @inbook{Zambrano_2023, title={From nCoder to ChatGPT: From Automated Coding to Refining Human Coding}, ISBN={9783031470141}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-47014-1_32}, DOI={10.1007/978-3-031-47014-1_32}, booktitle={Advances in Quantitative Ethnography}, publisher={Springer Nature Switzerland}, author={Zambrano, Andres Felipe and Liu, Xiner and Barany, Amanda and Baker, Ryan S. and Kim, Juhan and Nasiar, Nidhi}, year={2023}, pages={470–485} }
",https://link.springer.com/chapter/10.1007/978-3-031-47014-1_32,10.1007/978-3-031-47014-1_32,springer,2023
58,LLMs4OL: Large Language Models for Ontology Learning," @inbook{Babaei_Giglou_2023, title={LLMs4OL: Large Language Models for Ontology Learning}, ISBN={9783031472404}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-47240-4_22}, DOI={10.1007/978-3-031-47240-4_22}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Babaei Giglou, Hamed and D’Souza, Jennifer and Auer, Sören}, year={2023}, pages={408–427} }
",http://dx.doi.org/10.1007/978-3-031-47240-4_22,10.1007/978-3-031-47240-4_22,web_of_science,2023
59,Assessing ChatGPT’s Proficiency in CS1-Level Problem Solving," @inbook{S_nchez_2023, title={Assessing ChatGPT’s Proficiency in CS1-Level Problem Solving}, ISBN={9783031473722}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-47372-2_7}, DOI={10.1007/978-3-031-47372-2_7}, booktitle={Advances in Computing}, publisher={Springer Nature Switzerland}, author={Sánchez, Mario and Herrera, Andrea}, year={2023}, month=nov, pages={71–81} }
",https://link.springer.com/chapter/10.1007/978-3-031-47372-2_7,10.1007/978-3-031-47372-2_7,springer,2024
60,Lost in Transformation: Rediscovering LLM-Generated Campaigns in Social Media," @inbook{Grimme_2023, title={Lost in Transformation: Rediscovering LLM-Generated Campaigns in Social Media}, ISBN={9783031478963}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-47896-3_6}, DOI={10.1007/978-3-031-47896-3_6}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Grimme, Britta and Pohl, Janina and Winkelmann, Hendrik and Stampe, Lucas and Grimme, Christian}, year={2023}, pages={72–87} }
",http://dx.doi.org/10.1007/978-3-031-47896-3_6,10.1007/978-3-031-47896-3_6,web_of_science,2023
61,How Can Natural Language Processing and Generative AI Address Grand Challenges of Quantitative User Personas?," @inbook{Salminen_2023, title={How Can Natural Language Processing and Generative AI Address Grand Challenges of Quantitative User Personas?}, ISBN={9783031480577}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-48057-7_14}, DOI={10.1007/978-3-031-48057-7_14}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Salminen, Joni and Jung, Soon-gyo and Almerekhi, Hind and Cambria, Erik and Jansen, Bernard}, year={2023}, pages={211–231} }
",https://link.springer.com/chapter/10.1007/978-3-031-48057-7_14,10.1007/978-3-031-48057-7_14,springer,2023
62,Acceptance of Generative AI in the Creative Industry: Examining the Role of AI Anxiety in the UTAUT2 Model," @inbook{Yin_2023, title={Acceptance of Generative AI in the Creative Industry: Examining the Role of AI Anxiety in the UTAUT2 Model}, ISBN={9783031480577}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-48057-7_18}, DOI={10.1007/978-3-031-48057-7_18}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Yin, Ming and Han, Bingxu and Ryu, Sunghan and Hua, Min}, year={2023}, pages={288–310} }
",https://link.springer.com/chapter/10.1007/978-3-031-48057-7_18,10.1007/978-3-031-48057-7_18,springer,2023
63,Demystifying the Impact of ChatGPT on Teaching and Learning," @inbook{Gundu_2023, title={Demystifying the Impact of ChatGPT on Teaching and Learning}, ISBN={9783031485367}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-48536-7_7}, DOI={10.1007/978-3-031-48536-7_7}, booktitle={ICT Education}, publisher={Springer Nature Switzerland}, author={Gundu, Tapiwa and Chibaya, Colin}, year={2023}, month=nov, pages={93–104} }
",https://link.springer.com/chapter/10.1007/978-3-031-48536-7_7,10.1007/978-3-031-48536-7_7,springer,2024
64,ChatGPT as a Fullstack Web Developer - Early Results,"@article{2-s2.0-85181976399,
  title={ChatGPT as a Fullstack Web Developer - Early Results},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85181976399&origin=inward,10.1007/978-3-031-48550-3_20,scopus,2024
65,Adaptation of Enterprise Modeling Methods for Large Language Models," @inbook{Barn_2023, title={Adaptation of Enterprise Modeling Methods for Large Language Models}, ISBN={9783031485831}, ISSN={1865-1356}, url={http://dx.doi.org/10.1007/978-3-031-48583-1_1}, DOI={10.1007/978-3-031-48583-1_1}, booktitle={The Practice of Enterprise Modeling}, publisher={Springer Nature Switzerland}, author={Barn, Balbir S. and Barat, Souvik and Sandkuhl, Kurt}, year={2023}, month=nov, pages={3–18} }
",https://link.springer.com/chapter/10.1007/978-3-031-48583-1_1,10.1007/978-3-031-48583-1_1,springer,2024
66,Analyzing Scrum Team Impediments Using NLP," @inbook{Kaleemunnisa_2023, title={Analyzing Scrum Team Impediments Using NLP}, ISBN={9783031486395}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-48639-5_4}, DOI={10.1007/978-3-031-48639-5_4}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Kaleemunnisa and Scharff, Christelle and Bathula, Krishna Mohan and Chen, Kaiyin}, year={2023}, pages={42–55} }
",https://link.springer.com/chapter/10.1007/978-3-031-48639-5_4,10.1007/978-3-031-48639-5_4,"springer, web_of_science, scopus",2023
67,Towards LLM-Based System Migration in Language-Driven Engineering,"@article{2-s2.0-85180157925,
  title={Towards LLM-Based System Migration in Language-Driven Engineering},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180157925&origin=inward,10.1007/978-3-031-49252-5_14,scopus,2024
68,KG-CTG: Citation Generation Through Knowledge Graph-Guided Large Language Models," @inbook{Anand_2023, title={KG-CTG: Citation Generation Through Knowledge Graph-Guided Large Language Models}, ISBN={9783031496011}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-49601-1_3}, DOI={10.1007/978-3-031-49601-1_3}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Anand, Avinash and Gupta, Mohit and Prasad, Kritarth and Goel, Ujjwal and Lal, Naman and Verma, Astha and Shah, Rajiv Ratn}, year={2023}, pages={37–49} }
",https://link.springer.com/chapter/10.1007/978-3-031-49601-1_3,10.1007/978-3-031-49601-1_3,springer,2023
69,Large Language Model for Geometric Algebra: A Preliminary Attempt," @inbook{Wang_2023, title={Large Language Model for Geometric Algebra: A Preliminary Attempt}, ISBN={9783031500787}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-50078-7_19}, DOI={10.1007/978-3-031-50078-7_19}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Wang, Jian and Wang, Ziqiang and Wang, Han and Luo, Wen and Yuan, Linwang and Lü, Guonian and Yu, Zhaoyuan}, year={2023}, month=dec, pages={237–249} }
",https://link.springer.com/chapter/10.1007/978-3-031-50078-7_19,10.1007/978-3-031-50078-7_19,springer,2024
70,Academic Integrity in the Face of Generative Language Models," @inbook{Me_a_2023, title={Academic Integrity in the Face of Generative Language Models}, ISBN={9783031502156}, ISSN={1867-822X}, url={http://dx.doi.org/10.1007/978-3-031-50215-6_5}, DOI={10.1007/978-3-031-50215-6_5}, booktitle={Emerging Technologies in Computing}, publisher={Springer Nature Switzerland}, author={Meça, Alba and Shkëlzeni, Nirvana}, year={2023}, month=dec, pages={58–70} }
",https://link.springer.com/chapter/10.1007/978-3-031-50215-6_5,10.1007/978-3-031-50215-6_5,springer,2024
71,Performance of Large Language Models in a Computer Science Degree Program," @inbook{Kr_ger_2024, title={Performance of Large Language Models in a Computer Science Degree Program}, ISBN={9783031504853}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-50485-3_40}, DOI={10.1007/978-3-031-50485-3_40}, booktitle={Artificial Intelligence. ECAI 2023 International Workshops}, publisher={Springer Nature Switzerland}, author={Krüger, Tim and Gref, Michael}, year={2024}, pages={409–424} }
",https://link.springer.com/chapter/10.1007/978-3-031-50485-3_40,10.1007/978-3-031-50485-3_40,"springer, scopus",2024
72,Bridging the Programming Skill Gap with ChatGPT: A Machine Learning Project with Business Students," @inbook{Reiche_2024, title={Bridging the Programming Skill Gap with ChatGPT: A Machine Learning Project with Business Students}, ISBN={9783031504853}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-50485-3_42}, DOI={10.1007/978-3-031-50485-3_42}, booktitle={Artificial Intelligence. ECAI 2023 International Workshops}, publisher={Springer Nature Switzerland}, author={Reiche, Michael and Leidner, Jochen L.}, year={2024}, pages={439–446} }
",https://link.springer.com/chapter/10.1007/978-3-031-50485-3_42,10.1007/978-3-031-50485-3_42,springer,2024
73,Developments in Artificial Intelligence and Linguistics," @inbook{Ciesla_2024, title={Developments in Artificial Intelligence and Linguistics}, ISBN={9783031510045}, url={http://dx.doi.org/10.1007/978-3-031-51004-5_2}, DOI={10.1007/978-3-031-51004-5_2}, booktitle={The Book of Chatbots}, publisher={Springer Nature Switzerland}, author={Ciesla, Robert}, year={2024}, pages={11–39} }
",https://link.springer.com/chapter/10.1007/978-3-031-51004-5_2,10.1007/978-3-031-51004-5_2,springer,2024
74,The Current Era of Chatbots," @inbook{Ciesla_2024, title={The Current Era of Chatbots}, ISBN={9783031510045}, url={http://dx.doi.org/10.1007/978-3-031-51004-5_4}, DOI={10.1007/978-3-031-51004-5_4}, booktitle={The Book of Chatbots}, publisher={Springer Nature Switzerland}, author={Ciesla, Robert}, year={2024}, pages={53–89} }
",https://link.springer.com/chapter/10.1007/978-3-031-51004-5_4,10.1007/978-3-031-51004-5_4,springer,2024
75,Chatbots as Villains: The Antisocial Uses of AI," @inbook{Ciesla_2024, title={Chatbots as Villains: The Antisocial Uses of AI}, ISBN={9783031510045}, url={http://dx.doi.org/10.1007/978-3-031-51004-5_7}, DOI={10.1007/978-3-031-51004-5_7}, booktitle={The Book of Chatbots}, publisher={Springer Nature Switzerland}, author={Ciesla, Robert}, year={2024}, pages={127–150} }
",https://link.springer.com/chapter/10.1007/978-3-031-51004-5_7,10.1007/978-3-031-51004-5_7,springer,2024
76,Application of Large Language Models to DDoS Attack Detection," @inbook{Guastalla_2024, title={Application of Large Language Models to DDoS Attack Detection}, ISBN={9783031516306}, ISSN={1867-822X}, url={http://dx.doi.org/10.1007/978-3-031-51630-6_6}, DOI={10.1007/978-3-031-51630-6_6}, booktitle={Security and Privacy in Cyber-Physical Systems and Smart Vehicles}, publisher={Springer Nature Switzerland}, author={Guastalla, Michael and Li, Yiyi and Hekmati, Arvin and Krishnamachari, Bhaskar}, year={2024}, pages={83–99} }
",https://link.springer.com/chapter/10.1007/978-3-031-51630-6_6,10.1007/978-3-031-51630-6_6,springer,2024
77,Prof Pi: Using Whatsapp Bots and GPT-4 for Tutoring Mathematics in Underserved Areas," @inbook{Butgereit_2024, title={Prof Pi: Using Whatsapp Bots and GPT-4 for Tutoring Mathematics in Underserved Areas}, ISBN={9783031518492}, ISSN={1867-822X}, url={http://dx.doi.org/10.1007/978-3-031-51849-2_19}, DOI={10.1007/978-3-031-51849-2_19}, booktitle={Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering}, publisher={Springer Nature Switzerland}, author={Butgereit, Laurie and Martinus, Herman}, year={2024}, pages={278–289} }
",https://link.springer.com/chapter/10.1007/978-3-031-51849-2_19,10.1007/978-3-031-51849-2_19,"springer, springer",2024
78,Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs," @inbook{Zeng_2023, title={Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs}, ISBN={9783031520389}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-52038-9_13}, DOI={10.1007/978-3-031-52038-9_13}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Zeng, Yankai and Rajasekharan, Abhiramon and Padalkar, Parth and Basu, Kinjal and Arias, Joaquín and Gupta, Gopal}, year={2023}, pages={204–222} }
",https://link.springer.com/chapter/10.1007/978-3-031-52038-9_13,10.1007/978-3-031-52038-9_13,springer,2023
79,Artificial Intelligence and Information Literacy: Hazards and Opportunities," @inbook{Flierl_2024, title={Artificial Intelligence and Information Literacy: Hazards and Opportunities}, ISBN={9783031530012}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-53001-2_5}, DOI={10.1007/978-3-031-53001-2_5}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Switzerland}, author={Flierl, Michael}, year={2024}, pages={52–63} }
",https://link.springer.com/chapter/10.1007/978-3-031-53001-2_5,10.1007/978-3-031-53001-2_5,"springer, springer",2024
80,A Qualitative Assessment of ChatGPT Generated Code in the Computer Science Curriculum,"@article{2-s2.0-85185711696,
  title={A Qualitative Assessment of ChatGPT Generated Code in the Computer Science Curriculum},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185711696&origin=inward,10.1007/978-3-031-53022-7_5,scopus,2024
81,"Large-Language-Models (LLM)-Based AI Chatbots: Architecture, In-Depth Analysis and Their Performance Evaluation"," @inbook{Kumar_2024, title={Large-Language-Models (LLM)-Based AI Chatbots: Architecture, In-Depth Analysis and Their Performance Evaluation}, ISBN={9783031530852}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-53085-2_20}, DOI={10.1007/978-3-031-53085-2_20}, booktitle={Recent Trends in Image Processing and Pattern Recognition}, publisher={Springer Nature Switzerland}, author={Kumar, Vimal and Srivastava, Priyam and Dwivedi, Ashay and Budhiraja, Ishan and Ghosh, Debjani and Goyal, Vikas and Arora, Ruchika}, year={2024}, pages={237–249} }
",https://link.springer.com/chapter/10.1007/978-3-031-53085-2_20,10.1007/978-3-031-53085-2_20,springer,2024
82,Business and Ethical Concerns in Domestic Conversational Generative AI-Empowered Multi-robot Systems," @inbook{Rousi_2024, title={Business and Ethical Concerns in Domestic Conversational Generative AI-Empowered Multi-robot Systems}, ISBN={9783031532276}, ISSN={1865-1356}, url={http://dx.doi.org/10.1007/978-3-031-53227-6_13}, DOI={10.1007/978-3-031-53227-6_13}, booktitle={Software Business}, publisher={Springer Nature Switzerland}, author={Rousi, Rebekah and Samani, Hooman and Mäkitalo, Niko and Vakkuri, Ville and Linkola, Simo and Kemell, Kai-Kristian and Daubaris, Paulius and Fronza, Ilenia and Mikkonen, Tommi and Abrahamsson, Pekka}, year={2024}, pages={173–189} }
",https://link.springer.com/chapter/10.1007/978-3-031-53227-6_13,10.1007/978-3-031-53227-6_13,springer,2024
83,From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer Multiple-Choice Questions for Programming Classes in Higher Education," @inbook{Savelka_2024, title={From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer Multiple-Choice Questions for Programming Classes in Higher Education}, ISBN={9783031536564}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-53656-4_8}, DOI={10.1007/978-3-031-53656-4_8}, booktitle={Computer Supported Education}, publisher={Springer Nature Switzerland}, author={Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Sakr, Majd}, year={2024}, pages={160–182} }
",https://link.springer.com/chapter/10.1007/978-3-031-53656-4_8,10.1007/978-3-031-53656-4_8,"springer, scopus",2024
84,My Perspective," @inbook{Lipizzi_2024, title={My Perspective}, ISBN={9783031537479}, ISSN={1932-1686}, url={http://dx.doi.org/10.1007/978-3-031-53747-9_2}, DOI={10.1007/978-3-031-53747-9_2}, booktitle={Synthesis Lectures on Computer Science}, publisher={Springer International Publishing}, author={Lipizzi, Carlo}, year={2024}, pages={7–17} }
",https://link.springer.com/chapter/10.1007/978-3-031-53747-9_2,10.1007/978-3-031-53747-9_2,springer,2024
85,Zero-Shot Translation of Attention Patterns in VQA Models to Natural Language," @inbook{Salewski_2024, title={Zero-Shot Translation of Attention Patterns in VQA Models to Natural Language}, ISBN={9783031546051}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-54605-1_25}, DOI={10.1007/978-3-031-54605-1_25}, booktitle={Pattern Recognition}, publisher={Springer Nature Switzerland}, author={Salewski, Leonard and Koepke, A. Sophia and Lensch, Hendrik P. A. and Akata, Zeynep}, year={2024}, pages={378–393} }
",http://dx.doi.org/10.1007/978-3-031-54605-1_25,10.1007/978-3-031-54605-1_25,web_of_science,2024
86,Anticipating User Needs: Insights from Design Fiction on Conversational Agents for Computational Thinking," @inbook{Penney_2024, title={Anticipating User Needs: Insights from Design Fiction on Conversational Agents for Computational Thinking}, ISBN={9783031549755}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-54975-5_12}, DOI={10.1007/978-3-031-54975-5_12}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Penney, Jacob and Pimentel, João Felipe and Steinmacher, Igor and Gerosa, Marco A.}, year={2024}, pages={204–219} }
",https://link.springer.com/chapter/10.1007/978-3-031-54975-5_12,10.1007/978-3-031-54975-5_12,springer,2024
87,Personalized Persuasive Technologies in Health and Wellness: From Theory to Practice," @inbook{Alslaity_2024, title={Personalized Persuasive Technologies in Health and Wellness: From Theory to Practice}, ISBN={9783031551093}, ISSN={2524-4477}, url={http://dx.doi.org/10.1007/978-3-031-55109-3_10}, DOI={10.1007/978-3-031-55109-3_10}, booktitle={A Human-Centered Perspective of Intelligent Personalized Environments and Systems}, publisher={Springer Nature Switzerland}, author={Alslaity, Alaa and Oyebode, Oladapo and Vassileva, Julita and Orji, Rita}, year={2024}, pages={261–292} }
",https://link.springer.com/chapter/10.1007/978-3-031-55109-3_10,10.1007/978-3-031-55109-3_10,springer,2024
88,Summary," @inbook{Chodak_2024, title={Summary}, ISBN={9783031552250}, url={http://dx.doi.org/10.1007/978-3-031-55225-0_9}, DOI={10.1007/978-3-031-55225-0_9}, booktitle={The Future of E-commerce}, publisher={Springer Nature Switzerland}, author={Chodak, Grzegorz}, year={2024}, pages={261–287} }
",https://link.springer.com/chapter/10.1007/978-3-031-55225-0_9,10.1007/978-3-031-55225-0_9,springer,2024
89,Value-Based Adoption of ChatGPT in Agile Software Development: A Survey Study of Nordic Software Experts," @inbook{Nguyen_Duc_2024, title={Value-Based Adoption of ChatGPT in Agile Software Development: A Survey Study of Nordic Software Experts}, ISBN={9783031556425}, url={http://dx.doi.org/10.1007/978-3-031-55642-5_12}, DOI={10.1007/978-3-031-55642-5_12}, booktitle={Generative AI for Effective Software Development}, publisher={Springer Nature Switzerland}, author={Nguyen-Duc, Anh and Khanna, Dron}, year={2024}, pages={257–273} }
",https://link.springer.com/chapter/10.1007/978-3-031-55642-5_12,10.1007/978-3-031-55642-5_12,springer,2024
90,1 \(^{st}\) Workshop on Information Retrieval for Understudied Users (IR4U2)," @inbook{Pera_2024, title={1$$^{st}$$ Workshop on Information Retrieval for Understudied Users (IR4U2)}, ISBN={9783031560699}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-56069-9_55}, DOI={10.1007/978-3-031-56069-9_55}, booktitle={Advances in Information Retrieval}, publisher={Springer Nature Switzerland}, author={Pera, Maria Soledad and Cena, Federica and Huibers, Theo and Landoni, Monica and Mauro, Noemi and Murgia, Emiliana}, year={2024}, pages={409–414} }
",https://link.springer.com/chapter/10.1007/978-3-031-56069-9_55,10.1007/978-3-031-56069-9_55,springer,2024
91,Examining Potential Harms of Large Language Models (LLMs) in Africa," @inbook{Baguma_2024, title={Examining Potential Harms of Large Language Models (LLMs) in Africa}, ISBN={9783031563966}, ISSN={1867-822X}, url={http://dx.doi.org/10.1007/978-3-031-56396-6_1}, DOI={10.1007/978-3-031-56396-6_1}, booktitle={Safe, Secure, Ethical, Responsible Technologies and Emerging Applications}, publisher={Springer Nature Switzerland}, author={Baguma, Rehema and Namuwaya, Hajarah and Nakatumba-Nabende, Joyce and Rashid, Qazi Mamunur}, year={2024}, pages={3–19} }
",https://link.springer.com/chapter/10.1007/978-3-031-56396-6_1,10.1007/978-3-031-56396-6_1,springer,2024
92,Support to Interaction Between Medical Practitioners and Patients: A Systematic Review," @inbook{Tolulope_2024, title={Support to Interaction Between Medical Practitioners and Patients: A Systematic Review}, ISBN={9783031563966}, ISSN={1867-822X}, url={http://dx.doi.org/10.1007/978-3-031-56396-6_24}, DOI={10.1007/978-3-031-56396-6_24}, booktitle={Safe, Secure, Ethical, Responsible Technologies and Emerging Applications}, publisher={Springer Nature Switzerland}, author={Tolulope, Ezekiel Olayide and Tchakounte, Franklin}, year={2024}, pages={380–408} }
",https://link.springer.com/chapter/10.1007/978-3-031-56396-6_24,10.1007/978-3-031-56396-6_24,springer,2024
93,"Integrating LLMs in Higher Education, Through Interactive Problem Solving and Tutoring: Algorithmic Approach and Use Cases"," @inbook{Bakas_2024, title={Integrating LLMs in Higher Education, Through Interactive Problem Solving and Tutoring: Algorithmic Approach and Use Cases}, ISBN={9783031564789}, ISSN={1865-1356}, url={http://dx.doi.org/10.1007/978-3-031-56478-9_21}, DOI={10.1007/978-3-031-56478-9_21}, booktitle={Lecture Notes in Business Information Processing}, publisher={Springer Nature Switzerland}, author={Bakas, Nikolaos P. and Papadaki, Maria and Vagianou, Evgenia and Christou, Ioannis and Chatzichristofis, Savvas A.}, year={2024}, pages={291–307} }
",https://link.springer.com/chapter/10.1007/978-3-031-56478-9_21,10.1007/978-3-031-56478-9_21,"springer, scopus",2024
94,Exploring LLMs' Ability to Detect Variability in Requirements," @inbook{Fantechi_2024, title={Exploring LLMs’ Ability to Detect Variability in Requirements}, ISBN={9783031573279}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-3-031-57327-9_11}, DOI={10.1007/978-3-031-57327-9_11}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Switzerland}, author={Fantechi, Alessandro and Gnesi, Stefania and Semini, Laura}, year={2024}, pages={178–188} }
",http://dx.doi.org/10.1007/978-3-031-57327-9_11,10.1007/978-3-031-57327-9_11,web_of_science,2024
95,Optimized BERT Model for Question Answering System on Mobile Platform," @inbook{Patil_2024, title={Optimized BERT Model for Question Answering System on Mobile Platform}, ISBN={9783031584954}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-3-031-58495-4_9}, DOI={10.1007/978-3-031-58495-4_9}, booktitle={Speech and Language Technologies for Low-Resource Languages}, publisher={Springer Nature Switzerland}, author={Patil, Priyadarshini and Rao, Chandan and Meena, S. M.}, year={2024}, pages={129–139} }
",https://link.springer.com/chapter/10.1007/978-3-031-58495-4_9,10.1007/978-3-031-58495-4_9,springer,2024
96,Conversational Systems for AI-Augmented Business Process Management," @inbook{Casciani_2024, title={Conversational Systems for AI-Augmented Business Process Management}, ISBN={9783031594656}, ISSN={1865-1356}, url={http://dx.doi.org/10.1007/978-3-031-59465-6_12}, DOI={10.1007/978-3-031-59465-6_12}, booktitle={Lecture Notes in Business Information Processing}, publisher={Springer Nature Switzerland}, author={Casciani, Angelo and Bernardi, Mario L. and Cimitile, Marta and Marrella, Andrea}, year={2024}, pages={183–200} }
",https://link.springer.com/chapter/10.1007/978-3-031-59465-6_12,10.1007/978-3-031-59465-6_12,springer,2024
97,Enhancing E-Learning Experience Through Embodied AI Tutors in Immersive Virtual Environments: A Multifaceted Approach for Personalized Educational Adaptation,"@article{2-s2.0-85196174389,
  title={Enhancing E-Learning Experience Through Embodied AI Tutors in Immersive Virtual Environments: A Multifaceted Approach for Personalized Educational Adaptation},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196174389&origin=inward,10.1007/978-3-031-60609-0_20,scopus,2024
98,Conceptual Data Normalisation from the Practical View of Using Graph Databases,"@article{2-s2.0-85196186509,
  title={Conceptual Data Normalisation from the Practical View of Using Graph Databases},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196186509&origin=inward,10.1007/978-3-031-61003-5_21,scopus,2024
99,The Impact of ChatGPT on Students’ Learning Programming Languages,"@article{2-s2.0-85196858578,
  title={The Impact of ChatGPT on Students’ Learning Programming Languages},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196858578&origin=inward,10.1007/978-3-031-61691-4_14,scopus,2024
100,Exploring Explainability and Transparency in Automated Essay Scoring Systems: A User-Centered Evaluation,"@article{2-s2.0-85196844294,
  title={Exploring Explainability and Transparency in Automated Essay Scoring Systems: A User-Centered Evaluation},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196844294&origin=inward,10.1007/978-3-031-61691-4_18,scopus,2024
101,Analyzing the Role of Generative AI in Fostering Self-directed Learning Through Structured Prompt Engineering,"@article{2-s2.0-85195866768,
  title={Analyzing the Role of Generative AI in Fostering Self-directed Learning Through Structured Prompt Engineering},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195866768&origin=inward,10.1007/978-3-031-63028-6_18,scopus,2024
102,"Automated Analysis of Algorithm Descriptions Quality, Through Large Language Models","@article{2-s2.0-85195877099,
  title={Automated Analysis of Algorithm Descriptions Quality, Through Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195877099&origin=inward,10.1007/978-3-031-63028-6_20,scopus,2024
103,Improving LLM Classification of Logical Errors by Integrating Error Relationship into Prompts,"@article{2-s2.0-85195845148,
  title={Improving LLM Classification of Logical Errors by Integrating Error Relationship into Prompts},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195845148&origin=inward,10.1007/978-3-031-63028-6_8,scopus,2024
104,"How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent
  for Debugging","<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10.1007/978-3-031-64302-6_19</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10.1007/978-3-031-64302-6_19"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",http://arxiv.org/pdf/2310.05292v4.pdf,10.1007/978-3-031-64302-6_19,arxiv,2023
105,Panda3D," @inbook{Surer_2023, title={Panda3D}, ISBN={9783319082349}, url={http://dx.doi.org/10.1007/978-3-319-08234-9_535-1}, DOI={10.1007/978-3-319-08234-9_535-1}, booktitle={Encyclopedia of Computer Graphics and Games}, publisher={Springer International Publishing}, author={Surer, Elif}, year={2023}, pages={1–3} }
",https://link.springer.com/chapter/10.1007/978-3-319-08234-9_535-1,10.1007/978-3-319-08234-9_535-1,springer,2023
112,Exploring GPT-4 as MR Sequence and Reconstruction Programming Assistant," @inbook{Zaiss_2024, title={Exploring GPT-4 as MR Sequence and Reconstruction Programming Assistant: GPT4MR}, ISBN={9783658440374}, ISSN={2628-8958}, url={http://dx.doi.org/10.1007/978-3-658-44037-4_28}, DOI={10.1007/978-3-658-44037-4_28}, booktitle={Informatik aktuell}, publisher={Springer Fachmedien Wiesbaden}, author={Zaiss, Moritz and Rajput, Junaid R. and Dang, Hoai N. and Golkov, Vladimir and Cremers, Daniel and Knoll, Florian and Maier, Andreas}, year={2024}, pages={94–99} }
",https://link.springer.com/chapter/10.1007/978-3-658-44037-4_28,10.1007/978-3-658-44037-4_28,springer,2024
114,Prospects for Hybrid AI," @inbook{Mainzer_2024, title={Prospects for Hybrid AI}, ISBN={9783662682906}, ISSN={2194-0789}, url={http://dx.doi.org/10.1007/978-3-662-68290-6_5}, DOI={10.1007/978-3-662-68290-6_5}, booktitle={Limits of AI - theoretical, practical, ethical}, publisher={Springer Berlin Heidelberg}, author={Mainzer, Klaus and Kahle, Reinhard}, year={2024}, pages={113–150} }
",https://link.springer.com/chapter/10.1007/978-3-662-68290-6_5,10.1007/978-3-662-68290-6_5,springer,2024
115,Automated Comment Generation Based on the Large Language Model," @inbook{Cai_2024, title={Automated Comment Generation Based on the Large Language Model}, ISBN={9789819707300}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-981-97-0730-0_25}, DOI={10.1007/978-981-97-0730-0_25}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Singapore}, author={Cai, Kaiwei and Zhou, Junsheng and Kong, Li and Liang, Dandan and Li, Xianzhuo}, year={2024}, pages={283–294} }
",https://link.springer.com/chapter/10.1007/978-981-97-0730-0_25,10.1007/978-981-97-0730-0_25,springer,2024
116,Assistant Teaching System for Computer Hardware Courses Based on Large Language Model," @inbook{Zhang_2024, title={Assistant Teaching System for Computer Hardware Courses Based on Large Language Model}, ISBN={9789819707300}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-981-97-0730-0_27}, DOI={10.1007/978-981-97-0730-0_27}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Singapore}, author={Zhang, Dongdong and Cao, Qian and Guo, Yuchen and Wang, Lisheng}, year={2024}, pages={301–313} }
",https://link.springer.com/chapter/10.1007/978-981-97-0730-0_27,10.1007/978-981-97-0730-0_27,"springer, scopus",2024
117,Automatic Generation of Multiple-Choice Questions for CS0 and CS1 Curricula Using Large Language Models," @inbook{Song_2024, title={Automatic Generation of Multiple-Choice Questions for CS0 and CS1 Curricula Using Large Language Models}, ISBN={9789819707300}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-981-97-0730-0_28}, DOI={10.1007/978-981-97-0730-0_28}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Singapore}, author={Song, Tian and Tian, Qinqin and Xiao, Yijia and Liu, Shuting}, year={2024}, pages={314–324} }
",https://link.springer.com/chapter/10.1007/978-981-97-0730-0_28,10.1007/978-981-97-0730-0_28,springer,2024
118,Knowledge Sources," @inbook{Jiang_2024, title={Knowledge Sources}, ISBN={9789819707478}, ISSN={2191-5776}, url={http://dx.doi.org/10.1007/978-981-97-0747-8_2}, DOI={10.1007/978-981-97-0747-8_2}, booktitle={SpringerBriefs in Computer Science}, publisher={Springer Nature Singapore}, author={Jiang, Meng and Lin, Bill Yuchen and Wang, Shuohang and Xu, Yichong and Yu, Wenhao and Zhu, Chenguang}, year={2024}, pages={7–21} }
",https://link.springer.com/chapter/10.1007/978-981-97-0747-8_2,10.1007/978-981-97-0747-8_2,springer,2024
119,Growth and Branching of Natural Language Processing," @inbook{Ida_2024, title={Growth and Branching of Natural Language Processing}, ISBN={9789819707713}, url={http://dx.doi.org/10.1007/978-981-97-0771-3_6}, DOI={10.1007/978-981-97-0771-3_6}, booktitle={A Narrative History of Artificial Intelligence}, publisher={Springer Nature Singapore}, author={Ida, Masayuki}, year={2024}, pages={225–265} }
",https://link.springer.com/chapter/10.1007/978-981-97-0771-3_6,10.1007/978-981-97-0771-3_6,springer,2024
120,Design and Application of Formative Evaluation in the Artificial Intelligence Course," @inbook{Zhong_2024, title={Design and Application of Formative Evaluation in the Artificial Intelligence Course}, ISBN={9789819707911}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-981-97-0791-1_22}, DOI={10.1007/978-981-97-0791-1_22}, booktitle={Computer Science and Education. Teaching and Curriculum}, publisher={Springer Nature Singapore}, author={Zhong, Ping and Zhu, Chengyang and Duan, Guihua and Sheng, Yu and Jiang, Wanchun}, year={2024}, pages={255–260} }
",https://link.springer.com/chapter/10.1007/978-981-97-0791-1_22,10.1007/978-981-97-0791-1_22,springer,2024
121,Towards Higher Abstraction Levels in Quantum Computing," @inbook{F_rntratt_2024, title={Towards Higher Abstraction Levels in Quantum Computing}, ISBN={9789819709892}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-981-97-0989-2_13}, DOI={10.1007/978-981-97-0989-2_13}, booktitle={Service-Oriented Computing – ICSOC 2023 Workshops}, publisher={Springer Nature Singapore}, author={Fürntratt, Hermann and Schnabl, Paul and Krebs, Florian and Unterberger, Roland and Zeiner, Herwig}, year={2024}, pages={162–173} }
",https://link.springer.com/chapter/10.1007/978-981-97-0989-2_13,10.1007/978-981-97-0989-2_13,springer,2024
122,Evolution Through Large Models," @inbook{Lehman_2023, title={Evolution Through Large Models}, ISBN={9789819938148}, ISSN={1932-0175}, url={http://dx.doi.org/10.1007/978-981-99-3814-8_11}, DOI={10.1007/978-981-99-3814-8_11}, booktitle={Genetic and Evolutionary Computation}, publisher={Springer Nature Singapore}, author={Lehman, Joel and Gordon, Jonathan and Jain, Shawn and Ndousse, Kamal and Yeh, Cathy and Stanley, Kenneth O.}, year={2023}, month=nov, pages={331–366} }
",https://link.springer.com/chapter/10.1007/978-981-99-3814-8_11,10.1007/978-981-99-3814-8_11,springer,2024
123,Self-agreement: A Framework for Fine-Tuning Language Models to Find Agreement Among Diverse Opinions," @inbook{Ding_2023, title={Self-agreement: A Framework for Fine-Tuning Language Models to Find Agreement Among Diverse Opinions}, ISBN={9789819970223}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-981-99-7022-3_26}, DOI={10.1007/978-981-99-7022-3_26}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Singapore}, author={Ding, Shiyao and Ito, Takayuki}, year={2023}, month=nov, pages={298–309} }
",https://link.springer.com/chapter/10.1007/978-981-99-7022-3_26,10.1007/978-981-99-7022-3_26,springer,2024
124,Applications and Implication of Generative AI in Non-STEM Disciplines in Higher Education," @inbook{Wu_2023, title={Applications and Implication of Generative AI in Non-STEM Disciplines in Higher Education}, ISBN={9789819975877}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-981-99-7587-7_29}, DOI={10.1007/978-981-99-7587-7_29}, booktitle={Communications in Computer and Information Science}, publisher={Springer Nature Singapore}, author={Wu, Tao and Zhang, Shu hua}, year={2023}, month=nov, pages={341–349} }
",https://link.springer.com/chapter/10.1007/978-981-99-7587-7_29,10.1007/978-981-99-7587-7_29,springer,2024
125,Assessing and Enhancing LLMs: A Physics and History Dataset and One-More-Check Pipeline Method," @inbook{He_2023, title={Assessing and Enhancing LLMs: A Physics and History Dataset and One-More-Check Pipeline Method}, ISBN={9789819981786}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-981-99-8178-6_38}, DOI={10.1007/978-981-99-8178-6_38}, booktitle={Neural Information Processing}, publisher={Springer Nature Singapore}, author={He, Chaofan and Li, Chunhui and Han, Tianyuan and Shen, Liping}, year={2023}, month=nov, pages={504–517} }
",https://link.springer.com/chapter/10.1007/978-981-99-8178-6_38,10.1007/978-981-99-8178-6_38,springer,2024
126,Prompting Large Language Models to Power Educational Chatbots," @inbook{Farah_2023, title={Prompting Large Language Models to Power Educational Chatbots}, ISBN={9789819983858}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-981-99-8385-8_14}, DOI={10.1007/978-981-99-8385-8_14}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Singapore}, author={Farah, Juan Carlos and Ingram, Sandy and Spaenlehauer, Basile and Lasne, Fanny Kim-Lan and Gillet, Denis}, year={2023}, pages={169–188} }
",https://link.springer.com/chapter/10.1007/978-981-99-8385-8_14,10.1007/978-981-99-8385-8_14,"springer, scopus",2023
127,Enhancing Image Comprehension for Computer Science Visual Question Answering," @inbook{Wang_2023, title={Enhancing Image Comprehension for Computer Science Visual Question Answering}, ISBN={9789819984299}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-981-99-8429-9_39}, DOI={10.1007/978-981-99-8429-9_39}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Singapore}, author={Wang, Hongyu and Qiang, Pengpeng and Tan, Hongye and Hu, Jingchang}, year={2023}, month=dec, pages={487–498} }
",https://link.springer.com/chapter/10.1007/978-981-99-8429-9_39,10.1007/978-981-99-8429-9_39,"springer, web_of_science, scopus",2024
128,Feasibility Study on Parameter Adjustment for a Humanoid Using LLM Tailoring Physical Care," @inbook{Miyake_2023, title={Feasibility Study on Parameter Adjustment for a Humanoid Using LLM Tailoring Physical Care}, ISBN={9789819987153}, ISSN={1611-3349}, url={http://dx.doi.org/10.1007/978-981-99-8715-3_20}, DOI={10.1007/978-981-99-8715-3_20}, booktitle={Lecture Notes in Computer Science}, publisher={Springer Nature Singapore}, author={Miyake, Tamon and Wang, Yushi and Yang, Pin-chu and Sugano, Shigeki}, year={2023}, month=dec, pages={230–243} }
",https://link.springer.com/chapter/10.1007/978-981-99-8715-3_20,10.1007/978-981-99-8715-3_20,springer,2024
129,The Recent Trends of Research on GitHub Copilot: A Systematic Review," @inbook{Ani_2024, title={The Recent Trends of Research on GitHub Copilot: A Systematic Review}, ISBN={9789819995899}, ISSN={1865-0937}, url={http://dx.doi.org/10.1007/978-981-99-9589-9_27}, DOI={10.1007/978-981-99-9589-9_27}, booktitle={Computing and Informatics}, publisher={Springer Nature Singapore}, author={Ani, Zhamri Che and Hamid, Zauridah Abdul and Zhamri, Nur Nazifa}, year={2024}, pages={355–366} }
",https://link.springer.com/chapter/10.1007/978-981-99-9589-9_27,10.1007/978-981-99-9589-9_27,springer,2024
130,"Threats, Opportunities, and Misconceptions"," @inbook{Amaratunga_2023, title={Threats, Opportunities, and Misconceptions}, ISBN={9798868800177}, url={http://dx.doi.org/10.1007/979-8-8688-0017-7_6}, DOI={10.1007/979-8-8688-0017-7_6}, booktitle={Understanding Large Language Models}, publisher={Apress}, author={Amaratunga, Thimira}, year={2023}, pages={131–148} }
",https://link.springer.com/chapter/10.1007/979-8-8688-0017-7_6,10.1007/979-8-8688-0017-7_6,springer,2023
131,Understanding ChatGPT’s Underlying Technology," @inbook{Waghmare_2023, title={Understanding ChatGPT’s Underlying Technology}, ISBN={9798868800320}, url={http://dx.doi.org/10.1007/979-8-8688-0032-0_2}, DOI={10.1007/979-8-8688-0032-0_2}, booktitle={Unleashing The Power of ChatGPT}, publisher={Apress}, author={Waghmare, Charles}, year={2023}, pages={27–44} }
",https://link.springer.com/chapter/10.1007/979-8-8688-0032-0_2,10.1007/979-8-8688-0032-0_2,springer,2023
139,"The imitation game, the “child machine,” and the fathers of AI"," @article{Heffernan_2022, title={The imitation game, the “child machine,” and the fathers of AI}, volume={39}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-022-01512-0}, DOI={10.1007/s00146-022-01512-0}, number={1}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={Heffernan, Teresa}, year={2022}, month=jun, pages={353–357} }
",https://link.springer.com/article/10.1007/s00146-022-01512-0,10.1007/s00146-022-01512-0,springer,2022
140,AI ethics as subordinated innovation network," @article{Steinhoff_2023, title={AI ethics as subordinated innovation network}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-023-01658-5}, DOI={10.1007/s00146-023-01658-5}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={Steinhoff, James}, year={2023}, month=apr }
",https://link.springer.com/article/10.1007/s00146-023-01658-5,10.1007/s00146-023-01658-5,springer,2023
141,Prompting meaning: a hermeneutic approach to optimising prompt engineering with ChatGPT," @article{Henrickson_2023, title={Prompting meaning: a hermeneutic approach to optimising prompt engineering with ChatGPT}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-023-01752-8}, DOI={10.1007/s00146-023-01752-8}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={Henrickson, Leah and Meroño-Peñuela, Albert}, year={2023}, month=sep }
",https://link.springer.com/article/10.1007/s00146-023-01752-8,10.1007/s00146-023-01752-8,"springer, springer",2023
142,Friend or foe? Exploring the implications of large language models on the science system," @article{Fecher_2023, title={Friend or foe? Exploring the implications of large language models on the science system}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-023-01791-1}, DOI={10.1007/s00146-023-01791-1}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={Fecher, Benedikt and Hebing, Marcel and Laufer, Melissa and Pohle, Jörg and Sofsky, Fabian}, year={2023}, month=oct }
",https://link.springer.com/article/10.1007/s00146-023-01791-1,10.1007/s00146-023-01791-1,springer,2023
143,At the intersection of humanity and technology: a technofeminist intersectional critical discourse analysis of gender and race biases in the natural language processing model GPT-3," @article{Palacios_Barea_2023, title={At the intersection of humanity and technology: a technofeminist intersectional critical discourse analysis of gender and race biases in the natural language processing model GPT-3}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-023-01804-z}, DOI={10.1007/s00146-023-01804-z}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={Palacios Barea, M. A. and Boeren, D. and Ferreira Goncalves, J. F.}, year={2023}, month=nov }
",https://link.springer.com/article/10.1007/s00146-023-01804-z,10.1007/s00146-023-01804-z,springer,2023
144,"Artificial thinking and doomsday projections: a discourse on trust, ethics and safety"," @article{White_2023, title={Artificial thinking and doomsday projections: a discourse on trust, ethics and safety}, volume={38}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-023-01810-1}, DOI={10.1007/s00146-023-01810-1}, number={6}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={White, Jeffrey and Brandt, Dietrich and Söffner, Jan and Stapleton, Larry}, year={2023}, month=nov, pages={2119–2124} }
",https://link.springer.com/article/10.1007/s00146-023-01810-1,10.1007/s00146-023-01810-1,springer,2023
145,Machine learning in human creativity: status and perspectives," @article{Farina_2024, title={Machine learning in human creativity: status and perspectives}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-023-01836-5}, DOI={10.1007/s00146-023-01836-5}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={Farina, Mirko and Lavazza, Andrea and Sartori, Giuseppe and Pedrycz, Witold}, year={2024}, month=jan }
",https://link.springer.com/article/10.1007/s00146-023-01836-5,10.1007/s00146-023-01836-5,springer,2024
146,The work of art in the age of artificial intelligibility," @article{McLoughlin_2024, title={The work of art in the age of artificial intelligibility}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-023-01845-4}, DOI={10.1007/s00146-023-01845-4}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={McLoughlin, John}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s00146-023-01845-4,10.1007/s00146-023-01845-4,springer,2024
147,ChatGPT: towards AI subjectivity," @article{D_Amato_2024, title={ChatGPT: towards AI subjectivity}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-024-01898-z}, DOI={10.1007/s00146-024-01898-z}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={D’Amato, Kristian}, year={2024}, month=apr }
",https://link.springer.com/article/10.1007/s00146-024-01898-z,10.1007/s00146-024-01898-z,springer,2024
148,Using rhetorical strategies to design prompts: a human-in-the-loop approach to make AI useful," @article{Ranade_2024, title={Using rhetorical strategies to design prompts: a human-in-the-loop approach to make AI useful}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-024-01905-3}, DOI={10.1007/s00146-024-01905-3}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={Ranade, Nupoor and Saravia, Marly and Johri, Aditya}, year={2024}, month=apr }
",https://link.springer.com/article/10.1007/s00146-024-01905-3,10.1007/s00146-024-01905-3,springer,2024
149,Challenges as catalysts: how Waymo’s Open Dataset Challenges shape AI development," @article{Hind_2024, title={Challenges as catalysts: how Waymo’s Open Dataset Challenges shape AI development}, ISSN={1435-5655}, url={http://dx.doi.org/10.1007/s00146-024-01927-x}, DOI={10.1007/s00146-024-01927-x}, journal={AI &amp; SOCIETY}, publisher={Springer Science and Business Media LLC}, author={Hind, Sam and van der Vlist, Fernando N. and Kanderske, Max}, year={2024}, month=apr }
",https://link.springer.com/article/10.1007/s00146-024-01927-x,10.1007/s00146-024-01927-x,springer,2024
150,A survey on sentiment analysis and its applications," @article{Al_Qablan_2023, title={A survey on sentiment analysis and its applications}, volume={35}, ISSN={1433-3058}, url={http://dx.doi.org/10.1007/s00521-023-08941-y}, DOI={10.1007/s00521-023-08941-y}, number={29}, journal={Neural Computing and Applications}, publisher={Springer Science and Business Media LLC}, author={Al-Qablan, Tamara Amjad and Mohd Noor, Mohd Halim and Al-Betar, Mohammed Azmi and Khader, Ahamad Tajudin}, year={2023}, month=aug, pages={21567–21601} }
",https://link.springer.com/article/10.1007/s00521-023-08941-y,10.1007/s00521-023-08941-y,springer,2023
151,"Exploring contactless techniques in multimodal emotion recognition: insights into diverse applications, challenges, solutions, and prospects"," @article{Khan_2024, title={Exploring contactless techniques in multimodal emotion recognition: insights into diverse applications, challenges, solutions, and prospects}, volume={30}, ISSN={1432-1882}, url={http://dx.doi.org/10.1007/s00530-024-01302-2}, DOI={10.1007/s00530-024-01302-2}, number={3}, journal={Multimedia Systems}, publisher={Springer Science and Business Media LLC}, author={Khan, Umair Ali and Xu, Qianru and Liu, Yang and Lagstedt, Altti and Alamäki, Ari and Kauttonen, Janne}, year={2024}, month=apr }
",https://link.springer.com/article/10.1007/s00530-024-01302-2,10.1007/s00530-024-01302-2,springer,2024
152,Similarity-driven and task-driven models for diversity of opinion in crowdsourcing markets," @article{Zhang_2024, title={Similarity-driven and task-driven models for diversity of opinion in crowdsourcing markets}, ISSN={0949-877X}, url={http://dx.doi.org/10.1007/s00778-024-00853-0}, DOI={10.1007/s00778-024-00853-0}, journal={The VLDB Journal}, publisher={Springer Science and Business Media LLC}, author={Zhang, Chen Jason and Liu, Yunrui and Zeng, Pengcheng and Wu, Ting and Chen, Lei and Hui, Pan and Hao, Fei}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s00778-024-00853-0,10.1007/s00778-024-00853-0,springer,2024
153,A systematic review and research challenges on phishing cyberattacks from an electroencephalography and gaze-based perspective," @article{Thomopoulos_2024, title={A systematic review and research challenges on phishing cyberattacks from an electroencephalography and gaze-based perspective}, ISSN={1617-4917}, url={http://dx.doi.org/10.1007/s00779-024-01794-9}, DOI={10.1007/s00779-024-01794-9}, journal={Personal and Ubiquitous Computing}, publisher={Springer Science and Business Media LLC}, author={Thomopoulos, George A. and Lyras, Dimitrios P. and Fidas, Christos A.}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s00779-024-01794-9,10.1007/s00779-024-01794-9,springer,2024
154,"“The ChatGPT bot is causing panic now – but it’ll soon be as mundane a tool as Excel”: analysing topics, sentiment and emotions relating to ChatGPT on Twitter"," @article{Heaton_2024, title={“The ChatGPT bot is causing panic now – but it’ll soon be as mundane a tool as Excel”: analysing topics, sentiment and emotions relating to ChatGPT on Twitter}, ISSN={1617-4917}, url={http://dx.doi.org/10.1007/s00779-024-01811-x}, DOI={10.1007/s00779-024-01811-x}, journal={Personal and Ubiquitous Computing}, publisher={Springer Science and Business Media LLC}, author={Heaton, Dan and Clos, Jeremie and Nichele, Elena and Fischer, Joel E.}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s00779-024-01811-x,10.1007/s00779-024-01811-x,springer,2024
155,BiMuF: a bi-directional recommender system with multi-semantic filter for online recruitment," @article{Lai_2023, title={BiMuF: a bi-directional recommender system with multi-semantic filter for online recruitment}, volume={66}, ISSN={0219-3116}, url={http://dx.doi.org/10.1007/s10115-023-01997-1}, DOI={10.1007/s10115-023-01997-1}, number={3}, journal={Knowledge and Information Systems}, publisher={Springer Science and Business Media LLC}, author={Lai, Pei-Yuan and Yang, Zhe-Rui and Dai, Qing-Yun and Liao, De-Zhang and Wang, Chang-Dong}, year={2023}, month=oct, pages={1751–1776} }
",https://link.springer.com/article/10.1007/s10115-023-01997-1,10.1007/s10115-023-01997-1,springer,2023
156,An analysis of large language models: their impact and potential applications," @article{Bharathi_Mohan_2024, title={An analysis of large language models: their impact and potential applications}, ISSN={0219-3116}, url={http://dx.doi.org/10.1007/s10115-024-02120-8}, DOI={10.1007/s10115-024-02120-8}, journal={Knowledge and Information Systems}, publisher={Springer Science and Business Media LLC}, author={Bharathi Mohan, G. and Prasanna Kumar, R. and Vishal Krishh, P. and Keerthinathan, A. and Lavanya, G. and Meghana, Meka Kavya Uma and Sulthana, Sheba and Doss, Srinath}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s10115-024-02120-8,10.1007/s10115-024-02120-8,springer,2024
157,Situational Data Integration in Question Answering systems: a survey over two decades," @article{Franciscatto_2024, title={Situational Data Integration in Question Answering systems: a survey over two decades}, ISSN={0219-3116}, url={http://dx.doi.org/10.1007/s10115-024-02136-0}, DOI={10.1007/s10115-024-02136-0}, journal={Knowledge and Information Systems}, publisher={Springer Science and Business Media LLC}, author={Franciscatto, Maria Helena and Erpen de Bona, Luis Carlos and Trois, Celio and Didonet Del FabroFabro, Marcos and Damasceno Lima, João Carlos}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s10115-024-02136-0,10.1007/s10115-024-02136-0,springer,2024
158,LLM examiner: automating assessment in informal self-directed e-learning using ChatGPT," @article{Askarbekuly_2024, title={LLM examiner: automating assessment in informal self-directed e-learning using ChatGPT}, ISSN={0219-3116}, url={http://dx.doi.org/10.1007/s10115-024-02156-w}, DOI={10.1007/s10115-024-02156-w}, journal={Knowledge and Information Systems}, publisher={Springer Science and Business Media LLC}, author={Askarbekuly, Nursultan and Aničić, Nenad}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s10115-024-02156-w,10.1007/s10115-024-02156-w,springer,2024
159,"Generative AI for pentesting: the good, the bad, the ugly"," @article{Hilario_2024, title={Generative AI for pentesting: the good, the bad, the ugly}, volume={23}, ISSN={1615-5270}, url={http://dx.doi.org/10.1007/s10207-024-00835-x}, DOI={10.1007/s10207-024-00835-x}, number={3}, journal={International Journal of Information Security}, publisher={Springer Science and Business Media LLC}, author={Hilario, Eric and Azam, Sami and Sundaram, Jawahar and Imran Mohammed, Khwaja and Shanmugam, Bharanidharan}, year={2024}, month=mar, pages={2075–2097} }
",https://link.springer.com/article/10.1007/s10207-024-00835-x,10.1007/s10207-024-00835-x,springer,2024
160,On the assessment of generative AI in modeling tasks: an experience report with ChatGPT and UML," @article{C_mara_2023, title={On the assessment of generative AI in modeling tasks: an experience report with ChatGPT and UML}, volume={22}, ISSN={1619-1374}, url={http://dx.doi.org/10.1007/s10270-023-01105-5}, DOI={10.1007/s10270-023-01105-5}, number={3}, journal={Software and Systems Modeling}, publisher={Springer Science and Business Media LLC}, author={Cámara, Javier and Troya, Javier and Burgueño, Lola and Vallecillo, Antonio}, year={2023}, month=may, pages={781–793} }
",https://link.springer.com/article/10.1007/s10270-023-01105-5,10.1007/s10270-023-01105-5,springer,2023
161,Large language models as an “operating” system for software and systems modeling," @article{Combemale_2023, title={Large language models as an “operating” system for software and systems modeling}, volume={22}, ISSN={1619-1374}, url={http://dx.doi.org/10.1007/s10270-023-01126-0}, DOI={10.1007/s10270-023-01126-0}, number={5}, journal={Software and Systems Modeling}, publisher={Springer Science and Business Media LLC}, author={Combemale, Benoit and Gray, Jeff and Rumpe, Bernhard}, year={2023}, month=sep, pages={1391–1392} }
",https://link.springer.com/article/10.1007/s10270-023-01126-0,10.1007/s10270-023-01126-0,springer,2023
162,Generating domain models from natural language text using NLP: a benchmark dataset and experimental comparison of tools," @article{Bozyigit_2024, title={Generating domain models from natural language text using NLP: a benchmark dataset and experimental comparison of tools}, ISSN={1619-1374}, url={http://dx.doi.org/10.1007/s10270-024-01176-y}, DOI={10.1007/s10270-024-01176-y}, journal={Software and Systems Modeling}, publisher={Springer Science and Business Media LLC}, author={Bozyigit, Fatma and Bardakci, Tolgahan and Khalilipour, Alireza and Challenger, Moharram and Ramackers, Guus and Babur, Önder and Chaudron, Michel R. V.}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s10270-024-01176-y,10.1007/s10270-024-01176-y,springer,2024
163,An association between fingerprint patterns with blood group and lifestyle based diseases: a review," @article{Patil_2020, title={An association between fingerprint patterns with blood group and lifestyle based diseases: a review}, volume={54}, ISSN={1573-7462}, url={http://dx.doi.org/10.1007/s10462-020-09891-w}, DOI={10.1007/s10462-020-09891-w}, number={3}, journal={Artificial Intelligence Review}, publisher={Springer Science and Business Media LLC}, author={Patil, Vijaykumar and Ingle, D. R.}, year={2020}, month=aug, pages={1803–1839} }
",https://link.springer.com/article/10.1007/s10462-020-09891-w,10.1007/s10462-020-09891-w,springer,2020
164,"Machine learning towards intelligent systems: applications, challenges, and opportunities"," @article{Injadat_2021, title={Machine learning towards intelligent systems: applications, challenges, and opportunities}, volume={54}, ISSN={1573-7462}, url={http://dx.doi.org/10.1007/s10462-020-09948-w}, DOI={10.1007/s10462-020-09948-w}, number={5}, journal={Artificial Intelligence Review}, publisher={Springer Science and Business Media LLC}, author={Injadat, MohammadNoor and Moubayed, Abdallah and Nassif, Ali Bou and Shami, Abdallah}, year={2021}, month=jan, pages={3299–3348} }
",https://link.springer.com/article/10.1007/s10462-020-09948-w,10.1007/s10462-020-09948-w,springer,2021
165,A comprehensive bibliometric and content analysis of artificial intelligence in language learning: tracing between the years 2017 and 2023," @article{Rahman_2024, title={A comprehensive bibliometric and content analysis of artificial intelligence in language learning: tracing between the years 2017 and 2023}, volume={57}, ISSN={1573-7462}, url={http://dx.doi.org/10.1007/s10462-023-10643-9}, DOI={10.1007/s10462-023-10643-9}, number={4}, journal={Artificial Intelligence Review}, publisher={Springer Science and Business Media LLC}, author={Rahman, Abdur and Raj, Antony and Tomy, Prajeesh and Hameed, Mohamed Sahul}, year={2024}, month=apr }
",https://link.springer.com/article/10.1007/s10462-023-10643-9,10.1007/s10462-023-10643-9,springer,2024
166,Unraveling the mysteries of AI chatbots," @article{Bridgelall_2024, title={Unraveling the mysteries of AI chatbots}, volume={57}, ISSN={1573-7462}, url={http://dx.doi.org/10.1007/s10462-024-10720-7}, DOI={10.1007/s10462-024-10720-7}, number={4}, journal={Artificial Intelligence Review}, publisher={Springer Science and Business Media LLC}, author={Bridgelall, Raj}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s10462-024-10720-7,10.1007/s10462-024-10720-7,springer,2024
167,On the computational complexity of ethics: moral tractability for minds and machines," @article{Stenseke_2024, title={On the computational complexity of ethics: moral tractability for minds and machines}, volume={57}, ISSN={1573-7462}, url={http://dx.doi.org/10.1007/s10462-024-10732-3}, DOI={10.1007/s10462-024-10732-3}, number={4}, journal={Artificial Intelligence Review}, publisher={Springer Science and Business Media LLC}, author={Stenseke, Jakob}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s10462-024-10732-3,10.1007/s10462-024-10732-3,springer,2024
168,A method for the ethical analysis of brain-inspired AI," @article{Farisco_2024, title={A method for the ethical analysis of brain-inspired AI}, volume={57}, ISSN={1573-7462}, url={http://dx.doi.org/10.1007/s10462-024-10769-4}, DOI={10.1007/s10462-024-10769-4}, number={6}, journal={Artificial Intelligence Review}, publisher={Springer Science and Business Media LLC}, author={Farisco, Michele and Baldassarre, G. and Cartoni, E. and Leach, A. and Petrovici, M.A. and Rosemann, A. and Salles, A. and Stahl, B. and van Albada, S. J.}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s10462-024-10769-4,10.1007/s10462-024-10769-4,springer,2024
169,A survey of safety and trustworthiness of large language models through the lens of verification and validation," @article{Huang_2024, title={A survey of safety and trustworthiness of large language models through the lens of verification and validation}, volume={57}, ISSN={1573-7462}, url={http://dx.doi.org/10.1007/s10462-024-10824-0}, DOI={10.1007/s10462-024-10824-0}, number={7}, journal={Artificial Intelligence Review}, publisher={Springer Science and Business Media LLC}, author={Huang, Xiaowei and Ruan, Wenjie and Huang, Wei and Jin, Gaojie and Dong, Yi and Wu, Changshun and Bensalem, Saddek and Mu, Ronghui and Qi, Yi and Zhao, Xingyu and Cai, Kaiwen and Zhang, Yanghao and Wu, Sihao and Xu, Peipei and Wu, Dengyu and Freitas, Andre and Mustafa, Mustafa A.}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s10462-024-10824-0,10.1007/s10462-024-10824-0,springer,2024
171,Re-evaluating GPT-4’s bar exam performance," @article{Mart_nez_2024, title={Re-evaluating GPT-4’s bar exam performance}, ISSN={1572-8382}, url={http://dx.doi.org/10.1007/s10506-024-09396-9}, DOI={10.1007/s10506-024-09396-9}, journal={Artificial Intelligence and Law}, publisher={Springer Science and Business Media LLC}, author={Martínez, Eric}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s10506-024-09396-9,10.1007/s10506-024-09396-9,springer,2024
172,Large language models for qualitative research in software engineering: exploring opportunities and challenges," @article{Bano_2023, title={Large language models for qualitative research in software engineering: exploring opportunities and challenges}, volume={31}, ISSN={1573-7535}, url={http://dx.doi.org/10.1007/s10515-023-00407-8}, DOI={10.1007/s10515-023-00407-8}, number={1}, journal={Automated Software Engineering}, publisher={Springer Science and Business Media LLC}, author={Bano, Muneera and Hoda, Rashina and Zowghi, Didar and Treude, Christoph}, year={2023}, month=dec }
",https://link.springer.com/article/10.1007/s10515-023-00407-8,10.1007/s10515-023-00407-8,springer,2023
173,Can AI serve as a substitute for human subjects in software engineering research?," @article{Gerosa_2024, title={Can AI serve as a substitute for human subjects in software engineering research?}, volume={31}, ISSN={1573-7535}, url={http://dx.doi.org/10.1007/s10515-023-00409-6}, DOI={10.1007/s10515-023-00409-6}, number={1}, journal={Automated Software Engineering}, publisher={Springer Science and Business Media LLC}, author={Gerosa, Marco and Trinkenreich, Bianca and Steinmacher, Igor and Sarma, Anita}, year={2024}, month=jan }
",https://link.springer.com/article/10.1007/s10515-023-00409-6,10.1007/s10515-023-00409-6,springer,2024
174,Distilled GPT for source code summarization," @article{Su_2024, title={Distilled GPT for source code summarization}, volume={31}, ISSN={1573-7535}, url={http://dx.doi.org/10.1007/s10515-024-00421-4}, DOI={10.1007/s10515-024-00421-4}, number={1}, journal={Automated Software Engineering}, publisher={Springer Science and Business Media LLC}, author={Su, Chia-Yi and McMillan, Collin}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s10515-024-00421-4,10.1007/s10515-024-00421-4,springer,2024
175,Future of software development with generative AI," @article{Sauvola_2024, title={Future of software development with generative AI}, volume={31}, ISSN={1573-7535}, url={http://dx.doi.org/10.1007/s10515-024-00426-z}, DOI={10.1007/s10515-024-00426-z}, number={1}, journal={Automated Software Engineering}, publisher={Springer Science and Business Media LLC}, author={Sauvola, Jaakko and Tarkoma, Sasu and Klemettinen, Mika and Riekki, Jukka and Doermann, David}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s10515-024-00426-z,10.1007/s10515-024-00426-z,"springer, web_of_science, scopus",2024
176,Automated quantum software engineering," @article{Sarkar_2024, title={Automated quantum software engineering}, volume={31}, ISSN={1573-7535}, url={http://dx.doi.org/10.1007/s10515-024-00436-x}, DOI={10.1007/s10515-024-00436-x}, number={1}, journal={Automated Software Engineering}, publisher={Springer Science and Business Media LLC}, author={Sarkar, Aritra}, year={2024}, month=apr }
",https://link.springer.com/article/10.1007/s10515-024-00436-x,10.1007/s10515-024-00436-x,springer,2024
177,Data cleaning and machine learning: a systematic literature review," @article{C_t__2024, title={Data cleaning and machine learning: a systematic literature review}, volume={31}, ISSN={1573-7535}, url={http://dx.doi.org/10.1007/s10515-024-00453-w}, DOI={10.1007/s10515-024-00453-w}, number={2}, journal={Automated Software Engineering}, publisher={Springer Science and Business Media LLC}, author={Côté, Pierre-Olivier and Nikanjam, Amin and Ahmed, Nafisa and Humeniuk, Dmytro and Khomh, Foutse}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s10515-024-00453-w,10.1007/s10515-024-00453-w,springer,2024
178,"Chatgpt for cybersecurity: practical applications, challenges, and future directions"," @article{Al_Hawawreh_2023, title={Chatgpt for cybersecurity: practical applications, challenges, and future directions}, volume={26}, ISSN={1573-7543}, url={http://dx.doi.org/10.1007/s10586-023-04124-5}, DOI={10.1007/s10586-023-04124-5}, number={6}, journal={Cluster Computing}, publisher={Springer Science and Business Media LLC}, author={Al-Hawawreh, Muna and Aljuhani, Ahamed and Jararweh, Yaser}, year={2023}, month=aug, pages={3421–3436} }
",https://link.springer.com/article/10.1007/s10586-023-04124-5,10.1007/s10586-023-04124-5,springer,2023
179,Investigating large language models capabilities for automatic code repair in Python," @article{Omari_2024, title={Investigating large language models capabilities for automatic code repair in Python}, ISSN={1573-7543}, url={http://dx.doi.org/10.1007/s10586-024-04490-8}, DOI={10.1007/s10586-024-04490-8}, journal={Cluster Computing}, publisher={Springer Science and Business Media LLC}, author={Omari, Safwan and Basnet, Kshitiz and Wardat, Mohammad}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s10586-024-04490-8,10.1007/s10586-024-04490-8,springer,2024
180,To resist it or to embrace it? Examining ChatGPT’s potential to support teacher feedback in EFL writing," @article{Guo_2023, title={To resist it or to embrace it? Examining ChatGPT’s potential to support teacher feedback in EFL writing}, volume={29}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-023-12146-0}, DOI={10.1007/s10639-023-12146-0}, number={7}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Guo, Kai and Wang, Deliang}, year={2023}, month=aug, pages={8435–8463} }
",https://link.springer.com/article/10.1007/s10639-023-12146-0,10.1007/s10639-023-12146-0,springer,2023
181,Few-shot is enough: exploring ChatGPT prompt engineering method for automatic question generation in english education," @article{Lee_2023, title={Few-shot is enough: exploring ChatGPT prompt engineering method for automatic question generation in english education}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-023-12249-8}, DOI={10.1007/s10639-023-12249-8}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Lee, Unggi and Jung, Haewon and Jeon, Younghoon and Sohn, Younghoon and Hwang, Wonhee and Moon, Jewoong and Kim, Hyeoncheol}, year={2023}, month=oct }
",https://link.springer.com/article/10.1007/s10639-023-12249-8,10.1007/s10639-023-12249-8,springer,2023
182,"Editorial for EAIT issue 12, 2023"," @article{Tatnall_2023, title={Editorial for EAIT issue 12, 2023}, volume={28}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-023-12367-3}, DOI={10.1007/s10639-023-12367-3}, number={12}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Tatnall, Arthur}, year={2023}, month=nov, pages={15457–15468} }
",https://link.springer.com/article/10.1007/s10639-023-12367-3,10.1007/s10639-023-12367-3,springer,2023
183,The impact of ChatGPT on L2 writing and expected responses: Voice from doctoral students," @article{Zou_2023, title={The impact of ChatGPT on L2 writing and expected responses: Voice from doctoral students}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-023-12397-x}, DOI={10.1007/s10639-023-12397-x}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Zou, Min and Huang, Liang}, year={2023}, month=dec }
",https://link.springer.com/article/10.1007/s10639-023-12397-x,10.1007/s10639-023-12397-x,springer,2023
184,Constructing a teacher portrait for the artificial intelligence age based on the micro ecological system theory: A systematic review," @article{Hu_2024, title={Constructing a teacher portrait for the artificial intelligence age based on the micro ecological system theory: A systematic review}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-024-12513-5}, DOI={10.1007/s10639-024-12513-5}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Hu, Xiaoyong and Sui, Hui and Geng, Xingyu and Zhao, Li}, year={2024}, month=feb }
",https://link.springer.com/article/10.1007/s10639-024-12513-5,10.1007/s10639-024-12513-5,springer,2024
185,Detecting AI assisted submissions in introductory programming via code anomaly,"@article{2-s2.0-85185132151,
  title={Detecting AI assisted submissions in introductory programming via code anomaly},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185132151&origin=inward,10.1007/s10639-024-12520-6,scopus,2024
186,Empowering education development through AIGC: A systematic literature review," @article{Chen_2024, title={Empowering education development through AIGC: A systematic literature review}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-024-12549-7}, DOI={10.1007/s10639-024-12549-7}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Chen, Xiaojiao and Hu, Zhebing and Wang, Chengliang}, year={2024}, month=feb }
",https://link.springer.com/article/10.1007/s10639-024-12549-7,10.1007/s10639-024-12549-7,springer,2024
187,Incorporating AI in foreign language education: An investigation into ChatGPT’s effect on foreign language learners," @article{Karata__2024, title={Incorporating AI in foreign language education: An investigation into ChatGPT’s effect on foreign language learners}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-024-12574-6}, DOI={10.1007/s10639-024-12574-6}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Karataş, Fatih and Abedi, Faramarz Yaşar and Ozek Gunyel, Filiz and Karadeniz, Derya and Kuzgun, Yasemin}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s10639-024-12574-6,10.1007/s10639-024-12574-6,springer,2024
188,Natural language processing in educational research: The evolution of research topics," @article{Wu_2024, title={Natural language processing in educational research: The evolution of research topics}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-024-12764-2}, DOI={10.1007/s10639-024-12764-2}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Wu, Hao and Li, Shan and Gao, Ying and Weng, Jinta and Ding, Guozhu}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s10639-024-12764-2,10.1007/s10639-024-12764-2,springer,2024
189,Acceptance and use of ChatGPT in the academic community," @article{Strzelecki_2024, title={Acceptance and use of ChatGPT in the academic community}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-024-12765-1}, DOI={10.1007/s10639-024-12765-1}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Strzelecki, Artur and Cicha, Karina and Rizun, Mariia and Rutecka, Paulina}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s10639-024-12765-1,10.1007/s10639-024-12765-1,springer,2024
190,Exploratory study on the potential of ChatGPT as a rater of second language writing," @article{Shin_2024, title={Exploratory study on the potential of ChatGPT as a rater of second language writing}, ISSN={1573-7608}, url={http://dx.doi.org/10.1007/s10639-024-12817-6}, DOI={10.1007/s10639-024-12817-6}, journal={Education and Information Technologies}, publisher={Springer Science and Business Media LLC}, author={Shin, Dongkwang and Lee, Jang Ho}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s10639-024-12817-6,10.1007/s10639-024-12817-6,springer,2024
191,Fairness-aware machine learning engineering: how far are we?," @article{Ferrara_2023, title={Fairness-aware machine learning engineering: how far are we?}, volume={29}, ISSN={1573-7616}, url={http://dx.doi.org/10.1007/s10664-023-10402-y}, DOI={10.1007/s10664-023-10402-y}, number={1}, journal={Empirical Software Engineering}, publisher={Springer Science and Business Media LLC}, author={Ferrara, Carmine and Sellitto, Giulia and Ferrucci, Filomena and Palomba, Fabio and De Lucia, Andrea}, year={2023}, month=nov }
",https://link.springer.com/article/10.1007/s10664-023-10402-y,10.1007/s10664-023-10402-y,springer,2023
192,Exploring Gender Bias In Remote Pair Programming Among Software Engineering Students: The twincode Original Study And First External Replication," @article{Dur_n_Toro_2024, title={Exploring Gender Bias In Remote Pair Programming Among Software Engineering Students: The twincode Original Study And First External Replication}, volume={29}, ISSN={1573-7616}, url={http://dx.doi.org/10.1007/s10664-023-10416-6}, DOI={10.1007/s10664-023-10416-6}, number={2}, journal={Empirical Software Engineering}, publisher={Springer Science and Business Media LLC}, author={Durán Toro, Amador and Fernández, Pablo and Bernárdez, Beatriz and Weinman, Nathaniel and Akalın, Aslıhan and Fox, Armando}, year={2024}, month=feb }
",https://link.springer.com/article/10.1007/s10664-023-10416-6,10.1007/s10664-023-10416-6,springer,2024
193,Use case cards: a use case reporting framework inspired by the European AI Act," @article{Hupont_2024, title={Use case cards: a use case reporting framework inspired by the European AI Act}, volume={26}, ISSN={1572-8439}, url={http://dx.doi.org/10.1007/s10676-024-09757-7}, DOI={10.1007/s10676-024-09757-7}, number={2}, journal={Ethics and Information Technology}, publisher={Springer Science and Business Media LLC}, author={Hupont, Isabelle and Fernández-Llorca, David and Baldassarri, Sandra and Gómez, Emilia}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s10676-024-09757-7,10.1007/s10676-024-09757-7,springer,2024
194,"A phenomenology and epistemology of large language models: transparency, trust, and trustworthiness"," @article{Heersmink_2024, title={A phenomenology and epistemology of large language models: transparency, trust, and trustworthiness}, volume={26}, ISSN={1572-8439}, url={http://dx.doi.org/10.1007/s10676-024-09777-3}, DOI={10.1007/s10676-024-09777-3}, number={3}, journal={Ethics and Information Technology}, publisher={Springer Science and Business Media LLC}, author={Heersmink, Richard and de Rooij, Barend and Clavel Vázquez, María Jimena and Colombo, Matteo}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s10676-024-09777-3,10.1007/s10676-024-09777-3,springer,2024
195,Getting it right: the limits of fine-tuning large language models," @article{Browning_2024, title={Getting it right: the limits of fine-tuning large language models}, volume={26}, ISSN={1572-8439}, url={http://dx.doi.org/10.1007/s10676-024-09779-1}, DOI={10.1007/s10676-024-09779-1}, number={2}, journal={Ethics and Information Technology}, publisher={Springer Science and Business Media LLC}, author={Browning, Jacob}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s10676-024-09779-1,10.1007/s10676-024-09779-1,springer,2024
196,Predictive analysis visualization component in simulated data streams," @article{Dud__2024, title={Predictive analysis visualization component in simulated data streams}, volume={27}, ISSN={2948-2992}, url={http://dx.doi.org/10.1007/s10791-024-09447-4}, DOI={10.1007/s10791-024-09447-4}, number={1}, journal={Discover Computing}, publisher={Springer Science and Business Media LLC}, author={Dudáš, Adam and Demian, Daniel}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s10791-024-09447-4,10.1007/s10791-024-09447-4,springer,2024
197,Enhancing BERT-Based Language Model for Multi-label Vulnerability Detection of Smart Contract in Blockchain," @article{Tong_2024, title={Enhancing BERT-Based Language Model for Multi-label Vulnerability Detection of Smart Contract in Blockchain}, volume={32}, ISSN={1573-7705}, url={http://dx.doi.org/10.1007/s10922-024-09832-w}, DOI={10.1007/s10922-024-09832-w}, number={3}, journal={Journal of Network and Systems Management}, publisher={Springer Science and Business Media LLC}, author={Tong, Van and Dao, Cuong and Tran, Hai-Anh and Tran, Truong X. and Souihi, Sami}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s10922-024-09832-w,10.1007/s10922-024-09832-w,springer,2024
198,Opposing agents evolve the research: a decade of digital forensics," @article{Raman_2024, title={Opposing agents evolve the research: a decade of digital forensics}, ISSN={1573-7721}, url={http://dx.doi.org/10.1007/s11042-024-19519-8}, DOI={10.1007/s11042-024-19519-8}, journal={Multimedia Tools and Applications}, publisher={Springer Science and Business Media LLC}, author={Raman, Raghu and Sahu, Aditya Kumar and Nair, Vinith Kumar and Nedungadi, Prema}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s11042-024-19519-8,10.1007/s11042-024-19519-8,springer,2024
199,Analyzing the impact of companies on AI research based on publications," @article{F_rber_2023, title={Analyzing the impact of companies on AI research based on publications}, volume={129}, ISSN={1588-2861}, url={http://dx.doi.org/10.1007/s11192-023-04867-3}, DOI={10.1007/s11192-023-04867-3}, number={1}, journal={Scientometrics}, publisher={Springer Science and Business Media LLC}, author={Färber, Michael and Tampakis, Lazaros}, year={2023}, month=nov, pages={31–63} }
",https://link.springer.com/article/10.1007/s11192-023-04867-3,10.1007/s11192-023-04867-3,springer,2023
200,Computational Approaches for Traditional Chinese Painting: From the “Six Principles of Painting” Perspective," @article{Zhang_2024, title={Computational Approaches for Traditional Chinese Painting: From the “Six Principles of Painting” Perspective}, volume={39}, ISSN={1860-4749}, url={http://dx.doi.org/10.1007/s11390-024-3408-x}, DOI={10.1007/s11390-024-3408-x}, number={2}, journal={Journal of Computer Science and Technology}, publisher={Springer Science and Business Media LLC}, author={Zhang, Wei and Zhang, Jian-Wei and Wong, Kam-Kwai and Wang, Yi-Fang and Feng, Ying-Chao-Jie and Wang, Lu-Wei and Chen, Wei}, year={2024}, month=mar, pages={269–285} }
",https://link.springer.com/article/10.1007/s11390-024-3408-x,10.1007/s11390-024-3408-x,springer,2024
201,Design criteria for AI-based IT systems,"@article{2-s2.0-85182981944,
  title={Design criteria for AI-based IT systems},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182981944&origin=inward,10.1007/s11548-024-03064-8,scopus,2024
202,RA-CFGPT: Chinese financial assistant with retrieval-augmented large language model," @article{Li_2024, title={RA-CFGPT: Chinese financial assistant with retrieval-augmented large language model}, volume={18}, ISSN={2095-2236}, url={http://dx.doi.org/10.1007/s11704-024-31018-5}, DOI={10.1007/s11704-024-31018-5}, number={5}, journal={Frontiers of Computer Science}, publisher={Springer Science and Business Media LLC}, author={Li, Jiangtong and Lei, Yang and Bian, Yuxuan and Cheng, Dawei and Ding, Zhijun and Jiang, Changjun}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s11704-024-31018-5,10.1007/s11704-024-31018-5,springer,2024
203,FIFAWC: a dataset with detailed annotation and rich semantics for group activity recognition," @article{Pei_2024, title={FIFAWC: a dataset with detailed annotation and rich semantics for group activity recognition}, volume={18}, ISSN={2095-2236}, url={http://dx.doi.org/10.1007/s11704-024-40027-3}, DOI={10.1007/s11704-024-40027-3}, number={6}, journal={Frontiers of Computer Science}, publisher={Springer Science and Business Media LLC}, author={Pei, Duoxuan and Huang, Di and Wang, Yunhong}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s11704-024-40027-3,10.1007/s11704-024-40027-3,springer,2024
204,A survey on large language model based autonomous agents," @article{Wang_2024, title={A survey on large language model based autonomous agents}, volume={18}, ISSN={2095-2236}, url={http://dx.doi.org/10.1007/s11704-024-40231-1}, DOI={10.1007/s11704-024-40231-1}, number={6}, journal={Frontiers of Computer Science}, publisher={Springer Science and Business Media LLC}, author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Jirong}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s11704-024-40231-1,10.1007/s11704-024-40231-1,springer,2024
205,"ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review"," @article{Khowaja_2024, title={ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review}, ISSN={1866-9964}, url={http://dx.doi.org/10.1007/s12559-024-10285-1}, DOI={10.1007/s12559-024-10285-1}, journal={Cognitive Computation}, publisher={Springer Science and Business Media LLC}, author={Khowaja, Sunder Ali and Khuwaja, Parus and Dev, Kapal and Wang, Weizheng and Nkenyereye, Lewis}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s12559-024-10285-1,10.1007/s12559-024-10285-1,springer,2024
206,"Public attitudes toward chatgpt on twitter: sentiments, topics, and occupations"," @article{Koonchanok_2024, title={Public attitudes toward chatgpt on twitter: sentiments, topics, and occupations}, volume={14}, ISSN={1869-5469}, url={http://dx.doi.org/10.1007/s13278-024-01260-7}, DOI={10.1007/s13278-024-01260-7}, number={1}, journal={Social Network Analysis and Mining}, publisher={Springer Science and Business Media LLC}, author={Koonchanok, Ratanond and Pan, Yanling and Jang, Hyeju}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s13278-024-01260-7,10.1007/s13278-024-01260-7,springer,2024
207,Interpretable Dropout Prediction: Towards XAI-Based Personalized Intervention," @article{Nagy_2023, title={Interpretable Dropout Prediction: Towards XAI-Based Personalized Intervention}, volume={34}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-023-00331-8}, DOI={10.1007/s40593-023-00331-8}, number={2}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Nagy, Marcell and Molontay, Roland}, year={2023}, month=mar, pages={274–300} }
",https://link.springer.com/article/10.1007/s40593-023-00331-8,10.1007/s40593-023-00331-8,springer,2023
208,Beyond Predictive Learning Analytics Modelling and onto Explainable Artificial Intelligence with Prescriptive Analytics and ChatGPT," @article{Susnjak_2023, title={Beyond Predictive Learning Analytics Modelling and onto Explainable Artificial Intelligence with Prescriptive Analytics and ChatGPT}, volume={34}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-023-00336-3}, DOI={10.1007/s40593-023-00336-3}, number={2}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Susnjak, Teo}, year={2023}, month=jun, pages={452–482} }
",https://link.springer.com/article/10.1007/s40593-023-00336-3,10.1007/s40593-023-00336-3,springer,2023
209,Beyond Mastery: Toward a Broader Understanding of AI in Education," @article{Tuomi_2023, title={Beyond Mastery: Toward a Broader Understanding of AI in Education}, volume={34}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-023-00343-4}, DOI={10.1007/s40593-023-00343-4}, number={1}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Tuomi, Ilkka}, year={2023}, month=jun, pages={20–30} }
",https://link.springer.com/article/10.1007/s40593-023-00343-4,10.1007/s40593-023-00343-4,springer,2023
210,Can ChatGPT Pass High School Exams on English Language Comprehension?," @article{de_Winter_2023, title={Can ChatGPT Pass High School Exams on English Language Comprehension?}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-023-00372-z}, DOI={10.1007/s40593-023-00372-z}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={de Winter, Joost C. F.}, year={2023}, month=sep }
",https://link.springer.com/article/10.1007/s40593-023-00372-z,10.1007/s40593-023-00372-z,springer,2023
211,Formative Feedback on Student-Authored Summaries in Intelligent Textbooks Using Large Language Models," @article{Morris_2024, title={Formative Feedback on Student-Authored Summaries in Intelligent Textbooks Using Large Language Models}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-024-00395-0}, DOI={10.1007/s40593-024-00395-0}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Morris, Wesley and Crossley, Scott and Holmes, Langdon and Ou, Chaohua and Dascalu, Mihai and McNamara, Danielle}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s40593-024-00395-0,10.1007/s40593-024-00395-0,springer,2024
212,"GPT-4 in Education: Evaluating Aptness, Reliability, and Loss of Coherence in Solving Calculus Problems and Grading Submissions"," @article{Gandolfi_2024, title={GPT-4 in Education: Evaluating Aptness, Reliability, and Loss of Coherence in Solving Calculus Problems and Grading Submissions}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-024-00403-3}, DOI={10.1007/s40593-024-00403-3}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Gandolfi, Alberto}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s40593-024-00403-3,10.1007/s40593-024-00403-3,springer,2024
213,Evaluation of LLM Tools for Feedback Generation in a Course on Concurrent Programming," @article{Est_vez_Ayres_2024, title={Evaluation of LLM Tools for Feedback Generation in a Course on Concurrent Programming}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-024-00406-0}, DOI={10.1007/s40593-024-00406-0}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Estévez-Ayres, Iria and Callejo, Patricia and Hombrados-Herrera, Miguel Ángel and Alario-Hoyos, Carlos and Delgado Kloos, Carlos}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s40593-024-00406-0,10.1007/s40593-024-00406-0,"springer, web_of_science, scopus",2024
214,Transforming Driver Education: A Comparative Analysis of LLM-Augmented Training and Conventional Instruction for Autonomous Vehicle Technologies," @article{Murtaza_2024, title={Transforming Driver Education: A Comparative Analysis of LLM-Augmented Training and Conventional Instruction for Autonomous Vehicle Technologies}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-024-00407-z}, DOI={10.1007/s40593-024-00407-z}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Murtaza, Mohsin and Cheng, Chi-Tsun and Fard, Mohammad and Zeleznikow, John}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s40593-024-00407-z,10.1007/s40593-024-00407-z,springer,2024
215,The Use of ChatGPT in Source-Based Writing Tasks," @article{Tarchi_2024, title={The Use of ChatGPT in Source-Based Writing Tasks}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-024-00413-1}, DOI={10.1007/s40593-024-00413-1}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Tarchi, Christian and Zappoli, Alessandra and Casado Ledesma, Lidia and Brante, Eva Wennås}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s40593-024-00413-1,10.1007/s40593-024-00413-1,springer,2024
216,A Large Language Model Approach to Educational Survey Feedback Analysis," @article{Parker_2024, title={A Large Language Model Approach to Educational Survey Feedback Analysis}, ISSN={1560-4306}, url={http://dx.doi.org/10.1007/s40593-024-00414-0}, DOI={10.1007/s40593-024-00414-0}, journal={International Journal of Artificial Intelligence in Education}, publisher={Springer Science and Business Media LLC}, author={Parker, Michael J. and Anderson, Caitlin and Stone, Claire and Oh, YeaRim}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s40593-024-00414-0,10.1007/s40593-024-00414-0,springer,2024
217,Identifying missing data handling methods with text mining," @article{Boros_2024, title={Identifying missing data handling methods with text mining}, ISSN={2364-4168}, url={http://dx.doi.org/10.1007/s41060-024-00582-1}, DOI={10.1007/s41060-024-00582-1}, journal={International Journal of Data Science and Analytics}, publisher={Springer Science and Business Media LLC}, author={Boros, Krisztián and Kmetty, Zoltán}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s41060-024-00582-1,10.1007/s41060-024-00582-1,springer,2024
218,Clinical Information Retrieval: A Literature Review," @article{Sivarajkumar_2024, title={Clinical Information Retrieval: A Literature Review}, volume={8}, ISSN={2509-498X}, url={http://dx.doi.org/10.1007/s41666-024-00159-4}, DOI={10.1007/s41666-024-00159-4}, number={2}, journal={Journal of Healthcare Informatics Research}, publisher={Springer Science and Business Media LLC}, author={Sivarajkumar, Sonish and Mohammad, Haneef Ahamed and Oniani, David and Roberts, Kirk and Hersh, William and Liu, Hongfang and He, Daqing and Visweswaran, Shyam and Wang, Yanshan}, year={2024}, month=jan, pages={313–352} }
",https://link.springer.com/article/10.1007/s41666-024-00159-4,10.1007/s41666-024-00159-4,springer,2024
219,@llegra: a chatbot for Vallader," @article{Bendel_2024, title={@llegra: a chatbot for Vallader}, volume={16}, ISSN={2511-2112}, url={http://dx.doi.org/10.1007/s41870-024-01779-0}, DOI={10.1007/s41870-024-01779-0}, number={4}, journal={International Journal of Information Technology}, publisher={Springer Science and Business Media LLC}, author={Bendel, Oliver and Jabou, Dalil}, year={2024}, month=feb, pages={2035–2045} }
",https://link.springer.com/article/10.1007/s41870-024-01779-0,10.1007/s41870-024-01779-0,springer,2024
220,Breaking language barriers with ChatGPT: enhancing low-resource machine translation between algerian arabic and MSA," @article{Babaali_2024, title={Breaking language barriers with ChatGPT: enhancing low-resource machine translation between algerian arabic and MSA}, ISSN={2511-2112}, url={http://dx.doi.org/10.1007/s41870-024-01926-7}, DOI={10.1007/s41870-024-01926-7}, journal={International Journal of Information Technology}, publisher={Springer Science and Business Media LLC}, author={Babaali, Baligh and Salem, Mohammed and Alharbe, Nawaf R.}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s41870-024-01926-7,10.1007/s41870-024-01926-7,springer,2024
221,Text Analysis on Early Reactions to ChatGPT as a Tool for Academic Progress or Exploitation," @article{Bukar_2024, title={Text Analysis on Early Reactions to ChatGPT as a Tool for Academic Progress or Exploitation}, volume={5}, ISSN={2661-8907}, url={http://dx.doi.org/10.1007/s42979-024-02714-7}, DOI={10.1007/s42979-024-02714-7}, number={4}, journal={SN Computer Science}, publisher={Springer Science and Business Media LLC}, author={Bukar, Umar Ali and Sayeed, Md Shohel and Razak, Siti Fatimah Abdul and Yogarayan, Sumendra and Amodu, Oluwatosin Ahmed and Raja Mahmood, Raja Azlina}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s42979-024-02714-7,10.1007/s42979-024-02714-7,springer,2024
222,Creating Automatic Connections for Personal Knowledge Management," @article{Fraga_2024, title={Creating Automatic Connections for Personal Knowledge Management}, volume={5}, ISSN={2661-8907}, url={http://dx.doi.org/10.1007/s42979-024-02876-4}, DOI={10.1007/s42979-024-02876-4}, number={5}, journal={SN Computer Science}, publisher={Springer Science and Business Media LLC}, author={Fraga, Felipe Poggi A. and Poggi, Marcus and Casanova, Marco A. and Leme, Luiz André P. Paes}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s42979-024-02876-4,10.1007/s42979-024-02876-4,springer,2024
223,Docimological Quality Analysis of LLM-Generated Multiple Choice Questions in Computer Science and Medicine," @article{Gr_visse_2024, title={Docimological Quality Analysis of LLM-Generated Multiple Choice Questions in Computer Science and Medicine}, volume={5}, ISSN={2661-8907}, url={http://dx.doi.org/10.1007/s42979-024-02963-6}, DOI={10.1007/s42979-024-02963-6}, number={5}, journal={SN Computer Science}, publisher={Springer Science and Business Media LLC}, author={Grévisse, Christian and Pavlou, Maria Angeliki S. and Schneider, Jochen G.}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s42979-024-02963-6,10.1007/s42979-024-02963-6,"springer, scopus",2024
224,Student Opinion Mining About Instructor Using Optimized Ensemble Machine Learning Model and Feature Fusion," @article{Ahuja_2024, title={Student Opinion Mining About Instructor Using Optimized Ensemble Machine Learning Model and Feature Fusion}, volume={5}, ISSN={2661-8907}, url={http://dx.doi.org/10.1007/s42979-024-03032-8}, DOI={10.1007/s42979-024-03032-8}, number={6}, journal={SN Computer Science}, publisher={Springer Science and Business Media LLC}, author={Ahuja, Ravinder and Sharma, S. C.}, year={2024}, month=jun }
",https://link.springer.com/article/10.1007/s42979-024-03032-8,10.1007/s42979-024-03032-8,springer,2024
225,Needs and artificial intelligence," @article{Human_2022, title={Needs and artificial intelligence}, volume={3}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-022-00206-z}, DOI={10.1007/s43681-022-00206-z}, number={3}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Human, Soheil and Watkins, Ryan}, year={2022}, month=oct, pages={811–826} }
",https://link.springer.com/article/10.1007/s43681-022-00206-z,10.1007/s43681-022-00206-z,springer,2022
226,Beware of sustainable AI! Uses and abuses of a worthy goal," @article{Heilinger_2023, title={Beware of sustainable AI! Uses and abuses of a worthy goal}, volume={4}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-023-00259-8}, DOI={10.1007/s43681-023-00259-8}, number={2}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Heilinger, Jan-Christoph and Kempt, Hendrik and Nagel, Saskia}, year={2023}, month=feb, pages={201–212} }
",https://link.springer.com/article/10.1007/s43681-023-00259-8,10.1007/s43681-023-00259-8,springer,2023
227,Exploring differences in ethical decision-making processes between humans and ChatGPT-3 model: a study of trade-offs," @article{Rehman_2023, title={Exploring differences in ethical decision-making processes between humans and ChatGPT-3 model: a study of trade-offs}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-023-00335-z}, DOI={10.1007/s43681-023-00335-z}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Rehman, Umair and Iqbal, Farkhund and Shah, Muhammad Umair}, year={2023}, month=sep }
",https://link.springer.com/article/10.1007/s43681-023-00335-z,10.1007/s43681-023-00335-z,springer,2023
228,"The role of ChatGPT in disrupting concepts, changing values, and challenging ethical norms: a qualitative study"," @article{Esmaeilzadeh_2023, title={The role of ChatGPT in disrupting concepts, changing values, and challenging ethical norms: a qualitative study}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-023-00338-w}, DOI={10.1007/s43681-023-00338-w}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Esmaeilzadeh, Pouyan}, year={2023}, month=sep }
",https://link.springer.com/article/10.1007/s43681-023-00338-w,10.1007/s43681-023-00338-w,springer,2023
229,What do academics have to say about ChatGPT? A text mining analytics on the discussions regarding ChatGPT on research writing," @article{Bringula_2023, title={What do academics have to say about ChatGPT? A text mining analytics on the discussions regarding ChatGPT on research writing}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-023-00354-w}, DOI={10.1007/s43681-023-00354-w}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Bringula, Rex}, year={2023}, month=oct }
",https://link.springer.com/article/10.1007/s43681-023-00354-w,10.1007/s43681-023-00354-w,springer,2023
230,"On inscription and bias: data, actor network theory, and the social problems of text-to-image AI models"," @article{Morton_2024, title={On inscription and bias: data, actor network theory, and the social problems of text-to-image AI models}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00431-8}, DOI={10.1007/s43681-024-00431-8}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Morton, Jorge Luis}, year={2024}, month=feb }
",https://link.springer.com/article/10.1007/s43681-024-00431-8,10.1007/s43681-024-00431-8,springer,2024
231,Prospectives and drawbacks of ChatGPT in healthcare and clinical medicine," @article{Alam_2024, title={Prospectives and drawbacks of ChatGPT in healthcare and clinical medicine}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00434-5}, DOI={10.1007/s43681-024-00434-5}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Alam, Khadija and Kumar, Akhil and Samiullah, F. N. U.}, year={2024}, month=feb }
",https://link.springer.com/article/10.1007/s43681-024-00434-5,10.1007/s43681-024-00434-5,springer,2024
232,Exploring ChatGPT and its impact on society," @article{Haque_2024, title={Exploring ChatGPT and its impact on society}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00435-4}, DOI={10.1007/s43681-024-00435-4}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Haque, Md. Asraful and Li, Shuai}, year={2024}, month=feb }
",https://link.springer.com/article/10.1007/s43681-024-00435-4,10.1007/s43681-024-00435-4,springer,2024
233,Engaging the many-hands problem of generative-AI outputs: a framework for attributing credit," @article{Khosrowi_2024, title={Engaging the many-hands problem of generative-AI outputs: a framework for attributing credit}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00440-7}, DOI={10.1007/s43681-024-00440-7}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Khosrowi, Donal and Finn, Finola and Clark, Elinor}, year={2024}, month=mar }
",https://link.springer.com/article/10.1007/s43681-024-00440-7,10.1007/s43681-024-00440-7,springer,2024
234,AI hype as a cyber security risk: the moral responsibility of implementing generative AI in business," @article{Humphreys_2024, title={AI hype as a cyber security risk: the moral responsibility of implementing generative AI in business}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00443-4}, DOI={10.1007/s43681-024-00443-4}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Humphreys, Declan and Koay, Abigail and Desmond, Dennis and Mealy, Erica}, year={2024}, month=feb }
",https://link.springer.com/article/10.1007/s43681-024-00443-4,10.1007/s43681-024-00443-4,springer,2024
235,Safeguarding human values: rethinking US law for generative AI’s societal impacts," @article{Cheong_2024, title={Safeguarding human values: rethinking US law for generative AI’s societal impacts}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00451-4}, DOI={10.1007/s43681-024-00451-4}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Cheong, Inyoung and Caliskan, Aylin and Kohno, Tadayoshi}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s43681-024-00451-4,10.1007/s43681-024-00451-4,springer,2024
236,The mechanisms of AI hype and its planetary and social costs," @article{Markelius_2024, title={The mechanisms of AI hype and its planetary and social costs}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00461-2}, DOI={10.1007/s43681-024-00461-2}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Markelius, Alva and Wright, Connor and Kuiper, Joahna and Delille, Natalie and Kuo, Yu-Ting}, year={2024}, month=apr }
",https://link.springer.com/article/10.1007/s43681-024-00461-2,10.1007/s43681-024-00461-2,springer,2024
237,The ethics of using artificial intelligence in scientific research: new guidance needed for a new tool," @article{Resnik_2024, title={The ethics of using artificial intelligence in scientific research: new guidance needed for a new tool}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00493-8}, DOI={10.1007/s43681-024-00493-8}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Resnik, David B. and Hosseini, Mohammad}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s43681-024-00493-8,10.1007/s43681-024-00493-8,springer,2024
238,Anticipating impacts: using large-scale scenario-writing to explore diverse implications of generative AI in the news environment," @article{Kieslich_2024, title={Anticipating impacts: using large-scale scenario-writing to explore diverse implications of generative AI in the news environment}, ISSN={2730-5961}, url={http://dx.doi.org/10.1007/s43681-024-00497-4}, DOI={10.1007/s43681-024-00497-4}, journal={AI and Ethics}, publisher={Springer Science and Business Media LLC}, author={Kieslich, Kimon and Diakopoulos, Nicholas and Helberger, Natali}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s43681-024-00497-4,10.1007/s43681-024-00497-4,springer,2024
239,Examining Ethical and Social Implications of Digital Mental Health Technologies Through Expert Interviews and Sociotechnical Systems Theory," @article{Adams_2024, title={Examining Ethical and Social Implications of Digital Mental Health Technologies Through Expert Interviews and Sociotechnical Systems Theory}, volume={3}, ISSN={2731-4669}, url={http://dx.doi.org/10.1007/s44206-024-00110-5}, DOI={10.1007/s44206-024-00110-5}, number={2}, journal={Digital Society}, publisher={Springer Science and Business Media LLC}, author={Adams, Jonathan}, year={2024}, month=may }
",https://link.springer.com/article/10.1007/s44206-024-00110-5,10.1007/s44206-024-00110-5,springer,2024
240,Application of ChatGPT for automated problem reframing across academic domains,"@article{2-s2.0-85180303050,
  title={Application of ChatGPT for automated problem reframing across academic domains},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180303050&origin=inward,10.1016/j.caeai.2023.100194,scopus,2024
241,A ChatGPT-MATLAB framework for numerical modeling in geotechnical engineering applications," @article{Kim_2024, title={A ChatGPT-MATLAB framework for numerical modeling in geotechnical engineering applications}, volume={169}, ISSN={0266-352X}, url={http://dx.doi.org/10.1016/j.compgeo.2024.106237}, DOI={10.1016/j.compgeo.2024.106237}, journal={Computers and Geotechnics}, publisher={Elsevier BV}, author={Kim, Daehyun and Kim, Taegu and Kim, Yejin and Byun, Yong-Hoon and Yun, Tae Sup}, year={2024}, month=may, pages={106237} }
",http://dx.doi.org/10.1016/j.compgeo.2024.106237,10.1016/j.compgeo.2024.106237,web_of_science,2024
242,Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT," @article{Tsai_2023, title={Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT}, volume={44}, ISSN={1749-7728}, url={http://dx.doi.org/10.1016/j.ece.2023.05.001}, DOI={10.1016/j.ece.2023.05.001}, journal={Education for Chemical Engineers}, publisher={Elsevier BV}, author={Tsai, Meng-Lin and Ong, Chong Wei and Chen, Cheng-Liang}, year={2023}, month=jul, pages={71–95} }
",http://dx.doi.org/10.1016/j.ece.2023.05.001,10.1016/j.ece.2023.05.001,"web_of_science, scopus",2023
243,"“So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy","@article{2-s2.0-85149886538,
  title={“So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85149886538&origin=inward,10.1016/j.ijinfomgt.2023.102642,scopus,2023
244,VIRTSI: A novel trust dynamics model enhancing Artificial Intelligence collaboration with human users – Insights from a ChatGPT evaluation study,"@article{2-s2.0-85194165210,
  title={VIRTSI: A novel trust dynamics model enhancing Artificial Intelligence collaboration with human users – Insights from a ChatGPT evaluation study},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194165210&origin=inward,10.1016/j.ins.2024.120759,scopus,2024
245,AI-driven assistants for education and research? A case study on ChatGPT for air transport management,"@article{2-s2.0-85171346480,
  title={AI-driven assistants for education and research? A case study on ChatGPT for air transport management},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85171346480&origin=inward,10.1016/j.jairtraman.2023.102483,scopus,2023
246,"Decoding ChatGPT: A taxonomy of existing research, current challenges, and possible future directions","@article{2-s2.0-85167397382,
  title={Decoding ChatGPT: A taxonomy of existing research, current challenges, and possible future directions},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85167397382&origin=inward,10.1016/j.jksuci.2023.101675,scopus,2023
247,Future applications of generative large language models: A data-driven case study on ChatGPT,"@article{2-s2.0-85189010126,
  title={Future applications of generative large language models: A data-driven case study on ChatGPT},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189010126&origin=inward,10.1016/j.technovation.2024.103002,scopus,2024
249,AI will transform science — now researchers must tame it,"@article{2-s2.0-85172226273,
  title={AI will transform science — now researchers must tame it},
  author={N/A},
  journal={N/A},
  year={7980},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85172226273&origin=inward,10.1038/d41586-023-02988-6,scopus,2023
250,Why teachers should explore ChatGPT’s potential — despite the risks,"@article{2-s2.0-85176558665,
  title={Why teachers should explore ChatGPT’s potential — despite the risks},
  author={N/A},
  journal={N/A},
  year={7987},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85176558665&origin=inward,10.1038/d41586-023-03505-5,scopus,2023
251,ChatGPT has entered the classroom: how LLMs could transform education,"@article{2-s2.0-85176593400,
  title={ChatGPT has entered the classroom: how LLMs could transform education},
  author={N/A},
  journal={N/A},
  year={7987},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85176593400&origin=inward,10.1038/d41586-023-03507-3,scopus,2023
252,"ChatGPT one year on: who is using it, how and why?","@article{2-s2.0-85178232959,
  title={ChatGPT one year on: who is using it, how and why?},
  author={N/A},
  journal={N/A},
  year={7990},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85178232959&origin=inward,10.1038/d41586-023-03798-6,scopus,2023
253,Building open-source AI," @article{Shrestha_2023, title={Building open-source AI}, volume={3}, ISSN={2662-8457}, url={http://dx.doi.org/10.1038/s43588-023-00540-0}, DOI={10.1038/s43588-023-00540-0}, number={11}, journal={Nature Computational Science}, publisher={Springer Science and Business Media LLC}, author={Shrestha, Yash Raj and von Krogh, Georg and Feuerriegel, Stefan}, year={2023}, month=oct, pages={908–911} }
",https://link.springer.com/article/10.1038/s43588-023-00540-0,10.1038/s43588-023-00540-0,springer,2023
254,GPT-4/4V's performance on the Japanese National Medical Licensing Examination," @article{Kawahara_2024, title={GPT-4/4V’s performance on the Japanese National Medical Licensing Examination}, ISSN={1466-187X}, url={http://dx.doi.org/10.1080/0142159X.2024.2342545}, DOI={10.1080/0142159x.2024.2342545}, journal={Medical Teacher}, publisher={Informa UK Limited}, author={Kawahara, Tomoki and Sumi, Yuki}, year={2024}, month=apr, pages={1–8} }
",http://dx.doi.org/10.1080/0142159X.2024.2342545,10.1080/0142159X.2024.2342545,"web_of_science, scopus",2024
255,Global insights and the impact of generative AI-ChatGPT on multidisciplinary: a systematic review and bibliometric analysis," @article{Khan_2024, title={Global insights and the impact of generative AI-ChatGPT on multidisciplinary: a systematic review and bibliometric analysis}, volume={36}, ISSN={1360-0494}, url={http://dx.doi.org/10.1080/09540091.2024.2353630}, DOI={10.1080/09540091.2024.2353630}, number={1}, journal={Connection Science}, publisher={Informa UK Limited}, author={Khan, Nauman and Khan, Zahid and Koubaa, Anis and Khan, Muhammad Khurram and Salleh, Rosli bin}, year={2024}, month=may }
",http://dx.doi.org/10.1080/09540091.2024.2353630,10.1080/09540091.2024.2353630,"web_of_science, scopus",2024
256,Prompt text classifications with transformer models! An exemplary introduction to prompt-based learning with large language models,"@article{2-s2.0-85142666964,
  title={Prompt text classifications with transformer models! An exemplary introduction to prompt-based learning with large language models},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85142666964&origin=inward,10.1080/15391523.2022.2142872,scopus,2023
257,ZDDR: A Zero-Shot Defender for Adversarial Samples Detection and Restoration," @article{Chen_2024, title={ZDDR: A Zero-Shot Defender for Adversarial Samples Detection and Restoration}, volume={12}, ISSN={2169-3536}, url={http://dx.doi.org/10.1109/ACCESS.2024.3356568}, DOI={10.1109/access.2024.3356568}, journal={IEEE Access}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Chen, Musheng and He, Guowei and Wu, Junhua}, year={2024}, pages={39081–39094} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10410848,10.1109/ACCESS.2024.3356568,ieee,2024
258,"A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges"," @article{Raiaan_2024, title={A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges}, volume={12}, ISSN={2169-3536}, url={http://dx.doi.org/10.1109/ACCESS.2024.3365742}, DOI={10.1109/access.2024.3365742}, journal={IEEE Access}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Raiaan, Mohaimenul Azam Khan and Mukta, Md. Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami}, year={2024}, pages={26839–26874} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433480,10.1109/ACCESS.2024.3365742,ieee,2024
259,"How Good Is ChatGPT at Face Biometrics? A First Look Into Recognition, Soft Biometrics, and Explainability"," @article{Deandres_Tame_2024, title={How Good Is ChatGPT at Face Biometrics? A First Look Into Recognition, Soft Biometrics, and Explainability}, volume={12}, ISSN={2169-3536}, url={http://dx.doi.org/10.1109/ACCESS.2024.3370437}, DOI={10.1109/access.2024.3370437}, journal={IEEE Access}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Deandres-Tame, Ivan and Tolosana, Ruben and Vera-Rodriguez, Ruben and Morales, Aythami and Fierrez, Julian and Ortega-Garcia, Javier}, year={2024}, pages={34390–34401} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445251,10.1109/ACCESS.2024.3370437,ieee,2024
260,Students’ Experiences of Using ChatGPT in an Undergraduate Programming Course," @article{Haindl_2024, title={Students’ Experiences of Using ChatGPT in an Undergraduate Programming Course}, volume={12}, ISSN={2169-3536}, url={http://dx.doi.org/10.1109/ACCESS.2024.3380909}, DOI={10.1109/access.2024.3380909}, journal={IEEE Access}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Haindl, Philipp and Weinberger, Gerald}, year={2024}, pages={43519–43529} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478015,10.1109/ACCESS.2024.3380909,"ieee, web_of_science, scopus",2024
261,Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis," @article{Mughal_2024, title={Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis}, volume={12}, ISSN={2169-3536}, url={http://dx.doi.org/10.1109/ACCESS.2024.3386969}, DOI={10.1109/access.2024.3386969}, journal={IEEE Access}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Mughal, Nimra and Mujtaba, Ghulam and Shaikh, Sarang and Kumar, Aveenash and Daudpota, Sher Muhammad}, year={2024}, pages={60943–60959} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504711,10.1109/ACCESS.2024.3386969,ieee,2024
262,A Transformer-BERT Integrated Model-Based Automatic Conversation Method Under English Context," @article{Li_2024, title={A Transformer-BERT Integrated Model-Based Automatic Conversation Method Under English Context}, volume={12}, ISSN={2169-3536}, url={http://dx.doi.org/10.1109/ACCESS.2024.3388100}, DOI={10.1109/access.2024.3388100}, journal={IEEE Access}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Li, Xing’an and Liu, Tangfa and Zhang, Longlong and Alqahtani, Fayez and Tolba, Amr}, year={2024}, pages={55757–55767} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10497586,10.1109/ACCESS.2024.3388100,ieee,2024
263,ChatGPT and Large Language Models in Healthcare: Opportunities and Risks," @inproceedings{Ali_2023, title={ChatGPT and Large Language Models in Healthcare: Opportunities and Risks}, url={http://dx.doi.org/10.1109/AIBThings58340.2023.10291020}, DOI={10.1109/aibthings58340.2023.10291020}, booktitle={2023 IEEE International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings)}, publisher={IEEE}, author={Ali, Hazrat and Qadir, Junaid and Alam, Tanvir and Househ, Mowafa and Shah, Zubair}, year={2023}, month=sep }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10291020,10.1109/AIBThings58340.2023.10291020,ieee,2023
264,ChatPapers: An AI Chatbot for Interacting with Academic Research," @inproceedings{Dean_2023, title={ChatPapers: An AI Chatbot for Interacting with Academic Research}, url={http://dx.doi.org/10.1109/AICS60730.2023.10470521}, DOI={10.1109/aics60730.2023.10470521}, booktitle={2023 31st Irish Conference on Artificial Intelligence and Cognitive Science (AICS)}, publisher={IEEE}, author={Dean, Max and Bond, Raymond R. and McTear, Michael F. and Mulvenna, Maurice D.}, year={2023}, month=dec }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10470521,10.1109/AICS60730.2023.10470521,"ieee, web_of_science, scopus",2023
265,Refactoring Programs Using Large Language Models with Few-Shot Examples," @inproceedings{Shirafuji_2023, title={Refactoring Programs Using Large Language Models with Few-Shot Examples}, url={http://dx.doi.org/10.1109/APSEC60848.2023.00025}, DOI={10.1109/apsec60848.2023.00025}, booktitle={2023 30th Asia-Pacific Software Engineering Conference (APSEC)}, publisher={IEEE}, author={Shirafuji, Atsushi and Oda, Yusuke and Suzuki, Jun and Morishita, Makoto and Watanobe, Yutaka}, year={2023}, month=dec }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479398,10.1109/APSEC60848.2023.00025,"ieee, scopus",2023
266,Revolutionizing Formative Assessment in STEM Fields: Leveraging AI and NLP Techniques," @inproceedings{Tan_2023, title={Revolutionizing Formative Assessment in STEM Fields: Leveraging AI and NLP Techniques}, url={http://dx.doi.org/10.1109/APSIPAASC58517.2023.10317226}, DOI={10.1109/apsipaasc58517.2023.10317226}, booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, publisher={IEEE}, author={Tan, Chi Wee and Lim, Khai Yin}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10317226,10.1109/APSIPAASC58517.2023.10317226,ieee,2023
267,"Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain"," @inproceedings{Huang_2023, title={Let’s Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain}, url={http://dx.doi.org/10.1109/ASE56229.2023.00075}, DOI={10.1109/ase56229.2023.00075}, booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, publisher={IEEE}, author={Huang, Qing and Wan, Zhenyu and Xing, Zhenchang and Wang, Changjing and Chen, Jieshan and Xu, Xiwei and Lu, Qinghua}, year={2023}, month=sep }
",http://dx.doi.org/10.1109/ASE56229.2023.00075,10.1109/ASE56229.2023.00075,web_of_science,2023
268,Multi-Lingual Sentence Alignment with GPT Models," @inproceedings{Liang_2023, title={Multi-Lingual Sentence Alignment with GPT Models}, url={http://dx.doi.org/10.1109/AiDAS60501.2023.10284652}, DOI={10.1109/aidas60501.2023.10284652}, booktitle={2023 4th International Conference on Artificial Intelligence and Data Sciences (AiDAS)}, publisher={IEEE}, author={Liang, Xiao and Khaw, Yen-Min Jasmina and Liew, Soung-Yue and Tan, Tien-Ping and Qin, DongHong}, year={2023}, month=sep }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10284652,10.1109/AiDAS60501.2023.10284652,ieee,2023
269,Selective Propositional Reasoning: A Cognitive Load-Aware Strategy for Enhanced Reasoning," @inproceedings{Yue_2023, title={Selective Propositional Reasoning: A Cognitive Load-Aware Strategy for Enhanced Reasoning}, url={http://dx.doi.org/10.1109/CBASE60015.2023.10439142}, DOI={10.1109/cbase60015.2023.10439142}, booktitle={2023 2nd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE)}, publisher={IEEE}, author={Yue, Yangming and Lei, Yi and Shi, Wanghua and Zhou, Yi}, year={2023}, month=nov }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439142,10.1109/CBASE60015.2023.10439142,ieee,2023
270,The Potential of Large Language Models as Tools for Analyzing Student Textual Evaluation: A Differential Analysis Between CS and Non-CS Students,"@article{2-s2.0-85194134617,
  title={The Potential of Large Language Models as Tools for Analyzing Student Textual Evaluation: A Differential Analysis Between CS and Non-CS Students},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194134617&origin=inward,10.1109/CEI60616.2023.10527886,scopus,2023
271,TrumorGPT: Query Optimization and Semantic Reasoning over Networks for Automated Fact-Checking," @inproceedings{Hang_2024, title={TrumorGPT: Query Optimization and Semantic Reasoning over Networks for Automated Fact-Checking}, url={http://dx.doi.org/10.1109/CISS59072.2024.10480162}, DOI={10.1109/ciss59072.2024.10480162}, booktitle={2024 58th Annual Conference on Information Sciences and Systems (CISS)}, publisher={IEEE}, author={Hang, Ching Nam and Yu, Pei-Duo and Tan, Chee Wei}, year={2024}, month=mar }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10480162,10.1109/CISS59072.2024.10480162,ieee,2024
272,Probing into the Fairness of Large Language Models: A Case Study of ChatGPT," @inproceedings{Li_2024, title={Probing into the Fairness of Large Language Models: A Case Study of ChatGPT}, url={http://dx.doi.org/10.1109/CISS59072.2024.10480206}, DOI={10.1109/ciss59072.2024.10480206}, booktitle={2024 58th Annual Conference on Information Sciences and Systems (CISS)}, publisher={IEEE}, author={Li, Yunqi and Zhang, Lanjing and Zhang, Yongfeng}, year={2024}, month=mar }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10480206,10.1109/CISS59072.2024.10480206,ieee,2024
273,Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data," @inproceedings{Feng_2023, title={Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data}, url={http://dx.doi.org/10.1109/COMPSAC57700.2023.00117}, DOI={10.1109/compsac57700.2023.00117}, booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, publisher={IEEE}, author={Feng, Yunhe and Vanam, Sreecharan and Cherukupally, Manasa and Zheng, Weijian and Qiu, Meikang and Chen, Haihua}, year={2023}, month=jun }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196869,10.1109/COMPSAC57700.2023.00117,"ieee, web_of_science, scopus",2023
274,Analysis of Plagiarism via ChatGPT on Domain-Specific Exams," @inproceedings{Jo_2023, title={Analysis of Plagiarism via ChatGPT on Domain-Specific Exams}, url={http://dx.doi.org/10.1109/CSCE60160.2023.00171}, DOI={10.1109/csce60160.2023.00171}, booktitle={2023 Congress in Computer Science, Computer Engineering, &amp;amp; Applied Computing (CSCE)}, publisher={IEEE}, author={Jo, Jinyoung and Choi, Sean}, year={2023}, month=jul }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487540,10.1109/CSCE60160.2023.00171,"ieee, scopus",2023
275,ChatGPT as a Game-Changer for Embedding Emojis in Faculty Feedback," @inproceedings{Kupershtein_2023, title={ChatGPT as a Game-Changer for Embedding Emojis in Faculty Feedback}, url={http://dx.doi.org/10.1109/CSCE60160.2023.00173}, DOI={10.1109/csce60160.2023.00173}, booktitle={2023 Congress in Computer Science, Computer Engineering, &amp;amp; Applied Computing (CSCE)}, publisher={IEEE}, author={Kupershtein, Ethan and Kumar, Yulia and Manikandan, Anjana and Morreale, Patricia and Li, J. Jenny}, year={2023}, month=jul }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487568,10.1109/CSCE60160.2023.00173,"ieee, scopus",2023
276,Empowering Healthcare Professionals and Patients with ChatGPT: Applications and Challenges," @inproceedings{Mosaiyebzadeh_2023, title={Empowering Healthcare Professionals and Patients with ChatGPT: Applications and Challenges}, url={http://dx.doi.org/10.1109/CSCE60160.2023.00233}, DOI={10.1109/csce60160.2023.00233}, booktitle={2023 Congress in Computer Science, Computer Engineering, &amp;amp; Applied Computing (CSCE)}, publisher={IEEE}, author={Mosaiyebzadeh, Fatemeh and Pouriyeh, Seyedamin and Parizi, Reza M. and Han, Meng and Dehbozorgi, Nasrin and Dorodchi, Mohsen and Batista, Daniel Macêdo}, year={2023}, month=jul }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487439,10.1109/CSCE60160.2023.00233,ieee,2023
277,Recommendations to Create Programming Exercises to Overcome ChatGPT,"@article{2-s2.0-85173600448,
  title={Recommendations to Create Programming Exercises to Overcome ChatGPT},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173600448&origin=inward,10.1109/CSEET58097.2023.00031,scopus,2023
278,A Comparative Review of GPT-4’s Applications in Medicine and High Decision Making," @inproceedings{Bitri_2023, title={A Comparative Review of GPT-4’s Applications in Medicine and High Decision Making}, url={http://dx.doi.org/10.1109/CoNTESA61248.2023.10384948}, DOI={10.1109/contesa61248.2023.10384948}, booktitle={2023 International Conference on Computing, Networking, Telecommunications &amp; Engineering Sciences Applications (CoNTESA)}, publisher={IEEE}, author={Bitri, Rea and Ali, Maaruf}, year={2023}, month=dec }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10384948,10.1109/CoNTESA61248.2023.10384948,ieee,2023
279,Embodied Epistemology: A Meta-Cognitive Exploration of Chatbot-Enabled Document Analysis," @inproceedings{Ainapure_2023, title={Embodied Epistemology: A Meta-Cognitive Exploration of Chatbot-Enabled Document Analysis}, url={http://dx.doi.org/10.1109/EASCT59475.2023.10392618}, DOI={10.1109/easct59475.2023.10392618}, booktitle={2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)}, publisher={IEEE}, author={Ainapure, Atman and Dhamane, Shreyash and Dhage, Sudhir}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10392618,10.1109/EASCT59475.2023.10392618,ieee,2023
280,"Opportunities, Challenges, Strategies, and Reforms for ChatGPT in Higher Education"," @inproceedings{Xie_2023, title={Opportunities, Challenges, Strategies, and Reforms for ChatGPT in Higher Education}, url={http://dx.doi.org/10.1109/EKI61071.2023.00010}, DOI={10.1109/eki61071.2023.00010}, booktitle={2023 International Conference on Educational Knowledge and Informatization (EKI)}, publisher={IEEE}, author={Xie, Xiaoli and Ding, Sheng}, year={2023}, month=sep }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10430333,10.1109/EKI61071.2023.00010,ieee,2023
281,Detection of AI-Generated Text Using Large Language Model," @inproceedings{Prajapati_2024, title={Detection of AI-Generated Text Using Large Language Model}, url={http://dx.doi.org/10.1109/ESIC60604.2024.10481602}, DOI={10.1109/esic60604.2024.10481602}, booktitle={2024 International Conference on Emerging Systems and Intelligent Computing (ESIC)}, publisher={IEEE}, author={Prajapati, Manish and Baliarsingh, Santos Kumar and Dora, Chinmayee and Bhoi, Ashutosh and Hota, Jhalak and Mohanty, Jasaswi Prasad}, year={2024}, month=feb }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10481602,10.1109/ESIC60604.2024.10481602,ieee,2024
282,Generating Multiple Choice Questions for Computing Courses Using Large Language Models,"@article{2-s2.0-85182978399,
  title={Generating Multiple Choice Questions for Computing Courses Using Large Language Models},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182978399&origin=inward,10.1109/FIE58773.2023.10342898,scopus,2023
283,Affective Computing: A Topic-Based SER Approach on Collaborative Discussions in Academic Setting," @inproceedings{Dehbozorgi_2023, title={Affective Computing: A Topic-Based SER Approach on Collaborative Discussions in Academic Setting}, url={http://dx.doi.org/10.1109/FIE58773.2023.10342963}, DOI={10.1109/fie58773.2023.10342963}, booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, publisher={IEEE}, author={Dehbozorgi, Nasrin and Kunuku, Mourya Teja}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342963,10.1109/FIE58773.2023.10342963,"ieee, scopus",2023
284,Challenging the Confirmation Bias: Using ChatGPT as a Virtual Peer for Peer Instruction in Computer Programming Education," @inproceedings{Dos_Santos_2023, title={Challenging the Confirmation Bias: Using ChatGPT as a Virtual Peer for Peer Instruction in Computer Programming Education}, url={http://dx.doi.org/10.1109/FIE58773.2023.10343247}, DOI={10.1109/fie58773.2023.10343247}, booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, publisher={IEEE}, author={Dos Santos, Otávio Lube and Cury, Davidson}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343247,10.1109/FIE58773.2023.10343247,"ieee, scopus",2023
285,Using ChatGPT for Homework: Does it Feel Like Cheating? (WIP)," @inproceedings{Bego_2023, title={Using ChatGPT for Homework: Does it Feel Like Cheating? (WIP)}, url={http://dx.doi.org/10.1109/FIE58773.2023.10343397}, DOI={10.1109/fie58773.2023.10343397}, booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, publisher={IEEE}, author={Bego, Campbell R.}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343397,10.1109/FIE58773.2023.10343397,ieee,2023
286,Exploring the Potential of Large Language Models to Generate Formative Programming Feedback," @inproceedings{Kiesler_2023, title={Exploring the Potential of Large Language Models to Generate Formative Programming Feedback}, url={http://dx.doi.org/10.1109/FIE58773.2023.10343457}, DOI={10.1109/fie58773.2023.10343457}, booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, publisher={IEEE}, author={Kiesler, Natalie and Lohr, Dominic and Keuning, Hieke}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343457,10.1109/FIE58773.2023.10343457,ieee,2023
287,Generative AI in Computing Education: Perspectives of Students and Instructors,"@article{2-s2.0-85182997655,
  title={Generative AI in Computing Education: Perspectives of Students and Instructors},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182997655&origin=inward,10.1109/FIE58773.2023.10343467,scopus,2023
288,Smart-Infinity: Fast Large Language Model Training using Near-Storage Processing on a Real System," @inproceedings{Jang_2024, title={Smart-Infinity: Fast Large Language Model Training using Near-Storage Processing on a Real System}, url={http://dx.doi.org/10.1109/HPCA57654.2024.00034}, DOI={10.1109/hpca57654.2024.00034}, booktitle={2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}, publisher={IEEE}, author={Jang, Hongsun and Song, Jaeyong and Jung, Jaewon and Park, Jaeyoung and Kim, Youngsok and Lee, Jinho}, year={2024}, month=mar }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10476401,10.1109/HPCA57654.2024.00034,ieee,2024
289,Auto-Grading Comprehension on Reference-Student Answer Pairs using the Siamese-based Transformer," @inproceedings{Sayeed_2024, title={Auto-Grading Comprehension on Reference-Student Answer Pairs using the Siamese-based Transformer}, url={http://dx.doi.org/10.1109/I2CT61223.2024.10543346}, DOI={10.1109/i2ct61223.2024.10543346}, booktitle={2024 IEEE 9th International Conference for Convergence in Technology (I2CT)}, publisher={IEEE}, author={Sayeed, Mohammed Azam and Gupta, Deepa and Kanjirangat, Vani}, year={2024}, month=apr }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10543346,10.1109/I2CT61223.2024.10543346,ieee,2024
290,Exploring Pre-processing Strategies and Feature Extraction in practical aspect for Effective Spam Detection," @inproceedings{Singh_2024, title={Exploring Pre-processing Strategies and Feature Extraction in practical aspect for Effective Spam Detection}, url={http://dx.doi.org/10.1109/IATMSI60426.2024.10502863}, DOI={10.1109/iatmsi60426.2024.10502863}, booktitle={2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)}, publisher={IEEE}, author={Singh, Harjeet and Sood, Shivani and Maity, Heranmoy and Kumar, Yogesh}, year={2024}, month=mar }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10502863,10.1109/IATMSI60426.2024.10502863,ieee,2024
291,AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education," @inproceedings{Laato_2023, title={AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education}, url={http://dx.doi.org/10.1109/ICALT58122.2023.00072}, DOI={10.1109/icalt58122.2023.00072}, booktitle={2023 IEEE International Conference on Advanced Learning Technologies (ICALT)}, publisher={IEEE}, author={Laato, Samuli and Morschheuser, Benedikt and Hamari, Juho and Björne, Jari}, year={2023}, month=jul }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260931,10.1109/ICALT58122.2023.00072,"ieee, web_of_science, scopus",2023
292,Boosting LLMS with Ontology-Aware Prompt for Ner Data Augmentation," @inproceedings{Luo_2024, title={Boosting LLMS with Ontology-Aware Prompt for Ner Data Augmentation}, url={http://dx.doi.org/10.1109/ICASSP48485.2024.10446860}, DOI={10.1109/icassp48485.2024.10446860}, booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, publisher={IEEE}, author={Luo, Zhizhao and Wang, Youchen and Ke, Wenjun and Qi, Rui and Guo, Yikai and Wang, Peng}, year={2024}, month=apr }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446860,10.1109/ICASSP48485.2024.10446860,ieee,2024
293,How Big Can It Get? A comparative analysis of LLMs in architecture and scaling," @inproceedings{Yousri_2023, title={How Big Can It Get? A comparative analysis of LLMs in architecture and scaling}, url={http://dx.doi.org/10.1109/ICCA59364.2023.10401818}, DOI={10.1109/icca59364.2023.10401818}, booktitle={2023 International Conference on Computer and Applications (ICCA)}, publisher={IEEE}, author={Yousri, Ramez and Safwat, Soha}, year={2023}, month=nov }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10401818,10.1109/ICCA59364.2023.10401818,ieee,2023
294,ChatGPT: A Comprehensive Review of a Large Language Model," @inproceedings{Kaswan_2023, title={ChatGPT: A Comprehensive Review of a Large Language Model}, url={http://dx.doi.org/10.1109/ICCSAI59793.2023.10421090}, DOI={10.1109/iccsai59793.2023.10421090}, booktitle={2023 International Conference on Communication, Security and Artificial Intelligence (ICCSAI)}, publisher={IEEE}, author={Kaswan, Kuldeep Singh and Dhatterwal, Jagjit Singh and Batra, Reenu and Yadav, Dileep Kumar}, year={2023}, month=nov }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10421090,10.1109/ICCSAI59793.2023.10421090,ieee,2023
295,Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse," @inproceedings{Lee_2023, title={Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse}, url={http://dx.doi.org/10.1109/ICDMW60847.2023.00183}, DOI={10.1109/icdmw60847.2023.00183}, booktitle={2023 IEEE International Conference on Data Mining Workshops (ICDMW)}, publisher={IEEE}, author={Lee, Seungyoon and Jung, Dahyun and Park, Chanjun and Lee, Seolhwa and Lim, Heuiseok}, year={2023}, month=dec }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10411543,10.1109/ICDMW60847.2023.00183,ieee,2023
296,Using LLM Artificial Intelligence Systems as Complex SQL Programming Assistants," @inproceedings{Pornphol_2024, title={Using LLM Artificial Intelligence Systems as Complex SQL Programming Assistants}, url={http://dx.doi.org/10.1109/ICIET60671.2024.10542806}, DOI={10.1109/iciet60671.2024.10542806}, booktitle={2024 12th International Conference on Information and Education Technology (ICIET)}, publisher={IEEE}, author={Pornphol, Putsadee and Chittayasothorn, Suphamit}, year={2024}, month=mar }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10542806,10.1109/ICIET60671.2024.10542806,ieee,2024
297,Multi-Agent RAG Chatbot Architecture for Decision Support in Net-Zero Emission Energy Systems," @inproceedings{Gamage_2024, title={Multi-Agent RAG Chatbot Architecture for Decision Support in Net-Zero Emission Energy Systems}, url={http://dx.doi.org/10.1109/ICIT58233.2024.10540920}, DOI={10.1109/icit58233.2024.10540920}, booktitle={2024 IEEE International Conference on Industrial Technology (ICIT)}, publisher={IEEE}, author={Gamage, Gihan and Mills, Nishan and De Silva, Daswin and Manic, Milos and Moraliyage, Harsha and Jennings, Andrew and Alahakoon, Damminda}, year={2024}, month=mar }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10540920,10.1109/ICIT58233.2024.10540920,ieee,2024
298,PCR-Chain: Partial Code Reuse Assisted by Hierarchical Chaining of Prompts on Frozen Copilot,"@inproceedings{10.1109/ICSE-Companion58688.2023.00013,
author = {Huang, Qing and Zhu, Jiahui and Li, Zhilong and Xing, Zhenchang and Wang, Changjing and Xu, Xiwei},
title = {PCR-Chain: Partial Code Reuse Assisted by Hierarchical Chaining of Prompts on Frozen Copilot},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00013},
doi = {10.1109/ICSE-Companion58688.2023.00013},
abstract = {API documentation, technical blogs and programming Q&amp;A sites contain a large amount of partial code that can be reused in programming tasks. However, due to unresolved simple names and last-mile syntax errors, such partial code is frequently not compilable. To facilitate partial code reuse, we develop PCR-Chain for resolving FQNs and fixing last-mile syntax errors in partial code based on a giant pre-trained code model (e.g., Copilot). Methodologically, PCR-Chain is backed up by the underlying global-level prompt architecture (which combines three design ideas: hierarchical task breakdown, prompt composition including sequential and conditional structures, and a mix of prompt-based AI and non-AI units) and the local-level prompt design. Technically, we propose PCR-Chain, which employs in-context learning rather than supervised fine-tuning with gradient updates on downstream task data. This approach enables the frozen, giant pre-trained code model to learn the desired behavior for a specific task through behavior-describing prompts and imitate it to complete the task. Experimental results show that PCR-Chain automatically resolves the FQNs and fixes last-mile syntax errors in 50 partial code samples collected from Stack Overflow with high success rates, without requiring any program analysis. The correct execution of the unit, module, and PCR-Chain demonstrates the effectiveness of the prompt design, prompt composition, and prompt architecture.Website:https://github.com/SE-qinghuang/PCR-ChainDemo Video: https://youtu.be/6HGRNdc2_JE},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {1–5},
numpages = {5},
keywords = {in-context learning, pre-trained language model, frozen copilot, AI chain, hierarchical prompts},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

",https://doi.org/10.1109/ICSE-Companion58688.2023.00013,10.1109/ICSE-Companion58688.2023.00013,acm,2023
299,Large Language Models for Software Engineering: Survey and Open Problems," @inproceedings{Fan_2023, title={Large Language Models for Software Engineering: Survey and Open Problems}, url={http://dx.doi.org/10.1109/ICSE-FoSE59343.2023.00008}, DOI={10.1109/icse-fose59343.2023.00008}, booktitle={2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE)}, publisher={IEEE}, author={Fan, Angela and Gokkaya, Beliz and Harman, Mark and Lyubarskiy, Mitya and Sengupta, Shubho and Yoo, Shin and Zhang, Jie M.}, year={2023}, month=may }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10449667,10.1109/ICSE-FoSE59343.2023.00008,"ieee, web_of_science, scopus",2023
300,Towards Using Few-Shot Prompt Learning for Automating Model Completion,"@inproceedings{10.1109/ICSE-NIER58687.2023.00008,
author = {Chaaben, Meriem Ben and Burgue\~{n}o, Lola and Sahraoui, Houari},
title = {Towards Using Few-Shot Prompt Learning for Automating Model Completion},
year = {2023},
isbn = {9798350300390},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER58687.2023.00008},
doi = {10.1109/ICSE-NIER58687.2023.00008},
abstract = {We propose a simple yet a novel approach to improve completion in domain modeling activities. Our approach exploits the power of large language models by using few-shot prompt learning without the need to train or fine-tune those models with large datasets that are scarce in this field. We implemented our approach and tested it on the completion of static and dynamic domain diagrams. Our initial evaluation shows that such an approach is effective and can be integrated in different ways during the modeling activities.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {7–12},
numpages = {6},
keywords = {language models, few-shot learning, prompt learning, domain modeling, model completion},
location = {Melbourne, Australia},
series = {ICSE-NIER '23}
}

",https://doi.org/10.1109/ICSE-NIER58687.2023.00008,10.1109/ICSE-NIER58687.2023.00008,acm,2023
301,Automated Repair of Programs from Large Language Models," @inproceedings{Fan_2023, title={Automated Repair of Programs from Large Language Models}, url={http://dx.doi.org/10.1109/ICSE48619.2023.00128}, DOI={10.1109/icse48619.2023.00128}, booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)}, publisher={IEEE}, author={Fan, Zhiyu and Gao, Xiang and Mirchev, Martin and Roychoudhury, Abhik and Tan, Shin Hwei}, year={2023}, month=may }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172854,10.1109/ICSE48619.2023.00128,"ieee, acm",2023
302,Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering,"@inproceedings{10.1109/ICSE48619.2023.00169,
author = {McGuire, Sean and Schultz, Erin and Ayoola, Bimpe and Ralph, Paul},
title = {Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00169},
doi = {10.1109/ICSE48619.2023.00169},
abstract = {Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or ""pillars""---environmental, social, economic, technical and individual. However; these pillars are theoretically underdeveloped and require refinement. Objectives: The objective of this paper is to generate a better theory of SSE. Method: First, a scoping review was conducted to understand the state of research on SSE and identify existing models thereof. Next, a meta-synthesis of qualitative research on SSE was conducted to critique and improve the existing models identified. Results: 961 potentially relevant articles were extracted from five article databases. These articles were de-duplicated and then screened independently by two screeners, leaving 243 articles to examine. Of these, 109 were non-empirical, the most common empirical method was systematic review, and no randomized controlled experiments were found. Most papers focus on ecological sustainability (158) and the sustainability of software products (148) rather than processes. A meta-synthesis of 36 qualitative studies produced several key propositions, most notably, that sustainability is stratified (has different meanings at different levels of abstraction) and multisystemic (emerges from interactions among multiple social, technical, and sociotechnical systems). Conclusion: The academic literature on SSE is surprisingly non-empirical. More empirical evaluations of specific sustainability interventions are needed. The sustainability of software development products and processes should be conceptualized as multisystemic and stratified, and assessed accordingly.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {1996–2008},
numpages = {13},
keywords = {meta-synthesis, scoping review, sustainable software engineering, software engineering, sustainable development},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

",https://doi.org/10.1109/ICSE48619.2023.00169,10.1109/ICSE48619.2023.00169,acm,2023
303,ChatGPT and Software Testing Education: Promises & Perils," @inproceedings{Jalil_2023, title={ChatGPT and Software Testing Education: Promises &amp; Perils}, url={http://dx.doi.org/10.1109/ICSTW58534.2023.00078}, DOI={10.1109/icstw58534.2023.00078}, booktitle={2023 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, publisher={IEEE}, author={Jalil, Sajed and Rafi, Suzzana and LaToza, Thomas D. and Moran, Kevin and Lam, Wing}, year={2023}, month=apr }
",http://arxiv.org/pdf/2302.03287v3.pdf,10.1109/ICSTW58534.2023.00078,arxiv,2023
304,"ChatGPT: More Human-Like Than Computer-Like, but Not Necessarily in a Good Way"," @inproceedings{Azaria_2023, title={ChatGPT: More Human-Like Than Computer-Like, but Not Necessarily in a Good Way}, url={http://dx.doi.org/10.1109/ICTAI59109.2023.00074}, DOI={10.1109/ictai59109.2023.00074}, booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, publisher={IEEE}, author={Azaria, Amos}, year={2023}, month=nov }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356430,10.1109/ICTAI59109.2023.00074,ieee,2023
305,Transforming Software Requirements into User Stories with GPT-3.5 -: An AI-Powered Approach," @inproceedings{Oswal_2024, title={Transforming Software Requirements into User Stories with GPT-3.5 -: An AI-Powered Approach}, url={http://dx.doi.org/10.1109/IDCIoT59759.2024.10467750}, DOI={10.1109/idciot59759.2024.10467750}, booktitle={2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)}, publisher={IEEE}, author={Oswal, Jay U. and Kanakia, Harshil T. and Suktel, Devvrat}, year={2024}, month=jan }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467750,10.1109/IDCIoT59759.2024.10467750,ieee,2024
306,A Deep Understanding Video Q&A System for Film Education in Acting Department," @inproceedings{Wu_2023, title={A Deep Understanding Video Q&amp;A System for Film Education in Acting Department}, url={http://dx.doi.org/10.1109/IEIR59294.2023.10391232}, DOI={10.1109/ieir59294.2023.10391232}, booktitle={2023 International Conference on Intelligent Education and Intelligent Research (IEIR)}, publisher={IEEE}, author={Wu, Zhengqian and Li, Ruizhe and Guo, Jiahao and Wang, Zhongyuan and Liang, Chao}, year={2023}, month=nov }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10391232,10.1109/IEIR59294.2023.10391232,ieee,2023
307,Pre-made Empowering Artificial Intelligence and ChatGPT: The Growing Importance of Human AI-Experts,"@article{2-s2.0-85182016638,
  title={Pre-made Empowering Artificial Intelligence and ChatGPT: The Growing Importance of Human AI-Experts},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182016638&origin=inward,10.1109/IISA59645.2023.10345880,scopus,2023
308,A Framework for Identifying Diabetic Retinopathy Based on patch attention and lesion location," @inproceedings{Xia_2023, title={A Framework for Identifying Diabetic Retinopathy Based on patch attention and lesion location}, url={http://dx.doi.org/10.1109/IJCNN54540.2023.10191557}, DOI={10.1109/ijcnn54540.2023.10191557}, booktitle={2023 International Joint Conference on Neural Networks (IJCNN)}, publisher={IEEE}, author={Xia, Zhuoqun and Hu, Hangyu and Li, Wenjing and Jiang, Qisheng and Zhu, Chengzhang and Zou, Ziwei}, year={2023}, month=jun }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10191557,10.1109/IJCNN54540.2023.10191557,ieee,2023
309,Specialized Syntactic Quran Search Engines: Evaluation and Limitations," @inproceedings{Bakr_2023, title={Specialized Syntactic Quran Search Engines: Evaluation and Limitations}, url={http://dx.doi.org/10.1109/IMSA58542.2023.10217550}, DOI={10.1109/imsa58542.2023.10217550}, booktitle={2023 Intelligent Methods, Systems, and Applications (IMSA)}, publisher={IEEE}, author={Bakr, Abdollah and Yousef, Ahmed H. and Arafa, Tamer}, year={2023}, month=jul }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10217550,10.1109/IMSA58542.2023.10217550,ieee,2023
310,Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers,"@article{2-s2.0-85139537385,
  title={Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers},
  author={N/A},
  journal={N/A},
  year={2022},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85139537385&origin=inward,10.1109/IROS47612.2022.9981810,scopus,2022
311,Implementing Generative AI and Large Language Models in Education,"@article{2-s2.0-85184809261,
  title={Implementing Generative AI and Large Language Models in Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184809261&origin=inward,10.1109/ISAS60782.2023.10391517,scopus,2023
312,LLM-Driven SAT Impact on Phishing Defense: A Cross-Sectional Analysis," @inproceedings{__2024, title={LLM-Driven SAT Impact on Phishing Defense: A Cross-Sectional Analysis}, url={http://dx.doi.org/10.1109/ISDFS60797.2024.10527274}, DOI={10.1109/isdfs60797.2024.10527274}, booktitle={2024 12th International Symposium on Digital Forensics and Security (ISDFS)}, publisher={IEEE}, author={İŞ, Hafzullah}, year={2024}, month=apr }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10527274,10.1109/ISDFS60797.2024.10527274,ieee,2024
313,Spectrogram-Based Deep Learning for Flute Audition Assessment and Intelligent Feedback," @inproceedings{Agarwal_2023, title={Spectrogram-Based Deep Learning for Flute Audition Assessment and Intelligent Feedback}, url={http://dx.doi.org/10.1109/ISM59092.2023.00045}, DOI={10.1109/ism59092.2023.00045}, booktitle={2023 IEEE International Symposium on Multimedia (ISM)}, publisher={IEEE}, author={Agarwal, Manu and Greer, Ross}, year={2023}, month=dec }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473475,10.1109/ISM59092.2023.00045,ieee,2023
314,Vulnerability of Machine Learning Approaches Applied in IoT-Based Smart Grid: A Review," @article{Zhang_2024, title={Vulnerability of Machine Learning Approaches Applied in IoT-Based Smart Grid: A Review}, volume={11}, ISSN={2372-2541}, url={http://dx.doi.org/10.1109/JIOT.2024.3349381}, DOI={10.1109/jiot.2024.3349381}, number={11}, journal={IEEE Internet of Things Journal}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Zhang, Zhenyong and Liu, Mengxiang and Sun, Mingyang and Deng, Ruilong and Cheng, Peng and Niyato, Dusit and Chow, Mo-Yuen and Chen, Jiming}, year={2024}, month=jun, pages={18951–18975} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10380506,10.1109/JIOT.2024.3349381,ieee,2024
315,UnstrPrompt: Large Language Model Prompt for Driving in Unstructured Scenarios," @article{Li_2024, title={UnstrPrompt: Large Language Model Prompt for Driving in Unstructured Scenarios}, volume={8}, ISSN={2469-729X}, url={http://dx.doi.org/10.1109/JRFID.2024.3367975}, DOI={10.1109/jrfid.2024.3367975}, journal={IEEE Journal of Radio Frequency Identification}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Li, Yuchen and Li, Luxi and Wu, Zizhang and Bing, Zhenshan and Xuanyuan, Zhe and Knoll, Alois Christian and Chen, Long}, year={2024}, pages={367–375} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440443,10.1109/JRFID.2024.3367975,ieee,2024
316,Educating Augmented Programmers,"@article{2-s2.0-85177833523,
  title={Educating Augmented Programmers},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85177833523&origin=inward,10.1109/MC.2023.3313325,scopus,2023
317,The Rise of Generative Artificial Intelligence in Healthcare," @inproceedings{Kuzlu_2023, title={The Rise of Generative Artificial Intelligence in Healthcare}, url={http://dx.doi.org/10.1109/MECO58584.2023.10155107}, DOI={10.1109/meco58584.2023.10155107}, booktitle={2023 12th Mediterranean Conference on Embedded Computing (MECO)}, publisher={IEEE}, author={Kuzlu, Murat and Xiao, Zhenxin and Sarp, Salih and Catak, Ferhat Ozgur and Gurler, Necip and Guler, Ozgur}, year={2023}, month=jun }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155107,10.1109/MECO58584.2023.10155107,ieee,2023
318,ChatGPT in IoT Systems: Arduino Case Studies," @inproceedings{Petrovi__2023, title={ChatGPT in IoT Systems: Arduino Case Studies}, url={http://dx.doi.org/10.1109/MIEL58498.2023.10315791}, DOI={10.1109/miel58498.2023.10315791}, booktitle={2023 IEEE 33rd International Conference on Microelectronics (MIEL)}, publisher={IEEE}, author={Petrović, N. and Koničanin, S. and Suljović, S.}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10315791,10.1109/MIEL58498.2023.10315791,ieee,2023
319,On ChatGPT: Perspectives from Software Engineering Students," @inproceedings{Hanifi_2023, title={On ChatGPT: Perspectives from Software Engineering Students}, url={http://dx.doi.org/10.1109/QRS60937.2023.00028}, DOI={10.1109/qrs60937.2023.00028}, booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)}, publisher={IEEE}, author={Hanifi, Khadija and Cetin, Orcun and Yilmaz, Cemal}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366692,10.1109/QRS60937.2023.00028,"ieee, scopus",2023
320,Analysis of ChatGPT Performance in Computer Engineering Exams," @article{Rodriguez_Echeverr_a_2024, title={Analysis of ChatGPT Performance in Computer Engineering Exams}, volume={19}, ISSN={2374-0132}, url={http://dx.doi.org/10.1109/RITA.2024.3381842}, DOI={10.1109/rita.2024.3381842}, journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Rodriguez-Echeverría, Roberto and Gutiérrez, Juan D. and Conejero, José M. and Prieto, Álvaro E.}, year={2024}, pages={71–80} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478897,10.1109/RITA.2024.3381842,"ieee, web_of_science, scopus",2024
321,How Useful TutorBot+ is for Teaching and Learning in Programming Courses: a Preliminary Study,"@article{2-s2.0-85179006268,
  title={How Useful TutorBot+ is for Teaching and Learning in Programming Courses: a Preliminary Study},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85179006268&origin=inward,10.1109/SCCC59417.2023.10315697,scopus,2023
322,“We Need To Talk About ChatGPT”: The Future of AI and Higher Education," @inproceedings{Neumann_2023, title={“We Need To Talk About ChatGPT”: The Future of AI and Higher Education}, url={http://dx.doi.org/10.1109/SEENG59157.2023.00010}, DOI={10.1109/seeng59157.2023.00010}, booktitle={2023 IEEE/ACM 5th International Workshop on Software Engineering Education for the Next Generation (SEENG)}, publisher={IEEE}, author={Neumann, Michael and Rauschenberger, Maria and Schön, Eva-Maria}, year={2023}, month=may }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10190438,10.1109/SEENG59157.2023.00010,"ieee, web_of_science, scopus",2023
323,Clinical Knowledge and Reasoning Abilities of Large Language Models in Pharmacy: A Comparative Study on the NAPLEX Exam," @inproceedings{Angel_2023, title={Clinical Knowledge and Reasoning Abilities of Large Language Models in Pharmacy: A Comparative Study on the NAPLEX Exam}, url={http://dx.doi.org/10.1109/SNAMS60348.2023.10375395}, DOI={10.1109/snams60348.2023.10375395}, booktitle={2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS)}, publisher={IEEE}, author={Angel, Mirana and Patel, Anuj and Alachkar, Amal and Baldi, Pierre}, year={2023}, month=nov }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10375395,10.1109/SNAMS60348.2023.10375395,ieee,2023
324,AI and Veterinary Medicine: Performance of Large Language Models on the North American Licensing Examination," @inproceedings{Angel_2023, title={AI and Veterinary Medicine: Performance of Large Language Models on the North American Licensing Examination}, url={http://dx.doi.org/10.1109/SNAMS60348.2023.10375414}, DOI={10.1109/snams60348.2023.10375414}, booktitle={2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS)}, publisher={IEEE}, author={Angel, Mirana and Patel, Anuj and Xing, Haiyi and Balsz, Dylan and Arbuckle, Cody and Bruyette, David and Baldi, Pierre}, year={2023}, month=nov }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10375414,10.1109/SNAMS60348.2023.10375414,ieee,2023
325,Transformative Potentials and Ethical Considerations of AI Tools in Higher Education: Case Studies and Reflections,"@article{2-s2.0-85191707452,
  title={Transformative Potentials and Ethical Considerations of AI Tools in Higher Education: Case Studies and Reflections},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85191707452&origin=inward,10.1109/SoutheastCon52093.2024.10500042,scopus,2024
327,A CTC Alignment-Based Non-Autoregressive Transformer for End-to-End Automatic Speech Recognition,"@article{10.1109/TASLP.2023.3263789,
author = {Fan, Ruchao and Chu, Wei and Chang, Peng and Alwan, Abeer},
title = {A CTC Alignment-Based Non-Autoregressive Transformer for End-to-End Automatic Speech Recognition},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3263789},
doi = {10.1109/TASLP.2023.3263789},
abstract = {Recently, end-to-end models have been widely used in automatic speech recognition (ASR) systems. Two of the most representative approaches are connectionist temporal classification (CTC) and attention-based encoder-decoder (AED) models. Autoregressive transformers, variants of AED, adopt an autoregressive mechanism for token generation and thus are relatively slow during inference. In this article, we present a comprehensive study of a CTC Alignment-based Single-Step Non-Autoregressive Transformer (CASS-NAT) for end-to-end ASR. In CASS-NAT, word embeddings in the autoregressive transformer (AT) are substituted with token-level acoustic embeddings (TAE) that are extracted from encoder outputs with the acoustical boundary information offered by the CTC alignment. TAE can be obtained in parallel, resulting in a parallel generation of output tokens. During training, Viterbi-alignment is used for TAE generation, and multiple training strategies are further explored to improve the word error rate (WER) performance. During inference, an error-based alignment sampling method is investigated in depth to reduce the alignment mismatch in the training and testing processes. Experimental results show that the CASS-NAT has a WER that is close to AT on various ASR tasks, while providing a &lt;inline-formula&gt;&lt;tex-math notation=""LaTeX""&gt;$sim$&lt;/tex-math&gt;&lt;/inline-formula&gt;24x inference speedup. With and without self-supervised learning, we achieve new state-of-the-art results for non-autoregressive models on several datasets. We also analyze the behavior of the CASS-NAT decoder to explain why it can perform similarly to AT. We find that TAEs have similar functionality to word embeddings for grammatical structures, which might indicate the possibility of learning some semantic information from TAEs without a language model.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = {mar},
pages = {1436–1448},
numpages = {13}
}

",https://doi.org/10.1109/TASLP.2023.3263789,10.1109/TASLP.2023.3263789,acm,2023
328,Factors That Influence Automatic Recognition of African-American Vernacular English in Machine-Learning Models,"@article{10.1109/TASLP.2023.3331139,
author = {Hamel, Emma and Kani, Nickvash},
title = {Factors That Influence Automatic Recognition of African-American Vernacular English in Machine-Learning Models},
year = {2023},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3331139},
doi = {10.1109/TASLP.2023.3331139},
abstract = {Racial bias is a well-documented problem in natural language processing (NLP). The dialectal language used by marginalized groups is often misclassified or mischaracterized by language models, which in turn can further disenfranchise these populations. Previous works have noted that some popular language identification (LID) models perform worse when classifying tweets that contain African-American Vernacular English (AAVE) than when classifying tweets that contain White-Aligned English (WAE). This work examines the factors that contribute to racial bias in language models for the LID task. The contributions of this work are two-fold. First, a thorough analysis demonstrates that a lack of “unique” language-specific n-gram features in an LID model can lead to poor performance on dialectal data, especially on shorter-length inputs like those typically found on social media. Second, based on these findings, this work introduces and illustrates the efficacy of two simple yet accurate solutions: i.) mining “unique” n-gram features and ii.) including examples of dialectal English in training data. These solutions mitigate the accuracy gap between WAE and AAVE which some language identification models demonstrate when classifying shorter inputs. Mining for unique features and training with a more diverse dataset can improve the disparity on short-length sequences by 6% and 9.8% respectively.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = {nov},
pages = {509–516},
numpages = {8}
}

",https://doi.org/10.1109/TASLP.2023.3331139,10.1109/TASLP.2023.3331139,acm,2023
329,Advanced Long-Content Speech Recognition With Factorized Neural Transducer,"@article{10.1109/TASLP.2024.3350893,
author = {Gong, Xun and Wu, Yu and Li, Jinyu and Liu, Shujie and Zhao, Rui and Chen, Xie and Qian, Yanmin},
title = {Advanced Long-Content Speech Recognition With Factorized Neural Transducer},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3350893},
doi = {10.1109/TASLP.2024.3350893},
abstract = {Long-content automatic speech recognition (ASR) has obtained increasing interest in recent years, as it captures the relationship among consecutive historical utterances while decoding the current utterance. In this paper, we propose two novel approaches, which integrate long-content information into the factorized neural transducer (FNT) based architecture in both non-streaming (referred to as &lt;italic&gt;LongFNT&lt;/italic&gt;) and streaming (referred to as &lt;italic&gt;SLongFNT&lt;/italic&gt;) scenarios. We first investigate whether long-content transcriptions can improve the vanilla conformer transducer (C-T) models. Our experiments indicate that the vanilla C-T models do not exhibit improved performance when utilizing long-content transcriptions, possibly due to the predictor network of C-T models not functioning as a pure language model. Instead, FNT shows its potential in utilizing long-content information, where we propose the &lt;italic&gt;LongFNT&lt;/italic&gt; model and explore the impact of long-content information in both text (LongFNT-Text) and speech (LongFNT-Speech). The proposed LongFNT-Text and LongFNT-Speech models further complement each other to achieve better performance, with transcription history proving more valuable to the model. The effectiveness of our LongFNT approach is evaluated on LibriSpeech and GigaSpeech corpora, and obtains relative 19% and 12% word error rate reduction, respectively. Furthermore, we extend the LongFNT model to the streaming scenario, which is named &lt;italic&gt;SLongFNT&lt;/italic&gt;, consisting of SLongFNT-Text and SLongFNT-Speech approaches to utilize long-content text and speech information. Experiments show that the proposed SLongFNT model achieves relative 26% and 17% WER reduction on LibriSpeech and GigaSpeech respectively while keeping a good latency, compared to the FNT baseline. Overall, our proposed &lt;italic&gt;LongFNT&lt;/italic&gt; and &lt;italic&gt;SLongFNT&lt;/italic&gt; highlight the significance of considering long-content speech and transcription knowledge for improving both non-streaming and streaming speech recognition systems.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = {jan},
pages = {1803–1815},
numpages = {13}
}

",https://doi.org/10.1109/TASLP.2024.3350893,10.1109/TASLP.2024.3350893,acm,2024
330,TrICy: Trigger-Guided Data-to-Text Generation With Intent Aware Attention-Copy,"@article{10.1109/TASLP.2024.3353574,
author = {Agarwal, Vibhav and Ghosh, Sourav and BSS, Harichandana and Arora, Himanshu and Raja, Barath Raj Kandur},
title = {TrICy: Trigger-Guided Data-to-Text Generation With Intent Aware Attention-Copy},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3353574},
doi = {10.1109/TASLP.2024.3353574},
abstract = {Data-to-text (D2T) generation is a crucial task in many natural language understanding (NLU) applications and forms the foundation of task-oriented dialog systems. In the context of conversational AI solutions that can work directly with local data on the user's device, architectures utilizing large pre-trained language models (PLMs) are impractical for on-device deployment due to a high memory footprint. To this end, we propose TrICy, a novel lightweight framework for an enhanced D2T task that generates text sequences based on the intent in context and may further be guided by user-provided triggers. We leverage an attention-copy mechanism to predict out-of-vocabulary (OOV) words accurately. Performance analyses on E2E NLG dataset [Novikova et al. 2017] (BLEU: 66.43%, ROUGE-L: 70.14%), WebNLG dataset [Gardent et al. 2017] (BLEU: &lt;italic&gt;Seen&lt;/italic&gt; 64.08%, &lt;italic&gt;Unseen&lt;/italic&gt; 52.35%), and our Custom dataset related to text messaging applications, showcase our architecture's effectiveness. Moreover, we show that by leveraging an optional trigger input, data-to-text generation quality increases significantly and achieves the new SOTA score of 69.29% BLEU for E2E NLG. Furthermore, our analyses show that TrICy achieves at least 24% and 3% improvement in BLEU and METEOR respectively over LLMs like GPT-3, ChatGPT, and Llama 2. We also demonstrate that in some scenarios, performance improvement due to triggers is observed even when they are absent in training.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = {jan},
pages = {1173–1184},
numpages = {12}
}

",https://doi.org/10.1109/TASLP.2024.3353574,10.1109/TASLP.2024.3353574,acm,2024
331,Active Discovering New Slots for Task-Oriented Conversation,"@article{10.1109/TASLP.2024.3374060,
author = {Wu, Yuxia and Dai, Tianhao and Zheng, Zhedong and Liao, Lizi},
title = {Active Discovering New Slots for Task-Oriented Conversation},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3374060},
doi = {10.1109/TASLP.2024.3374060},
abstract = {Existing task-oriented conversational systems heavily rely on domain ontologies with pre-defined slots and candidate values. In practical settings, these prerequisites are hard to meet, due to the emerging new user requirements and ever-changing scenarios. To mitigate these issues for better interaction performance, there are efforts working towards detecting out-of-vocabulary values or discovering new slots under unsupervised or semi-supervised learning paradigms. However, overemphasizing on the conversation data patterns alone induces these methods to yield noisy and arbitrary slot results. To facilitate the pragmatic utility, real-world systems tend to provide a stringent amount of human labeling quota, which offers an authoritative way to obtain accurate and meaningful slot assignments. Nonetheless, it also brings forward the high requirement of utilizing such quota efficiently. Hence, we formulate a general new slot discovery task in an information extraction fashion and incorporate it into an active learning framework to realize human-in-the-loop learning. Specifically, we leverage existing language tools to extract value candidates where the corresponding labels are further leveraged as weak supervision signals. Based on these, we propose a bi-criteria selection scheme which incorporates two major strategies, namely, uncertainty-based and diversity-based sampling to efficiently identify terms of interest. We conduct extensive experiments on several public datasets and compare with a bunch of competitive baselines to demonstrate the effectiveness of our method.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = {mar},
pages = {2062–2072},
numpages = {11}
}

",https://doi.org/10.1109/TASLP.2024.3374060,10.1109/TASLP.2024.3374060,acm,2024
332,Developing Future Computational Thinking in Foundational CS Education: A Case Study From a Liberal Education University in India,"@article{2-s2.0-85193278986,
  title={Developing Future Computational Thinking in Foundational CS Education: A Case Study From a Liberal Education University in India},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193278986&origin=inward,10.1109/TE.2024.3394060,scopus,2024
333,ChatGPT-Aided QoS Estimation Le eraging Outage Probability of Mobile Networks Limited by α-η-µ Fading and α-η-µ Co-channel Interference," @inproceedings{Mili__2023, title={ChatGPT-Aided QoS Estimation Le eraging Outage Probability of Mobile Networks Limited by α-η-µ Fading and α-η-µ Co-channel Interference}, url={http://dx.doi.org/10.1109/TELSIKS57806.2023.10316065}, DOI={10.1109/telsiks57806.2023.10316065}, booktitle={2023 16th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS)}, publisher={IEEE}, author={Milić, Dejan and Petrović, Nenad and Milovanović, Dragan and Đorđević, Srđan and Suljović, Suad}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316065,10.1109/TELSIKS57806.2023.10316065,ieee,2023
334,Embodied Intelligence in Mining: Leveraging Multi-modal Large Language Model for Autonomous Driving in Mines," @article{Li_2024, title={Embodied Intelligence in Mining: Leveraging Multi-modal Large Language Model for Autonomous Driving in Mines}, ISSN={2379-8858}, url={http://dx.doi.org/10.1109/TIV.2024.3417938}, DOI={10.1109/tiv.2024.3417938}, journal={IEEE Transactions on Intelligent Vehicles}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Li, Luxi and Li, Yuchen and Zhang, Xiaotong and He, Yuhang and Yang, Jianjian and Tian, Bin and Ai, Yunfeng and Li, Lingxi and Nüchter, Andreas and Xuanyuan, Zhe}, year={2024}, pages={1–4} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10569079,10.1109/TIV.2024.3417938,ieee,2024
335,Teaching Plan Generation and Evaluation With GPT-4: Unleashing the Potential of LLM in Instructional Design," @article{Hu_2024, title={Teaching Plan Generation and Evaluation With GPT-4: Unleashing the Potential of LLM in Instructional Design}, volume={17}, ISSN={2372-0050}, url={http://dx.doi.org/10.1109/TLT.2024.3384765}, DOI={10.1109/tlt.2024.3384765}, journal={IEEE Transactions on Learning Technologies}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Hu, Bihao and Zheng, Longwei and Zhu, Jiayi and Ding, Lishan and Wang, Yilei and Gu, Xiaoqing}, year={2024}, pages={1471–1485} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10490240,10.1109/TLT.2024.3384765,ieee,2024
336,ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas," @article{Barambones_2024, title={ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas}, volume={17}, ISSN={2372-0050}, url={http://dx.doi.org/10.1109/TLT.2024.3386095}, DOI={10.1109/tlt.2024.3386095}, journal={IEEE Transactions on Learning Technologies}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Barambones, Jose and Moral, Cristian and de Antonio, Angélica and Imbert, Ricardo and Martínez-Normand, Loïc and Villalba-Mora, Elena}, year={2024}, pages={1486–1501} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494570,10.1109/TLT.2024.3386095,"ieee, web_of_science, scopus",2024
337,Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development," @article{Neyem_2024, title={Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development}, volume={17}, ISSN={2372-0050}, url={http://dx.doi.org/10.1109/TLT.2024.3396735}, DOI={10.1109/tlt.2024.3396735}, journal={IEEE Transactions on Learning Technologies}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Neyem, Andrés and González, Luis A. and Mendoza, Marcelo and Alcocer, Juan Pablo Sandoval and Centellas, Leonardo and Paredes, Carlos}, year={2024}, pages={1639–1654} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10518103,10.1109/TLT.2024.3396735,"ieee, web_of_science, scopus",2024
338,Automated Program Repair for Introductory Programming Assignments," @article{Wan_2024, title={Automated Program Repair for Introductory Programming Assignments}, volume={17}, ISSN={2372-0050}, url={http://dx.doi.org/10.1109/TLT.2024.3403710}, DOI={10.1109/tlt.2024.3403710}, journal={IEEE Transactions on Learning Technologies}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Wan, Han and Luo, Hongzhen and Li, Mengying and Luo, Xiaoyan}, year={2024}, pages={1745–1760} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10535720,10.1109/TLT.2024.3403710,"ieee, web_of_science, scopus",2024
339,Chat-GPT Based Learning Platform for Creation of Different Attack Model Signatures and Development of Defense Algorithm for Cyberattack Detection,"@article{2-s2.0-85196739162,
  title={Chat-GPT Based Learning Platform for Creation of Different Attack Model Signatures and Development of Defense Algorithm for Cyberattack Detection},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196739162&origin=inward,10.1109/TLT.2024.3417252,scopus,2024
340,Memory/Disk Operation Aware Lightweight VM Live Migration,"@article{10.1109/TNET.2022.3155935,
author = {Shi, Bin and Shen, Haiying and Dong, Bo and Zheng, Qinghua},
title = {Memory/Disk Operation Aware Lightweight VM Live Migration},
year = {2022},
issue_date = {Aug. 2022},
publisher = {IEEE Press},
volume = {30},
number = {4},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2022.3155935},
doi = {10.1109/TNET.2022.3155935},
abstract = {Live virtual machine migration technique allows migrating an entire OS with running applications from one physical host to another, while keeping all services available without interruption. It provides a flexible and powerful way to balance system load, save power, and tolerate faults in data centers. Meanwhile, with the stringent requirements of latency, scalability, and availability, an increasing number of applications are deployed across distributed data-centers. However, existing live migration approaches still suffer from long downtime and serious performance degradation in cross data-center scenes due to the mass of dirty retransmission, which limits the ability of cross data-center scheduling. In this paper, we propose a system named Memory/disk operation aware Lightweight VM Live Migration across data-centers with low performance impact (MLLM). It significantly improves the cross data-center migration performance by reducing the amount of dirty data in the migration process. In MLLM, we predict disk read workingset (i.e., more frequently read contents) and memory write workingset (i.e., more frequently write contents) based on the access sequence traces. And then we adjust the migration models and data transfer sequence by the workingset information. We further proposed an improved algorithm for workingset estimation. Moreover, we discussed the potential use of machine learning (ML) to enhance the performance of the VM migration and also propose a two-level hierarchical network model to make the ML-based prediction more efficient. We implement MLLM and its improved versions on the QEMU/KVM platform and conduct several experiments. The experimental results show that 1) MLLM averagely reduces 62.9% of total migration time and 36.0% service downtime over existing methods; 2) The improved workingset estimation algorithm reduces 9.32% memory pre-copy time on average over the original algorithm.},
journal = {IEEE/ACM Trans. Netw.},
month = {mar},
pages = {1895–1910},
numpages = {16}
}

",https://doi.org/10.1109/TNET.2022.3155935,10.1109/TNET.2022.3155935,acm,2022
341,Residual Sketch Learning for a Feature-Importance-Based and Linguistically Interpretable Ensemble Classifier," @article{Bian_2024, title={Residual Sketch Learning for a Feature-Importance-Based and Linguistically Interpretable Ensemble Classifier}, ISSN={2162-2388}, url={http://dx.doi.org/10.1109/TNNLS.2023.3242049}, DOI={10.1109/tnnls.2023.3242049}, journal={IEEE Transactions on Neural Networks and Learning Systems}, publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Bian, Zekang and Zhang, Jin and Chung, Fu-Lai and Wang, Shitong}, year={2024}, pages={1–14} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042180,10.1109/TNNLS.2023.3242049,ieee,2023
342,Chain-of-Thoughts Prompting with Language Models for Accurate Math Problem-Solving," @inproceedings{Fung_2023, title={Chain-of-Thoughts Prompting with Language Models for Accurate Math Problem-Solving}, url={http://dx.doi.org/10.1109/URTC60662.2023.10534945}, DOI={10.1109/urtc60662.2023.10534945}, booktitle={2023 IEEE MIT Undergraduate Research Technology Conference (URTC)}, publisher={IEEE}, author={Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10534945,10.1109/URTC60662.2023.10534945,ieee,2023
343,"Exploring the Role of AI Assistants in Computer Science Education: Methods, Implications, and Instructor Perspectives"," @inproceedings{Wang_2023, title={Exploring the Role of AI Assistants in Computer Science Education: Methods, Implications, and Instructor Perspectives}, url={http://dx.doi.org/10.1109/VL-HCC57772.2023.00018}, DOI={10.1109/vl-hcc57772.2023.00018}, booktitle={2023 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, publisher={IEEE}, author={Wang, Tianjia and Díaz, Daniel Vargas and Brown, Chris and Chen, Yan}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305701,10.1109/VL-HCC57772.2023.00018,"ieee, web_of_science, scopus",2023
344,First Steps in Constructing an AI-Powered Digital Twin Teacher: Harnessing Large Language Models in a Metaverse Classroom,"@article{2-s2.0-85195604439,
  title={First Steps in Constructing an AI-Powered Digital Twin Teacher: Harnessing Large Language Models in a Metaverse Classroom},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195604439&origin=inward,10.1109/VRW62533.2024.00266,scopus,2024
345,"Engineering, the Profession in Trouble: Lack of Programme Development Standards That Support the AI Chatbot? A System View"," @inproceedings{Tsoeu_2023, title={Engineering, the Profession in Trouble: Lack of Programme Development Standards That Support the AI Chatbot? A System View}, url={http://dx.doi.org/10.1109/WEEF-GEDC59520.2023.10343985}, DOI={10.1109/weef-gedc59520.2023.10343985}, booktitle={2023 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC)}, publisher={IEEE}, author={Tsoeu, Mohohlo and Maladzi, Rendani and Mthombeni, Nomcebo and Moloi, Katleho and Mashifana, Tebogo and Nemavhola, Fulufhelo}, year={2023}, month=oct }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343985,10.1109/WEEF-GEDC59520.2023.10343985,ieee,2023
346,Hallucinations in Large Language Models (LLMs)," @inproceedings{Reddy_2024, title={Hallucinations in Large Language Models (LLMs)}, url={http://dx.doi.org/10.1109/eStream61684.2024.10542617}, DOI={10.1109/estream61684.2024.10542617}, booktitle={2024 IEEE Open Conference of Electrical, Electronic and Information Sciences (eStream)}, publisher={IEEE}, author={Reddy, G. Pradeep and Pavan Kumar, Y. V. and Prakash, K. Purna}, year={2024}, month=apr }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10542617,10.1109/eStream61684.2024.10542617,ieee,2024
347,"Advanced Video Transcription And Summarization A Synergy of Langchain, Language Models, And VectorDB with Mozilla Deep Speech","@article{2-s2.0-85192517174,
  title={Advanced Video Transcription And Summarization A Synergy of Langchain, Language Models, And VectorDB with Mozilla Deep Speech},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85192517174&origin=inward,10.1109/ic-ETITE58242.2024.10493791,scopus,2024
348,ChatGPT and Python programming homework," @article{Ellis_2024, title={ChatGPT and Python programming homework}, volume={22}, ISSN={1540-4609}, url={http://dx.doi.org/10.1111/dsji.12306}, DOI={10.1111/dsji.12306}, number={2}, journal={Decision Sciences Journal of Innovative Education}, publisher={Wiley}, author={Ellis, Michael E. and Casey, K. Mike and Hill, Geoffrey}, year={2024}, month=jan, pages={74–87} }
",http://dx.doi.org/10.1111/dsji.12306,10.1111/dsji.12306,"web_of_science, scopus",2024
349,"When geoscience meets generative AI and large language models: Foundations, trends, and future challenges","@article{2-s2.0-85195594534,
  title={When geoscience meets generative AI and large language models: Foundations, trends, and future challenges},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195594534&origin=inward,10.1111/exsy.13654,scopus,2024
350,Medical education with large language models in ophthalmology: Custom instructions and enhanced retrieval capabilities,"@article{2-s2.0-85193318097,
  title={Medical education with large language models in ophthalmology: Custom instructions and enhanced retrieval capabilities},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193318097&origin=inward,10.1136/bjo-2023-325046,scopus,2024
351,Public perception of generative AI on Twitter: an empirical study based on occupation and usage," @article{Miyazaki_2024, title={Public perception of generative AI on Twitter: an empirical study based on occupation and usage}, volume={13}, ISSN={2193-1127}, url={http://dx.doi.org/10.1140/epjds/s13688-023-00445-y}, DOI={10.1140/epjds/s13688-023-00445-y}, number={1}, journal={EPJ Data Science}, publisher={Springer Science and Business Media LLC}, author={Miyazaki, Kunihiro and Murayama, Taichi and Uchiba, Takayuki and An, Jisun and Kwak, Haewoon}, year={2024}, month=jan }
",https://link.springer.com/article/10.1140/epjds/s13688-023-00445-y,10.1140/epjds/s13688-023-00445-y,springer,2024
356,SocialTruth Project Approach to Online Disinformation (Fake News) Detection and Mitigation,"@inproceedings{10.1145/3339252.3341497,
author = {Chora\'{s}, Micha\l{} and Pawlicki, Marek and Kozik, Rafa\l{} and Demestichas, Konstantinos and Kosmides, Pavlos and Gupta, Manik},
title = {SocialTruth Project Approach to Online Disinformation (Fake News) Detection and Mitigation},
year = {2019},
isbn = {9781450371643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339252.3341497},
doi = {10.1145/3339252.3341497},
abstract = {The extreme growth and adoption of Social Media, in combination with their poor governance and the lack of quality control over the digital content being published and shared, has led information veracity to a continuous deterioration. Current approaches entrust content verification to a single centralised authority, lack resilience towards attempts to successfully ""game"" verification checks, and make content verification difficult to access and use. In response, our ambition is to create an open, democratic, pluralistic and distributed ecosystem that allows easy access to various verification services (both internal and third-party), ensuring scalability and establishing trust in a completely decentralized environment. In fact, this is the ambition of the EU H2020 SocialTruth project. In this paper, we present the innovative project approach and the vision of effective online disinformation detection for various practical use-cases.},
booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
articleno = {68},
numpages = {10},
keywords = {detection, fake news, networks, pattern recognition, safety, security},
location = {Canterbury, CA, United Kingdom},
series = {ARES '19}
}

",https://doi.org/10.1145/3339252.3341497,10.1145/3339252.3341497,acm,2019
357,Jury Learning: Integrating Dissenting Voices into Machine Learning Models,"@inproceedings{10.1145/3491102.3502004,
author = {Gordon, Mitchell L. and Lam, Michelle S. and Park, Joon Sung and Patel, Kayur and Hancock, Jeff and Hashimoto, Tatsunori and Bernstein, Michael S.},
title = {Jury Learning: Integrating Dissenting Voices into Machine Learning Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502004},
doi = {10.1145/3491102.3502004},
abstract = {Whose labels should a machine learning (ML) algorithm learn to emulate? For ML tasks ranging from online comment toxicity to misinformation detection to medical diagnosis, different groups in society may have irreconcilable disagreements about ground truth labels. Supervised ML today resolves these label disagreements implicitly using majority vote, which overrides minority groups’ labels. We introduce jury learning, a supervised ML approach that resolves these disagreements explicitly through the metaphor of a jury: defining which people or groups, in what proportion, determine the classifier’s prediction. For example, a jury learning model for online toxicity might centrally feature women and Black jurors, who are commonly targets of online harassment. To enable jury learning, we contribute a deep learning architecture that models every annotator in a dataset, samples from annotators’ models to populate the jury, then runs inference to classify. Our architecture enables juries that dynamically adapt their composition, explore counterfactuals, and visualize dissent. A field evaluation finds that practitioners construct diverse juries that alter 14% of classification outcomes.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {115},
numpages = {19},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

",https://doi.org/10.1145/3491102.3502004,10.1145/3491102.3502004,acm,2022
358,AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts,"@inproceedings{10.1145/3491102.3517582,
author = {Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun},
title = {AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517582},
doi = {10.1145/3491102.3517582},
abstract = {Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by “unit-testing” sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {385},
numpages = {22},
keywords = {Human-AI Interaction, Large Language Models, Natural Language Processing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

",https://doi.org/10.1145/3491102.3517582,10.1145/3491102.3517582,acm,2022
359,"Automatic Generation of Programming Exercises and Code Explanations
  using Large Language Models"," @inproceedings{Sarsa_2022, series={ICER 2022}, title={Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models}, url={http://dx.doi.org/10.1145/3501385.3543957}, DOI={10.1145/3501385.3543957}, booktitle={Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1}, publisher={ACM}, author={Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho}, year={2022}, month=aug, collection={ICER 2022} }
",http://arxiv.org/pdf/2206.11861v2.pdf,10.1145/3501385.3543957,"arxiv, acm, scopus",2022
360,Generating Diverse Code Explanations using the GPT-3 Large Language Model,"@article{2-s2.0-85137106608,
  title={Generating Diverse Code Explanations using the GPT-3 Large Language Model},
  author={N/A},
  journal={N/A},
  year={2022},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137106608&origin=inward,10.1145/3501709.3544280,scopus,2022
361,Fooling MOSS Detection with Pretrained Language Models,"@article{2-s2.0-85140848572,
  title={Fooling MOSS Detection with Pretrained Language Models},
  author={N/A},
  journal={N/A},
  year={2022},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140848572&origin=inward,10.1145/3511808.3557079,scopus,2022
362,Social Simulacra: Creating Populated Prototypes for Social Computing Systems,"@inproceedings{10.1145/3526113.3545616,
author = {Park, Joon Sung and Popowski, Lindsay and Cai, Carrie and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
title = {Social Simulacra: Creating Populated Prototypes for Social Computing Systems},
year = {2022},
isbn = {9781450393201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526113.3545616},
doi = {10.1145/3526113.3545616},
abstract = {Social computing prototypes probe the social behaviors that may arise in an envisioned system design. This prototyping practice is currently limited to recruiting small groups of people. Unfortunately, many challenges do not arise until a system is populated at a larger scale. Can a designer understand how a social system might behave when populated, and make adjustments to the design before the system falls prey to such challenges? We introduce social simulacra, a prototyping technique that generates a breadth of realistic social interactions that may emerge when a social computing system is populated. Social simulacra take as input the designer’s description of a community’s design—goal, rules, and member personas—and produce as output an instance of that design with simulated behavior, including posts, replies, and anti-social behaviors. We demonstrate that social simulacra shift the behaviors that they generate appropriately in response to design changes, and that they enable exploration of “what if?” scenarios where community members or moderators intervene. To power social simulacra, we contribute techniques for prompting a large language model to generate thousands of distinct community members and their social interactions with each other; these techniques are enabled by the observation that large language models’ training data already includes a wide variety of positive and negative behavior on social media platforms. In evaluations, we show that participants are often unable to distinguish social simulacra from actual community behavior and that social computing designers successfully refine their social computing designs when using social simulacra.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
articleno = {74},
numpages = {18},
keywords = {prototyping, social computing},
location = {Bend, OR, USA},
series = {UIST '22}
}

",https://doi.org/10.1145/3526113.3545616,10.1145/3526113.3545616,acm,2022
363,Interactive Model Cards: A Human-Centered Approach to Model Documentation,"@inproceedings{10.1145/3531146.3533108,
author = {Crisan, Anamaria and Drouhard, Margaret and Vig, Jesse and Rajani, Nazneen},
title = {Interactive Model Cards: A Human-Centered Approach to Model Documentation},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533108},
doi = {10.1145/3531146.3533108},
abstract = {Deep learning models for natural language processing (NLP) are increasingly adopted and deployed by analysts without formal training in NLP or machine learning (ML). However, the documentation intended to convey the model’s details and appropriate use is tailored primarily to individuals with ML or NLP expertise. To address this gap, we conduct a design inquiry into interactive model cards, which augment traditionally static model cards with affordances for exploring model documentation and interacting with the models themselves. Our investigation consists of an initial conceptual study with experts in ML, NLP, and AI Ethics, followed by a separate evaluative study with non-expert analysts who use ML models in their work. Using a semi-structured interview format coupled with a think-aloud protocol, we collected feedback from a total of 30 participants who engaged with different versions of standard and interactive model cards. Through a thematic analysis of the collected data, we identified several conceptual dimensions that summarize the strengths and limitations of standard and interactive model cards, including: stakeholders; design; guidance; understandability &amp; interpretability; sensemaking &amp; skepticism; and trust &amp; safety. Our findings demonstrate the importance of carefully considered design and interactivity for orienting and supporting non-expert analysts using deep learning models, along with a need for consideration of broader sociotechnical contexts and organizational dynamics. We have also identified design elements, such as language, visual cues, and warnings, among others, that support interactivity and make non-interactive content accessible. We summarize our findings as design guidelines and discuss their implications for a human-centered approach towards AI/ML documentation.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {427–439},
numpages = {13},
keywords = {human centered design, interactive data visualization, model cards},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

",https://doi.org/10.1145/3531146.3533108,10.1145/3531146.3533108,acm,2022
364,The Fallacy of AI Functionality,"@inproceedings{10.1145/3531146.3533158,
author = {Raji, Inioluwa Deborah and Kumar, I. Elizabeth and Horowitz, Aaron and Selbst, Andrew},
title = {The Fallacy of AI Functionality},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533158},
doi = {10.1145/3531146.3533158},
abstract = {Deployed AI systems often do not work. They can be constructed haphazardly, deployed indiscriminately, and promoted deceptively. However, despite this reality, scholars, the press, and policymakers pay too little attention to functionality. This leads to technical and policy solutions focused on “ethical” or value-aligned deployments, often skipping over the prior question of whether a given system functions, or provides any benefits at all. To describe the harms of various types of functionality failures, we analyze a set of case studies to create a taxonomy of known AI functionality issues. We then point to policy and organizational responses that are often overlooked and become more readily available once functionality is drawn into focus. We argue that functionality is a meaningful AI policy challenge, operating as a necessary first step towards protecting affected communities from algorithmic harm.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {959–972},
numpages = {14},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

",https://doi.org/10.1145/3531146.3533158,10.1145/3531146.3533158,acm,2022
365,Predictability and Surprise in Large Generative Models,"@inproceedings{10.1145/3531146.3533229,
author = {Ganguli, Deep and Hernandez, Danny and Lovitt, Liane and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Dassarma, Nova and Drain, Dawn and Elhage, Nelson and El Showk, Sheer and Fort, Stanislav and Hatfield-Dodds, Zac and Henighan, Tom and Johnston, Scott and Jones, Andy and Joseph, Nicholas and Kernian, Jackson and Kravec, Shauna and Mann, Ben and Nanda, Neel and Ndousse, Kamal and Olsson, Catherine and Amodei, Daniela and Brown, Tom and Kaplan, Jared and McCandlish, Sam and Olah, Christopher and Amodei, Dario and Clark, Jack},
title = {Predictability and Surprise in Large Generative Models},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533229},
doi = {10.1145/3531146.3533229},
abstract = {Large-scale pre-training has recently emerged as a technique for creating capable, general-purpose, generative models such as GPT-3, Megatron-Turing NLG, Gopher, and many others. In this paper, we highlight a counterintuitive property of such models and discuss the policy implications of this property. Namely, these generative models have a paradoxical combination of predictable loss on a broad training distribution (as embodied in their ”scaling laws”), and unpredictable specific capabilities, inputs, and outputs. We believe that the high-level predictability and appearance of useful capabilities drives rapid development of such models, while the unpredictable qualities make it difficult to anticipate the consequences of model deployment. We go through examples of how this combination can lead to socially harmful behavior with examples from the literature and real world observations, and we also perform two novel experiments to illustrate our point about harms from unpredictability. Furthermore, we analyze how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment. We conclude with a list of possible interventions the AI community may take to increase the chance of these models having a beneficial impact. We intend for this paper to be useful to policymakers who want to understand and regulate AI systems, technologists who care about the potential policy impact of their work, funders who want to support work addressing these challenges, and academics who want to analyze, critique, and potentially develop large generative models.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1747–1764},
numpages = {18},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

",https://doi.org/10.1145/3531146.3533229,10.1145/3531146.3533229,acm,2022
366,Design and Prototype Conversational Agents for Research Data Collection,"@inproceedings{10.1145/3532104.3571467,
author = {Wei, Jing and Kim, Young-Ho and Chan, Samantha W. T. and Dingler, Tilman},
title = {Design and Prototype Conversational Agents for Research Data Collection},
year = {2022},
isbn = {9781450393560},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532104.3571467},
doi = {10.1145/3532104.3571467},
abstract = {Conversational agents have gained increasing interest from researchers as a tool to collect data and administer interventions. They provide a natural user interface through conversations and hence have the potential to reach a wide population in their homes and on the go. Several developer tools and commercial as well as open-source frameworks allow for the deployment of both text-based chatbots and voice assistants. In this 90 min tutorial, participants will learn how to choose an appropriate platform, how to design and deploy their conversational agents, and how to transform traditional surveys through conversation agents.},
booktitle = {Companion Proceedings of the 2022 Conference on Interactive Surfaces and Spaces},
pages = {57–58},
numpages = {2},
keywords = {ESM, chatbots, conversational agents, conversational user interface},
location = {Wellington, New Zealand},
series = {ISS '22}
}

",https://doi.org/10.1145/3532104.3571467,10.1145/3532104.3571467,acm,2022
367,Sparks: Inspiration for Science Writing using Language Models,"@inproceedings{10.1145/3532106.3533533,
author = {Gero, Katy Ilonka and Liu, Vivian and Chilton, Lydia},
title = {Sparks: Inspiration for Science Writing using Language Models},
year = {2022},
isbn = {9781450393584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532106.3533533},
doi = {10.1145/3532106.3533533},
abstract = {Large-scale language models are rapidly improving, performing well on a wide variety of tasks with little to no customization. In this work we investigate how language models can support science writing, a challenging writing task that is both open-ended and highly constrained. We present a system for generating “sparks”, sentences related to a scientific concept intended to inspire writers. We find that our sparks are more coherent and diverse than a competitive language model baseline, and approach a human-written gold standard. We run a user study with 13 STEM graduate students writing on topics of their own selection and find three main use cases of sparks—inspiration, translation, and perspective—each of which correlates with a unique interaction pattern. We also find that while participants were more likely to select higher quality sparks, the average quality of sparks seen by a given participant did not correlate with their satisfaction with the tool. We end with a discussion about what impacts human satisfaction with AI support tools, considering participant attitudes towards influence, their openness to technology, as well as issues of plagiarism, trustworthiness, and bias in AI.},
booktitle = {Proceedings of the 2022 ACM Designing Interactive Systems Conference},
pages = {1002–1019},
numpages = {18},
keywords = {co-creativity, creativity support tools, natural language processing, science writing, writing support},
location = {Virtual Event, Australia},
series = {DIS '22}
}

",https://doi.org/10.1145/3532106.3533533,10.1145/3532106.3533533,acm,2022
368,Designerly Understanding: Information Needs for Model Transparency to Support Design Ideation for AI-Powered User Experience,"@inproceedings{10.1145/3544548.3580652,
author = {Liao, Q. Vera and Subramonyam, Hariharan and Wang, Jennifer and Wortman Vaughan, Jennifer},
title = {Designerly Understanding: Information Needs for Model Transparency to Support Design Ideation for AI-Powered User Experience},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580652},
doi = {10.1145/3544548.3580652},
abstract = {Despite the widespread use of artificial intelligence (AI), designing user experiences (UX) for AI-powered systems remains challenging. UX designers face hurdles understanding AI technologies, such as pre-trained language models, as design materials. This limits their ability to ideate and make decisions about whether, where, and how to use AI. To address this problem, we bridge the literature on AI design and AI transparency to explore whether and how frameworks for transparent model reporting can support design ideation with pre-trained models. By interviewing 23 UX practitioners, we find that practitioners frequently work with pre-trained models, but lack support for UX-led ideation. Through a scenario-based design task, we identify common goals that designers seek model understanding for and pinpoint their model transparency information needs. Our study highlights the pivotal role that UX designers can play in Responsible AI and calls for supporting their understanding of AI limitations through model transparency and interrogation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {9},
numpages = {21},
keywords = {AI design, AI documentation, AI transparency, explainability, pre-trained models},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580652,10.1145/3544548.3580652,acm,2023
369,Social Dynamics of AI Support in Creative Writing,"@inproceedings{10.1145/3544548.3580782,
author = {Gero, Katy Ilonka and Long, Tao and Chilton, Lydia B},
title = {Social Dynamics of AI Support in Creative Writing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580782},
doi = {10.1145/3544548.3580782},
abstract = {Recently, large language models have made huge advances in generating coherent, creative text. While much research focuses on how users can interact with language models, less work considers the social-technical gap that this technology poses. What are the social nuances that underlie receiving support from a generative AI? In this work we ask when and why a creative writer might turn to a computer versus a peer or mentor for support. We interview 20 creative writers about their writing practice and their attitudes towards both human and computer support. We discover three elements that govern a writer’s interaction with support actors: 1) what writers desire help with, 2) how writers perceive potential support actors, and 3) the values writers hold. We align our results with existing frameworks of writing cognition and creativity support, uncovering the social dynamics which modulate user responses to generative technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {245},
numpages = {15},
keywords = {creative writing, human-AI collaboration, language models, writing assistants, writing support tools},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580782,10.1145/3544548.3580782,acm,2023
370,“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models,"@inproceedings{10.1145/3544548.3580817,
author = {Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
title = {“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580817},
doi = {10.1145/3544548.3580817},
abstract = {Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user’s natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users’ understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {598},
numpages = {31},
keywords = {Human-AI Interaction, Large Language Models, Natural Language Programming, Spreadsheets},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580817,10.1145/3544548.3580817,acm,2023
371,Moral Framing of Mental Health Discourse and Its Relationship to Stigma: A Comparison of Social Media and News,"@inproceedings{10.1145/3544548.3580834,
author = {Mittal, Shravika and De Choudhury, Munmun},
title = {Moral Framing of Mental Health Discourse and Its Relationship to Stigma: A Comparison of Social Media and News},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580834},
doi = {10.1145/3544548.3580834},
abstract = {Mental health discussions on public forums influence the perceptions of people. Negative consequences may result from hostile and “othering” portrayals of people with mental disorders. Adopting the lens of Moral Foundation Theory (MFT), we study framings of mental health discourse on Twitter and News, and how moral underpinnings abate or exacerbate stigma. We adopted a large language model based representation framework to score 13,277,115 public tweets and 21,167 news articles against MFT’s five foundations. We found discussions on Twitter to demonstrate compassion, justice and equity-centered moral values for those suffering from mental illness, in contrast to those on News. That said, stigmatized discussions appeared on both Twitter and News, with news articles being more stigmatizing than tweets. We discuss implications for public health authorities to refine measures for safe reporting of mental health, and for social media platforms to design affordances that enable empathetic discourse.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {484},
numpages = {19},
keywords = {BERT, mental health discourse, moral foundation theory, news media, stigma, twitter},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580834,10.1145/3544548.3580834,acm,2023
372,"Changes in Research Ethics, Openness, and Transparency in Empirical Studies between CHI 2017 and CHI 2022","@inproceedings{10.1145/3544548.3580848,
author = {Salehzadeh Niksirat, Kavous and Goswami, Lahari and S. B. Rao, Pooja and Tyler, James and Silacci, Alessandro and Aliyu, Sadiq and Aebli, Annika and Wacharamanotham, Chat and Cherubini, Mauro},
title = {Changes in Research Ethics, Openness, and Transparency in Empirical Studies between CHI 2017 and CHI 2022},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580848},
doi = {10.1145/3544548.3580848},
abstract = {In recent years, various initiatives from within and outside the HCI field have encouraged researchers to improve research ethics, openness, and transparency in their empirical research. We quantify how the CHI literature might have changed in these three aspects by analyzing samples of 118 CHI 2017 and 127 CHI 2022 papers—randomly drawn and stratified across conference sessions. We operationalized research ethics, openness, and transparency into 45&nbsp; criteria and manually annotated the sampled papers. The results show that the CHI 2022 sample was better in 18 criteria, but in the rest of the criteria, it has no improvement. The most noticeable improvements were related to research transparency (10 out of 17 criteria). We also explored the possibility of assisting the verification process by developing a proof-of-concept screening system. We tested this tool with eight criteria. Six of them achieved high accuracy and F1 score. We discuss the implications for future research practices and education. This paper and all supplementary materials are freely available at&nbsp;https://doi.org/10.17605/osf.io/n25d6.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {505},
numpages = {23},
keywords = {CHI, data availability, ethics, open science, replicability, reproducibility, transparency},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580848,10.1145/3544548.3580848,acm,2023
373,Stargazer: An Interactive Camera Robot for Capturing How-To Videos Based on Subtle Instructor Cues,"@inproceedings{10.1145/3544548.3580896,
author = {Li, Jiannan and Sousa, Maur\'{\i}cio and Mahadevan, Karthik and Wang, Bryan and Aoyagui, Paula Akemi and Yu, Nicole and Yang, Angela and Balakrishnan, Ravin and Tang, Anthony and Grossman, Tovi},
title = {Stargazer: An Interactive Camera Robot for Capturing How-To Videos Based on Subtle Instructor Cues},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580896},
doi = {10.1145/3544548.3580896},
abstract = {Live and pre-recorded video tutorials are an effective means for teaching physical skills such as cooking or prototyping electronics. A dedicated cameraperson following an instructor’s activities can improve production quality. However, instructors who do not have access to a cameraperson’s help often have to work within the constraints of static cameras. We present Stargazer, a novel approach for assisting with tutorial content creation with a camera robot that autonomously tracks regions of interest based on instructor actions to capture dynamic shots. Instructors can adjust the camera behaviors of Stargazer with subtle cues, including gestures and speech, allowing them to fluidly integrate camera control commands into instructional activities. Our user study with six instructors, each teaching a distinct skill, showed that participants could create dynamic tutorial videos with a diverse range of subjects, camera framing, and camera angle combinations using Stargazer.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {800},
numpages = {16},
keywords = {cameras, instructional videos, robots},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580896,10.1145/3544548.3580896,acm,2023
374,“It is currently hodgepodge”: Examining AI/ML Practitioners’ Challenges during Co-production of Responsible AI Values,"@inproceedings{10.1145/3544548.3580903,
author = {Varanasi, Rama Adithya and Goyal, Nitesh},
title = {“It is currently hodgepodge”: Examining AI/ML Practitioners’ Challenges during Co-production of Responsible AI Values},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580903},
doi = {10.1145/3544548.3580903},
abstract = {Recently, the AI/ML research community has indicated an urgent need to establish Responsible AI (RAI) values and practices as part of the AI/ML lifecycle. Several organizations and communities are responding to this call by sharing RAI guidelines. However, there are gaps in awareness, deliberation, and execution of such practices for multi-disciplinary ML practitioners. This work contributes to the discussion by unpacking co-production challenges faced by practitioners as they align their RAI values. We interviewed 23 individuals, across 10 organizations, tasked to ship AI/ML based products while upholding RAI norms and found that both top-down and bottom-up institutional structures create burden for different roles preventing them from upholding RAI values, a challenge that is further exacerbated when executing conflicted values. We share multiple value levers used as strategies by the practitioners to resolve their challenges. We end our paper with recommendations for inclusive and equitable RAI value-practices, creating supportive organizational structures and opportunities to further aid practitioners.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {251},
numpages = {17},
keywords = {FAT, RAI, Responsible AI, XAI, accountability, co-production, collaboration, ethical AI, explainability, fairness, transparency, value levers},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580903,10.1145/3544548.3580903,acm,2023
375,AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models,"@inproceedings{10.1145/3544548.3580907,
author = {Petridis, Savvas and Diakopoulos, Nicholas and Crowston, Kevin and Hansen, Mark and Henderson, Keren and Jastrzebski, Stan and Nickerson, Jeffrey V and Chilton, Lydia B},
title = {AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580907},
doi = {10.1145/3544548.3580907},
abstract = {News media often leverage documents to find ideas for stories, while being critical of the frames and narratives present. Developing angles from a document such as a press release is a cognitively taxing process, in which journalists critically examine the implicit meaning of its claims. Informed by interviews with journalists, we developed AngleKindling, an interactive tool which employs the common sense reasoning of large language models to help journalists explore angles for reporting on a press release. In a study with 12 professional journalists, we show that participants found AngleKindling significantly more helpful and less mentally demanding to use for brainstorming ideas, compared to a prior journalistic angle ideation tool. AngleKindling helped journalists deeply engage with the press release and recognize angles that were useful for multiple types of stories. From our findings, we discuss how to help journalists customize and identify promising angles, and extending AngleKindling to other knowledge-work domains.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {225},
numpages = {16},
keywords = {Brainstorming, Generative AI, Ideation, Journalism, Large Language Models},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580907,10.1145/3544548.3580907,acm,2023
376,Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming,"@inproceedings{10.1145/3544548.3580919,
author = {Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi},
title = {Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580919},
doi = {10.1145/3544548.3580919},
abstract = {AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {23},
keywords = {AI Coding Assistants, AI-Assisted Pair-Programming, ChatGPT, Copilot, GPT-3, Introductory Programming, K-12 Computer Science Education, Large Language Models, OpenAI Codex},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580919,10.1145/3544548.3580919,"acm, scopus",2023
377,ReadingQuizMaker: A Human-NLP Collaborative System that Supports Instructors to Design High-Quality Reading Quiz Questions,"@inproceedings{10.1145/3544548.3580957,
author = {Lu, Xinyi and Fan, Simin and Houghton, Jessica and Wang, Lu and Wang, Xu},
title = {ReadingQuizMaker: A Human-NLP Collaborative System that Supports Instructors to Design High-Quality Reading Quiz Questions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580957},
doi = {10.1145/3544548.3580957},
abstract = {Despite that reading assignments are prevalent, methods to encourage students to actively read are limited. We propose a system ReadingQuizMaker that supports instructors to conveniently design high-quality questions to help students comprehend readings. ReadingQuizMaker adapts to instructors’ natural workflows of creating questions, while providing NLP-based process-oriented support. ReadingQuizMaker enables instructors to decide when and which NLP models to use, select the input to the models, and edit the outcomes. In an evaluation study, instructors found the resulting questions to be comparable to their previously designed quizzes. Instructors praised ReadingQuizMaker for its ease of use, and considered the NLP suggestions to be satisfying and helpful. We compared ReadingQuizMaker with a control condition where instructors were given automatically generated questions to edit. Instructors showed a strong preference for the human-AI teaming approach provided by ReadingQuizMaker. Our findings suggest the importance of giving users control and showing an immediate preview of AI outcomes when providing AI support.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {454},
numpages = {18},
keywords = {Active Learning, Automatic Question Generation, Human-AI Teaming, Reading Quiz},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3580957,10.1145/3544548.3580957,acm,2023
378,CatAlyst: Domain-Extensible Intervention for Preventing Task Procrastination Using Large Generative Models,"@inproceedings{10.1145/3544548.3581133,
author = {Arakawa, Riku and Yakura, Hiromu and Goto, Masataka},
title = {CatAlyst: Domain-Extensible Intervention for Preventing Task Procrastination Using Large Generative Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581133},
doi = {10.1145/3544548.3581133},
abstract = {CatAlyst uses generative models to help workers’ progress by influencing their task engagement instead of directly contributing to their task outputs. It prompts distracted workers to resume their tasks by generating a continuation of their work and presenting it as an intervention that is more context-aware than conventional (predetermined) feedback. The prompt can function by drawing their interest and lowering the hurdle for resumption even when the generated continuation is insufficient to substitute their work, while recent human-AI collaboration research aiming at work substitution depends on a stable high accuracy. This frees CatAlyst from domain-specific model-tuning and makes it applicable to various tasks. Our studies involving writing and slide-editing tasks demonstrated CatAlyst’s effectiveness in helping workers swiftly resume tasks with a lowered cognitive load. The results suggest a new form of human-AI collaboration where large generative models publicly available but imperfect for each individual domain can contribute to workers’ digital well-being.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {157},
numpages = {19},
keywords = {behavior change, large generative models, procrastination, task engagement},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581133,10.1145/3544548.3581133,acm,2023
379,Co-Writing with Opinionated Language Models Affects Users’ Views,"@inproceedings{10.1145/3544548.3581196,
author = {Jakesch, Maurice and Bhat, Advait and Buschek, Daniel and Zalmanson, Lior and Naaman, Mor},
title = {Co-Writing with Opinionated Language Models Affects Users’ Views},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581196},
doi = {10.1145/3544548.3581196},
abstract = {If large language models like GPT-3 preferably produce a particular point of view, they may influence people’s opinions on an unknown scale. This study investigates whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write – and what they think. In an online experiment, we asked participants (N=1,506) to write a post discussing whether social media is good for society. Treatment group participants used a language-model-powered writing assistant configured to argue that social media is good or bad for society. Participants then completed a social media attitude survey, and independent judges (N=500) evaluated the opinions expressed in their writing. Using the opinionated language model affected the opinions expressed in participants’ writing and shifted their opinions in the subsequent attitude survey. We discuss the wider implications of our results and argue that the opinions built into AI language technologies need to be monitored and engineered more carefully.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {111},
numpages = {15},
keywords = {Co-writing, GPT-3, opinion change, risks of large language models},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581196,10.1145/3544548.3581196,acm,2023
380,Inform the Uninformed: Improving Online Informed Consent Reading with an AI-Powered Chatbot,"@inproceedings{10.1145/3544548.3581252,
author = {Xiao, Ziang and Li, Tiffany Wenting and Karahalios, Karrie and Sundaram, Hari},
title = {Inform the Uninformed: Improving Online Informed Consent Reading with an AI-Powered Chatbot},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581252},
doi = {10.1145/3544548.3581252},
abstract = {Informed consent is a core cornerstone of ethics in human subject research. Through the informed consent process, participants learn about the study procedure, benefits, risks, and more to make an informed decision. However, recent studies showed that current practices might lead to uninformed decisions and expose participants to unknown risks, especially in online studies. Without the researcher’s presence and guidance, online participants must read a lengthy form on their own with no answers to their questions. In this paper, we examined the role of an AI-powered chatbot in improving informed consent online. By comparing the chatbot with form-based interaction, we found the chatbot improved consent form reading, promoted participants’ feelings of agency, and closed the power gap between the participant and the researcher. Our exploratory analysis further revealed the altered power dynamic might eventually benefit study response quality. We discussed design implications for creating AI-powered chatbots to offer effective informed consent in broader settings.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {112},
numpages = {17},
keywords = {AI-powered chatbot, conversational agents, human-AI interaction, informed consent, power dynamic},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581252,10.1145/3544548.3581252,acm,2023
381,Designing Responsible AI: Adaptations of UX Practice to Meet Responsible AI Challenges,"@inproceedings{10.1145/3544548.3581278,
author = {Wang, Qiaosi and Madaio, Michael and Kane, Shaun and Kapania, Shivani and Terry, Michael and Wilcox, Lauren},
title = {Designing Responsible AI: Adaptations of UX Practice to Meet Responsible AI Challenges},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581278},
doi = {10.1145/3544548.3581278},
abstract = {Technology companies continue to invest in efforts to incorporate responsibility in their Artificial Intelligence (AI) advancements, while efforts to audit and regulate AI systems expand. This shift towards Responsible AI (RAI) in the tech industry necessitates new practices and adaptations to roles—undertaken by a variety of practitioners in more or less formal positions, many of whom focus on the user-centered aspects of AI. To better understand practices at the intersection of user experience (UX) and RAI, we conducted an interview study with industrial UX practitioners and RAI subject matter experts, both of whom are actively involved in addressing RAI concerns throughout the early design and development of new AI-based prototypes, demos, and products, at a large technology company. Many of the specific practices and their associated challenges have yet to be surfaced in the literature, and distilling them offers a critical view into how practitioners’ roles are adapting to meet present-day RAI challenges. We present and discuss three emerging practices in which RAI is being enacted and reified in UX practitioners’ everyday work. We conclude by arguing that the emerging practices, goals, and types of expertise that surfaced in our study point to an evolution in praxis, with associated challenges that suggest important areas for further research in HCI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {249},
numpages = {16},
keywords = {UX, industry practice, interview, responsible AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581278,10.1145/3544548.3581278,acm,2023
382,Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design,"@inproceedings{10.1145/3544548.3581290,
author = {Lam, Michelle S. and Ma, Zixian and Li, Anne and Freitas, Izequiel and Wang, Dakuo and Landay, James A. and Bernstein, Michael S.},
title = {Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581290},
doi = {10.1145/3544548.3581290},
abstract = {Machine learning practitioners often end up tunneling on low-level technical details like model architectures and performance metrics. Could early model development instead focus on high-level questions of which factors a model ought to pay attention to? Inspired by the practice of sketching in design, which distills ideas to their minimal representation, we introduce model sketching: a technical framework for iteratively and rapidly authoring functional approximations of a machine learning model’s decision-making logic. Model sketching refocuses practitioner attention on composing high-level, human-understandable concepts that the model is expected to reason over (e.g., profanity, racism, or sarcasm in a content moderation task) using zero-shot concept instantiation. In an evaluation with 17 ML practitioners, model sketching reframed thinking from implementation to higher-level exploration, prompted iteration on a broader range of model designs, and helped identify gaps in the problem formulation—all in a fraction of the time ordinarily required to build a model.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {741},
numpages = {24},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581290,10.1145/3544548.3581290,acm,2023
383,Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions,"@inproceedings{10.1145/3544548.3581318,
author = {Zhou, Jiawei and Zhang, Yixuan and Luo, Qianni and Parker, Andrea G and De Choudhury, Munmun},
title = {Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581318},
doi = {10.1145/3544548.3581318},
abstract = {Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work first examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found significant linguistic differences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a significant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {20},
keywords = {AI-generated misinformation, COVID-19, GPT, generative AI, large language model, misinformation, responsible AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581318,10.1145/3544548.3581318,acm,2023
384,DAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children’s Why and How Questions,"@inproceedings{10.1145/3544548.3581369,
author = {Lee, Yoonjoo and Kim, Tae Soo and Kim, Sungdong and Yun, Yohan and Kim, Juho},
title = {DAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children’s Why and How Questions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581369},
doi = {10.1145/3544548.3581369},
abstract = {Children acquire an understanding of the world by asking “why” and “how” questions. Conversational agents (CAs) like smart speakers or voice assistants can be promising respondents to children’s questions as they are more readily available than parents or teachers. However, CAs’ answers to “why” and “how” questions are not designed for children, as they can be difficult to understand and provide little interactivity to engage the child. In this work, we propose design guidelines for creating interactive dialogues that promote children’s engagement and help them understand explanations. Applying these guidelines, we propose DAPIE, a system that answers children’s questions through interactive dialogue by employing an AI-based pipeline that automatically transforms existing long-form answers from online sources into such dialogues. A user study (N=16) showed that, with DAPIE, children performed better in an immediate understanding assessment while also reporting higher enjoyment than when explanations were presented sentence-by-sentence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {22},
keywords = {Children, Conversational Agents, Dialogue, Natural Language, Question Answering},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581369,10.1145/3544548.3581369,acm,2023
385,Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts,"@inproceedings{10.1145/3544548.3581388,
author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
title = {Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581388},
doi = {10.1145/3544548.3581388},
abstract = {Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {437},
numpages = {21},
keywords = {design tools, end-users, language models},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581388,10.1145/3544548.3581388,acm,2023
386,RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions,"@inproceedings{10.1145/3544548.3581402,
author = {Wang, Yunlong and Shen, Shuyuan and Lim, Brian Y},
title = {RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581402},
doi = {10.1145/3544548.3581402},
abstract = {Generative AI models have shown impressive ability to produce images with text prompts, which could benefit creativity in visual art creation and self-expression. However, it is unclear how precisely the generated images express contexts and emotions from the input texts. We explored the emotional expressiveness of AI-generated images and developed RePrompt, an automatic method to refine text prompts toward precise expression of the generated images. Inspired by crowdsourced editing strategies, we curated intuitive text features, such as the number and concreteness of nouns, and trained a proxy model to analyze the feature effects on the AI-generated image. With model explanations of the proxy model, we curated a rubric to adjust text prompts to optimize image generation for precise emotion expression. We conducted simulation and user studies, which showed that RePrompt significantly improves the emotional expressiveness of AI-generated images, especially for negative emotions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {22},
numpages = {29},
location = {Hamburg, Germany},
series = {CHI '23}
}

",https://doi.org/10.1145/3544548.3581402,10.1145/3544548.3581402,acm,2023
387,Programming Is Hard - Or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation,"@inproceedings{10.1145/3545945.3569759,
author = {Becker, Brett A. and Denny, Paul and Finnie-Ansley, James and Luxton-Reilly, Andrew and Prather, James and Santos, Eddie Antonio},
title = {Programming Is Hard - Or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569759},
doi = {10.1145/3545945.3569759},
abstract = {The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {500–506},
numpages = {7},
keywords = {ai, alphacode, amazon, artificial intelligence, code generation, codewhisperer, codex, copilot, cs1, cs2, github, google, gpt-3, introductory programming, large language model, llm, machine learning, midjourney, novice programmers, openai, programming, tabnine},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

",https://doi.org/10.1145/3545945.3569759,10.1145/3545945.3569759,"acm, web_of_science, scopus",2023
388,Using Large Language Models to Enhance Programming Error Messages," @inproceedings{Leinonen_2023, series={SIGCSE 2023}, title={Using Large Language Models to Enhance Programming Error Messages}, url={http://dx.doi.org/10.1145/3545945.3569770}, DOI={10.1145/3545945.3569770}, booktitle={Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1}, publisher={ACM}, author={Leinonen, Juho and Hellas, Arto and Sarsa, Sami and Reeves, Brent and Denny, Paul and Prather, James and Becker, Brett A.}, year={2023}, month=mar, collection={SIGCSE 2023} }
",http://arxiv.org/pdf/2210.11630v1.pdf,10.1145/3545945.3569770,"arxiv, acm",2022
389,Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book,"@inproceedings{10.1145/3545945.3569785,
author = {MacNeil, Stephen and Tran, Andrew and Hellas, Arto and Kim, Joanne and Sarsa, Sami and Denny, Paul and Bernstein, Seth and Leinonen, Juho},
title = {Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569785},
doi = {10.1145/3545945.3569785},
abstract = {Advances in natural language processing have resulted in large language models (LLMs) that can generate code and code explanations. In this paper, we report on our experiences generating multiple code explanation types using LLMs and integrating them into an interactive e-book on web software development. Three different types of explanations -- a line-by-line explanation, a list of important concepts, and a high-level summary of the code -- were created. Students could view explanations by clicking a button next to code snippets, which showed the explanation and asked about its utility. Our results show that all explanation types were viewed by students and that the majority of students perceived the code explanations as helpful to them. However, student engagement varied by code snippet complexity, explanation type, and code snippet length. Drawing on our experiences, we discuss future directions for integrating explanations generated by LLMs into CS classrooms.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {931–937},
numpages = {7},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

",https://doi.org/10.1145/3545945.3569785,10.1145/3545945.3569785,"acm, scopus",2023
390,"Integrating Ethics into Computer Science Education: Multi-, Inter-, and Transdisciplinary Approaches","@inproceedings{10.1145/3545945.3569792,
author = {Goetze, Trystan S.},
title = {Integrating Ethics into Computer Science Education: Multi-, Inter-, and Transdisciplinary Approaches},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569792},
doi = {10.1145/3545945.3569792},
abstract = {While calls to integrate ethics into computer science education go back decades, recent high-profile ethical failures related to computing technology by large technology companies, governments, and academic institutions have accelerated the adoption of computer ethics education at all levels of instruction. Discussions of how to integrate ethics into existing computer science programmes often focus on the structure of the intervention---embedded modules or dedicated courses, humanists or computer scientists as ethics instructors---or on the specific content to be included---lists of case studies and essential topics to cover. While proponents of computer ethics education often emphasize the importance of closely connecting ethical and technical content in these initiatives, most do not reflect in depth on the variety of ways in which the disciplines can be combined. In this paper, I deploy a framework from cross-disciplinary studies that categorizes academic projects that work across disciplines as multidisciplinary, interdisciplinary, or transdisciplinary, depending on the degree of integration. When applied to computer ethics education, this framework is orthogonal to the structure and content of the initiative, as I illustrate using examples of dedicated ethics courses and embedded modules. It therefore highlights additional features of cross-disciplinary teaching that need to be considered when planning a computer ethics programme. I argue that computer ethics education should aim to be at least interdisciplinary-multidisciplinary initiatives are less aligned with the pedagogical aims of computer ethics-and that computer ethics educators should experiment with fully transdisciplinary education that could transform computer science as a whole for the better.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {645–651},
numpages = {7},
keywords = {cross-disciplinary studies, data justice, embedded ethics, ethics course, ethics education, higher education, interdisciplinary studies, interdisciplinary teaching and learning, responsible computing, transdisciplinary studies},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

",https://doi.org/10.1145/3545945.3569792,10.1145/3545945.3569792,acm,2023
391,Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language,"@inproceedings{10.1145/3545945.3569823,
author = {Denny, Paul and Kumar, Viraj and Giacaman, Nasser},
title = {Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569823},
doi = {10.1145/3545945.3569823},
abstract = {GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1136–1142},
numpages = {7},
keywords = {artificial intelligence, cs1, foundation models, github copilot, introductory programming, large language models, openai},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

",https://doi.org/10.1145/3545945.3569823,10.1145/3545945.3569823,"acm, scopus",2023
392,"Automatically Generating CS Learning Materials with Large Language
  Models"," @inproceedings{MacNeil_2022, series={SIGCSE 2023}, title={Automatically Generating CS Learning Materials with Large Language Models}, url={http://dx.doi.org/10.1145/3545947.3569630}, DOI={10.1145/3545947.3569630}, booktitle={Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2}, publisher={ACM}, author={MacNeil, Stephen and Tran, Andrew and Leinonen, Juho and Denny, Paul and Kim, Joanne and Hellas, Arto and Bernstein, Seth and Sarsa, Sami}, year={2022}, month=mar, collection={SIGCSE 2023} }
",http://arxiv.org/pdf/2212.05113v1.pdf,10.1145/3545947.3569630,arxiv,2022
393,Exploring the Potential of Chatbots to Provide Mental Well-being Support for Computer Science Students,"@article{2-s2.0-85149779953,
  title={Exploring the Potential of Chatbots to Provide Mental Well-being Support for Computer Science Students},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85149779953&origin=inward,10.1145/3545947.3576285,scopus,2023
394,Metaphorian: Leveraging Large Language Models to Support Extended Metaphor Creation for Science Writing,"@inproceedings{10.1145/3563657.3595996,
author = {Kim, Jeongyeon and Suh, Sangho and Chilton, Lydia B and Xia, Haijun},
title = {Metaphorian: Leveraging Large Language Models to Support Extended Metaphor Creation for Science Writing},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3595996},
doi = {10.1145/3563657.3595996},
abstract = {Science writers commonly use extended metaphors to communicate unfamiliar concepts in a more accessible way to a wider audience. However, creating metaphors for science writing is challenging even for professional writers; according to our formative study (n=6), finding inspiration and extending metaphors with coherent structures were critical yet significantly challenging tasks for them. We contribute Metaphorian, a system that supports science writers with the creation of scientific metaphors by facilitating the search, extension, and iterative revision of metaphors. Metaphorian uses a large language model-based workflow inspired by the heuristic rules revealed from a study with six professional writers. A user study (n=16) revealed that Metaphorian significantly enhances satisfaction, confidence, and inspiration in metaphor writing without decreasing writers’ sense of agency. We discuss design implications for creativity support for figurative writing in science.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {115–135},
numpages = {21},
keywords = {Creativity Support Tools, GPT-3, Large Language Model, Metaphors, Science Writing, Writing Support},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

",https://doi.org/10.1145/3563657.3595996,10.1145/3563657.3595996,acm,2023
395,Supporting Collaboration in Introductory Programming Classes Taught in Hybrid Mode: A Participatory Design Study,"@inproceedings{10.1145/3563657.3596042,
author = {Goswami, Lahari and Zeinoddin, Pegah Sadat and Estier, Thibault and Cherubini, Mauro},
title = {Supporting Collaboration in Introductory Programming Classes Taught in Hybrid Mode: A Participatory Design Study},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596042},
doi = {10.1145/3563657.3596042},
abstract = {Hybrid learning modalities, where learners can attend a course in-person or remotely, have gained particular significance in post-pandemic educational settings. In introductory programming courses, novices’ learning behaviour in the collaborative context of classrooms differs in hybrid mode from that of a traditional setting. Reflections from conducting an introductory programming course in hybrid mode led us to recognise the need for re-designing programming tools to support students’ collaborative learning practices. We conducted a participatory design study with nine students, directly engaging them in design to understand their interaction needs in hybrid pedagogical setups to enable effective collaboration during learning. Our findings first highlighted the difficulties that learners face in hybrid modes. The results then revealed learners’ preferences for design functionalities to enable collective notions, communication, autonomy, and regulation. Based on our findings, we discuss design principles and implications to inform the future design of collaborative programming environments for hybrid modes.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {1248–1262},
numpages = {15},
keywords = {collaboration, hybrid classroom, participatory design, programming environment},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

",https://doi.org/10.1145/3563657.3596042,10.1145/3563657.3596042,acm,2023
396,Designing Voice-First Ambient Interfaces to Support Aging in Place,"@inproceedings{10.1145/3563657.3596104,
author = {Cuadra, Andrea and Bethune, Jessica and Krell, Rony and Lempel, Alexa and H\""{a}nsel, Katrin and Shahrokni, Armin and Estrin, Deborah and Dell, Nicola},
title = {Designing Voice-First Ambient Interfaces to Support Aging in Place},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596104},
doi = {10.1145/3563657.3596104},
abstract = {We focus on the stories of five older adults who became voice assistant users through our study, and with whom we speculated about future interfaces through two design probes, one for health data reporting and one for positive reminiscing. We delivered a voice-first ambient interface (VFAI) to each participant, and closely observed participants’ journeys through periodic themed interviews (16 hours, 21 minutes of transcribed recordings), usage log reviews (4,657 entries), and phone and text support. Participants’ lived experiences impacted their perceptions and interactions with their VFAI, fueling rich insights about how to design for diverse needs. For example, while one participant saw increased potential in the VFAI after interacting with the design probe for health data reporting, another was skeptical of using it to communicate with her doctor. We contribute an in-depth exploration of VFAIs to support aging in place, implications for design, and areas for future work for tailoring VFAIs towards enabling continuity of care in people’s homes.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {2189–2205},
numpages = {17},
keywords = {Alexa, Older adults, aging in place, design probes, empirical study, field study, home health, inclusive design, internet of things, interviews, prototyping/implementation, qualitative methods, smart speakers, voice assistants, voice-first ambient interfaces, wellbeing},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

",https://doi.org/10.1145/3563657.3596104,10.1145/3563657.3596104,acm,2023
397,Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3,"@inproceedings{10.1145/3563657.3596138,
author = {Zamfirescu-Pereira, J.D. and Wei, Heather and Xiao, Amy and Gu, Kitty and Jung, Grace and Lee, Matthew G and Hartmann, Bjoern and Yang, Qian},
title = {Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596138},
doi = {10.1145/3563657.3596138},
abstract = {Prompting Large Language Models (LLMs) is an exciting new approach to designing chatbots. But can it improve LLM’s user experience (UX) reliably enough to power chatbot products? Our attempt to design a robust chatbot by prompting GPT-3/4 alone suggests: not yet. Prompts made achieving “80%” UX goals easy, but not the remaining 20%. Fixing the few remaining interaction breakdowns resembled herding cats: We could not address one UX issue or test one design solution at a time; instead, we had to handle everything everywhere all at once. Moreover, because no prompt could make GPT reliably say “I don’t know” when it should, the user-GPT conversations had no guardrails after a breakdown occurred, often leading to UX downward spirals. These risks incentivized us to design highly prescriptive prompts and scripted bots, counter to the promises of LLM-powered chatbots. This paper describes this case study, unpacks prompting’s fickleness and its impact on UX design processes, and discusses implications for LLM-based design methods and tools.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {2206–2220},
numpages = {15},
keywords = {GPT., Prompt engineering, UX, conversational user interface},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

",https://doi.org/10.1145/3563657.3596138,10.1145/3563657.3596138,acm,2023
398,A Comparative Analysis of Automatic Speech Recognition Errors in Small Group Classroom Discourse,"@inproceedings{10.1145/3565472.3595606,
author = {Cao, Jie and Ganesh, Ananya and Cai, Jon and Southwell, Rosy and Perkoff, E. Margaret and Regan, Michael and Kann, Katharina and Martin, James H. and Palmer, Martha and D'Mello, Sidney},
title = {A Comparative Analysis of Automatic Speech Recognition Errors in Small Group Classroom Discourse},
year = {2023},
isbn = {9781450399326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565472.3595606},
doi = {10.1145/3565472.3595606},
abstract = {In collaborative learning environments, effective intelligent learning systems need to accurately analyze and understand the collaborative discourse between learners (i.e., group modeling) to provide adaptive support. We investigate how automatic speech recognition&nbsp;(ASR) errors influence discourse models of small group collaboration in noisy real-world classrooms. Our dataset consisted of 30 students recorded by consumer off-the-shelf microphones&nbsp;(Yeti Blue) while engaging in dyadic- and triadic- collaborative learning in a multi-day STEM curriculum unit. We found that two state-of-the-art ASR systems (Google Speech and OpenAI Whisper) yielded very high word error rates (0.822, 0.847) but very different profiles of error with Google being more conservative, rejecting 38% of utterances instead of 12% for Whisper. Next, we examined how these ASR errors influenced down-stream small group modeling based on pre-trained large language models for three tasks: Abstract Meaning Representation parsing&nbsp;(AMRParsing), on-task/off-task detection&nbsp;(OnTask), and Accountable Productive Talk prediction&nbsp;(TalkMove). As expected, models trained on clean human transcripts yielded degraded performance on all three tasks, measured by the transfer ratio&nbsp;(TR). However, the TR of the specific sentence-level AMRParsing &nbsp;task&nbsp;(.39 - .62) was much lower than that of the abstract discourse-level OnTask &nbsp;(.63- .94) and TalkMove &nbsp; tasks&nbsp;(.64-.72). Furthermore, different training strategies that incorporated ASR transcripts alone or as augmentations of human transcripts increased accuracy for the discourse-level tasks&nbsp;(OnTask &nbsp;and TalkMove) but not AMRParsing. Simulation experiments suggested that the models were tolerant of missing utterances in the dialog context, and that jointly improving ASR accuracy on important word classes&nbsp;(e.g., verbs and nouns) can improve performance across all tasks. Overall, our results provide insights into how different types of NLP-based tasks might be tolerant of ASR errors under extremely noisy conditions and provide suggestions for how to improve accuracy in small group modeling settings for a more equitable, engaging, and adaptive collaborative learning environment.},
booktitle = {Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization},
pages = {250–262},
numpages = {13},
keywords = {Automatic Speech Recognition, Collaborative Learning, Group Discourse Analysis, Text Tagging},
location = {Limassol, Cyprus},
series = {UMAP '23}
}

",https://doi.org/10.1145/3565472.3595606,10.1145/3565472.3595606,acm,2023
399,"Am I Wrong, or Is the Autograder Wrong? Effects of AI Grading Mistakes on Learning","@inproceedings{10.1145/3568813.3600124,
author = {Li, Tiffany Wenting and Hsu, Silas and Fowler, Max and Zhang, Zhilin and Zilles, Craig and Karahalios, Karrie},
title = {Am I Wrong, or Is the Autograder Wrong? Effects of AI Grading Mistakes on Learning},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600124},
doi = {10.1145/3568813.3600124},
abstract = {Errors in AI grading and feedback often have an intractable set of causes and are, by their nature, difficult to completely avoid. Since inaccurate feedback potentially harms learning, there is a need for designs and workflows that mitigate these harms. To better understand the mechanisms by which erroneous AI feedback impacts students’ learning, we conducted surveys and interviews that recorded students’ interactions with a short-answer AI autograder for “Explain in Plain English” code reading problems. Using causal modeling, we inferred the learning impacts of wrong answers marked as right (false positives, FPs) and right answers marked as wrong (false negatives, FNs). We further explored explanations for the learning impacts, including errors influencing participants’ engagement with feedback and assessments of their answers’ correctness, and participants’ prior performance in the class. FPs harmed learning in large part due to participants’ failures to detect the errors. This was due to participants not paying attention to the feedback after being marked as right, and an apparent bias against admitting one’s answer was wrong once marked right. On the other hand, FNs harmed learning only for survey participants, suggesting that interviewees’ greater behavioral and cognitive engagement protected them from learning harms. Based on these findings, we propose ways to help learners detect FPs and encourage deeper reflection on FNs to mitigate the learning harms of AI errors.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {159–176},
numpages = {18},
keywords = {AI error, Bayesian modeling, EiPE, autograder, automated short answer grading, computer science education, explain in plain English, formative feedback, human-AI interaction},
location = {Chicago, IL, USA},
series = {ICER '23}
}

",https://doi.org/10.1145/3568813.3600124,10.1145/3568813.3600124,acm,2023
400,From ,"@inproceedings{10.1145/3568813.3600138,
author = {Lau, Sam and Guo, Philip},
title = {From ""Ban It Till We Understand It"" to ""Resistance is Futile"": How University Programming Instructors Plan to Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT and GitHub Copilot},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600138},
doi = {10.1145/3568813.3600138},
abstract = {Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {106–121},
numpages = {16},
keywords = {AI coding tools, ChatGPT, Copilot, LLM, instructor perspectives},
location = {Chicago, IL, USA},
series = {ICER '23}
}

",https://doi.org/10.1145/3568813.3600138,10.1145/3568813.3600138,"acm, web_of_science, scopus",2023
401,"Exploring the Responses of Large Language Models to Beginner
  Programmers' Help Requests"," @inproceedings{Hellas_2023, series={ICER 2023}, title={Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests}, url={http://dx.doi.org/10.1145/3568813.3600139}, DOI={10.1145/3568813.3600139}, booktitle={Proceedings of the 2023 ACM Conference on International Computing Education Research V.1}, publisher={ACM}, author={Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanpää, Lilja and Sorva, Juha}, year={2023}, month=aug, collection={ICER 2023} }
",http://arxiv.org/pdf/2306.05715v1.pdf,10.1145/3568813.3600139,"arxiv, acm, web_of_science, scopus",2023
402,"Thrilled by Your Progress! Large Language Models (GPT-4) No Longer
  Struggle to Pass Assessments in Higher Education Programming Courses"," @inproceedings{Savelka_2023, series={ICER 2023}, title={Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses}, url={http://dx.doi.org/10.1145/3568813.3600142}, DOI={10.1145/3568813.3600142}, booktitle={Proceedings of the 2023 ACM Conference on International Computing Education Research V.1}, publisher={ACM}, author={Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd}, year={2023}, month=aug, collection={ICER 2023} }
",http://arxiv.org/pdf/2306.10073v1.pdf,10.1145/3568813.3600142,"arxiv, acm, web_of_science, scopus",2023
403,Performance of Distributed Deep Learning Workloads on a Composable Cyberinfrastructure,"@inproceedings{10.1145/3569951.3593601,
author = {He, Zhenhua and Saluja, Aditi and Lawrence, Richard and Chakravorty, Dhruva and Dang, Francis and Perez, Lisa and Liu, Honggao},
title = {Performance of Distributed Deep Learning Workloads on a Composable Cyberinfrastructure},
year = {2023},
isbn = {9781450399852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569951.3593601},
doi = {10.1145/3569951.3593601},
abstract = {The next generation of computing systems are likely to rely on disaggregated resources that can be dynamically reconfigured and customized for researchers to support scientific and engineering workflows that require different cyberinfrastructure (CI) technologies. These resources would include memory, accelerators, co-processors among other technologies. This would represent a significant shift in High Performance Computing (HPC) from the now typical model of clusters that have these resources permanently connected to a single server. While composing hardware frameworks with disaggregated resources holds promise, we need to understand how to situate workflows on these resources and evaluate the impact of this approach on workflow performance against “traditional” clusters.&nbsp; Toward developing this knowledge framework, we study the applicability and performance of deep learning workloads on GPU-enabled composable and traditional HPC computing platforms. Results from tests performed using the Horovod framework with TensorFlow and PyTorch models on these HPC environments are presented here.},
booktitle = {Practice and Experience in Advanced Research Computing},
pages = {60–67},
numpages = {8},
keywords = {A100, Accelerators, BERT-Large, FASTER (Fostering Accelerated Sciences Transformation Education and Research), GPU (Graphics Processing Unit), Grace, ResNet50, T4},
location = {Portland, OR, USA},
series = {PEARC '23}
}

",https://doi.org/10.1145/3569951.3593601,10.1145/3569951.3593601,acm,2023
404,FlashFill++: Scaling Programming by Example by Cutting to the Chase,"@article{10.1145/3571226,
author = {Cambronero, Jos\'{e} and Gulwani, Sumit and Le, Vu and Perelman, Daniel and Radhakrishna, Arjun and Simon, Clint and Tiwari, Ashish},
title = {FlashFill++: Scaling Programming by Example by Cutting to the Chase},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {POPL},
url = {https://doi.org/10.1145/3571226},
doi = {10.1145/3571226},
abstract = {Programming-by-Examples (PBE) involves synthesizing an ""intended program"" from a small set of user-provided input-output examples. A key PBE strategy has been to restrict the search to a carefully designed small domain-specific language (DSL) with ""effectively-invertible"" (EI) operators at the top and ""effectively-enumerable"" (EE) operators at the bottom. This facilitates an effective combination of top-down synthesis strategy (which backpropagates outputs over various paths in the DSL using inverse functions) with a bottom-up synthesis strategy (which propagates inputs over various paths in the DSL). We address the problem of scaling synthesis to large DSLs with several non-EI/EE operators. This is motivated by the need to support a richer class of transformations and the need for readable code generation. We propose a novel solution strategy that relies on propagating fewer values and over fewer paths.  

Our first key idea is that of ""cut functions"" that prune the set of values being propagated by using knowledge of the sub-DSL on the other side. Cuts can be designed to preserve completeness of synthesis; however, DSL designers may use incomplete cuts to have finer control over the kind of programs synthesized. In either case, cuts make search feasible for non-EI/EE operators and efficient for deep DSLs. Our second key idea is that of ""guarded DSLs"" that allow a precedence on DSL operators, which dynamically controls exploration of various paths in the DSL. This makes search efficient over grammars with large fanouts without losing recall. It also makes ranking simpler yet more effective in learning an intended program from very few examples. Both cuts and precedence provide a mechanism to the DSL designer to restrict search to a reasonable, and possibly incomplete, space of programs.  

Using cuts and gDSLs, we have built FlashFill++, an industrial-strength PBE engine for performing rich string transformations, including datetime and number manipulations. The FlashFill++ gDSL is designed to enable readable code generation in different target languages including Excel's formula language, PowerFx, and Python. We show FlashFill++ is more expressive, more performant, and generates better quality code than comparable existing PBE systems. FlashFill++ is being deployed in several mass-market products ranging from spreadsheet software to notebooks and business intelligence applications, each with millions of users.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {33},
numpages = {30},
keywords = {domain-specific languages, programming by example, string transformations}
}

",https://doi.org/10.1145/3571226,10.1145/3571226,acm,2023
405,Programming by Voice: Exploring User Preferences and Speaking Styles,"@inproceedings{10.1145/3571884.3597130,
author = {Nowrin, Sadia and Vertanen, Keith},
title = {Programming by Voice: Exploring User Preferences and Speaking Styles},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3597130},
doi = {10.1145/3571884.3597130},
abstract = {Programming by voice is a potentially useful method for individuals with motor impairments. Spoken programs can be challenging for a standard speech recognizer with a language model trained on written text mined from sources such as web pages. Having an effective language model that captures the variability in spoken programs may be necessary for accurate recognition. In this work, we explore how novice and expert programmers speak code without requiring them to adhere to strict grammar rules. We investigate two approaches to collect data by having programmers speak either highlighted or missing lines of code. We observed that expert programmers spoke more naturally, while novice programmers spoke more syntactically. A commercial speech recognizer had a high error rate on our spoken programs. However, by adapting the recognizer’s language model with our spoken code transcripts, we were able to substantially reduce the error rate by 27% relative to the baseline on unseen spoken code.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {20},
numpages = {13},
keywords = {Accessibility, Speech Recognition, Voice Programming, Voice User Interfaces},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

",https://doi.org/10.1145/3571884.3597130,10.1145/3571884.3597130,acm,2023
406,The User Experience of ChatGPT: Findings from a Questionnaire Study of Early Users,"@inproceedings{10.1145/3571884.3597144,
author = {Skjuve, Marita and F\o{}lstad, Asbj\o{}rn and Brandtzaeg, Petter Bae},
title = {The User Experience of ChatGPT: Findings from a Questionnaire Study of Early Users},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3597144},
doi = {10.1145/3571884.3597144},
abstract = {The launch of ChatGPT has attracted significant attention and showcased the potentially game-changing capabilities of conversational AI. These capabilities, and lack of user research, highlight the need to investigate how users experience interactions with conversational AIs like ChatGPT. Therefore, we conducted a questionnaire study with ChatGPT users (N=194), inquiring about their good and poor experiences with ChatGPT. The user reports were analyzed by a thematic analysis and systematized through a pragmatic-hedonic framework. Our results demonstrate how user experience is influenced by pragmatic attributes such as ChatGPT providing useful and detailed information and easing work- or school-related tasks. Additionally, user experience is impacted by hedonic attributes, such as entertainment and creative interactions, and interactions leaving the user impressed or surprised. Our study underscores that user experience concerning conversational AI like ChatGPT is assessed by useful and productive interactions even in early phase of uptake, suggesting the importance of pragmatic attributes.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {2},
numpages = {10},
keywords = {ChatGPT, Conversational AI, Pragmatic-hedonic framework, User experience},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

",https://doi.org/10.1145/3571884.3597144,10.1145/3571884.3597144,acm,2023
407,High-Resolution Course Feedback: Timely Feedback Mechanism for Instructors,"@inproceedings{10.1145/3573051.3593391,
author = {Kim, Yunsung and Piech, Chris},
title = {High-Resolution Course Feedback: Timely Feedback Mechanism for Instructors},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3593391},
doi = {10.1145/3573051.3593391},
abstract = {We study the problem of minimizing the delay between when an issue comes up in a course and when instructors get feedback about it. The widespread practice of obtaining midterm and end-of-term feedback from students is suboptimal in this regard, especially for large courses: it over-samples at a specific point in the course and can be biased by factors irrelevant to the teaching process. As a solution, we release High Resolution Course Feedback (HRCF), an open-source student feedback mechanism that builds on a surprisingly simple idea: survey each student on random weeks exactly twice per term. Despite the simplicity of its core idea, when deployed to 31 courses totaling a cumulative 6,835 students, HRCF was able to detect meaningful mood changes in courses and significantly improve timely feedback without asking for extra work from students compared to the common practice. An interview with the instructors revealed that HRCF provided constructive and useful feedback about their courses early enough to be acted upon, which would have otherwise been unobtainable through other survey methods. We also explore the possibility of using Large Language Models to flexibly and intuitively organize large volumes of student feedback at scale and discuss how HRCF can be further improved.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {81–91},
numpages = {11},
keywords = {course improvement, course survey, student evaluations of teaching, student feedback on teaching, timely feedback},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

",https://doi.org/10.1145/3573051.3593391,10.1145/3573051.3593391,acm,2023
408,GPTeach: Interactive TA Training with GPT-based Students,"@inproceedings{10.1145/3573051.3593393,
author = {Markel, Julia M. and Opferman, Steven G. and Landay, James A. and Piech, Chris},
title = {GPTeach: Interactive TA Training with GPT-based Students},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3593393},
doi = {10.1145/3573051.3593393},
abstract = {Interactive and realistic teacher training is hard to scale. This is a key issue for learning at scale, as inadequate preparation can negatively impact both students and teachers. What if we could make the teacher training experience more engaging and, as a downstream effect, reduce the potential for harm that teachers-in-training could inflict on students? We present GPTeach, an interactive chat-based teacher training tool that allows novice teachers to practice with simulated students. We performed two studies to evaluate GPTeach: one think-aloud study and one A/B test between our tool and a baseline. Participants took the role of a teaching assistant conducting office hours with two GPT-simulated students. We found that our tool provides the opportunity for teachers to get valuable teaching practice without the pressures of affecting real students, allowing them to iterate their responses both during and across sessions. Additionally, participants enjoyed flexibility in tailoring their responses according to the varied personas, needs, and learning goals. In this paper, we provide quantitative results and qualitative observations to inform future work in this area. We conclude with a discussion of actionable design ideas for such systems, as well as other ways to use this tool for evaluating teachers and students. GPTeach has recently been deployed into the teacher training component of an online course with over 800 novice teachers.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {226–236},
numpages = {11},
keywords = {GPT-simulated students, scalable teacher training},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

",https://doi.org/10.1145/3573051.3593393,10.1145/3573051.3593393,acm,2023
409,Optimus-CC: Efficient Large NLP Model Training with 3D Parallelism Aware Communication Compression,"@inproceedings{10.1145/3575693.3575712,
author = {Song, Jaeyong and Yim, Jinkyu and Jung, Jaewon and Jang, Hongsun and Kim, Hyung-Jin and Kim, Youngsok and Lee, Jinho},
title = {Optimus-CC: Efficient Large NLP Model Training with 3D Parallelism Aware Communication Compression},
year = {2023},
isbn = {9781450399166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575693.3575712},
doi = {10.1145/3575693.3575712},
abstract = {In training of modern large natural language processing (NLP) models, it has become a common practice to split models using 3D parallelism to multiple GPUs. Such technique, however, suffers from a high overhead of inter-node communication. Compressing the communication is one way to mitigate the overhead by reducing the inter-node traffic volume; however, the existing compression techniques have critical limitations to be applied for NLP models with 3D parallelism in that 1) only the data parallelism traffic is targeted, and 2) the existing compression schemes already harm the model quality too much.  

In this paper, we present Optimus-CC, a fast and scalable distributed training framework for large NLP models with aggressive communication compression. Optimus-CC differs from existing communication compression frameworks in the following ways: First, we compress pipeline parallel (inter-stage) traffic. In specific, we compress the inter-stage backpropagation and the embedding synchronization in addition to the existing data-parallel traffic compression methods. Second, we propose techniques to avoid the model quality drop that comes from the compression. We further provide mathematical and empirical analyses to show that our techniques can successfully suppress the compression error. Lastly, we analyze the pipeline and opt to selectively compress those traffic lying on the critical path. This further helps reduce the compression error. We demonstrate our solution on a GPU cluster, and achieve superior speedup from the baseline state-of-the-art solutions for distributed training without sacrificing the model quality.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {560–573},
numpages = {14},
keywords = {3D Parallelism, Communication Optimization, Distributed Systems, Gradient Compression, Large-scale NLP Training, Pipeline Parallelism, Systems for Machine Learning},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

",https://doi.org/10.1145/3575693.3575712,10.1145/3575693.3575712,acm,2023
410,Always Provide Context: The Effects of Code Context on Programming Error Message Enhancement,"@inproceedings{10.1145/3576882.3617909,
author = {Santos, Eddie Antonio and Prasad, Prajish and Becker, Brett A.},
title = {Always Provide Context: The Effects of Code Context on Programming Error Message Enhancement},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617909},
doi = {10.1145/3576882.3617909},
abstract = {Programming error messages (PEMs) are notoriously difficult for novice programmers to utilise. Many efforts have been made to enhance PEMs such that they are reworded to explain problems in terms that novices can understand. However, the effectiveness of these efforts to enhance PEMs has been weak or inconclusive. This work seeks to determine the role that code context has on programming error message enhancement. Erroneous Java code written by novices was sampled from the Blackbox Mini dataset. The erroneous code was presented to expert raters with four different PEM variants: javac (control), Decaf -- an error message enhancing IDE -- and two variants generated using GPT-4: one that enhanced just the javac error message alone, and one that incorporates the code context in the prompt. We find that providing code context to LLMs increases the likelihood of correct explanations for underlying errors, produces more specific fixes for erroneous programs, and produces fixes that are more likely to be correct. In large language models, the community now has a resource that is capable of taking code context into account, to the benefit of novice programmers.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {147–153},
numpages = {7},
keywords = {Blackbox, BlueJ, CS1, GPT-4, Java, compiler error messages, computing education, debugging, feedback, large language models, novice programmers, programming error messages},
location = {Hyderabad, India},
series = {CompEd 2023}
}

",https://doi.org/10.1145/3576882.3617909,10.1145/3576882.3617909,"acm, scopus",2023
411,A Bug's New Life: Creating Refute Questions from Filtered CS1 Student Code Snapshots,"@inproceedings{10.1145/3576882.3617916,
author = {Agarwal, Nimisha and Kumar, Viraj and Raman, Arun and Karkare, Amey},
title = {A Bug's New Life: Creating Refute Questions from Filtered CS1 Student Code Snapshots},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617916},
doi = {10.1145/3576882.3617916},
abstract = {In an introductory programming (CS1) context, a Refute question asks students for a counter-example which proves that a given code fragment is an incorrect solution for a given task. Such a question can be used as an assessment item to (formatively) develop or (summatively) demonstrate a student's abilities to comprehend the task and the code well enough to recognize a mismatch. These abilities assume greater significance with the emergence of generative AI technologies capable of writing code that is plausible (at least to novice programmers) but not always correct.Instructors must address three concerns while designing an effective Refute question, each influenced by their specific teaching-learning context: (1) Is the task comprehensible? (2) Is the incorrect code a plausible solution for the task? (3) Is the complexity of finding a counter-example acceptable? While the first concern can often be addressed by reusing tasks from previous code writing questions, addressing the latter concerns may require substantial instructor effort. We therefore investigate whether concerns (2) and (3) can be addressed by buggy student solutions for the corresponding code writing question from a previous course offering. For 6 code writing questions (from a Fall 2015 C programming course), our automated evaluation system logged 13,847 snapshots of executable student code, of which 10,574 were buggy (i.e., they failed at least one instructor-supplied test case). Code selected randomly from this pool rarely addresses these concerns, and manual selection is infeasible. Our paper makes three contributions. First, we propose an automated mechanism to filter this pool to a more manageable number of snapshots from which appropriate code can be selected manually. Second, we evaluate our semi-automated mechanism with respect to concerns (2) and (3) by surveying a diverse set of 56 experienced participants (instructors, tutors, and teaching assistants). Third, we use this mechanism to seed a public repository of Refute questions and provide a template to create additional questions using a public resource (CodeCheck).},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {7–14},
numpages = {8},
keywords = {CS1, assessment, refute questions},
location = {Hyderabad, India},
series = {CompEd 2023}
}

",https://doi.org/10.1145/3576882.3617916,10.1145/3576882.3617916,acm,2023
412,Generating Programs Trivially: Student Use of Large Language Models,"@inproceedings{10.1145/3576882.3617921,
author = {Prasad, Siddhartha and Greenman, Ben and Nelson, Tim and Krishnamurthi, Shriram},
title = {Generating Programs Trivially: Student Use of Large Language Models},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617921},
doi = {10.1145/3576882.3617921},
abstract = {Educators have been concerned about the capability of large language models to automatically generate programs in response to textual prompts. However, little is known about whether and how students actually use these tools.In the context of an upper-level formal methods course, we gave students access to large language models. They were told they could use the models freely. We built a Visual Studio Code extension to simplify access to these models. We also paid for an account so students could use the models for free without worrying about cost.In this experience report we analyze the outcomes. We see how students actually do and do not use the models. We codify the different uses they make. Most of all, we notice that students actually do not use them very much at all, and provide insight into the many reasons why not. We believe such experiments can help rebalance some of the public narrative about such tools.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {126–132},
numpages = {7},
keywords = {formal methods, large language models, properties, testing},
location = {Hyderabad, India},
series = {CompEd 2023}
}

",https://doi.org/10.1145/3576882.3617921,10.1145/3576882.3617921,acm,2023
413,A Computational Inflection for Scientific Discovery,"@article{10.1145/3576896,
author = {Hope, Tom and Downey, Doug and Weld, Daniel S. and Etzioni, Oren and Horvitz, Eric},
title = {A Computational Inflection for Scientific Discovery},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/3576896},
doi = {10.1145/3576896},
abstract = {Enabling researchers to leverage systems to overcome the limits of human cognitive capacity.},
journal = {Commun. ACM},
month = {jul},
pages = {62–73},
numpages = {12}
}

",https://doi.org/10.1145/3576896,10.1145/3576896,acm,2023
414,Large Language Models to generate meaningful feature model instances,"@inproceedings{10.1145/3579027.3608973,
author = {Galindo, Jos\'{e} A. and Dominguez, Antonio J. and White, Jules and Benavides, David},
title = {Large Language Models to generate meaningful feature model instances},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608973},
doi = {10.1145/3579027.3608973},
abstract = {Feature models are the ""de facto"" standard for representing variability in software-intensive systems. Automated analysis of feature models is the computer-aided extraction of information of feature models and is used in testing, maintenance, configuration, and derivation, among other tasks. Testing the analyses of feature models often requires relying on a large number of models that are as realistic as possible. There exist different proposals to generate synthetic feature models using random techniques or metamorphic relations; however, the existing methods do not take into account the semantics of the concepts of the domain that are being represented and the interrelations between them, leading to less realistic feature models. In this paper, we propose a novel approach that uses Large Language Models (LLMs), such as Codex or GPT-3, to generate realistic feature models that preserve semantic coherence while maintaining syntactic validity. The approach automatically generates instances of feature models from a given domain. Concretely, two language models were used, first OpenAI's Codex to generate new instances of feature models using the Universal Variability Language (UVL) syntax and then Cohere's semantic analysis to verify if the newly introduced concepts are from the same domain. This approach enabled the generation of 90% of valid instances according to the UVL syntax. In addition, the valid models score well on model complexity metrics, and the generated features mirror the domain of the original UVL instance used as prompts. With this work, we envision a new thread of research where variability is generated and analyzed using LLMs. This opens the door for a new generation of techniques and tools for variability management.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {15–26},
numpages = {12},
keywords = {deep learning, large language models, synthetic models, universal variability language},
location = {Tokyo, Japan},
series = {SPLC '23}
}

",https://doi.org/10.1145/3579027.3608973,10.1145/3579027.3608973,acm,2023
415,Generative AI for Reengineering Variants into Software Product Lines: An Experience Report,"@inproceedings{10.1145/3579028.3609016,
author = {Acher, Mathieu and Martinez, Jabier},
title = {Generative AI for Reengineering Variants into Software Product Lines: An Experience Report},
year = {2023},
isbn = {9798400700927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579028.3609016},
doi = {10.1145/3579028.3609016},
abstract = {The migration and reengineering of existing variants into a software product line (SPL) is an error-prone and time-consuming activity. Many extractive approaches have been proposed, spanning different activities from feature identification and naming to the synthesis of reusable artefacts. In this paper, we explore how large language model (LLM)-based assistants can support domain analysts and developers. We revisit four illustrative cases of the literature where the challenge is to migrate variants written in different formalism (UML class diagrams, Java, GraphML, statecharts). We systematically report on our experience with ChatGPT-4, describing our strategy to prompt LLMs and documenting positive aspects but also failures. We compare the use of LLMs with state-of-the-art approach, BUT4Reuse. While LLMs offer potential in assisting domain analysts and developers in transitioning software variants into SPLs, their intrinsic stochastic nature and restricted ability to manage large variants or complex structures necessitate a semiautomatic approach, complete with careful review, to counteract inaccuracies.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume B},
pages = {57–66},
numpages = {10},
location = {Tokyo, Japan},
series = {SPLC '23}
}

",https://doi.org/10.1145/3579028.3609016,10.1145/3579028.3609016,acm,2023
416,MASCARA : Systematically Generating Memorable And Secure Passphrases,"@inproceedings{10.1145/3579856.3582839,
author = {Mukherjee, Avirup and Murali, Kousshik and Jha, Shivam Kumar and Ganguly, Niloy and Chatterjee, Rahul and Mondal, Mainack},
title = {MASCARA : Systematically Generating Memorable And Secure Passphrases},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579856.3582839},
doi = {10.1145/3579856.3582839},
abstract = {Passwords are the most common mechanism for authenticating users online. However, studies have shown that users find it difficult to create and manage secure passwords. To that end, passphrases are often recommended as a usable alternative to passwords, which would potentially be easy to remember and hard to guess. However, as we show, user-chosen passphrases fall short of being secure, while state-of-the-art machine-generated passphrases are difficult to remember. In this work, we aim to tackle the drawbacks of the systems that generate passphrases for practical use. In particular, we address the problem of generating secure and memorable passphrases and compare them against user chosen passphrases in use. We identify and characterize 72, 999 user-chosen in-use unique English passphrases from prior leaked password databases. Then we leverage this understanding to create a novel framework for measuring memorability and guessability of passphrases. Utilizing our framework, we design MASCARA, which follows a constrained Markov generation process to create passphrases that optimize for both memorability and guessability. Our evaluation of passphrases shows that MASCARA -generated passphrases are harder to guess than in-use user-generated passphrases, while being easier to remember compared to state-of-the-art machine-generated passphrases. We conduct a two-part user study with crowdsourcing platform Prolific to demonstrate that users have highest memory-recall (and lowest error rate) while using MASCARA passphrases. Moreover, for passphrases of length desired by the users, the recall rate is 60-100% higher for MASCARA-generated passphrases compared to current system-generated ones.},
booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
pages = {524–538},
numpages = {15},
keywords = {authentication, dataset, guessability, memorability, passphrases},
location = {Melbourne, VIC, Australia},
series = {ASIA CCS '23}
}

",https://doi.org/10.1145/3579856.3582839,10.1145/3579856.3582839,acm,2023
417,Powering an AI Chatbot with Expert Sourcing to Support Credible Health Information Access,"@inproceedings{10.1145/3581641.3584031,
author = {Xiao, Ziang and Liao, Q. Vera and Zhou, Michelle and Grandison, Tyrone and Li, Yunyao},
title = {Powering an AI Chatbot with Expert Sourcing to Support Credible Health Information Access},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581641.3584031},
doi = {10.1145/3581641.3584031},
abstract = {During a public health crisis like the COVID-19 pandemic, a credible and easy-to-access information portal is highly desirable. It helps with disease prevention, public health planning, and misinformation mitigation. However, creating such an information portal is challenging because 1) domain expertise is required to identify and curate credible and intelligible content, 2) the information needs to be updated promptly in response to the fast-changing environment, and 3) the information should be easily accessible by the general public; which is particularly difficult when most people do not have the domain expertise about the crisis. In this paper, we presented an expert-sourcing framework and created Jennifer, an AI chatbot, which serves as a credible and easy-to-access information portal for individuals during the COVID-19 pandemic. Jennifer was created by a team of over 150 scientists and health professionals around the world, deployed in the real world and answered thousands of user questions about COVID-19. We evaluated Jennifer from two key stakeholders’ perspectives, expert volunteers and information seekers. We first interviewed experts who contributed to the collaborative creation of Jennifer to learn about the challenges in the process and opportunities for future improvement. We then conducted an online experiment that examined Jennifer’s effectiveness in supporting information seekers in locating COVID-19 information and gaining their trust. We share the key lessons learned and discuss design implications for building expert-sourced and AI-powered information portals, along with the risks and opportunities of misinformation mitigation and beyond.},
booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {2–18},
numpages = {17},
keywords = {AI-powered chatbot, COVID-19, crisis informatics, expert sourcing, information access, information seeking, misinformation},
location = {Sydney, NSW, Australia},
series = {IUI '23}
}

",https://doi.org/10.1145/3581641.3584031,10.1145/3581641.3584031,acm,2023
418,Scim: Intelligent Skimming Support for Scientific Papers,"@inproceedings{10.1145/3581641.3584034,
author = {Fok, Raymond and Kambhamettu, Hita and Soldaini, Luca and Bragg, Jonathan and Lo, Kyle and Hearst, Marti and Head, Andrew and Weld, Daniel S},
title = {Scim: Intelligent Skimming Support for Scientific Papers},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581641.3584034},
doi = {10.1145/3581641.3584034},
abstract = {Scholars need to keep up with an exponentially increasing flood of scientific papers. To aid this challenge, we introduce Scim, a novel intelligent interface that helps experienced researchers skim – or rapidly review – a paper to attain a cursory understanding of its contents. Scim supports the skimming process by highlighting salient paper contents in order to direct a reader’s attention. The system’s highlights are faceted by content type, evenly distributed across a paper, and have a density configurable by readers at both the global and local level. We evaluate Scim with both an in-lab usability study and a longitudinal diary study, revealing how its highlights facilitate the more efficient construction of a conceptualization of a paper. We conclude by discussing design considerations and tensions for the design of future intelligent skimming tools.},
booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {476–490},
numpages = {15},
keywords = {Intelligent reading interfaces, highlights, scientific papers, skimming},
location = {Sydney, NSW, Australia},
series = {IUI '23}
}

",https://doi.org/10.1145/3581641.3584034,10.1145/3581641.3584034,acm,2023
419,Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System,"@article{2-s2.0-85151988830,
  title={Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85151988830&origin=inward,10.1145/3581754.3584111,scopus,2023
420,Zero-TextCap: Zero-shot Framework for Text-based Image Captioning,"@inproceedings{10.1145/3581783.3612571,
author = {Xu, Dongsheng and Zhao, Wenye and Cai, Yi and Huang, Qingbao},
title = {Zero-TextCap: Zero-shot Framework for Text-based Image Captioning},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612571},
doi = {10.1145/3581783.3612571},
abstract = {Text-based image captioning is a vital but under-explored task, which aims to describe images by captions containing scene text automatically. Recent studies have made encouraging progress, but they are still suffering from two issues. Firstly, current models cannot capture and generate scene text in non-Latin script languages, which severely limits the objectivity and the information completeness of generated captions. Secondly, current models tend to describe images with monotonous and templated style, which greatly limits the diversity of the generated captions. Although the above-mentioned issues can be alleviated through carefully designed annotations, this process is undoubtedly laborious and time-consuming. To address the above issues, we propose a Zero-shot Framework for Text-based Image Captioning (Zero-TextCap). Concretely, to generate candidate sentences starting from the prompt 'Image of' and iteratively refine them to improve the quality and diversity of captions, we introduce a Hybrid-sampling masked language model (H-MLM). To read multi-lingual scene text and model the relationships between them, we introduce a robust OCR system. To ensure that the captions generated by H-MLM contain scene text and are highly relevant to the image, we propose a CLIP-based generation guidance module to insert OCR tokens and filter candidate sentences. Our Zero-TextCap is capable of generalizing captions containing multi-lingual scene text and boosting the diversity of captions. Sufficient experiments demonstrate the effectiveness of our proposed Zero-TextCap. Our codes are available at https://github.com/Gemhuang79/Zero_TextCap.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {4949–4957},
numpages = {9},
keywords = {diversity, language bias, text-based image captioning, zero-shot},
location = {Ottawa ON, Canada},
series = {MM '23}
}

",https://doi.org/10.1145/3581783.3612571,10.1145/3581783.3612571,acm,2023
421,A Hierarchical Deep Video Understanding Method with Shot-Based Instance Search and Large Language Model,"@inproceedings{10.1145/3581783.3612838,
author = {Li, Ruizhe and Guo, Jiahao and Li, Mingxi and Wu, Zhengqian and Liang, Chao},
title = {A Hierarchical Deep Video Understanding Method with Shot-Based Instance Search and Large Language Model},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612838},
doi = {10.1145/3581783.3612838},
abstract = {Deep video understanding (DVU) is often considered a challenge due to the aim of interpreting a video with storyline, which is designed to solve two levels of problems: predicting the human interaction in scene-level and identifying the relationship between two entities in movie-level. Based on our understanding of the movie characteristics and analysis of DVU tasks, in this paper, we propose a four-stage method to solve the task, which includes video structuring, shot based instance search, interaction &amp; relation prediction and shot-scene summary &amp; Question Answering (QA) with ChatGPT. In these four stages, shot based instance search allows accurate identification and tracking of characters at an appropriate video granularity. Using ChatGPT in QA, on the one hand, can narrow the answer space, on the other hand, with the help of the powerful text understanding ability, ChatGPT can help us answer the questions by giving background knowledge. We rank first in movie-level group 2 and scene-level group 1, second in movie-level group 1 and scene-level group 2 in ACM MM 2023 Grand Challenge.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9425–9429},
numpages = {5},
keywords = {instance search, multi-modal feature, vedio understanding},
location = {Ottawa ON, Canada},
series = {MM '23}
}

",https://doi.org/10.1145/3581783.3612838,10.1145/3581783.3612838,acm,2023
422,VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores,"@inproceedings{10.1145/3581784.3607087,
author = {Castro, Roberto L. and Ivanov, Andrei and Andrade, Diego and Ben-Nun, Tal and Fraguela, Basilio B. and Hoefler, Torsten},
title = {VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3607087},
doi = {10.1145/3581784.3607087},
abstract = {The increasing success and scaling of Deep Learning models demands higher computational efficiency and power. Sparsification can lead to both smaller models as well as higher compute efficiency, and accelerated hardware is becoming available. However, exploiting it efficiently requires kernel implementations, pruning algorithms, and storage formats, to utilize hardware support of specialized sparse vector units. An example of those are the NVIDIA's Sparse Tensor Cores (SPTCs), which promise a 2\texttimes{} speedup. However, SPTCs only support the 2:4 format, limiting achievable sparsity ratios to 50%. We present the V:N:M format, which enables the execution of arbitrary N:M ratios on SPTCs. To efficiently exploit the resulting format, we propose Spatha, a high-performance sparse-library for DL routines. We show that Spatha achieves up to 37\texttimes{} speedup over cuBLAS. We also demonstrate a second-order pruning technique that enables sparsification to high sparsity ratios with V:N:M and little to no loss in accuracy in modern transformers.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {72},
numpages = {14},
keywords = {neural networks, pruning, GPGPU, CUDA, sparse tensor cores},
location = {Denver, CO, USA},
series = {SC '23}
}

",https://doi.org/10.1145/3581784.3607087,10.1145/3581784.3607087,acm,2023
423,FORGE: Pre-Training Open Foundation Models for Science,"@inproceedings{10.1145/3581784.3613215,
author = {Yin, Junqi and Dash, Sajal and Wang, Feiyi and Shankar, Mallikarjun},
title = {FORGE: Pre-Training Open Foundation Models for Science},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3613215},
doi = {10.1145/3581784.3613215},
abstract = {Large language models (LLMs) are poised to revolutionize the way we conduct scientific research. However, both model complexity and pre-training cost are impeding effective adoption for the wider science community. Identifying suitable scientific use cases, finding the optimal balance between model and data sizes, and scaling up model training are among the most pressing issues that need to be addressed. In this study, we provide practical solutions for building and using LLM-based foundation models targeting scientific research use cases. We present an end-to-end examination of the effectiveness of LLMs in scientific research, including their scaling behavior and computational requirements on Frontier, the first Exascale supercomputer. We have also developed for release to the scientific community a suite of open foundation models called FORGE with up to 26B parameters using 257B tokens from over 200M scientific articles, with performance either on par or superior to other state-of-the-art comparable models. We have demonstrated the use and effectiveness of FORGE on scientific downstream tasks. Our research establishes best practices that can be applied across various fields to take advantage of LLMs for scientific discovery.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {81},
numpages = {13},
location = {Denver, CO, USA},
series = {SC '23}
}

",https://doi.org/10.1145/3581784.3613215,10.1145/3581784.3613215,acm,2023
424,The Social Impact of Generative AI: An Analysis on ChatGPT,"@inproceedings{10.1145/3582515.3609555,
author = {Baldassarre, Maria Teresa and Caivano, Danilo and Fernandez Nieto, Berenice and Gigante, Domenico and Ragone, Azzurra},
title = {The Social Impact of Generative AI: An Analysis on ChatGPT},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609555},
doi = {10.1145/3582515.3609555},
abstract = {In recent months, the impact of Artificial Intelligence (AI) on citizens’ lives has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a citizen-centric AI.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {363–373},
numpages = {11},
keywords = {Citizen-centric AI, Generative AI Social Impact, Trustable AI},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

",https://doi.org/10.1145/3582515.3609555,10.1145/3582515.3609555,acm,2023
425,Data Discovery for the SDGs: A Systematic Rule-based Approach,"@inproceedings{10.1145/3582515.3609557,
author = {Jiang, Yuwei and Johnson, David},
title = {Data Discovery for the SDGs: A Systematic Rule-based Approach},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609557},
doi = {10.1145/3582515.3609557},
abstract = {In 2015, the United Nations put forward 17 Sustainable Development Goals (SDGs) to be achieved by 2030, where data has been promoted as a focus to innovating sustainable development and as a means to measuring progress towards achieving the SDGs. In this study, we propose a systematic approach towards discovering data types and sources that can be used for SDG research. The proposed method integrates a systematic mapping approach using manual qualitative coding over a corpus of SDG-related research literature followed by an automated process that applies rules to perform data entity extraction computationally. This approach is exemplified by an analysis of literature relating to SDG 7, the results of which are also presented in this paper. The paper concludes with a discussion of the approach and suggests future work to extend the method with more advanced NLP and machine learning techniques.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {384–391},
numpages = {8},
keywords = {SDG, data use, knowledge discovery, named entity extraction, sustainable development, systematic mapping},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

",https://doi.org/10.1145/3582515.3609557,10.1145/3582515.3609557,acm,2023
426,Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models,"@inproceedings{10.1145/3583780.3614905,
author = {Chen, Yuyan and Fu, Qiang and Yuan, Yichen and Wen, Zhihao and Fan, Ge and Liu, Dayiheng and Zhang, Dongmei and Li, Zhixu and Xiao, Yanghua},
title = {Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614905},
doi = {10.1145/3583780.3614905},
abstract = {Large language models (LLMs) have gained widespread adoption in various natural language processing tasks, including question answering and dialogue systems. However, a major drawback of LLMs is the issue of hallucination, where they generate unfaithful or inconsistent content that deviates from the input source, leading to severe consequences. In this paper, we propose a robust discriminator named RelD to effectively detect hallucination in LLMs' generated answers. RelD is trained on the constructed RelQA, a bilingual question-answering dialogue dataset along with answers generated by LLMs and a comprehensive set of metrics. Our experimental results demonstrate that the proposed RelD successfully detects hallucination in the answers generated by diverse LLMs. Moreover, it performs well in distinguishing hallucination in LLMs' generated answers from both in-distribution and out-of-distribution datasets. Additionally, we also conduct a thorough analysis of the types of hallucinations that occur and present valuable insights. This research significantly contributes to the detection of reliable answers generated by LLMs and holds noteworthy implications for mitigating hallucination in the future work.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {245–255},
numpages = {11},
keywords = {hallucination detection, large language models, reliable answers},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

",https://doi.org/10.1145/3583780.3614905,10.1145/3583780.3614905,acm,2023
427,SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction,"@inproceedings{10.1145/3583780.3615047,
author = {Hoq, Muntasir and Chilla, Sushanth Reddy and Ahmadi Ranjbar, Melika and Brusilovsky, Peter and Akram, Bita},
title = {SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615047},
doi = {10.1145/3583780.3615047},
abstract = {Automated analysis of programming data using code representation methods offers valuable services for programmers, from code completion to clone detection to bug detection. Recent studies show the effectiveness of Abstract Syntax Trees (AST), pre-trained Transformer-based models, and graph-based embeddings in programming code representation. However, pre-trained large language models lack interpretability, while other embedding-based approaches struggle with extracting important information from large ASTs. This study proposes a novel Subtree-based Attention Neural Network (SANN) to address these gaps by integrating different components: an optimized sequential subtree extraction process using Genetic algorithm optimization, a two-way embedding approach, and an attention network. We investigate the effectiveness of SANN by applying it to two different tasks: program correctness prediction and algorithm detection on two educational datasets containing both small and large-scale code snippets written in Java and C, respectively. The experimental results show SANN's competitive performance against baseline models from the literature, including code2vec, ASTNN, TBCNN, CodeBERT, GPT-2, and MVG, regarding accurate predictive power. Finally, a case study is presented to show the interpretability of our model prediction and its application for an important human-centered computing application, student modeling. Our results indicate the effectiveness of the SANN model in capturing important syntactic and semantic information from students' code, allowing the construction of accurate student models, which serve as the foundation for generating adaptive instructional support such as individualized hints and feedback.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {783–792},
numpages = {10},
keywords = {algorithm detection, code representation, program analysis, program correctness prediction, static analysis},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

",https://doi.org/10.1145/3583780.3615047,10.1145/3583780.3615047,acm,2023
428,Continually-Adaptive Representation Learning Framework for Time-Sensitive Healthcare Applications,"@inproceedings{10.1145/3583780.3615464,
author = {Choudhuri, Akash and Jang, Hankyu and Segre, Alberto M. and Polgreen, Philip M. and Jha, Kishlay and Adhikari, Bijaya},
title = {Continually-Adaptive Representation Learning Framework for Time-Sensitive Healthcare Applications},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615464},
doi = {10.1145/3583780.3615464},
abstract = {Continual learning has emerged as a powerful approach to address the challenges of non-stationary environments, allowing machine learning models to adapt to new data while retaining the previously acquired knowledge. In time-sensitive healthcare applications, where entities such as physicians, hospital rooms, and medications exhibit continuous changes over time, continual learning holds great promise, yet its application remains relatively unexplored. This paper aims to bridge this gap by proposing a novel framework, i.e., Continually-Adaptive Representation Learning, designed to adapt representations in response to changing data distributions in evolving healthcare applications. Specifically, the proposed approach develops a continual learning strategy wherein the context information (e.g., interactions) of healthcare entities is exploited to continually identify and retrain the representations of those entities whose context evolved over time. Moreover, different from existing approaches, the proposed approach leverages the valuable patient information present in clinical notes to generate accurate and robust healthcare embeddings. Notably, the proposed continually-adaptive representations have practical benefits in low-resource clinical settings where it is difficult to training machine learning models from scratch to accommodate the newly available data streams. Experimental evaluations on real-world healthcare datasets demonstrate the effectiveness of our approach in time-sensitive healthcare applications such as Clostridioides difficile (C.diff) Infection (CDI) incidence prediction task and medical intensive care unit transfer prediction task.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {4538–4544},
numpages = {7},
keywords = {clinical notes, continual learning, dynamic embeddings, electronic healthcare records},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

",https://doi.org/10.1145/3583780.3615464,10.1145/3583780.3615464,acm,2023
429,Ethics of Emerging Communication and Collaboration Technologies for Children,"@inproceedings{10.1145/3584931.3606957,
author = {Hourcade, Juan Pablo and Bonsignore, Elizabeth and Clegg, Tamara and Currin, Flannery and Fails, Jerry A and Jin, Georgie Qiao and Schmuecker, Summer R and Yarosh, Lana},
title = {Ethics of Emerging Communication and Collaboration Technologies for Children},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3606957},
doi = {10.1145/3584931.3606957},
abstract = {This SIG will provide child-computer interaction researchers and practitioners, as well as other interested CSCW attendees, an opportunity to discuss topics related to the ethics of emerging communication and collaboration technologies for children. The child-computer interaction community has conducted many discussions on ethical issues, including a recent SIG at CHI 2023. However, the angle of communication and collaboration has not been a focus, even though emerging technologies could affect these aspects in significant ways. Hence, there is a need to consider emerging technologies, such as extended reality, and how they may impact the way children communicate and collaborate in face-to-face, remote, and hybrid (mixed-presence) contexts. This SIG will be an opportunity to discuss methods to consider these ethical concerns, properties of emerging technologies that may affect communication and collaboration, considerations for deployment of these emerging technologies, and future scenarios to ponder.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {560–562},
numpages = {3},
keywords = {children, emerging technologies, ethics, extended reality, participatory methods},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

",https://doi.org/10.1145/3584931.3606957,10.1145/3584931.3606957,acm,2023
430,Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub,"@inproceedings{10.1145/3584931.3606959,
author = {Yoo, Taewon and Lee, Hyunmin and Oh, SeungYoung and Kwon, Hyosun and Jung, Hyunggu},
title = {Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3606959},
doi = {10.1145/3584931.3606959},
abstract = {The increasing performance of machine learning (ML) models necessitates greater computing resources, contributing to rising carbon intensity in ML computing and raising concerns about computational equity. Previous studies focused on developing tools that enable model developers to view the carbon intensity of the ML models in the training process. Still, little is known about how to support ML developers in online communities to explore the carbon intensity of ML models during inference. We developed MIEV, a model inference emission visualizer, that supports ML developers on TensorFlow Hub to explore the carbon intensity of image domain models during the model Inference phase. We also provide insights into designing technologies that promote collaborative work among ML developers to drive sustainable AI development processes. To the best of our knowledge, this is the first attempt to interactively visualize the carbon intensity of ML models in online communities during the Inference phase.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {206–211},
numpages = {6},
keywords = {TensorFlow Hub, carbon intensity, inference, online communities},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

",https://doi.org/10.1145/3584931.3606959,10.1145/3584931.3606959,acm,2023
431,Toward Value Scenario Generation Through Large Language Models,"@inproceedings{10.1145/3584931.3606960,
author = {Jung, Hyunggu and Seo, Woosuk and Song, Seokwoo and Na, Sungmin},
title = {Toward Value Scenario Generation Through Large Language Models},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3606960},
doi = {10.1145/3584931.3606960},
abstract = {We propose a method of generating value scenarios for design research by leveraging ChatGPT, an AI-powered chatbot based on large language models. Identifying the needs of a vulnerable population, such as North Korean defectors, is challenging for researchers. To address this, we introduce ChatGPT-generated value scenarios, an extension of scenario-based design that supports critical, systemic, long-term thinking in current design practice, technology development, and deployment. Using our proposed method, we created a prompt to generate value scenarios on ChatGPT. Based on our analysis of the generated scenarios, we identified that ChatGPT could generate plausible information about Value Implications. However, it lacks details on Pervasiveness and Systemic Effects. After discussing the limitations and opportunities of ChatGPT in generating value scenarios, we conclude with suggestions for how ChatGPT might be better used to generate value scenarios.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {212–220},
numpages = {9},
keywords = {ChatGPT, large language models, value scenarios},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

",https://doi.org/10.1145/3584931.3606960,10.1145/3584931.3606960,acm,2023
432,NBGuru: Generating Explorable Data Science Flowcharts to Facilitate Asynchronous Communication in Interdisciplinary Data Science Teams,"@inproceedings{10.1145/3584931.3607020,
author = {Keelawat, Panayu},
title = {NBGuru: Generating Explorable Data Science Flowcharts to Facilitate Asynchronous Communication in Interdisciplinary Data Science Teams},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3607020},
doi = {10.1145/3584931.3607020},
abstract = {Data scientists typically work with domain experts in a Data Science (DS) project, resulting in knowledge gaps between roles. Communication holds an immense and difficult workload due to the complicated content, limited meeting time, vast audience backgrounds, etc. Thus, it is almost impossible to build a common ground within the team. Taking a step back, flowcharts and program descriptions have shown to help programmers learn algorithms. However, drawing a flowchart or writing a description takes time and effort. The novel AI-powered search engines can generate elaborate grounded responses with citations. It is then possible to generate flowcharts with text descriptions from code. Therefore, we studied 92 DS flowcharts and 173 code descriptions from top-voted Kaggle notebooks. We propose NBGuru, a flowchart-based communication tool. Users can explore computation steps asynchronously with generated texts and citations. Furthermore, we also discuss the possibility of AI in other collaborative roles.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {6–11},
numpages = {6},
keywords = {artificial intelligence, asynchronous communication, collaboration, computational notebooks, data science, flowchart, interdisciplinary, large language model, on-the-job training},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

",https://doi.org/10.1145/3584931.3607020,10.1145/3584931.3607020,acm,2023
433,ReaderQuizzer: Augmenting Research Papers with Just-In-Time Learning Questions to Facilitate Deeper Understanding,"@inproceedings{10.1145/3584931.3607494,
author = {Richards Maldonado, Liam and Abouzied, Azza and Gleason, Nancy W.},
title = {ReaderQuizzer: Augmenting Research Papers with Just-In-Time Learning Questions to Facilitate Deeper Understanding},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3607494},
doi = {10.1145/3584931.3607494},
abstract = {Academic reading is a key component of higher education, and serves as a basis for critical thinking, knowledge acquisition and effective communication. Research shows many students struggle with comprehension and analysis tasks with academic texts, despite the central importance of academic reading to success in higher education. Undergraduates and researchers need to internalize dense literature to scaffold their own work upon it. This reading task is time-consuming and difficult to do. Oftentimes, students struggle to actively and critically engage and as a result attain merely a cursory understanding of a paper’s contents, or worse, incorrectly interpret the text. How, then, can we provide a means to more easily digest a text while also facilitating meaningful, critical engagement and understanding? This paper locates itself within the broader field of augmented reading interfaces to implement an augmented reading interface that leverages the power of large language models (LLM) to intelligently generate and co-locate comprehension and analysis questions in an academic paper, thereby making the paper more digestible with the end goal of facilitating deeper understanding, and developing critical reading skills.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {391–394},
numpages = {4},
keywords = {academic papers, augmented reading interfaces, reading comprehension},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

",https://doi.org/10.1145/3584931.3607494,10.1145/3584931.3607494,acm,2023
434,Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models,"@inproceedings{10.1145/3585059.3611409,
author = {Gumina, Sharon and Dalton, Travis and Gerdes, John},
title = {Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611409},
doi = {10.1145/3585059.3611409},
abstract = {This paper argues for the inclusion of tools that utilize Artificial Intelligence (AI) Large Language Models (LLMs) in information technology (IT) undergraduate courses that teach the fundamentals of software. LLM tools have become widely available and disrupt traditional methods for teaching software concepts. Learning objectives are compromised when students submit AI-generated code for a classroom assignment without comprehending or validating the code. Since LLM tools including OpenAI Codex, Copilot by GitHub, and ChatGPT are being used in industry for software development, students need to be familiar with their use without compromising student learning. Incorporating LLM tools into the curriculum prepares students for real-world software development. However, students still need to understand software fundamentals including how to write and debug code. There are many challenges associated with the inclusion of AI tools into the IT curriculum that need to be addressed and mitigated. This paper presents strategies and techniques to integrate student use of LLM tools, assist students’ interaction with the tools, and help prepare students for careers that increasingly use AI tools to design, develop, and maintain software.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {60–65},
numpages = {6},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

",https://doi.org/10.1145/3585059.3611409,10.1145/3585059.3611409,"acm, scopus",2023
435,"ChatGPT for Teaching and Learning: An Experience from Data Science
  Education"," @inproceedings{Zheng_2023, series={SIGITE ’23}, title={ChatGPT for Teaching and Learning: An Experience from Data Science Education}, url={http://dx.doi.org/10.1145/3585059.3611431}, DOI={10.1145/3585059.3611431}, booktitle={The 24th Annual Conference on Information Technology Education}, publisher={ACM}, author={Zheng, Yong}, year={2023}, month=oct, collection={SIGITE ’23} }
",http://arxiv.org/pdf/2307.16650v1.pdf,10.1145/3585059.3611431,"arxiv, acm, scopus",2023
436,Exploring the Role of ChatGPT in Education: Applications and Challenges,"@inproceedings{10.1145/3585059.3611445,
author = {Mosaiyebzadeh, Fatemeh and Pouriyeh, Seyedamin and Parizi, Reza and Dehbozorgi, Nasrin and Dorodchi, Mohsen and Mac\^{e}do Batista, Daniel},
title = {Exploring the Role of ChatGPT in Education: Applications and Challenges},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611445},
doi = {10.1145/3585059.3611445},
abstract = {The development of ChatGPT as a sophisticated artificial intelligence technology has impacted numerous sectors, including education and research. The ChatGPT is a powerful large language model that allows students and educators to take advantage of many opportunities, such as personalized learning, lesson planning, and task reduction. While ChatGPT has the potential to streamline pedagogy and research, it poses a variety of challenges, such as allowing cheating on exams and homework, which puts students’ problem-solving skills at risk. Also, ChatGPT creates text that looks like human text, so cheating can be difficult to detect. In this paper, we explore the potential opportunities of ChatGPT in the education sector, as well as its limitations and challenges.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {84–89},
numpages = {6},
keywords = {OpenAI, Large Language Model, Education, ChatGPT, Artificial Intelligence},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

",https://doi.org/10.1145/3585059.3611445,10.1145/3585059.3611445,acm,2023
437,Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts,"@inproceedings{10.1145/3586183.3606719,
author = {Angert, Tyler and Suzara, Miroslav and Han, Jenny and Pondoc, Christopher and Subramonyam, Hariharan},
title = {Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606719},
doi = {10.1145/3586183.3606719},
abstract = {Creative coding tasks are often exploratory in nature. When producing digital artwork, artists usually begin with a high-level semantic construct such as a “stained glass filter” and programmatically implement it by varying code parameters such as shape, color, lines, and opacity to produce visually appealing results. Based on interviews with artists, it can be effortful to translate semantic constructs to program syntax, and current programming tools don’t lend well to rapid creative exploration. To address these challenges, we introduce Spellburst, a large language model (LLM) powered creative-coding environment. Spellburst provides (1) a node-based interface that allows artists to create generative art and explore variations through branching and merging operations, (2) expressive prompt-based interactions to engage in semantic programming, and (3) dynamic prompt-driven interfaces and direct code editing to seamlessly switch between semantic and syntactic exploration. Our evaluation with artists demonstrates Spellburst’s potential to enhance creative coding practices and inform the design of computational creativity tools that bridge semantic and syntactic spaces.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {100},
numpages = {22},
keywords = {creative coding, exploratory programming, generative art, large language models, prompt engineering},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606719,10.1145/3586183.3606719,acm,2023
438,GenAssist: Making Image Generation Accessible,"@inproceedings{10.1145/3586183.3606735,
author = {Huh, Mina and Peng, Yi-Hao and Pavel, Amy},
title = {GenAssist: Making Image Generation Accessible},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606735},
doi = {10.1145/3586183.3606735},
abstract = {Blind and low vision (BLV) creators use images to communicate with sighted audiences. However, creating or retrieving images is challenging for BLV creators as it is difficult to use authoring tools or assess image search results. Thus, creators limit the types of images they create or recruit sighted collaborators. While text-to-image generation models let creators generate high-fidelity images based on a text description (i.e. prompt), it is difficult to assess the content and quality of generated images. We present GenAssist, a system to make text-to-image generation accessible. Using our interface, creators can verify whether generated image candidates followed the prompt, access additional details in the image not specified in the prompt, and skim a summary of similarities and differences between image candidates. To power the interface, GenAssist uses a large language model to generate visual questions, vision-language models to extract answers, and a large language model to summarize the results. Our study with 12 BLV creators demonstrated that GenAssist enables and simplifies the process of image selection and generation, making visual authoring more accessible to all.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {38},
numpages = {17},
keywords = {Accessibility, Creativity Support Tools, Generative AI, Image Generation},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606735,10.1145/3586183.3606735,acm,2023
439,Graphologue: Exploring Large Language Model Responses with Interactive Diagrams,"@inproceedings{10.1145/3586183.3606737,
author = {Jiang, Peiling and Rayan, Jude and Dow, Steven P. and Xia, Haijun},
title = {Graphologue: Exploring Large Language Model Responses with Interactive Diagrams},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606737},
doi = {10.1145/3586183.3606737},
abstract = {Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented ability to synthesize text responses to diverse user questions. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can interact with the diagrams to flexibly adjust the graphical presentation and to submit context-specific prompts to obtain more information. Utilizing diagrams, Graphologue enables graphical, non-linear dialogues between humans and LLMs, facilitating information exploration, organization, and comprehension.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {3},
numpages = {20},
keywords = {Large Language Model, Natural Language Interface, Visualization},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606737,10.1145/3586183.3606737,acm,2023
440,From Gap to Synergy: Enhancing Contextual Understanding through Human-Machine Collaboration in Personalized Systems,"@inproceedings{10.1145/3586183.3606741,
author = {Chen, Weihao and Yu, Chun and Wang, Huadong and Wang, Zheng and Yang, Lichen and Wang, Yukun and Shi, Weinan and Shi, Yuanchun},
title = {From Gap to Synergy: Enhancing Contextual Understanding through Human-Machine Collaboration in Personalized Systems},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606741},
doi = {10.1145/3586183.3606741},
abstract = {This paper presents LangAware, a collaborative approach for constructing personalized context for context-aware applications. The need for personalization arises due to significant variations in context between individuals based on scenarios, devices, and preferences. However, there is often a notable gap between humans and machines in the understanding of how contexts are constructed, as observed in trigger-action programming studies such as IFTTT. LangAware enables end-users to participate in establishing contextual rules in-situ using natural language. The system leverages large language models (LLMs) to semantically connect low-level sensor detectors to high-level contexts and provide understandable natural language feedback for effective user involvement. We conducted a user study with 16 participants in real-life settings, which revealed an average success rate of 87.50% for defining contextual rules in a variety of 12 campus scenarios, typically accomplished within just two modifications. Furthermore, users reported a better understanding of the machine’s capabilities by interacting with LangAware.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {110},
numpages = {15},
keywords = {Context-Aware Systems, End User Context Construction, Large Language Models, Personalization},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606741,10.1145/3586183.3606741,acm,2023
441,Statslator: Interactive Translation of NHST and Estimation Statistics Reporting Styles in Scientific Documents,"@inproceedings{10.1145/3586183.3606762,
author = {Masson, Damien and Malacria, Sylvain and Casiez, G\'{e}ry and Vogel, Daniel},
title = {Statslator: Interactive Translation of NHST and Estimation Statistics Reporting Styles in Scientific Documents},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606762},
doi = {10.1145/3586183.3606762},
abstract = {Inferential statistics are typically reported using p-values (NHST) or confidence intervals on effect sizes (estimation). This is done using a range of styles, but some readers have preferences about how statistics should be presented and others have limited familiarity with alternatives. We propose a system to interactively translate statistical reporting styles in existing documents, allowing readers to switch between interval estimates, p-values, and standardized effect sizes, all using textual and graphical reports that are dynamic and user customizable. Forty years of CHI papers are examined. Using only the information reported in scientific documents, equations are derived and validated on simulated datasets to show that conversions between p-values and confidence intervals are accurate. The system helps readers interpret statistics in a familiar style, compare reports that use different styles, and even validate the correctness of reports. Code and data: https://osf.io/x4ue7},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {91},
numpages = {14},
keywords = {estimation, explorable explanation, interactive system, nhst, reading interface, statistics, transparent statistics},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606762,10.1145/3586183.3606762,acm,2023
442,Generative Agents: Interactive Simulacra of Human Behavior,"@inproceedings{10.1145/3586183.3606763,
author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
title = {Generative Agents: Interactive Simulacra of Human Behavior},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606763},
doi = {10.1145/3586183.3606763},
abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {2},
numpages = {22},
keywords = {Human-AI interaction, agents, generative AI, large language models},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606763,10.1145/3586183.3606763,acm,2023
443,VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping,"@inproceedings{10.1145/3586183.3606800,
author = {Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun},
title = {VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606800},
doi = {10.1145/3586183.3606800},
abstract = {In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confirmed the usability and effectiveness of VISAR in facilitating the argumentative writing planning process.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {5},
numpages = {30},
keywords = {creativity support, human-AI collaboration, writing support},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606800,10.1145/3586183.3606800,acm,2023
444,Odyssey: An Interactive Workbench for Expert-Driven Floating-Point Expression Rewriting,"@inproceedings{10.1145/3586183.3606819,
author = {Misback, Edward and Chan, Caleb C. and Saiki, Brett and Jun, Eunice and Tatlock, Zachary and Panchekha, Pavel},
title = {Odyssey: An Interactive Workbench for Expert-Driven Floating-Point Expression Rewriting},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606819},
doi = {10.1145/3586183.3606819},
abstract = {In recent years, researchers have proposed a number of automated tools to identify and improve floating-point rounding error in mathematical expressions. However, users struggle to effectively apply these tools. In this paper, we work with novices, experts, and tool developers to investigate user needs during the expression rewriting process. We find that users follow an iterative design process. They want to compare expressions on multiple input ranges, integrate and guide various rewriting tools, and understand where errors come from. We organize this investigation’s results into a three-stage workflow and implement that workflow in a new, extensible workbench dubbed Odyssey. Odyssey enables users to: (1) diagnose problems in an expression, (2) generate solutions automatically or by hand, and (3) tune their results. Odyssey tracks a working set of expressions and turns a state-of-the-art automated tool “inside out,” giving the user access to internal heuristics, algorithms, and functionality. In a user study, Odyssey enabled five expert numerical analysts to solve challenging rewriting problems where state-of-the-art automated tools fail. In particular, the experts unanimously praised Odyssey’s novel support for interactive range modification and local error visualization.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {77},
numpages = {15},
keywords = {Debugging, Developer Tools, Dynamic Analysis, Expert Programming, Floating Point, Term Rewriting},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606819,10.1145/3586183.3606819,acm,2023
445,Augmented Math: Authoring AR-Based Explorable Explanations by Augmenting Static Math Textbooks,"@inproceedings{10.1145/3586183.3606827,
author = {Chulpongsatorn, Neil and Lunding, Mille Skovhus and Soni, Nishan and Suzuki, Ryo},
title = {Augmented Math: Authoring AR-Based Explorable Explanations by Augmenting Static Math Textbooks},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606827},
doi = {10.1145/3586183.3606827},
abstract = {We introduce Augmented Math, a machine learning-based approach to authoring AR explorable explanations by augmenting static math textbooks without programming. To augment a static document, our system first extracts mathematical formulas and figures from a given document using optical character recognition (OCR) and computer vision. By binding and manipulating these extracted contents, the user can see the interactive animation overlaid onto the document through mobile AR interfaces. This empowers non-technical users, such as teachers or students, to transform existing math textbooks and handouts into on-demand and personalized explorable explanations. To design our system, we first analyzed existing explorable math explanations to identify common design strategies. Based on the findings, we developed a set of augmentation techniques that can be automatically generated based on the extracted content, which are 1) dynamic values, 2) interactive figures, 3) relationship highlights, 4) concrete examples, and 5) step-by-step hints. To evaluate our system, we conduct two user studies: preliminary user testing and expert interviews. The study results confirm that our system allows more engaging experiences for learning math concepts.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {92},
numpages = {16},
keywords = {Augmented Reality, Augmented Textbook, Authoring Interfaces, Explorable Explanations, Interactive Paper},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606827,10.1145/3586183.3606827,acm,2023
446,"Cells, Generators, and Lenses: Design Framework for Object-Oriented Interaction with Large Language Models","@inproceedings{10.1145/3586183.3606833,
author = {Kim, Tae Soo and Lee, Yoonjoo and Chang, Minsuk and Kim, Juho},
title = {Cells, Generators, and Lenses: Design Framework for Object-Oriented Interaction with Large Language Models},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606833},
doi = {10.1145/3586183.3606833},
abstract = {Large Language Models (LLMs) have become the backbone of numerous writing interfaces with the goal of supporting end-users across diverse writing tasks. While LLMs reduce the effort of manual writing, end-users may need to experiment and iterate with various generation configurations (e.g., inputs and model parameters) until results meet their goals. However, these interfaces are not designed for experimentation and iteration, and can restrict how end-users track, compare, and combine configurations. In this work, we present “cells, generators, and lenses”, a framework to designing interfaces that support interactive objects that embody configuration components (i.e., input, model, output). Interface designers can apply our framework to produce interfaces that enable end-users to create variations of these objects, combine and recombine them into new configurations, and compare them in parallel to efficiently iterate and experiment with LLMs. To showcase how our framework generalizes to diverse writing tasks, we redesigned three different interfaces—story writing, copywriting, and email composing—and, to demonstrate its effectiveness in supporting end-users, we conducted a comparative study (N=18) where participants used our interactive objects to generate and experiment more. Finally, we investigate the usability of the framework through a workshop with designers (N=3) where we observed that our framework served as both bootstrapping and inspiration in the design process.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {4},
numpages = {18},
keywords = {Generative Models, Large Language Models, Reification, Writing-Support Tool},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

",https://doi.org/10.1145/3586183.3606833,10.1145/3586183.3606833,acm,2023
447,Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?," @inproceedings{Denny_2023, series={ITiCSE 2023}, title={Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?}, url={http://dx.doi.org/10.1145/3587102.3588773}, DOI={10.1145/3587102.3588773}, booktitle={Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1}, publisher={ACM}, author={Denny, Paul and Becker, Brett A. and Leinonen, Juho and Prather, James}, year={2023}, month=jun, collection={ITiCSE 2023} }
",http://dx.doi.org/10.1145/3587102.3588773,10.1145/3587102.3588773,web_of_science,2023
448,"Comparing Code Explanations Created by Students and Large Language
  Models"," @inproceedings{Leinonen_2023, series={ITiCSE 2023}, title={Comparing Code Explanations Created by Students and Large Language Models}, url={http://dx.doi.org/10.1145/3587102.3588785}, DOI={10.1145/3587102.3588785}, booktitle={Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1}, publisher={ACM}, author={Leinonen, Juho and Denny, Paul and MacNeil, Stephen and Sarsa, Sami and Bernstein, Seth and Kim, Joanne and Tran, Andrew and Hellas, Arto}, year={2023}, month=jun, collection={ITiCSE 2023} }
",http://arxiv.org/pdf/2304.03938v1.pdf,10.1145/3587102.3588785,"arxiv, acm, web_of_science, scopus",2023
449,Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations,"@inproceedings{10.1145/3587102.3588805,
author = {Reeves, Brent and Sarsa, Sami and Prather, James and Denny, Paul and Becker, Brett A. and Hellas, Arto and Kimmel, Bailey and Powell, Garrett and Leinonen, Juho},
title = {Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588805},
doi = {10.1145/3587102.3588805},
abstract = {The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {299–305},
numpages = {7},
keywords = {CS1, GPT-3, GitHub, ML, academic integrity, ai, artificial intelligence, chatgpt, code generation, code writing, codex, computer programming, copilot, deep learning, generative ai, introductory programming, large language models, machine learning, natural language processing, neural networks, novice programming, openAI},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

",https://doi.org/10.1145/3587102.3588805,10.1145/3587102.3588805,"acm, scopus",2023
450,GPT-3 vs Object Oriented Programming Assignments: An Experience Report,"@inproceedings{10.1145/3587102.3588814,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {GPT-3 vs Object Oriented Programming Assignments: An Experience Report},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588814},
doi = {10.1145/3587102.3588814},
abstract = {Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages.In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {61–67},
numpages = {7},
keywords = {GPT-3, large language models, object oriented programming, programming assignments, teaching},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

",https://doi.org/10.1145/3587102.3588814,10.1145/3587102.3588814,"acm, scopus",2023
451,Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments,"@inproceedings{10.1145/3587102.3588852,
author = {Balse, Rishabh and Valaboju, Bharath and Singhal, Shreya and Warriem, Jayakrishnan Madathil and Prasad, Prajish},
title = {Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588852},
doi = {10.1145/3587102.3588852},
abstract = {Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course.We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {292–298},
numpages = {7},
keywords = {GPT-3, evaluation, feedback, large language models (LLM), python programming},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

",https://doi.org/10.1145/3587102.3588852,10.1145/3587102.3588852,"acm, web_of_science, scopus",2023
452,Checking Conformance to a Subset of the Python Language,"@article{2-s2.0-85166308355,
  title={Checking Conformance to a Subset of the Python Language},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85166308355&origin=inward,10.1145/3587103.3594155,scopus,2023
453,Classifying Course Discussion Board Questions using LLMs," @inproceedings{Zhang_2023, series={ITiCSE 2023}, title={Classifying Course Discussion Board Questions using LLMs}, url={http://dx.doi.org/10.1145/3587103.3594202}, DOI={10.1145/3587103.3594202}, booktitle={Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2}, publisher={ACM}, author={Zhang, Paul and Jaipersaud, Brandon and Ba, Jimmy and Petersen, Andrew and Zhang, Lisa and Zhang, Michael R.}, year={2023}, month=jun, collection={ITiCSE 2023} }
",http://dx.doi.org/10.1145/3587103.3594202,10.1145/3587103.3594202,web_of_science,2023
454,Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education An ITiCSE Working Group Conducted by Humans," @inproceedings{Prather_2023, series={ITiCSE 2023}, title={Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans}, url={http://dx.doi.org/10.1145/3587103.3594206}, DOI={10.1145/3587103.3594206}, booktitle={Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2}, publisher={ACM}, author={Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Caspersen, Michael E. and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir}, year={2023}, month=jun, collection={ITiCSE 2023} }
",http://dx.doi.org/10.1145/3587103.3594206,10.1145/3587103.3594206,"web_of_science, scopus",2023
455,Low-Code Programming Models,"@article{10.1145/3587691,
author = {Hirzel, Martin},
title = {Low-Code Programming Models},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/3587691},
doi = {10.1145/3587691},
abstract = {Low-code has the potential to empower more people to automate tasks by creating computer programs.},
journal = {Commun. ACM},
month = {sep},
pages = {76–85},
numpages = {10}
}

",https://doi.org/10.1145/3587691,10.1145/3587691,acm,2023
456,Harnessing Large Language Models for Text-Rich Sequential Recommendation,"@inproceedings{10.1145/3589334.3645358,
author = {Zheng, Zhi and Chao, WenShuo and Qiu, Zhaopeng and Zhu, Hengshu and Xiong, Hui},
title = {Harnessing Large Language Models for Text-Rich Sequential Recommendation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645358},
doi = {10.1145/3589334.3645358},
abstract = {Recent advances in Large Language Models (LLMs) have been changing the paradigm of Recommender Systems (RS). However, when items in the recommendation scenarios contain rich textual information, such as product descriptions in online shopping or news headlines on social media, LLMs require longer texts to comprehensively depict the historical user behavior sequence. This poses significant challenges to LLM-based recommenders, such as over-length limitations, extensive time and space overheads, and suboptimal model performance. To this end, in this paper, we design a novel framework for harnessing Large Language Models for Text-Rich Sequential Recommendation (LLM-TRSR). Specifically, we first propose to segment the user historical behaviors and subsequently employ an LLM-based summarizer for summarizing these user behavior blocks. Particularly, drawing inspiration from the successful application of Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) models in user modeling, we introduce two unique summarization techniques in this paper, respectively hierarchical summarization and recurrent summarization. Then, we construct a prompt text encompassing the user preference summary, recent user interactions, and candidate item information into an LLM-based recommender, which is subsequently fine-tuned using Supervised Fine-Tuning (SFT) techniques to yield our final recommendation model. We also use Low-Rank Adaptation (LoRA) for Parameter-Efficient Fine-Tuning (PEFT). We conduct experiments on two public datasets, and the results clearly demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the ACM on Web Conference 2024},
pages = {3207–3216},
numpages = {10},
keywords = {large language model, recommender system, sequential recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

",https://doi.org/10.1145/3589334.3645358,10.1145/3589334.3645358,acm,2024
457,Labor Space: A Unifying Representation of the Labor Market via Large Language Models,"@inproceedings{10.1145/3589334.3645464,
author = {Kim, Seongwoon and Ahn, Yong-Yeol and Park, Jaehyuk},
title = {Labor Space: A Unifying Representation of the Labor Market via Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645464},
doi = {10.1145/3589334.3645464},
abstract = {The labor market is a complex ecosystem comprising diverse, interconnected entities, such as industries, occupations, skills, and firms. Due to the lack of a systematic method to map these heterogeneous entities together, each entity has been analyzed in isolation or only through pairwise relationships, inhibiting comprehensive understanding of the whole ecosystem. Here, we introduce Labor Space, a vector-space embedding of heterogeneous labor market entities, derived through applying a large language model with fine-tuning. Labor Space exposes the complex relational fabric of various labor market constituents, facilitating coherent integrative analysis of industries, occupations, skills, and firms, while retaining type-specific clustering. We demonstrate its unprecedented analytical capacities, including positioning heterogeneous entities on an economic axes, such as 'Manufacturing-Healthcare and Social Assistance'. Furthermore, by allowing vector arithmetic of these entities, Labor Space enables the exploration of complex inter-unit relations, and subsequently the estimation of the ramifications of economic shocks on individual units and their ripple effect across the labor market. We posit that Labor Space provides policymakers and business leaders with a comprehensive unifying framework for labor market analysis and simulation, fostering more nuanced and effective strategic decision-making.},
booktitle = {Proceedings of the ACM on Web Conference 2024},
pages = {2441–2451},
numpages = {11},
keywords = {firm, industry, job, labor market, large language model, skill, word embedding},
location = {Singapore, Singapore},
series = {WWW '24}
}

",https://doi.org/10.1145/3589334.3645464,10.1145/3589334.3645464,acm,2024
458,GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks,"@inproceedings{10.1145/3589334.3645682,
author = {Zhang, Mengmei and Sun, Mingwei and Wang, Peng and Fan, Shen and Mo, Yanhu and Xu, Xiaoxiao and Liu, Hong and Yang, Cheng and Shi, Chuan},
title = {GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645682},
doi = {10.1145/3589334.3645682},
abstract = {Large language models (LLMs) like ChatGPT, exhibit powerful zero-shot and instruction-following capabilities, have catalyzed a revolutionary transformation across diverse fields, especially for open-ended tasks. While the idea is less explored in the graph domain, despite the availability of numerous powerful graph models (GMs), they are restricted to tasks in a pre-defined form. Although several methods applying LLMs to graphs have been proposed, they fail to simultaneously handle the pre-defined and open-ended tasks, with LLM as a node feature enhancer or as a standalone predictor. To break this dilemma, we propose to bridge the pretrained GM and LLM by a Translator, named GraphTranslator, aiming to leverage GM to handle the pre-defined tasks effectively and utilize the extended interface of LLMs to offer various open-ended tasks for GM. To train such Translator, we propose a Producer capable of constructing the graph-text alignment data along node information, neighbor information and model information. By translating node representation into tokens, GraphTranslator empowers an LLM to make predictions based on language instructions, providing a unified perspective for both pre-defined and open-ended tasks. Extensive results demonstrate the effectiveness of our proposed GraphTranslator on zero-shot node classification. The graph question answering experiments reveal our GraphTranslator potential across a broad spectrum of open-ended tasks through language instructions. Our code is available at: https://github.com/alibaba/GraphTranslator},
booktitle = {Proceedings of the ACM on Web Conference 2024},
pages = {1003–1014},
numpages = {12},
keywords = {graph neural network, large language model},
location = {Singapore, Singapore},
series = {WWW '24}
}

",https://doi.org/10.1145/3589334.3645682,10.1145/3589334.3645682,acm,2024
459,How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation,"@inproceedings{10.1145/3589335.3651955,
author = {Zhu, Lixi and Huang, Xiaowen and Sang, Jitao},
title = {How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651955},
doi = {10.1145/3589335.3651955},
abstract = {Conversational Recommender System (CRS) interacts with users through natural language to understand their preferences and provide personalized recommendations in real-time. CRS has demonstrated significant potential, prompting researchers to address the development of more realistic and reliable user simulators as a key focus. Recently, the capabilities of Large Language Models (LLMs) have attracted a lot of attention in various fields. Simultaneously, efforts are underway to construct user simulators based on LLMs. While these works showcase innovation, they also come with certain limitations that require attention. In this work, we aim to analyze the limitations of using LLMs in constructing user simulators for CRS, to guide future research. To achieve this goal, we conduct analytical validation on the notable work, iEvaLM. Through multiple experiments on two widely-used datasets in the field of conversational recommendation, we highlight several issues with the current evaluation methods for user simulators based on LLMs: (1) Data leakage, which occurs in conversational history and the user simulator's replies, results in inflated evaluation results. (2) The success of CRS recommendations depends more on the availability and quality of conversational history than on the responses from user simulators. (3) Controlling the output of the user simulator through a single prompt template proves challenging. To overcome these limitations, we propose SimpleUserSim, employing a straightforward strategy to guide the topic toward the target items. Our study validates the ability of CRS models to utilize the interaction information, significantly improving the recommendation results.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2024},
pages = {1726–1732},
numpages = {7},
keywords = {conversational recommendation system, large language model, user simulator},
location = {Singapore, Singapore},
series = {WWW '24}
}

",https://doi.org/10.1145/3589335.3651955,10.1145/3589335.3651955,acm,2024
460,Prompting Is Programming: A Query Language for Large Language Models,"@article{10.1145/3591300,
author = {Beurer-Kellner, Luca and Fischer, Marc and Vechev, Martin},
title = {Prompting Is Programming: A Query Language for Large Language Models},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591300},
doi = {10.1145/3591300},
abstract = {Large language models have demonstrated outstanding performance on a wide range of tasks such as question answering and code generation.  
On a high level, given an input, a language model can be used to automatically complete the sequence in a statistically-likely way. Based on this, users prompt these models with language instructions or examples, to implement a variety of downstream tasks. Advanced prompting methods can even imply interaction between the language model, a user, and external tools such as calculators. However, to obtain state-of-the-art performance or adapt language models for specific tasks, complex task- and model-specific programs have to be implemented, which may still require ad-hoc interaction.  

Based on this, we present the novel idea of Language Model Programming (LMP). LMP generalizes language model prompting from pure text prompts to an intuitive combination of text prompting and scripting. Additionally, LMP allows constraints to be specified over the language model output. This enables easy adaption to many tasks while abstracting language model internals and providing high-level semantics.  

To enable LMP, we implement LMQL (short for Language Model Query Language), which leverages the constraints and control flow from an LMP prompt to generate an efficient inference procedure that minimizes the number of expensive calls to the underlying language model.  

We show that LMQL can capture a wide range of state-of-the-art prompting methods in an intuitive way, especially facilitating interactive flows that are challenging to implement with existing high-level APIs. Our evaluation shows that we retain or increase the accuracy on several downstream tasks, while also significantly reducing the required amount of computation or cost in the case of pay-to-use APIs (26-85% cost savings).},
journal = {Proc. ACM Program. Lang.},
month = {jun},
articleno = {186},
numpages = {24},
keywords = {language model programming, prompt programming}
}

",https://doi.org/10.1145/3591300,10.1145/3591300,acm,2023
461,Capturing Humans’ Mental Models of AI: An Item Response Theory Approach,"@inproceedings{10.1145/3593013.3594111,
author = {Kelly, Markelle and Kumar, Aakriti and Smyth, Padhraic and Steyvers, Mark},
title = {Capturing Humans’ Mental Models of AI: An Item Response Theory Approach},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594111},
doi = {10.1145/3593013.3594111},
abstract = {Improving our understanding of how humans perceive AI teammates is an important foundation for our general understanding of human-AI teams. Extending relevant work from cognitive science, we propose a framework based on item response theory for modeling these perceptions. We apply this framework to real-world experiments, in which each participant works alongside another person or an AI agent in a question-answering setting, repeatedly assessing their teammate’s performance. Using this experimental data, we demonstrate the use of our framework for testing research questions about people’s perceptions of both AI agents and other people. We contrast mental models of AI teammates with those of human teammates as we characterize the dimensionality of these mental models, their development over time, and the influence of the participants’ own self-perception. Our results indicate that people expect AI agents’ performance to be significantly better on average than the performance of other humans, with less variation across different types of problems. We conclude with a discussion of the implications of these findings for human-AI interaction.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1723–1734},
numpages = {12},
keywords = {human-AI interaction, mental models, theory of mind},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

",https://doi.org/10.1145/3593013.3594111,10.1145/3593013.3594111,acm,2023
462,Evaluating a Large Language Model on Searching for GUI Layouts,"@article{10.1145/3593230,
author = {Brie, Paul and Burny, Nicolas and Slu\""{y}ters, Arthur and Vanderdonckt, Jean},
title = {Evaluating a Large Language Model on Searching for GUI Layouts},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593230},
doi = {10.1145/3593230},
abstract = {The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {jun},
articleno = {178},
numpages = {37},
keywords = {web pages, large language model, gui layout, gui design, generative pre-training}
}

",https://doi.org/10.1145/3593230,10.1145/3593230,acm,2023
463,AI-Generated Code Not Considered Harmful,"@inproceedings{10.1145/3593342.3593349,
author = {Kendon, Tyson and Wu, Leanne and Aycock, John},
title = {AI-Generated Code Not Considered Harmful},
year = {2023},
isbn = {9798400707896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593342.3593349},
doi = {10.1145/3593342.3593349},
abstract = {Recent developments in AI-generated code are merely the latest in a series of challenges to traditional computer science education. AI code generators, along with the plethora of available code on the Internet and sites that facilitate contract cheating, are a striking contrast to the heroic notion of programmers toiling away to create artisanal code from whole cloth. We need not interpret this to mean that more, potentially automated, policing of student assignments is necessary: automated policing of student work is already fraught with complications and ethical concerns. We argue that instructors should instead reconsider assessment design in their pedagogy in light of recent developments, with a focus on how students build knowledge, practice skills, and develop processes. How can these new tools support students and the way they learn, and support the way that computer scientists will work in the years to come? This is an opportunity to revisit how computer science is taught, how it is assessed, how we think about and present academic integrity, and the role of the computer scientist in general.},
booktitle = {Proceedings of the 25th Western Canadian Conference on Computing Education},
articleno = {3},
numpages = {7},
keywords = {AI-generated code, academic integrity, assessments, contract cheating, copy-paste, tool-generated code},
location = {Vancouver, BC, Canada},
series = {WCCCE '23}
}

",https://doi.org/10.1145/3593342.3593349,10.1145/3593342.3593349,acm,2023
464,Experiences with Remote Examination Formats in Light of GPT-4,"@inproceedings{10.1145/3593663.3593695,
author = {Dobslaw, Felix and Bergh, Peter},
title = {Experiences with Remote Examination Formats in Light of GPT-4},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593695},
doi = {10.1145/3593663.3593695},
abstract = {Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {220–225},
numpages = {6},
keywords = {Software Engineering Education, Oral Examinations, Examination Formats, ChatGPT},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

",https://doi.org/10.1145/3593663.3593695,10.1145/3593663.3593695,"acm, web_of_science, scopus",2023
465,Preparing Future Designers for Human-AI Collaboration in Persona Creation,"@inproceedings{10.1145/3596671.3598574,
author = {Goel, Toshali and Shaer, Orit and Delcourt, Catherine and Gu, Quan and Cooper, Angel},
title = {Preparing Future Designers for Human-AI Collaboration in Persona Creation},
year = {2023},
isbn = {9798400708077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596671.3598574},
doi = {10.1145/3596671.3598574},
abstract = {This paper presents findings from an exploratory study investigating the use of AI text-generation tools to support novice designers in persona creation. We conducted a workshop with 22 undergraduate students enrolled in an introductory human-computer interaction course, who were instructed to use GPT-3 in the creation of personas. These novice designers were able to use GPT-3 to iterate to produce satisfactory personas, particularly when providing detailed prompts. Our findings suggest that personas created with GPT-3 assistance were mostly comparable to those created manually but rated lower on some evaluation dimensions. The study also reveals merits and concerns of using GPT-3 for persona creation. Based on our findings, we propose recommendations for novice designers on how to use text-generative AIs to create personas effectively and responsibly.},
booktitle = {Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {4},
numpages = {14},
keywords = {education, human-AI collaboration, large language models, natural-language generation, novice designers, personas},
location = {Oldenburg, Germany},
series = {CHIWORK '23}
}

",https://doi.org/10.1145/3596671.3598574,10.1145/3596671.3598574,acm,2023
466,Designing with AI,"@article{10.1145/3596926,
author = {Chilton, Lydia},
title = {Designing with AI},
year = {2023},
issue_date = {Summer 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {1528-4972},
url = {https://doi.org/10.1145/3596926},
doi = {10.1145/3596926},
abstract = {How I came to love design and used AI to alleviate the most frustrating parts of the process.},
journal = {XRDS},
month = {jun},
pages = {20–25},
numpages = {6}
}

",https://doi.org/10.1145/3596926,10.1145/3596926,acm,2023
467,How to Support ML End-User Programmers through a Conversational Agent,"@inproceedings{10.1145/3597503.3608130,
author = {Arteaga Garcia, Emily Judith and Nicolaci Pimentel, Jo\~{a}o Felipe and Feng, Zixuan and Gerosa, Marco and Steinmacher, Igor and Sarma, Anita},
title = {How to Support ML End-User Programmers through a Conversational Agent},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3608130},
doi = {10.1145/3597503.3608130},
abstract = {Machine Learning (ML) is increasingly gaining significance for enduser programmer (EUP) applications. However, machine learning end-user programmers (ML-EUPs) without the right background face a daunting learning curve and a heightened risk of mistakes and flaws in their models. In this work, we designed a conversational agent named ""Newton"" as an expert to support ML-EUPs. Newton's design was shaped by a comprehensive review of existing literature, from which we identified six primary challenges faced by ML-EUPs and five strategies to assist them. To evaluate the efficacy of Newton's design, we conducted a Wizard of Oz within-subjects study with 12 ML-EUPs. Our findings indicate that Newton effectively assisted ML-EUPs, addressing the challenges highlighted in the literature. We also proposed six design guidelines for future conversational agents, which can help other EUP applications and software engineering activities.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {53},
numpages = {12},
keywords = {end-user programming, conversational agent, wizard of Oz},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

",https://doi.org/10.1145/3597503.3608130,10.1145/3597503.3608130,acm,2024
468,On the Helpfulness of Answering Developer Questions on Discord with Similar Conversations and Posts from the Past,"@inproceedings{10.1145/3597503.3623341,
author = {Lill, Alexander and Meyer, Andr\'{e} N. and Fritz, Thomas},
title = {On the Helpfulness of Answering Developer Questions on Discord with Similar Conversations and Posts from the Past},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623341},
doi = {10.1145/3597503.3623341},
abstract = {A big part of software developers' time is spent finding answers to their coding-task-related questions. To answer their questions, developers usually perform web searches, ask questions on Q&amp;A websites, or, more recently, in chat communities. Yet, many of these questions have frequently already been answered in previous chat conversations or other online communities. Automatically identifying and then suggesting these previous answers to the askers could, thus, save time and effort. In an empirical analysis, we first explored the frequency of repeating questions on the Discord chat platform and assessed our approach to identify them automatically. The approach was then evaluated with real-world developers in a field experiment, through which we received 142 ratings on the helpfulness of the suggestions we provided to help answer 277 questions that developers posted in four Discord communities. We further collected qualitative feedback through 53 surveys and 10 follow-up interviews. We found that the suggestions were considered helpful in 40% of the cases, that suggesting Stack Overflow posts is more often considered helpful than past Discord conversations, and that developers have difficulties describing their problems as search queries and, thus, prefer describing them as natural language questions in online communities.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {58},
numpages = {13},
keywords = {developer questions, chat community, semantic similarity},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

",https://doi.org/10.1145/3597503.3623341,10.1145/3597503.3623341,acm,2024
469,ChatGPT-Resistant Screening Instrument for Identifying Non-Programmers,"@inproceedings{10.1145/3597503.3639075,
author = {Serafini, Raphael and Otto, Clemens and Horstmann, Stefan Albert and Naiakshina, Alena},
title = {ChatGPT-Resistant Screening Instrument for Identifying Non-Programmers},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639075},
doi = {10.1145/3597503.3639075},
abstract = {To ensure the validity of software engineering and IT security studies with professional programmers, it is essential to identify participants without programming skills. Existing screening questions are efficient, cheating robust, and effectively differentiate programmers from non-programmers. However, the release of ChatGPT raises concerns about their continued effectiveness in identifying non-programmers. In a simulated attack, we showed that Chat-GPT can easily solve existing screening questions. Therefore, we designed new ChatGPT-resistant screening questions using visual concepts and code comprehension tasks. We evaluated 28 screening questions in an online study with 121 participants involving programmers and non-programmers. Our results showed that questions using visualizations of well-known programming concepts performed best in differentiating between programmers and non-programmers. Participants prompted to use ChatGPT struggled to solve the tasks. They considered ChatGPT ineffective and changed their strategy after a few screening questions. In total, we present six ChatGPT-resistant screening questions that effectively identify non-programmers. We provide recommendations on setting up a ChatGPT-resistant screening instrument that takes less than three minutes to complete by excluding 99.47% of non-programmers while including 94.83% of programmers.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {181},
numpages = {13},
keywords = {chatgpt, programmer screening, developer study, study protection},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

",https://doi.org/10.1145/3597503.3639075,10.1145/3597503.3639075,acm,2024
470,A User-centered Security Evaluation of Copilot,"@inproceedings{10.1145/3597503.3639154,
author = {Asare, Owura and Nagappan, Meiyappan and Asokan, N.},
title = {A User-centered Security Evaluation of Copilot},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639154},
doi = {10.1145/3597503.3639154},
abstract = {Code generation tools driven by artificial intelligence have recently become more popular due to advancements in deep learning and natural language processing that have increased their capabilities. The proliferation of these tools may be a double-edged sword because while they can increase developer productivity by making it easier to write code, research has shown that they can also generate insecure code. In this paper, we perform a user-centered evaluation GitHub's Copilot to better understand its strengths and weaknesses with respect to code security. We conduct a user study where participants solve programming problems (with and without Copilot assistance) that have potentially vulnerable solutions. The main goal of the user study is to determine how the use of Copilot affects participants' security performance. In our set of participants (n=25), we find that access to Copilot accompanies a more secure solution when tackling harder problems. For the easier problem, we observe no effect of Copilot access on the security of solutions. We also observe no disproportionate impact of Copilot use on particular kinds of vulnerabilities. Our results indicate that there are potential security benefits to using Copilot, but more research is warranted on the effects of the use of code generation tools on technically complex problems with security requirements.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {158},
numpages = {11},
keywords = {user study, code generation, copilot, security, software engineering},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

",https://doi.org/10.1145/3597503.3639154,10.1145/3597503.3639154,acm,2024
471,Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions,"@inproceedings{10.1145/3597503.3639180,
author = {Liu, Zhe and Chen, Chunyang and Wang, Junjie and Chen, Mengzhuo and Wu, Boyu and Che, Xing and Wang, Dandan and Wang, Qing},
title = {Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639180},
doi = {10.1145/3597503.3639180},
abstract = {Automated Graphical User Interface (GUI) testing plays a crucial role in ensuring app quality, especially as mobile applications have become an integral part of our daily lives. Despite the growing popularity of learning-based techniques in automated GUI testing due to their ability to generate human-like interactions, they still suffer from several limitations, such as low testing coverage, inadequate generalization capabilities, and heavy reliance on training data. Inspired by the success of Large Language Models (LLMs) like ChatGPT in natural language understanding and question answering, we formulate the mobile GUI testing problem as a Q&amp;A task. We propose GPTDroid, asking LLM to chat with the mobile apps by passing the GUI page information to LLM to elicit testing scripts, and executing them to keep passing the app feedback to LLM, iterating the whole process. Within this framework, we have also introduced a functionality-aware memory prompting mechanism that equips the LLM with the ability to retain testing knowledge of the whole process and conduct long-term, functionality-based reasoning to guide exploration. We evaluate it on 93 apps from Google Play and demonstrate that it outperforms the best baseline by 32% in activity coverage, and detects 31% more bugs at a faster rate. Moreover, GPTDroid identifies 53 new bugs on Google Play, of which 35 have been confirmed and fixed.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {100},
numpages = {13},
keywords = {automated GUI testing, large language model},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

",https://doi.org/10.1145/3597503.3639180,10.1145/3597503.3639180,acm,2024
472,ReFAIR: Toward a Context-Aware Recommender for Fairness Requirements Engineering,"@inproceedings{10.1145/3597503.3639185,
author = {Ferrara, Carmine and Casillo, Francesco and Gravino, Carmine and De Lucia, Andrea and Palomba, Fabio},
title = {ReFAIR: Toward a Context-Aware Recommender for Fairness Requirements Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639185},
doi = {10.1145/3597503.3639185},
abstract = {Machine learning (ML) is increasingly being used as a key component of most software systems, yet serious concerns have been raised about the fairness of ML predictions. Researchers have been proposing novel methods to support the development of fair machine learning solutions. Nonetheless, most of them can only be used in late development stages, e.g., during model training, while there is a lack of methods that may provide practitioners with early fairness analytics enabling the treatment of fairness throughout the development lifecycle. This paper proposes ReFair, a novel context-aware requirements engineering framework that allows to classify sensitive features from User Stories. By exploiting natural language processing and word embedding techniques, our framework first identifies both the use case domain and the machine learning task to be performed in the system being developed; afterward, it recommends which are the context-specific sensitive features to be considered during the implementation. We assess the capabilities of ReFair by experimenting it against a synthetic dataset---which we built as part of our research---composed of 12,401 User Stories related to 34 application domains. Our findings showcase the high accuracy of ReFair, other than highlighting its current limitations.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {213},
numpages = {12},
keywords = {software fairness, machine learning, requirements engineering},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

",https://doi.org/10.1145/3597503.3639185,10.1145/3597503.3639185,acm,2024
473,Using an LLM to Help With Code Understanding,"@inproceedings{10.1145/3597503.3639187,
author = {Nam, Daye and Macvean, Andrew and Hellendoorn, Vincent and Vasilescu, Bogdan and Myers, Brad},
title = {Using an LLM to Help With Code Understanding},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639187},
doi = {10.1145/3597503.3639187},
abstract = {Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domain-specific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {97},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

",https://doi.org/10.1145/3597503.3639187,10.1145/3597503.3639187,acm,2024
474,Who Judges the Judge: An Empirical Study on Online Judge Tests,"@inproceedings{10.1145/3597926.3598060,
author = {Liu, Kaibo and Han, Yudong and Zhang, Jie M. and Chen, Zhenpeng and Sarro, Federica and Harman, Mark and Huang, Gang and Ma, Yun},
title = {Who Judges the Judge: An Empirical Study on Online Judge Tests},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598060},
doi = {10.1145/3597926.3598060},
abstract = {Online Judge platforms play a pivotal role in education, competitive programming, recruitment, career training, and large language model training. They rely on predefined test suites to judge the correctness of submitted solutions. It is therefore important that the solution judgement is reliable and free from potentially misleading false positives (i.e., incorrect solutions that are judged as correct). In this paper, we conduct an empirical study of 939 coding problems with 541,552 solutions, all of which are judged to be correct according to the test suites used by the platform, finding that 43.4% of the problems include false positive solutions (3,440 bugs are revealed in total). We also find that test suites are, nevertheless, of high quality according to widely-studied test effectiveness measurements: 88.2% of false positives have perfect (100%) line coverage, 78.9% have perfect branch coverage, and 32.5% have a perfect mutation score. Our findings indicate that more work is required to weed out false positive solutions and to further improve test suite effectiveness. We have released the detected false positive solutions and the generated test inputs to facilitate future research.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {334–346},
numpages = {13},
keywords = {Online judge platform, software testing, test assessment},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

",https://doi.org/10.1145/3597926.3598060,10.1145/3597926.3598060,"acm, web_of_science, scopus",2023
475,Analyzing the Use of Large Language Models for Content Moderation with ChatGPT Examples,"@inproceedings{10.1145/3599696.3612895,
author = {Franco, Mirko and Gaggi, Ombretta and Palazzi, Claudio E.},
title = {Analyzing the Use of Large Language Models for Content Moderation with ChatGPT Examples},
year = {2023},
isbn = {9798400702259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3599696.3612895},
doi = {10.1145/3599696.3612895},
abstract = {Content moderation systems are crucial in Online Social Networks (OSNs). Indeed, their role is to keep platforms and their users safe from malicious activities. However, there is an emerging consensus that such systems are unfair to fragile users and minorities. Furthermore, content moderation systems are difficult to personalize and lack effective communication between users and platforms. In this context, we propose an enhancement of the current framework of content moderation, integrating Large Language Models (LLMs) in the enforcing pipeline.},
booktitle = {Proceedings of the 3rd International Workshop on Open Challenges in Online Social Networks},
pages = {1–8},
numpages = {8},
keywords = {content moderation, harmful content, large language models},
location = {Rome, Italy},
series = {OASIS '23}
}

",https://doi.org/10.1145/3599696.3612895,10.1145/3599696.3612895,acm,2023
476,ChatGPT-Based Debate Game Application Utilizing Prompt Engineering,"@inproceedings{10.1145/3599957.3606244,
author = {Lee, Eun-young and il, Ngagaba Gogo Dae and An, Gi-hong and Lee, Sungchul and Lim, Kiho},
title = {ChatGPT-Based Debate Game Application Utilizing Prompt Engineering},
year = {2023},
isbn = {9798400702280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3599957.3606244},
doi = {10.1145/3599957.3606244},
abstract = {This paper1 focuses on the implementation of a debate game using ChatGPT, aiming to investigate the feasibility of incorporating large language models into the educational domain through prompt engineering. The study explores strategies to elicit desired outputs from the GPT model by employing the prompt engineering methodology, as provided by Microsoft.Specifically, the game implementation involves the customization of ChatGPT's responses to facilitate a natural progression of debates, varying levels of difficulty, and an evaluation system for assessing the quality of discourse. By leveraging the prompt engineering methodology, we demonstrate that providing specific instructions or case-based prompts improves the accuracy and relevance of ChatGPT's answers. The developed application targets teenagers, enabling them to engage in real-time debates with ChatGPT and enhance their literacy skills. Furthermore, the game fosters the development of logical reasoning, persuasive abilities, effective expression, active participation, and attentive listening while expressing personal opinions, ultimately fostering a sense of accomplishment. Moreover, through debate evaluation and personalized advice, ChatGPT is expected to recognize and address its shortcomings, thereby continuously improving its conversational capabilities.Overall, this research contributes to the understanding of how large language models can be harnessed in educational settings and underscores the potential benefits of prompt engineering techniques in optimizing the outputs of such models.},
booktitle = {Proceedings of the 2023 International Conference on Research in Adaptive and Convergent Systems},
articleno = {29},
numpages = {6},
keywords = {ChatGPT, Large Language Model, Prompt Engineering},
location = {Gdansk, Poland},
series = {RACS '23}
}

",https://doi.org/10.1145/3599957.3606244,10.1145/3599957.3606244,acm,2023
477,Evaluating Biased Attitude Associations of Language Models in an Intersectional Context,"@inproceedings{10.1145/3600211.3604666,
author = {Omrani Sabbaghi, Shiva and Wolfe, Robert and Caliskan, Aylin},
title = {Evaluating Biased Attitude Associations of Language Models in an Intersectional Context},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604666},
doi = {10.1145/3600211.3604666},
abstract = {Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model that we study is also more biased as it effectively captures bias embedded in sociocultural data. We validate the bias evaluation method by overperforming on an intrinsic valence evaluation task. The approach enables us to measure complex intersectional biases as they are known to manifest in the outputs and applications of language models that perpetuate historical biases. Moreover, our approach contributes to design justice as it studies the associations of groups underrepresented in language such as transgender and homosexual individuals.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {542–553},
numpages = {12},
keywords = {AI bias, contextualized word embeddings, intersectional bias, language models, psycholinguistics},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

",https://doi.org/10.1145/3600211.3604666,10.1145/3600211.3604666,acm,2023
478,AI Art and its Impact on Artists,"@inproceedings{10.1145/3600211.3604681,
author = {Jiang, Harry H. and Brown, Lauren and Cheng, Jessica and Khan, Mehtab and Gupta, Abhishek and Workman, Deja and Hanna, Alex and Flowers, Johnathan and Gebru, Timnit},
title = {AI Art and its Impact on Artists},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604681},
doi = {10.1145/3600211.3604681},
abstract = {The last 3 years have resulted in machine learning (ML)-based image generators with the ability to output consistently higher quality images based on natural language prompts as inputs. As a result, many popular commercial “generative AI Art” products have entered the market, making generative AI an estimated $48B industry&nbsp;[125]. However, many professional artists have spoken up about the harms they have experienced due to the proliferation of large scale image generators trained on image/text pairs from the Internet. In this paper, we review some of these harms which include reputational damage, economic loss, plagiarism and copyright infringement. To guard against these issues while reaping the potential benefits of image generators, we provide recommendations such as regulation that forces organizations to disclose their training data, and tools that help artists prevent using their content as training data without their consent.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {363–374},
numpages = {12},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

",https://doi.org/10.1145/3600211.3604681,10.1145/3600211.3604681,acm,2023
479,Disambiguating Algorithmic Bias: From Neutrality to Justice,"@inproceedings{10.1145/3600211.3604695,
author = {Edenberg, Elizabeth and Wood, Alexandra},
title = {Disambiguating Algorithmic Bias: From Neutrality to Justice},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604695},
doi = {10.1145/3600211.3604695},
abstract = {As algorithms have become ubiquitous in consequential domains, societal concerns about the potential for discriminatory outcomes have prompted urgent calls to address algorithmic bias. In response, a rich literature across computer science, law, and ethics is rapidly proliferating to advance approaches to designing fair algorithms. Yet computer scientists, legal scholars, and ethicists are often not speaking the same language when using the term ‘bias.’ Debates concerning whether society can or should tackle the problem of algorithmic bias are hampered by conflations of various understandings of bias, ranging from neutral deviations from a standard to morally problematic instances of injustice due to prejudice, discrimination, and disparate treatment. This terminological confusion impedes efforts to address clear cases of discrimination. In this paper, we examine the promises and challenges of different approaches to disambiguating bias and designing for justice. While both approaches aid in understanding and addressing clear algorithmic harms, we argue that they also risk being leveraged in ways that ultimately deflect accountability from those building and deploying these systems. Applying this analysis to recent examples of generative AI, our argument highlights unseen dangers in current methods of evaluating algorithmic bias and points to ways to redirect approaches to addressing bias in generative AI at its early stages in ways that can more robustly meet the demands of justice.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {691–704},
numpages = {14},
keywords = {algorithms, bias, discrimination, fairness, generative AI, justice, large language models, law, philosophy, vision-language models},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

",https://doi.org/10.1145/3600211.3604695,10.1145/3600211.3604695,acm,2023
480,Why We Need to Know More: Exploring the State of AI Incident Documentation Practices,"@inproceedings{10.1145/3600211.3604700,
author = {Turri, Violet and Dzombak, Rachel},
title = {Why We Need to Know More: Exploring the State of AI Incident Documentation Practices},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604700},
doi = {10.1145/3600211.3604700},
abstract = {To enable the development and use of safe and equitable artificial intelligence (AI) systems, AI engineers must monitor deployed AI systems and learn from past AI incidents where failures have occurred. Around the world, public databases for cataloging AI systems and resulting harms are instrumental in promoting awareness of potential AI harms among policymakers, researchers, and the public. However, despite growing recognition of the potential of AI systems to produce harms, causes of AI systems failure remain elusive and AI incidents continue to occur. For example, incidents of AI bias are frequently reported and discussed, yet biased systems continue to be developed and deployed. This raises the question – how are we learning from documented incidents? What information do we need to analyze AI incidents and develop new AI engineering best practices? This paper examines reporting techniques from a variety of AI stakeholders and across different industries, identifies requirements towards the design of effective AI incident documentation, and proposes policy recommendations for augmenting current practice.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {576–583},
numpages = {8},
keywords = {Explainable Artificial Intelligence},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

",https://doi.org/10.1145/3600211.3604700,10.1145/3600211.3604700,acm,2023
481,What does it mean to be a responsible AI practitioner: An ontology of roles and skills,"@inproceedings{10.1145/3600211.3604702,
author = {Rismani, Shalaleh and Moon, AJung},
title = {What does it mean to be a responsible AI practitioner: An ontology of roles and skills},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604702},
doi = {10.1145/3600211.3604702},
abstract = {With the growing need to regulate AI systems across a wide variety of application domains, a new set of occupations has emerged in the industry. The so-called responsible Artificial Intelligence (AI) practitioners or AI ethicists are generally tasked with interpreting and operationalizing best practices for ethical and safe design of AI systems. Due to the nascent nature of these roles, however, it is unclear to future employers and aspiring AI ethicists what specific function these roles serve and what skills are necessary to serve the functions. Without clarity on these, we cannot train future AI ethicists with meaningful learning objectives. In this work, we examine what responsible AI practitioners do in the industry and what skills they employ on the job. We propose an ontology of existing roles alongside skills and competencies that serve each role. We created this ontology by examining the job postings for such roles over a two-year period (2020-2022) and conducting expert interviews with fourteen individuals who currently hold such a role in the industry. Our ontology contributes to business leaders looking to build responsible AI teams and provides educators with a set of competencies that an AI ethics curriculum can prioritize.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {584–595},
numpages = {12},
keywords = {Competency Framework, Education, Responsible AI Practitioner},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

",https://doi.org/10.1145/3600211.3604702,10.1145/3600211.3604702,acm,2023
482,Seven Hypertexts,"@inproceedings{10.1145/3603163.3609048,
author = {Anderson, Mark W. R. and Millard, David E.},
title = {Seven Hypertexts},
year = {2023},
isbn = {9798400702327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603163.3609048},
doi = {10.1145/3603163.3609048},
abstract = {What is Hypertext? It has been studied and explored for over 50 years but a complete definition seems ever more elusive. The term is invoked in multiple communities, and applied in radically different domains, but if we cannot reconcile the different perspectives then we will be unable to learn from our shared history, or from each other in the future. In this paper we argue that the longevity and variety of hypertext work makes a simple definition impractical. Instead we suggest different contexts in which hypertext work has been conducted, and then attempt to draw out the relationships and commonalities between them. We describe seven contexts drawn from the literature: Hypertext as a Tool for Thought, as Knowledge Representation, as Social Fabric, as Literature, as Games, as Infrastructure, and as Interface. We argue that these are connected by a common requirement for non-regularity, driven by post-structuralist philosophy, and enshrining existentialist values in our technology. It is the application of these ideas to different problems that gives rise to current Hypertext, as we see the same technical features, and engineering and creative challenges, manifest in otherwise quite different digital domains.},
booktitle = {Proceedings of the 34th ACM Conference on Hypertext and Social Media},
articleno = {42},
numpages = {15},
keywords = {PKM, blogs, games, hyperfilm, hypermedia, hypertext, hypertext literature, infrastucture, interactive fiction, interface, knowledge bases, knowledge management, knowledge representation, linkbases, metadata, narrative, social networks, stretchtext, tools for thought},
location = {Rome, Italy},
series = {HT '23}
}

",https://doi.org/10.1145/3603163.3609048,10.1145/3603163.3609048,acm,2023
483,From ChatGPT to FactGPT: A Participatory Design Study to Mitigate the Effects of Large Language Model Hallucinations on Users,"@inproceedings{10.1145/3603555.3603565,
author = {Leiser, Florian and Eckhardt, Sven and Knaeble, Merlin and Maedche, Alexander and Schwabe, Gerhard and Sunyaev, Ali},
title = {From ChatGPT to FactGPT: A Participatory Design Study to Mitigate the Effects of Large Language Model Hallucinations on Users},
year = {2023},
isbn = {9798400707711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603555.3603565},
doi = {10.1145/3603555.3603565},
abstract = {Large language models (LLMs) like ChatGPT recently gained interest across all walks of life with their human-like quality in textual responses. Despite their success in research, healthcare, or education, LLMs frequently include incorrect information, called hallucinations, in their responses. These hallucinations could influence users to trust fake news or change their general beliefs. Therefore, we investigate mitigation strategies desired by users to enable identification of LLM hallucinations. To achieve this goal, we conduct a participatory design study where everyday users design interface features which are then assessed for their feasibility by machine learning (ML) experts. We find that many of the desired features are well-perceived by ML experts but are also considered as difficult to implement. Finally, we provide a list of desired features that should serve as a basis for mitigating the effect of LLM hallucinations on users.},
booktitle = {Proceedings of Mensch Und Computer 2023},
pages = {81–90},
numpages = {10},
keywords = {Artificial Hallucinations, ChatGPT, Disney Method, Large Language Models, Participatory Design},
location = {Rapperswil, Switzerland},
series = {MuC '23}
}

",https://doi.org/10.1145/3603555.3603565,10.1145/3603555.3603565,acm,2023
484,Predictability of Post-Earnings Announcement Drift with Textual and Contextual Factors of Earnings Calls,"@inproceedings{10.1145/3604237.3626861,
author = {Chung, Andy and Tanaka-Ishii, Kumiko},
title = {Predictability of Post-Earnings Announcement Drift with Textual and Contextual Factors of Earnings Calls},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626861},
doi = {10.1145/3604237.3626861},
abstract = {Post-Earnings Announcement Drift (PEAD), a well-known anomaly in financial markets, describes the tendency of cumulative stock returns to drift in the direction of an earnings surprise for a prolonged period following an earnings announcement. Numerous studies have used a supervised learning approach to predict PEAD, using earnings, fundamental and technical factors. However, there is a lack of study on how the context of the earnings call can be used for the PEAD prediction task. This paper uses computational linguistics techniques and large language models to examine the effectiveness of incorporating textual and contextual features from earnings calls for the PEAD prediction task. Our proposed supervised model includes four categories of features: 1) textual features, 2) contextual features, 3) earnings features, and 4) fundamental and technical features. We study the proposed model using earnings from 2010/01/01 to 2022/12/31 of all point-in-time S&amp;P500 constituents in the US stock market. Our results show that contextual features provide information unexplained by earnings, fundamental and technical features, improving the average returns per trade of a hypothetical long-short portfolio against baseline solution in out-of-sample across all four different abnormal return calculations, ranging from 53 to 354 basis points and 16.9% to 108.5% improvement from baseline model, which uses only earnings, fundamental and technical features.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {401–408},
numpages = {8},
keywords = {Post-earnings announcement drift, computational linguistics, earnings call, large language models, machine learning},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

",https://doi.org/10.1145/3604237.3626861,10.1145/3604237.3626861,acm,2023
485,RecAD: Towards A Unified Library for Recommender Attack and Defense,"@inproceedings{10.1145/3604915.3609490,
author = {WANG, CHANGSHENG and Ye, Jianbai and Wang, Wenjie and Gao, Chongming and Feng, Fuli and He, Xiangnan},
title = {RecAD: Towards A Unified Library for Recommender Attack and Defense},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3609490},
doi = {10.1145/3604915.3609490},
abstract = {In recent years, recommender systems have become a ubiquitous part of our daily lives, while they suffer from a high risk of being attacked due to the growing commercial and social values. Despite significant research progress in recommender attack and defense, there is a lack of a widely-recognized benchmarking standard in the field, leading to unfair performance comparison and limited credibility of experiments. To address this, we propose RecAD, a unified library aiming at establishing an open benchmark for recommender attack and defense. RecAD takes an initial step to set up a unified benchmarking pipeline for reproducible research by integrating diverse datasets, standard source codes, hyper-parameter settings, running logs, attack knowledge, attack budget, and evaluation results. The benchmark is designed to be comprehensive and sustainable, covering both attack, defense, and evaluation tasks, enabling more researchers to easily follow and contribute to this promising field. RecAD will drive more solid and reproducible research on recommender systems attack and defense, reduce the redundant efforts of researchers, and ultimately increase the credibility and practical value of recommender attack and defense. The project is released at https://github.com/gusye1234/recad.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {234–244},
numpages = {11},
keywords = {Benchmark, Recommender Systems, Shilling Attack and Defense},
location = {Singapore, Singapore},
series = {RecSys '23}
}

",https://doi.org/10.1145/3604915.3609490,10.1145/3604915.3609490,acm,2023
486,Improving Soft Skill Extraction via Data Augmentation and Embedding Manipulation,"@inproceedings{10.1145/3605098.3636010,
author = {Ul Haq, Muhammad Uzair and Frazzetto, Paolo and Sperduti, Alessandro and Da San Martino, Giovanni},
title = {Improving Soft Skill Extraction via Data Augmentation and Embedding Manipulation},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636010},
doi = {10.1145/3605098.3636010},
abstract = {Soft skills (SS) are important for Human Resource Management when recruiting suitable candidates for a job. Nowadays, enterprises aim to automatically extract such information from documents, curriculum vitae (CVs) and job descriptions, to speed up their recruitment process. State-of-the-art Large Language Models (LLMs) have been successful in Natural Language Processing (NLP) by fine-tuning them to the domain-specific task. However, annotated data for the task is very limited and costly to obtain, since it requires domain experts. Moreover, SS consists of complex long entities which are difficult to extract given few annotated examples. As a consequence, the performance of the LLMs on soft skill detection still needs improvement before being used in a real-world context. In this paper, we introduce data augmentation based entity extraction approach which shows promising performance when the entity length is long (i.e more than three tokens). Moreover, we explore the performance of pre-trained LLMs to generate synthetic data for training. The pre-trained models are used to generate contextual augmentation of the baseline dataset. We further analyse the embeddings generated by these models in aiding the extraction process of entities. We develop an Embedding Manipulation (EM) approach to further improve the performance of baseline models. We evaluated our approach on the only publicly available dataset for soft skills (SKILLSPAN), and on three Entity Extraction datasets (GUM, WNUT-2017 and CoNLL-2003) to assess the proposed approach. Empirical evidence shows that the proposed approach allows us to get 6.52% increased F1 over the baseline model for the soft skills.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {987–996},
numpages = {10},
keywords = {skill extraction, data augmentation, human resource, embeddings, NER},
location = {Avila, Spain},
series = {SAC '24}
}

",https://doi.org/10.1145/3605098.3636010,10.1145/3605098.3636010,acm,2024
487,A Large-Scale Study of ML-Related Python Projects,"@inproceedings{10.1145/3605098.3636056,
author = {Idowu, Samuel and Sens, Yorick and Berger, Thorsten and Krueger, Jacob and Vierhauser, Michael},
title = {A Large-Scale Study of ML-Related Python Projects},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636056},
doi = {10.1145/3605098.3636056},
abstract = {The rise of machine learning (ML) for solving current and future problems increased the production of ML-enabled software systems. Unfortunately, standardized tool chains for developing, employing, and maintaining such projects are not yet mature, which can mainly be attributed to a lack of understanding of the properties of ML-enabled software. For instance, it is still unclear how to manage and evolve ML-specific assets together with other software-engineering assets. In particular, ML-specific tools and processes, such as those for managing ML experiments, are often perceived as incompatible with practitioners' software engineering tools and processes. To design new tools for developing ML-enabled software, it is crucial to understand the properties and current problems of developing these projects by eliciting empirical data from real projects, including the evolution of the different assets involved. Moreover, while studies in this direction have recently been conducted, identifying certain types of ML-enabled projects (e.g., experiments, libraries and software systems) remains a challenge for researchers. We present a large-scale study of over 31,066 ML projects found on GitHub, with an emphasis on their development stages and evolution. Our contributions include a dataset, together with empirical data providing an overview of the existing project types and analysis of the projects' properties and characteristics, especially regarding the implementation of different ML development stages and their evolution. We believe that our results support researchers, practitioners, and tool builders conduct follow-up studies and especially build novel tools for managing ML projects, ideally unified with traditional software-engineering tools.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {1272–1281},
numpages = {10},
keywords = {machine learning, ml-enabled systems, evolution, mining study, open-source projects, large-scale study, tensorflow, scikit-learn},
location = {Avila, Spain},
series = {SAC '24}
}

",https://doi.org/10.1145/3605098.3636056,10.1145/3605098.3636056,acm,2024
488,Dual-Submission Homework in Parallel Computer Architecture: An Exploratory Study in the Age of LLMs,"@inproceedings{10.1145/3605507.3610629,
author = {Gehringer, Edward F. and Wang, Jianxun George and Jilla, Sharan Kumar},
title = {Dual-Submission Homework in Parallel Computer Architecture: An Exploratory Study in the Age of LLMs},
year = {2024},
isbn = {9798400702532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605507.3610629},
doi = {10.1145/3605507.3610629},
abstract = {The traditional model of assigning textbook problems for homework is endangered by the ability of students to find answers to almost any published problem on the web. An alternative is a dual-submission approach, where students submit their work, then receive the solutions, and submit a second metacognitive reflection, explaining any errors they made. Students’ scores can depend on the quality of their second submissions alone or the combined quality of their first and second submissions. We tried this approach in a class on parallel computer architecture. We report students’ personal experience based on their questionnaires responses. In addition, we quantitatively compare students’ performance on test questions related to dual-submission homework against their performance on other questions and previous semesters’ student performance on similar questions. Students overwhelmingly preferred this approach and thought they learned more from it, but evidence about whether it improved their learning was inconclusive. We also analyze the continued viability of this approach in the era of large language models.},
booktitle = {Proceedings of the Workshop on Computer Architecture Education},
pages = {41–47},
numpages = {7},
location = {Orlando, FL, USA},
series = {WCAE '23}
}

",https://doi.org/10.1145/3605507.3610629,10.1145/3605507.3610629,acm,2024
489,Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation,"@inproceedings{10.1145/3605731.3605886,
author = {Godoy, William and Valero-Lara, Pedro and Teranishi, Keita and Balaprakash, Prasanna and Vetter, Jeffrey},
title = {Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation},
year = {2023},
isbn = {9798400708428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605731.3605886},
doi = {10.1145/3605731.3605886},
abstract = {We evaluate AI-assisted generative capabilities on fundamental numerical kernels in high-performance computing (HPC), including AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG. We test the generated kernel codes for a variety of language-supported programming models, including (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). We use the GitHub Copilot capabilities powered by the GPT-based OpenAI Codex available in Visual Studio Code as of April 2023 to generate a vast amount of implementations given simple &lt;kernel&gt; + &lt;programming model&gt; + &lt;optional hints&gt; prompt variants. To quantify and compare the results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. Results suggest that the OpenAI Codex outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general-purpose Python can benefit from adding code keywords, while Julia prompts perform acceptably well for its mature programming models (e.g., Threads and CUDA.jl). We expect for these benchmarks to provide a point of reference for each programming model’s community. Overall, understanding the convergence of large language models, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human-computer interactions.},
booktitle = {Proceedings of the 52nd International Conference on Parallel Processing Workshops},
pages = {136–144},
numpages = {9},
keywords = {GPT, GitHub Copilot, HPC, LLM, OpenAI Codex, generative AI, high-performance computing, large language models, numerical kernels, programming models},
location = {Salt Lake City, UT, USA},
series = {ICPP Workshops '23}
}

",https://doi.org/10.1145/3605731.3605886,10.1145/3605731.3605886,acm,2023
490,Broken Promises: Measuring Confounding Effects in Learning-based Vulnerability Discovery,"@inproceedings{10.1145/3605764.3623915,
author = {Imgrund, Erik and Ganz, Tom and H\""{a}rterich, Martin and Pirch, Lukas and Risse, Niklas and Rieck, Konrad},
title = {Broken Promises: Measuring Confounding Effects in Learning-based Vulnerability Discovery},
year = {2023},
isbn = {9798400702600},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605764.3623915},
doi = {10.1145/3605764.3623915},
abstract = {Several learning-based vulnerability detection methods have been proposed to assist developers during the secure software development life-cycle. In particular, recent learning-based large transformer networks have shown remarkably high performance in various vulnerability detection and localization benchmarks. However, these models have also been shown to have difficulties accurately locating the root cause of flaws and generalizing to out-of-distribution samples. In this work, we investigate this problem and identify spurious correlations as the main obstacle to transferability and generalization, resulting in performance losses of up to 30% for current models. We propose a method to measure the impact of these spurious correlations on learning models and estimate their true, unbiased performance. We present several strategies to counteract the underlying confounding bias, but ultimately our work highlights the limitations of evaluations in the laboratory for complex learning tasks such as vulnerability discovery.},
booktitle = {Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
pages = {149–160},
numpages = {12},
keywords = {causal learning, confounding effect, large language models, overfitting, vulnerability discovery},
location = {Copenhagen, Denmark},
series = {AISec '23}
}

",https://doi.org/10.1145/3605764.3623915,10.1145/3605764.3623915,acm,2023
491,Moving From Narrative to Interactive Multi-Modal Sentiment Analysis: A Survey,"@article{10.1145/3610288,
author = {Ma, Junxia and Rong, Lu and Zhang, Yazhou and Tiwari, Prayag},
title = {Moving From Narrative to Interactive Multi-Modal Sentiment Analysis: A Survey},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3610288},
doi = {10.1145/3610288},
abstract = {A growing number of individuals are expressing their opinions and engaging in interactive communication with others through various modalities, including natural language (text), facial gestures (vision), acoustic behaviors (audio), and more. Within the realms of natural language processing (NLP) and artificial intelligence (AI), multi-modal sentiment analysis has consistently remained a fundamental research area. Building upon recent advancements, this survey aims to provide researchers with a comprehensive overview of the state-of-the-art techniques in multi-modal sentiment analysis, specifically focusing on various sentiment interaction tasks. It is worth noting that the existing literature on multi-modal sentiment analysis has rarely delved into the realm of sentiment interaction. This survey presents a novel perspective by outlining the progression of multi-modal sentiment analysis from narrative sentiment to interactive sentiment. Furthermore, it discusses the research background, problem definition, and various approaches in multi-modal sentiment analysis. Additionally, this survey provides insights into the development of multi-modal sarcasm recognition, emphasizing the shift from narrativity to interactivity. Lastly, we summarize the current scientific challenges related to interaction modeling and highlight future development trends in the field.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {jul},
keywords = {multi-modal sentiment analysis, interactive dialogue, natural language processing, deep learning, artificial intelligence}
}

",https://doi.org/10.1145/3610288,10.1145/3610288,acm,2023
492,AI N\,"@inproceedings{10.1145/3610591.3616427,
author = {Sun, Yuqian and Tang, Yuying and Gao, Ze and Pan, Zhijun and Xu, Chuyan and Chen, Yurou and Qian, Kejiang and Wang, Zhigang and Braud, Tristan and Lee, Chang Hee and Asadipour, Ali},
title = {AI N\""{u}shu: An Exploration of Language Emergence in Sisterhood Through the Lens of Computational Linguistics},
year = {2023},
isbn = {9798400703201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610591.3616427},
doi = {10.1145/3610591.3616427},
abstract = {This paper presents “AI N\""{u}shu,"" an emerging language system inspired by N\""{u}shu (women’s scripts), the unique language created and used exclusively by ancient Chinese women who were thought to be illiterate under a patriarchal society. In this interactive installation, two artificial intelligence (AI) agents are trained in the Chinese dictionary and the N\""{u}shu corpus. By continually observing their environment and communicating, these agents collaborate towards creating a standard writing system to encode Chinese. It offers an artistic interpretation of the creation of a non-western script from a computational linguistics perspective, integrating AI technology with Chinese cultural heritage and a feminist viewpoint.},
booktitle = {SIGGRAPH Asia 2023 Art Papers},
articleno = {4},
numpages = {7},
keywords = {AI N\""{u}shu, Chinese Cultural Heritage, Computational Linguistics, Language Emergence},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

",https://doi.org/10.1145/3610591.3616427,10.1145/3610591.3616427,acm,2023
493,PREDILECT: Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning,"@inproceedings{10.1145/3610977.3634970,
author = {Holk, Simon and Marta, Daniel and Leite, Iolanda},
title = {PREDILECT: Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634970},
doi = {10.1145/3610977.3634970},
abstract = {Preference-based reinforcement learning (RL) has emerged as a new field in robot learning, where humans play a pivotal role in shaping robot behavior by expressing preferences on different sequences of state-action pairs. However, formulating realistic policies for robots demands responses from humans to an extensive array of queries. In this work, we approach the sample-efficiency challenge by expanding the information collected per query to contain both preferences and optional text prompting. To accomplish this, we leverage the zero-shot capabilities of a large language model (LLM) to reason from the text provided by humans. To accommodate the additional query information, we reformulate the reward learning objectives to contain flexible highlights -- state-action pairs that contain relatively high information and are related to the features processed in a zero-shot fashion from a pretrained LLM. In both a simulated scenario and a user study, we reveal the effectiveness of our work by analyzing the feedback and its implications. Additionally, the collective feedback collected serves to train a robot on socially compliant trajectories in a simulated social navigation landscape. We provide video examples of the trained policies at https://sites.google.com/view/rl-predilect},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {259–268},
numpages = {10},
keywords = {human-in-the-loop learning, interactive learning, preference learning, reinforcement learning},
location = {Boulder, CO, USA},
series = {HRI '24}
}

",https://doi.org/10.1145/3610977.3634970,10.1145/3610977.3634970,acm,2024
494,,"@inproceedings{10.1145/3610977.3634979,
author = {Hsu, Long-Jing and Stafford, Philip B. and Khoo, Weslie and Swaminathan, Manasi and Amon, Kyrie Jig and Sato, Hiroki and Tsui, Katherine M. and Crandall, David J. and Sabanovi\'{c}, Selma},
title = {""Give it Time:"" Longitudinal Panels Scaffold Older Adults' Learning and Robot Co-Design},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634979},
doi = {10.1145/3610977.3634979},
abstract = {Participatory robot design projects with older adults often use multiple sessions to encourage design feedback and active participation from users. Prior projects have, however, not analyzed the learning outcomes for older adults across co-design sessions and how they support constructive design feedback and meaningful participation. To bridge this gap, we examined the learning outcomes within a ""longitudinal panel."" This panel comprised seven co-design sessions with 11 older adults of varying cognitive abilities over six months, aimed at designing a robot to guide a photograph-based conversational activity. Using Nelson and Stolterman's framework of the hierarchy of design-learning, we demonstrate how older adult panelists achieved multiple design-learning outcomes- capacity, confidence, capability, competence, courage, and connection- which allowed them to provide actionable design suggestions. We provide guidelines for conducting longitudinal panels that can enhance user design-learning and participation in robot design.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {283–292},
numpages = {10},
keywords = {co-design, design-learning, older adults, participatory design, photograph, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

",https://doi.org/10.1145/3610977.3634979,10.1145/3610977.3634979,acm,2024
495,Getting pwn’d by AI: Penetration Testing with Large Language Models,"@inproceedings{10.1145/3611643.3613083,
author = {Happe, Andreas and Cito, J\""{u}rgen},
title = {Getting pwn’d by AI: Penetration Testing with Large Language Models},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613083},
doi = {10.1145/3611643.3613083},
abstract = {The field of software security testing, more specifically penetration testing, requires high levels of expertise and involves many manual testing and analysis steps. This paper explores the potential use of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners. We explore two distinct use cases: high-level task planning for security testing assignments and low-level vulnerability hunting within a vulnerable virtual machine. For the latter, we implemented a closed-feedback loop between LLM-generated low-level actions with a vulnerable virtual machine (connected through SSH) and allowed the LLM to analyze the machine state for vulnerabilities and suggest concrete attack vectors which were automatically executed within the virtual machine. We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of AI sparring partners.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2082–2086},
numpages = {5},
keywords = {large language models, penetration testing, security testing},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

",https://doi.org/10.1145/3611643.3613083,10.1145/3611643.3613083,acm,2023
496,InferFix: End-to-End Program Repair with LLMs,"@inproceedings{10.1145/3611643.3613892,
author = {Jin, Matthew and Shahriar, Syed and Tufano, Michele and Shi, Xin and Lu, Shuai and Sundaresan, Neel and Svyatkovskiy, Alexey},
title = {InferFix: End-to-End Program Repair with LLMs},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613892},
doi = {10.1145/3611643.3613892},
abstract = {Software development life cycle is profoundly influenced by bugs; their introduction, identification, and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose : a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs.  combines a Retriever – transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator – an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated , a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that  outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of  alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration (CI) pipeline to automate the software development workflow.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1646–1656},
numpages = {11},
keywords = {Program repair, finetuning, prompt augmentation, static analyses},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

",https://doi.org/10.1145/3611643.3613892,10.1145/3611643.3613892,acm,2023
497,Evaluating Transfer Learning for Simplifying GitHub READMEs,"@inproceedings{10.1145/3611643.3616291,
author = {Gao, Haoyu and Treude, Christoph and Zahedi, Mansooreh},
title = {Evaluating Transfer Learning for Simplifying GitHub READMEs},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616291},
doi = {10.1145/3611643.3616291},
abstract = {Software documentation captures detailed knowledge about a software product, e.g., code, technologies, and design. It plays an important role in the coordination of development teams and in conveying ideas to various stakeholders. However, software documentation can be hard to comprehend if it is written with jargon and complicated sentence structure. In this study, we explored the potential of text simplification techniques in the domain of software engineering to automatically simplify GitHub README files. We collected software-related pairs of GitHub README files consisting of 14,588 entries, aligned difficult sentences with their simplified counterparts, and trained a Transformer-based model to automatically simplify difficult versions. To mitigate the sparse and noisy nature of the software-related simplification dataset, we applied general text simplification knowledge to this field. Since many general-domain difficult-to-simple Wikipedia document pairs are already publicly available, we explored the potential of transfer learning by first training the model on the Wikipedia data and then fine-tuning it on the README data. Using automated BLEU scores and human evaluation, we compared the performance of different transfer learning schemes and the baseline models without transfer learning. The transfer learning model using the best checkpoint trained on a general topic corpus achieved the best performance of 34.68 BLEU score and statistically significantly higher human annotation scores compared to the rest of the schemes and baselines. We conclude that using transfer learning is a promising direction to circumvent the lack of data and drift style problem in software README files simplification and achieved a better trade-off between simplification and preservation of meaning.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1548–1560},
numpages = {13},
keywords = {GitHub, Software Documentation, Text Simplification, Transfer Learning},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

",https://doi.org/10.1145/3611643.3616291,10.1145/3611643.3616291,acm,2023
498,TransMap: Pinpointing Mistakes in Neural Code Translation,"@inproceedings{10.1145/3611643.3616322,
author = {Wang, Bo and Li, Ruishi and Li, Mingkai and Saxena, Prateek},
title = {TransMap: Pinpointing Mistakes in Neural Code Translation},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616322},
doi = {10.1145/3611643.3616322},
abstract = {Automated code translation between programming languages can greatly reduce the human effort needed in learning new languages or in migrating code. Recent neural machine translation models, such as Codex, have been shown to be effective on many code generation tasks including translation. However, code produced by neural translators often has semantic mistakes. These mistakes are difficult to eliminate from the neural translator itself because the translator is a black box, which is difficult to interpret or control compared to rule-based transpilers. We propose the first automated approach to pinpoint semantic mistakes in code obtained after neural code translation. Our techniques are implemented in a prototype tool called TransMap which translates Python to JavaScript, both of which are popular scripting languages. On our created micro-benchmarks of Python programs with 648 semantic mistakes in total, TransMap accurately pinpoints the correct location for a fix for 87.96%, often highlighting 1-2 lines for the user to inspect per mistake. We report on our experience in translating 5 Python libraries with up to 1k lines of code with TransMap. Our preliminary user study suggests that TransMap can reduce the time for fixing semantic mistakes by around 70% compared to using a standard IDE with debuggers.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {999–1011},
numpages = {13},
keywords = {Code Translation, Large Language Models, Semantic Mistakes},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

",https://doi.org/10.1145/3611643.3616322,10.1145/3611643.3616322,acm,2023
499,Large Language Models for Education: Grading Open-Ended Questions Using ChatGPT,"@inproceedings{10.1145/3613372.3614197,
author = {Pinto, Gustavo and Cardoso-Pereira, Isadora and Monteiro, Danilo and Lucena, Danilo and Souza, Alberto and Gama, Kiev},
title = {Large Language Models for Education: Grading Open-Ended Questions Using ChatGPT},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3614197},
doi = {10.1145/3613372.3614197},
abstract = {As a way of addressing increasingly sophisticated problems, software professionals face the constant challenge of seeking improvement. However, for these individuals to enhance their skills, their process of studying and training must involve feedback that is both immediate and accurate. In the context of software companies, where the scale of professionals undergoing training is large, but the number of qualified professionals available for providing corrections is small, delivering effective feedback becomes even more challenging. To circumvent this challenge, this work presents an exploration of using Large Language Models (LLMs) to support the correction process of open-ended questions in technical training. In this study, we utilized ChatGPT to correct open-ended questions answered by 42 industry professionals on two topics. Evaluating the corrections and feedback provided by ChatGPT, we observed that it is capable of identifying semantic details in responses that other metrics cannot observe. Furthermore, we noticed that, in general, subject matter experts tended to agree with the corrections and feedback given by ChatGPT.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {293–302},
numpages = {10},
keywords = {Automated grading, ChatGPT, Open-ended Questions},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

",https://doi.org/10.1145/3613372.3614197,10.1145/3613372.3614197,acm,2023
500,How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study,"@inproceedings{10.1145/3613904.3641891,
author = {Gu, Ken and Grunde-McLaughlin, Madeleine and McNutt, Andrew and Heer, Jeffrey and Althoff, Tim},
title = {How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641891},
doi = {10.1145/3613904.3641891},
abstract = {Data analysis is challenging as analysts must navigate nuanced decisions that may yield divergent conclusions. AI assistants have the potential to support analysts in planning their analyses, enabling more robust decision making. Though AI-based assistants that target code execution (e.g., Github Copilot) have received significant attention, limited research addresses assistance for both analysis execution and planning. In this work, we characterize helpful planning suggestions and their impacts on analysts’ workflows. We first review the analysis planning literature and crowd-sourced analysis studies to categorize suggestion content. We then conduct a Wizard-of-Oz study (n=13) to observe analysts’ preferences and reactions to planning assistance in a realistic scenario. Our findings highlight subtleties in contextual factors that impact suggestion helpfulness, emphasizing design implications for supporting different abstractions of assistance, forms of initiative, increased engagement, and alignment of goals between analysts and assistants.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1015},
numpages = {22},
keywords = {Analysis Planning, Analysis Tools, Artificial Intelligence, Code Assistant, Computational Notebooks, Copilot, Data Analysis, Data Science Assistant, Human-AI Collaboration, Human-AI Interaction, Human-Centered Data Science, Human-LLM Interaction, Statistical Analysis, Wizard of Oz},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641891,10.1145/3613904.3641891,acm,2024
501,The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization,"@inproceedings{10.1145/3613904.3641895,
author = {Hoque, Md Naimul and Mashiat, Tasfia and Ghai, Bhavya and Shelton, Cecilia D. and Chevalier, Fanny and Kraus, Kari and Elmqvist, Niklas},
title = {The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641895},
doi = {10.1145/3613904.3641895},
abstract = {The use of Large Language Models (LLMs) for writing has sparked controversy both among readers and writers. On one hand, writers are concerned that LLMs will deprive them of agency and ownership, and readers are concerned about spending their time on text generated by soulless machines. On the other hand, AI-assistance can improve writing as long as writers can conform to publisher policies, and as long as readers can be assured that a text has been verified by a human. We argue that a system that captures the provenance of interaction with an LLM can help writers retain their agency, conform to policies, and communicate their use of AI to publishers and readers transparently. Thus we propose HaLLMark, a tool for visualizing the writer’s interaction with the LLM. We evaluated HaLLMark with 13 creative writers, and found that it helped them retain a sense of control and ownership of the text.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1045},
numpages = {15},
keywords = {Creative writing, LLMs, agency, co-writing, visualization.},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641895,10.1145/3613904.3641895,acm,2024
502,ABScribe: Rapid Exploration &amp; Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models,"@inproceedings{10.1145/3613904.3641899,
author = {Reza, Mohi and Laundry, Nathan M and Musabirov, Ilya and Dushniku, Peter and Yu, Zhi Yuan “Michael” and Mittal, Kashish and Grossman, Tovi and Liut, Michael and Kuzminykh, Anastasia and Williams, Joseph Jay},
title = {ABScribe: Rapid Exploration &amp; Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641899},
doi = {10.1145/3613904.3641899},
abstract = {Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers’ flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p &lt; 0.001), enhances user perceptions of the revision process (d = 2.41, p &lt; 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1042},
numpages = {18},
keywords = {datasets, gaze detection, neural networks, text tagging},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641899,10.1145/3613904.3641899,acm,2024
503,Beyond the Waiting Room: Patient's Perspectives on the Conversational Nuances of Pre-Consultation Chatbots,"@inproceedings{10.1145/3613904.3641913,
author = {Li, Brenna and Gross, Ofek and Crampton, Noah and Kapoor, Mamta and Tauseef, Saba and Jain, Mohit and Truong, Khai N. and Mariakakis, Alex},
title = {Beyond the Waiting Room: Patient's Perspectives on the Conversational Nuances of Pre-Consultation Chatbots},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641913},
doi = {10.1145/3613904.3641913},
abstract = {Pre-consultation serves as a critical information exchange between healthcare providers and patients, streamlining visits and supporting patient-centered care. Human-led pre-consultations offer many benefits, yet they require significant time and energy from clinical staff. In this work, we identify design goals for pre-consultation chatbots given their potential to carry out human-like conversations and autonomously adapt their line of questioning. We conducted a study with 33 walk-in clinic patients to elicit design considerations for pre-consultation chatbots. Participants were exposed to one of two study conditions: an LLM-powered AI agent and a Wizard-of-Oz agent simulated by medical professionals. Our study found that both conditions were equally well-received and demonstrated comparable conversational capabilities. However, the extent of the follow-up questions and the amount of empathy impacted the chatbot’s perceived thoroughness and sincerity. Patients also highlighted the importance of setting expectations for the chatbot before and after the pre-consultation experience.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {438},
numpages = {24},
keywords = {LLMs, chatbots, information gathering, patient intake, primary care},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641913,10.1145/3613904.3641913,acm,2024
504,VAL: Interactive Task Learning with GPT Dialog Parsing,"@inproceedings{10.1145/3613904.3641915,
author = {Lawley, Lane and Maclellan, Christopher},
title = {VAL: Interactive Task Learning with GPT Dialog Parsing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641915},
doi = {10.1145/3613904.3641915},
abstract = {Machine learning often requires millions of examples to produce static, black-box models. In contrast, interactive task learning (ITL) emphasizes incremental knowledge acquisition from limited instruction provided by humans in modalities such as natural language. However, ITL systems often suffer from brittle, error-prone language parsing, which limits their usability. Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally. We present VAL, an ITL system with a new philosophy for LLM/symbolic integration. By using LLMs only for specific tasks—such as predicate and argument selection—within an algorithmic framework, VAL reaps the benefits of LLMs to support interactive learning of hierarchical task knowledge from natural language. Acquired knowledge is human interpretable and generalizes to support execution of novel tasks without additional training. We studied users’ interactions with VAL in a video game setting, finding that most users could successfully teach VAL using language they felt was natural.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {5},
numpages = {18},
keywords = {GPT, hierarchical task networks, hybrid AI, large language models (LLMs), neuro-symbolic AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641915,10.1145/3613904.3641915,acm,2024
505,Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant with Refined Template Instructions,"@inproceedings{10.1145/3613904.3641924,
author = {Szymanski, Annalisa and Wimer, Brianna L and Anuyah, Oghenemaro and Eicher-Miller, Heather A and Metoyer, Ronald A},
title = {Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant with Refined Template Instructions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641924},
doi = {10.1145/3613904.3641924},
abstract = {Large Language Models (LLMs) have the potential to contribute to the fields of nutrition and dietetics in generating food product explanations that facilitate informed food selections. However, the extent to which these models offer effective and accurate information remains unverified. In collaboration with registered dietitians (RDs), we evaluate the strengths and weaknesses of LLMs in providing accurate and personalized nutrition information. Through a mixed-methods approach, RDs validated GPT-4 outputs at various levels of prompt specificity, which led to the development of design guidelines used to prompt LLMs for nutrition information. We tested these guidelines by creating a GPT prototype, The Food Product Nutrition Assistant, tailored for food product explanations. This prototype was refined and evaluated in focus groups with RDs. We find that the implementation of these dietitian-reviewed template instructions enhance the generation of detailed food product descriptions and tailored nutrition information.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {992},
numpages = {22},
keywords = {Artificial Intelligence, Food Recommendations, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641924,10.1145/3613904.3641924,acm,2024
506,Writing out the Storm: Designing and Evaluating Tools for Weather Risk Messaging,"@inproceedings{10.1145/3613904.3641926,
author = {Jit, Sophia S and Spinney, Jennifer and Chandra, Priyank and Chilton, Lydia B and Soden, Robert},
title = {Writing out the Storm: Designing and Evaluating Tools for Weather Risk Messaging},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641926},
doi = {10.1145/3613904.3641926},
abstract = {Communicating risk to the public in the lead-up to and during severe weather events has the potential to reduce the impacts of these events on lives and property. Globally, these events are anticipated to increase due to climate change, rendering effective risk communication an integral component of climate adaptation policies. Research in risk communications literature has developed substantial knowledge and best practices for the design of risk messaging. This study considers the potential for quantifying the compliance of severe weather risk messages with these best practices, individually and at scale, and developing tools to improve risk communication messaging. The current work makes two contributions. First, we develop a string-matching approach to evaluate whether messaging complies with best practices and suggest areas for improvement. Second, we conduct an interview study with risk communication professionals to inform the design space of authoring tools and other technologies to support severe weather risk communicators.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {502},
numpages = {16},
keywords = {Creativity Support, Crisis/Disaster, Empirical study that tells us about how people use a system},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641926,10.1145/3613904.3641926,acm,2024
507,Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming,"@inproceedings{10.1145/3613904.3641936,
author = {Mozannar, Hussein and Bansal, Gagan and Fourney, Adam and Horvitz, Eric},
title = {Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641936},
doi = {10.1145/3613904.3641936},
abstract = {Code-recommendation systems, such as Copilot and CodeWhisperer, have the potential to improve programmer productivity by suggesting and auto-completing code. However, to fully realize their potential, we must understand how programmers interact with these systems and identify ways to improve that interaction. To seek insights about human-AI collaboration with code recommendations systems, we studied GitHub Copilot, a code-recommendation system used by millions of programmers daily. We developed CUPS, a taxonomy of common programmer activities when interacting with Copilot. Our study of 21 programmers, who completed coding tasks and retrospectively labeled their sessions with CUPS, showed that CUPS can help us understand how programmers interact with code-recommendation systems, revealing inefficiencies and time costs. Our insights reveal how programmers interact with Copilot and motivate new interface designs and metrics.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {142},
numpages = {16},
keywords = {AI-assisted Programming, Copilot, User State Model},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641936,10.1145/3613904.3641936,acm,2024
508,Understanding Choice Independence and Error Types in Human-AI Collaboration,"@inproceedings{10.1145/3613904.3641946,
author = {Erlei, Alexander and Sharma, Abhinav and Gadiraju, Ujwal},
title = {Understanding Choice Independence and Error Types in Human-AI Collaboration},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641946},
doi = {10.1145/3613904.3641946},
abstract = {The ability to make appropriate delegation decisions is an important prerequisite of effective human-AI collaboration. Recent work, however, has shown that people struggle to evaluate AI systems in the presence of forecasting errors, falling well short of relying on AI systems appropriately. We use a pre-registered crowdsourcing study (N = 611) to extend this literature by two underexplored crucial features of human AI decision-making: choice independence and error type. Subjects in our study repeatedly complete two prediction tasks and choose which predictions they want to delegate to an AI system. For one task, subjects receive a decision heuristic that allows them to make informed and relatively accurate predictions. The second task is substantially harder to solve, and subjects must come up with their own decision rule. We systematically vary the AI system’s performance such that it either provides the best possible prediction for both tasks or only for one of the two. Our results demonstrate that people systematically violate choice independence by taking the AI’s performance in an unrelated second task into account. Humans who delegate predictions to a superior AI in their own expertise domain significantly reduce appropriate reliance when the model makes systematic errors in a complementary expertise domain. In contrast, humans who delegate predictions to a superior AI in a complementary expertise domain significantly increase appropriate reliance when the model systematically errs in the human expertise domain. Furthermore, we show that humans differentiate between error types and that this effect is conditional on the considered expertise domain. This is the first empirical exploration of choice independence and error types in the context of human-AI collaboration. Our results have broad and important implications for the future design, deployment, and appropriate application of AI systems.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {308},
numpages = {19},
keywords = {Algorithm Aversion, Complementary AI Systems, Crowdsourcing Study, Decision Support System, Errors, Human-AI Collaboration, Interaction},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641946,10.1145/3613904.3641946,acm,2024
509,From Text to Self: Users’ Perception of AIMC Tools on Interpersonal Communication and Self,"@inproceedings{10.1145/3613904.3641955,
author = {Fu, Yue and Foell, Sami and Xu, Xuhai and Hiniker, Alexis},
title = {From Text to Self: Users’ Perception of AIMC Tools on Interpersonal Communication and Self},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641955},
doi = {10.1145/3613904.3641955},
abstract = {In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users’ perceptions of these tools’ ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, finding precise language to express their thoughts, and navigating linguistic and cultural barriers. However, our findings also show current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. We identify four key communication spaces delineated by communication stakes (high or low) and relationship dynamics (formal or informal) that differentially predict users’ attitudes toward AIMC tools. Specifically, participants report that these tools are more suitable for communicating in formal relationships than informal ones and more beneficial in high-stakes than low-stakes communication.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {977},
numpages = {17},
keywords = {computer mediated communication, diary study},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641955,10.1145/3613904.3641955,acm,2024
510,,"@inproceedings{10.1145/3613904.3641964,
author = {Kobiella, Charlotte and Flores L\'{o}pez, Yarhy Said and Waltenberger, Franz and Draxler, Fiona and Schmidt, Albrecht},
title = {""If the Machine Is As Good As Me, Then What Use Am I?"" – How the Use of ChatGPT Changes Young Professionals' Perception of Productivity and Accomplishment},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641964},
doi = {10.1145/3613904.3641964},
abstract = {Large language models (LLMs) like ChatGPT have been widely adopted in work contexts. We explore the impact of ChatGPT on young professionals’ perception of productivity and sense of accomplishment. We collected LLMs’ main use cases in knowledge work through a preliminary study, which served as the basis for a two-week diary study with 21 young professionals reflecting on their ChatGPT use. Findings indicate that ChatGPT enhanced some participants’ perceptions of productivity and accomplishment by enabling greater creative output and satisfaction from efficient tool utilization. Others experienced decreased perceived productivity and accomplishment, driven by a diminished sense of ownership, perceived lack of challenge, and mediocre results. We found that the suitability of task delegation to ChatGPT varies strongly depending on the task nature. It’s especially suitable for comprehending broad subject domains, generating creative solutions, and uncovering new information. It’s less suitable for research tasks due to hallucinations, which necessitate extensive validation.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1018},
numpages = {16},
keywords = {Generative AI, knowledge work, productivity, self-efficacy, sense of accomplishment},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641964,10.1145/3613904.3641964,acm,2024
511,"Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions","@inproceedings{10.1145/3613904.3641965,
author = {Calle, Paul and Shao, Ruosi and Liu, Yunlong and H\'{e}bert, Emily T and Kendzor, Darla and Neil, Jordan and Businelle, Michael and Pan, Chongle},
title = {Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641965},
doi = {10.1145/3613904.3641965},
abstract = {Creating intervention messages for smoking cessation is a labor-intensive process. Advances in Large Language Models (LLMs) offer a promising alternative for automated message generation. Two critical questions remain: 1) How to optimize LLMs to mimic human expert writing, and 2) Do LLM-generated messages meet clinical standards? We systematically examined the message generation and evaluation processes through three studies investigating prompt engineering (Study 1), decoding optimization (Study 2), and expert review (Study 3). We employed computational linguistic analysis in LLM assessment and established a comprehensive evaluation framework, incorporating automated metrics, linguistic attributes, and expert evaluations. Certified tobacco treatment specialists assessed the quality, accuracy, credibility, and persuasiveness of LLM-generated messages, using expert-written messages as the benchmark. Results indicate that larger LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate expert writing to generate well-written, accurate, and persuasive messages, thereby demonstrating the capability of LLMs in augmenting clinical practices of smoking cessation interventions.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {16},
keywords = {Computational Linguistic Analysis, Expert Review, Large Language Model, Message Generation, Smoking Cessation Intervention},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641965,10.1145/3613904.3641965,acm,2024
512,Marco: Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models,"@inproceedings{10.1145/3613904.3641969,
author = {Fok, Raymond and Lipka, Nedim and Sun, Tong and Siu, Alexa F},
title = {Marco: Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641969},
doi = {10.1145/3613904.3641969},
abstract = {Knowledge workers often need to extract and analyze information from a collection of documents to solve complex information tasks in the workplace, e.g., hiring managers reviewing resumes or analysts assessing risk in contracts. However, foraging for relevant information can become tedious and repetitive over many documents and criteria of interest. We introduce Marco, a mixed-initiative workspace supporting sensemaking over diverse business document collections. Through collection-centric assistance, Marco reduces the cognitive costs of extracting and structuring information, allowing users to prioritize comparative synthesis and decision making processes. Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection. Findings from a usability study (n=16) demonstrate that when using Marco, users complete sensemaking tasks 16% more quickly, with less effort, and without diminishing accuracy. A design probe with seven domain experts identifies how Marco can benefit various real-world workflows.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {842},
numpages = {20},
keywords = {business document workflows, document collections, large language models, mixed-initiative systems, sensemaking},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641969,10.1145/3613904.3641969,acm,2024
513,Unlock Life with a Chat(GPT): Integrating Conversational AI with Large Language Models into Everyday Lives of Autistic Individuals,"@inproceedings{10.1145/3613904.3641989,
author = {Choi, Dasom and Lee, Sunok and Kim, Sung-In and Lee, Kyungah and Yoo, Hee Jeong and Lee, Sangsu and Hong, Hwajung},
title = {Unlock Life with a Chat(GPT): Integrating Conversational AI with Large Language Models into Everyday Lives of Autistic Individuals},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641989},
doi = {10.1145/3613904.3641989},
abstract = {Autistic individuals often draw on insights from their supportive networks to develop self-help life strategies ranging from everyday chores to social activities. However, human resources may not always be immediately available. Recently emerging conversational agents (CAs) that leverage large language models (LLMs) have the potential to serve as powerful information-seeking tools, facilitating autistic individuals to tackle daily concerns independently. This study explored the opportunities and challenges of LLM-driven CAs in empowering autistic individuals through focus group interviews and workshops (N=14). We found that autistic individuals expected LLM-driven CAs to offer a non-judgmental space, encouraging them to approach day-to-day issues proactively. However, they raised issues regarding critically digesting the CA responses and disclosing their autistic characteristics. Based on these findings, we propose approaches that place autistic individuals at the center of shaping the meaning and role of LLM-driven CAs in their lives, while preserving their unique needs and characteristics.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {72},
numpages = {17},
keywords = {autism, conversational agent, large language model, participatory design workshop},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3641989,10.1145/3613904.3641989,acm,2024
514,"CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models","@inproceedings{10.1145/3613904.3642002,
author = {Gao, Jie and Guo, Yuchen and Lim, Gionnieve and Zhang, Tianqin and Zhang, Zheng and Li, Toby Jia-Jun and Perrault, Simon Tangi},
title = {CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642002},
doi = {10.1145/3613904.3642002},
abstract = {Collaborative Qualitative Analysis (CQA) can enhance qualitative analysis rigor and depth by incorporating varied viewpoints. Nevertheless, ensuring a rigorous CQA procedure itself can be both complex and costly. To lower this bar, we take a theoretical perspective to design a one-stop, end-to-end workflow, CollabCoder, that integrates Large Language Models (LLMs) into key inductive CQA stages. In the independent open coding phase, CollabCoder offers AI-generated code suggestions and records decision-making data. During the iterative discussion phase, it promotes mutual understanding by sharing this data within the coding team and using quantitative metrics to identify coding (dis)agreements, aiding in consensus-building. In the codebook development phase, CollabCoder provides primary code group suggestions, lightening the workload of developing a codebook from scratch. A 16-user evaluation confirmed the effectiveness of CollabCoder, demonstrating its advantages over the existing CQA platform. All related materials of CollabCoder, including code and further extensions, will be included in: https://gaojie058.github.io/CollabCoder/.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {11},
numpages = {29},
keywords = {Collaborative Qualitative Analysis, Grounded Theory, Inductive Qualitative Coding, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642002,10.1145/3613904.3642002,acm,2024
515,Towards Designing a Question-Answering Chatbot for Online News: Understanding Questions and Perspectives,"@inproceedings{10.1145/3613904.3642007,
author = {Hoque, Md Naimul and Mahfuz, Ayman A and Kindi, Mayukha Sridhatri and Hassan, Naeemul},
title = {Towards Designing a Question-Answering Chatbot for Online News: Understanding Questions and Perspectives},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642007},
doi = {10.1145/3613904.3642007},
abstract = {Large Language Models (LLMs) have created opportunities for designing chatbots that can support complex question-answering (QA) scenarios and improve news audience engagement. However, we still lack an understanding of what roles journalists and readers deem fit for such a chatbot in newsrooms. To address this gap, we first interviewed six journalists to understand how they answer questions from readers currently and how they want to use a QA chatbot for this purpose. To understand how readers want to interact with a QA chatbot, we then conducted an online experiment (N=124) where we asked each participant to read three news articles and ask questions to either the author(s) of the articles or a chatbot. By combining results from the studies, we present alignments and discrepancies between how journalists and readers want to use QA chatbots and propose a framework for designing effective QA chatbots in newsrooms.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {154},
numpages = {17},
keywords = {LLMs, Online news, chatbots, question-answering},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642007,10.1145/3613904.3642007,acm,2024
516,ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing,"@inproceedings{10.1145/3613904.3642016,
author = {Arawjo, Ian and Swoopes, Chelse and Vaithilingam, Priyan and Wattenberg, Martin and Glassman, Elena L.},
title = {ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642016},
doi = {10.1145/3613904.3642016},
abstract = {Evaluating outputs of large language models (LLMs) is challenging, requiring making—and making sense of—many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {18},
keywords = {auditing, language models, prompt engineering, toolkits, visual programming environments},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642016,10.1145/3613904.3642016,acm,2024
517,Towards Co-Creating Access and Inclusion: A Group Autoethnography on a Hearing Individual's Journey Towards Effective Communication in Mixed-Hearing Ability Higher Education Settings,"@inproceedings{10.1145/3613904.3642017,
author = {Chen, Si and Waller, James and Seita, Matthew and Vogler, Christian and Kushalnagar, Raja and Wang, Qi},
title = {Towards Co-Creating Access and Inclusion: A Group Autoethnography on a Hearing Individual's Journey Towards Effective Communication in Mixed-Hearing Ability Higher Education Settings},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642017},
doi = {10.1145/3613904.3642017},
abstract = {We present a group autoethnography detailing a hearing student’s journey in adopting communication technologies at a mixed-hearing ability summer research camp. Our study focuses on how this student, a research assistant with emerging American Sign Language (ASL) skills, (in)effectively communicates with deaf and hard-of-hearing (DHH) peers and faculty during the ten-week program. The DHH members also reflected on their communication with the hearing student. We depict scenarios and analyze the (in)effectiveness of how emerging technologies like live automatic speech recognition (ASR) and typing are utilized to facilitate communication. We outline communication strategies to engage everyone with diverse signing skills in conversations - directing visual attention, pause-for-attention-and-proceed, and back-channeling via expressive body. These strategies promote inclusive collaboration and leverage technology advancements. Furthermore, we delve into the factors that have motivated individuals to embrace more inclusive communication practices and provide design implications for accessible communication technologies within the mixed-hearing ability context.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {55},
numpages = {14},
keywords = {American Sign Language, DHH, Higher Education, Mixed-Ability},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642017,10.1145/3613904.3642017,acm,2024
518,Deus Ex Machina and Personas from Large Language Models: Investigating the Composition of AI-Generated Persona Descriptions,"@inproceedings{10.1145/3613904.3642036,
author = {Salminen, Joni and Liu, Chang and Pian, Wenjing and Chi, Jianxing and H\""{a}yh\""{a}nen, Essi and Jansen, Bernard J},
title = {Deus Ex Machina and Personas from Large Language Models: Investigating the Composition of AI-Generated Persona Descriptions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642036},
doi = {10.1145/3613904.3642036},
abstract = {Large language models (LLMs) can generate personas based on prompts that describe the target user group. To understand what kind of personas LLMs generate, we investigate the diversity and bias in 450 LLM-generated personas with the help of internal evaluators (n=4) and subject-matter experts (SMEs) (n=5). The research findings reveal biases in LLM-generated personas, particularly in age, occupation, and pain points, as well as a strong bias towards personas from the United States. Human evaluations demonstrate that LLM persona descriptions were informative, believable, positive, relatable, and not stereotyped. The SMEs rated the personas slightly more stereotypical, less positive, and less relatable than the internal evaluators. The findings suggest that LLMs can generate consistent personas perceived as believable, relatable, and informative while containing relatively low amounts of stereotyping.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {510},
numpages = {20},
keywords = {AI, HCI, LLMs, evaluation, user personas},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642036,10.1145/3613904.3642036,acm,2024
519,"Scientific and Fantastical: Creating Immersive, Culturally Relevant Learning Experiences with Augmented Reality and Large Language Models","@inproceedings{10.1145/3613904.3642041,
author = {Cheng, Alan Y. and Guo, Meng and Ran, Melissa and Ranasaria, Arpit and Sharma, Arjun and Xie, Anthony and Le, Khuyen N. and Vinaithirthan, Bala and Luan, Shihe (Tracy) and Wright, David Thomas Henry and Cuadra, Andrea and Pea, Roy and Landay, James A.},
title = {Scientific and Fantastical: Creating Immersive, Culturally Relevant Learning Experiences with Augmented Reality and Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642041},
doi = {10.1145/3613904.3642041},
abstract = {Motivating children to learn is a major challenge in education. One way to inspire motivation to learn is through immersion. We combine the immersive potential of augmented reality (AR), narrative, and large language models (LLMs) to bridge fantasy with reality in a mobile application, Moon Story, that teaches elementary schoolers astronomy and environmental science. Our system also builds upon learning theories such as culturally-relevant pedagogy. Using our application, a child embarks on a journey inspired by Chinese mythology, engages in real-world AR activities, and converses with a fictional character powered by an LLM. We conducted a controlled experiment (N = 50) with two conditions: one using an LLM and one that was hard-coded. Both conditions resulted in learning gains, high engagement levels, and increased science learning motivation. Participants in the LLM condition also wrote more relevant answers. Finally, participants of both Chinese and non-Chinese heritage found the culturally-based narrative compelling.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {275},
numpages = {23},
keywords = {Artifact or System, Children/Parents, Education/Learning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642041,10.1145/3613904.3642041,acm,2024
520,BLIP: Facilitating the Exploration of Undesirable Consequences of Digital Technologies,"@inproceedings{10.1145/3613904.3642054,
author = {Pang, Rock Yuren and Santy, Sebastin and Just, Ren\'{e} and Reinecke, Katharina},
title = {BLIP: Facilitating the Exploration of Undesirable Consequences of Digital Technologies},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642054},
doi = {10.1145/3613904.3642054},
abstract = {Digital technologies have positively transformed society, but they have also led to undesirable consequences not anticipated at the time of design or development. We posit that insights into past undesirable consequences can help researchers and practitioners gain awareness and anticipate potential adverse effects. To test this assumption, we introduce Blip, a system that extracts real-world undesirable consequences of technology from online articles, summarizes and categorizes them, and presents them in an interactive, web-based interface. In two user studies with 15 researchers in various computer science disciplines, we found that Blip substantially increased the number and diversity of undesirable consequences they could list in comparison to relying on prior knowledge or searching online. Moreover, Blip helped them identify undesirable consequences relevant to their ongoing projects, made them aware of undesirable consequences they “had never considered,” and inspired them to reflect on their own experiences with technology.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {290},
numpages = {18},
keywords = {NLP, computer ethics, societal impacts, undesirable consequences},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642054,10.1145/3613904.3642054,acm,2024
521,SEAM-EZ: Simplifying Stateful Analytics through Visual Programming,"@inproceedings{10.1145/3613904.3642055,
author = {Yu, Zhengyan and Namkung, Hun and Guo, Jiang and Milner, Henry and Goldfoot, Joel and Wang, Yang and Sekar, Vyas},
title = {SEAM-EZ: Simplifying Stateful Analytics through Visual Programming},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642055},
doi = {10.1145/3613904.3642055},
abstract = {Across many domains (e.g., media/entertainment, mobile apps, finance, IoT, cybersecurity), there is a growing need for stateful analytics over streams of events to meet key business outcomes. Stateful analytics over event streams entails carefully modeling the sequence, timing, and contextual correlations of events to dynamic attributes. Unfortunately, existing frameworks and languages (e.g., SQL, Flink, Spark) entail significant code complexity and expert effort to express such stateful analytics because of their dynamic and stateful nature. Our overarching goal is to simplify and democratize stateful analytics. Through an iterative design and evaluation process including a foundational user study and two rounds of formative evaluations with 15 industry practitioners, we created SEAM-EZ, a no-code visual programming platform for quickly creating and validating stateful metrics. SEAM-EZ features a node-graph editor, interactive tooltips, embedded data views, and auto-suggestion features to facilitate the creation and validation of stateful analytics. We then conducted three real-world case studies of SEAM-EZ with 20 additional practitioners. Our results suggest that practitioners who previously could not or had to spend significant effort to create stateful metrics using traditional tools such as SQL or Spark can now easily and quickly create and validate such metrics using SEAM-EZ.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1041},
numpages = {23},
keywords = {data analytics, metrics, stateful computation, visual programming},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642055,10.1145/3613904.3642055,acm,2024
522,Co-Designing QuickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction,"@inproceedings{10.1145/3613904.3642080,
author = {Fontana De Vargas, Mauricio and Yu, Christina and Shane, Howard C. and Moffatt, Karyn},
title = {Co-Designing QuickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642080},
doi = {10.1145/3613904.3642080},
abstract = {Traditional topic-specific communication boards for Augmentative and Alternative Communication (AAC) require manual programming of relevant symbolic vocabulary, which is time-consuming and often impractical even for experienced Speech-Language Pathologists (SLPs). While recent research has demonstrated the potential to automatically generate these boards from photographs using artificial intelligence, there has been no exploration on how to design such tools to support the specific needs of AAC-based language instruction. This paper introduces QuickPic, a mobile AAC application co-designed with SLPs and special educators, aimed at enhancing language learning for non-speaking individuals, such as autistic children. Through a 17-month design process, we uncover the unique design features required to provide timely language support in therapy and special education contexts. We present emerging evidence on the overall satisfaction of SLPs using QuickPic, and on the advantages of large language model-based generation compared to the existing technique for automated vocabulary from photographs for AAC.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {910},
numpages = {16},
keywords = {Augmentative and Alternative Communication, LLM, assistive technology, autism, just-in-time},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642080,10.1145/3613904.3642080,"acm, scopus",2024
523,Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination,"@inproceedings{10.1145/3613904.3642081,
author = {Bhattacharjee, Ananya and Zeng, Yuchen and Xu, Sarah Yi and Kulzhabayeva, Dana and Ma, Minyi and Kornfield, Rachel and Ahmed, Syed Ishtiaque and Mariakakis, Alex and Czerwinski, Mary P and Kuzminykh, Anastasia and Liut, Michael and Williams, Joseph Jay},
title = {Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642081},
doi = {10.1145/3613904.3642081},
abstract = {Traditional interventions for academic procrastination often fail to capture the nuanced, individual-specific factors that underlie them. Large language models (LLMs) hold immense potential for addressing this gap by permitting open-ended inputs, including the ability to customize interventions to individuals’ unique needs. However, user expectations and potential limitations of LLMs in this context remain underexplored. To address this, we conducted interviews and focus group discussions with 15 university students and 6 experts, during which a technology probe for generating personalized advice for managing procrastination was presented. Our results highlight the necessity for LLMs to provide structured, deadline-oriented steps and enhanced user support mechanisms. Additionally, our results surface the need for an adaptive approach to questioning based on factors like busyness. These findings offer crucial design implications for the development of LLM-based tools for managing procrastination while cautioning the use of LLMs for therapeutic guidance.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {15},
numpages = {18},
keywords = {ChatGPT, Education, GPT-4, Large Language Models, Personalized Reflections, Procrastination},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642081,10.1145/3613904.3642081,acm,2024
524,Watch Your Mouth: Silent Speech Recognition with Depth Sensing,"@inproceedings{10.1145/3613904.3642092,
author = {Wang, Xue and Su, Zixiong and Rekimoto, Jun and Zhang, Yang},
title = {Watch Your Mouth: Silent Speech Recognition with Depth Sensing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642092},
doi = {10.1145/3613904.3642092},
abstract = {Silent speech recognition is a promising technology that decodes human speech without requiring audio signals, enabling private human-computer interactions. In this paper, we propose Watch Your Mouth, a novel method that leverages depth sensing to enable accurate silent speech recognition. By leveraging depth information, our method provides unique resilience against environmental factors such as variations in lighting and device orientations, while further addressing privacy concerns by eliminating the need for sensitive RGB data. We started by building a deep-learning model that locates lips using depth data. We then designed a deep learning pipeline to efficiently learn from point clouds and translate lip movements into commands and sentences. We evaluated our technique and found it effective across diverse sensor locations: On-Head, On-Wrist, and In-Environment. Watch Your Mouth outperformed the state-of-the-art RGB-based method, demonstrating its potential as an accurate and reliable input technique.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {323},
numpages = {15},
keywords = {Deep Learning, Depth Sensing, Input Techniques, Lip Reading, Silent Speech Recognition, Visual Speech Recognition},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642092,10.1145/3613904.3642092,acm,2024
525,STILE: Exploring and Debugging Social Biases in Pre-trained Text Representations,"@inproceedings{10.1145/3613904.3642111,
author = {Kabir, Samia and Li, Lixiang and Zhang, Tianyi},
title = {STILE: Exploring and Debugging Social Biases in Pre-trained Text Representations},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642111},
doi = {10.1145/3613904.3642111},
abstract = {The recent success of Natural Language Processing (NLP) relies heavily on pre-trained text representations such as word embeddings. However, pre-trained text representations may exhibit social biases and stereotypes, e.g., disproportionately associating gender with occupations. Though prior work presented various bias detection algorithms, they are limited to pre-defined biases and lack effective interaction support. In this work, we propose Stile, an interactive system that supports mixed-initiative bias discovery and debugging in pre-trained text representations. Stile provides users the flexibility to interactively define and customize biases to detect based on their interests. Furthermore, it provides a bird’s-eye view of detected biases in a Chord diagram and allows users to dive into the training data to investigate how a bias was developed. Our lab study and expert review confirm the usefulness and usability of Stile as an effective aid in identifying and understanding biases in pre-trained text representations.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {293},
numpages = {20},
keywords = {AI Fairness, Natural Language Processing, Word Embedding},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642111,10.1145/3613904.3642111,acm,2024
526,"Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks","@inproceedings{10.1145/3613904.3642116,
author = {Lee, Hao-Ping (Hank) and Yang, Yu-Ju and Von Davier, Thomas Serban and Forlizzi, Jodi and Das, Sauvik},
title = {Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642116},
doi = {10.1145/3613904.3642116},
abstract = {Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {775},
numpages = {19},
keywords = {AI incidents, Human-centered AI, Privacy, Privacy risks, Privacy taxonomy},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642116,10.1145/3613904.3642116,acm,2024
527,Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models,"@inproceedings{10.1145/3613904.3642134,
author = {Dhillon, Paramveer S. and Molaei, Somayeh and Li, Jiaqi and Golub, Maximilian and Zheng, Shaochun and Robert, Lionel Peter},
title = {Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642134},
doi = {10.1145/3613904.3642134},
abstract = {Advances in language modeling have paved the way for novel human-AI co-writing experiences. This paper explores how varying levels of scaffolding from large language models (LLMs) shape the co-writing process. Employing a within-subjects field experiment with a Latin square design, we asked participants (N=131) to respond to argumentative writing prompts under three randomly sequenced conditions: no AI assistance (control), next-sentence suggestions (low scaffolding), and next-paragraph suggestions (high scaffolding). Our findings reveal a U-shaped impact of scaffolding on writing quality and productivity (words/time). While low scaffolding did not significantly improve writing quality or productivity, high scaffolding led to significant improvements, especially benefiting non-regular writers and less tech-savvy users. No significant cognitive burden was observed while using the scaffolded writing tools, but a moderate decrease in text ownership and satisfaction was noted. Our results have broad implications for the design of AI-powered writing tools, including the need for personalized scaffolding mechanisms.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1044},
numpages = {18},
keywords = {Generative AI, Human-AI collaboration, co-writing, writing assistants},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642134,10.1145/3613904.3642134,acm,2024
528,"“As an AI language model, I cannot”: Investigating LLM Denials of User Requests","@inproceedings{10.1145/3613904.3642135,
author = {Wester, Joel and Schrills, Tim and Pohl, Henning and van Berkel, Niels},
title = {“As an AI language model, I cannot”: Investigating LLM Denials of User Requests},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642135},
doi = {10.1145/3613904.3642135},
abstract = {Users ask large language models (LLMs) to help with their homework, for lifestyle advice, or for support in making challenging decisions. Yet LLMs are often unable to fulfil these requests, either as a result of their technical inabilities or policies restricting their responses. To investigate the effect of LLMs denying user requests, we evaluate participants’ perceptions of different denial styles. We compare specific denial styles (baseline, factual, diverting, and opinionated) across two studies, respectively focusing on LLM’s technical limitations and their social policy restrictions. Our results indicate significant differences in users’ perceptions of the denials between the denial styles. The baseline denial, which provided participants with brief denials without any motivation, was rated significantly higher on frustration and significantly lower on usefulness, appropriateness, and relevance. In contrast, we found that participants generally appreciated the diverting denial style. We provide design recommendations for LLM denials that better meet peoples’ denial expectations.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {979},
numpages = {14},
keywords = {Breakdowns, Denials, Errors, GPT-4, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642135,10.1145/3613904.3642135,acm,2024
529,Critical Heritage Studies as a Lens to Understand Short Video Sharing of Intangible Cultural Heritage on Douyin,"@inproceedings{10.1145/3613904.3642138,
author = {Wang, Huanchen and Zhao, Minzhu and Hu, Wanyang and Ma, Yuxin and Lu, Zhicong},
title = {Critical Heritage Studies as a Lens to Understand Short Video Sharing of Intangible Cultural Heritage on Douyin},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642138},
doi = {10.1145/3613904.3642138},
abstract = {Intangible Cultural Heritage (ICH) faces numerous threats that can lead to its destruction. While the emergence of short video platforms provides opportunities for fostering innovation and communication among ICH practitioners and viewers, it is still understudied how different stakeholders present, explain, and manage ICH via short videos. To address this, we conduct a mixed-method study of ICH-related videos on Douyin, a popular short video platform in China with an extensive user base and wealth of ICH content. By adopting the Critical Heritage Studies (CHS) framework, we propose a taxonomy of frames that construct the landscape of ICH short videos and then investigate the interactions among different groups regarding power, identity, and knowledge. Additionally, we analyze viewer responses to different frames and groups based on audience metrics (e.g., # of likes and comments) and comments. Our research reveals that government-affiliated and indigenous groups dominate the promotion and presentation of ICH on Douyin. Contrary to previous literature, viewer responses show a preference for videos from external ICH groups and ordinary individuals, suggesting a tendency to counter authority and exclusivity associated with ICH. Moreover, it highlights a lack of sustainable debates and negotiations among different groups involved in ICH discourse. Situated within CHS, we provide design implications for ICH safeguarding and sustainability through short videos and online media.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {613},
numpages = {21},
keywords = {Intangible cultural heritage, critical theory, online video platforms},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642138,10.1145/3613904.3642138,acm,2024
530,Rehearsal: Simulating Conflict to Teach Conflict Resolution,"@inproceedings{10.1145/3613904.3642159,
author = {Shaikh, Omar and Chai, Valentino Emil and Gelfand, Michele and Yang, Diyi and Bernstein, Michael S.},
title = {Rehearsal: Simulating Conflict to Teach Conflict Resolution},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642159},
doi = {10.1145/3613904.3642159},
abstract = {Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill—one that can be learned through deliberate practice—but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual “what if?” scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {920},
numpages = {20},
keywords = {conflict resolution, interests-rights-power, large language models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642159,10.1145/3613904.3642159,acm,2024
531,"Generative AI in the Wild: Prospects, Challenges, and Strategies","@inproceedings{10.1145/3613904.3642160,
author = {Sun, Yuan and Jang, Eunchae and Ma, Fenglong and Wang, Ting},
title = {Generative AI in the Wild: Prospects, Challenges, and Strategies},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642160},
doi = {10.1145/3613904.3642160},
abstract = {Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects – GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges – Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies – In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {747},
numpages = {16},
keywords = {Generative AI, Human-AI Collaboration, Transparency, User Agency},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642160,10.1145/3613904.3642160,acm,2024
532,“They only care to show us the wheelchair”: disability representation in text-to-image AI models,"@inproceedings{10.1145/3613904.3642166,
author = {Mack, Kelly Avery and Qadri, Rida and Denton, Remi and Kane, Shaun K. and Bennett, Cynthia L.},
title = {“They only care to show us the wheelchair”: disability representation in text-to-image AI models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642166},
doi = {10.1145/3613904.3642166},
abstract = {This paper reports on disability representation in images output from text-to-image (T2I) generative AI systems. Through eight focus groups with 25 people with disabilities, we found that models repeatedly presented reductive archetypes for different disabilities. Often these representations reflected broader societal stereotypes and biases, which our participants were concerned to see reproduced through T2I. Our participants discussed further challenges with using these models including the current reliance on prompt engineering to reach satisfactorily diverse results. Finally, they offered suggestions for how to improve disability representation with solutions like showing multiple, heterogeneous images for a single prompt and including the prompt with images generated. Our discussion reflects on tensions and tradeoffs we found among the diverse perspectives shared to inform future research on representation-oriented generative AI system evaluation metrics and development processes.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {288},
numpages = {23},
keywords = {AI harms, algorithmic harms, disability representation, generative AI, human-centered AI, text-to-image models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642166,10.1145/3613904.3642166,acm,2024
533,Enhancing UX Evaluation Through Collaboration with Conversational AI Assistants: Effects of Proactive Dialogue and Timing,"@inproceedings{10.1145/3613904.3642168,
author = {Kuang, Emily and Li, Minghao and Fan, Mingming and Shinohara, Kristen},
title = {Enhancing UX Evaluation Through Collaboration with Conversational AI Assistants: Effects of Proactive Dialogue and Timing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642168},
doi = {10.1145/3613904.3642168},
abstract = {Usability testing is vital for enhancing the user experience (UX) of interactive systems. However, analyzing test videos is complex and resource-intensive. Recent AI advancements have spurred exploration into human-AI collaboration for UX analysis, particularly through natural language. Unlike user-initiated dialogue, our study investigated the potential of proactive conversational assistants to aid UX evaluators through automatic suggestions at three distinct times: before, in sync with, and after potential usability problems. We conducted a hybrid Wizard-of-Oz study involving 24 UX evaluators, using ChatGPT to generate automatic problem suggestions and a human actor to respond to impromptu questions. While timing did not significantly impact analytic performance, suggestions appearing after potential problems were preferred, enhancing trust and efficiency. Participants found the automatic suggestions useful, but they collectively identified more than twice as many problems, underscoring the irreplaceable role of human expertise. Our findings also offer insights into future human-AI collaborative tools for UX evaluation.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {3},
numpages = {16},
keywords = {Human-AI collaboration, Proactive conversational assistants, Usability testing, User experience},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642168,10.1145/3613904.3642168,acm,2024
534,Epigraphics: Message-Driven Infographics Authoring,"@inproceedings{10.1145/3613904.3642172,
author = {Zhou, Tongyu and Huang, Jeff and Chan, Gromit Yeuk-Yin},
title = {Epigraphics: Message-Driven Infographics Authoring},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642172},
doi = {10.1145/3613904.3642172},
abstract = {The message a designer wants to convey plays a pivotal role in directing the design of an infographic, yet most authoring workflows start with creating the visualizations or graphics first without gauging whether they fit the message. To address this gap, we propose Epigraphics, a web-based authoring system that treats an “epigraph” as the first-class object, and uses it to guide infographic asset creation, editing, and syncing. The system uses the text-based message to recommend visualizations, graphics, data filters, color palettes, and animations. It further supports between-asset interactions and fine-tuning such as recoloring, highlighting, and animation syncing that enhance the aesthetic cohesiveness of the assets. A gallery and case studies show that our system can produce infographics inspired by existing popular ones, and a task-based usability study with 10 designers show that a text-sourced workflow can standardize content, empower users to think more about the big picture, and facilitate rapid prototyping.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {200},
numpages = {18},
keywords = {data visualization, infographics authoring, visual storytelling},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642172,10.1145/3613904.3642172,acm,2024
535,Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs,"@inproceedings{10.1145/3613904.3642191,
author = {Kotturi, Yasmine and Anderson, Angel and Ford, Glenn and Skirpan, Michael and Bigham, Jeffrey P},
title = {Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642191},
doi = {10.1145/3613904.3642191},
abstract = {Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while simultaneously deconstructing the veneer of simplicity to address the many operational skills needed for successful application.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1014},
numpages = {16},
keywords = {community-based research, entrepreneurship, generative artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642191,10.1145/3613904.3642191,acm,2024
536,Teaching artificial intelligence in extracurricular contexts through narrative-based learnersourcing,"@inproceedings{10.1145/3613904.3642198,
author = {Moore, Dylan Edward and Moore, Sophia R. R. and Ireen, Bansharee and Iskandar, Winston P. and Artazyan, Grigory and Murnane, Elizabeth L.},
title = {Teaching artificial intelligence in extracurricular contexts through narrative-based learnersourcing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642198},
doi = {10.1145/3613904.3642198},
abstract = {Collaborative technology provides powerful opportunities to engage young people in active learning experiences that are inclusive, immersive, and personally meaningful. In particular, interactive narratives have proven to be effective scaffolds for learning, and learnersourcing has emerged as a promising student-driven approach to enable personalized education and quality control at-scale. We introduce the first synthesis of these ideas in the context of teaching artificial intelligence (AI), which is now seen as a critical component of 21st-century education. Specifically, we explore the design of a narrative-based learnersourcing platform where engagement is centered around a learner-made choose-your-own-adventure story. In grounding our approach, we draw from pedagogical literature, digital storytelling, and recent work on learnersourcing. We report on our iterative, learner-centered design process as well as our study findings that demonstrate the platform’s positive effects on knowledge gains, interest in AI concepts, and the overall user experience of narrative-based learnersourcing technology.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {28},
keywords = {AI literacy, STEM education, collaborative learning, digital narratives, learnersourcing, online learning tools, storytelling},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642198,10.1145/3613904.3642198,acm,2024
537,Bystanders of Online Moderation: Examining the Effects of Witnessing Post-Removal Explanations,"@inproceedings{10.1145/3613904.3642204,
author = {Jhaver, Shagun and Rathi, Himanshu and Saha, Koustuv},
title = {Bystanders of Online Moderation: Examining the Effects of Witnessing Post-Removal Explanations},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642204},
doi = {10.1145/3613904.3642204},
abstract = {Prior research on transparency in content moderation has demonstrated the benefits of offering post-removal explanations to sanctioned users. In this paper, we examine whether the influence of such explanations transcends those who are moderated to the bystanders who witness such explanations. We conduct a quasi-experimental study on two popular Reddit communities (r/AskReddit and r/science) by collecting their data spanning 13 months—a total of 85.5M posts made by 5.9M users. Our causal-inference analyses show that bystanders significantly increase their posting activity and interactivity levels as compared to their matched control set of users. In line with previous applications of Deterrence Theory on digital platforms, our findings highlight that understanding the rationales behind sanctions on other users significantly shapes observers’ behaviors. We discuss the theoretical implications and design recommendations of this research, focusing on how investing more efforts in post-removal explanations can help build thriving online communities.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {191},
numpages = {9},
keywords = {causal-inference, content moderation, social media, transparency},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642204,10.1145/3613904.3642204,acm,2024
538,Stochastic Machine Witnesses at Work: Today's Critiques of Taylorism are Inadequate for Workplace Surveillance Epistemologies of the Future,"@inproceedings{10.1145/3613904.3642206,
author = {Gould, Sandy J. J.},
title = {Stochastic Machine Witnesses at Work: Today's Critiques of Taylorism are Inadequate for Workplace Surveillance Epistemologies of the Future},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642206},
doi = {10.1145/3613904.3642206},
abstract = {I argue that epistemologies of workplace surveillance are shifting in fundamental ways, and so critiques must shift accordingly. I begin the paper by relating Scientific Management to Human-Centred Computing’s ways of knowing through a study of ‘metaverse’ virtual reality workplaces. From this, I develop two observations. The first is that today’s workplace measurement science does not resemble the science that Taylor developed for Scientific Management. Contemporary workplace science is more passive, more intermediated and less controlled. The second observation is that new forms of workplace measurement challenge the norms of empirical science. Instead of having credentialed human witnesses observe phenomena and agree facts about them, we instead make outsourced, uncredentialed stochastic machine witnesses responsible for producing facts about work. With these observations in mind, I assert that critiques of workplace surveillance still framed by Taylorism will not be fit for interrogating workplace surveillance practices of the future.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {578},
numpages = {12},
keywords = {Metaverse, Neo-Taylorism, Scientific Management, Taylorism, Ubiquitous Computing, Work Measurement, Workplace Surveillance},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642206,10.1145/3613904.3642206,acm,2024
539,TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision People,"@inproceedings{10.1145/3613904.3642222,
author = {Zhao, Yichun and Nacenta, Miguel A and Sukhai, Mahadeo A. and Somanath, Sowmya},
title = {TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision People},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642222},
doi = {10.1145/3613904.3642222},
abstract = {Diagrams often appear as node-link representations in contexts such as taxonomies, mind maps and networks in textbooks. Despite their pervasiveness, they present accessibility challenges for blind and low-vision people. To address this challenge, we introduce Touch-and-Audio-based Diagram Access (TADA), a tablet-based interactive system that makes diagram exploration accessible through musical tones and speech. We designed TADA informed by an interview study with 15 participants who shared their challenges and strategies with diagrams. TADA enables people to access a diagram by: i) engaging in open-ended touch-based explorations, ii) searching for nodes, iii) navigating between nodes and iv) filtering information. We evaluated TADA with 25 participants and found it useful for gaining different perspectives on diagrammatic information.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {45},
numpages = {20},
keywords = {Accessibility, Artifact or System, Assistive Technologies, Gestures, Haptics, Individuals with Disabilities, Pointing, Touch},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642222,10.1145/3613904.3642222,acm,2024
540,"ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming
  Learning for Children Aged 6-12"," @inproceedings{Chen_2024, series={CHI ’24}, title={ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12}, url={http://dx.doi.org/10.1145/3613904.3642229}, DOI={10.1145/3613904.3642229}, booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems}, publisher={ACM}, author={Chen, Liuqing and Xiao, Shuhong and Chen, Yunnong and Song, Yaxuan and Wu, Ruoyu and Sun, Lingyun}, year={2024}, month=may, collection={CHI ’24} }
",http://arxiv.org/pdf/2402.04975v1.pdf,10.1145/3613904.3642229,"arxiv, acm, scopus",2024
541,VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models,"@inproceedings{10.1145/3613904.3642235,
author = {Wang, Zhan and Yuan, Lin-Ping and Wang, Liangwei and Jiang, Bingchuan and Zeng, Wei},
title = {VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642235},
doi = {10.1145/3613904.3642235},
abstract = {Tour guidance in virtual museums encourages multi-modal interactions to boost user experiences, concerning engagement, immersion, and spatial awareness. Nevertheless, achieving the goal is challenging due to the complexity of comprehending diverse user needs and accommodating personalized user preferences. Informed by a formative study that characterizes guidance-seeking contexts, we establish a multi-modal interaction design framework for virtual tour guidance. We then design VirtuWander, a two-stage innovative system using domain-oriented large language models to transform user inquiries into diverse guidance-seeking contexts and facilitate multi-modal interactions. The feasibility and versatility of VirtuWander are demonstrated with virtual guiding examples that encompass various touring scenarios and cater to personalized preferences. We further evaluate VirtuWander through a user study within an immersive simulated museum. The results suggest that our system enhances engaging virtual tour experiences through personalized communication and knowledgeable assistance, indicating its potential for expanding into real-world scenarios.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {612},
numpages = {20},
keywords = {large language models, multi-modal feedback, virtual museum},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642235,10.1145/3613904.3642235,acm,2024
542,VAID: Indexing View Designs in Visual Analytics System,"@inproceedings{10.1145/3613904.3642237,
author = {Ying, Lu and Wu, Aoyu and Li, Haotian and Deng, Zikun and Lan, Ji and Wu, Jiang and Wang, Yong and Qu, Huamin and Deng, Dazhen and Wu, Yingcai},
title = {VAID: Indexing View Designs in Visual Analytics System},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642237},
doi = {10.1145/3613904.3642237},
abstract = {Visual analytics (VA) systems have been widely used in various application domains. However, VA systems are complex in design, which imposes a serious problem: although the academic community constantly designs and implements new designs, the designs are difficult to query, understand, and refer to by subsequent designers. To mark a major step forward in tackling this problem, we index VA designs in an expressive and accessible way, transforming the designs into a structured format. We first conducted a workshop study with VA designers to learn user requirements for understanding and retrieving professional designs in VA systems. Thereafter, we came up with an index structure VAID to describe advanced and composited visualization designs with comprehensive labels about their analytical tasks and visual designs. The usefulness of VAID was validated through user studies. Our work opens new perspectives for enhancing the accessibility and reusability of professional visualization designs.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {198},
numpages = {15},
keywords = {Visual Analytics, Visualization Design, Visualization Retrieval},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642237,10.1145/3613904.3642237,acm,2024
543,"Lies, Deceit, and Hallucinations: Player Perception and Expectations Regarding Trust and Deception in Games","@inproceedings{10.1145/3613904.3642253,
author = {Yin, Michael and Wang, Emi and Ng, Chuoxi and Xiao, Robert},
title = {Lies, Deceit, and Hallucinations: Player Perception and Expectations Regarding Trust and Deception in Games},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642253},
doi = {10.1145/3613904.3642253},
abstract = {Lying and deception are important parts of social interaction; when applied to storytelling mediums such as video games, such elements can add complexity and intrigue. We developed a game, “AlphaBetaCity”, in which non-playable characters (NPCs) made various false statements, and used this game to investigate perceptions of deceptive behaviour. We used a mix of human-written dialogue incorporating deliberate falsehoods and LLM-written scripts with (human-approved) hallucinated responses. The degree of falsehoods varied between believable but untrue statements to outright fabrications. 29 participants played the game and were interviewed about their experiences. Participants discussed methods for developing trust and gauging NPC truthfulness. Whereas perceived intentional false statements were often attributed towards narrative and gameplay effects, seemingly unintentional false statements generally mismatched participants’ mental models and lacked inherent meaning. We discuss how the perception of intentionality, the audience demographic, and the desire for meaning are major considerations when designing video games with falsehoods.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {781},
numpages = {15},
keywords = {LLM hallucinations, large language models, lying, player experience, video games},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642253,10.1145/3613904.3642253,acm,2024
544,PANDALens: Towards AI-Assisted In-Context Writing on OHMD During Travels,"@inproceedings{10.1145/3613904.3642320,
author = {Cai, Runze and Janaka, Nuwan and Chen, Yang and Wang, Lucia and Zhao, Shengdong and Liu, Can},
title = {PANDALens: Towards AI-Assisted In-Context Writing on OHMD During Travels},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642320},
doi = {10.1145/3613904.3642320},
abstract = {While effective for recording and sharing experiences, traditional in-context writing tools are relatively passive and unintelligent, serving more like instruments rather than companions. This reduces primary task (e.g., travel) enjoyment and hinders high-quality writing. Through formative study and iterative development, we introduce PANDALens, a Proactive AI Narrative Documentation Assistant built on an Optical See-Through Head Mounted Display that supports personalized documentation in everyday activities. PANDALens observes multimodal contextual information from user behaviors and environment to confirm interests and elicit contemplation, and employs Large Language Models to transform such multimodal information into coherent narratives with significantly reduced user effort. A real-world travel scenario comparing PANDALens with a smartphone alternative confirmed its effectiveness in improving writing quality and travel enjoyment while minimizing user effort. Accordingly, we propose design guidelines for AI-assisted in-context writing, highlighting the potential of transforming them from tools to intelligent companions.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1053},
numpages = {24},
keywords = {AI, HMD, Human-AI collaborative writing, in-context writing, large language model, multimodal information, smart glasses, travel blog},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642320,10.1145/3613904.3642320,acm,2024
545,"Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT","@inproceedings{10.1145/3613904.3642332,
author = {Belghith, Yasmine and Mahdavi Goloujeh, Atefeh and Magerko, Brian and Long, Duri and Mcklin, Tom and Roberts, Jessica},
title = {Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642332},
doi = {10.1145/3613904.3642332},
abstract = {As generative AI rapidly enters everyday life, educational interventions for teaching about AI need to cater to how young people, in particular middle schoolers who are at a critical age for reasoning skills and identity formation, conceptualize and interact with AI. We conducted nine focus groups with 24 middle school students to elicit their interests, conceptions of, and approaches to a popular generative AI tool, ChatGPT. We highlight a) personally and culturally-relevant topics to this population, b) three distinct approaches in students’ open-ended interactions with ChatGPT: AI testing-oriented, AI socializing-oriented, and content exploring-oriented, and 3) an improved understanding of youths’ conceptions and misconceptions of generative AI. While misconceptions highlight gaps in understanding what generative AI is and how it works, most learners show interest in learning about what AI is and what it can do. We discuss the implications of these conceptions for designing AI literacy interventions in museums.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {17},
keywords = {AI literacy, ChatGPT, Child-AI Interaction, Conceptions of AI, Conversational Agents (CAs), Generative AI, Informal Learning, Large Language Models (LLMs)},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642332,10.1145/3613904.3642332,acm,2024
546,Farsight: Fostering Responsible AI Awareness During AI Application Prototyping,"@inproceedings{10.1145/3613904.3642335,
author = {Wang, Zijie J. and Kulkarni, Chinmay and Wilcox, Lauren and Terry, Michael and Madaio, Michael},
title = {Farsight: Fostering Responsible AI Awareness During AI Application Prototyping},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642335},
doi = {10.1145/3613904.3642335},
abstract = {Prompt-based interfaces for Large Language Models (LLMs) have made prototyping and building AI-powered applications easier than ever before. However, identifying potential harms that may arise from AI applications remains a challenge, particularly during prompt-based prototyping. To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping. Based on a user’s prompt, Farsight highlights news articles about relevant AI incidents and allows users to explore and edit LLM-generated use cases, stakeholders, and harms. We report design insights from a co-design study with 10 AI prototypers and findings from a user study with 42 AI prototypers. After using Farsight, AI prototypers in our user study are better able to independently identify potential harms associated with a prompt and find our tool more useful and usable than existing resources. Their qualitative feedback also highlights that Farsight encourages them to focus on end-users and think beyond immediate harms. We discuss these findings and reflect on their implications for designing AI prototyping experiences that meaningfully engage with AI harms. Farsight is publicly accessible at: https://pair-code.github.io/farsight.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {976},
numpages = {40},
keywords = {Human-AI Collaboration, Large Language Models, Responsible AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642335,10.1145/3613904.3642335,acm,2024
547,The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction,"@inproceedings{10.1145/3613904.3642336,
author = {Cuadra, Andrea and Wang, Maria and Stein, Lynn Andrea and Jung, Malte F. and Dell, Nicola and Estrin, Deborah and Landay, James A.},
title = {The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642336},
doi = {10.1145/3613904.3642336},
abstract = {From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {446},
numpages = {18},
keywords = {AI, Affective Computing, Automation, Autonomous Agents, Chatbots, Conversational Agents, Conversational User Interfaces, Disability, Emotion, Empathy, Ethics, Gender, Health, Human-AI Interaction, Human-Computer Interaction, Identity, LLMs, Marginalization, Mental Health, Natural Language Processing, Personalization, Power and Privilege, Religion, Social Robots, Technological Harm, Ubiquitous Computing, User Experience Design, Values in Design, Voice Assistants, Wellbeing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642336,10.1145/3613904.3642336,acm,2024
548,Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education,"@inproceedings{10.1145/3613904.3642349,
author = {Jin, Hyoungwook and Lee, Seonghee and Shin, Hyungyu and Kim, Juho},
title = {Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642349},
doi = {10.1145/3613904.3642349},
abstract = {This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs’ expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs’ knowledge and makes them initiate “why” and “how” questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo’s problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo’s questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {652},
numpages = {28},
keywords = {AI and Education, Generative AI, Human-AI interaction, LLM agents},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642349,10.1145/3613904.3642349,"acm, scopus",2024
549,‘We Do Not Have the Capacity to Monitor All Media’: A Design Case Study on Cyber Situational Awareness in Computer Emergency Response Teams,"@inproceedings{10.1145/3613904.3642368,
author = {Kaufhold, Marc-Andr\'{e} and Riebe, Thea and Bayer, Markus and Reuter, Christian},
title = {‘We Do Not Have the Capacity to Monitor All Media’: A Design Case Study on Cyber Situational Awareness in Computer Emergency Response Teams},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642368},
doi = {10.1145/3613904.3642368},
abstract = {Computer Emergency Response Teams (CERTs) provide advisory, preventive and reactive cybersecurity services for authorities, citizens, and businesses. However, their responsibility of monitoring, analyzing, and communicating cyber threats have become challenging due to the growing volume and varying quality of information disseminated through public channels. Based on a design case study conducted from 2021 to 2023, this paper combines three iterations of expert interviews, design workshops and cognitive walkthroughs to design an automated, cross-platform and real-time cybersecurity dashboard. By adopting the notion of cyber situational awareness, the study extracts user requirements and design heuristics for enhanced threat awareness and mission awareness in CERTs, discussing the aspects of source integration, data management, customizable visualization, relationship awareness, information assessment, software integration, (inter-)organizational collaboration, and communication of stakeholder warnings.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {580},
numpages = {16},
keywords = {Computer Emergency Response Teams, Cyber Situational Awareness, Design Case Studies, Security and Privacy},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642368,10.1145/3613904.3642368,acm,2024
550,"Learning Agent-based Modeling with LLM Companions: Experiences of
  Novices and Experts Using ChatGPT & NetLogo Chat"," @inproceedings{Chen_2024, series={CHI ’24}, title={Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat}, url={http://dx.doi.org/10.1145/3613904.3642377}, DOI={10.1145/3613904.3642377}, booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems}, publisher={ACM}, author={Chen, John and Lu, Xi and Du, Yuzhou and Rejtig, Michael and Bagley, Ruth and Horn, Mike and Wilensky, Uri}, year={2024}, month=may, collection={CHI ’24} }
",http://arxiv.org/pdf/2401.17163v2.pdf,10.1145/3613904.3642377,"arxiv, acm, scopus",2024
551,A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education,"@inproceedings{10.1145/3613904.3642379,
author = {Hedderich, Michael A. and Bazarova, Natalie N. and Zou, Wenting and Shim, Ryun and Ma, Xinda and Yang, Qian},
title = {A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642379},
doi = {10.1145/3613904.3642379},
abstract = {Cyberbullying harms teenagers’ mental health, and teaching them upstanding intervention is crucial. Wizard-of-Oz studies show chatbots can scale up personalized and interactive cyberbullying education, but implementing such chatbots is a challenging and delicate task. We created a no-code chatbot design tool for K-12 teachers. Using large language models and prompt chaining, our tool allows teachers to prototype bespoke dialogue flows and chatbot utterances. In offering this tool, we explore teachers’ distinctive needs when designing chatbots to assist their teaching, and how chatbot design tools might better support them. Our findings reveal that teachers welcome the tool enthusiastically. Moreover, they see themselves as playwrights guiding both the students’ and the chatbot’s behaviors, while allowing for some improvisation. Their goal is to enable students to rehearse both desirable and undesirable reactions to cyberbullying in a safe environment. We discuss the design opportunities LLM-Chains offer for empowering teachers and the research opportunities this work opens up.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {668},
numpages = {17},
keywords = {chatbot, cyberbullying, education, large language models, teachers},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642379,10.1145/3613904.3642379,acm,2024
552,"“It's a Fair Game”, or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents","@inproceedings{10.1145/3613904.3642385,
author = {Zhang, Zhiping and Jia, Michelle and Lee, Hao-Ping (Hank) and Yao, Bingsheng and Das, Sauvik and Lerner, Ada and Wang, Dakuo and Li, Tianshi},
title = {“It's a Fair Game”, or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642385},
doi = {10.1145/3613904.3642385},
abstract = {The widespread use of Large Language Model (LLM)-based conversational agents (CAs), especially in high-stakes domains, raises many privacy concerns. Building ethical LLM-based CAs that respect user privacy requires an in-depth understanding of the privacy risks that concern users the most. However, existing research, primarily model-centered, does not provide insight into users’ perspectives. To bridge this gap, we analyzed sensitive disclosures in real-world ChatGPT conversations and conducted semi-structured interviews with 19 LLM-based CA users. We found that users are constantly faced with trade-offs between privacy, utility, and convenience when using LLM-based CAs. However, users’ erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks. Additionally, the human-like interactions encouraged more sensitive disclosures, which complicated users’ ability to navigate the trade-offs. We discuss practical design guidelines and the needs for paradigm shifts to protect the privacy of LLM-based CA users.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {156},
numpages = {26},
keywords = {Artificial general intelligence (AGI), Chatbots, Contextual integrity, Conversational agents, Empirical studies, Interviews, Large language models (LLM), Privacy, Privacy risks, Privacy-enhancing technologies},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642385,10.1145/3613904.3642385,acm,2024
553,Writer-Defined AI Personas for On-Demand Feedback Generation,"@inproceedings{10.1145/3613904.3642406,
author = {Benharrak, Karim and Zindulka, Tim and Lehmann, Florian and Heuer, Hendrik and Buschek, Daniel},
title = {Writer-Defined AI Personas for On-Demand Feedback Generation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642406},
doi = {10.1145/3613904.3642406},
abstract = {Compelling writing is tailored to its audience. This is challenging, as writers may struggle to empathize with readers, get feedback in time, or gain access to the target group. We propose a concept that generates on-demand feedback, based on writer-defined AI personas of any target audience. We explore this concept with a prototype (using GPT-3.5) in two user studies (N=5 and N=11): Writers appreciated the concept and strategically used personas for getting different perspectives. The feedback was seen as helpful and inspired revisions of text and personas, although it was often verbose and unspecific. We discuss the impact of on-demand feedback, the limited representativity of contemporary AI systems, and further ideas for defining AI personas. This work contributes to the vision of supporting writers with AI by expanding the socio-technical perspective in AI tool design: To empower creators, we also need to keep in mind their relationship to an audience.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1049},
numpages = {18},
keywords = {Human-AI interaction, Large language models, Personas, Text feedback, Writing assistance},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642406,10.1145/3613904.3642406,acm,2024
554,AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation,"@inproceedings{10.1145/3613904.3642414,
author = {Shaer, Orit and Cooper, Angelora and Mokryn, Osnat and Kun, Andrew L and Ben Shoshan, Hagit},
title = {AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642414},
doi = {10.1145/3613904.3642414},
abstract = {The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process – the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implications for HCI education and practice.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1050},
numpages = {17},
keywords = {Brainwriting, LLM, human-AI collaboration},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642414,10.1145/3613904.3642414,acm,2024
555,Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention,"@inproceedings{10.1145/3613904.3642420,
author = {Jo, Eunkyung and Jeong, Yuin and Park, Sohyun and Epstein, Daniel A. and Kim, Young-Ho},
title = {Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642420},
doi = {10.1145/3613904.3642420},
abstract = {Recent large language models (LLMs) offer the potential to support public health monitoring by facilitating health disclosure through open-ended conversations but rarely preserve the knowledge gained about individuals across repeated interactions. Augmenting LLMs with long-term memory (LTM) presents an opportunity to improve engagement and self-disclosure, but we lack an understanding of how LTM impacts people’s interaction with LLM-driven chatbots in public health interventions. We examine the case of CareCall—an LLM-driven voice chatbot with LTM—through the analysis of 1,252 call logs and interviews with nine users. We found that LTM enhanced health disclosure and fostered positive perceptions of the chatbot by offering familiarity. However, we also observed challenges in promoting self-disclosure through LTM, particularly around addressing chronic health conditions and privacy concerns. We discuss considerations for LTM integration in LLM-driven chatbots for public health monitoring, including carefully deciding what topics need to be remembered in light of public health goals.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {440},
numpages = {21},
keywords = {Chatbot, Check-up calls, Large language models, Long-term memory, Open-domain dialog systems, Public health, Social isolation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642420,10.1145/3613904.3642420,acm,2024
556,HILL: A Hallucination Identifier for Large Language Models,"@inproceedings{10.1145/3613904.3642428,
author = {Leiser, Florian and Eckhardt, Sven and Leuthe, Valentin and Knaeble, Merlin and M\""{a}dche, Alexander and Schwabe, Gerhard and Sunyaev, Ali},
title = {HILL: A Hallucination Identifier for Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642428},
doi = {10.1145/3613904.3642428},
abstract = {Large language models (LLMs) are prone to hallucinations, i.e., nonsensical, unfaithful, and undesirable text. Users tend to overrely on LLMs and corresponding hallucinations which can lead to misinterpretations and errors. To tackle the problem of overreliance, we propose HILL, the ""Hallucination Identifier for Large Language Models"". First, we identified design features for HILL with a Wizard of Oz approach with nine participants. Subsequently, we implemented HILL based on the identified design features and evaluated HILL’s interface design by surveying 17 participants. Further, we investigated HILL’s functionality to identify hallucinations based on an existing question-answering dataset and five user interviews. We find that HILL can correctly identify and highlight hallucinations in LLM responses which enables users to handle LLM responses with more caution. With that, we propose an easy-to-implement adaptation to existing LLMs and demonstrate the relevance of user-centered designs of AI artifacts.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {482},
numpages = {13},
keywords = {Artifact Development, Artificial Hallucinations, ChatGPT, Large Language Models, Wizard of Oz},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642428,10.1145/3613904.3642428,acm,2024
557,"Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education","@inproceedings{10.1145/3613904.3642438,
author = {Han, Ariel and Zhou, Xiaofei and Cai, Zhenyao and Han, Shenshen and Ko, Richard and Corrigan, Seth and Peppler, Kylie A},
title = {Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642438},
doi = {10.1145/3613904.3642438},
abstract = {The viral launch of new generative AI (GAI) systems, such as ChatGPT and Text-to-Image (TTL) generators, sparked questions about how they can be effectively incorporated into writing education. However, it is still unclear how teachers, parents, and students perceive and suspect GAI systems in elementary school settings. We conducted a workshop with twelve families (parent-child dyads) with children ages 8-12 and interviewed sixteen teachers in order to understand each stakeholder’s perspectives and opinions on GAI systems for learning and teaching writing. We found that the GAI systems could be beneficial in generating adaptable teaching materials for teachers, enhancing ideation, and providing students with personalized, timely feedback. However, there are concerns over authorship, students’ agency in learning, and uncertainty concerning bias and misinformation. In this article, we discuss design strategies to mitigate these constraints by implementing an adults-oversight system, balancing AI-role allocation, and facilitating customization to enhance students’ agency over writing projects.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {678},
numpages = {17},
keywords = {Artificial Intelligence, Generative AI, K-12 Education},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642438,10.1145/3613904.3642438,acm,2024
558,Generative Echo Chamber? Effect of LLM-Powered Search Systems on Diverse Information Seeking,"@inproceedings{10.1145/3613904.3642459,
author = {Sharma, Nikhil and Liao, Q. Vera and Xiao, Ziang},
title = {Generative Echo Chamber? Effect of LLM-Powered Search Systems on Diverse Information Seeking},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642459},
doi = {10.1145/3613904.3642459},
abstract = {Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search. However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers—limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search. We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user’s view change the effect. Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias. These results present critical implications for the development of LLMs and conversational search systems, and the policy governing these technologies.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1033},
numpages = {17},
keywords = {Confirmation Bias, Conversational Search, Echo Chamber Effect, Generative AI, Information Diversity, Information Seeking, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642459,10.1145/3613904.3642459,acm,2024
559,Design Principles for Generative AI Applications,"@inproceedings{10.1145/3613904.3642466,
author = {Weisz, Justin D. and He, Jessica and Muller, Michael and Hoefer, Gabriela and Miles, Rachel and Geyer, Werner},
title = {Design Principles for Generative AI Applications},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642466},
doi = {10.1145/3613904.3642466},
abstract = {Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {378},
numpages = {22},
keywords = {Generative AI, design principles, foundation models, human-centered AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642466,10.1145/3613904.3642466,acm,2024
560,"CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models","@inproceedings{10.1145/3613904.3642472,
author = {Ha, Juhye and Jeon, Hyeon and Han, Daeun and Seo, Jinwook and Oh, Changhoon},
title = {CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642472},
doi = {10.1145/3613904.3642472},
abstract = {Large language models (LLMs) have facilitated significant strides in generating conversational agents, enabling seamless, contextually relevant dialogues across diverse topics. However, the existing LLM-driven conversational agents have fixed personalities and functionalities, limiting their adaptability to individual user needs. Creating personalized agent personas with distinct expertise or traits can address this issue. Nonetheless, we lack knowledge of how people customize and interact with agent personas. In this research, we investigated how users customize agent personas and their impact on interaction quality, diversity, and dynamics. To this end, we developed CloChat, an interface supporting easy and accurate customization of agent personas in LLMs. We conducted a study comparing how participants interact with CloChat and ChatGPT. The results indicate that participants formed emotional bonds with the customized agents, engaged in more dynamic dialogues, and showed interest in sustaining interactions. These findings contribute to design implications for future systems with conversational agents using LLMs.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {305},
numpages = {24},
keywords = {Conversational Agents, Large Language Models, Persona, Persona Customization},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642472,10.1145/3613904.3642472,acm,2024
561,Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI,"@inproceedings{10.1145/3613904.3642480,
author = {Chen, Qing and Shuai, Wei and Zhang, Jiyao and Sun, Zhida and Cao, Nan},
title = {Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642480},
doi = {10.1145/3613904.3642480},
abstract = {Unfamiliar measurements usually hinder readers from grasping the scale of the numerical data, understanding the content, and feeling engaged with the context. To enhance data comprehension and communication, we leverage analogies to bridge the gap between abstract data and familiar measurements. In this work, we first conduct semi-structured interviews with design experts to identify design problems and summarize design considerations. Then, we collect an analogy dataset of 138 cases from various online sources. Based on the collected dataset, we characterize a design space for creating data analogies. Next, we build a prototype system, AnalogyMate, that automatically suggests data analogies, their corresponding design solutions, and generated visual representations powered by generative AI. The study results show the usefulness of AnalogyMate in aiding the creation process of data analogies and the effectiveness of data analogy in enhancing data comprehension and communication.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {377},
numpages = {14},
keywords = {creativity support, interview, lab study, prototyping/implementation, qualitative methods, quantitative methods},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642480,10.1145/3613904.3642480,acm,2024
562,Debate Chatbots to Facilitate Critical Thinking on YouTube: Social Identity and Conversational Style Make A Difference,"@inproceedings{10.1145/3613904.3642513,
author = {Tanprasert, Thitaree and Fels, Sidney S and Sinnamon, Luanne and Yoon, Dongwook},
title = {Debate Chatbots to Facilitate Critical Thinking on YouTube: Social Identity and Conversational Style Make A Difference},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642513},
doi = {10.1145/3613904.3642513},
abstract = {Exposure to diverse perspectives is helpful for bursting the filter bubble in online public video platforms. The recent advancement of Large Language Models (LLMs) illuminates the potential of creating a debate chatbot that prompts users to critically examine their stances on a topic formed by watching videos. However, whether the viewer is influenced by the chatbot may depend on its persona. In this paper, we investigated the effect of two relevant persona attributes - social identity and rhetorical styles - on critical thinking. In a mixed-methods study (n=36), we found that chatbots with outgroup (vs. ingroup) identity (t(33)=-2.33, p=0.03) and persuasive (vs. eristic) rhetoric (t(44)=1.98, p=0.05) induced critical thinking most effectively, making participants re-examine their arguments. However, participants’ stances remain largely unaffected, likely due to the chatbot’s lack of contextual knowledge and human touch. Our paper provides empirical groundwork for designing chatbot persona for remedying filter bubbles in online communities.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {805},
numpages = {24},
keywords = {agent personas, conversational agents, critical thinking, filter bubble, online public videos},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642513,10.1145/3613904.3642513,acm,2024
563,AudioXtend: Assisted Reality Visual Accompaniments for Audiobook Storytelling During Everyday Routine Tasks,"@inproceedings{10.1145/3613904.3642514,
author = {Tan, Felicia Fang-Yi and Xu, Peisen and Ram, Ashwin and Suen, Wei Zhen and Zhao, Shengdong and Huang, Yun and Hurter, Christophe},
title = {AudioXtend: Assisted Reality Visual Accompaniments for Audiobook Storytelling During Everyday Routine Tasks},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642514},
doi = {10.1145/3613904.3642514},
abstract = {The rise of multitasking in contemporary lifestyles has positioned audio-first content as an essential medium for information consumption. We present AudioXtend, an approach to augment audiobook experiences during daily tasks by integrating glanceable, AI-generated visuals through optical see-through head-mounted displays (OHMDs). Our initial study showed that these visual augmentations not only preserved users’ primary task efficiency but also dramatically enhanced immediate auditory content recall by 33.3% and 7-day recall by 32.7%, alongside a marked improvement in narrative engagement. Through participatory design workshops involving digital arts designers, we crafted a set of design principles for visual augmentations that are attuned to the requirements of multitaskers. Finally, a 3-day take-home field study further revealed new insights for everyday use, underscoring the potential of assisted reality (aR) to enhance heads-up listening and incidental learning experiences.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {83},
numpages = {22},
keywords = {Assisted Reality, Audiobook Augmentation, Heads-Up Computing, Incidental learning, Optical See-Through Head-Mounted Displays, Recall Enhancement, Smart-glasses, Visual Storytelling},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642514,10.1145/3613904.3642514,acm,2024
564,ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models,"@inproceedings{10.1145/3613904.3642517,
author = {Yang, Jackie (Junrui) and Shi, Yingtian and Zhang, Yuhan and Li, Karina and Rosli, Daniel Wan and Jain, Anisha and Zhang, Shuning and Li, Tianshi and Landay, James A. and Lam, Monica S.},
title = {ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642517},
doi = {10.1145/3613904.3642517},
abstract = {By combining voice and touch interactions, multimodal interfaces can surpass the efficiency of either modality alone. Traditional multimodal frameworks require laborious developer work to support rich multimodal commands where the user’s multimodal command involves possibly exponential combinations of actions/function invocations. This paper presents ReactGenie, a programming framework that better separates multimodal input from the computational model to enable developers to create efficient and capable multimodal interfaces with ease. ReactGenie translates multimodal user commands into NLPL (Natural Language Programming Language), a programming language we created, using a neural semantic parser based on large-language models. The ReactGenie runtime interprets the parsed NLPL and composes primitives in the computational model to implement complex user commands. As a result, ReactGenie allows easy implementation and unprecedented richness in commands for end-users of multimodal apps. Our evaluation showed that 12 developers can learn and build a non-trivial ReactGenie application in under 2.5 hours on average. In addition, compared with a traditional GUI, end-users can complete tasks faster and with less task load using ReactGenie apps.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {483},
numpages = {23},
keywords = {development frameworks, large-language model, multimodal interactions, natural language processing, programming framework},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642517,10.1145/3613904.3642517,acm,2024
565,Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts,"@inproceedings{10.1145/3613904.3642529,
author = {Kim, Taewook and Han, Hyomin and Adar, Eytan and Kay, Matthew and Chung, John Joon Young},
title = {Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642529},
doi = {10.1145/3613904.3642529},
abstract = {Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author’s vision to the audience’s context and taste at scale. However, it is unclear what the authors’ values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors’ concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors’ values.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {31},
numpages = {16},
keywords = {Authorial control, Creative language arts, Creative writing, Generative AI, Large language models, Scalable personalization},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642529,10.1145/3613904.3642529,acm,2024
566,Listening to the Voices: Describing Ethical Caveats of Conversational User Interfaces According to Experts and Frequent Users,"@inproceedings{10.1145/3613904.3642542,
author = {Mildner, Thomas and Cooney, Orla and Meck, Anna-Maria and Bartl, Marion and Savino, Gian-Luca and Doyle, Philip R and Garaialde, Diego and Clark, Leigh and Sloan, John and Wenig, Nina and Malaka, Rainer and Niess, Jasmin},
title = {Listening to the Voices: Describing Ethical Caveats of Conversational User Interfaces According to Experts and Frequent Users},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642542},
doi = {10.1145/3613904.3642542},
abstract = {Advances in natural language processing and understanding have led to a rapid growth in the popularity of conversational user interfaces (CUIs). While CUIs introduce novel benefits, they also yield risks that may exploit people’s trust. Although research looking at unethical design deployed through graphical user interfaces (GUIs) established a thorough understanding of so-called dark patterns, there is a need to continue this discourse within the CUI community to understand potentially problematic interactions. Addressing this gap, we interviewed 27 participants from three cohorts: researchers, practitioners, and frequent users of CUIs. Applying thematic analysis, we construct five themes reflecting each cohort’s insights about ethical design challenges and introduce the CUI Expectation Cycle, bridging system capabilities and user expectations while considering each theme’s ethical caveats. This research aims to inform future development of CUIs to consider ethical constraints while adopting a human-centred approach.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {307},
numpages = {18},
keywords = {CUI, chatbots, conversational agents, conversational user interfaces, dark patterns, deceptive design patterns, ethical design, thematic analysis, voice agents},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642542,10.1145/3613904.3642542,acm,2024
567,"See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles","@inproceedings{10.1145/3613904.3642545,
author = {Zhang, Yu and Sun, Jingwei and Feng, Li and Yao, Cen and Fan, Mingming and Zhang, Liuxin and Wang, Qianying and Geng, Xin and Rui, Yong},
title = {See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642545},
doi = {10.1145/3613904.3642545},
abstract = {The proliferation of AI-powered search and recommendation systems has accelerated the formation of “filter bubbles” that reinforce people’s biases and narrow their perspectives. Previous research has attempted to address this issue by increasing the diversity of information exposure, which is often hindered by a lack of user motivation to engage with. In this study, we took a human-centered approach to explore how Large Language Models (LLMs) could assist users in embracing more diverse perspectives. We developed a prototype featuring LLM-powered multi-agent characters that users could interact with while reading social media content. We conducted a participatory design study with 18 participants and found that multi-agent dialogues with gamification incentives could motivate users to engage with opposing viewpoints. Additionally, progressive interactions with assessment tasks could promote thoughtful consideration. Based on these findings, we provided design implications with future work outlooks for leveraging LLMs to help users burst their filter bubbles.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {484},
numpages = {24},
keywords = {diverse information, filter bubble, interaction design, large language model, multi-agent system},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642545,10.1145/3613904.3642545,acm,2024
568,LLMR: Real-time Prompting of Interactive Worlds using Large Language Models,"@inproceedings{10.1145/3613904.3642579,
author = {De La Torre, Fernanda and Fang, Cathy Mengying and Huang, Han and Banburski-Fahey, Andrzej and Amores Fernandez, Judith and Lanier, Jaron},
title = {LLMR: Real-time Prompting of Interactive Worlds using Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642579},
doi = {10.1145/3613904.3642579},
abstract = {We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR’s cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {600},
numpages = {22},
keywords = {artificial intelligence, large language model, mixed reality, spatial reasoning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642579,10.1145/3613904.3642579,acm,2024
569,Open Sesame? Open Salami! Personalizing Vocabulary Assessment-Intervention for Children via Pervasive Profiling and Bespoke Storybook Generation,"@inproceedings{10.1145/3613904.3642580,
author = {Lee, Jungeun and Yoon, Suwon and Lee, Kyoosik and Jeong, Eunae and Cho, Jae-Eun and Park, Wonjeong and Yim, Dongsun and Hwang, Inseok},
title = {Open Sesame? Open Salami! Personalizing Vocabulary Assessment-Intervention for Children via Pervasive Profiling and Bespoke Storybook Generation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642580},
doi = {10.1145/3613904.3642580},
abstract = {Children acquire language by interacting with their surroundings. Due to the different language environments each child is exposed to, the words they encounter and need in their life vary. Despite the standard tools for assessment and intervention as per predefined vocabulary sets, speech-language pathologists and parents struggle with the absence of systematic tools for child-specific custom vocabulary, i.e., out-of-standard but personally more important. We propose “Open Sesame? Open Salami! (OSOS)”, a personalized vocabulary assessment and intervention system with pervasive language profiling and targeted storybook generation, collaboratively developed with speech-language pathologists. Melded into a child’s daily life and powered by large language models (LLM), OSOS profiles the child’s language environment, extracts priority words therein, and generates bespoke storybooks naturally incorporating those words. We evaluated OSOS through 4-week-long deployments to 9 families. We report their experiences with OSOS, and its implications in supporting personalization outside standards.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {120},
numpages = {32},
keywords = {generative AI, language assessment and intervention, large language model, storybook generation, vocabulary learning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642580,10.1145/3613904.3642580,acm,2024
570,Is Stack Overflow Obsolete? An Empirical Study of the Characteristics of ChatGPT Answers to Stack Overflow Questions,"@inproceedings{10.1145/3613904.3642596,
author = {Kabir, Samia and Udo-Imeh, David N. and Kou, Bonan and Zhang, Tianyi},
title = {Is Stack Overflow Obsolete? An Empirical Study of the Characteristics of ChatGPT Answers to Stack Overflow Questions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642596},
doi = {10.1145/3613904.3642596},
abstract = {Q&amp;A platforms have been crucial for the online help-seeking behavior of programmers. However, the recent popularity of ChatGPT is altering this trend. Despite this popularity, no comprehensive study has been conducted to evaluate the characteristics of ChatGPT’s answers to programming questions. To bridge the gap, we conducted the first in-depth analysis of ChatGPT answers to 517 programming questions on Stack Overflow and examined the correctness, consistency, comprehensiveness, and conciseness of ChatGPT answers. Furthermore, we conducted a large-scale linguistic analysis, as well as a user study, to understand the characteristics of ChatGPT answers from linguistic and human aspects. Our analysis shows that 52% of ChatGPT answers contain incorrect information and 77% are verbose. Nonetheless, our user study participants still preferred ChatGPT answers 35% of the time due to their comprehensiveness and well-articulated language style. However, they also overlooked the misinformation in the ChatGPT answers 39% of the time. This implies the need to counter misinformation in ChatGPT answers to programming questions and raise awareness of the risks associated with seemingly correct answers.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {935},
numpages = {17},
keywords = {chatgpt, large language model, misinformation, q&amp;a, stack overflow},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642596,10.1145/3613904.3642596,acm,2024
571,From Letterboards to Holograms: Advancing Assistive Technology for Nonspeaking Autistic Individuals with the HoloBoard,"@inproceedings{10.1145/3613904.3642626,
author = {Alabood, Lorans and Dow, Travis and Feeley, Kaylyn B and Jaswal, Vikram K. and Krishnamurthy, Diwakar},
title = {From Letterboards to Holograms: Advancing Assistive Technology for Nonspeaking Autistic Individuals with the HoloBoard},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642626},
doi = {10.1145/3613904.3642626},
abstract = {About one-third of autistic individuals are nonspeaking, i.e., they cannot use speech to convey their thoughts reliably. Many in this population communicate via spelling, a process in which they point to letters on a letterboard held upright in their field of view by a trained Communication and Regulation Partner (CRP). This paper focuses on transitioning such individuals to more independent, digital spelling that requires less support from the CRP, a goal most nonspeakers we consulted with desire. To enable this transition, we followed an approach that mimics an environment familiar to the nonspeaker and that harnesses the skills they already possess from physical letterboard training. Using this approach, we developed HoloBoard, a system that allows a nonspeaker, their CRP, and others, e.g., researchers, to share a common Augmented Reality (AR) environment containing a virtual letterboard. We configured the system to offer a brief (less than 10 minutes, on average) training module with graduated spelling tasks on the virtual letterboard. In a study involving 23 participants, 16 completed the entire module. These participants were able to spell words on the virtual letterboard without the CRP holding that board, an outcome we had not expected. When offered the opportunity to continue interacting with the virtual letterboard after the training module, 14 performed more complicated tasks than we had anticipated, spelling full sentences, or even offering feedback on the HoloBoard using solely the virtual board. Furthermore, five of these participants used the system solo, i.e., with the CRP and researchers absent from the virtual environment. These results suggest that training with the HoloBoard can lay the foundation for more independent communication, providing new social and educational opportunities for this marginalized population.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {71},
numpages = {18},
keywords = {Cross-reality, accessibility, assistive technology, extended reality, nonspeaking autistic people},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642626,10.1145/3613904.3642626,acm,2024
572,Artful Path to Healing: Using Machine Learning for Visual Art Recommendation to Prevent and Reduce Post-Intensive Care Syndrome (PICS),"@inproceedings{10.1145/3613904.3642636,
author = {Yilma, Bereket A. and Kim, Chan Mi and Cupchik, Gerald C. and Leiva, Luis A.},
title = {Artful Path to Healing: Using Machine Learning for Visual Art Recommendation to Prevent and Reduce Post-Intensive Care Syndrome (PICS)},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642636},
doi = {10.1145/3613904.3642636},
abstract = {Staying in the intensive care unit (ICU) is often traumatic, leading to post-intensive care syndrome (PICS), which encompasses physical, psychological, and cognitive impairments. Currently, there are limited interventions available for PICS. Studies indicate that exposure to visual art may help address the psychological aspects of PICS and be more effective if it is personalized. We develop Machine Learning-based Visual Art Recommendation Systems (VA RecSys) to enable personalized therapeutic visual art experiences for post-ICU patients. We investigate four state-of-the-art VA RecSys engines, evaluating the relevance of their recommendations for therapeutic purposes compared to expert-curated recommendations. We conduct an expert pilot test and a large-scale user study (n=150) to assess the appropriateness and effectiveness of these recommendations. Our results suggest all recommendations enhance temporal affective states. Visual and multimodal VA RecSys engines compare favourably with expert-curated recommendations, indicating their potential to support the delivery of personalized art therapy for PICS prevention and treatment.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {447},
numpages = {19},
keywords = {Artwork, Health, Machine Learning, Personalization, Recommendation, User Experience, intensive care unit, rehabilitation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642636,10.1145/3613904.3642636,acm,2024
573,How AI Processing Delays Foster Creativity: Exploring Research Question Co-Creation with an LLM-based Agent,"@inproceedings{10.1145/3613904.3642698,
author = {Liu, Yiren and Chen, Si and Cheng, Haocong and Yu, Mengxia and Ran, Xiao and Mo, Andrew and Tang, Yiliu and Huang, Yun},
title = {How AI Processing Delays Foster Creativity: Exploring Research Question Co-Creation with an LLM-based Agent},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642698},
doi = {10.1145/3613904.3642698},
abstract = {Developing novel research questions (RQs) often requires extensive literature reviews, especially in interdisciplinary fields. To support RQ development through human-AI co-creation, we leveraged Large Language Models (LLMs) to build an LLM-based agent system named CoQuest. We conducted an experiment with 20 HCI researchers to examine the impact of two interaction designs: breadth-first and depth-first RQ generation. The findings revealed that participants perceived the breadth-first approach as more creative and trustworthy upon task completion. Conversely, during the task, participants considered the depth-first generated RQs as more creative. Additionally, we discovered that AI processing delays allowed users to reflect on multiple RQs simultaneously, leading to a higher quantity of generated RQs and an enhanced sense of control. Our work makes both theoretical and practical contributions by proposing and evaluating a mental model for human-AI co-creation of RQs. We also address potential ethical issues, such as biases and over-reliance on AI, advocating for using the system to improve human research creativity rather than automating scientific inquiry. The system’s source is available at: https://github.com/yiren-liu/coquest.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {17},
numpages = {25},
keywords = {Co-creation Systems, Large Language Models, Mixed-initiative Design, Scientifc Discovery},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642698,10.1145/3613904.3642698,acm,2024
574,An AI-Resilient Text Rendering Technique for Reading and Skimming Documents,"@inproceedings{10.1145/3613904.3642699,
author = {Gu, Ziwei and Arawjo, Ian and Li, Kenneth and Kummerfeld, Jonathan K. and Glassman, Elena L.},
title = {An AI-Resilient Text Rendering Technique for Reading and Skimming Documents},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642699},
doi = {10.1145/3613904.3642699},
abstract = {Readers find text difficult to consume for many reasons. Summarization can address some of these difficulties, but introduce others, such as omitting, misrepresenting, or hallucinating information, which can be hard for a reader to notice. One approach to addressing this problem is to instead modify how the original text is rendered to make important information more salient. We introduce Grammar-Preserving Text Saliency Modulation (GP-TSM), a text rendering method with a novel means of identifying what to de-emphasize. Specifically, GP-TSM uses a recursive sentence compression method to identify successive levels of detail beyond the core meaning of a passage, which are de-emphasized by rendering words in successively lighter but still legible gray text. In a lab study (n=18), participants preferred GP-TSM over pre-existing word-level text rendering methods and were able to answer GRE reading comprehension questions more efficiently.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {898},
numpages = {22},
keywords = {human-AI interaction, natural language processing, text visualization},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642699,10.1145/3613904.3642699,acm,2024
575,How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries,"@inproceedings{10.1145/3613904.3642700,
author = {Woodruff, Allison and Shelby, Renee and Kelley, Patrick Gage and Rousso-Schindler, Steven and Smith-Loud, Jamila and Wilcox, Lauren},
title = {How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642700},
doi = {10.1145/3613904.3642700},
abstract = {Generative AI is expected to have transformative effects in multiple knowledge industries. To better understand how knowledge workers expect generative AI may affect their industries in the future, we conducted participatory research workshops for seven different industries, with a total of 54 participants across three US cities. We describe participants’ expectations of generative AI’s impact, including a dominant narrative that cut across the groups’ discourse: participants largely envision generative AI as a tool to perform menial work, under human review. Participants do not generally anticipate the disruptive changes to knowledge industries currently projected in common media and academic narratives. Participants do however envision generative AI may amplify four social forces currently shaping their industries: deskilling, dehumanization, disconnection, and disinformation. We describe these forces, and then we provide additional detail regarding attitudes in specific knowledge industries. We conclude with a discussion of implications and research challenges for the HCI community.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {641},
numpages = {26},
keywords = {generative AI, industries, knowledge work},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642700,10.1145/3613904.3642700,acm,2024
576,How Beginning Programmers and Code LLMs (Mis)read Each Other,"@inproceedings{10.1145/3613904.3642706,
author = {Nguyen, Sydney and Babe, Hannah McLean and Zi, Yangtian and Guha, Arjun and Anderson, Carolyn Jane and Feldman, Molly Q},
title = {How Beginning Programmers and Code LLMs (Mis)read Each Other},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642706},
doi = {10.1145/3613904.3642706},
abstract = {Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {651},
numpages = {26},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642706,10.1145/3613904.3642706,acm,2024
577,Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration,"@inproceedings{10.1145/3613904.3642726,
author = {Li, Haotian and Wang, Yun and Qu, Huamin},
title = {Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642726},
doi = {10.1145/3613904.3642726},
abstract = {Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans’ and AI’s advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {845},
numpages = {19},
keywords = {Data storytelling, human-AI collaboration},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642726,10.1145/3613904.3642726,acm,2024
578,Art or Artifice? Large Language Models and the False Promise of Creativity,"@inproceedings{10.1145/3613904.3642731,
author = {Chakrabarty, Tuhin and Laban, Philippe and Agarwal, Divyansh and Muresan, Smaranda and Wu, Chien-Sheng},
title = {Art or Artifice? Large Language Models and the False Promise of Creativity},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642731},
doi = {10.1145/3613904.3642731},
abstract = {Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT) [64], which measures creativity as a process, we use the Consensual Assessment Technique [3] and propose Torrance Test of Creative Writing (TTCW) to evaluate creativity as product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {30},
numpages = {34},
keywords = {Creativity, Design Methods, Evaluation, Human-AI collaboration, Large Language Models, Natural Language Generation, StoryTelling},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642731,10.1145/3613904.3642731,acm,2024
579,Visual Cues for Data Analysis Features Amplify Challenges for Blind Spreadsheet Users,"@inproceedings{10.1145/3613904.3642753,
author = {Perera, Minoli and Lee, Bongshin and Choe, Eun Kyoung and Marriott, Kim},
title = {Visual Cues for Data Analysis Features Amplify Challenges for Blind Spreadsheet Users},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642753},
doi = {10.1145/3613904.3642753},
abstract = {Spreadsheets are widely used for storing, manipulating, analyzing, and visualizing data. Features such as conditional formatting, formulas, sorting, and filtering play an important role when understanding and analyzing data in spreadsheets. They employ visual cues, but we have little understanding of the experiences of blind screen reader (SR) users with such features. We conducted a study with 12 blind SR users to gain insights into their challenges, workarounds, and strategies in understanding and extracting information from a spreadsheet consisting of multiple tables that incorporated data analysis features. We identified five factors that impact blind SR users’ experiences: cognitive overload, time-information trade-off, lack of awareness and expertise, inadequate system feedback, and delayed and absent SR responses. Drawn from these findings, we discuss design suggestions and future research agenda to improve SR users’ spreadsheet experiences.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {42},
numpages = {16},
keywords = {accessibility, assistive technology, blind, data analysis, screen readers., spreadsheets, tables},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642753,10.1145/3613904.3642753,acm,2024
580,Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs,"@inproceedings{10.1145/3613904.3642754,
author = {Subramonyam, Hari and Pea, Roy and Pondoc, Christopher and Agrawala, Maneesh and Seifert, Colleen},
title = {Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642754},
doi = {10.1145/3613904.3642754},
abstract = {Large language models (LLMs) exhibit dynamic capabilities and appear to comprehend complex and ambiguous natural language prompts. However, calibrating LLM interactions is challenging for interface designers and end-users alike. A central issue is our limited grasp of how human cognitive processes begin with a goal and form intentions for executing actions, a blindspot even in established interaction models such as Norman’s gulfs of execution and evaluation. To address this gap, we theorize how end-users ‘envision’ translating their goals into clear intentions and craft prompts to obtain the desired LLM response. We define a process of Envisioning by highlighting three misalignments on not knowing: (1) what the task should be, (2) how to instruct the LLM to do the task, and (3) what to expect for the LLM’s output in meeting the goal. Finally, we make recommendations to narrow the gulf of envisioning in human-LLM interactions.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1039},
numpages = {19},
keywords = {cognitive psychology, large language models, prompt-based interactions},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642754,10.1145/3613904.3642754,acm,2024
581,Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring,"@inproceedings{10.1145/3613904.3642761,
author = {Sharma, Ashish and Rushton, Kevin and Lin, Inna Wanyin and Nguyen, Theresa and Althoff, Tim},
title = {Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642761},
doi = {10.1145/3613904.3642761},
abstract = {Self-guided mental health interventions, such as “do-it-yourself” tools to learn and practice coping strategies, show great promise to improve access to mental health care. However, these interventions are often cognitively demanding and emotionally triggering, creating accessibility barriers that limit their wide-scale implementation and adoption. In this paper, we study how human-language model interaction can support self-guided mental health interventions. We take cognitive restructuring, an evidence-based therapeutic technique to overcome negative thinking, as a case study. In an IRB-approved randomized field study on a large mental health website with 15,531 participants, we design and evaluate a system that uses language models to support people through various steps of cognitive restructuring. Our findings reveal that our system positively impacts emotional intensity for 67% of participants and helps 65% overcome negative thoughts. Although adolescents report relatively worse outcomes, we find that tailored interventions that simplify language model generations improve overall effectiveness and equity.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {700},
numpages = {29},
keywords = {cognitive restructuring, field study, human-AI collaboration, language models, mental health, randomized trial},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642761,10.1145/3613904.3642761,acm,2024
582,"CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming
  Assistant that Balances Student and Educator Needs"," @inproceedings{Kazemitabaar_2024, series={CHI ’24}, title={CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs}, url={http://dx.doi.org/10.1145/3613904.3642773}, DOI={10.1145/3613904.3642773}, booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems}, publisher={ACM}, author={Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi}, year={2024}, month=may, collection={CHI ’24} }
",http://arxiv.org/pdf/2401.11314v2.pdf,10.1145/3613904.3642773,"arxiv, acm, scopus",2024
583,"The Promise and Peril of ChatGPT in Higher Education: Opportunities, Challenges, and Design Implications","@inproceedings{10.1145/3613904.3642785,
author = {Park, Hyanghee and Ahn, Daehwan},
title = {The Promise and Peril of ChatGPT in Higher Education: Opportunities, Challenges, and Design Implications},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642785},
doi = {10.1145/3613904.3642785},
abstract = {A growing number of students in higher education are using ChatGPT for various educational purposes, ranging from seeking information to writing essays. Although many universities have officially banned the use of ChatGPT because of its potential harm and unintended consequences, it is still important to uncover how students leverage ChatGPT for learning, what challenges emerge, and how we can make better use of ChatGPT in higher education. Thus, we conducted focus group workshops and a series of participatory design sessions with thirty students who have actively interacted with ChatGPT for one semester in university and with other five stakeholders (e.g., professors, AI experts). Based on these, this paper identifies real opportunities and challenges of utilizing and designing ChatGPT for higher education.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {271},
numpages = {21},
keywords = {AI in Education, ChatGPT, Higher education, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642785,10.1145/3613904.3642785,acm,2024
584,MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention,"@inproceedings{10.1145/3613904.3642790,
author = {Wu, Ruolan and Yu, Chun and Pan, Xiaole and Liu, Yujia and Zhang, Ningning and Fu, Yue and Wang, Yuhan and Zheng, Zhi and Chen, Li and Jiang, Qiaolei and Xu, Xuhai and Shi, Yuanchun},
title = {MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642790},
doi = {10.1145/3613904.3642790},
abstract = {Problematic smartphone use negatively affects physical and mental health. Despite the wide range of prior research, existing persuasive techniques are not flexible enough to provide dynamic persuasion content based on users’ physical contexts and mental states. We first conducted a Wizard-of-Oz study (N=12) and an interview study (N=10) to summarize the mental states behind problematic smartphone use: boredom, stress, and inertia. This informs our design of four persuasion strategies: understanding, comforting, evoking, and scaffolding habits. We leveraged large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content. We developed MindShift, a novel LLM-powered problematic smartphone use intervention technique. MindShift takes users’ in-the-moment app usage behaviors, physical contexts, mental states, goals &amp; habits as input, and generates personalized and dynamic persuasive content with appropriate persuasion strategies. We conducted a 5-week field experiment (N=25) to compare MindShift with its simplified version (remove mental states) and baseline techniques (fixed reminder). The results show that MindShift improves intervention acceptance rates by 4.7-22.5% and reduces smartphone usage duration by 7.4-9.8%. Moreover, users have a significant drop in smartphone addiction scale scores and a rise in self-efficacy scale scores. Our study sheds light on the potential of leveraging LLMs for context-aware persuasion in other behavior change domains.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {248},
numpages = {24},
keywords = {Problematic smartphone use, large language model, mental model, persuasion},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642790,10.1145/3613904.3642790,acm,2024
585,Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults,"@inproceedings{10.1145/3613904.3642800,
author = {Jin, Yucheng and Cai, Wanling and Chen, Li and Zhang, Yizhe and Doherty, Gavin and Jiang, Tonglin},
title = {Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642800},
doi = {10.1145/3613904.3642800},
abstract = {Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults’ attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1012},
numpages = {17},
keywords = {Generative AI, Human-AI Interaction, Music-based Reminiscence, Older Adults, Reminiscence},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642800,10.1145/3613904.3642800,acm,2024
586,"Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool","@inproceedings{10.1145/3613904.3642805,
author = {Zavolokina, Liudmila and Sprenkamp, Kilian and Katashinskaya, Zoya and Jones, Daniel Gordon and Schwabe, Gerhard},
title = {Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642805},
doi = {10.1145/3613904.3642805},
abstract = {In today's digital age, characterized by rapid news consumption and increasing vulnerability to propaganda, fostering citizens' critical thinking is crucial for stable democracies. This paper introduces the design of ClarifAI, a novel automated propaganda detection tool designed to nudge readers towards more critical news consumption by activating the analytical mode of thinking, following Kahneman's dual-system theory of cognition. Using Large Language Models, ClarifAI detects propaganda in news articles and provides context-rich explanations, enhancing users' understanding and critical thinking. Our contribution is threefold: first, we propose the design of ClarifAI; second, in an online experiment, we demonstrate that this design effectively encourages news readers to engage in more critical reading; and third, we emphasize the value of explanations for fostering critical thinking. The study thus offers both a practical tool and useful design knowledge for mitigating propaganda in digital news.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {24},
keywords = {digital nudging, dual-system thinking, propaganda detection},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642805,10.1145/3613904.3642805,acm,2024
587,Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students,"@inproceedings{10.1145/3613904.3642807,
author = {Zheng, Chengbo and Yuan, Kangyu and Guo, Bingcan and Hadi Mogavi, Reza and Peng, Zhenhui and Ma, Shuai and Ma, Xiaojuan},
title = {Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642807},
doi = {10.1145/3613904.3642807},
abstract = {Students’ increasing use of Artificial Intelligence (AI) presents new challenges for assessing their mastery of knowledge and skills in project-based learning (PBL). This paper introduces a co-design study to explore the potential of students’ AI usage data as a novel material for PBL assessment. We conducted workshops with 18 college students, encouraging them to speculate an alternative world where they could freely employ AI in PBL while needing to report this process to assess their skills and contributions. Our workshops yielded various scenarios of students’ use of AI in PBL and ways of analyzing such usage grounded by students’ vision of how educational goals may transform. We also found that students with different attitudes toward AI exhibited distinct preferences in how to analyze and understand their use of AI. Based on these findings, we discuss future research opportunities on student-AI interactions and understanding AI-enhanced learning.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {94},
numpages = {19},
keywords = {AI for education, co-design, generative AI, project-based learning, qualitative study},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642807,10.1145/3613904.3642807,acm,2024
588,Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM,"@inproceedings{10.1145/3613904.3642830,
author = {Lam, Michelle S. and Teoh, Janice and Landay, James A. and Heer, Jeffrey and Bernstein, Michael S.},
title = {Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642830},
doi = {10.1145/3613904.3642830},
abstract = {Data analysts have long sought to turn unstructured text data into meaningful concepts. Though common, topic modeling and clustering focus on lower-level keywords and require significant interpretative work. We introduce concept induction, a computational process that instead produces high-level concepts, defined by explicit inclusion criteria, from unstructured text. For a dataset of toxic online comments, where a state-of-the-art BERTopic model outputs “women, power, female,” concept induction produces high-level concepts such as “Criticism of traditional gender roles” and “Dismissal of women’s concerns.” We present LLooM, a concept induction algorithm that leverages large language models to iteratively synthesize sampled text and propose human-interpretable concepts of increasing generality. We then instantiate LLooM in a mixed-initiative text analysis tool, enabling analysts to shift their attention from interpreting topics to engaging in theory-driven analysis. Through technical evaluations and four analysis scenarios ranging from literature review to content moderation, we find that LLooM’s concepts improve upon the prior art of topic models in terms of quality and data coverage. In expert case studies, LLooM helped researchers to uncover new insights even from familiar datasets, for example by suggesting a previously unnoticed concept of attacks on out-party stances in a political social media dataset.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {766},
numpages = {28},
keywords = {data visualization, human-AI interaction, large language models, topic modeling, unstructured text analysis},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642830,10.1145/3613904.3642830,acm,2024
589,Making Short-Form Videos Accessible with Hierarchical Video Summaries,"@inproceedings{10.1145/3613904.3642839,
author = {Van Daele, Tess and Iyer, Akhil and Zhang, Yuning and Derry, Jalyn C and Huh, Mina and Pavel, Amy},
title = {Making Short-Form Videos Accessible with Hierarchical Video Summaries},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642839},
doi = {10.1145/3613904.3642839},
abstract = {Short videos on platforms such as TikTok, Instagram Reels, and YouTube Shorts (i.e. short-form videos) have become a primary source of information and entertainment. Many short-form videos are inaccessible to blind and low vision (BLV) viewers due to their rapid visual changes, on-screen text, and music or meme-audio overlays. In our formative study, 7 BLV viewers who regularly watched short-form videos reported frequently skipping such inaccessible content. We present &nbsp;ShortScribe, a system that provides hierarchical visual summaries of short-form videos at three levels of detail to support BLV viewers in selecting and understanding short-form videos. ShortScribe allows BLV users to navigate between video descriptions based on their level of interest. To evaluate &nbsp;ShortScribe, we assessed description accuracy and conducted a user study with 10 BLV participants comparing &nbsp;ShortScribe to a baseline interface. When using ShortScribe, participants reported higher comprehension and provided more accurate summaries of video content.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {895},
numpages = {17},
keywords = {Accessibility, Short-Form Video, Summaries, Video Description},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642839,10.1145/3613904.3642839,acm,2024
590,DiaryHelper: Exploring the Use of an Automatic Contextual Information Recording Agent for Elicitation Diary Study,"@inproceedings{10.1145/3613904.3642853,
author = {Li, Junze and He, Changyang and Hu, Jiaxiong and Jia, Boyang and Halevy, Alon Y and Ma, Xiaojuan},
title = {DiaryHelper: Exploring the Use of an Automatic Contextual Information Recording Agent for Elicitation Diary Study},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642853},
doi = {10.1145/3613904.3642853},
abstract = {Elicitation diary studies, a type of qualitative, longitudinal research method, involve participants to self-report aspects of events of interest at their occurrences as memory cues for providing details and insights during post-study interviews. However, due to time constraints and lack of motivation, participants’ diary entries may be vague or incomplete, impairing their later recall. To address this challenge, we designed an automatic contextual information recording agent, DiaryHelper, based on the theory of episodic memory. DiaryHelper can predict five dimensions of contextual information and confirm with participants. We evaluated the use of DiaryHelper in both the recording period and the elicitation interview through a within-subject study (N=12) over a period of two weeks. Our results demonstrated that DiaryHelper can assist participants in capturing abundant and accurate contextual information without significant burden, leading to a more detailed recall of recorded events and providing greater insights.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {818},
numpages = {16},
keywords = {Diary Study Methods, Elicitation Diary Study, Episodic Memory, Generative AI Techniques},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642853,10.1145/3613904.3642853,acm,2024
591,ReelFramer: Human-AI Co-Creation for News-to-Video Translation,"@inproceedings{10.1145/3613904.3642868,
author = {Wang, Sitong and Menon, Samia and Long, Tao and Henderson, Keren and Li, Dingzeyu and Crowston, Kevin and Hansen, Mark and Nickerson, Jeffrey V and Chilton, Lydia B},
title = {ReelFramer: Human-AI Co-Creation for News-to-Video Translation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642868},
doi = {10.1145/3613904.3642868},
abstract = {Short videos on social media are the dominant way young people consume content. News outlets aim to reach audiences through news reels—short videos conveying news—but struggle to translate traditional journalistic formats into short, entertaining videos. To translate news into social media reels, we support journalists in reframing the narrative. In literature, narrative framing is a high-level structure that shapes the overall presentation of a story. We identified three narrative framings for reels that adapt social media norms but preserve news value, each with a different balance of information and entertainment. We introduce ReelFramer, a human-AI co-creative system that helps journalists translate print articles into scripts and storyboards. ReelFramer supports exploring multiple narrative framings to find one appropriate to the story. AI suggests foundational narrative details, including characters, plot, setting, and key information. ReelFramer also supports visual framing; AI suggests character and visual detail designs before generating a full storyboard. Our studies show that narrative framing introduces the necessary diversity to translate various articles into reels, and establishing foundational details helps generate scripts that are more relevant and coherent. We also discuss the benefits of using narrative framing and foundational details in content retargeting.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {169},
numpages = {20},
keywords = {creativity support tools, generative AI, narratives, scriptwriting, short videos, storyboarding},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642868,10.1145/3613904.3642868,acm,2024
592,BIDTrainer: An LLMs-driven Education Tool for Enhancing the Understanding and Reasoning in Bio-inspired Design,"@inproceedings{10.1145/3613904.3642887,
author = {Chen, Liuqing and Jiang, Zhaojun and Xia, Duowei and Cai, Zebin and Sun, Lingyun and Childs, Peter and Zuo, Haoyu},
title = {BIDTrainer: An LLMs-driven Education Tool for Enhancing the Understanding and Reasoning in Bio-inspired Design},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642887},
doi = {10.1145/3613904.3642887},
abstract = {Bio-inspired design (BID) fosters innovations in engineering. Learning BID is crucial for developing multidisciplinary innovation skills of designers and engineers. Current BID education aims to enhance learners’ understanding and analogical reasoning skills. However, it often heavily relies on the teachers’ expertise. When learners pursue independent learning using some educational tools, they face challenges in understanding and reasoning practice within this multidisciplinary field. Additionally, evaluating their learning outcomes comprehensively becomes problematic. Addressing these challenges, we introduce a LLMs-driven BID education method based on a structured ontology and three strategies: enhancing understanding through LLMs-enpowered ""learning by asking"", assisting reasoning by providing hints and feedback, and assessing learning outcomes through benchmarking against existing BID cases. Implementing the method, we developed BIDTrainer, a BID education tool. User studies indicate that learners using BIDTrainer understood BID knowledge better, reason faster with higher interactivity than the baseline, and BIDTrainer assessed the learning outcomes consistent with experts.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {676},
numpages = {20},
keywords = {Analogy training, Bio-inspired design, Design education, Design evaluation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642887,10.1145/3613904.3642887,acm,2024
593,The Metacognitive Demands and Opportunities of Generative AI,"@inproceedings{10.1145/3613904.3642902,
author = {Tankelevitch, Lev and Kewenig, Viktor and Simkute, Auste and Scott, Ava Elizabeth and Sarkar, Advait and Sellen, Abigail and Rintel, Sean},
title = {The Metacognitive Demands and Opportunities of Generative AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642902},
doi = {10.1145/3613904.3642902},
abstract = {Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {680},
numpages = {24},
keywords = {Generative AI, Human-AI interaction, Metacognition, System Usability, User Experience Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642902,10.1145/3613904.3642902,acm,2024
594,Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM,"@inproceedings{10.1145/3613904.3642939,
author = {Liu, Zhe and Chen, Chunyang and Wang, Junjie and Chen, Mengzhuo and Wu, Boyu and Huang, Yuekai and Hu, Jun and Wang, Qing},
title = {Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642939},
doi = {10.1145/3613904.3642939},
abstract = {Mobile apps have become indispensable for accessing and participating in various environments, especially for low-vision users. Users with visual impairments can use screen readers to read the content of each screen and understand the content that needs to be operated. Screen readers need to read the hint-text attribute in the text input component to remind visually impaired users what to fill in. Unfortunately, based on our analysis of 4,501 Android apps with text inputs, over 76% of them are missing hint-text. These issues are mostly caused by developers’ lack of awareness when considering visually impaired individuals. To overcome these challenges, we developed an LLM-based hint-text generation model called HintDroid, which analyzes the GUI information of input components and uses in-context learning to generate the hint-text. To ensure the quality of hint-text generation, we further designed a feedback-based inspection mechanism to further adjust hint-text. The automated experiments demonstrate the high BLEU and a user study further confirms its usefulness. HintDroid can not only help visually impaired individuals, but also help ordinary people understand the requirements of input components. HintDroid demo video: https://youtu.be/FWgfcctRbfI.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {51},
numpages = {20},
keywords = {App Accessibility, Large Language Model, Mobile App Design, User Interface},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642939,10.1145/3613904.3642939,acm,2024
595,Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models,"@inproceedings{10.1145/3613904.3642943,
author = {Ko, Hyung-Kwon and Jeon, Hyeon and Park, Gwanmo and Kim, Dae Hyun and Kim, Nam Wook and Kim, Juho and Seo, Jinwook},
title = {Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642943},
doi = {10.1145/3613904.3642943},
abstract = {We introduce VL2NL, a Large Language Model (LLM) framework that generates rich and diverse NL datasets using Vega-Lite specifications as input, thereby streamlining the development of Natural Language Interfaces (NLIs) for data visualization. To synthesize relevant chart semantics accurately and enhance syntactic diversity in each NL dataset, we leverage 1) a guided discovery incorporated into prompting so that LLMs can steer themselves to create faithful NL datasets in a self-directed manner; 2) a score-based paraphrasing to augment NL syntax along with four language axes. We also present a new collection of 1,981 real-world Vega-Lite specifications that have increased diversity and complexity than existing chart collections. When tested on our chart collection, VL2NL extracted chart semantics and generated L1/L2 captions with 89.4% and 76.0% accuracy, respectively. It also demonstrated generating and paraphrasing utterances and questions with greater diversity compared to the benchmarks. Last, we discuss how our NL datasets and framework can be utilized in real-world scenarios. The codes and chart collection are available at https://github.com/hyungkwonko/chart-llm.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {843},
numpages = {22},
keywords = {Vega-Lite, data visualization, framework, large language models, natural language datasets, natural language interfaces},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642943,10.1145/3613904.3642943,acm,2024
596,ClassMeta: Designing Interactive Virtual Classmate to Promote VR Classroom Participation,"@inproceedings{10.1145/3613904.3642947,
author = {Liu, Ziyi and Zhu, Zhengzhe and Zhu, Lijun and Jiang, Enze and Hu, Xiyun and Peppler, Kylie A and Ramani, Karthik},
title = {ClassMeta: Designing Interactive Virtual Classmate to Promote VR Classroom Participation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642947},
doi = {10.1145/3613904.3642947},
abstract = {Peer influence plays a crucial role in promoting classroom participation, where behaviors from active students can contribute to a collective classroom learning experience. However, the presence of these active students depends on several conditions and is not consistently available across all circumstances. Recently, Large Language Models (LLMs) such as GPT have demonstrated the ability to simulate diverse human behaviors convincingly due to their capacity to generate contextually coherent responses based on their role settings. Inspired by this advancement in technology, we designed ClassMeta, a GPT-4 powered agent to help promote classroom participation by playing the role of an active student. These agents, which are embodied as 3D avatars in virtual reality, interact with actual instructors and students with both spoken language and body gestures. We conducted a comparative study to investigate the potential of ClassMeta for improving the overall learning experience of the class.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {17},
keywords = {VR classroom, collaborative learning, large language Model, pedagogical agent},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642947,10.1145/3613904.3642947,acm,2024
597,Designing Scaffolding Strategies for Conversational Agents in Dialog Task of Neurocognitive Disorders Screening,"@inproceedings{10.1145/3613904.3642960,
author = {Hu, Jiaxiong and Li, Junze and Zeng, Yuhang and Yang, Dongjie and Liang, Danxuan and Meng, Helen and Ma, Xiaojuan},
title = {Designing Scaffolding Strategies for Conversational Agents in Dialog Task of Neurocognitive Disorders Screening},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642960},
doi = {10.1145/3613904.3642960},
abstract = {Regular screening is critical for individuals at risk of neurocognitive disorders (NCDs) to receive early intervention. Conversational agents (CAs) have been adopted to administer dialog-based NCD screening tests for their scalability compared to human-administered tests. However, unique communication skills are required for CAs during NCD screening, e.g., clinicians often apply scaffolding to ensure subjects’ understanding of and engagement in screening tests. Based on scaffolding theories and analysis of clinicians’ practices from human-administered test recordings, we designed a scaffolding framework for the CA. In an exploratory wizard-of-Oz study, the CA empowered by ChatGPT administered tasks in the Grocery Shopping Dialog Task with 15 participants (10 diagnosed with NCDs). Clinical experts verified the quality of the CA’s scaffolding and we explored its effects on task understanding of the participants. Moreover, we proposed implications for the future design of CAs that enable scaffolding for scalable NCD screening.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {21},
keywords = {Aging, Conversational Agent, Health, Neurocognitive Disorder Screening, Scaffolding},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

",https://doi.org/10.1145/3613904.3642960,10.1145/3613904.3642960,acm,2024
598,Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study,"@article{2-s2.0-85194192158,
  title={Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194192158&origin=inward,10.1145/3613905.3637148,scopus,2024
599,Enhancing Programming Error Messages in Real Time with Generative AI,"@article{2-s2.0-85194193660,
  title={Enhancing Programming Error Messages in Real Time with Generative AI},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194193660&origin=inward,10.1145/3613905.3647967,scopus,2024
600,"Exploring How Multiple Levels of GPT-Generated Programming Hints Support
  or Disappoint Novices"," @inproceedings{Xiao_2024, series={CHI ’24}, title={Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices}, url={http://dx.doi.org/10.1145/3613905.3650937}, DOI={10.1145/3613905.3650937}, booktitle={Extended Abstracts of the CHI Conference on Human Factors in Computing Systems}, publisher={ACM}, author={Xiao, Ruiwei and Hou, Xinying and Stamper, John}, year={2024}, month=may, collection={CHI ’24} }
",http://arxiv.org/pdf/2404.02213v1.pdf,10.1145/3613905.3650937,"arxiv, scopus",2024
601,ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings,"@inproceedings{10.1145/3613944.3613946,
author = {Qureshi, Basit},
title = {ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings},
year = {2023},
isbn = {9798400700415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613944.3613946},
doi = {10.1145/3613944.3613946},
abstract = {The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility, and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore-level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to textbooks and notes of programming courses, however, no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using Programming Contest Control (PC2) environment which is widely used in ACM International Collegiate Programming Contest (ICPC). Each team of students addresses the problem by writing executable code that satisfies a certain number of test cases. Student teams were scored based on their performance in terms of the number of successfully passed test cases. Results show that students using ChatGPT had an advantage in terms of earned scores, however, there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper’s findings indicate that incorporating AI in higher education brings about various opportunities and challenges. Nonetheless, universities can efficiently manage these apprehensions by adopting a proactive and ethical stance toward the implementation of such tools.},
booktitle = {Proceedings of the 2023 9th International Conference on E-Society, e-Learning and e-Technologies},
pages = {7–13},
numpages = {7},
keywords = {Academic assessment, ChatGPT, Data Structures and Algorithms, programming concepts},
location = {Portsmouth, United Kingdom},
series = {ICSLT '23}
}

",https://doi.org/10.1145/3613944.3613946,10.1145/3613944.3613946,acm,2023
602,Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain (The Short Version),"@inproceedings{10.1145/3614407.3643696,
author = {Lee, Katherine and Cooper, A. Feder and Grimmelmann, James},
title = {Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain (The Short Version)},
year = {2024},
isbn = {9798400703331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614407.3643696},
doi = {10.1145/3614407.3643696},
abstract = {""Does generative AI infringe copyright?"" is an urgent question. It is also a difficult question, for two reasons. First, ""generative AI"" is not just one product from one company. It is a catch-all name for a massive ecosystem of loosely related technologies. These systems behave differently and raise different legal issues. Second, copyright law is notoriously complicated, and generative-AI systems manage to touch on a great many corners of it. They raise issues of authorship, similarity, direct and indirect liability, and fair use, among much else. These issues cannot be analyzed in isolation, because there are connections everywhere. We aim to bring order to the chaos. To do so, we introduce the generative-AI supply chain: an interconnected set of stages that transform training data into generations. The supply chain reveals all of the places at which companies and users make choices that have copyright consequences. It enables us to trace the effects of upstream technical designs on downstream uses, and to assess who in these complicated sociotechnical systems bears responsibility for infringement when it happens. Because we engage so closely with the technology of generative AI, we are able to shed more light on the copyright questions. We identify the key decisions that courts will need to make as they grapple with these issues, and point out the consequences that would likely flow from different liability regimes. This article is a much-abbreviated version of a forthcoming law review article at The Journal of the Copyright Society.},
booktitle = {Proceedings of the Symposium on Computer Science and Law},
pages = {48–63},
numpages = {16},
location = {Boston, MA, USA},
series = {CSLAW '24}
}

",https://doi.org/10.1145/3614407.3643696,10.1145/3614407.3643696,acm,2024
603,Translating Legalese: Enhancing Public Understanding of Court Opinions with Legal Summarizers,"@inproceedings{10.1145/3614407.3643700,
author = {Ash, Elliott and Kesari, Aniket and Naidu, Suresh and Song, Lena and Stammbach, Dominik},
title = {Translating Legalese: Enhancing Public Understanding of Court Opinions with Legal Summarizers},
year = {2024},
isbn = {9798400703331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614407.3643700},
doi = {10.1145/3614407.3643700},
abstract = {Judicial opinions are written to be persuasive and could build public trust in court decisions, yet they can be difficult for non-experts to understand. We present a pipeline for using an AI assistant to generate simplified summaries of judicial opinions. Compared to existing expert-written summaries, these AI-generated simple summaries are more accessible to the public and more easily understood by non-experts. We show in a survey experiment that the AI summaries help respondents understand the key features of a ruling, and have higher perceived quality, especially for respondents with less formal education.},
booktitle = {Proceedings of the Symposium on Computer Science and Law},
pages = {136–157},
numpages = {22},
location = {Boston, MA, USA},
series = {CSLAW '24}
}

",https://doi.org/10.1145/3614407.3643700,10.1145/3614407.3643700,acm,2024
604,Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit,"@inproceedings{10.1145/3614419.3644014,
author = {Wu, Chuhao and Wang, Xinyu and Carroll, John and Rajtmajer, Sarah},
title = {Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644014},
doi = {10.1145/3614419.3644014},
abstract = {Generative Artificial intelligence (GenAI) such as ChatGPT has elicited strong reactions from almost all stakeholders across the education system. Education-oriented and academic social media communities provide an important venue for these stakeholders to share experiences and exchange ideas about GenAI, which is constructive for developing human-centered policies. This study examines early user reactions to GenAI, consisting of 725 Reddit threads between 06/2022 and 05/2023. Through natural language processing (NLP) and content analysis, we observe an increasingly negative sentiment in the discussion and identify six main categories of student and faculty experiences of GenAI in education. These experiences reflect concerns about academic integrity and AI’s negative impact on the values of traditional education. Our analysis also highlights the tension and burden imposed by new technologies. Our findings suggest that dialogue between stakeholders in the education community is critical and can mitigate sources of tension between students and faculty.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {103–113},
numpages = {11},
keywords = {Generative AI, Higher Education, Social Media, Topic Modeling},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}

",https://doi.org/10.1145/3614419.3644014,10.1145/3614419.3644014,acm,2024
605,Playing with AI Chat: Positioning “Dangerous” Language Model Futures through Interactive Fiction,"@inproceedings{10.1145/3615335.3623015,
author = {Murray, John T. and Murray, Jack and Salter, Anastasia},
title = {Playing with AI Chat: Positioning “Dangerous” Language Model Futures through Interactive Fiction},
year = {2023},
isbn = {9798400703362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615335.3623015},
doi = {10.1145/3615335.3623015},
abstract = {Large language models (LLMs) use statistical models to predict the next sequence of tokens and have capabilities previously considered unattainable outside of human intelligence. Communication design can benefit from a close examination of the ongoing conversations around the adoption and use of LLMs, both the public discourse and the specific language and rhetoric used in the initial set of application interfaces and prompts. Through a survey of existing practices and a case study of how AI is used within the interactive fiction community, where procedural content generation has played with expectations and personas, this paper offers a foundation for future critique of these models as they are embedded in the digital tools we rely upon for daily communication and work.},
booktitle = {Proceedings of the 41st ACM International Conference on Design of Communication},
pages = {82–88},
numpages = {7},
keywords = {AI Dungeon, Bard, Bing Chat, Chat Interfaces, ChatGPT, GPT-4, Large-Language Models},
location = {Orlando, FL, USA},
series = {SIGDOC '23}
}

",https://doi.org/10.1145/3615335.3623015,10.1145/3615335.3623015,acm,2023
606,Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy,"@inproceedings{10.1145/3615335.3623035,
author = {York, Eric},
title = {Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy},
year = {2023},
isbn = {9798400703362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615335.3623035},
doi = {10.1145/3615335.3623035},
abstract = {The advent of widely-accessible generative AI tools and their rapid adoption across industry and education is necessitating large-scale revisions to user experience design and web development pedagogies and curricula, a process that will take some time. This report describes a series of initial experiments using generative AI tools as a student or junior designer or web developer might, sometimes na\""{\i}vely and sometimes in more sophisticated ways, to complete beginner-level and advanced projects. The report evaluates how ChatGPT performs across three categories of prompts (brainstorming, design, and coding) and assesses the quality of the outputs in order to inform the research design of a larger, ongoing interdisciplinary study in its initial phases and to document the results for instructors or senior members of design and development teams to aid them in assessing the fitness of generative AI for user experience design and web development production.},
booktitle = {Proceedings of the 41st ACM International Conference on Design of Communication},
pages = {197–201},
numpages = {5},
keywords = {Artificial Intelligence, Pedagogy, User experience (UX) design, Web development},
location = {Orlando, FL, USA},
series = {SIGDOC '23}
}

",https://doi.org/10.1145/3615335.3623035,10.1145/3615335.3623035,acm,2023
607,Towards Understanding the Geospatial Skills of ChatGPT: Taking a Geographic Information Systems (GIS) Exam,"@inproceedings{10.1145/3615886.3627745,
author = {Mooney, Peter and Cui, Wencong and Guan, Boyuan and Juh\'{a}sz, Levente},
title = {Towards Understanding the Geospatial Skills of ChatGPT: Taking a Geographic Information Systems (GIS) Exam},
year = {2023},
isbn = {9798400703485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615886.3627745},
doi = {10.1145/3615886.3627745},
abstract = {This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and ability to grasp geospatial concepts by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3% (GPT-3.5) and 88.3% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.},
booktitle = {Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {85–94},
numpages = {10},
keywords = {ChatGPT, GIS, Generative AI, Large Language Models, education, foundation model, geospatial},
location = {Hamburg, Germany},
series = {GeoAI '23}
}

",https://doi.org/10.1145/3615886.3627745,10.1145/3615886.3627745,acm,2023
608,Temporal Blind Spots in Large Language Models,"@inproceedings{10.1145/3616855.3635818,
author = {Wallat, Jonas and Jatowt, Adam and Anand, Avishek},
title = {Temporal Blind Spots in Large Language Models},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635818},
doi = {10.1145/3616855.3635818},
abstract = {Large language models (LLMs) have recently gained significant attention due to their unparalleled zero-shot performance on various natural language processing tasks. However, the pre-training data utilized in LLMs is often confined to a specific corpus, resulting in inherent freshness and temporal scope limitations. Consequently, this raises concerns regarding the effectiveness of LLMs for tasks involving temporal intents. In this study, we aim to investigate the underlying limitations of general-purpose LLMs when deployed for tasks that require a temporal understanding. We pay particular attention to handling factual temporal knowledge through three popular temporal QA datasets. Specifically, we observe low performance on detailed questions about the past and, surprisingly, for rather new information. In manual and automatic testing, we find multiple temporal errors and characterize the conditions under which QA performance deteriorates. Our analysis contributes to understanding LLM limitations and offers valuable insights into developing future models that can better cater to the demands of temporally-oriented tasks. The code is available https://github.com/jwallat/temporalblindspots.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {683–692},
numpages = {10},
keywords = {large language models, question answering, temporal information retrieval, temporal query intents},
location = {Merida, Mexico},
series = {WSDM '24}
}

",https://doi.org/10.1145/3616855.3635818,10.1145/3616855.3635818,acm,2024
609,"""Call me Kiran"" ChatGPT as a Tutoring Chatbot in a Computer Science Course","@inproceedings{10.1145/3616961.3616974,
author = {Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\""{a}, Pia},
title = {""\""Call me Kiran\"" – ChatGPT as a Tutoring Chatbot in a Computer Science Course""},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616974},
doi = {10.1145/3616961.3616974},
abstract = {Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {83–94},
numpages = {12},
keywords = {ChatGPT, artificial intelligence, chatbots, discussion forum, education, generative AI, student perceptions, tutoring},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

",https://doi.org/10.1145/3616961.3616974,10.1145/3616961.3616974,"acm, scopus",2023
610,“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers,"@article{10.1145/3617367,
author = {Prather, James and Reeves, Brent N. and Denny, Paul and Becker, Brett A. and Leinonen, Juho and Luxton-Reilly, Andrew and Powell, Garrett and Finnie-Ansley, James and Santos, Eddie Antonio},
title = {“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3617367},
doi = {10.1145/3617367},
abstract = {Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = {nov},
articleno = {4},
numpages = {31},
keywords = {AI, Artificial Intelligence, automatic code generation, Codex, Copilot, CS1, GitHub, GPT-3, HCI, introductory programming, large language models, LLM, novice programming, OpenAI}
}

",https://doi.org/10.1145/3617367,10.1145/3617367,"acm, scopus",2023
611,Is ChatGPT Capable of Crafting Gamification Strategies for Software Engineering Tasks?,"@inproceedings{10.1145/3617553.3617887,
author = {Fulcini, Tommaso and Torchiano, Marco},
title = {Is ChatGPT Capable of Crafting Gamification Strategies for Software Engineering Tasks?},
year = {2023},
isbn = {9798400703737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617553.3617887},
doi = {10.1145/3617553.3617887},
abstract = {Gamification has gained significant attention in the last decade for its potential to enhance engagement and motivation in various domains. During the last year ChatGPT, a state-of-the-art large language model has received even more attention both in the field of scientific research and in common use by individuals or companies.  
In this study, we investigate the possibility of adopting ChatGPT as a tool for designing gamification platforms in the Software Engineering domain. Leveraging the capabilities of ChatGPT, we assess how good is it at generating effective suggestions and ideas for designers or developers.  
To evaluate ChatGPT's potential as a gamification platform creator we narrowed the context to one particular Software Engineering activity, asking for possible aspects of the activity to be gamified. Each proposed aspect was subsequently unraveled by ChatGPT both asking in a shared and separate context, first following the conversational nature of the model, then applying a validated design framework. The study assesses ChatGPT's ability to select and integrate game elements to build a thriving gamification environment by framing the design of the platform to a state-of-the-art conceptual framework. To evaluate the goodness of the design choices made we relied both on the Octalysis framework and on personal experience.  
The findings of the papers show that ChatGPT can only create simple playful experiences not very effective. Although, by instructing the model with more specific desired mechanics and dynamics, it is possible to guide it toward the application of the ideas suggested. We argue that ChatGPT is not capable of building a gamified environment on its own, but it could still be used to build the foundation of a gamification platform as long as the designers refine and rough out the advice gained from a user-centered solution.},
booktitle = {Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation},
pages = {22–28},
numpages = {7},
keywords = {Software Lifecycle, Software Engineering, Large Language Model, Gamification, Artificial Intelligence},
location = {San Francisco, CA, USA},
series = {Gamify 2023}
}

",https://doi.org/10.1145/3617553.3617887,10.1145/3617553.3617887,acm,2023
612,Exploring the Potential of GPT-4 in Automated Mentoring for Programming Courses,"@article{2-s2.0-85180004577,
  title={Exploring the Potential of GPT-4 in Automated Mentoring for Programming Courses},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180004577&origin=inward,10.1145/3617650.3624946,scopus,2023
613,Teaching Students To Use Programming Error Messages,"@article{2-s2.0-85180005666,
  title={Teaching Students To Use Programming Error Messages},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180005666&origin=inward,10.1145/3617650.3624950,scopus,2023
614,"A Journey of a 1,000 Kernels Begins with a Single Step: A Retrospective of Deep Learning on GPUs","@inproceedings{10.1145/3620665.3640367,
author = {Davies, Michael and McDougall, Ian and Anandaraj, Selvaraj and Machchhar, Deep and Jain, Rithik and Sankaralingam, Karthikeyan},
title = {A Journey of a 1,000 Kernels Begins with a Single Step: A Retrospective of Deep Learning on GPUs},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620665.3640367},
doi = {10.1145/3620665.3640367},
abstract = {We are in age of AI, with rapidly changing algorithms and a somewhat synergistic change in hardware. MLPerf is a recent benchmark suite that serves as a way to compare and evaluate hardware. However it has several drawbacks - it is dominated by CNNs and does a poor job of capturing the diversity of AI use cases, and only represents a sliver of production AI use cases. This paper performs a longitudinal study of state-of-art AI applications spanning vision, physical simulation, vision synthesis, language and speech processing, and tabular data processing, across three generations of hardware to understand how the AI revolution has panned out. We call this collection of applications and execution scaffolding the CaSiO suite. The paper reports on data gathered at the framework level, device API level, and hardware and microarchitecture level. The paper provides insights on the hardware-software revolution with pointers to future trends.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {20–36},
numpages = {17},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

",https://doi.org/10.1145/3620665.3640367,10.1145/3620665.3640367,acm,2024
615,SpecPIM: Accelerating Speculative Inference on PIM-Enabled System via Architecture-Dataflow Co-Exploration,"@inproceedings{10.1145/3620666.3651352,
author = {Li, Cong and Zhou, Zhe and Zheng, Size and Zhang, Jiaxi and Liang, Yun and Sun, Guangyu},
title = {SpecPIM: Accelerating Speculative Inference on PIM-Enabled System via Architecture-Dataflow Co-Exploration},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620666.3651352},
doi = {10.1145/3620666.3651352},
abstract = {Generative large language models' (LLMs) inference suffers from inefficiency because of the token dependency brought by autoregressive decoding. Recently, speculative inference has been proposed to alleviate this problem, which introduces small language models to generate draft tokens and adopts the original large language model to conduct verification. Although speculative inference can enhance the efficiency of the decoding procedure, we find that it presents variable resource demands due to the distinct computation patterns of the models used in speculative inference. This variability impedes the full realization of speculative inference's acceleration potential in current systems.To tackle this problem, we propose SpecPIM to accelerate speculative inference on the PIM-enabled system. SpecPIM aims to boost the performance of speculative inference by extensively exploring the heterogeneity brought by both the algorithm and the architecture. To this end, we construct the architecture design space to satisfy each model's disparate resource demands and dedicate the dataflow design space to fully utilize the system's hardware resources. Based on the co-design space, we propose a design space exploration (DSE) framework to provide the optimal design under different target scenarios. Compared with speculative inference on GPUs and existing PIM-based LLM accelerators, SpecPIM achieves 1.52\texttimes{}/2.02\texttimes{} geomean speedup and 6.67\texttimes{}/2.68\texttimes{} geomean higher energy efficiency.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {950–965},
numpages = {16},
keywords = {near-memory processing, large language models, speculative inference, domain-specific accelerator},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

",https://doi.org/10.1145/3620666.3651352,10.1145/3620666.3651352,acm,2024
616,Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?,"@inproceedings{10.1145/3622758.3622882,
author = {Sarkar, Advait},
title = {Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?},
year = {2023},
isbn = {9798400703881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622758.3622882},
doi = {10.1145/3622758.3622882},
abstract = {The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which ""traditional"" programming languages remain relevant for non-expert end-user programmers in a world with generative AI. We posit the ""generative shift hypothesis"": that generative AI will create qualitative and quantitative expansions in the traditional scope of end-user programming. We outline some reasons that traditional programming languages may still be relevant and useful for end-user programmers. We speculate whether each of these reasons might be fundamental and enduring, or whether they may disappear with further improvements and innovations in generative AI. Finally, we articulate a set of implications for end-user programming research, including the possibility of needing to revisit many well-established core concepts, such as Ko's learning barriers and Blackwell's attention investment model.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {153–167},
numpages = {15},
keywords = {attention investment model, end-user software customization, generative shift hypothesis, learning barriers, live programming, prompt engineering, self-efficacy},
location = {Cascais, Portugal},
series = {Onward! 2023}
}

",https://doi.org/10.1145/3622758.3622882,10.1145/3622758.3622882,acm,2023
617,KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education,"@inproceedings{10.1145/3622780.3623648,
author = {Kuramitsu, Kimio and Obara, Yui and Sato, Miyu and Obara, Momoka},
title = {KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education},
year = {2023},
isbn = {9798400703904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622780.3623648},
doi = {10.1145/3622780.3623648},
abstract = {The impact of ChatGPT has brought both anxiety and anticipation to schools and universities. Exploring a positive method to improve programming skills with ChatGPT is a new and pressing challenge.  
In pursuit of this goal, we have developed KOGI, a learning support system that integrates ChatGPT into the Jupyter environment. This paper demonstrates how KOGI enables students to receive timely advice from ChatGPT in response to errors and other questions they encounter.  

We immediately introduced KOGI in our two introductory courses: Algorithms and Data Science. The introduction of KOGI resulted in a significant decrease in the number of unresolved student errors. In addition, we report on student trends observed in the classroom regarding the type and frequency of help requested. Although our findings are preliminary, they are informative for programming instructors interested in using ChatGPT.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E},
pages = {50–59},
numpages = {10},
keywords = {ChatGPT, LLM, classroom experience, programming education},
location = {Cascais, Portugal},
series = {SPLASH-E 2023}
}

",https://doi.org/10.1145/3622780.3623648,10.1145/3622780.3623648,"acm, web_of_science, scopus",2023
618,A Grounded Conceptual Model for Ownership Types in Rust,"@article{10.1145/3622841,
author = {Crichton, Will and Gray, Gavin and Krishnamurthi, Shriram},
title = {A Grounded Conceptual Model for Ownership Types in Rust},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3622841},
doi = {10.1145/3622841},
abstract = {Programmers learning Rust struggle to understand ownership types, Rust’s core mechanism for ensuring memory safety without garbage collection. This paper describes our attempt to systematically design a pedagogy for ownership types. First, we studied Rust developers’ misconceptions of ownership to create the Ownership Inventory, a new instrument for measuring a person’s knowledge of ownership. We found that Rust learners could not connect Rust’s static and dynamic semantics, such as determining why an ill-typed program would (or would not) exhibit undefined behavior. Second, we created a conceptual model of Rust’s semantics that explains borrow checking in terms of flow-sensitive permissions on paths into memory. Third, we implemented a Rust compiler plugin that visualizes programs under the model. Fourth, we integrated the permissions model and visualizations into a broader pedagogy of ownership by writing a new ownership chapter for The Rust Programming Language, a popular Rust textbook. Fifth, we evaluated an initial deployment of our pedagogy against the original version, using reader responses to the Ownership Inventory as a point of comparison. Thus far, the new pedagogy has improved learner scores on the Ownership Inventory by an average of 9},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {265},
numpages = {29},
keywords = {Rust, concept inventory, ownership types, program state visualization}
}

",https://doi.org/10.1145/3622841,10.1145/3622841,acm,2023
619,MetaFraming: A Methodology for Democratizing Heritage Interpretation Through Wiki Surveys,"@inproceedings{10.1145/3623462.3623465,
author = {Wehmeier, Colter and Artopoulos, Georgios},
title = {MetaFraming: A Methodology for Democratizing Heritage Interpretation Through Wiki Surveys},
year = {2023},
isbn = {9798400708367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623462.3623465},
doi = {10.1145/3623462.3623465},
abstract = {Recent developments in the Digital Humanities reveal how traditional survey methods, when applied to the study of cultural heritage, often struggle to encapsulate the intricate social dynamics of our interactions with built environments and artefacts. Despite the allure of digital tools promising scalability, nonlinearity, and increased engagement, their fit for heritage interpretation remains an open question. To address this gap, we introduce MetaFraming—a contribution to participatory methodology designed to leverage computational social science tools such as artificial intelligence and wiki surveys, towards inclusive and democratic approaches in heritage interpretation. MetaFraming enables researchers to transform extensive preliminary research notes into a metadata-rich, semantically structured dataset using an AI processing pipeline, thereby modelling diverse perspectives on heritage artefacts. Following manual refinement, this dataset serves as the initial ’seed’ state for a wiki survey (a user-editable, collaborative survey). Such a survey enables the crowd to rank propositions, comment, and contribute new ideas. Notably, participant input itself contains metadata, allowing for a subsequent automated pipeline to reconstruct the context of actions such as comments. This secondary process provides rich insights into recommendations, specific user/actor experiences, group interests, and the complex relationships between them. Through a design-research framework, we apply MetaFraming to a case study in architectural heritage: our artefact of study is Le Corbusier’s renowned Unit\'{e} d’habitation (1952), a seminal prototype for social housing and urbanism in post-war France. This exploration enables us to contrast our novel web-based survey method with traditional approaches, thereby highlighting new opportunities for computer-aided collaboration in heritage interpretation. By fostering reflective exploration of built environments and societal legacies, our work contributes to the growing discourse on digital technologies in cultural heritage, advocating for interdisciplinary research and dialogue.},
booktitle = {Proceedings of the 20th International Conference on Culture and Computer Science: Code and Materiality},
articleno = {4},
numpages = {9},
keywords = {MetaFraming, Modern Architectural Heritage, Participatory Heritage, Wiki Surveys},
location = {Lisbon, Portugal},
series = {KUI '23}
}

",https://doi.org/10.1145/3623462.3623465,10.1145/3623462.3623465,acm,2023
620,Arguments for and Approaches to Computing Education in Undergraduate Computer Science Programmes,"@inproceedings{10.1145/3623762.3633494,
author = {Cutts, Quintin and Kallia, Maria and Anderson, Ruth and Crick, Tom and Devlin, Marie and Farghally, Mohammed and Mirolo, Claudio and Runde, Ragnhild Kobro and Sepp\""{a}l\""{a}, Otto and Urquiza-Fuentes, Jaime and Vahrenhold, Jan},
title = {Arguments for and Approaches to Computing Education in Undergraduate Computer Science Programmes},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633494},
doi = {10.1145/3623762.3633494},
abstract = {Computing education (CE), the scientific foundation of the teaching and learning of subject matter specific to computing, has matured into a field with its own research journals and conferences as well as graduate programmes. Yet, and unlike other mature subfields of computer science (CS), it is rarely taught as part of undergraduate CS programmes. In this report, we present a gap analysis resulting from semi-structured interviews with various types of stakeholders and derive a set of arguments for teaching CE courses in undergraduate CS programmes. This analysis and the arguments highlight a number of opportunities for the discipline of CS at large, in academia, in industry, and in school education, that would be opened up with undergraduate CE courses, as well as potential barriers to implementation that will need to be overcome. We also report on the results of a Delphi process performed to elicit topics for such a course with various audiences in mind. The Delphi process yielded 19 high-level categories that encompass the subject matter CE courses should incorporate, tailored to the specific needs of their intended student audiences. This outcome underscores the extensive range of content that can be integrated into a comprehensive CE programme. Based on these two stakeholder interactions as well as a systematic literature review aiming to explore the current practices in teaching CE to undergraduate students, we develop two prototypical outlines of such a course, keeping in mind that departments may have different preferences and affordances resulting in different kinds of CE offerings. Overall, input from external stakeholders underscores the clear significance of undergraduate CE courses. We anticipate leveraging this valuable feedback to actively promote these courses on a broader scale.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {160–195},
numpages = {36},
keywords = {argument, computing education, curriculum outline, undergraduate},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

",https://doi.org/10.1145/3623762.3633494,10.1145/3623762.3633494,acm,2023
621,The Robots Are Here: Navigating the Generative AI Revolution in Computing Education,"@inproceedings{10.1145/3623762.3633499,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

",https://doi.org/10.1145/3623762.3633499,10.1145/3623762.3633499,"acm, web_of_science, scopus",2023
622,MPI-RICAL: Data-Driven MPI Distributed Parallelism Assistance with Transformers,"@inproceedings{10.1145/3624062.3624063,
author = {Schneider, Nadav and Kadosh, Tal and Hasabnis, Niranjan and Mattson, Timothy and Pinter, Yuval and Oren, Gal},
title = {MPI-RICAL: Data-Driven MPI Distributed Parallelism Assistance with Transformers},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624063},
doi = {10.1145/3624062.3624063},
abstract = {Computational science has made rapid progress in recent years, leading to ever increasing demand for supercomputing resources. For scientific applications that leverage such resources, Message Passing Interface (MPI) plays a crucial role in enabling distributed memory parallelization across multiple nodes. However, parallelizing MPI code manually, and specifically, performing domain decomposition, is a challenging and error-prone task. In this paper, we address this problem by developing MPI-rical, a novel data-driven, programming-assistance tool that assists programmers in writing domain decomposition based distributed memory parallelization code using MPI. Specifically, we leverage Transformer architecture — the invention that led to advancements in the field of natural language processing (NLP) — with a supervised language model to suggest MPI functions and their proper locations in the code on the fly. In addition to the novel model for MPI-based parallel programming, in this paper, we also introduce MPICodeCorpus, the first publicly-available corpus of MPI-based parallel programs that is created by mining more than 15,000 open-source repositories on GitHub. Experimental results demonstrate the effectiveness of MPI-rical on both dataset from MPICodeCorpus and more importantly, on a compiled benchmark of MPI-based parallel programs for numerical computations that represent real-world scientific applications. Specifically, MPI-rical achieves F1 scores between 0.87-0.91 on these programs, demonstrating its accuracy in suggesting correct MPI functions at appropriate code locations. The source code used in this work, as well as other relevant sources, are available at: https://github.com/Scientific-Computing-Lab-NRCN/MPI-rical.},
booktitle = {Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {2–10},
numpages = {9},
keywords = {Domain Decomposition, LLM, MPI, MPI-rical, MPICodeCorpus, SPT-Code, Transformer},
location = {Denver, CO, USA},
series = {SC-W '23}
}

",https://doi.org/10.1145/3624062.3624063,10.1145/3624062.3624063,acm,2023
623,Computing Education in the Era of Generative AI,"@article{10.1145/3624720,
author = {Denny, Paul and Prather, James and Becker, Brett A. and Finnie-Ansley, James and Hellas, Arto and Leinonen, Juho and Luxton-Reilly, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami},
title = {Computing Education in the Era of Generative AI},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624720},
doi = {10.1145/3624720},
abstract = {Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.},
journal = {Commun. ACM},
month = {jan},
pages = {56–67},
numpages = {12}
}

",https://doi.org/10.1145/3624720,10.1145/3624720,acm,2024
624,The Science of Detecting LLM-Generated Text,"@article{10.1145/3624725,
author = {Tang, Ruixiang and Chuang, Yu-Neng and Hu, Xia},
title = {The Science of Detecting LLM-Generated Text},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624725},
doi = {10.1145/3624725},
abstract = {While many detection methods have been proposed, understanding the challenges is far more daunting.},
journal = {Commun. ACM},
month = {mar},
pages = {50–59},
numpages = {10}
}

",https://doi.org/10.1145/3624725,10.1145/3624725,acm,2024
625,Lossy Compression Options for Dense Index Retention,"@inproceedings{10.1145/3624918.3625316,
author = {Mackenzie, Joel and Moffat, Alistair},
title = {Lossy Compression Options for Dense Index Retention},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3625316},
doi = {10.1145/3624918.3625316},
abstract = {Dense indexes derived from whole-of-document neural models are now more effective at locating likely-relevant documents than are conventional term-based inverted indexes. That effectiveness comes at a cost, however: inverted indexes require less than a byte per posting to store, whereas dense indexes store a fixed-length vector of floating point coefficients (typically 768) for each document, making them potentially an order of magnitude larger. In this paper we consider compression of indexes employing dense vectors. Only limited space savings can be achieved via lossless compression techniques, but we demonstrate that dense indexes are responsive to lossy techniques that sacrifice controlled amounts of numeric resolution in order to gain compressibility. We describe suitable schemes, and, via experiments on three different collections, show that substantial space savings can be achieved with minimal loss of ranking fidelity. These techniques further boost the attractiveness of dense indexes for practical use.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {185–194},
numpages = {10},
keywords = {Index compression, dense indexing, lossy compression},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

",https://doi.org/10.1145/3624918.3625316,10.1145/3624918.3625316,acm,2023
626,From Guest to Family: An Innovative Framework for Enhancing Memorable Experiences in the Hotel Industry,"@inproceedings{10.1145/3625007.3632331,
author = {Alhamadani, Abdulaziz and Althubiti, Khadija and Sarkar, Shailik and He, Jianfeng and Alkulaib, Lulwah and Behal, Srishti and Khan, Mahmood and Lu, Chang-Tien},
title = {From Guest to Family: An Innovative Framework for Enhancing Memorable Experiences in the Hotel Industry},
year = {2024},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625007.3632331},
doi = {10.1145/3625007.3632331},
abstract = {This paper presents an innovative framework developed to identify, analyze, and generate memorable experiences in the hotel industry. People prefer memorable experiences over traditional services or products in today's ever-changing consumer world. As a result, the hospitality industry has shifted its focus toward creating unique and unforgettable experiences rather than just providing essential services. Despite the inherent subjectivity and difficulties in quantifying experiences, the quest to capture and understand these critical elements in the hospitality context has persisted. However, traditional methods have proven inadequate due to their reliance on objective surveys or limited social media data, resulting in a lack of diversity and potential bias. Our framework addresses these issues, offering a holistic solution that effectively identifies and extracts memorable experiences from online customer reviews, discerns trends on a monthly or yearly basis, and utilizes a local LLM to generate potential, unexplored experiences. As the first successfully deployed, fast, and accurate product of its kind in the industry, This framework significantly contributes to the hotel industry's efforts to enhance services and create compelling, personalized experiences for its customers.},
booktitle = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {492–501},
numpages = {10},
keywords = {hotel industry, memorable experience, keyword extraction, text generation, social media data mining},
location = {Kusadasi, Turkiye},
series = {ASONAM '23}
}

",https://doi.org/10.1145/3625007.3632331,10.1145/3625007.3632331,acm,2024
627,Editor's note,"@article{10.1145/3625384.3625385,
title = {Editor's note},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3625384.3625385},
doi = {10.1145/3625384.3625385},
abstract = {In this issue of the Reproducibility Retro from the EIG on Reproducibility and Replicability, we're interested in exploring the intersection of trust and reproducibility. We're in part inspired by the ACM's recent TechBrief (our first 'to be read' item below), which starts with a strong problem statement: ""the full potential of data-driven systems cannot be realized without better understanding the roots of the distrust they can engender."" But we know that building trustworthy systems for research (which includes its reproducibility) relies on three key pillars: legal, social, and technical.},
journal = {Reprod. Retro!},
month = {sep},
articleno = {1},
numpages = {5}
}

",https://doi.org/10.1145/3625384.3625385,10.1145/3625384.3625385,acm,2023
628,Toward Reproducing Network Research Results Using Large Language Models,"@inproceedings{10.1145/3626111.3628189,
author = {Xiang, Qiao and Lin, Yuling and Fang, Mingjun and Huang, Bang and Huang, Siyong and Wen, Ridi and Le, Franck and Kong, Linghe and Shu, Jiwu},
title = {Toward Reproducing Network Research Results Using Large Language Models},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626111.3628189},
doi = {10.1145/3626111.3628189},
abstract = {Reproducing research results is important for the networking community. The current best practice typically resorts to: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; or (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private ones are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). We first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report our observations and lessons and discuss future open research questions of this proposal.},
booktitle = {Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
pages = {56–62},
numpages = {7},
keywords = {Large language models, Networking systems},
location = {Cambridge, MA, USA},
series = {HotNets '23}
}

",https://doi.org/10.1145/3626111.3628189,10.1145/3626111.3628189,acm,2023
629,Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud,"@inproceedings{10.1145/3626246.3653378,
author = {Pavlenko, Anna and Cahoon, Joyce and Zhu, Yiwen and Kroth, Brian and Nelson, Michael and Carter, Andrew and Liao, David and Wright, Travis and Camacho-Rodr\'{\i}guez, Jes\'{u}s and Saur, Karla},
title = {Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653378},
doi = {10.1145/3626246.3653378},
abstract = {Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {241–254},
numpages = {14},
keywords = {containers, kubernetes, resource optimization, vertical auto-scaling},
location = {Santiago AA, Chile},
series = {SIGMOD/PODS '24}
}

",https://doi.org/10.1145/3626246.3653378,10.1145/3626246.3653378,acm,2024
630,A Large Scale RCT on Effective Error Messages in CS1,"@inproceedings{10.1145/3626252.3630764,
author = {Wang, Sierra and Mitchell, John and Piech, Chris},
title = {A Large Scale RCT on Effective Error Messages in CS1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630764},
doi = {10.1145/3626252.3630764},
abstract = {In this paper, we evaluate the most effective error message types through a large-scale randomized controlled trial conducted in an open-access, online introductory computer science course with 8,762 students from 146 countries. We assess existing error message enhancement strategies, as well as two novel approaches of our own: (1) generating error messages using OpenAI's GPT in real time and (2) constructing error messages that incorporate the course discussion forum. By examining students' direct responses to error messages, and their behavior throughout the course, we quantitatively evaluate the immediate and longer term efficacy of different error message types. We find that students using GPT generated error messages repeat an error 23.1% less often in the subsequent attempt, and resolve an error in 34.8% fewer additional attempts, compared to students using standard error messages. We also perform an analysis across various demographics to understand any disparities in the impact of different error message types. Our results find no significant difference in the effectiveness of GPT generated error messages for students from varying socioeconomic and demographic backgrounds. Our findings underscore GPT generated error messages as the most helpful error message type, especially as a universally effective intervention across demographics.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1395–1401},
numpages = {7},
keywords = {cs1, error messages, gpt, llm, randomized control trial},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630764,10.1145/3626252.3630764,"acm, web_of_science, scopus",2024
631,"AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style
  Feedback in a Global Course"," @inproceedings{Woodrow_2024, series={SIGCSE 2024}, title={AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course}, url={http://dx.doi.org/10.1145/3626252.3630773}, DOI={10.1145/3626252.3630773}, booktitle={Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1}, publisher={ACM}, author={Woodrow, Juliette and Malik, Ali and Piech, Chris}, year={2024}, month=mar, collection={SIGCSE 2024} }
",http://arxiv.org/pdf/2403.14986v1.pdf,10.1145/3626252.3630773,"arxiv, acm, web_of_science",2024
632,Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study,"@inproceedings{10.1145/3626252.3630784,
author = {Rogers, Michael P. and Hillberg, Hannah Miller and Groves, Christopher L.},
title = {Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630784},
doi = {10.1145/3626252.3630784},
abstract = {ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1147–1153},
numpages = {7},
keywords = {academic misconduct, artificial intelligence, chatgpt, large language models, student survey},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630784,10.1145/3626252.3630784,"acm, web_of_science, scopus",2024
633,Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science,"@inproceedings{10.1145/3626252.3630789,
author = {Liu, Mengqi and M'Hiri, Faten},
title = {Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630789},
doi = {10.1145/3626252.3630789},
abstract = {As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {743–749},
numpages = {7},
keywords = {adaptive teaching, chatgpt, cs education, gpt, llm, machine learning, novice programmers, openai, programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630789,10.1145/3626252.3630789,"acm, web_of_science, scopus",2024
634,"Brief, Just-in-Time Teaching Tips to Support Computer Science Tutors","@inproceedings{10.1145/3626252.3630794,
author = {Cheng, Alan Y. and Tanimura, Ellie and Tey, Joseph and Wu, Andrew C. and Brunskill, Emma},
title = {Brief, Just-in-Time Teaching Tips to Support Computer Science Tutors},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630794},
doi = {10.1145/3626252.3630794},
abstract = {As enrollments in computing-related programs continue to rise, computer science departments are increasingly relying on teaching assistants (TAs) to provide additional educational support to students, such as one-on-one tutoring or office hours. Tutoring is more effective with highly trained tutors, but most TAs receive little to no training in pedagogical skills. How might we provide support to TAs working with students one-on-one, especially in online settings? We propose a just-in-time intervention that shows a tutor actionable teaching tips and relevant information right before they begin an online tutoring session with a student. We conducted a crossover experiment (n = 46) where participants engaged in two tutoring roleplays for an introductory computer science programming task and found that participants demonstrated effective instructional strategies for much longer periods of time after receiving the intervention. We discuss the implications of these findings for both educators looking to support tutors and researchers seeking to build technology for tutors.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {200–206},
numpages = {7},
keywords = {online tutoring teacher training, remote tutoring, ta training, tutoring},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630794,10.1145/3626252.3630794,acm,2024
635,Can Lexical Sophistication and Cohesion Automatically Differentiate Student Engagement in Socio-technical Platforms?,"@inproceedings{10.1145/3626252.3630800,
author = {Akgun, Mahir and Sharma, Priya and Li, Qiyuan},
title = {Can Lexical Sophistication and Cohesion Automatically Differentiate Student Engagement in Socio-technical Platforms?},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630800},
doi = {10.1145/3626252.3630800},
abstract = {This work aims to better analyze student engagement in socio-technical platforms by investigating whether the language students produce in online discussions is an indication of their cognitive engagement in collaborative activities. Primarily, this study evaluates whether a combination of linguistic features related to lexical sophistication and cohesion can capture students' cognitive engagement levels in an online course. We downloaded and annotated posts from the online platform for an undergraduate information sciences and technology course to create the human-coded dataset. Then, we assessed the lexical sophistication and cohesion of human-annotated posts and used lexical sophistication and cohesion indices in multivariate analysis of variance (MANOVA). A subsequent analysis using discriminant function analysis (DFA) suggested that the discriminant functions obtained from the human-annotated posts indicate a distinction between cognitive engagement categories. While the DFA model developed using cohesion indices shows a clear separation between cognitive engagement categories, the model built on lexical sophistication indices provides a partial separation. Study results suggest a promising approach for the application of linguistic features to support the categorization of discourse based on cognitive engagement.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {25–31},
numpages = {7},
keywords = {cognitive engagement, cohesion, collaborative learning, lexical sophistication, linguistic features},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630800,10.1145/3626252.3630800,acm,2024
636,ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions,"@inproceedings{10.1145/3626252.3630803,
author = {Joshi, Ishika and Budhiraja, Ritvik and Dev, Harshal and Kadia, Jahnvi and Ataullah, Mohammad Osama and Mitra, Sayan and Akolekar, Harshal D. and Kumar, Dhruv},
title = {ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630803},
doi = {10.1145/3626252.3630803},
abstract = {This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {625–631},
numpages = {7},
keywords = {chatgpt, computer science, education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630803,10.1145/3626252.3630803,"acm, scopus",2024
637,CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI,"@inproceedings{10.1145/3626252.3630817,
author = {Fernandez, Amanda S. and Cornell, Kimberly A.},
title = {CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630817},
doi = {10.1145/3626252.3630817},
abstract = {As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create ""black box"" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {345–351},
numpages = {7},
keywords = {ai, artificial intelligence, code generation, copilot, cs1, gpt-4, introductory programming, large language model, llm, machine learning, novice programmers, programming, prompt engineering, secure code, software verification},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630817,10.1145/3626252.3630817,"acm, web_of_science, scopus",2024
638,dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models,"@inproceedings{10.1145/3626252.3630822,
author = {Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond},
title = {dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630822},
doi = {10.1145/3626252.3630822},
abstract = {In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1314–1320},
numpages = {7},
keywords = {ai in cs1, ai in education, compiler error messages, cs1, debugging, error message enhancement, generative ai, large language models, programming error messages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630822,10.1145/3626252.3630822,"acm, web_of_science, scopus",2024
639,Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models,"@inproceedings{10.1145/3626252.3630826,
author = {Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita},
title = {Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630826},
doi = {10.1145/3626252.3630826},
abstract = {The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {526–532},
numpages = {7},
keywords = {artificial intelligence, chatgpt, cheat detection, cs1, introductory programming course, large language model, plagiarism detection},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630826,10.1145/3626252.3630826,"acm, web_of_science, scopus",2024
640,A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design,"@inproceedings{10.1145/3626252.3630828,
author = {Prasad, Prajish and Sane, Aamod},
title = {A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630828},
doi = {10.1145/3626252.3630828},
abstract = {Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1070–1076},
numpages = {7},
keywords = {chatgpt, generative ai, llm, metacognition, pair programming, pair thinking, self-regulated learning, self-regulation, srl},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630828,10.1145/3626252.3630828,"acm, web_of_science, scopus",2024
641,Trust in Generative AI among Students: An exploratory study,"@inproceedings{10.1145/3626252.3630842,
author = {Amoozadeh, Matin and Daniels, David and Nam, Daye and Kumar, Aayush and Chen, Stella and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Mohammad Amin},
title = {Trust in Generative AI among Students: An exploratory study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630842},
doi = {10.1145/3626252.3630842},
abstract = {Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {67–73},
numpages = {7},
keywords = {generative ai, novice programmers, trust},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630842,10.1145/3626252.3630842,acm,2024
642,Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development,"@article{2-s2.0-85189360811,
  title={Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189360811&origin=inward,10.1145/3626252.3630854,scopus,2024
643,Evaluating Automatically Generated Contextualised Programming Exercises,"@inproceedings{10.1145/3626252.3630863,
author = {Del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating Automatically Generated Contextualised Programming Exercises},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630863},
doi = {10.1145/3626252.3630863},
abstract = {Introductory programming courses often require students to solve many small programming exercises as part of their learning. Researchers have previously suggested that the context used in the problem description for these exercises is likely to impact student engagement and motivation. Furthermore, supplying programming exercises that use a broad range of contexts or even allowing students to select contexts to personalize their own exercises, may support the interests of a diverse student population. Unfortunately, it is time-consuming for instructors to create large numbers of programming exercises that provide a wide range of contextualized problems. However, recent work has shown that large language models may be able to automate the mass production of programming exercises, reducing the burden on instructors. In this research, we explore the potential of OpenAI's GPT-4 to create high-quality and novel programming exercises that implement various contexts. Finally, through prompt engineering, we compare different prompting strategies used to generate many programming exercises with various contextualized problem descriptions and then evaluate the quality of the exercises generated.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {289–295},
numpages = {7},
keywords = {chatgpt, cs1, gpt-4, large language models, novice programmers, openai, programming exercises, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630863,10.1145/3626252.3630863,"acm, scopus",2024
644,Implications of ChatGPT for Data Science Education,"@inproceedings{10.1145/3626252.3630874,
author = {Shen, Yiyin and Ai, Xinyi and Soosai Raj, Adalbert Gerald and Leo John, Rogers Jeffrey and Syamkumar, Meenakshi},
title = {Implications of ChatGPT for Data Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630874},
doi = {10.1145/3626252.3630874},
abstract = {ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1230–1236},
numpages = {7},
keywords = {data science education, large language models, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630874,10.1145/3626252.3630874,"acm, scopus",2024
645,Improved Program Repair Methods using Refactoring with GPT Models,"@inproceedings{10.1145/3626252.3630875,
author = {Ishizue, Ryosuke and Sakamoto, Kazunori and Washizaki, Hironori and Fukazawa, Yoshiaki},
title = {Improved Program Repair Methods using Refactoring with GPT Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630875},
doi = {10.1145/3626252.3630875},
abstract = {Teachers often utilize automatic program repair methods to provide feedback on submitted student code using model answer code. A state-of-the-art tool is Refactory, which achieves a high repair success rate and small patch size (less code repair) by refactoring code to expand the variety of correct code samples that can be referenced. However, Refactory has two major limitations. First, it cannot fix code with syntax errors. Second, it has difficulty fixing code when there are few correct submissions. Herein we propose a new method that combines Refactory and OpenAI's GPT models to address these issues and conduct a performance measurement experiment. The experiment uses a dataset consisting of 5 programming assignment problems and almost 1,800 real-life incorrect Python program submissions from 361 students for an introductory programming course at a large public university. The proposed method improves the repair success rate by 1-21% when the set of correct code samples is sufficient and the patch size is smaller than Refactory alone in 16-45% of the cases. When there was no set of correct code samples at all (only the model answer code was used as a reference for repair), method improves the repair success rate by 1-43% and the patch size is smaller than Refactory alone in 42-68% of the cases.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {569–575},
numpages = {7},
keywords = {generative ai, program repair, programming assignment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630875,10.1145/3626252.3630875,acm,2024
646,Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study,"@inproceedings{10.1145/3626252.3630880,
author = {Sheard, Judy and Denny, Paul and Hellas, Arto and Leinonen, Juho and Malmi, Lauri and Simon},
title = {Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630880},
doi = {10.1145/3626252.3630880},
abstract = {Much of the recent work investigating large language models and AI Code Generation tools in computing education has focused on assessing their capabilities for solving typical programming problems and for generating resources such as code explanations and exercises. If progress is to be made toward the inevitable lasting pedagogical change, there is a need for research that explores the instructor voice, seeking to understand how instructors with a range of experiences plan to adapt. In this paper, we report the results of an interview study involving 12 instructors from Australia, Finland and New Zealand, in which we investigate educators' current practices, concerns, and planned adaptations relating to these tools. Through this empirical study, our goal is to prompt dialogue between researchers and educators to inform new pedagogical strategies in response to the rapidly evolving landscape of AI code generation tools.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1223–1229},
numpages = {7},
keywords = {ai code generation, generative ai, instructor perceptions, interview study, large language models, llms, programming education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630880,10.1145/3626252.3630880,"acm, scopus",2024
647,Learners Teaching Novices: An Uplifting Alternative Assessment," @inproceedings{Malik_2024, series={SIGCSE 2024}, title={Learners Teaching Novices: An Uplifting Alternative Assessment}, url={http://dx.doi.org/10.1145/3626252.3630887}, DOI={10.1145/3626252.3630887}, booktitle={Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1}, publisher={ACM}, author={Malik, Ali and Woodrow, Juliette and Piech, Chris}, year={2024}, month=mar, collection={SIGCSE 2024} }
",http://arxiv.org/pdf/2403.14971v1.pdf,10.1145/3626252.3630887,"arxiv, acm",2024
648,Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5,"@inproceedings{10.1145/3626252.3630897,
author = {Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald},
title = {Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630897},
doi = {10.1145/3626252.3630897},
abstract = {Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {618–624},
numpages = {7},
keywords = {introductory programming, large language models, non-native english speakers, problem generation},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630897,10.1145/3626252.3630897,"acm, web_of_science, scopus",2024
649,Prompt Problems: A New Programming Exercise for the Generative AI Era,"@inproceedings{10.1145/3626252.3630909,
author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
title = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630909},
doi = {10.1145/3626252.3630909},
abstract = {Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {296–302},
numpages = {7},
keywords = {ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630909,10.1145/3626252.3630909,"acm, web_of_science, scopus",2024
650,Software Engineering Education Must Adapt and Evolve for an LLM Environment,"@inproceedings{10.1145/3626252.3630927,
author = {Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.},
title = {Software Engineering Education Must Adapt and Evolve for an LLM Environment},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630927},
doi = {10.1145/3626252.3630927},
abstract = {In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {666–672},
numpages = {7},
keywords = {chatgpt, generative ai, large language models (llms), responsible ai, software engineering, software engineering education, software engineering ethics, software ethics},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630927,10.1145/3626252.3630927,"acm, web_of_science, scopus",2024
651,Solving Proof Block Problems Using Large Language Models,"@inproceedings{10.1145/3626252.3630928,
author = {Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.},
title = {Solving Proof Block Problems Using Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630928},
doi = {10.1145/3626252.3630928},
abstract = {Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1063–1069},
numpages = {7},
keywords = {ai, algorithms, artificial intelligence, chatgpt, code generation, generative ai, gpt-3, gpt-4, large language models, openai, proof blocks, proofs},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630928,10.1145/3626252.3630928,"acm, scopus",2024
652,"Teaching AI to K-12 Learners: Lessons, Issues, and Guidance","@inproceedings{10.1145/3626252.3630937,
author = {Grover, Shuchi},
title = {Teaching AI to K-12 Learners: Lessons, Issues, and Guidance},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630937},
doi = {10.1145/3626252.3630937},
abstract = {There is growing recognition of the need to teach artificial intelli- gence (AI) and machine learning (ML) at the school level. This push acknowledges the meteoric growth in the range and diversity of ap- plications of ML in all industries and everyday consumer products, with Large Language Models (LLMs) being only the latest and most compelling example yet. Efforts to bring AI, especially ML educa- tion to school learners are being propelled by substantial industry interest, research efforts, as well as technological developments that make sophisticated ML tools readily available to learners of all ages. These early efforts span a variety of learning goals captured by the AI4K12 ""big ideas"" framework and employ a plurality of pedagogies.This paper provides a sense for the current state of the field, shares lessons learned from early K-12 AI education as well as CS education efforts that can be leveraged, highlights issues that must be addressed in designing for teaching AI in K-12, and provides guidance for future K-12 AI education efforts and tackle what to many feels like ""the next new thing"".},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {422–428},
numpages = {7},
keywords = {artificial intelligence, k-12 ai education, k-12 cs education, machine learning},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630937,10.1145/3626252.3630937,acm,2024
653,Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education,"@inproceedings{10.1145/3626252.3630938,
author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630938},
doi = {10.1145/3626252.3630938},
abstract = {In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had ""a personal tutor.'' Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {750–756},
numpages = {7},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630938,10.1145/3626252.3630938,"acm, scopus",2024
654,The Case for LLM Workshops,"@inproceedings{10.1145/3626252.3630941,
author = {Bopp, Chris and Foerst, Anne and Kellogg, Brian},
title = {The Case for LLM Workshops},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630941},
doi = {10.1145/3626252.3630941},
abstract = {Large Language Models (LLMs) are radically changing the academic landscape. Many professors are unaware of how LLMs work and are therefore unsure how to incorporate them in their teaching. This is problematic as students will use them anyway. In this paper, we outline our institution as a case study for a curricular initiative. We develop an intellectual framework for creating workshops for faculty at small liberal arts universities. We base their development on the literature we have analyzed and discussed as a group. Our approach is to address our colleagues across a variety of different disciplines and teach them the responsible use of LLMs in the classroom. We also teach our colleagues how to modify assignments to make them, to some extent, LLM proof. This includes adding personalized elements, and including LLM designed parts explicitly, such as article summaries. We also design a syllabus policy about the responsible use of LLMs. We present philosophical and ethical challenges and teach a list of other actionable items. We ultimately support the use of LLMs in academia but seek to teach our colleagues how they can guide students to use them mindfully and responsibly.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {130–136},
numpages = {7},
keywords = {ethics, large language models, liberal arts universities, pedagogy, philosophy, workshops},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630941,10.1145/3626252.3630941,"acm, web_of_science",2024
655,Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review,"@inproceedings{10.1145/3626252.3630958,
author = {Cambaz, Doga and Zhang, Xiaoling},
title = {Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630958},
doi = {10.1145/3626252.3630958},
abstract = {The recent emergence of LLM-based code generation models can potentially transform programming education. To pinpoint the current state of research on using LLM-based code generators to support the teaching and learning of programming, we conducted a systematic literature review of 21 papers published since 2018. The review focuses on (1) the teaching and learning practices in programming education that utilized LLM-based code generation models, (2) characteristics and (3) performance indicators of the models, and (4) aspects to consider when utilizing the models in programming education, including the risks and challenges. We found that the most commonly reported uses of LLM-based code generation models for teachers are generating assignments and evaluating student work, while for students, the models function as virtual tutors. We identified that the models exhibit accuracy limitations; generated content often contains minor errors that are manageable by instructors but pose risks for novice learners. Moreover, risks such as academic misconduct and over-reliance on the models are critical when considering integrating these models into education. Overall, LLM-based code generation models can be an assistive tool for both learners and instructors if the risks are mitigated.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {artificial intelligence in education, code generation models, large language models, programming education, systematic review},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630958,10.1145/3626252.3630958,"acm, web_of_science, scopus",2024
656,"Using GPT-4 to Provide Tiered, Formative Code Feedback","@inproceedings{10.1145/3626252.3630960,
author = {Nguyen, Ha and Allan, Vicki},
title = {Using GPT-4 to Provide Tiered, Formative Code Feedback},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630960},
doi = {10.1145/3626252.3630960},
abstract = {Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {958–964},
numpages = {7},
keywords = {computer science education, feedback, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

",https://doi.org/10.1145/3626252.3630960,10.1145/3626252.3630960,"acm, web_of_science, scopus",2024
657,DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface,"@article{2-s2.0-85189142855,
  title={DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189142855&origin=inward,10.1145/3626253.3635483,scopus,2024
658,My Learnings from Allowing Large Language Models in Introductory Computer Science Classes,"@article{2-s2.0-85189138134,
  title={My Learnings from Allowing Large Language Models in Introductory Computer Science Classes},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189138134&origin=inward,10.1145/3626253.3635511,scopus,2024
659,"Evaluating Large Language Model Code Generation as an Autograding Mechanism for ""Explain in Plain English"" Questions","@article{2-s2.0-85189147391,
  title={Evaluating Large Language Model Code Generation as an Autograding Mechanism for ""Explain in Plain English"" Questions},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189147391&origin=inward,10.1145/3626253.3635542,scopus,2024
660,CAET: Code Analysis and Education Tutor,"@article{2-s2.0-85189161612,
  title={CAET: Code Analysis and Education Tutor},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189161612&origin=inward,10.1145/3626253.3635543,scopus,2024
661,Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises,"@article{2-s2.0-85189183730,
  title={Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189183730&origin=inward,10.1145/3626253.3635592,scopus,2024
662,Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing,"@article{2-s2.0-85189137107,
  title={Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189137107&origin=inward,10.1145/3626253.3635606,scopus,2024
663,Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models,"@article{2-s2.0-85189146522,
  title={Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189146522&origin=inward,10.1145/3626253.3635624,scopus,2024
664,Script-Generated Picture Book Technology Based on Large Language Models and AIGC,"@inproceedings{10.1145/3626686.3626704,
author = {Wang, Dejiang and Zhai, Zhuoran and Cheong, Ngai and Peng, Li},
title = {Script-Generated Picture Book Technology Based on Large Language Models and AIGC},
year = {2023},
isbn = {9798400708527},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626686.3626704},
doi = {10.1145/3626686.3626704},
abstract = {This paper mainly discusses how to use the large language models such as GPT and Ernie model combined with the AIGC tools represented by stable diffusion, which uses a random story script to generate images with fixed style, character characteristics, and continuous plots. The article provides a detailed introduction to how to build an assembly line, using a large language model and a story script to generate the prompt words required for stable diffusion. Subsequently, by comparing the characteristics of traditional picture book production and the image results of using language models word prompts, summarize the limitations of text to images. This leads to a supervised multi round iterative LoRA model scheme that utilizes the CLIP to achieve character IP fixation. Simultaneously using the ControlNet model and inpainting to preprocess and reprocess the image can achieve controllable character poses and fixed backgrounds in the picture book. Finally, we will evaluate and summarize the new scheme and analyze its strengths in picture book creation accordingly.},
booktitle = {Proceedings of the 7th International Conference on Digital Technology in Education},
pages = {104–108},
numpages = {5},
location = {Hangzhou, China},
series = {ICDTE '23}
}

",https://doi.org/10.1145/3626686.3626704,10.1145/3626686.3626704,acm,2023
665,"Conversational Interfaces in IoT Ecosystems: Where We Are, What Is Still Missing","@inproceedings{10.1145/3626705.3627775,
author = {Gallo, Simone and Paterno, Fabio and Malizia, Alessio},
title = {Conversational Interfaces in IoT Ecosystems: Where We Are, What Is Still Missing},
year = {2023},
isbn = {9798400709210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626705.3627775},
doi = {10.1145/3626705.3627775},
abstract = {In the last few years, text and voice-based conversational agents have become more and more popular all over the world as virtual assistants for a variety of tasks. In addition, the deployment on the market of many smart objects connected with these agents has introduced the possibility of controlling and personalising the behaviour of several connected objects using natural language. This has the potential to allow people, also those without a technical background, to effectively control and use the wide variety of connected objects and services. In this paper, we present an analysis of how conversational agents have been used to interact with smart environments (such as smart homes). For this purpose, we have carried out a systematic literature review considering publications selected from the ACM and IEEE digital libraries to investigate the technologies used to design and develop conversational agents for IoT settings, including Artificial Intelligence techniques, the purpose that they have been used for, and the level of user involvement in such studies. The resulting analysis is useful to better understand how this field is evolving and indicate the challenges still open in this area that should be addressed in future research work to allow people to completely benefit from this type of solution.},
booktitle = {Proceedings of the 22nd International Conference on Mobile and Ubiquitous Multimedia},
pages = {279–293},
numpages = {15},
keywords = {Conversational Agents, Internet of Things, User Experience},
location = {Vienna, Austria},
series = {MUM '23}
}

",https://doi.org/10.1145/3626705.3627775,10.1145/3626705.3627775,acm,2023
666,Pervasive Chatbots: Investigating Chatbot Interventions for Multi-Device Applications,"@inproceedings{10.1145/3627043.3659570,
author = {Olapade, Mayowa and Hasanli, Tarlan and Ottun, Abdul-Rasheed and Akintola, Adeyinka and Liyanage, Mohan and Flores, Huber},
title = {Pervasive Chatbots: Investigating Chatbot Interventions for Multi-Device Applications},
year = {2024},
isbn = {9798400704338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627043.3659570},
doi = {10.1145/3627043.3659570},
abstract = {The inherent social characteristics of humans make them prone to adopting distributed and collaborative applications easily. Although fundamental methods and technologies have been defined and developed over the years to construct these applications, their adoption in practice is uncommon because end-users may be puzzled about how to use them without much hassle. Indeed, commonly, these applications require a certain level of technical expertise and awareness to use them correctly. Fortunately, AI-chatbot interventions are envisioned to assist and support various human tasks. In this paper, we contribute pervasive chatbots as a solution that fosters a more transparent and user-friendly interconnection of devices in distributed and collaborative environments. Through two rigorous user studies, firstly, we quantify the perception of users toward distributed and collaborative applications (N = 56 participants). Secondly, we analyze the benefits of adopting pervasive chatbots when compared with the chatbot reference model designed for assistance and recommendations (N = 24 participants). Our results suggest that pervasive chatbots can significantly enhance the practicability of distributed and collaborative applications, reducing the time and effort needed for collaboration with surrounding devices by 57%. With this information, we then provide design and development implications to integrate pervasive chatbot interventions in distributed and collaborative environments. Moreover, challenges and opportunities are also provided to highlight the remaining issues that need to be addressed to realize the full vision of pervasive chatbots for any multi-device application. Our work paves the way towards the proliferation of sophisticated and highly decentralized computing environments that are easily interconnected.},
booktitle = {Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {290–300},
numpages = {11},
keywords = {Decentralized infrastructures, collaborative computing, distributed computing, opportunistic networks},
location = {Cagliari, Italy},
series = {UMAP '24}
}

",https://doi.org/10.1145/3627043.3659570,10.1145/3627043.3659570,acm,2024
667,Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs,"@inproceedings{10.1145/3627217.3627233,
author = {Balse, Rishabh and Kumar, Viraj and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627233},
doi = {10.1145/3627217.3627233},
abstract = {When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30&nbsp;buggy student solutions across 6&nbsp;code-writing problems. First, in a study with 5&nbsp;undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30&nbsp;buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {49–54},
numpages = {6},
keywords = {Explanation, GPT-3.5-Turbo, Large language models (LLMs), Logical Errors, Python Programming},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

",https://doi.org/10.1145/3627217.3627233,10.1145/3627217.3627233,"acm, web_of_science, scopus",2023
668,GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements,"@inproceedings{10.1145/3627217.3627234,
author = {Pawagi, Mrigank and Kumar, Viraj},
title = {GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627234},
doi = {10.1145/3627217.3627234},
abstract = {Before implementing a function, programmers are encouraged to write a purpose statement i.e., a short, natural-language explanation of what the function computes. A purpose statement may be ambiguous i.e., it may fail to specify the intended behaviour when two or more inequivalent computations are plausible on certain inputs. Our paper makes four contributions. First, we propose a novel heuristic that suggests such inputs using Large Language Models (LLMs). Using these suggestions, the programmer may choose to clarify the purpose statement (e.g., by providing a functional example that specifies the intended behaviour on such an input). Second, to assess the quality of inputs suggested by our heuristic, and to facilitate future research, we create an open dataset of purpose statements with known ambiguities. Third, we compare our heuristic against GitHub Copilot’s Chat feature, which can suggest similar inputs when prompted to generate unit tests. Fourth, we provide an open-source implementation of our heuristic as an extension to Visual Studio Code for the Python programming language, where purpose statements and functional examples are specified as docstrings and doctests respectively. We believe that this tool will be particularly helpful to novice programmers and instructors.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {55–60},
numpages = {6},
keywords = {CS1, function design, purpose statement},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

",https://doi.org/10.1145/3627217.3627234,10.1145/3627217.3627234,acm,2023
669,Evaluating Copilot on CS1 Code Writing Problems with Suppressed Specifications,"@article{2-s2.0-85180417465,
  title={Evaluating Copilot on CS1 Code Writing Problems with Suppressed Specifications},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180417465&origin=inward,10.1145/3627217.3627235,scopus,2023
670,Comparing Traditional and LLM-based Search for Image Geolocation,"@inproceedings{10.1145/3627508.3638305,
author = {Wazzan, Albatool and MacNeil, Stephen and Souvenir, Richard},
title = {Comparing Traditional and LLM-based Search for Image Geolocation},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638305},
doi = {10.1145/3627508.3638305},
abstract = {Web search engines have long served as indispensable tools for information retrieval; user behavior and query formulation strategies have been well studied. The introduction of search engines powered by large language models (LLMs) suggested more conversational search and new types of query strategies. In this paper, we compare traditional and LLM-based search for the task of image geolocation, i.e., determining the location where an image was captured. Our work examines user interactions, with a particular focus on query formulation strategies. In our study, 60 participants were assigned either traditional or LLM-based search engines as assistants for geolocation. Participants using traditional search more accurately predicted the location of the image compared to those using the LLM-based search. Distinct strategies emerged between users depending on the type of assistant. Participants using the LLM-based search issued longer, more natural language queries, but had shorter search sessions. When reformulating their search queries, traditional search participants tended to add more terms to their initial queries, whereas participants using the LLM-based search consistently rephrased their initial queries.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {291–302},
numpages = {12},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

",https://doi.org/10.1145/3627508.3638305,10.1145/3627508.3638305,acm,2024
671,“Intelligent Heuristics Are the Future of Computing”,"@article{10.1145/3627708,
author = {Teng, Shang-Hua},
title = {“Intelligent Heuristics Are the Future of Computing”},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3627708},
doi = {10.1145/3627708},
abstract = {Back in 1988, the partial game trees explored by computer chess programs were among the largest search structures in real-world computing. Because the game tree is too large to be fully evaluated, chess programs must make heuristic strategic decisions based on partial information, making it an illustrative subject for teaching AI search. In one of his lectures that year on AI search for games and puzzles, Professor Hans Berliner—a pioneer of computer chess programs1—stated:As a student in the field of the theory of computation, I was naturally perplexed but fascinated by this perspective. I had been trained to believe that “Algorithms and computational complexity theory are the foundation of computer science.” However, as it happens, my attempts to understand heuristics in computing have subsequently played a significant role in my career as a theoretical computer scientist. I have come to realize that Berliner’s postulation is a far-reaching worldview, particularly in the age of big, rich, complex, and multifaceted data and models, when computing has ubiquitous interactions with science, engineering, humanity, and society. In this article,2I will share some of my experiences on the subject of heuristics in computing, presenting examples of theoretical attempts to understand the behavior of heuristics on real data, as well as efforts to design practical heuristics with desirable theoretical characterizations. My hope is that these theoretical insights from past heuristics—such as spectral partitioning, multilevel methods, evolutionary algorithms, and simplex methods—can shed light on and further inspire a deeper understanding of the current and future techniques in AI and data mining.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {nov},
articleno = {96},
numpages = {39},
keywords = {Heuristics in computing, data mining, AI, network analysis, data analysis, deep learning, spectral graph theory, multilevel methods, smoothed analysis, beyond worst-cast analysis, axiomatic approach, linear programming, evolutionary algorithm, local clustering, robust statistics, game trees, binary decision diagram, PageRank, spectral graph sparsification, dimensionality reduction, Shapley value, network influence, network centrality}
}

",https://doi.org/10.1145/3627708,10.1145/3627708,acm,2023
672,Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study,"@article{10.1145/3628162,
author = {Shoufan, Abdulhadi},
title = {Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {4},
url = {https://doi.org/10.1145/3628162},
doi = {10.1145/3628162},
abstract = {With the immense interest in ChatGPT worldwide, education has seen a mix of both excitement and skepticism. To properly evaluate its impact on education, it is crucial to understand how far it can help students without prior knowledge answer assessment questions. This study aims to address this question as well as the impact of the question type. We conducted multiple experiments with computer engineering students (experiment group: n=41 to 56), who were asked to use ChatGPT to answer previous test questions before learning about the related topics. Their scores were then compared with the scores of previous-term students who answered the same questions in a quiz or exam setting (control group: n=24 to 61). The results showed a wide range of effect sizes, from -2.55 to 1.23, depending on the question type and content. The experiment group performed best answering code analysis and conceptual questions but struggled with code completion and questions that involved images. However, the performance in code generation tasks was inconsistent. Overall, the ChatGPT group’s answers lagged slightly behind the control group’s answers with an effect size of -0.16. We conclude that ChatGPT, at least in the field of this study, is not yet ready to rely on by students who do not have sufficient background to evaluate generated answers. We suggest that educators try using ChatGPT and educate students on effective questioning techniques and how to assess the generated responses. This study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.},
journal = {ACM Trans. Comput. Educ.},
month = {dec},
articleno = {45},
numpages = {29},
keywords = {ChatGPT, large language models}
}

",https://doi.org/10.1145/3628162,10.1145/3628162,"acm, scopus",2023
673,University Students’ Acceptance and Usage of Generative AI (ChatGPT) from a Psycho-Technical Perspective,"@inproceedings{10.1145/3628454.3629552,
author = {Faruk, Lawal Ibrahim Dutsinma and Rohan, Rohani and Ninrutsirikun, Unhawa and Pal, Debajyoti},
title = {University Students’ Acceptance and Usage of Generative AI (ChatGPT) from a Psycho-Technical Perspective},
year = {2023},
isbn = {9798400708497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628454.3629552},
doi = {10.1145/3628454.3629552},
abstract = {The emergence of ChatGPT as a generative AI tool has revolutionized the educational scenario by bringing in unprecedented changes. In this respect exploring the factors that affect the adoption and acceptance of ChatGPT services for educational purpose is of utmost importance. Accordingly, in this work we take a hybrid psycho-technical approach by considering the technological (perceived usefulness, ease of use and facilitating conditions), contextual (perceived humanness and novelty value), and psychological (agreeableness, extraversion, openness, conscientiousness, and neuroticism) gratifications of ChatGPT use. Data is collected from a sample of university students who use ChatGPT regularly across two Asian countries. The data analysis is done using Partial Least Squares Structural Equation Modelling. Results indicate that among the technical factors only perceived usefulness successfully predicts ChatGPT usage. Both the contextual factors of humanness and novelty use significantly explain ChatGPT usage. Finally, among the psychological factors’ openness, agreeableness, and neuroticism determine the usage scenario, however, the later two are found to be negatively associated with ChatGPT usage.},
booktitle = {Proceedings of the 13th International Conference on Advances in Information Technology},
articleno = {15},
numpages = {8},
keywords = {ChatGPT, higher education, novelty value, perceived humanness, personality},
location = {Bangkok, Thailand},
series = {IAIT '23}
}

",https://doi.org/10.1145/3628454.3629552,10.1145/3628454.3629552,acm,2023
674,Unlocking the Black Box: Exploring the use of Generative AI (ChatGPT) in Information Systems Research,"@inproceedings{10.1145/3628454.3629998,
author = {Rohan, Rohani and Faruk, Lawal Ibrahim Dutsinma and Puapholthep, Kittiphan and Pal, Debajyoti},
title = {Unlocking the Black Box: Exploring the use of Generative AI (ChatGPT) in Information Systems Research},
year = {2023},
isbn = {9798400708497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628454.3629998},
doi = {10.1145/3628454.3629998},
abstract = {With the gaining popularity of generative AI tools like ChatGPT and their usage across several domains and disciplines, the question that naturally arises is how it can help the Information Systems (IS) researchers? Measuring hidden or latent constructs is one critical and primitive aspects of the IS domain that has always been challenging due to its abstractness. How good or bad these specially trained AI-based models are with respect to their conceptual understanding capabilities of specific IS constructs together with their usage for the purpose of testing IS theories is an unknown area. We set out to explore these unknown aspects in this work by conducting two separate experiments with ChatGPT using the already proven and robust Technology Acceptance Model (TAM) as the reference. Our results suggest that ChatGPT has good conceptual understanding of the presented latent constructs, although there might be certain validity issues in case of complex models. Therefore, it shows promise in the broader aspect of testing theories, but not without its limitations that we present in this research.},
booktitle = {Proceedings of the 13th International Conference on Advances in Information Technology},
articleno = {17},
numpages = {9},
keywords = {ChatGPT, information systems, latent constructs, scale, technology acceptance model},
location = {Bangkok, Thailand},
series = {IAIT '23}
}

",https://doi.org/10.1145/3628454.3629998,10.1145/3628454.3629998,acm,2023
675,Vi-ATISO: An Effective Video Search Engine at AI Challenge HCMC 2023,"@inproceedings{10.1145/3628797.3628997,
author = {Nguyen, Quang-Tan and Nguyen, Xuan-Quang and Ho, Trong-Bao and Truong, Duc-Thang and Le, Minh-Hoang},
title = {Vi-ATISO: An Effective Video Search Engine at AI Challenge HCMC 2023},
year = {2023},
isbn = {9798400708916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628797.3628997},
doi = {10.1145/3628797.3628997},
abstract = {In this paper, we present the first version of Vi-ATISO, a fast and efficient video search engine on medium-scale datasets. The tool provides several search functions based on text-to-image retrieval, text-to-video retrieval, optical character recognition, and object detection algorithms. With diverse algorithms provided, our system can handle a larger amount of data from the AI Challenge HCMC 2023 and achieve good results. In addition, we feel confident that this search engine can be applied in practice because we also consider user experience during the development process.},
booktitle = {Proceedings of the 12th International Symposium on Information and Communication Technology},
pages = {960–965},
numpages = {6},
keywords = {Interactive retrieval system, Lifelog, Video event retrieval},
location = {Ho Chi Minh, Vietnam},
series = {SOICT '23}
}

",https://doi.org/10.1145/3628797.3628997,10.1145/3628797.3628997,acm,2023
676,Data Feminism for AI,"@inproceedings{10.1145/3630106.3658543,
author = {Klein, Lauren and D'Ignazio, Catherine},
title = {Data Feminism for AI},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658543},
doi = {10.1145/3630106.3658543},
abstract = {This paper presents a set of intersectional feminist principles for conducting equitable, ethical, and sustainable AI research. In Data Feminism (2020), we offered seven principles for examining and challenging unequal power in data science. Here, we present a rationale for why feminism remains deeply relevant for AI research, rearticulate the original principles of data feminism with respect to AI, and introduce two potential new principles related to environmental impact and consent. Together, these principles help to 1) account for the unequal, undemocratic, extractive, and exclusionary forces at work in AI research, development, and deployment; 2) identify and mitigate predictable harms in advance of unsafe, discriminatory, or otherwise oppressive systems being released into the world; and 3) inspire creative, joyful, and collective ways to work towards a more equitable, sustainable world in which all of us can thrive.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {100–112},
numpages = {13},
keywords = {ai ethics, data feminism, data justice, feminism, responsible ai},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

",https://doi.org/10.1145/3630106.3658543,10.1145/3630106.3658543,acm,2024
677,Tackling Language Modelling Bias in Support of Linguistic Diversity,"@inproceedings{10.1145/3630106.3658925,
author = {Bella, G\'{a}bor and Helm, Paula and Koch, Gertraud and Giunchiglia, Fausto},
title = {Tackling Language Modelling Bias in Support of Linguistic Diversity},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658925},
doi = {10.1145/3630106.3658925},
abstract = {Current AI-based language technologies—language models, machine translation systems, multilingual dictionaries and corpora—are known to focus on the world’s 2–3% most widely spoken languages. Research efforts of the past decade have attempted to expand this coverage to ‘under-resourced languages.’ The goal of our paper is to bring attention to a corollary phenomenon that we call language modelling bias: multilingual language processing systems often exhibit a hardwired, yet usually involuntary and hidden representational preference towards certain languages. We define language modelling bias as uneven per-language performance under similar test conditions. We show that bias stems not only from technology but also from ethically problematic research and development methodologies that disregard the needs of language communities. Moving towards diversity-aware alternatives, we present an initiative that aims at reducing language modelling bias within lexical resources through both technology design and methodology, based on an eye-level collaboration with local communities.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {562–572},
numpages = {11},
keywords = {language modeling bias, linguistic diversity, low-resource languages, natural language processing, value-sensitive design},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

",https://doi.org/10.1145/3630106.3658925,10.1145/3630106.3658925,acm,2024
678,Identifying and Improving Disability Bias in GPT-Based Resume Screening,"@inproceedings{10.1145/3630106.3658933,
author = {Glazko, Kate and Mohammed, Yusuf and Kosa, Ben and Potluri, Venkatesh and Mankoff, Jennifer},
title = {Identifying and Improving Disability Bias in GPT-Based Resume Screening},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658933},
doi = {10.1145/3630106.3658933},
abstract = {As Generative AI rises in adoption, its use has expanded to include domains such as hiring and recruiting. However, without examining the potential of bias, this may negatively impact marginalized populations, including people with disabilities. To address this important concern, we present a resume audit study, in which we ask ChatGPT (specifically, GPT-4) to rank a resume against the same resume enhanced with an additional leadership award, scholarship, panel presentation, and membership that are disability-related. We find that GPT-4 exhibits prejudice towards these enhanced CVs. Further, we show that this prejudice can be quantifiably reduced by training a custom GPTs on principles of DEI and disability justice. Our study also includes a unique qualitative analysis of the types of direct and indirect ableism GPT-4 uses to justify its biased decisions and suggest directions for additional bias mitigation work. Additionally, since these justifications are presumably drawn from training data containing real-world biased statements made by humans, our analysis suggests additional avenues for understanding and addressing human bias.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {687–700},
numpages = {14},
keywords = {Ableism, Bias, GPT, Resume Audit},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

",https://doi.org/10.1145/3630106.3658933,10.1145/3630106.3658933,acm,2024
679,"Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization Tool for Mitigating the Risk of Whistleblower Re-Identification","@inproceedings{10.1145/3630106.3658936,
author = {Staufer, Dimitri and Pallas, Frank and Berendt, Bettina},
title = {Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization Tool for Mitigating the Risk of Whistleblower Re-Identification},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658936},
doi = {10.1145/3630106.3658936},
abstract = {Whistleblowing is essential for ensuring transparency and accountability in both public and private sectors. However, (potential) whistleblowers often fear or face retaliation, even when reporting anonymously. The specific content of their disclosures and their distinct writing style may re-identify them as the source. Legal measures, such as the EU Whistleblower Directive, are limited in their scope and effectiveness. Therefore, computational methods to prevent re-identification are important complementary tools for encouraging whistleblowers to come forward. However, current text sanitization tools follow a one-size-fits-all approach and take an overly limited view of anonymity. They aim to mitigate identification risk by replacing typical high-risk words (such as person names and other labels of named entities) and combinations thereof with placeholders. Such an approach, however, is inadequate for the whistleblowing scenario since it neglects further re-identification potential in textual features, including the whistleblower’s writing style. Therefore, we propose, implement, and evaluate a novel classification and mitigation strategy for rewriting texts that involves the whistleblower in the assessment of the risk and utility. Our prototypical tool semi-automatically evaluates risk at the word/term level and applies risk-adapted anonymization techniques to produce a grammatically disjointed yet appropriately sanitized text. We then use a Large Language Model (LLM) that we fine-tuned for paraphrasing to render this text coherent and style-neutral. We evaluate our tool’s effectiveness using court cases from the European Court of Human Rights (ECHR) and excerpts from a real-world whistleblower testimony and measure the protection against authorship attribution attacks and utility loss statistically using the popular IMDb62 movie reviews dataset, which consists of 62 individuals. Our method can significantly reduce authorship attribution accuracy from 98.81% to 31.22%, while preserving up to 73.1% of the original content’s semantics, as measured by the established cosine similarity of sentence embeddings.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {733–745},
numpages = {13},
keywords = {Authorship Obfuscation, Fine-tuning Language Models, LLM-based Rephrasing, Text Sanitization, Whistleblower Anonymity},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

",https://doi.org/10.1145/3630106.3658936,10.1145/3630106.3658936,acm,2024
680,Beyond Behaviorist Representational Harms: A Plan for Measurement and Mitigation,"@inproceedings{10.1145/3630106.3658946,
author = {Chien, Jennifer and Danks, David},
title = {Beyond Behaviorist Representational Harms: A Plan for Measurement and Mitigation},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658946},
doi = {10.1145/3630106.3658946},
abstract = {Algorithmic harms are commonly categorized as either allocative or representational. This study specifically addresses the latter, examining current definitions of representational harms to discern what is included and what is not. This analysis motivates our expansion beyond behavioral definitions to encompass harms to cognitive and affective states. The paper outlines high-level requirements for measurement: identifying the necessary expertise to implement this approach and illustrating it through a case study. Our work highlights the unique vulnerabilities of large language models to perpetrating representational harms, particularly when these harms go unmeasured and unmitigated. The work concludes by presenting proposed mitigations and delineating when to employ them. The overarching aim of this research is to establish a framework for broadening the definition of representational harms and to translate insights from fairness research into practical measurement and mitigation praxis.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {933–946},
numpages = {14},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

",https://doi.org/10.1145/3630106.3658946,10.1145/3630106.3658946,acm,2024
681,When Human-AI Interactions Become Parasocial: Agency and Anthropomorphism in Affective Design,"@inproceedings{10.1145/3630106.3658956,
author = {Maeda, Takuya and Quan-Haase, Anabel},
title = {When Human-AI Interactions Become Parasocial: Agency and Anthropomorphism in Affective Design},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658956},
doi = {10.1145/3630106.3658956},
abstract = {With the continuous improvement of large language models (LLMs), chatbots can produce coherent and continuous word sequences that mirror natural human language. While the use of natural language and human-like conversation styles enables the use of chatbots within a range of everyday settings, these usability-enhancing features can also have unintended consequences, such as making fallible information seem trustworthy by emphasizing friendliness and closeness. This can have serious implications for information retrieval tasks performed with chatbots. In this paper, we provide an overview of the literature on parasociality, social affordance, and trust to bridge these concepts within human-AI interactions. We critically examine how chatbot “roleplaying” and user role projection co-produce a pseudo-interactive, technologically-mediated space with imbalanced dynamics between users and chatbots. Based on the review of the literature, we develop a conceptual framework of parasociality in chatbots that describes interactions between humans and anthropomorphized chatbots. We dissect how chatbots use personal pronouns, conversational conventions, affirmations, and similar strategies to position the chatbots as users’ companions or assistants, and how these tactics induce trust-forming behaviors in users. Finally, based on the conceptual framework, we outline a set of ethical concerns that emerge from parasociality, including illusions of reciprocal engagement, task misalignment, and leaks of sensitive information. This paper argues that these possible consequences arise from a positive feedback cycle wherein anthropomorphized chatbot features encourage users to fill in the context around predictive outcomes.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1068–1077},
numpages = {10},
keywords = {anthropomorphism, chatbots, design, ethics, human-AI interactions, parasociality, trust},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

",https://doi.org/10.1145/3630106.3658956,10.1145/3630106.3658956,acm,2024
682,Participation in the age of foundation models,"@inproceedings{10.1145/3630106.3658992,
author = {Suresh, Harini and Tseng, Emily and Young, Meg and Gray, Mary and Pierson, Emma and Levy, Karen},
title = {Participation in the age of foundation models},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658992},
doi = {10.1145/3630106.3658992},
abstract = {Growing interest and investment in the capabilities of foundation models has positioned such systems to impact a wide array of services, from banking to healthcare. Alongside these opportunities is the risk that these systems reify existing power imbalances and cause disproportionate harm to historically marginalized groups. The larger scale and domain-agnostic manner in which these models operate further heightens the stakes: any errors or harms are liable to reoccur across use cases. In AI &amp; ML more broadly, participatory approaches hold promise to lend agency and decision-making power to marginalized stakeholders, leading to systems that better benefit justice through equitable and distributed governance. But existing approaches in participatory AI/ML are typically grounded in a specific application and set of relevant stakeholders, and it is not straightforward how to apply these lessons to the context of foundation models. Our paper aims to fill this gap. First, we examine existing attempts at incorporating participation into foundation models. We highlight the tension between participation and scale, demonstrating that it is intractable for impacted communities to meaningfully shape a foundation model that is intended to be universally applicable. In response, we develop a blueprint for participatory foundation models that identifies more local, application-oriented opportunities for meaningful participation. In addition to the “foundation” layer, our framework proposes the “subfloor” layer, in which stakeholders develop shared technical infrastructure, norms and governance for a grounded domain such as clinical care, journalism, or finance, and the “surface” (or application) layer, in which affected communities shape the use of a foundation model for a specific downstream task. The intermediate “subfloor” layer scopes the range of potential harms to consider, and affords communities more concrete avenues for deliberation and intervention. At the same time, it avoids duplicative effort by scaling input across relevant use cases. Through three case studies in clinical care, financial services, and journalism, we illustrate how this multi-layer model can create more meaningful opportunities for participation than solely intervening at the foundation layer.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1609–1621},
numpages = {13},
keywords = {Foundation models, communities, governance, public participation, stakeholders},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

",https://doi.org/10.1145/3630106.3658992,10.1145/3630106.3658992,acm,2024
683,Unlawful Proxy Discrimination: A Framework for Challenging Inherently Discriminatory Algorithms,"@inproceedings{10.1145/3630106.3659010,
author = {Weerts, Hilde and Kelly-Lyth, Aislinn and Binns, Reuben and Adams-Prassl, Jeremias},
title = {Unlawful Proxy Discrimination: A Framework for Challenging Inherently Discriminatory Algorithms},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659010},
doi = {10.1145/3630106.3659010},
abstract = {Emerging scholarship suggests that the EU legal concept of direct discrimination - where a person is given different treatment on grounds of a protected characteristic - may apply to various algorithmic decision-making contexts. This has important implications: unlike indirect discrimination, there is generally no ‘objective justification’ stage in the direct discrimination framework, which means that the deployment of directly discriminatory algorithms will usually be unlawful per se. In this paper, we focus on the most likely candidate for direct discrimination in the algorithmic context, termed inherent direct discrimination, where a proxy is inextricably linked to a protected characteristic. We draw on computer science literature to suggest that, in the algorithmic context, ‘treatment on the grounds of’ needs to be understood in terms of two steps: proxy capacity and proxy use. Only where both elements can be made out can direct discrimination be said to be ‘on grounds of’ a protected characteristic. We analyse the legal conditions of our proposed proxy capacity and proxy use tests. Based on this analysis, we discuss technical approaches and metrics that could be developed or applied to identify inherent direct discrimination in algorithmic decision-making.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1850–1860},
numpages = {11},
keywords = {EU non-discrimination law, algorithmic fairness, direct discrimination, disparate treatment, machine learning, proxy discrimination},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

",https://doi.org/10.1145/3630106.3659010,10.1145/3630106.3659010,acm,2024
684,ChatGeppetto - an AI-powered Storyteller,"@inproceedings{10.1145/3631085.3631302,
author = {De Lima, Edirlei Soares and Feij\'{o}, Bruno and Cassanova, Marco A. and Furtado, Antonio L.},
title = {ChatGeppetto - an AI-powered Storyteller},
year = {2024},
isbn = {9798400716270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631085.3631302},
doi = {10.1145/3631085.3631302},
abstract = {In this paper we introduce a novel highly interactive process to generate natural language narratives on the basis of our ongoing work on semiotic relations. To the two basic components of interactive systems, namely, a software tool and a user interface, we add a third component – AI agents, understood as an upgraded rendition of software agents. Our semiotic relations approach considers four ways of composing new narratives from existing narratives. Along what semioticians call the horizontal syntagmatic axis, one can form the new narrative by combining two or more previous narratives. Along the vertical paradigmatic axis, the new narrative may emerge as a similar version, which imitates the previous one, possibly in a different context. Along the depth meronymic axis, the hierarchic narrative levels, such as plot, event, and scene, are explored, allowing either expansion or summarization. Lastly, the antithetic consideration, rather than adding a dimension, aims at some form of reversal, through the adoption of opposite values. A fully operational prototype is described. Its name, ChatGeppetto, conflates the skilled Geppetto, who fashioned Pinocchio, an early case of artisanship-produced human level intelligence, with ChatGPT, which operates as the main AI agent component. To run the experiments, we concentrated on book narratives.},
booktitle = {Proceedings of the 22nd Brazilian Symposium on Games and Digital Entertainment},
pages = {28–37},
numpages = {10},
keywords = {Artificial Intelligence, Book Narratives, ChatGPT, Chatbots, Interactive Story Composition, Semiotic Relations, Storyboards},
location = {Rio Grande (RS), Brazil},
series = {SBGames '23}
}

",https://doi.org/10.1145/3631085.3631302,10.1145/3631085.3631302,acm,2024
685,ARIEL: Brain-Computer Interfaces meet Large Language Models for Emotional Support Conversation,"@inproceedings{10.1145/3631700.3665193,
author = {Sorino, Paolo and Biancofiore, Giovanni Maria and Lof\`{u}, Domenico and Colafiglio, Tommaso and Lombardi, Angela and Narducci, Fedelucio and Di Noia, Tommaso},
title = {ARIEL: Brain-Computer Interfaces meet Large Language Models for Emotional Support Conversation},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665193},
doi = {10.1145/3631700.3665193},
abstract = {In an era characterized by unprecedented virtual connectivity, paradoxically, individuals often find themselves disconnected from genuine human interactions. The advent of remote working arrangements, compounded by the influence of digital communication platforms, has fostered a sense of isolation among people. Consequently, the prevailing socio-technological landscape has underscored the critical need for innovative solutions to address the emotional void. Conversational systems help people improve their everyday tasks with informative dialogues, and recent applications employ them to target emotional support conversation tasks. Nevertheless, their understanding of human feelings is limited, as they depend solely on information discernible from the text or the users’ emotional declarations. Recently, Brain-Computer Interfaces (BCIs), devices that analyze electroencephalographic (EEG) signals, have increasingly become popular given their minimally invasive nature and low cost, besides enabling the detection of users’ emotional states reliably. Hence, we propose ARIEL, an emotionAl suppoRt bcI dEvices and Llm-based conversational agent that aims at supporting users’ emotional states through conversations and monitoring them via BCI. In this way, it is possible to comprehend the users’ feelings reliably, thus making the conversational agent aware of users’ emotional evolution during conversations. Our framework makes the LlaMA 2 chat model communicate with an emotion recognition BCI-based system to achieve the emotional support conversation goal. Also, we present a controlled running example that shows the potential of our model and its effective functioning, made possible by a wisely designed hard-prompt strategy. In the future, we will conduct an in-vivo experiment to evaluate the system and its components.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {601–609},
numpages = {9},
keywords = {Brain-Computer Interface, Conversational Agent, Emotion Recognition, Emotional Support Conversation, Large Language Model, Machine Learning},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

",https://doi.org/10.1145/3631700.3665193,10.1145/3631700.3665193,acm,2024
686,Towards Zero-shot Knowledge Graph building: Automated Schema Inference,"@inproceedings{10.1145/3631700.3665234,
author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Tiddia, Sandro Gabriele},
title = {Towards Zero-shot Knowledge Graph building: Automated Schema Inference},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665234},
doi = {10.1145/3631700.3665234},
abstract = {In the current Digital Transformation scenario, Knowledge Graphs are essential for comprehending, representing, and exploiting complex information in a structured form. The main paradigm in automatically generating proper Knowledge Graphs relies on predefined schemas or ontologies. Such schemas are typically manually constructed, requiring an intensive human effort, and are often sensitive to information loss due to negligence, incomplete analysis, or human subjectivity or inclination. Limiting human bias and the resulting information loss in creating proper Knowledge Graphs is paramount, particularly for user modeling in various sectors, such as education or healthcare. To this end, we propose a novel approach to automatically generating a proper entity schema. The devised methodology combines the language understanding capabilities of LLM with classical machine learning methods such as clustering to properly build an entity schema from a set of documents. This solution eliminates the need for human intervention and fosters a more efficient and comprehensive knowledge representation. The assessment of our proposal concerns adopting a state-of-the-art entity extraction model (UniNER) to estimate the relevance of the extracted entities based on the generated schema. Results confirm the potential of our approach, as we observed a negligible difference between the topic similarity score obtained with the ground truth and with the automatically generated schema (less than 1% on average on three different datasets). Such an outcome confirms that the proposed approach may be valuable in automatically creating an entity schema from a set of documents.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {467–473},
numpages = {7},
keywords = {Large Language Models, Named Entity Recognition, Ontology Learning},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

",https://doi.org/10.1145/3631700.3665234,10.1145/3631700.3665234,acm,2024
687,Towards Knowledge Graph Refinement: Misdirected Triple Identification,"@inproceedings{10.1145/3631700.3665235,
author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Pompianu, Livio and Tiddia, Sandro Gabriele},
title = {Towards Knowledge Graph Refinement: Misdirected Triple Identification},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665235},
doi = {10.1145/3631700.3665235},
abstract = {In the current digital transformation scenario, Knowledge Graphs (KGs) represent an across-the-board instrument for representing knowledge in a structured form. Such tools allow to effectively enhance the performance of Artificial Intelligence models in manifold contexts, such as reasoning or information retrieval. Nevertheless, the effectiveness of KGs is often affected by the incorrect directionality of some of their edges, due in most cases to human error or the inefficiency of automatic and semi-automatic graph creation methods. This paper proposes a classification-based approach to identify misdirected triples within a KG, aiming to support and assist humans in creating graph refinement. Triples are the main component of KGs, and they model the connection between nodes with a &lt;subject, predicate, object&gt; form. Our proposal allows us to refine a KG by devising a classification-based approach for recognizing whether the subjects and objects are not compliant with the logic directionality of the corresponding predicate, meaning that they should be switched (e.g., the triple &lt;U.S.A., is capital, Washington&gt; should be inverted as &lt;Washington, is capital, U.S.A.&gt;). We compare traditional machine learning techniques with cutting-edge advanced methods, including pre-trained language models and large language models. Extensive experiments have been performed across several datasets, confirming the effectiveness of our proposal.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {460–466},
numpages = {7},
keywords = {Artificial Intelligence, Digital Transformation, Large Language Models},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

",https://doi.org/10.1145/3631700.3665235,10.1145/3631700.3665235,acm,2024
688,How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment,"@inproceedings{10.1145/3631802.3631806,
author = {Kazemitabaar, Majeed and Hou, Xinying and Henley, Austin and Ericson, Barbara Jane and Weintrop, David and Grossman, Tovi},
title = {How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631806},
doi = {10.1145/3631802.3631806},
abstract = {As Large Language Models (LLMs) gain in popularity, it is important to understand how novice programmers use them and the effect they have on learning to code. We present the results of a thematic analysis on a data set from 33 learners, aged 10-17, as they independently learned Python by working on 45 code-authoring tasks with access to an AI Code Generator based on OpenAI Codex. We explore several important questions related to how learners used LLM-based AI code generators, and provide an analysis of the properties of the written prompts and the resulting AI generated code. Specifically, we explore (A) the context in which learners use Codex, (B) what learners are asking from Codex in terms of syntax and logic, (C) properties of prompts written by learners in terms of relation to task description, language, clarity, and prompt crafting patterns, (D) properties of the AI-generated code in terms of correctness, complexity, and accuracy, and (E) how learners utilize AI-generated code in terms of placement, verification, and manual modifications. Furthermore, our analysis reveals four distinct coding approaches when writing code with an AI code generator: AI Single Prompt, where learners prompted Codex once to generate the entire solution to a task; AI Step-by-Step, where learners divided the problem into parts and used Codex to generate each part; Hybrid, where learners wrote some of the code themselves and used Codex to generate others; and Manual coding, where learners wrote the code themselves. Our findings reveal consistently positive trends between learners’ utilization of the Hybrid coding approach and their post-test evaluation scores, while showing consistent negative trends between the AI Single Prompt and the post-test evaluation scores. Furthermore, we offer insights into novice learners’ use of AI code generators in a self-paced learning environment, highlighting signs of over-reliance, self-regulation, and opportunities for enhancing AI-assisted learning tools.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {3},
numpages = {12},
keywords = {ChatGPT, Copilot, Introductory Programming, Large Language Models, OpenAI Codex, Self-paced Learning, Self-regulation},
location = {Koli, Finland},
series = {Koli Calling '23}
}

",https://doi.org/10.1145/3631802.3631806,10.1145/3631802.3631806,acm,2024
689,Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper),"@article{2-s2.0-85185532603,
  title={Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper)},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185532603&origin=inward,10.1145/3631802.3631816,scopus,2023
690,CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes,"@inproceedings{10.1145/3631802.3631830,
author = {Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul},
title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631830},
doi = {10.1145/3631802.3631830},
abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {8},
numpages = {11},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Koli, Finland},
series = {Koli Calling '23}
}

",https://doi.org/10.1145/3631802.3631830,10.1145/3631802.3631830,"acm, scopus",2024
691,"Insights from Social Shaping Theory: The Appropriation of Large Language
  Models in an Undergraduate Programming Course","<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10.1145/3632620.3671098</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10.1145/3632620.3671098"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",http://arxiv.org/pdf/2406.06451v1.pdf,10.1145/3632620.3671098,arxiv,2024
692,Harnessing the Power of Prompt-based Techniques for Generating School-Level Questions using Large Language Models,"@inproceedings{10.1145/3632754.3632755,
author = {Maity, Subhankar and Deroy, Aniket and Sarkar, Sudeshna},
title = {Harnessing the Power of Prompt-based Techniques for Generating School-Level Questions using Large Language Models},
year = {2024},
isbn = {9798400716324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632754.3632755},
doi = {10.1145/3632754.3632755},
abstract = {Designing high-quality educational questions is a challenging and time-consuming task. In this work, we propose a novel approach that utilizes prompt-based techniques to generate descriptive and reasoning-based questions. However, current question-answering (QA) datasets are inadequate for conducting our experiments on prompt-based question generation (QG) in an educational setting. Therefore, we curate a new QG dataset called EduProbe for school-level subjects, by leveraging the rich content of NCERT textbooks. We carefully annotate this dataset as quadruples of 1) Context: a segment upon which the question is formed; 2) Long Prompt: a long textual cue for the question (i.e., a longer sequence of words or phrases, covering the main theme of the context); 3) Short Prompt: a short textual cue for the question (i.e., a condensed representation of the key information or focus of the context); 4) Question: a deep question that aligns with the context and is coherent with the prompts. We investigate several prompt-based QG methods by fine-tuning pre-trained transformer-based large language models (LLMs), namely PEGASUS, T5, MBART, and BART. Moreover, we explore the performance of two general-purpose pre-trained LLMs such as Text-Davinci-003 and GPT-3.5-Turbo without any further training. By performing automatic evaluation, we show that T5 (with long prompt) outperforms all other models, but still falls short of the human baseline. Under human evaluation criteria, Text-Davinci-003 usually shows better results than other models under various prompt settings. Even in the case of human evaluation criteria, QG models mostly fall short of the human baseline. Our code and dataset are available at: https://github.com/my625/PromptQG},
booktitle = {Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {30–39},
numpages = {10},
keywords = {Education, Large Language Models (LLMs), Prompt, Question Generation},
location = {Panjim, India},
series = {FIRE '23}
}

",https://doi.org/10.1145/3632754.3632755,10.1145/3632754.3632755,acm,2024
693,Speculative Design with Generative AI: Applying Stable Diffusion and ChatGPT to imagining climate change futures,"@inproceedings{10.1145/3632776.3632827,
author = {LC, RAY and Tang, Yuying},
title = {Speculative Design with Generative AI: Applying Stable Diffusion and ChatGPT to imagining climate change futures},
year = {2024},
isbn = {9798400708725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632776.3632827},
doi = {10.1145/3632776.3632827},
abstract = {Policy mandates in addressing climate change are hindered by a lack of intrinsic motivation amongst participants to take collective action. Instead of overt persuasion, this study applied generative AI tools to speculative imagining of future climate scenarios and their adaptation strategies, using a workshop to encourage participants to align themselves with climate action. Participants used text-to-image tools to generate visions of the future in speculative scenarios, then prompted ChatGPT for potential solutions in these scenarios. They then asked text-to-image again to visualize the ChatGPT suggestions. Participants encountered difficulties editing or removing visual elements, dealt with the lack of transparency in the generation process by specifying the physical layout as opposed to the semantics, and collaboratively developed linguistic strategies for visual depiction of novel artifacts. This work shows how generative tools can be used to prototype future scenarios and envision designs that serve social purposes.},
booktitle = {Proceedings of the 11th International Conference on Digital and Interactive Arts},
articleno = {36},
numpages = {8},
keywords = {ChatGPT, Stable diffusion, climate change, co-design workshop, prompt design, speculative design},
location = {Faro, Portugal},
series = {ARTECH '23}
}

",https://doi.org/10.1145/3632776.3632827,10.1145/3632776.3632827,acm,2024
694,Programming-by-Demonstration for Long-Horizon Robot Tasks,"@article{10.1145/3632860,
author = {Patton, Noah and Rahmani, Kia and Missula, Meghana and Biswas, Joydeep and Dillig, I\c{s}\i{}l},
title = {Programming-by-Demonstration for Long-Horizon Robot Tasks},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632860},
doi = {10.1145/3632860},
abstract = {The goal of programmatic Learning from Demonstration (LfD) is to learn a policy in a programming language that can be used to control a robot’s behavior from a set of user demonstrations. This paper presents a new programmatic LfD algorithm that targets long-horizon robot tasks which require synthesizing programs with complex control flow structures, including nested loops with multiple conditionals. Our proposed method first learns a program sketch that captures the target program’s control flow and then completes this sketch using an LLM-guided search procedure that incorporates a novel technique for proving unrealizability of programming-by-demonstration problems. We have implemented our approach in a new tool called PROLEX and present the results of a comprehensive experimental evaluation on 120 benchmarks involving complex tasks and environments. We show that, given a 120 second time limit, PROLEX can find a program consistent with the demonstrations in 80% of the cases. Furthermore, for 81% of the tasks for which a solution is returned, PROLEX is able to find the ground truth program with just one demonstration. In comparison, CVC5, a syntax-guided synthesis tool, is only able to solve 25% of the cases even when given the ground truth program sketch, and an LLM-based approach, GPT-Synth, is unable to solve any of the tasks due to the environment complexity.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {18},
numpages = {34},
keywords = {Abstract Interpretation, Learning from Demonstrations, Program Synthesis}
}

",https://doi.org/10.1145/3632860,10.1145/3632860,acm,2024
695,Incorporating Generative AI into Software Development Education,"@inproceedings{10.1145/3633053.3633057,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca},
title = {Incorporating Generative AI into Software Development Education},
year = {2024},
isbn = {9798400709326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633053.3633057},
doi = {10.1145/3633053.3633057},
abstract = {This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.},
booktitle = {Proceedings of the 8th Conference on Computing Education Practice},
pages = {37–40},
numpages = {4},
keywords = {apprenticeship, assessment, education, generative AI, software engineering},
location = {Durham, United Kingdom},
series = {CEP '24}
}

",https://doi.org/10.1145/3633053.3633057,10.1145/3633053.3633057,acm,2024
696,Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment,"@article{10.1145/3633287,
author = {Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel},
title = {Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3633287},
doi = {10.1145/3633287},
abstract = {Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.},
journal = {ACM Trans. Comput. Educ.},
month = {jan},
articleno = {5},
numpages = {32},
keywords = {ChatGPT, generative AI, cheating, quality assurance, university assessment’}
}

",https://doi.org/10.1145/3633287,10.1145/3633287,acm,2024
697,An Analysis of Large Language Models and LangChain in Mathematics Education,"@inproceedings{10.1145/3633598.3633614,
author = {Soygazi, Fatih and Oguz, Damla},
title = {An Analysis of Large Language Models and LangChain in Mathematics Education},
year = {2024},
isbn = {9798400708985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633598.3633614},
doi = {10.1145/3633598.3633614},
abstract = {The development of large language models (LLMs) has led to the consideration of new approaches, particularly in education. Word problems, especially in subjects like mathematics, and the need to solve these problems by collectively addressing specific stages of reasoning, have raised the question of whether LLMs can be successful in this area as well. In our study, we conducted analyses by asking mathematics questions especially related to word problems using ChatGPT, which is based on the latest language models like Generative Pretrained Transformer (GPT). Additionally, we compared the correct and incorrect answers by posing the same questions to LLMMathChain, a mathematics-specific LLM based on the latest language models like LangChain. It was observed that the answers obtained were more successful with ChatGPT (GPT 3.5), particularly in the field of mathematics. However, both language models were found to be below expectations, particularly in word problems, and suggestions for improvement were provided.},
booktitle = {Proceedings of the 2023 7th International Conference on Advances in Artificial Intelligence},
pages = {92–97},
numpages = {6},
keywords = {ChatGPT, LangChain, Large Language Models (LLMs), Mathematics Education},
location = {Istanbul, Turkiye},
series = {ICAAI '23}
}

",https://doi.org/10.1145/3633598.3633614,10.1145/3633598.3633614,acm,2024
698,XAI for Medicine by ChatGPT Code interpreter,"@inproceedings{10.1145/3633624.3633629,
author = {Kitamura, Kenta and Irvan, Mhd and Shigetomi Yamaguchi, Rie},
title = {XAI for Medicine by ChatGPT Code interpreter},
year = {2024},
isbn = {9798400708923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633624.3633629},
doi = {10.1145/3633624.3633629},
abstract = {In recent years, with the prevalence of Artificial Intelligence (AI), the interpretability of AI outputs has become a significant issue. Especially the interpretability of large language models (LLMs), including ChatGPT, has emerged as a major challenge. Consequently, there is a growing interest in the research of Explainable Artificial Intelligence (XAI), which seeks to elucidate the decision-making processes of AI in a manner that humans can comprehend. In the medical field, where trust and transparency are important, the use of AI becomes challenging when its decisions are unclear. Therefore, XAI techniques become critically important in the medical field. In this study, we propose the prompt named Code Base Prompt (CBP) to make the ChatGPT's decision-making process on medical texts explainable by using the Python code execution function of Chat GPT Code interpreter. In CBP, the medical decision-making algorithm is rewritten as Python code. Moreover, we propose an explainability evaluation system named Medical Algorithm Presentation Criteria (MAPC) for medical algorithm application tasks to medical text. MAPC is evaluated by five factors to align the human understanding process. To compare CBP with a Text Base Prompt (TBP), we conducted an experiment applying the heart failure classification algorithm to heart failure case report texts in three medical articles. With CBP, the results showed that the ChatGPT Code interpreter executed the Python code in all three cases and met all the five MAPC factors. In contrast, with TBP, no Python code execution was observed in any of the three cases, validating only one factor of MAPC. This study presents a new method for implementing XAI in the use of ChatGPT for medical tasks.},
booktitle = {Proceedings of the 2023 5th International Conference on Big-Data Service and Intelligent Computation},
pages = {28–34},
numpages = {7},
keywords = {ChatGPT, ChatGPT Code interpreter, XAI, health care, medicine},
location = {Singapore, Singapore},
series = {BDSIC '23}
}

",https://doi.org/10.1145/3633624.3633629,10.1145/3633624.3633629,acm,2024
699,BinAdapter: Leveraging Continual Learning for Inferring Function Symbol Names in a Binary,"@inproceedings{10.1145/3634737.3645006,
author = {Murodova, Nozima and Koo, Hyungjoon},
title = {BinAdapter: Leveraging Continual Learning for Inferring Function Symbol Names in a Binary},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3645006},
doi = {10.1145/3634737.3645006},
abstract = {Binary reverse engineering is crucial to gaining insights into the inner workings of a stripped binary. Yet, it is challenging to read the original semantics from a binary code snippet because of the unavailability of high-level information in the source, such as function names, variable names, and types. Recent advancements in deep learning show the possibility of recovering such vanished information with a well-trained model from a pre-defined dataset. Albeit a static model's notable performance, it can hardly cope with an ever-increasing data stream (e.g., compiled binaries) by nature. The two viable approaches for ceaseless learning are retraining the whole dataset from scratch and fine-tuning a pre-trained model; however, retraining suffers from large computational overheads and fine-tuning from performance degradation (i.e., catastrophic forgetting). Lately, continual learning (CL) tackles the problem of handling incremental data in security domains (e.g., network intrusion detection, malware detection) using reasonable resources while maintaining performance in practice.In this paper, we focus on how CL assists in the improvement of a generative model that predicts a function symbol name from a series of machine instructions. To this end, we introduce BinAdapter, a system that can infer function names from an incremental dataset without performance degradation from an original dataset by leveraging CL techniques. Our major finding shows that incremental tokens in the source (i.e., machine instructions) or the target (i.e., function names) largely affect the overall performance of a CL-enabled model. Accordingly, BinAdapter adopts three built-in approaches: [EQUATION] inserting adapters in case of no incremental tokens in both the source and target, [EQUATION] harnessing multilingual neural machine translation (M-NMT) and fine-tuning the source embeddings with [EQUATION] in case of incremental tokens in the source, and [EQUATION] fine-tuning target embeddings with [EQUATION] in case of incremental tokens in both. To demonstrate the effectiveness of BinAdapter, we evaluate the above three scenarios using incremental datasets with or without a set of new tokens (e.g., unseen machine instructions or function names), spanning across different architectures and optimization levels. Our empirical results show that BinAdapter outperforms the state-of-the-art CL techniques for an F1 of up to 24.3% or a Rouge-l of 21.5% in performance.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {1200–1213},
numpages = {14},
keywords = {binary analysis, software security, reverse engineering, continual learning},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

",https://doi.org/10.1145/3634737.3645006,10.1145/3634737.3645006,acm,2024
700,HQsFL: A Novel Training Strategy for Constructing High-performance and Quantum-safe Federated Learning,"@inproceedings{10.1145/3634737.3656285,
author = {Yu, Bo and Shen, Huajie and Xu, Qian and He, Wei and Mao, Wankui and Zhang, Qing and Zhang, Fan},
title = {HQsFL: A Novel Training Strategy for Constructing High-performance and Quantum-safe Federated Learning},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3656285},
doi = {10.1145/3634737.3656285},
abstract = {Federated Learning (FL) has attracted increasing attention from both academia and industry due to its merit of securely constructing AI models across multiple entities while preserving the privacy of local training data. However, recent research shows two persisting problems in FL that have yet to be solved: (1) limited practical adaptation of federated learning because of time-consuming conventional privacy-preserving methods, and (2) the absence of quantum-computing resistance in these methods. To address these problems, we propose a novel vertical federated learning strategy, HQsFL, which relies on Fully Homomorphic Encryption (FHE) and Matrix Vector Product basing on Coefficient Encoding. The proposed method can be widely applied to FL algorithms such as logistic regression and XGBoost, etc. We fully implement our approach and evaluate its utility and efficiency through extensive experiments performed on four synthetic datasets. The experimental results demonstrate that our proposed methods for vertical LR and XGBoost achieve comparable levels of AUC to conventional methods, while significantly improving training efficiency and achieving security property of quantum-computing resistance.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {512–521},
numpages = {10},
keywords = {feaderated learning, fully homomorphic encryption, matrix vector mutiplication, quantum-safe cryptography},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

",https://doi.org/10.1145/3634737.3656285,10.1145/3634737.3656285,acm,2024
701,An Investigation into Misuse of Java Security APIs by Large Language Models,"@inproceedings{10.1145/3634737.3661134,
author = {Mousavi, Zahra and Islam, Chadni and Moore, Kristen and Abuadbba, Alsharif and Babar, M. Ali},
title = {An Investigation into Misuse of Java Security APIs by Large Language Models},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3661134},
doi = {10.1145/3634737.3661134},
abstract = {The increasing trend of using Large Language Models (LLMs) for code generation raises the question of their capability to generate trustworthy code. While many researchers are exploring the utility of code generation for uncovering software vulnerabilities, one crucial but often overlooked aspect is the security Application Programming Interfaces (APIs). APIs play an integral role in upholding software security, yet effectively integrating security APIs presents substantial challenges. This leads to inadvertent misuse by developers, thereby exposing software to vulnerabilities. To overcome these challenges, developers may seek assistance from LLMs. In this paper, we systematically assess ChatGPT's trustworthiness in code generation for security API use cases in Java. To conduct a thorough evaluation, we compile an extensive collection of 48 programming tasks for 5 widely used security APIs. We employ both automated and manual approaches to effectively detect security API misuse in the code generated by ChatGPT for these tasks. Our findings are concerning: around 70% of the code instances across 30 attempts per task contain security API misuse, with 20 distinct misuse types identified. Moreover, for roughly half of the tasks, this rate reaches 100%, indicating that there is a long way to go before developers can rely on ChatGPT to securely implement security API code.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {1299–1315},
numpages = {17},
keywords = {security API, misuse, ChatGPT, LLM-generated code, software security, secure software development},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

",https://doi.org/10.1145/3634737.3661134,10.1145/3634737.3661134,acm,2024
702,SoK: Where to Fuzz? Assessing Target Selection Methods in Directed Fuzzing,"@inproceedings{10.1145/3634737.3661141,
author = {Weissberg, Felix and M\""{o}ller, Jonas and Ganz, Tom and Imgrund, Erik and Pirch, Lukas and Seidel, Lukas and Schloegel, Moritz and Eisenhofer, Thorsten and Rieck, Konrad},
title = {SoK: Where to Fuzz? Assessing Target Selection Methods in Directed Fuzzing},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3661141},
doi = {10.1145/3634737.3661141},
abstract = {A common paradigm for improving fuzzing performance is to focus on selected regions of a program rather than its entirety. While previous work has largely explored how these locations can be reached, their selection, that is, the where, has received little attention so far. In this paper, we fill this gap and present the first comprehensive analysis of target selection methods for fuzzing. To this end, we examine papers from leading security and software engineering conferences, identifying prevalent methods for choosing targets. By modeling these methods as general scoring functions, we are able to compare and measure their efficacy on a corpus of more than 1,600 crashes from the OSS-Fuzz project. Our analysis provides new insights for target selection in practice: First, we find that simple software metrics significantly outperform other methods, including common heuristics used in directed fuzzing, such as recently modified code or locations with sanitizer instrumentation. Next to this, we identify language models as a promising choice for target selection. In summary, our work offers a new perspective on directed fuzzing, emphasizing the role of target selection as an orthogonal dimension to improve performance.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {1539–1553},
numpages = {15},
keywords = {directed fuzzing, software security, target selection},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

",https://doi.org/10.1145/3634737.3661141,10.1145/3634737.3661141,acm,2024
703,Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction,"@inproceedings{10.1145/3634814.3634816,
author = {Cowan, Brendan and Watanobe, Yutaka and Shirafuji, Atsushi},
title = {Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction},
year = {2024},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634814.3634816},
doi = {10.1145/3634814.3634816},
abstract = {Due to their robustness, large language models (LLMs) are being utilized in many fields of study, including programming and education. Notably, they can be used by programmers by interfacing with their IDEs to assist with development, and in education by giving students meaningful and immediate feedback. In this paper, we propose and explore the groundwork of a framework designed to combine these two applications of LLMs. The framework acts as a facilitator between the LLM and the student by reading the student’s prompts before filtering and modifying them and sending them to the LLM. The intent is that this will improve the responses from the LLM, thereby improving the student’s learning experience. We discuss the framework in detail and analyze the value of individual responses returned from the LLM as a result of our framework. We conclude that the framework causes the LLM to give helpful responses in comparison to how it would respond without the framework.},
booktitle = {Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
pages = {10–16},
numpages = {7},
keywords = {ChatGPT, educational technology, large language models, programming education, prompt engineering},
location = {Aizu-Wakamatsu City, Japan},
series = {ASSE '23}
}

",https://doi.org/10.1145/3634814.3634816,10.1145/3634814.3634816,"acm, scopus",2024
704,Large Language Models versus Natural Language Understanding and Generation,"@inproceedings{10.1145/3635059.3635104,
author = {Karanikolas, Nikitas and Manga, Eirini and Samaridi, Nikoletta and Tousidou, Eleni and Vassilakopoulos, Michael},
title = {Large Language Models versus Natural Language Understanding and Generation},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635104},
doi = {10.1145/3635059.3635104},
abstract = {In recent years, the process humans adopt to learn a foreign language has moved from the strict ""Grammar –Translation"" method, which is based mainly on grammar and syntax rules, to more innovative processes, resulting to the more modern ""Communicative approach"". As its name states, this approach focuses on the coherent communication with native speakers and the cultivation of oral skills, without taking into consideration, at least at the first stages, the rules that govern the language. The same trend seems to have been applied to the way machinery can be ""educated"" to comprehend and reproduce the unfamiliar, human language. The ""rule based"" Natural Language Generation (NLG) and Natural Language Understanding (NLU) algorithms, on one hand, and the ""text based"" Large Language Models (LLMs), on the other, are two, analogous to the two human foreign language learning processes, subareas of Natural Language Processing (NLP). This paper presents these two alternative approaches, LLMs (a technology having surfaced as an influential catalyst of NLP, during last years) on the one hand and NLG/NLU on the other, highlighting their applications, their technologies, their capabilities, their differences, their strengths and weaknesses and the challenges they present, contributing to a deeper comprehension of the evolving landscape of Artificial Intelligence and human-computer communication.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {278–290},
numpages = {13},
keywords = {Large Language Models, Natural Language Generation, Natural Language Processing, Natural Language Understanding},
location = {Lamia, Greece},
series = {PCI '23}
}

",https://doi.org/10.1145/3635059.3635104,10.1145/3635059.3635104,acm,2024
705,Evolving Roles and Workflows of Creative Practitioners in the Age of Generative AI,"@inproceedings{10.1145/3635636.3656190,
author = {Palani, Srishti and Ramos, Gonzalo},
title = {Evolving Roles and Workflows of Creative Practitioners in the Age of Generative AI},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3656190},
doi = {10.1145/3635636.3656190},
abstract = {Creative practitioners (like designers, software developers, and architects) have started to employ Generative AI models (GenAI) to produce text, images, and assets comparable to those made by people. While HCI research explores specific GenAI models and creativity support tools, little is known about practitioners’ evolving roles and workflows with GenAI models across a project’s stages. This knowledge is key to guide the development of the new generation of Creativity Support Tools. We contribute to this knowledge by employing a triangulated method to capture interviews, videos, and survey responses of creative practitioners reflecting on projects they completed with GenAI. Our observations let us derive a set of factors that capture practitioners’ perceived roles, challenges, benefits, and interaction patterns when creating with GenAI. From these factors, we offer insights and propose design opportunities and priorities that serve to encourage reflection from the wider community of Creativity Support Tools and GenAI stakeholders such as systems creators, researchers, and educators on how to develop systems that meet the needs of creatives in human-centered ways.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {170–184},
numpages = {15},
keywords = {Creative Practitioners, Creativity, Generative AI},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

",https://doi.org/10.1145/3635636.3656190,10.1145/3635636.3656190,acm,2024
706,Creativity Support in the Age of Large Language Models: An Empirical Study Involving Professional Writers,"@inproceedings{10.1145/3635636.3656201,
author = {Chakrabarty, Tuhin and Padmakumar, Vishakh and Brahman, Faeze and Muresan, Smaranda},
title = {Creativity Support in the Age of Large Language Models: An Empirical Study Involving Professional Writers},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3656201},
doi = {10.1145/3635636.3656201},
abstract = {The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions has led to increased interest in their use across various support tools. We investigate the effectiveness of contemporary LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing &nbsp;[17]. This allows writers to obtain model help in each of the three non-linear cognitive activities in the writing process: planning, translating and reviewing. Participants write short fiction/non-fiction with model help and are subsequently asked to submit a post-completion survey to provide qualitative feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while seeking help across all three types of cognitive activities, writers find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research directions in creative writing assistance using LLMs.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {132–155},
numpages = {24},
keywords = {Co-Creativity, Computational Creativity, Creativity, Evaluation, Human-AI collaboration, Large Language Models, Natural Language Generation, StoryTelling},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

",https://doi.org/10.1145/3635636.3656201,10.1145/3635636.3656201,acm,2024
707,Improving Selection of Analogical Inspirations through Chunking and Recombination,"@inproceedings{10.1145/3635636.3656207,
author = {Srinivasan, Arvind and Chan, Joel},
title = {Improving Selection of Analogical Inspirations through Chunking and Recombination},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3656207},
doi = {10.1145/3635636.3656207},
abstract = {Analogies can be a powerful source of new ideas; however, creators often fail to recognize and harness potentially beneficial analogical leads, especially from other problem domains. In this paper, we introduce AnalogiLead, an interactive interface designed to reduce premature dismissal of analogies by facilitating playful exploration of analogical leads. Drawing on cognitive mechanisms of conceptual chunking and recombination, AnalogiLead scaffolds users to engage with meaningful chunks of problems and analogies and recombine them into inspiring brainstorming questions. In a within-subjects experiment, participants (N=23) who used AnalogiLead dismissed analogies 4x less often, with 12x fewer decision changes, compared to a baseline interface with no chunking or recombination. This reduction in premature dismissal was associated with &nbsp;64% longer processing time. Through qualitative analysis of video and think-aloud data, we describe how the chunking and recombination mechanisms facilitated playful engagement with analogies. These findings highlight opportunities and challenges for improving analogical innovation through careful theory-driven design of interfaces for selecting analogical leads.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {374–397},
numpages = {24},
keywords = {Analogy, Creativity Support Tools, Large Language Models},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

",https://doi.org/10.1145/3635636.3656207,10.1145/3635636.3656207,acm,2024
708,Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models,"@inproceedings{10.1145/3636243.3636245,
author = {Macneil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne},
title = {Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636245},
doi = {10.1145/3636243.3636245},
abstract = {Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior – in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {11–18},
numpages = {8},
keywords = {bug detection, computing education, generative AI, large language models, programming errors},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

",https://doi.org/10.1145/3636243.3636245,10.1145/3636243.3636245,"acm, web_of_science, scopus",2024
709,More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems,"@inproceedings{10.1145/3636243.3636247,
author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636247},
doi = {10.1145/3636243.3636247},
abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {29–38},
numpages = {10},
keywords = {Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

",https://doi.org/10.1145/3636243.3636247,10.1145/3636243.3636247,"acm, web_of_science, scopus",2024
710,The Effects of Generative AI on Computing Students’ Help-Seeking Preferences,"@inproceedings{10.1145/3636243.3636248,
author = {Hou, Irene and Mettille, Sophia and Man, Owen and Li, Zhuo and Zastudil, Cynthia and MacNeil, Stephen},
title = {The Effects of Generative AI on Computing Students’ Help-Seeking Preferences},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636248},
doi = {10.1145/3636243.3636248},
abstract = {Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {39–48},
numpages = {10},
keywords = {ChatGPT, Generative AI, computing education, help-seeking},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

",https://doi.org/10.1145/3636243.3636248,10.1145/3636243.3636248,acm,2024
711,"Patterns of Student Help-Seeking When Using a Large Language
  Model-Powered Programming Assistant"," @inproceedings{Sheese_2024, series={ACE 2024}, title={Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant}, url={http://dx.doi.org/10.1145/3636243.3636249}, DOI={10.1145/3636243.3636249}, booktitle={Proceedings of the 26th Australasian Computing Education Conference}, publisher={ACM}, author={Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul}, year={2024}, month=jan, collection={ACE 2024} }
",http://arxiv.org/pdf/2310.16984v1.pdf,10.1145/3636243.3636249,"arxiv, acm, web_of_science, scopus",2023
712,Evaluating LLM-generated Worked Examples in an Introductory Programming Course,"@inproceedings{10.1145/3636243.3636252,
author = {Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating LLM-generated Worked Examples in an Introductory Programming Course},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636252},
doi = {10.1145/3636243.3636252},
abstract = {Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {77–86},
numpages = {10},
keywords = {CS1, GPT-3.5, LLM, chat-GPT, computing education, large language models, worked examples},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

",https://doi.org/10.1145/3636243.3636252,10.1145/3636243.3636252,"acm, web_of_science, scopus",2024
713,"A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in
  Programming Education"," @inproceedings{Doughty_2024, series={ACE 2024}, title={A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education}, url={http://dx.doi.org/10.1145/3636243.3636256}, DOI={10.1145/3636243.3636256}, booktitle={Proceedings of the 26th Australasian Computing Education Conference}, publisher={ACM}, author={Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd}, year={2024}, month=jan, collection={ACE 2024} }
",http://arxiv.org/pdf/2312.03173v1.pdf,10.1145/3636243.3636256,"arxiv, acm, web_of_science, scopus",2023
714,"""It's not like Jarvis, but it's pretty close!"" -- Examining ChatGPT's
  Usage among Undergraduate Students in Computer Science"," @inproceedings{Budhiraja_2024, series={ACE 2024}, title={“It’s not like Jarvis, but it’s pretty close!” - Examining ChatGPT’s Usage among Undergraduate Students in Computer Science}, url={http://dx.doi.org/10.1145/3636243.3636257}, DOI={10.1145/3636243.3636257}, booktitle={Proceedings of the 26th Australasian Computing Education Conference}, publisher={ACM}, author={Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv}, year={2024}, month=jan, collection={ACE 2024} }
",http://arxiv.org/pdf/2311.09651v2.pdf,10.1145/3636243.3636257,"arxiv, acm, web_of_science, scopus",2023
715,Next-Step Hint Generation for Introductory Programming Using Large Language Models,"@inproceedings{10.1145/3636243.3636259,
author = {Roest, Lianne and Keuning, Hieke and Jeuring, Johan},
title = {Next-Step Hint Generation for Introductory Programming Using Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636259},
doi = {10.1145/3636243.3636259},
abstract = {Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student’s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {Generative AI, Large Language Models, Next-step hints, automated feedback, learning programming},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

",https://doi.org/10.1145/3636243.3636259,10.1145/3636243.3636259,"acm, web_of_science, scopus",2024
716,More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions,"@inproceedings{10.1145/3636243.3636263,
author = {Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan},
title = {More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636263},
doi = {10.1145/3636243.3636263},
abstract = {Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {182–191},
numpages = {10},
keywords = {Artificial Intelligence, Assessment, Computer Graphics, Computing Education, Evaluation, GPT-4, Large Language Models},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

",https://doi.org/10.1145/3636243.3636263,10.1145/3636243.3636263,"acm, scopus",2024
717,Report on the Dagstuhl Seminar on Frontiers of Information Access Experimentation for Research and Education,"@article{10.1145/3636341.3636351,
author = {Bauer, Christine and Carterette, Ben and Ferro, Nicola and Fuhr, Norbert and Beel, Joeran and Breuer, Timo and Clarke, Charles L. A. and Crescenzi, Anita and Demartini, Gianluca and Di Nunzio, Giorgio Maria and Dietz, Laura and Faggioli, Guglielmo and Ferwerda, Bruce and Fr\""{o}be, Maik and Hagen, Matthias and Hanbury, Allan and Hauff, Claudia and Jannach, Dietmar and Kando, Noriko and Kanoulas, Evangelos and Knijnenburg, Bart P. and Kruschwitz, Udo and Li, Meijie and Maistro, Maria and Michiels, Lien and Papenmeier, Andrea and Potthast, Martin and Rosso, Paolo and Said, Alan and Schaer, Philipp and Seifert, Christin and Spina, Damiano and Stein, Benno and Tintarev, Nava and Urbano, Juli\'{a}n and Wachsmuth, Henning and Willemsen, Martijn C. and Zobel, Justin},
title = {Report on the Dagstuhl Seminar on Frontiers of Information Access Experimentation for Research and Education},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/3636341.3636351},
doi = {10.1145/3636341.3636351},
abstract = {This report documents the program and the outcomes of Dagstuhl Seminar 23031 ""Frontiers of Information Access Experimentation for Research and Education"", which brought together 38 participants from 12 countries. The seminar addressed technology-enhanced information access (information retrieval, recommender systems, natural language processing) and specifically focused on developing more responsible experimental practices leading to more valid results, both for research as well as for scientific education.The seminar featured a series of long and short talks delivered by participants, who helped in setting a common ground and in letting emerge topics of interest to be explored as the main output of the seminar. This led to the definition of five groups which investigated challenges, opportunities, and next steps in the following areas: reality check, i.e. conducting real-world studies, human-machine-collaborative relevance judgment frameworks, overcoming methodological challenges in information retrieval and recommender systems through awareness and education, results-blind reviewing, and guidance for authors.Date: 15--20 January 2023.Website: https://www.dagstuhl.de/23031.},
journal = {SIGIR Forum},
month = {dec},
articleno = {7},
numpages = {28}
}

",https://doi.org/10.1145/3636341.3636351,10.1145/3636341.3636351,acm,2023
718,Automated Grading and Feedback Tools for Programming Education: A Systematic Review,"@article{10.1145/3636515,
author = {Messer, Marcus and Brown, Neil C. C. and K\""{o}lling, Michael and Shi, Miaojing},
title = {Automated Grading and Feedback Tools for Programming Education: A Systematic Review},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3636515},
doi = {10.1145/3636515},
abstract = {We conducted a systematic literature review on automated grading and feedback tools for programming education. We analysed 121 research papers from 2017 to 2021 inclusive and categorised them based on skills assessed, approach, language paradigm, degree of automation, and evaluation techniques. Most papers assess the correctness of assignments in object-oriented languages. Typically, these tools use a dynamic technique, primarily unit testing, to provide grades and feedback to the students or static analysis techniques to compare a submission with a reference solution or with a set of correct student submissions. However, these techniques’ feedback is often limited to whether the unit tests have passed or failed, the expected and actual output, or how they differ from the reference solution. Furthermore, few tools assess the maintainability, readability, or documentation of the source code, with most using static analysis techniques, such as code quality metrics, in conjunction with grading correctness. Additionally, we found that most tools offered fully automated assessment to allow for near-instantaneous feedback and multiple resubmissions, which can increase student satisfaction and provide them with more opportunities to succeed. In terms of techniques used to evaluate the tools’ performance, most papers primarily use student surveys or compare the automatic assessment tools to grades or feedback provided by human graders. However, because the evaluation dataset is frequently unavailable, it is more difficult to reproduce results and compare tools to a collection of common assignments.},
journal = {ACM Trans. Comput. Educ.},
month = {feb},
articleno = {10},
numpages = {43},
keywords = {Automated grading, feedback, assessment, computer science education, systematic literature review, automatic assessment tools}
}

",https://doi.org/10.1145/3636515,10.1145/3636515,acm,2024
719,AutoDroid: LLM-powered Task Automation in Android,"@inproceedings{10.1145/3636534.3649379,
author = {Wen, Hao and Li, Yuanchun and Liu, Guohong and Zhao, Shanhui and Yu, Tao and Li, Toby Jia-Jun and Jiang, Shiqi and Liu, Yunhao and Zhang, Yaqin and Liu, Yunxin},
title = {AutoDroid: LLM-powered Task Automation in Android},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649379},
doi = {10.1145/3636534.3649379},
abstract = {Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or endusers. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system capable of handling arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection techniques that augment the app-specific domain knowledge of LLM, and a multi-granularity query optimization module that reduces the cost of model inference. We integrate AutoDroid with off-the-shelf LLMs including online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a new benchmark for memory-augmented Android task automation with 158 common tasks. The results demonstrated that AutoDroid is able to precisely generate actions with an accuracy of 90.9%, and complete tasks with a success rate of 71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {543–557},
numpages = {15},
keywords = {task automation, large language models, app analysis},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

",https://doi.org/10.1145/3636534.3649379,10.1145/3636534.3649379,acm,2024
720,Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation,"@inproceedings{10.1145/3636555.3636846,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Singh, Anjali and Brooks, Christopher and Cambronero, Jos\'{e} and Gulwani, Sumit and Singla, Adish and Soares, Gustavo},
title = {Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636846},
doi = {10.1145/3636555.3636846},
abstract = {Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a “tutor” model to generate hints – it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a “student” model to further validate the hint quality – it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {12–23},
numpages = {12},
keywords = {ChatGPT, Feedback Generation, GPT4, Generative AI, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

",https://doi.org/10.1145/3636555.3636846,10.1145/3636555.3636846,"acm, scopus",2024
721,Feedback on Feedback: Comparing Classic Natural Language Processing and Generative AI to Evaluate Peer Feedback,"@inproceedings{10.1145/3636555.3636850,
author = {Hutt, Stephen and DePiro, Allison and Wang, Joann and Rhodes, Sam and Baker, Ryan S and Hieb, Grayson and Sethuraman, Sheela and Ocumpaugh, Jaclyn and Mills, Caitlin},
title = {Feedback on Feedback: Comparing Classic Natural Language Processing and Generative AI to Evaluate Peer Feedback},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636850},
doi = {10.1145/3636555.3636850},
abstract = {Peer feedback can be a powerful tool as it presents learning opportunities for both the learner receiving feedback as well as the learner providing feedback. Despite its utility, it can be difficult to implement effectively, particularly for younger learners, who are often novices at providing feedback. It can be difficult for students to learn what constitutes “good” feedback – particularly in open-ended problem-solving contexts. To address this gap, we investigate both classical natural language processing techniques and large language models, specifically ChatGPT, as potential approaches to devise an automated detector of feedback quality (including both student progress towards goals and next steps needed). Our findings indicate that the classical detectors are highly accurate and, through feature analysis, we elucidate the pivotal elements influencing its decision process. We find that ChatGPT is less accurate than classical NLP but illustrate the potential of ChatGPT in evaluating feedback, by generating explanations for ratings, along with scores. We discuss how the detector can be used for automated feedback evaluation and to better scaffold peer feedback for younger learners.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {55–65},
numpages = {11},
keywords = {Generative AI, Language Analytics, Large Language Models, Natural Language Processing, Peer Feedback},
location = {Kyoto, Japan},
series = {LAK '24}
}

",https://doi.org/10.1145/3636555.3636850,10.1145/3636555.3636850,acm,2024
722,Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence,"@article{2-s2.0-85187550433,
  title={Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85187550433&origin=inward,10.1145/3636555.3636882,scopus,2024
723,Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches,"@inproceedings{10.1145/3636555.3636905,
author = {Suraworachet, Wannapon and Seon, Jennifer and Cukurova, Mutlu},
title = {Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636905},
doi = {10.1145/3636555.3636905},
abstract = {Effective collaboration requires groups to strategically regulate themselves to overcome challenges. Research has shown that groups may fail to regulate due to differences in members’ perceptions of challenges which may benefit from external support. In this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ML) model and a Large Language model (LLM), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical/other challenges) from student discourse, was investigated. The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts. The paper provides an extensive discussion of the three approaches’ performance for automated detection and support of students’ challenge moments in collaborative learning activities. It argues that, although LLMs provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation. We conclude the paper with a discussion on additional considerations, including model transparency to explore feasible and meaningful analytical feedback for students and educators using LLMs.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {473–485},
numpages = {13},
keywords = {Challenge moments, Collaborative learning, Discourse analysis, Natural language processing},
location = {Kyoto, Japan},
series = {LAK '24}
}

",https://doi.org/10.1145/3636555.3636905,10.1145/3636555.3636905,acm,2024
724,Prompt-based and Fine-tuned GPT Models for Context-Dependent and -Independent Deductive Coding in Social Annotation,"@inproceedings{10.1145/3636555.3636910,
author = {Hou, Chenyu and Zhu, Gaoxia and Zheng, Juan and Zhang, Lishan and Huang, Xiaoshan and Zhong, Tianlong and Li, Shan and Du, Hanxiang and Ker, Chin Lee},
title = {Prompt-based and Fine-tuned GPT Models for Context-Dependent and -Independent Deductive Coding in Social Annotation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636910},
doi = {10.1145/3636555.3636910},
abstract = {GPT has demonstrated impressive capabilities in executing various natural language processing (NLP) and reasoning tasks, showcasing its potential for deductive coding in social annotations. This research explored the effectiveness of prompt engineering and fine-tuning approaches of GPT for deductive coding of context-dependent and context-independent dimensions. Coding context-dependent dimensions (i.e., Theorizing, Integration, Reflection) requires a contextualized understanding that connects the target comment with reading materials and previous comments, whereas coding context-independent dimensions (i.e., Appraisal, Questioning, Social, Curiosity, Surprise) relies more on the comment itself. Utilizing strategies such as prompt decomposition, multi-prompt learning, and a codebook-centered approach, we found that prompt engineering can achieve fair to substantial agreement with expert-labeled data across various coding dimensions. These results affirm GPT's potential for effective application in real-world coding tasks. Compared to context-independent coding, context-dependent dimensions had lower agreement with expert-labeled data. To enhance accuracy, GPT models were fine-tuned using 102 pieces of expert-labeled data, with an additional 102 cases used for validation. The fine-tuned models demonstrated substantial agreement with ground truth in context-independent dimensions and elevated the inter-rater reliability of context-dependent categories to moderate levels. This approach represents a promising path for significantly reducing human labor and time, especially with large unstructured datasets, without sacrificing the accuracy and reliability of deductive coding tasks in social annotation. The study marks a step toward optimizing and streamlining coding processes in social annotation. Our findings suggest the promise of using GPT to analyze qualitative data and provide detailed, immediate feedback for students to elicit deepening inquiries.&nbsp;},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {518–528},
numpages = {11},
keywords = {Context-Dependent, Fine-tuning, GPT, Prompt Engineering, Social Annotation, deductive coding},
location = {Kyoto, Japan},
series = {LAK '24}
}

",https://doi.org/10.1145/3636555.3636910,10.1145/3636555.3636910,acm,2024
725,Analyzing Students Collaborative Problem-Solving Behaviors in Synergistic STEM+C Learning,"@inproceedings{10.1145/3636555.3636912,
author = {Snyder, Caitlin and Hutchins, Nicole M and Cohn, Clayton and Fonteles, Joyce Horn and Biswas, Gautam},
title = {Analyzing Students Collaborative Problem-Solving Behaviors in Synergistic STEM+C Learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636912},
doi = {10.1145/3636555.3636912},
abstract = {This study introduces a methodology to investigate students’ collaborative behaviors as they work in pairs to build computational models of scientific processes. We expand the Self-Regulated Learning (SRL) framework—specifically, Planning, Enacting, and Reflection—proposed in the literature, applying it to examine students’ collaborative problem-solving (CPS) behaviors in a computational modeling task. We analyze these behaviors by employing a Markov Chain (MC) modeling approach that scrutinizes students’ model construction and model debugging behaviors during CPS. This involves interpreting their actions in the system collected through computer logs and analyzing their conversations using a Large Language Model (LLM) as they progress through their modeling task in segments. Our analytical framework assesses the behaviors of high- and low-performing students by evaluating their proficiency in completing the specified computational model for a kinematics problem. We employ a mixed-methods approach, combining Markov Chain analysis of student problem-solving transitions with qualitative interpretations of their conversation segments. The results highlight distinct differences in behaviors between high- and low-performing groups, suggesting potential for developing adaptive scaffolds in future work to enhance support for students in collaborative problem-solving.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {540–550},
numpages = {11},
keywords = {SRL, STEM, collaboration, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

",https://doi.org/10.1145/3636555.3636912,10.1145/3636555.3636912,acm,2024
726,Comparing Authoring Experiences with Spreadsheet Interfaces vs GUIs,"@inproceedings{10.1145/3636555.3636919,
author = {Sheel, Shreya and Anastasopoulos, Ioannis and Pardos, Zach A.},
title = {Comparing Authoring Experiences with Spreadsheet Interfaces vs GUIs},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636919},
doi = {10.1145/3636555.3636919},
abstract = {There is little consensus over whether graphical user interfaces (GUIs) or programmatic systems are better for word processing. Even less is known about each interfaces’ affordances and limitations in the context of creating content for adaptive tutoring systems. In order to afford instructors the use of such systems with their own or adapted pedagogies, we must study their experiences in inputting their content. In this study, we conduct a between-subjects A/B test with two content authoring interfaces, a GUI and spreadsheet, to explore 32 instructors’ experiences in authoring algebra content with hints, scaffolds, images, and special characters. We study their experiences by measuring time taken, accuracy, and their perceptions of each interfaces’ usability. Our findings indicate no significant relationship between interface used and time taken authoring problems but significantly more accuracy in authoring problems in the spreadsheet interface over the GUI. Although both interfaces performed reasonably well in time taken and accuracy, both were perceived as average to low in usability, highlighting a dissonance between instructors’ perceptions and actual performances. Since both interfaces are reasonable in authoring content, other factors can be explored, such as cost and author incentive, when deciding which interface approach to take for authoring tutor content.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {598–607},
numpages = {10},
keywords = {A/B testing, adaptive tutoring systems, content authoring, human-computer interaction, usability},
location = {Kyoto, Japan},
series = {LAK '24}
}

",https://doi.org/10.1145/3636555.3636919,10.1145/3636555.3636919,acm,2024
727,Measuring and Clustering Heterogeneous Chatbot Designs,"@article{10.1145/3637228,
author = {Ca\~{n}izares, Pablo C. and L\'{o}pez-Morales, Jose Mar\'{\i}a and P\'{e}rez-Soler, Sara and Guerra, Esther and de Lara, Juan},
title = {Measuring and Clustering Heterogeneous Chatbot Designs},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3637228},
doi = {10.1145/3637228},
abstract = {Conversational agents, or chatbots, have become popular to access all kind of software services. They provide an intuitive natural language interface for interaction, available from a wide range of channels including social networks, web pages, intelligent speakers or cars. In response to this demand, many chatbot development platforms and tools have emerged. However, they typically lack support to statically measure properties of the chatbots being built, as indicators of their size, complexity, quality or usability. Similarly, there are hardly any mechanisms to compare and cluster chatbots developed with heterogeneous technologies.To overcome this limitation, we propose a suite of 21 metrics for chatbot designs, as well as two clustering methods that help in grouping chatbots along their conversation topics and design features. Both the metrics and the clustering methods are defined on a neutral chatbot design language, becoming independent of the implementation platform. We provide automatic translations of chatbots defined on some major platforms into this neutral notation to perform the measurement and clustering. The approach is supported by our tool Asymob, which we have used to evaluate the metrics and the clustering methods over a set of 259 Dialogflow and Rasa chatbots from open-source repositories. The results open the door to incorporating the metrics within chatbot development processes for the early detection of quality issues, and to exploit clustering to organise large collections of chatbots into significant groups to ease chatbot comprehension, search and comparison.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
articleno = {90},
numpages = {43},
keywords = {Chatbot design, metrics, clustering, quality assurance, model-driven engineering}
}

",https://doi.org/10.1145/3637228,10.1145/3637228,acm,2024
728,,"@article{10.1145/3637361,
author = {Wan, Qian and Hu, Siying and Zhang, Yu and Wang, Piaohong and Wen, Bo and Lu, Zhicong},
title = {""It Felt Like Having a Second Mind"": Investigating Human-AI Co-creativity in Prewriting with Large Language Models},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637361},
doi = {10.1145/3637361},
abstract = {Prewriting is the process of discovering and developing ideas before writing a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creative process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in addition to mixed and shifting levels of initiative that exist between humans and LLMs. This research also reports on collaboration breakdowns that occur during this process, user perceptions of using existing LLMs during Human-AI Co-creativity, and discusses design implications to support this co-creativity process.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {84},
numpages = {26},
keywords = {creative writing, creativity support, human-ai collaboration, large language models, prewriting}
}

",https://doi.org/10.1145/3637361,10.1145/3637361,acm,2024
729,Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data,"@article{10.1145/3637364,
author = {Wei, Jing and Kim, Sungdong and Jung, Hyunhoon and Kim, Young-Ho},
title = {Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637364},
doi = {10.1145/3637364},
abstract = {Large language models (LLMs) provide a new way to build chatbots by accepting natural language prompts. Yet, it is unclear how to design prompts to power chatbots to carry on naturalistic conversations while pursuing a given goal such as collecting self-report data from users. We explore what design factors of prompts can help steer chatbots to talk naturally and collect data reliably. To this aim, we formulated four prompt designs with different structures and personas. Through an online study (N = 48) where participants conversed with chatbots driven by different designs of prompts, we assessed how prompt designs and conversation topics affected the conversation flows and users' perceptions of chatbots. Our chatbots covered 79% of the desired information slots during conversations, and the designs of prompts and topics significantly influenced the conversation flows and the data collection performance. We discuss the opportunities and challenges of building chatbots with LLMs.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {87},
numpages = {35},
keywords = {chatbots, conversational agents, dialogue acts, large language models}
}

",https://doi.org/10.1145/3637364,10.1145/3637364,acm,2024
730,Understanding Practices around Computational News Discovery Tools in the Domain of Science Journalism,"@article{10.1145/3637419,
author = {Nishal, Sachita and Sinchai, Jasmine and Diakopoulos, Nicholas},
title = {Understanding Practices around Computational News Discovery Tools in the Domain of Science Journalism},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637419},
doi = {10.1145/3637419},
abstract = {Science and technology journalists today face challenges in finding newsworthy leads due to increased workloads, reduced resources, and expanding scientific publishing ecosystems. Given this context, we explore computational methods to aid these journalists' news discovery in terms of their agency and time-efficiency. We prototyped three computational information subsidies into an interactive tool that we used as a probe to better understand how such a tool may offer utility or more broadly shape the practices of professional science journalists. Our findings highlight central considerations around science journalists' user agency, contexts of use, and professional responsibility that such tools can influence and could account for in design. Based on this, we suggest design opportunities for enhancing and extending user agency over the longer-term; incorporating contextual, personal and collaborative notions of newsworthiness; and leveraging flexible interfaces and generative models. Overall, our findings contribute a richer view of the sociotechnical system around computational news discovery tools, and suggest ways to improve such tools to better support the practices of science journalists.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {142},
numpages = {36},
keywords = {computational news discovery, human-ai interaction, large language models, newsworthiness, science communication}
}

",https://doi.org/10.1145/3637419,10.1145/3637419,acm,2024
731,Simulating the Human in HCD with ChatGPT: Redesigning Interaction Design with AI,"@article{10.1145/3637436,
author = {Schmidt, Albrecht and Elagroudy, Passant and Draxler, Fiona and Kreuter, Frauke and Welsch, Robin},
title = {Simulating the Human in HCD with ChatGPT: Redesigning Interaction Design with AI},
year = {2024},
issue_date = {January - February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1072-5520},
url = {https://doi.org/10.1145/3637436},
doi = {10.1145/3637436},
journal = {Interactions},
month = {jan},
pages = {24–31},
numpages = {8}
}

",https://doi.org/10.1145/3637436,10.1145/3637436,acm,2024
732,Fairness in Deep Learning: A Survey on Vision and Language Research,"@article{10.1145/3637549,
author = {Parraga, Otavio and More, Martin D. and Oliveira, Christian M. and Gavenski, Nathan S. and Kupssinsk\""{u}, Lucas S. and Medronha, Adilson and Moura, Luis V. and Sim\~{o}es, Gabriel S. and Barros, Rodrigo C.},
title = {Fairness in Deep Learning: A Survey on Vision and Language Research},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3637549},
doi = {10.1145/3637549},
abstract = {Despite being responsible for state-of-the-art results in several computer vision and natural language processing tasks, neural networks have faced harsh criticism due to some of their current shortcomings. One of them is that neural networks are correlation machines prone to model biases within the data instead of focusing on actual useful causal relationships. This problem is particularly serious in application domains affected by aspects such as race, gender, and age. To prevent models from incurring unfair decision-making, the AI community has concentrated efforts on correcting algorithmic biases, giving rise to the research area now widely known as fairness in AI. In this survey paper, we provide an in-depth overview of the main debiasing methods for fairness-aware neural networks in the context of vision and language research. We propose a novel taxonomy that builds upon previous proposals but is tailored for deep learning research to better organize the literature on debiasing methods for fairness. We review all important neural-based methods and evaluation metrics while discussing the current challenges, trends, and important future work directions for the interested researcher and practitioner.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = {dec},
keywords = {fairness, neural networks, bias mitigation, computer vision, natural language processing, deep learning}
}

",https://doi.org/10.1145/3637549,10.1145/3637549,acm,2023
733,Development of chatbots connected to Learning Management Systems for the support and formative assessment of students,"@inproceedings{10.1145/3637989.3637998,
author = {Puertas, Enrique and Mariscal-Vivas, Gonzalo and Mart\'{\i}nez-Requejo, Sonia},
title = {Development of chatbots connected to Learning Management Systems for the support and formative assessment of students},
year = {2024},
isbn = {9798400708732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637989.3637998},
doi = {10.1145/3637989.3637998},
abstract = {This work discusses the development of chatbots connected to Learning Management Systems for the support and formative assessment of students in higher education. Because of the diversity of students, and limited time for teaching and evaluation, teachers are facing issues in terms of personalized learning and individualized attention. We present a system connected to a Learning Management System for retrieving course documents, that we use for feeding a chatbot that uses Large Language Model (LLM) in the background for supporting students. The architecture allows students to ask questions against an LLM model, and the response text uses a knowledge base built using the content of the notes and documents that teachers have uploaded to the educational platform as context and sources of information. This allows the answers to be specific and updated, providing insights on how chatbots can be used to enhance the learning experience of students in higher education.},
booktitle = {Proceedings of the 2023 7th International Conference on Education and E-Learning},
pages = {14–18},
numpages = {5},
keywords = {artificial intelligence, chatbot, e-learning, large language models, learning bots, learning management system},
location = {Tokyo, Japan},
series = {ICEEL '23}
}

",https://doi.org/10.1145/3637989.3637998,10.1145/3637989.3637998,acm,2024
734,May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes,"@inproceedings{10.1145/3638067.3638100,
author = {Freire, Andr\'{e} Pimenta and Cardoso, Paula Christina Figueira and Salgado, Andr\'{e} de Lima},
title = {May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638100},
doi = {10.1145/3638067.3638100},
abstract = {Using ChatGPT in education presents challenges for evaluating students. It requires distinguishing between original ideas and those generated by the model, assessing critical thinking skills, and gauging subject mastery accurately, which can impact fair assessment practices. The Human-Computer Interaction course described in this experience report has enabled consultation with textbooks, slides and other materials for over five years. This experience report describes reflections regarding using ChatGPT as a source of consultation in a written HCI exam in 2023. The paper describes experiences with analysis of the types of questions ChatGPT was able to solve immediately without mediation and the types of questions that could benefit from ChatGPT’s assistance without compromising the assessment of higher-level learning outcomes that professors want to analyse in teaching HCI. The paper uses Bloom’s taxonomy to analyse different questions and abilities to be evaluated and how they can be solved solely by using ChatGPT. The paper discusses questions that need mediation, previous lived experience in class and understanding of the knowledge acquired in class that cannot be answered directly by copying and pasting questions into ChatGPT. The discussions can raise reflections on the learning outcomes that can be assessed in HCI written exams and how professors should reflect upon their experiences and expectations for exams in the age of growing generative artificial intelligence resources.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {6},
numpages = {11},
keywords = {ChatGPT, HCI education, evaluation, open-book exams},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

",https://doi.org/10.1145/3638067.3638100,10.1145/3638067.3638100,acm,2024
735,Building Domain-Specific Machine Learning Workflows: A Conceptual Framework for the State of the Practice,"@article{10.1145/3638243,
author = {Oakes, Bentley James and Famelis, Michalis and Sahraoui, Houari},
title = {Building Domain-Specific Machine Learning Workflows: A Conceptual Framework for the State of the Practice},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3638243},
doi = {10.1145/3638243},
abstract = {Domain experts are increasingly employing machine learning to solve their domain-specific problems. This article presents to software engineering researchers the six key challenges that a domain expert faces in addressing their problem with a computational workflow, and the underlying executable implementation. These challenges arise out of our conceptual framework which presents the “route” of transformations that a domain expert may choose to take while developing their solution.To ground our conceptual framework in the state of the practice, this article discusses a selection of available textual and graphical workflow systems and their support for the transformations described in our framework. Example studies from the literature in various domains are also examined to highlight the tools used by the domain experts as well as a classification of the domain specificity and machine learning usage of their problem, workflow, and implementation.The state of the practice informs our discussion of the six key challenges, where we identify which challenges and transformations are not sufficiently addressed by available tools. We also suggest possible research directions for software engineering researchers to increase the automation of these tools and disseminate best-practice techniques between software engineering and various scientific domains.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
articleno = {91},
numpages = {50},
keywords = {Computational workflow, workflow composition, domain experts, machine learning, machine learning pipelines, software engineering framework}
}

",https://doi.org/10.1145/3638243,10.1145/3638243,acm,2024
736,Classifying Sentiments on Social Media Texts: A GPT-4 Preliminary Study,"@inproceedings{10.1145/3639233.3639353,
author = {Maceda, Lany Laguna and Llovido, Jennifer Laraya and Artiaga, Miles Biago and Abisado, Mideth Balawiswis},
title = {Classifying Sentiments on Social Media Texts: A GPT-4 Preliminary Study},
year = {2024},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639233.3639353},
doi = {10.1145/3639233.3639353},
abstract = {In today's digital age, social media has become a hub for people to express their thoughts and feelings. Sentiment classification discerns public opinions and trends to understand their sentiments towards a certain topic. Often, achieving accurate sentiment classifications in large datasets necessitate the use of human-annotated training data which can be costly and time-consuming. Large Language Models (LLMs) like the Generative Pre-trained models by OpenAI have surged in popularity due to its capabilities in understanding the given tasks. In this preliminary study, we report the performance of the latest OpenAI GPT-4 using zero- and one-shot learning approaches on classifying sentiments when fed with social media dataset. Notably, the latter approach written in English which mimics the instructions designed for human annotators, achieved a substantial agreement (k = 0.77) with human annotations, displaying high accuracy, precision, and recall accordingly even without explicit training data. Meanwhile, the fine-tuned mBERT resulted to lower evaluation scores than the GPT-4. Our findings provide foundational insights into the strengths and limitations of GPT-4 for sentiment classification in a social media dataset, setting the groundwork for broad future research in this field.},
booktitle = {Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
pages = {19–24},
numpages = {6},
keywords = {GPT-4, LLM Prompting, Sentiment Annotation, Social Media Data},
location = {Seoul, Republic of Korea},
series = {NLPIR '23}
}

",https://doi.org/10.1145/3639233.3639353,10.1145/3639233.3639353,acm,2024
737,"LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4
  and Bard's Capacity to Handle Object-Oriented Programming Assignments"," @inproceedings{Cipriano_2024, series={ICSE-SEET ’24}, title={LLMs Still Can’t Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard’s Capacity to Handle Object-Oriented Programming Assignments}, url={http://dx.doi.org/10.1145/3639474.3640052}, DOI={10.1145/3639474.3640052}, booktitle={Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training}, publisher={ACM}, author={Cipriano, Bruno Pereira and Alves, Pedro}, year={2024}, month=apr, collection={ICSE-SEET ’24} }
",http://arxiv.org/pdf/2403.06254v1.pdf,10.1145/3639474.3640052,"arxiv, acm, scopus",2024
738,"Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To
  Program Comprehension Questions"," @inproceedings{Lehtinen_2024, series={ICSE-SEET ’24}, title={Let’s Ask AI About Their Programs: Exploring ChatGPT’s Answers To Program Comprehension Questions}, url={http://dx.doi.org/10.1145/3639474.3640058}, DOI={10.1145/3639474.3640058}, booktitle={Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training}, publisher={ACM}, author={Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto}, year={2024}, month=apr, collection={ICSE-SEET ’24} }
",http://arxiv.org/pdf/2404.11734v1.pdf,10.1145/3639474.3640058,"arxiv, acm, scopus",2024
739,Experience Report: Identifying Common Misconceptions and Errors of Novice Programmers with ChatGPT," @inproceedings{Fwa_2024, series={ICSE-SEET ’24}, title={Experience Report: Identifying common misconceptions and errors of novice programmers with ChatGPT}, url={http://dx.doi.org/10.1145/3639474.3640059}, DOI={10.1145/3639474.3640059}, booktitle={Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training}, publisher={ACM}, author={Fwa, Hua Leong}, year={2024}, month=apr, collection={ICSE-SEET ’24} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554713,10.1145/3639474.3640059,"ieee, acm",2024
740,AI-Tutoring in Software Engineering Education," @inproceedings{Frankford_2024, series={ICSE-SEET ’24}, title={AI-Tutoring in Software Engineering Education}, url={http://dx.doi.org/10.1145/3639474.3640061}, DOI={10.1145/3639474.3640061}, booktitle={Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training}, publisher={ACM}, author={Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth}, year={2024}, month=apr, collection={ICSE-SEET ’24} }
",http://arxiv.org/pdf/2404.02548v2.pdf,10.1145/3639474.3640061,"arxiv, acm, scopus",2024
741,Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments,"@inproceedings{10.1145/3639474.3640065,
author = {Tao, Yida and Chen, Wenyan and Ye, Qingyang and Zhao, Yao},
title = {Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640065},
doi = {10.1145/3639474.3640065},
abstract = {Practical programming assignments are critical parts of programming courses in Computer Science education. Students are expected to translate programming concepts learned from lectures into executable implementations that solve the tasks outlined in the assignments. These implementations are primarily assessed based on their functional correctness, ensuring that students' code produces the expected output when provided with specific inputs.However, functional correctness is not the only metric that evaluates the quality of programs. Runtime efficiency is a metric that is less frequently evaluated in programming courses, yet it holds significant importance in the context of professional software development. To investigate this gap and its potential ramifications, we conducted a large-scale empirical study on the time efficiency of 250 programming assignments that are evaluated solely on functional correctness. The results demonstrate that students' programming assignments exhibit significant variance in terms of execution time. We further identified 27 recurring inefficient code patterns from these assignments, and observed that most of the inefficient patterns can be optimized by automated tools such as PMD, IntelliJ IDEA and ChatGPT. Our findings provide actionable guidelines for educators to enhance the organization and integration of code performance topics throughout the programming course curriculum.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {320–330},
numpages = {11},
keywords = {programming assignment, code performance, tool support},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

",https://doi.org/10.1145/3639474.3640065,10.1145/3639474.3640065,acm,2024
742,Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education," @inproceedings{Pan_2024, series={ICSE-SEET ’24}, title={Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education}, url={http://dx.doi.org/10.1145/3639474.3640068}, DOI={10.1145/3639474.3640068}, booktitle={Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training}, publisher={ACM}, author={Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan}, year={2024}, month=apr, collection={ICSE-SEET ’24} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554754,10.1145/3639474.3640068,"ieee, acm, scopus",2024
743,Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments,"@article{2-s2.0-85194836271,
  title={Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194836271&origin=inward,10.1145/3639474.3640084,scopus,2024
744,Towards Trustworthy AI Software Development Assistance,"@inproceedings{10.1145/3639476.3639770,
author = {Maninger, Daniel and Narasimhan, Krishna and Mezini, Mira},
title = {Towards Trustworthy AI Software Development Assistance},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639770},
doi = {10.1145/3639476.3639770},
abstract = {It is expected that in the near future, AI software development assistants will play an important role in the software industry. However, current software development assistants tend to be unreliable, often producing incorrect, unsafe, or low-quality code. We seek to resolve these issues by introducing a holistic architecture for constructing, training, and using trustworthy AI software development assistants. In the center of the architecture, there is a foundational LLM trained on datasets representative of real-world coding scenarios and complex software architectures, and fine-tuned on code quality criteria beyond correctness. The LLM will make use of graph-based code representations for advanced semantic comprehension. We envision a knowledge graph integrated into the system to provide up-to-date background knowledge and to enable the assistant to provide appropriate explanations. Finally, a modular framework for constrained decoding will ensure that certain guarantees (e.g., for correctness and security) hold for the generated code.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {112–116},
numpages = {5},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

",https://doi.org/10.1145/3639476.3639770,10.1145/3639476.3639770,acm,2024
745,LogExpert: Log-based Recommended Resolutions Generation using Large Language Model,"@inproceedings{10.1145/3639476.3639773,
author = {Wang, Jiabo and Chu, Guojun and Wang, Jingyu and Sun, Haifeng and Qi, Qi and Wang, Yuanyi and Qi, Ji and Liao, Jianxin},
title = {LogExpert: Log-based Recommended Resolutions Generation using Large Language Model},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639773},
doi = {10.1145/3639476.3639773},
abstract = {Software logs play a vital role in ensuring the reliability and availability of large-scale software systems. In recent years, researchers have made significant efforts to build log analysis approaches to manage software systems. However, these approaches focus on log compression, log parsing and log anomaly detection. In the current context, engineers continue to spend substantial time and effort on resolving errors once anomalous logs have been detected. To achieve truly automated software system management and high-level Artificial Intelligence for IT Operations (AIOps), it's necessary to bridge the gap between anomalous logs and their resolutions.In this paper, we propose a novel framework LogExpert to automatically generate recommended resolutions for anomalous logs. Specifically, we build a log recognizer to utilize the wealth of software knowledge in technical forums such as Stack Overflow (SO). In addition, LogExpert combines the great power of a Large Language Model (LLM) with domain-specific knowledge to generate the resolution. We conducted a preliminary evaluation of our framework on datasets from SO. Our log recognizer achieves the F1 score of 0.936. Our lexical metrics and human evaluation show the overall LogExpert framework achieves excellent performance in log-based resolution generation.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {42–46},
numpages = {5},
keywords = {log-based resolution generation, log anomaly detection, large language models, Stack Overflow},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

",https://doi.org/10.1145/3639476.3639773,10.1145/3639476.3639773,acm,2024
746,ITG: Trace Generation via Iterative Interaction between LLM Query and Trace Checking,"@inproceedings{10.1145/3639476.3639779,
author = {Luo, Weilin and Fang, Weiyuan and Qiu, Junming and Wan, Hai and Liu, Yanan and Ye, Rongzhen},
title = {ITG: Trace Generation via Iterative Interaction between LLM Query and Trace Checking},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639779},
doi = {10.1145/3639476.3639779},
abstract = {Due to the complexity of linear temporal logic (LTL) trace generation (PSPACE-Complete), existing neural network-based approaches will fail as the formula sizes increase. Recently, large language models (LLMs) have demonstrated remarkable reasoning capabilities, benefiting from efficient training on hyper-scale data. Inspired by this, we propose an iterative interaction framework for applying LLMs, exemplified by ChatGPT, to generate a trace satisfying a given LTL formula. The key insight behind it is to transfer the powerful reasoning capabilities of LLM to LTL trace generation via iterative interaction between LLM reasoning and logical reasoning. Preliminary results show that compared with the state-of-the-art approach, the accuracy is relatively improved by 9.7%-23.4%. Besides, we show that our framework is able to produce heuristics for new tasks, which provides a reference for other reasoning-heavy tasks requiring heuristics.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {11–15},
numpages = {5},
keywords = {large language model, linear temporal logic, satisfiability checking, trace generation, trace checking},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

",https://doi.org/10.1145/3639476.3639779,10.1145/3639476.3639779,acm,2024
747,Enhancing Text-to-SQL Translation for Financial System Design,"@inproceedings{10.1145/3639477.3639732,
author = {Song, Yewei and Ezzini, Saad and Tang, Xunzhu and Lothritz, Cedric and Klein, Jacques and Bissyande, Tegawende and Boytsov, Andrey and Ble, Ulrick and Goujon, Anne},
title = {Enhancing Text-to-SQL Translation for Financial System Design},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639732},
doi = {10.1145/3639477.3639732},
abstract = {Text-to-SQL, the task of translating natural language questions into SQL queries, is part of various business processes. Its automation, which is an emerging challenge, will empower software practitioners to seamlessly interact with relational databases using natural language, thereby bridging the gap between business needs and software capabilities.In this paper, we consider Large Language Models (LLMs), which have achieved state of the art for various NLP tasks. Specifically, we benchmark Text-to-SQL performance, the evaluation methodologies, as well as input optimization (e.g., prompting). In light of the empirical observations that we have made, we propose two novel metrics that were designed to adequately measure the similarity between SQL queries.Overall, we share with the community various findings, notably on how to select the right LLM on Text-to-SQL tasks. We further demonstrate that a tree-based edit distance constitutes a reliable metric for assessing the similarity between generated SQL queries and the oracle for benchmarking Text2SQL approaches. This metric is important as it relieves researchers from the need to perform computationally expensive experiments such as executing generated queries as done in prior works. Our work implements financial domain use cases and, therefore contributes to the advancement of Text2SQL systems and their practical adoption in this domain.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {252–262},
numpages = {11},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

",https://doi.org/10.1145/3639477.3639732,10.1145/3639477.3639732,acm,2024
748,GitBug-Actions: Building Reproducible Bug-Fix Benchmarks with GitHub Actions,"@inproceedings{10.1145/3639478.3640023,
author = {Saavedra, Nuno and Silva, Andr\'{e} and Monperrus, Martin},
title = {GitBug-Actions: Building Reproducible Bug-Fix Benchmarks with GitHub Actions},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3640023},
doi = {10.1145/3639478.3640023},
abstract = {Bug-fix benchmarks are fundamental in advancing various sub-fields of software engineering such as automatic program repair (APR) and fault localization (FL). A good benchmark must include recent examples that accurately reflect technologies and development practices of today. To be executable in the long term, a benchmark must feature test suites that do not degrade overtime due to, for example, dependencies that are no longer available. Existing benchmarks fail in meeting both criteria. For instance, Defects4J, one of the foremost Java benchmarks, last received an update in 2020. Moreover, full-reproducibility has been neglected by the majority of existing benchmarks. In this paper, we present GitBug-Actions: a novel tool for building bug-fix benchmarks with modern and fully-reproducible bug-fixes. GitBug-Actions relies on the most popular CI platform, GitHub Actions, to detect bug-fixes and smartly locally execute the CI pipeline in a controlled and reproducible environment. To the best of our knowledge, we are the first to rely on GitHub Actions to collect bug-fixes. To demonstrate our toolchain, we deploy GitBug-Actions to build a proof-of-concept Go bug-fix benchmark containing executable, fully-reproducible bug-fixes from different repositories. A video demonstrating GitBug-Actions is available at: https://youtu.be/aBWwa1sJYBs.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {1–5},
numpages = {5},
keywords = {software bugs, bug benchmark, bug database, reproducibility, software testing, program analysis, github actions},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

",https://doi.org/10.1145/3639478.3640023,10.1145/3639478.3640023,acm,2024
749,GitHubInclusifier: Finding and fixing non-inclusive language in GitHub Repositories,"@inproceedings{10.1145/3639478.3640025,
author = {Todd, Liam and Grundy, John and Treude, Christoph},
title = {GitHubInclusifier: Finding and fixing non-inclusive language in GitHub Repositories},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3640025},
doi = {10.1145/3639478.3640025},
abstract = {Non-inclusive language in software artefacts has been recognised as a serious problem. We describe a tool to find and fix non-inclusive language in a variety of GitHub repository artefacts. These include various README files, PDFs, code comments, and code. A wide variety of non-inclusive language including racist, ageist, ableist, violent and others are located and issues created, tagging the artefacts for checking. Suggested fixes can be generated using third-party LLM APIs, and approved changes made to documents, including code refactorings, and committed to the repository.The tool and evaluation data are available from: https://github.com/LiamTodd/github-inclusifierThe demo video is available at: https://www.youtube.com/watch?v=1z1QKdQg-nM},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {89–93},
numpages = {5},
keywords = {inclusive language, refactoring, biased language, inappropriate language, software documentation, software maintenance tools},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

",https://doi.org/10.1145/3639478.3640025,10.1145/3639478.3640025,acm,2024
750,Prompt-Enhanced Software Vulnerability Detection Using ChatGPT," @inproceedings{Zhang_2024, series={ICSE-Companion ’24}, title={Prompt-Enhanced Software Vulnerability Detection Using ChatGPT}, url={http://dx.doi.org/10.1145/3639478.3643065}, DOI={10.1145/3639478.3643065}, booktitle={Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings}, publisher={ACM}, author={Zhang, Chenyuan and Liu, Hao and Zeng, Jiutian and Yang, Kejing and Li, Yuhong and Li, Hui}, year={2024}, month=apr, collection={ICSE-Companion ’24} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554843,10.1145/3639478.3643065,ieee,2024
751,MissConf: LLM-Enhanced Reproduction of Configuration-Triggered Bugs,"@inproceedings{10.1145/3639478.3647635,
author = {Fu, Ying and Wang, Teng and Li, Shanshan and Ding, Jinyan and Zhou, Shulin and Jia, Zhouyang and Li, Wang and Jiang, Yu and Liao, Xiangke},
title = {MissConf: LLM-Enhanced Reproduction of Configuration-Triggered Bugs},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3647635},
doi = {10.1145/3639478.3647635},
abstract = {Bug reproduction stands as a pivotal phase in software development, but the absence of configuration information emerges as the main obstacle to effective bug reproduction. Since configuration options generally control critical branches of the software, many bugs can only be triggered under specific configuration settings. We refer to these bugs as configuration-triggered bugs or CTBugs for short. The reproduction of CTBugs consumes considerable time and manual efforts due to the challenges in deducing the missing configuration options within the vast search space of configurations. This complexity contributes to a form of technical debt in software development.To address these challenges, we first conducted an empirical study on 120 CTBugs from 4 widely used systems to understand the root causes and factors influencing the reproduction of CTBugs. Based on our study, we designed and implemented MissConf, the first LLM-enhanced automated tool for CTBug reproduction. Miss-Conf first leverages the LLM to infer whether crucial configuration options are missing in the bug report. Once a suspect CTBug is found, MissConf employs configuration taint analysis and dynamic monitoring methods to filter suspicious configuration options set. Furthermore, it adopts a heuristic strategy for identifying crucial configuration options and their corresponding values. We evaluated MissConf on 5 real-world software systems. The experimental results demonstrate that MissConf successfully infers the 84% (41/49) of the CTBugs and reproduces the 65% (32/49) CTBugs. In the reproduction phase, MissConf eliminates up to 76% of irrelevant configurations, offering significant time savings for developers.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {484–495},
numpages = {12},
keywords = {bug reproduction, software configuration, software maintenance},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

",https://doi.org/10.1145/3639478.3647635,10.1145/3639478.3647635,acm,2024
752,wr-AI-ter: Enhancing Ownership Perception in AI-Driven Script Writing,"@inproceedings{10.1145/3639701.3656325,
author = {Weber, Christoph Johannes and Burgkart, Sebastian and Rothe, Sylvia},
title = {wr-AI-ter: Enhancing Ownership Perception in AI-Driven Script Writing},
year = {2024},
isbn = {9798400705038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639701.3656325},
doi = {10.1145/3639701.3656325},
abstract = {The integration of artificial intelligence (AI) into creative domains is increasing, presenting both challenges and opportunities. In screenwriting, personal artistic expression is a fundamental aspect of the creator’s identity and work. The current use of AI in such creative processes can sometimes overshadow the creator’s vision and lead to a reduced sense of ownership over the final product. We introduce wr-AI-ter, an interactive application consisting of four basic stages: Ideation, Structure, Refinement, and Export. While some related work focuses on experts The application is intended to aid users with varying levels of screenwriting proficiency in generating screenplays using artificial intelligence, while preserving their sense of authorship. We conducted a user study with 23 participants, who had different expertise (screenwriting, documentary filmmaking, and VFX artistry). The results indicate that AI has the potential to accelerate the screenwriting process and improve the quality of scripts without compromising the sense of ownership.},
booktitle = {Proceedings of the 2024 ACM International Conference on Interactive Media Experiences},
pages = {145–156},
numpages = {12},
keywords = {computational creativity, human-computer interaction, natural language evaluation, natural language generation, ownership, screenplay},
location = {Stockholm, Sweden},
series = {IMX '24}
}

",https://doi.org/10.1145/3639701.3656325,10.1145/3639701.3656325,acm,2024
753,PRogramAR: Augmented Reality End-User Robot Programming,"@article{10.1145/3640008,
author = {Ikeda, Bryce and Szafir, Daniel},
title = {PRogramAR: Augmented Reality End-User Robot Programming},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
url = {https://doi.org/10.1145/3640008},
doi = {10.1145/3640008},
abstract = {The field of end-user robot programming seeks to develop methods that empower non-expert programmers to task and modify robot operations. In doing so, researchers may enhance robot flexibility and broaden the scope of robot deployments into the real world. We introduce PRogramAR (Programming Robots using Augmented Reality), a novel end-user robot programming system that combines the intuitive visual feedback of augmented reality (AR) with the simplistic and responsive paradigm of trigger-action programming (TAP) to facilitate human-robot collaboration. Through PRogramAR, users are able to rapidly author task rules and desired reactive robot behaviors, while specifying task constraints and observing program feedback contextualized directly in the real world. PRogramAR provides feedback by simulating the robot’s intended behavior and providing instant evaluation of TAP rule executability to help end users better understand and debug their programs during development. In a system validation, 17 end users ranging from ages 18 to 83 used PRogramAR to program a robot to assist them in completing three collaborative tasks. Our results demonstrate how merging the benefits of AR and TAP using elements from prior robot programming research into a single novel system can successfully enhance the robot programming process for non-expert users.},
journal = {J. Hum.-Robot Interact.},
month = {mar},
articleno = {15},
numpages = {20},
keywords = {End-user robot programming, Trigger-Action Programming (TAP), Augmented Reality (AR), Human-Robot Interaction (HRI), Human-Robot Collaboration (HRC)}
}

",https://doi.org/10.1145/3640008,10.1145/3640008,acm,2024
754,Diverse Visual Question Generation Based on Multiple Objects Selection,"@article{10.1145/3640014,
author = {Fang, Wenhao and Xie, Jiayuan and Liu, Hongfei and Chen, Jiali and Cai, Yi},
title = {Diverse Visual Question Generation Based on Multiple Objects Selection},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1551-6857},
url = {https://doi.org/10.1145/3640014},
doi = {10.1145/3640014},
abstract = {Visual question generation task aims at generating high-quality questions about a given image. To make this tak applicable to various scenarios, e.g., the growing demand for exams, it is important to generate diverse questions. The existing methods for this task control diverse question generation based on different question types, e.g., “what” and “when.” Although different question types lead to description diversity, they cannot guarantee semantic diversity when asking the same objects. Research in the field of psychology shows that humans pay attention to different objects in an image based on their preferences, which is beneficial to constructing semantically diverse questions. According to the research, we propose a multi-selector visual question generation (MS-VQG) model that aims to focus on different objects to generate diverse questions. Specifically, our MS-VQG model employs multiple selectors to imitate different humans to select different objects in a given image. Based on these different selected objects, our MS-VQG model can generate diverse questions corresponding to each selector. Extensive experiments on two datasets show that our proposed model outperforms the baselines in generating diverse questions.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {mar},
articleno = {161},
numpages = {22},
keywords = {Multimodal, visual question generation, mixture of experts}
}

",https://doi.org/10.1145/3640014,10.1145/3640014,acm,2024
755,iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries,"@inproceedings{10.1145/3640543.3645142,
author = {Coscia, Adam and Holmes, Langdon and Morris, Wesley and Choi, Joon Suh and Crossley, Scott and Endert, Alex},
title = {iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645142},
doi = {10.1145/3640543.3645142},
abstract = {The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods. To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction. To validate our approach, we deployed iScore with three learning engineers over the course of a month. We present a case study where interacting with iScore led a learning engineer to improve their LLM’s score accuracy by three percentage points. Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {787–802},
numpages = {16},
keywords = {Data visualization, educational technology, explainable AI, large language models, visual analytics},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645142,10.1145/3640543.3645142,acm,2024
756,"Understanding Users’ Dissatisfaction with ChatGPT Responses: Types, Resolving Tactics, and the Effect of Knowledge Level","@inproceedings{10.1145/3640543.3645148,
author = {Kim, Yoonsu and Lee, Jueon and Kim, Seoyoung and Park, Jaehyuk and Kim, Juho},
title = {Understanding Users’ Dissatisfaction with ChatGPT Responses: Types, Resolving Tactics, and the Effect of Knowledge Level},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645148},
doi = {10.1145/3640543.3645148},
abstract = {Large language models (LLMs) with chat-based capabilities, such as ChatGPT, are widely used in various workflows. However, due to a limited understanding of these large-scale models, users struggle to use this technology and experience different kinds of dissatisfaction. Researchers have introduced several methods, such as prompt engineering, to improve model responses. However, they focus on enhancing the model’s performance in specific tasks, and little has been investigated on how to deal with the user dissatisfaction resulting from the model’s responses. Therefore, with ChatGPT as the case study, we examine users’ dissatisfaction along with their strategies to address the dissatisfaction. After organizing users’ dissatisfaction with LLM into seven categories based on a literature review, we collected 511 instances of dissatisfactory ChatGPT responses from 107 users and their detailed recollections of dissatisfactory experiences, which we released as a publicly accessible dataset. Our analysis reveals that users most frequently experience dissatisfaction when ChatGPT fails to grasp their intentions, while they rate the severity of dissatisfaction related to accuracy the highest. We also identified four tactics users employ to address their dissatisfaction and their effectiveness. We found that users often do not use any tactics to address their dissatisfaction, and even when using tactics, 72% of dissatisfaction remained unresolved. Moreover, we found that users with low knowledge of LLMs tend to face more dissatisfaction on accuracy while they often put minimal effort in addressing dissatisfaction. Based on these findings, we propose design implications for minimizing user dissatisfaction and enhancing the usability of chat-based LLM.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {385–404},
numpages = {20},
keywords = {Chat-based LLM, ChatGPT, Knowledge-level, Large Language Models, Resolving tactics, User-side dissatisfaction, datasets},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645148,10.1145/3640543.3645148,acm,2024
757,DataDive: Supporting Readers' Contextualization of Statistical Statements with Data Exploration,"@inproceedings{10.1145/3640543.3645155,
author = {Kim, Hyunwoo and Le, Khanh Duy and Lim, Gionnieve and Kim, Dae Hyun and Hong, Yoo Jin and Kim, Juho},
title = {DataDive: Supporting Readers' Contextualization of Statistical Statements with Data Exploration},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645155},
doi = {10.1145/3640543.3645155},
abstract = {Statistical statements that refer to data to support narratives or claims are commonly used to inform readers about the magnitude of social issues. While contextualizing statistical statements with relevant data supports readers in building their own interpretation of statements, the complexity of finding contextual information on the web and linking statistical statements with it impedes readers’ efforts to do so. We present DataDive, an interactive tool for contextualizing statistical statements for the readers of online texts. Based on users’ selections of statistical statements, our tool uses an LLM-powered pipeline to generate candidates of relevant contexts and poses them as guiding questions to the user as potential contexts for exploration. When the user selects a question, DataDive employs visualizations to further help the user compare and explore contextually relevant data. A technical evaluation shows that DataDive generates important and diverse questions that facilitate exploration around statistical statements and retrieves relevant data for comparison. Moreover, a user study with 21 participants suggests that DataDive facilitates users to explore diverse contexts and to be more aware of how statistical data could relate to the text.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {623–639},
numpages = {17},
keywords = {Contextualization, Data visualization, Reader support},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645155,10.1145/3640543.3645155,acm,2024
758,DynamicLabels: Supporting Informed Construction of Machine Learning Label Sets with Crowd Feedback,"@inproceedings{10.1145/3640543.3645157,
author = {Park, Jeongeon and Ko, Eun-Young and Park, Yeon Su and Yim, Jinyeong and Kim, Juho},
title = {DynamicLabels: Supporting Informed Construction of Machine Learning Label Sets with Crowd Feedback},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645157},
doi = {10.1145/3640543.3645157},
abstract = {Label set construction—deciding on a group of distinct labels—is an essential stage in building a supervised machine learning (ML) application, as a badly designed label set negatively affects subsequent stages, such as training dataset construction, model training, and model deployment. Despite its significance, it is challenging for ML practitioners to come up with a well-defined label set, especially when no external references are available. Through our formative study (n=8), we observed that even with the help of external references or domain experts, ML practitioners still need to go through multiple iterations to gradually improve the label set. In this process, there exist challenges in collecting helpful feedback and utilizing it to make optimal refinement decisions. To support informed refinement, we present DynamicLabels, a system that aims to support a more informed label set-building process with crowd feedback. Crowd workers provide annotations and label suggestions to the ML practitioner’s label set, and the ML practitioner can review the feedback through multi-aspect analysis and refine the label set with crowd-made labels. Through a within-subjects study (n=16) using two datasets, we found that DynamicLabels enables better understanding and exploration of the collected feedback and supports a more structured and flexible refinement process. The crowd feedback helped ML practitioners explore diverse perspectives, spot current weaknesses, and shop from crowd-generated labels. Metrics and label suggestions in DynamicLabels helped in obtaining a high-level overview of the feedback, gaining assurance, and spotting surfacing conflicts and edge cases that could have been overlooked.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {209–228},
numpages = {20},
keywords = {artifact or system, crowdsourcing, label set construction, machine learning},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645157,10.1145/3640543.3645157,acm,2024
759,Empirical Evidence on Conversational Control of GUI in Semantic Automation,"@inproceedings{10.1145/3640543.3645172,
author = {Weidele, Daniel Karl I. and Martino, Mauro and Valente, Abel N. and Rossiello, Gaetano and Strobelt, Hendrik and Franke, Loraine and Alvero, Kathryn and Misko, Shayenna and Auer, Robin and Bagchi, Sugato and Mihindukulasooriya, Nandana and Chowdhury, Faisal and Bramble, Gregory and Samulowitz, Horst and Gliozzo, Alfio and Amini, Lisa},
title = {Empirical Evidence on Conversational Control of GUI in Semantic Automation},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645172},
doi = {10.1145/3640543.3645172},
abstract = {This research explores integration of a Large Language Model (LLM) fine-tuned to conversationally control the user interface (UI) for a Semantic Automation Layer (SAL). We condense SAL capabilities from prior work and prioritize with business analysts and data engineers via a Kano model, before implementing a prototypical UI. We augment the UI with our conversational engine and propose In-situ Prompt Engineering and learn from Human Feedback to smoothen the interaction and manipulation of UI through natural language commands. To evaluate the efficacy and usability of conversational control in various use-case scenarios, we conduct and report on an empirical interaction design user study. Our findings provide evidence supporting enhanced user engagement and satisfaction. We also observe significant increase of trust in AI after working with our conversational UI. This work generates areas for further refinement and research towards more intelligent, highly-integrated conversational UIs even beyond our application within Semantic Automation. We discuss our findings and point out next steps paving the way for future research and development in creating more intuitive and adaptive user interfaces.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {869–885},
numpages = {17},
keywords = {Conversational Graphical User Interface, Empirical Interaction Design User Study, Fine-tuned large language model, In-situ Prompt Engineering for UI Control, Semantic Automation Layer},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645172,10.1145/3640543.3645172,acm,2024
760,From Text to Pixels: Enhancing User Understanding through Text-to-Image Model Explanations,"@inproceedings{10.1145/3640543.3645173,
author = {Evirgen, Noyan and Wang, Ruolin and Chen, Xiang 'Anthony},
title = {From Text to Pixels: Enhancing User Understanding through Text-to-Image Model Explanations},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645173},
doi = {10.1145/3640543.3645173},
abstract = {Recent progress in Text-to-Image (T2I) models promises transformative applications in art, design, education, medicine, and entertainment. These models, exemplified by Dall-e, Imagen, and Stable Diffusion, have the potential to revolutionize various industries. However, a primary concern is their operation as a ‘black-box’ for many users. Without understanding the underlying mechanics, users are unable to harness the full potential of these models. This study focuses on bridging this gap by developing and evaluating explanation techniques for T2I models, targeting inexperienced end users. While prior works have delved into Explainable AI (XAI) methods for classification or regression tasks, T2I generation poses distinct challenges. Through formative studies with experts, we identified unique explanation goals and subsequently designed tailored explanation strategies. We then empirically evaluated these methods with a cohort of 473 participants from Amazon Mechanical Turk (AMT) across three tasks. Our results highlight users’ ability to learn new keywords through explanations, a preference for example-based explanations, and challenges in comprehending explanations that significantly shift the image’s theme. Moreover, findings suggest users benefit from a limited set of concurrent explanations. Our main contributions include a curated dataset for evaluating T2I explainability techniques, insights from a comprehensive AMT user study, and observations critical for future T2I model explainability research.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {74–87},
numpages = {14},
keywords = {Explainability Methods, Text-to-Image, User-Study, XAI},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645173,10.1145/3640543.3645173,acm,2024
761,The effect of personalizing a psychotherapy conversational agent on therapeutic bond and usage intentions,"@inproceedings{10.1145/3640543.3645195,
author = {Vossen, Wout and Szymanski, Maxwell and Verbert, Katrien},
title = {The effect of personalizing a psychotherapy conversational agent on therapeutic bond and usage intentions},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645195},
doi = {10.1145/3640543.3645195},
abstract = {While 33.6% of college students suffer from mental health problems, only 24.6% of these students with symptoms would seek professional help due to their personal attitudes or costs associated with therapy. Psychotherapy chatbots may offer a solution as they are always available, anonymous, and cost-effective. Research has shown that these chatbots can significantly reduce symptoms of anxiety and depression. However, there is a lack of understanding about the personalization preferences of users and the effects of personalization on health outcomes. To investigate this, we developed a personalizable psychotherapy chatbot designed to provide personalized help. In a randomized controlled trial (n = 54), participants were either assigned to a personalizable condition or a non-personalizable control condition. After 1 week of usage, participants had a significantly higher therapeutic bond with the personalized version compared to the baseline. In fact, the therapeutic bond was similar to that between a psychologist and his client. This is a promising result, as a high therapeutic bond has been linked to therapeutic success in psychotherapy. Participants reported that the therapy style, personality, and avatar were the most important personalizable aspects of the chatbot. Participants also liked the chatbot’s usage of their name and the transparency about what the chatbot had learned about them. These features are likely important for establishing a strong therapeutic bond with users. However, the ability to personalize the chatbot had no impact on the usage intentions of the participants. This can be explained by the fact that users from both conditions equally reported that the chatbot was able to help them with their mental health. 53 participants also indicated that they would be willing to use a psychotherapy chatbot when integrated with a human therapist. These findings indicate the potential of psychotherapy chatbots and the need for further research on their integration with traditional psychotherapy.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {761–771},
numpages = {11},
keywords = {affective computing, conversational interfaces and assistants, generative ai, personalization},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645195,10.1145/3640543.3645195,acm,2024
762,Jamplate: Exploring LLM-Enhanced Templates for Idea Reflection,"@inproceedings{10.1145/3640543.3645196,
author = {Xu, Xiaotong (Tone) and Yin, Jiayu and Gu, Catherine and Mar, Jenny and Zhang, Sydney and E, Jane L. and Dow, Steven P.},
title = {Jamplate: Exploring LLM-Enhanced Templates for Idea Reflection},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645196},
doi = {10.1145/3640543.3645196},
abstract = {Advances in AI, particularly large language models (LLMs), can transform creative work. When developing a new idea, LLMs can help designers gather information, find competitors, and generate alternatives. However, LLM responses tend to be long-winded or contain inaccuracies, placing a burden on users to carefully synthesize information. In our formative studies with 52 students and five instructors, we find that novice designers typically lack guidance on how to compose prompts, reflect critically on LLM responses, and extract key information to help shape an idea. Building on these insights, we explore an alternative approach for interacting with LLMs, not via chat, but rather through structured templates. Collaborative design templates are a well-established strategy for helping novices think, organize information, and reflect on creative work. Developed as a digital whiteboard plugin, Jamplate integrates LLM capabilities into design templates, streamlining the collection and organization of user-generated content and LLM responses within the template structure. In a preliminary study with 8 novice designers, participants expressed that Jamplate’s reflective questions and in-situ guidance improved their ability to think critically and improve ideas more effectively. We discuss the potential of designing LLM-enhanced templates to instigate critical reflection.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {907–921},
numpages = {15},
keywords = {LLM interaction, design process, design template, large language model interaction},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645196,10.1145/3640543.3645196,acm,2024
763,"Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration","@inproceedings{10.1145/3640543.3645198,
author = {Qian, Crystal and Wexler, James},
title = {Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645198},
doi = {10.1145/3640543.3645198},
abstract = {Although recent developments in generative AI have greatly enhanced the capabilities of conversational agents such as Google’s Bard or OpenAI’s ChatGPT, it’s unclear whether the usage of these agents aids users across various contexts. To better understand how access to conversational AI affects productivity and trust, we conducted a mixed-methods, task-based user study, observing 76 software engineers (N=76) as they completed a programming exam with and without access to Bard. Effects on performance, efficiency, satisfaction, and trust vary depending on user expertise, question type (open-ended ""solve"" questions vs. definitive ""search"" questions), and measurement type (demonstrated vs. self-reported). Our findings include evidence of automation complacency, increased reliance on the AI over the course of the task, and increased performance for novices on “solve”-type questions when using the AI. We discuss common behaviors, design recommendations, and impact considerations to improve collaborations with conversational AI.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {370–384},
numpages = {15},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645198,10.1145/3640543.3645198,acm,2024
764,Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking,"@inproceedings{10.1145/3640543.3645200,
author = {Khurana, Anjali and Subramonyam, Hariharan and Chilana, Parmit K},
title = {Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645200},
doi = {10.1145/3640543.3645200},
abstract = {Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software. LLMs use vast training data from domain-specific texts, software manuals, and code repositories to mimic human-like interactions, offering tailored assistance, including step-by-step instructions. In this work, we investigated LLM-generated software guidance through a within-subject experiment with 16 participants and follow-up interviews. We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts. We assessed task completion, perceived accuracy, relevance, and trust. Surprisingly, although SoftAIBot outperformed the baseline LLM, our results revealed no significant difference in LLM usage and user perceptions with or without prompt guidelines and the integration of domain context. Most users struggled to understand how the prompt’s text related to the LLM’s responses and often followed the LLM’s suggestions verbatim, even if they were incorrect. This resulted in difficulties when using the LLM’s advice for software tasks, leading to low task completion rates. Our detailed analysis also revealed that users remained unaware of inaccuracies in the LLM’s responses, indicating a gap between their lack of software expertise and their ability to evaluate the LLM’s assistance. With the growing push for designing domain-specific LLM assistants, we emphasize the importance of incorporating explainable, context-aware cues into LLMs to help users understand prompt-based interactions, identify biases, and maximize the utility of LLM assistants.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {288–303},
numpages = {16},
keywords = {feature-rich software, help-seeking, large language models, prompt-based interactions},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645200,10.1145/3640543.3645200,acm,2024
765,AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy,"@inproceedings{10.1145/3640543.3645213,
author = {Pillis, Daniel and Pataranutaporn, Pat and Maes, Pattie and Sra, Misha},
title = {AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645213},
doi = {10.1145/3640543.3645213},
abstract = {Despite significant historical progress, discrimination and social stigma continue to impact the lives of LGBTQIA+ individuals. The use of AI-generated virtual characters offers a unique opportunity to facilitate advocacy by engaging individuals in simulated conversations that can foster understanding, education, and empathy. This paper explores the potential of AI simulations to help individuals practice LGBTQIA+ advocacy, while also acknowledging the need for ethical considerations and addressing concerns about oversimplification or perpetuation of stereotypes. By combining technological innovation with a commitment to inclusivity, we aim to contribute to the ongoing struggle for equality in both the legal framework and the hearts and minds of the community. We present a study evaluating virtual characters driven by generative conversational AI simulating the social interactions surrounding “coming out of the closet”, a rite of passage associated with LGBTQIA+ communities. In our study, virtual characters embodied as queer individuals engage with users in a text-based conversation simulation paired with visual representations. We investigate how the interactions between the virtual characters and a user influence the user’s comfort, confidence, empathy and sympathy. The AI simulation includes distinct visual personas deployed in a series of conditions. We present findings from our deployments involving 307 users. Finally, we discuss the design implications of our work on the potential future of embodied, self-actuated and openly LGBTQIA+ intelligent agents.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {686–698},
numpages = {13},
keywords = {LGBTQIA+ · Drama Management · AI Actor · Virtual Characters · Player Modelling · Believable Characters · Choice-Based Narrative · Interactive Theatre},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645213,10.1145/3640543.3645213,acm,2024
766,Closing the Knowledge Gap in Designing Data Annotation Interfaces for AI-powered Disaster Management Analytic Systems,"@inproceedings{10.1145/3640543.3645214,
author = {Ara, Zinat and Salemi, Hossein and Hong, Sungsoo Ray and Senarath, Yasas and Peterson, Steve and Hughes, Amanda Lee and Purohit, Hemant},
title = {Closing the Knowledge Gap in Designing Data Annotation Interfaces for AI-powered Disaster Management Analytic Systems},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645214},
doi = {10.1145/3640543.3645214},
abstract = {Data annotation interfaces predominantly leverage ground truth labels to guide annotators toward accurate responses. With the growing adoption of Artificial Intelligence (AI) in domain-specific professional tasks, it has become increasingly important to help beginning annotators identify how their early-stage knowledge can lead to inaccurate answers, which in turn, helps to ensure quality annotations at scale. To investigate this issue, we conducted a formative study involving eight individuals from the field of disaster management, each possessing varying levels of expertise. The goal was to understand the prevalent factors contributing to disagreements among annotators when classifying Twitter messages related to disasters and to analyze their respective responses. Our analysis identified two primary causes of disagreement between expert and beginner annotators: 1) a lack of contextual knowledge or uncertainty about the situation, and 2) the absence of visual or supplementary cues. Based on these findings, we designed a Context interface, which generates aids that help beginners identify potential mistakes and provide the hidden context of the presented tweet. The summative study compares Context design with two widely used designs in data annotation UI, Highlight and Reasoning-based interfaces. We found significant differences between these designs in terms of attitudinal and behavioral data. We conclude with implications for designing future interfaces aiming at closing the knowledge gap among annotators.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {405–418},
numpages = {14},
keywords = {Data Annotation, Emergency Management, Group Work, Knowledge gap, Transportation},
location = {Greenville, SC, USA},
series = {IUI '24}
}

",https://doi.org/10.1145/3640543.3645214,10.1145/3640543.3645214,acm,2024
767,Understanding is a Two-Way Street: User-Initiated Repair on Agent Responses and Hearing in Conversational Interfaces,"@article{10.1145/3641026,
author = {Moore, Robert J. and An, Sungeun and Marrese, Olivia H.},
title = {Understanding is a Two-Way Street: User-Initiated Repair on Agent Responses and Hearing in Conversational Interfaces},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3641026},
doi = {10.1145/3641026},
abstract = {Although methods for repairing prior turns in natural conversation are critical for enabling mutual understanding, or successful communication, these methods are seldom built into conversational user interfaces systematically. Chatbots and voice assistants tend to ask users to paraphrase what they said if it was not understood, but users cannot do the same if they encounter trouble in understanding what the agent said. Understanding is a one-way street in most (intent-based) conversation-like interfaces. An exception to this is Moore and Arar (2019), who demonstrate nine types of user-initiated repair on agent responses that are common in natural conversation and who have shown that users will employ these repair features correctly in text-based interfaces if taught. In this small-scale study, we test these user-initiated repairs (in second position) in a voice-based interface. With understanding-oriented repairs, we found that participants employed them much the same way in text and voice. In addition, we examine some hearing- and speaking-oriented repairs that emerged from the use of our novel multi-modal interface. We found that participants used them to manage troubles specific to the voice modality. Analysis of user logs and transcripts suggests that user-initiated repair features are valuable components of conversational interfaces.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {187},
numpages = {26},
keywords = {chatbots, conversational agents, conversational ai, conversational user interfaces, conversational ux, user-initiated repair}
}

",https://doi.org/10.1145/3641026,10.1145/3641026,acm,2024
768,A Report on the Sixth Workshop on Emerging Software Engineering Education (WESEE 2024),"@article{2-s2.0-85186757810,
  title={A Report on the Sixth Workshop on Emerging Software Engineering Education (WESEE 2024)},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186757810&origin=inward,10.1145/3641399.3641436,scopus,2024
769,Report on the 1st Workshop on Generative Information Retrieval (Gen-IR 2023) at SIGIR 2023,"@article{10.1145/3642979.3642995,
author = {B\'{e}n\'{e}dict, Gabriel and Zhang, Ruqing and Metzler, Donald and Yates, Andrew and Deffayet, Romain and Hager, Philipp and Jullien, Sami},
title = {Report on the 1st Workshop on Generative Information Retrieval (Gen-IR 2023) at SIGIR 2023},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3642979.3642995},
doi = {10.1145/3642979.3642995},
abstract = {The first edition of the workshop on Generative Information Retrieval (Gen-IR 2023) took place in July 2023 in a hybrid fashion, co-located with the ACM SIGIR Conference 2023 in Taipei (SIGIR 2023). The aim was to bring information retrieval researchers together around the topic of generative AI that gathered attention in 2022 and 2023 with large language models and diffusion models. Given the novelty of the topic, the workshop was focused around multi-sided discussions, namely panels and poster sessions of the accepted proceedings papers. Two main research outcomes are the proceedings of the workshop1 and the potential research directions discussed in this report.Date: 27 July 2023.Website: https://coda.io/@sigir/gen-ir.},
journal = {SIGIR Forum},
month = {jan},
articleno = {13},
numpages = {23}
}

",https://doi.org/10.1145/3642979.3642995,10.1145/3642979.3642995,acm,2024
770,Chart Question Answering based on Modality Conversion and Large Language Models,"@inproceedings{10.1145/3643479.3662057,
author = {Liu, Yi-Cheng and Chu, Wei-Ta},
title = {Chart Question Answering based on Modality Conversion and Large Language Models},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643479.3662057},
doi = {10.1145/3643479.3662057},
abstract = {A two-stage chart question answering system is proposed in this paper. Chart/plot images are first converted into structured text-based data by a transformer-based conversion model. Based on the structured text data, a large language model (LLM) is employed to answer the given questions to achieve chart-related question answering. Techniques like chain-of-thoughts, self-consistency, and program of thoughts are utilized to prompt the LLM based on the one-shot learning scheme. We also found that, by rephrasing questions several times and asking the LLM, different answers may be obtained. Aggregating these answers gives rise to performance gain. Overall, we show the proposed method is competitive or even better than the state of the arts, with smaller model size and requiring less training data.},
booktitle = {Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
pages = {19–24},
numpages = {6},
keywords = {ChartQA, Large language model, PlotQA, Visual question answering},
location = {Phuket, Thailand},
series = {AIQAM '24}
}

",https://doi.org/10.1145/3643479.3662057,10.1145/3643479.3662057,acm,2024
771,Interview with Mariusz Pisarski,"@article{10.1145/3643603.3643606,
author = {Atzenbeck, Claus},
title = {Interview with Mariusz Pisarski},
year = {2024},
issue_date = {Winter 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2024},
number = {Winter},
issn = {1931-1745},
url = {https://doi.org/10.1145/3643603.3643606},
doi = {10.1145/3643603.3643606},
abstract = {Dr Mariusz Pisarski is a hypertext scholar, translator, publisher, the chief editor of ""Techsty""---a Polish journal on new media and literature. He teaches creative writing, hypertext, Twine and non-linear storytelling. His translation and media translation projects include Polish editions of Michael Joyce's hypertext fictions, poetry generator ""Sea and Spar Between"" by Stephanie Strickland and Nick Montfort and ""Hegirascope"" by Stuart Moulthrop. Recently he has created the online English edition of ""Twilight. A Symphony"" (2022) by Michael Joyce.His forthcoming publication is ""The Challenges of Born-Digital Fiction: Editions, Translations, and Emulations"" (co-authored with Dene Grigar) by Cambridge University Press. He is an assistant professor at Chair of Media and Journalism, University of Information Technology and Management in Rzesz\'{o}w, Poland and the secretary of Electronic Literature Research Center at Adam Mickiewicz University, Pozna\'{n}.},
journal = {SIGWEB Newsl.},
month = {feb},
articleno = {3},
numpages = {5}
}

",https://doi.org/10.1145/3643603.3643606,10.1145/3643603.3643606,acm,2024
772,Computer Science Education in Latin America and the Caribbean,"@article{10.1145/3643646,
author = {Pias, Marcelo and Cuadros-Vargas, Ernesto and Duran, Rodrigo},
title = {Computer Science Education in Latin America and the Caribbean},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {2153-2184},
url = {https://doi.org/10.1145/3643646},
doi = {10.1145/3643646},
journal = {ACM Inroads},
month = {feb},
pages = {38–47},
numpages = {10}
}

",https://doi.org/10.1145/3643646,10.1145/3643646,acm,2024
773,KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation,"@article{10.1145/3643675,
author = {Tao, Wei and Zhou, Yucheng and Wang, Yanlin and Zhang, Hongyu and Wang, Haofen and Zhang, Wenqiang},
title = {KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3643675},
doi = {10.1145/3643675},
abstract = {Commit messages are natural language descriptions of code changes, which are important for software evolution such as code understanding and maintenance. However, previous methods are trained on the entire dataset without considering the fact that a portion of commit messages adhere to good practice (i.e., good-practice commits), while the rest do not. On the basis of our empirical study, we discover that training on good-practice commits significantly contributes to the commit message generation. Motivated by this finding, we propose a novel knowledge-aware denoising learning method called KADEL. Considering that good-practice commits constitute only a small proportion of the dataset, we align the remaining training samples with these good-practice commits. To achieve this, we propose a model that learns the commit knowledge by training on good-practice commits. This knowledge model enables supplementing more information for training samples that do not conform to good practice. However, since the supplementary information may contain noise or prediction errors, we propose a dynamic denoising training method. This method composes a distribution-aware confidence function and a dynamic distribution list, which enhances the effectiveness of the training process. Experimental results on the whole MCMD dataset demonstrate that our method overall achieves state-of-the-art performance compared with previous methods.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {133},
numpages = {32},
keywords = {Commit message generation, knowledge introducing, denoising training}
}

",https://doi.org/10.1145/3643675,10.1145/3643675,acm,2024
774,Co-designing a knowledge management tool for educator communities of practice,"@inproceedings{10.1145/3643834.3660682,
author = {Fernandez-Nieto, Gloria Milena and Swiecki, Zachari and Tsai, Yi-Shan and Sha, Lele and Wei, Yinwei and Wen, Jim and Li, Yuheng and Jin, Yueqiao and Feraud, Ivan Silva and Li, Yuan-Fang and Wang, Weiqing and Chen, Guanliang and Gasevic, Dragan},
title = {Co-designing a knowledge management tool for educator communities of practice},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660682},
doi = {10.1145/3643834.3660682},
abstract = {Knowledge management involves finding, expanding, and using knowledge in an organisation to achieve goals. Its role is crucial in higher education to improve problem-solving, research, and teaching by acquiring, sharing, and applying knowledge. Higher education institutions can promote knowledge management through Communities of Practice, but doing so remains challenging due to cultural, organisational, and technological reasons. We present findings of the first step of co-design workshops with authentic higher education teaching teams that sought to understand (a) their practices as a community and any motivators and impediments to their community development; (b) how they perceived the tools they use for knowledge management; and (c) the kinds of tools they believed could help them better conduct knowledge management and develop as Communities of Practice. Our findings suggested four essential design requirements and informed our development of a new tool to support the knowledge management needs of higher education teaching teams.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1970–1990},
numpages = {21},
keywords = {co-design, communities of practice, education, knowledge management},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3660682,10.1145/3643834.3660682,acm,2024
775,Artificial Dreams: Surreal Visual Storytelling as Inquiry Into AI 'Hallucination',"@inproceedings{10.1145/3643834.3660685,
author = {Halperin, Brett A. and Lukin, Stephanie M},
title = {Artificial Dreams: Surreal Visual Storytelling as Inquiry Into AI 'Hallucination'},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660685},
doi = {10.1145/3643834.3660685},
abstract = {What does it mean for stochastic artificial intelligence (AI) to “hallucinate” when performing a literary task as open-ended as creative visual storytelling? In this paper, we investigate AI “hallucination” by stress-testing a visual storytelling algorithm with different visual and textual inputs designed to probe dream logic inspired by cinematic surrealism. Following a close reading of 100 visual stories that we deem artificial dreams, we describe how AI “hallucination” in computational visual storytelling is the opposite of groundedness: literary expression that is ungrounded in the visual or textual inputs. We find that this lack of grounding can be a source of either creativity or harm entangled with bias and illusion. In turn, we disentangle these obscurities and discuss steps toward addressing the perils while harnessing the potentials for innocuous cases of AI “hallucination” to enhance the creativity of visual storytelling.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {619–637},
numpages = {19},
keywords = {AI, Automatic Story Generation, Bias, Computational Storytelling, Creativity, Dreams, Generative AI, Hallucination, LLM, Large Language Models, NLG, Narrative Intelligence, Narrative System, Natural Language Generation, Storytelling, Surrealism, Visual Storytelling},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3660685,10.1145/3643834.3660685,acm,2024
776,The Power of Absence: Thinking with Archival Theory in Algorithmic Design,"@inproceedings{10.1145/3643834.3660690,
author = {Sherman, Jihan and Morrison, Romi and Klein, Lauren and Rosner, Daniela},
title = {The Power of Absence: Thinking with Archival Theory in Algorithmic Design},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660690},
doi = {10.1145/3643834.3660690},
abstract = {This paper explores the value of archival theory as a means of grappling with bias in algorithmic design. Rather than seek to mitigate biases perpetuated by datasets and algorithmic systems, archival theory offers a reframing of bias itself. Drawing on a range of archival theory from the fields of history, literary and cultural studies, Black studies, and feminist STS, we propose absence—as power, presence, and productive—as a concept that might more securely anchor investigations into the causes of algorithmic bias, and that can prompt more capacious, creative, and joyful future work. This essay, in turn, can intervene into the technical as well as the social, historical, and political structures that serve as sources of bias.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {214–223},
numpages = {10},
keywords = {AI, Absence, Algorithmic Systems, Automated Decision-making, Bias, Critical Archival Theory, Design Speculation},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3660690,10.1145/3643834.3660690,acm,2024
777,Understanding On-the-Fly End-User Robot Programming,"@inproceedings{10.1145/3643834.3660721,
author = {Stegner, Laura and Hwang, Yuna and Porfirio, David and Mutlu, Bilge},
title = {Understanding On-the-Fly End-User Robot Programming},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660721},
doi = {10.1145/3643834.3660721},
abstract = {Novel end-user programming (EUP) tools enable on-the-fly (i.e., spontaneous, easy, and rapid) creation of interactions with robotic systems. These tools are expected to empower users in determining system behavior, although very little is understood about how end users perceive, experience, and use these systems. In this paper, we seek to address this gap by investigating end-user experience with on-the-fly robot EUP. We trained 21 end users to use an existing on-the-fly EUP tool, asked them to create robot interactions for four scenarios, and assessed their overall experience. Our findings provide insight into how these systems should be designed to better support end-user experience with on-the-fly EUP, focusing on user interaction with an automatic program synthesizer that resolves imprecise user input, the use of multimodal inputs to express user intent, and the general process of programming a robot.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2468–2480},
numpages = {13},
keywords = {End-user Programming, Programming Tools, Robot Programming, Service Robots, Usage Patterns, User Experience, User Study},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3660721,10.1145/3643834.3660721,acm,2024
778,The CoExplorer Technology Probe: A Generative AI-Powered Adaptive Interface to Support Intentionality in Planning and Running Video Meetings,"@inproceedings{10.1145/3643834.3661507,
author = {Park, Gun Woo (Warren) and Panda, Payod and Tankelevitch, Lev and Rintel, Sean},
title = {The CoExplorer Technology Probe: A Generative AI-Powered Adaptive Interface to Support Intentionality in Planning and Running Video Meetings},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661507},
doi = {10.1145/3643834.3661507},
abstract = {Effective meetings are effortful, but traditional videoconferencing systems offer little support for reducing this effort across the meeting lifecycle. Generative AI (GenAI) has the potential to radically redefine meetings by augmenting intentional meeting behaviors. CoExplorer, our novel adaptive meeting prototype, preemptively generates likely phases that meetings would undergo, tools that allow capturing attendees’ thoughts before the meeting, and for each phase, window layouts, and appropriate applications and files. Using CoExplorer as a technology probe in a guided walkthrough, we studied its potential in a sample of participants from a global technology company. Our findings suggest that GenAI has the potential to help meetings stay on track and reduce workload, although concerns were raised about users’ agency, trust, and possible disruption to traditional meeting norms. We discuss these concerns and their design implications for the development of GenAI meeting technology.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1638–1657},
numpages = {20},
keywords = {adaptive user interface, design, effectiveness, effort, intent recognition, speech recognition, technology probe, video meetings, windowing system},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3661507,10.1145/3643834.3661507,acm,2024
779,Longitudinal Evaluation of Casual Puzzle Tablet Games by Older Adults,"@inproceedings{10.1145/3643834.3661528,
author = {Chaudhry, Beenish Moalla and Islam, Muhammad Usama and Chawla, Nitesh Vinay},
title = {Longitudinal Evaluation of Casual Puzzle Tablet Games by Older Adults},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661528},
doi = {10.1145/3643834.3661528},
abstract = {Despite growing interest in mobile games for older adults, there is limited exploration of older adults’ gaming behaviors, perceptions, and experiences as they engage with casual puzzle games over a period of time. To address this, we conducted a 9-month study with 20 older adults, examining training needs, in-situ experiences, and preferences. Participants were trained on tablet PCs and ten selected games. During the study, participants documented their experiences and attended technology workshops. Gaming behaviors were logged and analyzed using descriptive and inferential statistics, revealing patterns and statistically significant differences in play frequency and duration over the course of the study. Thematic analysis identified facilitators and barriers to engagement such as customization, co-play experiences, and health issues. Based on these findings, we recommend incorporating educational elements, enhancing user control, leveraging identity and nostalgia, supporting social interactions, designing for tangible interaction, and emphasizing the importance of learning aids. Future research should test the effectiveness of these recommendations in increasing older adults’ engagement with casual games.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2073–2087},
numpages = {15},
keywords = {casual games, design, evaluation, longitudinal study, mobile, older adults, tablet},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3661528,10.1145/3643834.3661528,acm,2024
780,How People Prompt Generative AI to Create Interactive VR Scenes,"@inproceedings{10.1145/3643834.3661547,
author = {Aghel Manesh, Setareh and Zhang, Tianyi and Onishi, Yuki and Hara, Kotaro and Bateman, Scott and Li, Jiannan and Tang, Anthony},
title = {How People Prompt Generative AI to Create Interactive VR Scenes},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661547},
doi = {10.1145/3643834.3661547},
abstract = {Generative AI tools can provide people with the ability to create virtual environments and scenes with natural language prompts. Yet, how people will formulate such prompts is unclear—particularly when they inhabit the environment that they are designing. For instance, it is likely that a person might say, “Put a chair here,” while pointing at a location. If such linguistic and embodied features are common to people’s prompts, we need to tune models to accommodate them. In this work, we present a Wizard of Oz elicitation study with 22 participants, where we studied people’s implicit expectations when verbally prompting such programming agents to create interactive VR scenes. Our findings show when people prompted the agent, they had several implicit expectations of these agents: (1) they should have an embodied knowledge of the environment; (2) they should understand embodied prompts by users; (3) they should recall previous states of the scene and the conversation, and that (4) they should have a commonsense understanding of objects in the scene. Further, we found that participants prompted differently when they were prompting in situ (i.e. within the VR environment) versus ex situ (i.e. viewing the VR environment from the outside). To explore how these lessons could be applied, we designed and built Ostaad, a conversational programming agent that allows non-programmers to design interactive VR experiences that they inhabit. Based on these explorations, we outline new opportunities and challenges for conversational programming agents that create VR environments.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2319–2340},
numpages = {22},
keywords = {embodied interaction, embodied prompting, generative ai, interactive virtual reality, multi-modal, prompting, virtual reality},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3661547,10.1145/3643834.3661547,acm,2024
781,Towards integrated learning experiences on social media: An exploration of #DayInTheLife videos for career exploration,"@inproceedings{10.1145/3643834.3661566,
author = {Malik, Hayat and Bhandari, Sonali and Fonseca, Elizabeth L and Bonaccorsi, Chiara and Lee, David},
title = {Towards integrated learning experiences on social media: An exploration of #DayInTheLife videos for career exploration},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661566},
doi = {10.1145/3643834.3661566},
abstract = {Though social media platforms contain rich information and insights on professional life, encounters with this content are often fleeting and disconnected, raising questions about the extent social media content is valuable for career identity formation. This paper reports on a research through design study that explores the potential of social media for supporting integrated learning experiences, through investigating and prototyping experiences around the use of TikTok #DayInTheLife videos for career exploration. We conducted semi-structured interviews of 10 college students to understand the value of social media content for career exploration and the feasibility of integrating such content towards reflective learning experiences. A qualitative analysis revealed that #DayInTheLife videos offer firsthand insights into professions that facilitates aspects of career identity formation, and have the potential to prompt and motivate further exploration. However, they are also limited due their short-form, disconnected, entertainment-oriented nature, the distracting context in which they exist, and the potential lack of representation in recommended content. We also had the students participate in an experience prototype in which we used native social media interactions such as comments, mentions, and direct messages to integrate encounters of disparate posts towards holistic and reflective learning experiences. We found that integrating encounters can facilitate more intentional reflection, add interactivity, and provide a sense of agency. We also surfaced contextual risk factors and design factors for designing integrated learning experiences on social media. We build on our findings to introduce and discuss a concept we call SIMPLE apps (Social media Interactions Merged for Purposeful Learning Experiences) and to discuss broader design implications for better harnessing social media content towards purposeful integrated learning.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1722–1740},
numpages = {19},
keywords = {#DayInTheLife videos, SIMPLE apps (Social media Interactions Merged for Purposeful Learning Experiences), career identity formation, integrated learning experiences, research through design, social media, youth career exploration},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3661566,10.1145/3643834.3661566,acm,2024
782,Not Just Novelty: A Longitudinal Study on Utility and Customization of an AI Workflow,"@inproceedings{10.1145/3643834.3661587,
author = {Long, Tao and Gero, Katy Ilonka and Chilton, Lydia B},
title = {Not Just Novelty: A Longitudinal Study on Utility and Customization of an AI Workflow},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661587},
doi = {10.1145/3643834.3661587},
abstract = {Generative AI brings novel and impressive abilities to help people in everyday tasks. There are many AI workflows that solve real and complex problems by chaining AI outputs together with human interaction. Although there is an undeniable lure of AI, it is uncertain how useful generative AI workflows are after the novelty wears off. Additionally, workflows built with generative AI have the potential to be easily customized to fit users’ individual needs, but do users take advantage of this? We conducted a three-week longitudinal study with 12 users to understand the familiarization and customization of generative AI tools for science communication. Our study revealed that there exists a familiarization phase, during which users were exploring the novel capabilities of the workflow and discovering which aspects they found useful. After this phase, users understood the workflow and were able to anticipate the outputs. Surprisingly, after familiarization the perceived utility of the system was rated higher than before, indicating that the perceived utility of AI is not just a novelty effect. The increase in benefits mainly comes from end-users’ ability to customize prompts, and thus potentially appropriate the system to their own needs. This points to a future where generative AI systems can allow us to design for appropriation.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {782–803},
numpages = {22},
keywords = {AI chains, LLMs, customization, familiarization, generative AI, longitudinal user experience, mental model, novelty, ownership, scaffolding, science communication, technology appropriation, workflow},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3661587,10.1145/3643834.3661587,acm,2024
783,Understanding the Initial Journey of UX Designers Toward Sustainable Interaction Design: A Focus on Digital Infrastructure Energy Reduction,"@inproceedings{10.1145/3643834.3661598,
author = {Lee, Minha and Jun, Jian and Lee, Sunok and Lee, Sangsu},
title = {Understanding the Initial Journey of UX Designers Toward Sustainable Interaction Design: A Focus on Digital Infrastructure Energy Reduction},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661598},
doi = {10.1145/3643834.3661598},
abstract = {Environmental sustainability is increasingly important, and actions on “digital sustainability” are expanding to reduce energy consumption from digital infrastructures. As many digital services today have extensive user bases, exploring sustainable design features holds significant potential for reducing environmental impact. However, further exploration of foundational research is still necessary to enable broader and more effective adoption of digital sustainability in design practice. This study focuses on understanding important considerations when encouraging more designers, especially those with limited expertise in sustainability-oriented design, to integrate sustainable practices into digital services—acknowledging that embracing unfamiliar approaches presents natural challenges. We conducted design workshops and debriefing interviews with user experience (UX) designers unfamiliar with design for sustainability to explore their early encounters with sustainable interaction design (SID) in the context of digital infrastructure energy reduction. Our study provides insight into designers’ initial perceptions and challenges with sustainable design and discusses opportunities for their broader engagement.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {3079–3096},
numpages = {18},
keywords = {Digital Infrastructures, Sustainability, Sustainable HCI, Sustainable Interaction Design, User Experience Design},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

",https://doi.org/10.1145/3643834.3661598,10.1145/3643834.3661598,acm,2024
784,Compositional API Recommendation for Library-Oriented Code Generation,"@inproceedings{10.1145/3643916.3644403,
author = {Ma, Zexiong and An, Shengnan and Xie, Bing and Lin, Zeqi},
title = {Compositional API Recommendation for Library-Oriented Code Generation},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644403},
doi = {10.1145/3643916.3644403},
abstract = {Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task.To address this, we propose CAPIR (Compositional API Recommendation), which adopts a ""divide-and-conquer"" strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation.To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation). Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines. Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On LOCG's Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0% to 28.0%.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {87–98},
numpages = {12},
keywords = {API recommendation, code generation, requirements decomposition, large language model},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

",https://doi.org/10.1145/3643916.3644403,10.1145/3643916.3644403,acm,2024
785,Knowledge-Aware Code Generation with Large Language Models,"@inproceedings{10.1145/3643916.3644418,
author = {Huang, Tao and Sun, Zhihong and Jin, Zhi and Li, Ge and Lyu, Chen},
title = {Knowledge-Aware Code Generation with Large Language Models},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644418},
doi = {10.1145/3643916.3644418},
abstract = {Large Language Models (LLMs) perform well on basic programming problems. However, they encounter challenges when dealing with complex tasks involving the use of diverse algorithmic and data structure skills, particularly programming competition-level problems. Notably, ChatGPT exhibits proficient performance on problems it has encountered during its pre-training phase, but this performance deteriorates when faced with novel problems. Consequently, enhancing the ability of LLMs to address unfamiliar problems has emerged as a pivotal research focus. The problem-solving process of LLMs mirrors human programmers' approach to a certain extent. When confronted with new programming tasks, human programmers engage in task planning and code writing with the previously acquired knowledge about algorithms and data structures. Despite having learned such knowledge, LLMs struggle to effectively apply it when faced with specific new problems. To address this issue, we constructed a novel dataset, CodeF, which contains a portion of programming problems that ChatGPT has not previously encountered. Furthermore, we developed a Knowledge Library tailored for Python programming contest problems and introduced the concept of Knowledge-Aware Code Generation (KareCoder). KareCoder bolsters the models' understanding and problem-solving capabilities by integrating prompt and knowledge from the library into the LLMs' code generation reasoning process, especially on Pass@1 metrics. Upon testing on the CodeF and APPS datasets, KareCoder demonstrated outstanding performance in handling novel problems previously unencountered by LLMs. In contrast with the code directly generated by ChatGPT, KareCoder achieved a relative improvement of 23.3% on the Pass@1 metric on the CodeF post2021-9 dataset. Additionally, it performs well compared to other methods when dealing with problems that LLMs have previously encountered. Our dataset and experiment data are open-sourced and can be accessed at https://github.com/CodeGeneration3/KareCoder.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {52–63},
numpages = {12},
keywords = {code generation, large language models, knowledge library},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

",https://doi.org/10.1145/3643916.3644418,10.1145/3643916.3644418,acm,2024
786,Reassessing Java Code Readability Models with a Human-Centered Approach,"@inproceedings{10.1145/3643916.3644435,
author = {Sergeyuk, Agnia and Lvova, Olga and Titov, Sergey and Serova, Anastasiia and Bagirov, Farid and Kirillova, Evgeniia and Bryksin, Timofey},
title = {Reassessing Java Code Readability Models with a Human-Centered Approach},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644435},
doi = {10.1145/3643916.3644435},
abstract = {To ensure that Large Language Models (LLMs) effectively support user productivity, they need to be adjusted. Existing Code Readability (CR) models can guide this alignment. However, there are concerns about their relevance in modern software engineering since they often miss the developers' notion of readability and rely on outdated code. This research assesses existing Java CR models for LLM adjustments, measuring the correlation between their and developers' evaluations of AI-generated Java code. Using the Repertory Grid Technique with 15 developers, we identified 12 key code aspects influencing CR that were consequently assessed by 390 programmers when labeling 120 AI-generated snippets. Our findings indicate that when AI generates concise and executable code, it's often considered readable by CR models and developers. However, a limited correlation between these evaluations underscores the importance of future research on learning objectives for adjusting LLMs and on the aspects influencing CR evaluations included in predictive models.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {225–235},
numpages = {11},
keywords = {code readability, code readability models, repertory grid technique, AI-generated code, human-computer interaction},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

",https://doi.org/10.1145/3643916.3644435,10.1145/3643916.3644435,acm,2024
787,GitBug-Java: A Reproducible Java Benchmark of Recent Bugs,"@inproceedings{10.1145/3643991.3644884,
author = {Silva, Andr\'{e} and Saavedra, Nuno and Monperrus, Martin},
title = {GitBug-Java: A Reproducible Java Benchmark of Recent Bugs},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644884},
doi = {10.1145/3643991.3644884},
abstract = {Bug-fix benchmarks are essential for evaluating methodologies in automatic program repair (APR) and fault localization (FL). However, existing benchmarks, exemplified by Defects4J, need to evolve to incorporate recent bug-fixes aligned with contemporary development practices. Moreover, reproducibility, a key scientific principle, has been lacking in bug-fix benchmarks. To address these gaps, we present GitBug-Java, a reproducible benchmark of recent Java bugs. GitBug-Java features 199 bugs extracted from the 2023 commit history of 55 notable open-source repositories. The methodology for building GitBug-Java ensures the preservation of bug-fixes in fully-reproducible environments. We publish GitBug-Java at https://github.com/gitbugactions/gitbug-java.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {118–122},
numpages = {5},
keywords = {software bugs, bug benchmark, reproducibility, bug database, Java benchmark, software testing, program analysis},
location = {Lisbon, Portugal},
series = {MSR '24}
}

",https://doi.org/10.1145/3643991.3644884,10.1145/3643991.3644884,acm,2024
788,Improving Automated Code Reviews: Learning from Experience,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10.1145/3643991.3644910</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10.1145/3643991.3644910"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",http://arxiv.org/pdf/2402.03777v1.pdf,10.1145/3643991.3644910,arxiv,2024
789,Data Augmentation for Supervised Code Translation Learning,"@inproceedings{10.1145/3643991.3644923,
author = {Chen, Binger and Golebiowski, Jacek and Abedjan, Ziawasch},
title = {Data Augmentation for Supervised Code Translation Learning},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644923},
doi = {10.1145/3643991.3644923},
abstract = {Data-driven program translation has been recently the focus of several lines of research. A common and robust strategy is supervised learning. However, there is typically a lack of parallel training data, i.e., pairs of code snippets in the source and target language. While many data augmentation techniques exist in the domain of natural language processing, they cannot be easily adapted to tackle code translation due to the unique restrictions of programming languages. In this paper, we develop a novel rule-based augmentation approach tailored for code translation data, and a novel retrieval-based approach that combines code samples from unorganized big code repositories to obtain new training data. Both approaches are language-independent. We perform an extensive empirical evaluation on existing Java-C#-benchmarks showing that our method improves the accuracy of state-of-the-art supervised translation techniques by up to 35%.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {444–456},
numpages = {13},
location = {Lisbon, Portugal},
series = {MSR '24}
}

",https://doi.org/10.1145/3643991.3644923,10.1145/3643991.3644923,acm,2024
790,"Whodunit: Classifying Code as Human Authored or GPT-4 Generated -- A
  case study on CodeChef problems","<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10.1145/3643991.3644926</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10.1145/3643991.3644926"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",http://arxiv.org/pdf/2403.04013v1.pdf,10.1145/3643991.3644926,arxiv,2024
791,Chatting with AI: Deciphering Developer Conversations with ChatGPT,"@inproceedings{10.1145/3643991.3645078,
author = {Mohamed, Suad and Parvin, Abdullah and Parra, Esteban},
title = {Chatting with AI: Deciphering Developer Conversations with ChatGPT},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645078},
doi = {10.1145/3643991.3645078},
abstract = {Large Language Models (LLMs) have been widely adopted and are becoming ubiquitous and integral to software development. However, we have little knowledge as to how these tools are being used by software developers beyond anecdotal evidence and word-of-mouth reports. In this work, we present a study toward understanding how developers engage with and utilize LLMs by reporting the results of an empirical study identifying patterns in the conversation that developers have with LLMs. We identified a total of 19 topics describing the purpose of the developers in their conversations with LLMs. Our findings reveal that developers use LLMs to facilitate various aspects of their software development processes (e.g., information-seeking about programming languages and frameworks and soliciting high-level design recommendations) to a similar extent to which they use them for non-development purposes such as writing assistance, general purpose queries, and conducting Turing tests to assess the intrinsic capabilities of the models. This work not only sheds light on the diverse applications of LLMs in software development but also underscores their emerging role as critical tools in enhancing developer productivity and creativity as we move closer to widespread AI-assisted software development.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {187–191},
numpages = {5},
keywords = {large language models, LLM, ChatGPT, software development, empirical study, developer conversations},
location = {Lisbon, Portugal},
series = {MSR '24}
}

",https://doi.org/10.1145/3643991.3645078,10.1145/3643991.3645078,acm,2024
792,Enhancing User Interaction in ChatGPT: Characterizing and Consolidating Multiple Prompts for Issue Resolution,"@inproceedings{10.1145/3643991.3645085,
author = {Mondal, Saikat and Bappon, Suborno Deb and Roy, Chanchal K.},
title = {Enhancing User Interaction in ChatGPT: Characterizing and Consolidating Multiple Prompts for Issue Resolution},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645085},
doi = {10.1145/3643991.3645085},
abstract = {Prompt design plays a crucial role in shaping the efficacy of ChatGPT, influencing the model's ability to extract contextually accurate responses. Thus, optimal prompt construction is essential for maximizing the utility and performance of ChatGPT. However, sub-optimal prompt design may necessitate iterative refinement, as imprecise or ambiguous instructions can lead to undesired responses from ChatGPT. Existing studies explore several prompt patterns and strategies to improve the relevance of responses generated by ChatGPT. However, the exploration of constraints that necessitate the submission of multiple prompts is still an unmet attempt. In this study, our contributions are twofold. First, we attempt to uncover gaps in prompt design that demand multiple iterations. In particular, we manually analyze 686 prompts that were submitted to resolve issues related to Java and Python programming languages and identify eleven prompt design gaps (e.g., missing specifications). Such gap exploration can enhance the efficacy of single prompts in ChatGPT. Second, we attempt to reproduce the ChatGPT response by consolidating multiple prompts into a single one. We can completely consolidate prompts with four gaps (e.g., missing context) and partially consolidate prompts with three gaps (e.g., additional functionality). Such an effort provides concrete evidence to users to design more optimal prompts mitigating these gaps. Our study findings and evidence can - (a) save users time, (b) reduce costs, and (c) increase user satisfaction.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {222–226},
numpages = {5},
keywords = {prompt design, ChatGPT, prompt consolidation, qualitative analysis},
location = {Lisbon, Portugal},
series = {MSR '24}
}

",https://doi.org/10.1145/3643991.3645085,10.1145/3643991.3645085,acm,2024
793,Leveraging Large Language Models to Boost Dafny’s Developers Productivity,"@inproceedings{10.1145/3644033.3644374,
author = {Silva, \'{A}lvaro F. and Mendes, Alexandra and Ferreira, Jo\~{a}o F.},
title = {Leveraging Large Language Models to Boost Dafny’s Developers Productivity},
year = {2024},
isbn = {9798400705892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644033.3644374},
doi = {10.1145/3644033.3644374},
abstract = {This research idea paper proposes leveraging Large Language Models (LLMs) to enhance the productivity of Dafny developers. Although the use of verification-aware languages, such as Dafny, has increased considerably in the last decade, these are still not widely adopted. Often the cost of using such languages is too high, due to the level of expertise required from the developers and challenges that they often face when trying to prove a program correct. Even though Dafny automates a lot of the verification process, sometimes there are steps that are too complex for Dafny to perform on its own. One such case is that of missing lemmas, i.e. Dafny is unable to prove a result without being given further help in the form of a theorem that can assist it in the proof of the step.In this paper, we describe preliminary work on using LLMs to assist developers by generating suggestions for relevant lemmas that Dafny is unable to discover and use. Moreover, for the lemmas that cannot be proved automatically, we attempt to provide accompanying calculational proofs. We also discuss ideas for future work by describing a research agenda on using LLMs to increase the adoption of verification-aware languages in general, by increasing developers productivity and by reducing the level of expertise required for crafting formal specifications and proving program properties.},
booktitle = {Proceedings of the 2024 IEEE/ACM 12th International Conference on Formal Methods in Software Engineering (FormaliSE)},
pages = {138–142},
numpages = {5},
keywords = {verification-aware languages, dafny, large language models, generative AI, software productivity, software verification, lemma inference, proof inference, automated program repair},
location = {Lisbon, Portugal},
series = {FormaliSE '24}
}

",https://doi.org/10.1145/3644033.3644374,10.1145/3644033.3644374,acm,2024
794,Seven Failure Points When Engineering a Retrieval Augmented Generation System,"@inproceedings{10.1145/3644815.3644945,
author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644945},
doi = {10.1145/3644815.3644945},
abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {194–199},
numpages = {6},
keywords = {retrieval augmented generation, RAG, SE4AI, case study},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

",https://doi.org/10.1145/3644815.3644945,10.1145/3644815.3644945,"acm, scopus",2024
795,Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for AI Accountability,"@inproceedings{10.1145/3644815.3644959,
author = {Xia, Boming and Lu, Qinghua and Zhu, Liming and Lee, Sung Une and Liu, Yue and Xing, Zhenchang},
title = {Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for AI Accountability},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644959},
doi = {10.1145/3644815.3644959},
abstract = {Artificial Intelligence (AI), particularly through the advent of large-scale generative AI (GenAI) models such as Large Language Models (LLMs), has become a transformative element in contemporary technology. While these models have unlocked new possibilities, they simultaneously present significant challenges, such as concerns over data privacy and the propensity to generate misleading or fabricated content. Current frameworks for Responsible AI (RAI) often fall short in providing the granular guidance necessary for tangible application, especially for Accountability---a principle that is pivotal for ensuring transparent and auditable decision-making, bolstering public trust, and meeting increasing regulatory expectations. This study bridges the Accountability gap by introducing our effort towards a comprehensive metrics catalogue, formulated through a systematic multivocal literature review (MLR) that integrates findings from both academic and grey literature. Our catalogue delineates process metrics that underpin procedural integrity, resource metrics that provide necessary tools and frameworks, and product metrics that reflect the outputs of AI systems. This tripartite framework is designed to operationalize Accountability in AI, with a special emphasis on addressing the intricacies of GenAI.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {100–111},
numpages = {12},
keywords = {responsible AI, accountable AI, risk assessment, generative AI},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

",https://doi.org/10.1145/3644815.3644959,10.1145/3644815.3644959,acm,2024
796,Generating Rate Features for Mobile Applications,"@inproceedings{10.1145/3647632.3647986,
author = {Shrestha, Shristi and Mahmoud, Anas},
title = {Generating Rate Features for Mobile Applications},
year = {2024},
isbn = {9798400705946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647632.3647986},
doi = {10.1145/3647632.3647986},
abstract = {Mobile application (app) stores employ standardized mechanisms for rating hosted apps, typically in the form of free text reviews and numerical rating scales. App users use these mechanisms to express their opinions about their apps and discover apps that fit their specific needs. However, existing app rating systems do not take into account the operational characteristics of application domains. Thus, generated user reviews are often short, subjective, and one-dimensional. To overcome these limitations, in this paper, we propose a multi-dimensional rating system for mobile apps. Our assumption is that an adaptive goal-based app rating system can prompt users to generate higher-quality reviews. To achieve our research objectives, we initially apply extractive summarization to generate short and concise summaries of salient themes in app reviews. Extracted summaries are then fed to a language model to generate Rate Features for apps. Our results show that the language model GPT-3.5 can be prompted to generate abstract, neutral, and domain-specific Rate Features that are aligned to a large extent with user goals in different application domains.},
booktitle = {Proceedings of the IEEE/ACM 11th International Conference on Mobile Software Engineering and Systems},
pages = {54–64},
numpages = {11},
location = {Lisbon, Portugal},
series = {MOBILESoft '24}
}

",https://doi.org/10.1145/3647632.3647986,10.1145/3647632.3647986,acm,2024
797,How Natural Language Processing Enables AIGC Recognition? --Latest Trends and Future Prospects,"@inproceedings{10.1145/3647722.3647738,
author = {Wang, Weizheng and Qiao, Hong},
title = {How Natural Language Processing Enables AIGC Recognition? --Latest Trends and Future Prospects},
year = {2024},
isbn = {9798400709197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647722.3647738},
doi = {10.1145/3647722.3647738},
abstract = {As the technology behind large language models advances rapidly, AI-generated content (AIGC) pervades our daily lives. Classifiers that identify AIGC play a crucial role in distinguishing between text generated by humans and that generated by artificial intelligence. In order to better prevent the abuse of AIGC and reduce the emergence of issues such as false information, academic misconduct, and deceptive comments, we introduced the task of AIGC classifiers, emphasizing the necessity of classifier development in this era. The essence of AIGC identification tasks lies in binary classification, aiming to discern whether a piece of content is created by artificial intelligence. In recent years, white-box and black-box methods as classifiers for identifying AIGC have made significant strides. In this paper, we curated the main research achievements in the field of AIGC identification, emphasizing the crucial role of comprehensive and excellent datasets in constructing AIGC recognition classifiers. Additionally, we explored the limitations and development goals of current popular datasets, as well as potential datasets. Furthermore, we analyzed paradigms of various classifiers, addressing challenges such as multidomain recognition tasks, cross-language recognition tasks, and data ambiguity issues. Finally, we proposed pathways for the future development of AIGC identification. This study aims to provide a clear overview for relevant researchers and offer constructive suggestions for constructing more stable and efficient classifiers.},
booktitle = {Proceedings of the 2024 7th International Conference on Software Engineering and Information Management},
pages = {103–109},
numpages = {7},
keywords = {AIGC, Black box test, Deep learning, Machine -generated content detection, white box test},
location = {Suva, Fiji},
series = {ICSIM '24}
}

",https://doi.org/10.1145/3647722.3647738,10.1145/3647722.3647738,acm,2024
798,The Impact of Large Language Models on Social Media Communication,"@inproceedings{10.1145/3647722.3647749,
author = {Qi, Jinhu},
title = {The Impact of Large Language Models on Social Media Communication},
year = {2024},
isbn = {9798400709197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647722.3647749},
doi = {10.1145/3647722.3647749},
abstract = {This article explores the impact of large language models (LLMs) on social media communication, with a focus on the spread of misinformation and cyberbullying. As social media becomes an integral part of modern life, challenges such as the rapid spread of misinformation and unethical online behavior continue to escalate. In this paper, the lab's main research delves into how large language models can improve the accuracy of information dissemination on platforms such as Twitter with their advanced capabilities and larger parameters. It also highlights the application of LLMs in identifying and filtering misinformation, as well as potential ethical and privacy considerations associated with their use. The studies mentioned here also explore the impact of LLMs in shaping social media communications, addressing technological advancements, and attendant social responsibilities.},
booktitle = {Proceedings of the 2024 7th International Conference on Software Engineering and Information Management},
pages = {165–170},
numpages = {6},
location = {Suva, Fiji},
series = {ICSIM '24}
}

",https://doi.org/10.1145/3647722.3647749,10.1145/3647722.3647749,acm,2024
799,A Literature Survey on Open Source Large Language Models,"@inproceedings{10.1145/3647782.3647803,
author = {Kukreja, Sanjay and Kumar, Tarun and Purohit, Amit and Dasgupta, Abhijit and Guha, Debashis},
title = {A Literature Survey on Open Source Large Language Models},
year = {2024},
isbn = {9798400716652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647782.3647803},
doi = {10.1145/3647782.3647803},
abstract = {Since the 1950s, post the Turing test, humans have been striving hard to make machines learn the art of mastering linguistic intelligence. Language being a complex and intricate tool of expression used by humans, poses a large number of challenges for AI enabled algorithms to grasp its understanding in entirety. Over the past few years, a chain of efforts have been made to make machines understand linguistic intricacies. Small scale models such as BERT and pre-trained language models (PLMs) have demonstrated strong capabilities in understanding and solving various language based tasks. Over the period of years, it is also observed that by increasing the parameters scale to larger size, large language models show a significant improvement in performance and showcase abilities to understand context. For the PLMs of a humongous size i.e in the tune of tens or hundreds of billions of parameters, and to understand the large parametric scales, the scientific community introduced the term LLMs - large language models. The whole world witnessed the launch and quick adoption of ChatGPT, an AI chatbot built on LLMs. As the usage of AI algorithms changes the way the scientific community, society and industry works, it is imperative to review the advances of LLMs. Since 2022, almost daily nearly a dozen LLMs are released. These LLMs are categorized as open and closed source. This paper aims to focus on major aspects of open source LLMs - pre-training covering data collection and pre-processing, model architecture and training. We will select open source models released in June, July and August 2023 with training parameters greater than 70 billion parameters and provide a comprehensive survey on the mentioned aspects. As new models are released on daily / weekly basis in the LLM space, in order to keep the survey concise and targeted to important models, we chose to select time-box of 3 months and a large parameter range of 70 billion in our literature survey. We will also cover historical evolution of LLMs and list open items for future directions.},
booktitle = {Proceedings of the 2024 7th International Conference on Computers in Management and Business},
pages = {133–143},
numpages = {11},
keywords = {Generative AI, Large Language Models, Open Source LLMs},
location = {Singapore, Singapore},
series = {ICCMB '24}
}

",https://doi.org/10.1145/3647782.3647803,10.1145/3647782.3647803,acm,2024
800,Cleenex: Support for User Involvement during an Iterative Data Cleaning Process,"@article{10.1145/3648476,
author = {Pereira, Jo\~{a}o L. M. and Fonseca, Manuel J. and Lopes, Ant\'{o}nia and Galhardas, Helena},
title = {Cleenex: Support for User Involvement during an Iterative Data Cleaning Process},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1936-1955},
url = {https://doi.org/10.1145/3648476},
doi = {10.1145/3648476},
abstract = {The existence of large amounts of data increases the probability of occurring data quality problems. A data cleaning process that corrects these problems is usually an iterative process, because it may need to be re-executed and refined to produce high-quality data. Moreover, due to the specificity of some data quality problems and the limitation of data cleaning programs to cover all problems, often a user has to be involved during the program executions by manually repairing data. However, there is no data cleaning framework that appropriately supports this involvement in such an iterative process, a form of human-in-the-loop, to clean structured data. Moreover, data preparation tools that somehow involve the user in data cleaning processes have not been evaluated with real users to assess their effort.Therefore, we propose Cleenex, a data cleaning framework with support for user involvement during an iterative data cleaning process, and conduct two data cleaning experimental evaluations: an assessment of the Cleenex components that support the user when manually repairing data with a simulated user; and a comparison, in terms of user involvement, of data preparation tools with real users.Results show that Cleenex components reduce the user effort when manually cleaning data during a data cleaning process, for example, the number of tuples visualized is reduced in 99%. Moreover, when performing data cleaning tasks with Cleenex, real users need less time/effort (e.g., half the clicks) and, based on questionnaires, prefer it to the other tools used for comparison, OpenRefine and Pentaho Data Integration.},
journal = {J. Data and Information Quality},
month = {mar},
articleno = {6},
numpages = {26},
keywords = {Data quality, data curation, user involvement, human-in-the-loop}
}

",https://doi.org/10.1145/3648476,10.1145/3648476,acm,2024
801,Enabling Untrained Users to Shape Real-World Robot Behavior Using an Intuitive Visual Programming Tool in Human-Robot Interaction Scenarios,"@inproceedings{10.1145/3648536.3648541,
author = {Weike, Michel and Ruske, Kai and Gerndt, Reinhard and Doernbach, Tobias},
title = {Enabling Untrained Users to Shape Real-World Robot Behavior Using an Intuitive Visual Programming Tool in Human-Robot Interaction Scenarios},
year = {2024},
isbn = {9798400716614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648536.3648541},
doi = {10.1145/3648536.3648541},
abstract = {For untrained users, programming a robot that interacts with humans in a real-world scenario is challenging to impossible. However, in order to make interactive robots available in a wide range of domains and connect them with other smart devices, it must be possible to change their behavior in a simple and intuitive way. We present a visual programming tool that builds on top of the open-source Node-RED software and enables users to quickly and easily connect robots with Internet of Things (IoT) devices in order to build scenarios that include human interaction. The tool, called Node-(RED)² (Node-RED-based Robotics Empowerment Designer) is available online and currently supports the humanoid robot Pepper, but is extendable to other robots with very little effort. We demonstrate two real-world use cases of our tool that include Pepper and IoT devices and evaluate the utility of Node-(RED)² via a user study.},
booktitle = {Proceedings of the 2024 International Symposium on Technological Advances in Human-Robot Interaction},
pages = {38–46},
numpages = {9},
keywords = {Human-Robot Interaction, Real-World Robotics, Robot Behavior Planning, Visual Programming},
location = {Boulder, CO, USA},
series = {TAHRI '24}
}

",https://doi.org/10.1145/3648536.3648541,10.1145/3648536.3648541,acm,2024
802,Pairing Human and Artificial Intelligence: Enforcing Access Control Policies with LLMs and Formal Specifications,"@inproceedings{10.1145/3649158.3657032,
author = {Rubio-Medrano, Carlos E. and Kotak, Akash and Wang, Wenlu and Sohr, Karsten},
title = {Pairing Human and Artificial Intelligence: Enforcing Access Control Policies with LLMs and Formal Specifications},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649158.3657032},
doi = {10.1145/3649158.3657032},
abstract = {Large Language Models (LLMs), such as ChatGPT and Google Bard, have performed interestingly well when assisting developers on computer programming tasks, a.k.a., coding, thus potentially resulting in convenient and faster software constructions. This new approach significantly enhances efficiency but also presents challenges in unsupervised code construction with limited security guarantees. LLMs excel in producing code with accurate grammar, yet they are not specifically trained to guarantee the security of the code. In this paper, we provide an initial exploration into using formal software specifications as a starting point for software construction, allowing developers to translate descriptions of security-related behavior into natural language instructions for LLMs, a.k.a., prompts. In addition, we leveraged automated verification tools to evaluate the code produced against the aforementioned specifications , following a modular, step-by-step software construction process. For our study, we leveraged Role-based Access Control (RBAC), a mature security model, and the Java Modeling Language (JML), a behavioral specification language for Java. We test our approach on different publicly-available LLMs, namely, OpenAI ChatGPT 4.0, Google Bard, and Microsoft CoPilot. We provide a description of two applications-a security-sensitive Banking application employing RBAC and an RBAC API module itself-, the corresponding JML specifications, as well as a description of the prompts, the generated code, the verification results, as well as a series of interesting insights for practitioners interested in further exploring the use of LLMs for securely constructing applications.},
booktitle = {Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
pages = {105–116},
numpages = {12},
keywords = {chatgpt, formal specifications, large language models, prompt engineering, software construction. java modeling language},
location = {San Antonio, TX, USA},
series = {SACMAT 2024}
}

",https://doi.org/10.1145/3649158.3657032,10.1145/3649158.3657032,acm,2024
803,"Automating Personalized Parsons Problems with Customized Contexts and
  Concepts","<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10.1145/3649217.3653568</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10.1145/3649217.3653568"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",http://arxiv.org/pdf/2404.10990v1.pdf,10.1145/3649217.3653568,arxiv,2024
804,"Desirable Characteristics for AI Teaching Assistants in Programming
  Education","<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10.1145/3649217.3653574</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10.1145/3649217.3653574"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",http://arxiv.org/pdf/2405.14178v1.pdf,10.1145/3649217.3653574,arxiv,2024
805,In-Page Navigation Aids for Screen-Reader Users with Automatic Topicalisation and Labelling,"@article{10.1145/3649223,
author = {Silva, Jorge Sassaki Resende and Cardoso, Paula Christina Figueira and de Bettio, Raphael Winckler and Tavares, Daniela Cardoso and Silva, Carlos Alberto and Watanabe, Willian Massami and Freire, Andr\'{e} Pimenta},
title = {In-Page Navigation Aids for Screen-Reader Users with Automatic Topicalisation and Labelling},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1936-7228},
url = {https://doi.org/10.1145/3649223},
doi = {10.1145/3649223},
abstract = {Navigation aids such as headers and internal links provide vital support for screen-reader users on web documents to grasp a document’s structure. However, when such navigation aids are unavailable or not appropriately marked up, this situation can cause serious difficulties. This paper presents the design and evaluation of a tool for automatically generating navigation aids with headers and internal links for screen readers with topicalisation and labelling algorithms. The proposed tool uses natural language processing techniques to divide a web document into topic segments and label each segment in two cycles based on its content. We conducted an initial user study in the first cycle with eight blind and partially-sighted screen reader users. The evaluation involved tasks with questions answered by participants with information from texts with and without automatically generated headers. The results in the first cycle provided preliminary indicators of performance improvement and cognitive load reduction. The second cycle involved co-designing an improved version with two blind experts in web accessibility, resulting in a browser extension which injects automatically generated headers and in-page navigation with internal links, along with improvements in the generation of labels using OpenAI’s ChatGPT. The browser extension was evaluated by seven blind participants using the same four texts used to evaluate the preliminary prototype developed in the first cycle. With the two development cycles, the study provided important insights into the design of navigation aids for screen-reader users using natural language processing techniques, including the potential use of generative artificial intelligence for assistive technologies and limitations that need to be explored in future research.},
note = {Just Accepted},
journal = {ACM Trans. Access. Comput.},
month = {feb},
keywords = {Accessibility, natural language processing, screen readers, topic segmentation and labelling, large language models, assistive technologies}
}

",https://doi.org/10.1145/3649223,10.1145/3649223,acm,2024
806,Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web?,"@article{10.1145/3649468,
author = {Shah, Chirag and Bender, Emily M.},
title = {Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web?},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1559-1131},
url = {https://doi.org/10.1145/3649468},
doi = {10.1145/3649468},
abstract = {We observe a recent trend toward applying large language models (LLMs) in search and positioning them as effective information access systems. While the interfaces may look appealing and the apparent breadth of applicability is exciting, we are concerned that the field is rushing ahead with a technology without sufficient study of the uses it is meant to serve, how it would be used, and what its use would mean. We argue that it is important to reassert the central research focus of the field of information retrieval, because information access is not merely an application to be solved by the so-called ‘AI’ techniques du jour. Rather, it is a key human activity, with impacts on both individuals and society. As information scientists, we should be asking what do people and society want and need from information access systems and how do we design and build systems to meet those needs? With that goal, in this conceptual article we investigate fundamental questions concerning information access from user and societal viewpoints. We revisit foundational work related to information behavior, information seeking, information retrieval, information filtering, and information access to resurface what we know about these fundamental questions and what may be missing. We then provide our conceptual framing about how we could fill this gap, focusing on methods as well as experimental and evaluation frameworks. We consider the Web as an information ecosystem and explore the ways in which synthetic media, produced by LLMs and otherwise, endangers that ecosystem. The primary goal of this conceptual article is to shed light on what we still do not know about the potential impacts of LLM-based information access systems, how to advance our understanding of user behaviors, and where the next generations of students, scholars, and developers could fruitfully invest their energies.},
journal = {ACM Trans. Web},
month = {apr},
articleno = {33},
numpages = {24},
keywords = {Information access systems, large language models, information ecosystem}
}

",https://doi.org/10.1145/3649468,10.1145/3649468,acm,2024
807,CYCLE: Learning to Self-Refine the Code Generation,"@article{10.1145/3649825,
author = {Ding, Yangruibo and Min, Marcus J. and Kaiser, Gail and Ray, Baishakhi},
title = {CYCLE: Learning to Self-Refine the Code Generation},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649825},
doi = {10.1145/3649825},
abstract = {Pre-trained code language models have achieved promising performance in code generation and improved the programming efficiency of human developers. However, their self-refinement capability is typically overlooked by the existing evaluations of code LMs, which focus only on the accuracy of the one-time prediction. For the cases when code LMs fail to implement the correct program, developers actually find it hard to debug and fix the faulty prediction since it is not written by the developers themselves. Unfortunately, our study reveals that code LMs cannot efficiently self-refine their faulty generations as well. In this paper, we propose CYCLE framework, learning to self-refine the faulty generation according to the available feedback, such as the execution results reported by the test suites. We evaluate CYCLE on three popular code generation benchmarks, HumanEval, MBPP, and APPS. The results reveal that CYCLE successfully maintains, sometimes improves, the quality of one-time code generation, while significantly improving the self-refinement capability of code LMs. We implement four variants of CYCLE with varied numbers of parameters across 350M, 1B, 2B, and 3B, and the experiments show that CYCLE consistently boosts the code generation performance, by up to 63.5},
journal = {Proc. ACM Program. Lang.},
month = {apr},
articleno = {108},
numpages = {27},
keywords = {Code Generation, Code Language Models, Iterative Programming, Source Code Modeling}
}

",https://doi.org/10.1145/3649825,10.1145/3649825,acm,2024
808,Enhancing Static Analysis for Practical Bug Detection: An LLM-Integrated Approach,"@article{10.1145/3649828,
author = {Li, Haonan and Hao, Yu and Zhai, Yizhuo and Qian, Zhiyun},
title = {Enhancing Static Analysis for Practical Bug Detection: An LLM-Integrated Approach},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649828},
doi = {10.1145/3649828},
abstract = {While static analysis is instrumental in uncovering software bugs, its precision in analyzing large and intricate codebases remains challenging. The emerging prowess of Large Language Models (LLMs) offers a promising avenue to address these complexities. In this paper, we present LLift, a pioneering framework that synergizes static analysis and LLMs, with a spotlight on identifying use-before-initialization (UBI) bugs within the Linux kernel. Drawing from our insights into variable usage conventions in Linux, we enhance path analysis using post-constraint guidance. This approach, combined with our methodically crafted procedures, empowers LLift to adeptly handle the challenges of bug-specific modeling, extensive codebases, and the unpredictable nature of LLMs. Our real-world evaluations identified four previously undiscovered UBI bugs in the mainstream Linux kernel, which the Linux community has acknowledged. This study reaffirms the potential of marrying static analysis with LLMs, setting a compelling direction for future research in this area.},
journal = {Proc. ACM Program. Lang.},
month = {apr},
articleno = {111},
numpages = {26},
keywords = {Static analysis, bug detection, large language model}
}

",https://doi.org/10.1145/3649828,10.1145/3649828,acm,2024
809,PyDex: Repairing Bugs in Introductory Python Assignments using LLMs,"@article{10.1145/3649850,
author = {Zhang, Jialu and Cambronero, Jos\'{e} Pablo and Gulwani, Sumit and Le, Vu and Piskac, Ruzica and Soares, Gustavo and Verbruggen, Gust},
title = {PyDex: Repairing Bugs in Introductory Python Assignments using LLMs},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649850},
doi = {10.1145/3649850},
abstract = {Students often make mistakes in their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex (a version of GPT), to build an APR system -- PyDex -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate PyDex on 286 real student programs and compare to three baselines, including one that combines a state-of-the-art Python syntax repair engine, BIFI, and a state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that PyDex can fix more programs and produce smaller patches on average.},
journal = {Proc. ACM Program. Lang.},
month = {apr},
articleno = {133},
numpages = {25},
keywords = {AI for programming education, automated program repair, large language models}
}

",https://doi.org/10.1145/3649850,10.1145/3649850,"acm, web_of_science, scopus",2024
810,"Characterizing Learners' Complex Attentional States During Online Multimedia Learning Using Eye-tracking, Egocentric Camera, Webcam, and Retrospective recalls","@inproceedings{10.1145/3649902.3653939,
author = {Chandran, Prasanth and Huang, Yifeng and Munsell, Jeremy and Howatt, Brian and Wallace, Brayden and Wilson, Lindsey and D'Mello, Sidney and Hoai, Minh and Rebello, N. Sanjay and Loschky, Lester C},
title = {Characterizing Learners' Complex Attentional States During Online Multimedia Learning Using Eye-tracking, Egocentric Camera, Webcam, and Retrospective recalls},
year = {2024},
isbn = {9798400706073},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649902.3653939},
doi = {10.1145/3649902.3653939},
abstract = {As online learning becomes increasingly ubiquitous, a key challenge is maintaining learners’ sustained attention. Using eye-tracking, together with observing and interviewing learners, we can characterize both 1) whether they are looking at their learning materials, and 2) whether they are thinking about them. Critically, eye-tracking only speaks to the first distinction, not the second. To overcome this limitation, we supplemented eye-tracking with an egocentric camera, a webcam, a retrospective recall, and mind-wandering probes to capture a 2x2 matrix of attentional/cognitive states. We then categorized N=101 learners’ attentional/cognitive states while they completed a multimedia physics module. This meets two goals: 1) allowing basic research to understand the relationship between attentional/cognitive states and behavioral outcomes; and 2) facilitating applied research by generating rich ground truth for future use in training machine learning to categorize this 2x2 set of attentional states, for which eye-tracking is necessary, but not sufficient.},
booktitle = {Proceedings of the 2024 Symposium on Eye Tracking Research and Applications},
articleno = {68},
numpages = {7},
keywords = {Attentional States, Eye-tracking, Multimodal data, Online learning},
location = {Glasgow, United Kingdom},
series = {ETRA '24}
}

",https://doi.org/10.1145/3649902.3653939,10.1145/3649902.3653939,acm,2024
811,Reality Bites: Assessing the Realism of Driving Scenarios with Large Language Models,"@inproceedings{10.1145/3650105.3652296,
author = {Wu, Jiahui and Lu, Chengjie and Arrieta, Aitor and Yue, Tao and Ali, Shaukat},
title = {Reality Bites: Assessing the Realism of Driving Scenarios with Large Language Models},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652296},
doi = {10.1145/3650105.3652296},
abstract = {Large Language Models (LLMs) are demonstrating outstanding potential for tasks such as text generation, summarization, and classification. Given that such models are trained on a humongous amount of online knowledge, we hypothesize that LLMs can assess whether driving scenarios generated by autonomous driving testing techniques are realistic, i.e., being aligned with real-world driving conditions. To test this hypothesis, we conducted an empirical evaluation to assess whether LLMs are effective and robust in performing the task. This reality check is an important step towards devising LLM-based autonomous driving testing techniques. For our empirical evaluation, we selected 64 realistic scenarios from DeepScenario-an open driving scenario dataset. Next, by introducing minor changes to them, we created 512 additional realistic scenarios, to form an overall dataset of 576 scenarios. With this dataset, we evaluated three LLMs (GPT-3.5, Llama2-13B, and Mistral-7B) to assess their robustness in assessing the realism of driving scenarios. Our results show that: (1) Overall, GPT-3.5 achieved the highest robustness compared to Llama2-13B and Mistral-7B, consistently throughout almost all scenarios, roads, and weather conditions; (2) Mistral-7B performed the worst consistently; (3) Llama2-13B achieved good results under certain conditions; and (4) roads and weather conditions do influence the robustness of the LLMs.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {40–51},
numpages = {12},
keywords = {large language models, realistic driving scenarios, robustness},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

",https://doi.org/10.1145/3650105.3652296,10.1145/3650105.3652296,acm,2024
812,"Gamify: Gamification in Software Development, Verification,and Validation","@article{10.1145/3650142.3650151,
author = {Coppola, Riccardo and Ardito, Luca and Leotta, Maurizio},
title = {Gamify: Gamification in Software Development, Verification,and Validation},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/3650142.3650151},
doi = {10.1145/3650142.3650151},
abstract = {In this paper we report the outcomes of the 1st and 2nd edition of the International Workshop on Gamification in Software Development, Verification, and Validation (Gamify 2022 and Gamify 2023) which were held as part of the 30th and 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2022, in Singapore, November 17, 2022 and ESEC/FSE 2023, online workshop, December 4, 2023).},
journal = {SIGSOFT Softw. Eng. Notes},
month = {apr},
pages = {27–30},
numpages = {4}
}

",https://doi.org/10.1145/3650142.3650151,10.1145/3650142.3650151,acm,2024
813,Multization: Multi-Modal Summarization Enhanced by Multi-Contextually Relevant and Irrelevant Attention Alignment,"@article{10.1145/3651983,
author = {Rong, Huan and Chen, Zhongfeng and Lu, Zhenyu and Xu, Fan and Sheng, Victor S},
title = {Multization: Multi-Modal Summarization Enhanced by Multi-Contextually Relevant and Irrelevant Attention Alignment},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {5},
issn = {2375-4699},
url = {https://doi.org/10.1145/3651983},
doi = {10.1145/3651983},
abstract = {This article focuses on the task of Multi-Modal Summarization with Multi-Modal Output for China JD.COM e-commerce product description containing both source text and source images. In the context learning of multi-modal (text and image) input, there exists a semantic gap between text and image, especially in the cross-modal semantics of text and image. As a result, capturing shared cross-modal semantics earlier becomes crucial for multi-modal summarization. However, when generating the multi-modal summarization, based on the different contributions of input text and images, the relevance and irrelevance of multi-modal contexts to the target summary should be considered, so as to optimize the process of learning cross-modal context to guide the summary generation process and to emphasize the significant semantics within each modality. To address the aforementioned challenges, Multization has been proposed to enhance multi-modal semantic information by multi-contextually relevant and irrelevant attention alignment. Specifically, a Semantic Alignment Enhancement mechanism is employed to capture shared semantics between different modalities (text and image), so as to enhance the importance of crucial multi-modal information in the encoding stage. Additionally, the IR-Relevant Multi-Context Learning mechanism is utilized to observe the summary generation process from both relevant and irrelevant perspectives, so as to form a multi-modal context that incorporates both text and image semantic information. The experimental results in the China JD.COM e-commerce dataset demonstrate that the proposed Multization method effectively captures the shared semantics between the input source text and source images, and highlights essential semantics. It also successfully generates the multi-modal summary (including image and text) that comprehensively considers the semantics information of both text and image.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {may},
articleno = {69},
numpages = {29},
keywords = {Business intelligence, multi-modal summarization, semantic enhancement and attention, multi-modal cross learning}
}

",https://doi.org/10.1145/3651983,10.1145/3651983,acm,2024
814,Generative AI in Psychological Therapy: Perspectives on Computational Linguistics and Large Language Models in Written Behaviour Monitoring,"@inproceedings{10.1145/3652037.3663893,
author = {Bird, Jordan J. and Wright, David and Sumich, Alexander and Lotfi, Ahmad},
title = {Generative AI in Psychological Therapy: Perspectives on Computational Linguistics and Large Language Models in Written Behaviour Monitoring},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3663893},
doi = {10.1145/3652037.3663893},
abstract = {Technological intervention to support care areas that some people may not have access to is of paramount importance to promote sustainable development of good health and wellbeing. This study aims to explore the linguistic similarities and differences between human professionals and Generative Artificial Intelligence (AI) conversational agents in therapeutic dialogues. Initially, the MISTRAL-7B Large Language Model (LLM) is instructed to generate responses to patient queries to form a synthetic equivalent to a publicly available psychology dataset. A large set of linguistic features (e.g., text metrics, lexical diversity and richness, readability scores, sentiment, emotions, and named entities) is extracted and studied from both the expert and synthetically-generated text. The results suggest a significantly richer vocabulary in humans than the LLM approach. Similarly, the use of sentiment was significantly different between the two, suggesting a difference in the supportive or objective language used and that synthetic linguistic expressions of emotion may differ from those expressed by an intelligent being. However, no statistical significance was observed between human professionals and AI in the use of function words, pronouns and several named entities; possibly reflecting an increased proficiency of LLMs in modelling some language patterns, even in a specialised context (i.e., therapy). However, current findings do not support the similarity in sentimental nuance and emotional expression, which limits the effectiveness of contemporary LLMs as standalone agents. Further development is needed towards clinically validated algorithms.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {322–328},
numpages = {7},
keywords = {AI, Computational Linguistics, Generative Artificial Intelligence, LLMs, Large Language Models, Psychology},
location = {Crete, Greece},
series = {PETRA '24}
}

",https://doi.org/10.1145/3652037.3663893,10.1145/3652037.3663893,acm,2024
815,Navigating the Complexity of Generative AI Adoption in Software Engineering,"@article{10.1145/3652154,
author = {Russo, Daniel},
title = {Navigating the Complexity of Generative AI Adoption in Software Engineering},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3652154},
doi = {10.1145/3652154},
abstract = {This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {135},
numpages = {50},
keywords = {Generative AI, large language models, technology adaption, empirical software engineering}
}

",https://doi.org/10.1145/3652154,10.1145/3652154,acm,2024
816,From Prompt Engineering to Collaborating: A Human-Centered Approach to AI Interfaces,"@article{10.1145/3652622,
author = {Kraljic, Tanya and Lahav, Michal},
title = {From Prompt Engineering to Collaborating: A Human-Centered Approach to AI Interfaces},
year = {2024},
issue_date = {May - June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1072-5520},
url = {https://doi.org/10.1145/3652622},
doi = {10.1145/3652622},
journal = {Interactions},
month = {may},
pages = {30–35},
numpages = {6}
}

",https://doi.org/10.1145/3652622,10.1145/3652622,acm,2024
817,A Survey on Trustworthy Recommender Systems,"@article{10.1145/3652891,
author = {Ge, Yingqiang and Liu, Shuchang and Fu, Zuohui and Tan, Juntao and Li, Zelong and Xu, Shuyuan and Li, Yunqi and Xian, Yikun and Zhang, Yongfeng},
title = {A Survey on Trustworthy Recommender Systems},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652891},
doi = {10.1145/3652891},
abstract = {Recommender systems (RS), serving at the forefront of Human-centered AI, are widely deployed in almost every corner of the web and facilitate the human decision-making process. However, despite their enormous capabilities and potential, RS may also lead to undesired effects on users, items, producers, platforms, or even the society at large, such as compromised user trust due to non-transparency, unfair treatment of different consumers, or producers, privacy concerns due to extensive use of user’s private data for personalization, just to name a few. All of these create an urgent need for Trustworthy Recommender Systems (TRS) so as to mitigate or avoid such adverse impacts and risks. In this survey, we will introduce techniques related to trustworthy recommendation, including but not limited to explainable recommendation, fairness in recommendation, privacy-aware recommendation, robustness in recommendation, user-controllable recommendation, as well as the relationship between these different perspectives in terms of trustworthy recommendation. Through this survey, we hope to deliver readers with a comprehensive view of the research area and raise attention to the community about the importance, existing research achievements, and future research directions on trustworthy recommendation.},
note = {Just Accepted},
journal = {ACM Trans. Recomm. Syst.},
month = {apr}
}

",https://doi.org/10.1145/3652891,10.1145/3652891,acm,2024
818,FastPerson: Enhancing Video-Based Learning through Video Summarization that Preserves Linguistic and Visual Contexts,"@inproceedings{10.1145/3652920.3652922,
author = {Kawamura, Kazuki and Rekimoto, Jun},
title = {FastPerson: Enhancing Video-Based Learning through Video Summarization that Preserves Linguistic and Visual Contexts},
year = {2024},
isbn = {9798400709807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652920.3652922},
doi = {10.1145/3652920.3652922},
abstract = {Quickly understanding lengthy lecture videos is essential for learners with limited time and interest in various topics to improve their learning efficiency. To this end, video summarization has been actively researched to enable users to view only important scenes from a video. However, these studies focus on either the visual or audio information of a video and extract important segments in the video. Therefore, there is a risk of missing important information when both the teacher’s speech and visual information on the blackboard or slides are important, such as in a lecture video. To tackle this issue, we propose FastPerson, a video summarization approach that considers both the visual and auditory information in lecture videos. FastPerson creates summary videos by utilizing audio transcriptions along with on-screen images and text, minimizing the risk of overlooking crucial information for learners. Further, it provides a feature that allows learners to switch between the summary and original videos for each chapter of the video, enabling them to adjust the pace of learning based on their interests and level of understanding. We conducted an evaluation with 40 participants to assess the effectiveness of our method and confirmed that it reduced viewing time by 53% at the same level of comprehension as that when using traditional video playback methods.},
booktitle = {Proceedings of the Augmented Humans International Conference 2024},
pages = {205–216},
numpages = {12},
keywords = {Video summarization, e-learning, human–computer interaction, large language model, learning efficiency, multimodal information processing, speech synthesis, user-centered design},
location = {Melbourne, VIC, Australia},
series = {AHs '24}
}

",https://doi.org/10.1145/3652920.3652922,10.1145/3652920.3652922,acm,2024
819,Kavy: Fostering Language Speaking Skills and Self-Confidence Through Conversational AI,"@inproceedings{10.1145/3652920.3652944,
author = {Cooray, Sankha and Hettiarachchi, Chathuranga and Nanayakkara, Vishaka and Matthies, Denys and Samaradivakara, Yasith and Nanayakkara, Suranga},
title = {Kavy: Fostering Language Speaking Skills and Self-Confidence Through Conversational AI},
year = {2024},
isbn = {9798400709807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652920.3652944},
doi = {10.1145/3652920.3652944},
abstract = {Cognitive augmentation is the process of enhancing one’s abilities, including learning a new language. For this, we could utilize conversational chatbots. Conventional chatbots such as Siri, have predominantly been based on the question-and-answer model, where a communicator seeks a specific answer to accomplish a specific task. The conversational capabilities of chatbots offer great potential to promote English language learning, particularly in developing countries, such as Sri Lanka, where many young adults lack confidence in speaking English. This is due to limited exposure to conversational-style learning and a lack of opportunity to practice without social anxiety which is often rooted in the fear of making mistakes. In this paper, we developed a conversational chatbot, Kavy, as a companion to help them practice English. We investigated, in a study with 40 users, if Kavy could improve a communicator’s proficiency (e.g., verbal expression, conversation length, quality of speech) and self-confidence using both poetic and non-poetic conversational styles. We found that the users were highly motivated by the poetic version, with its use resulting in a significant increase in vocabulary. Nevertheless, a poetic chatbot may present challenges, with several users reporting that they find the poetic version confusing. We see this pioneering work as a first and promising approach that should be continued to be investigated in the future.},
booktitle = {Proceedings of the Augmented Humans International Conference 2024},
pages = {226–236},
numpages = {11},
keywords = {Artificial Intelligence, Cognitive Augmentation, Conversational AI Agents, Language Studies, Poetry, Self Confidence, Social chatbots, Voice Interfaces},
location = {Melbourne, VIC, Australia},
series = {AHs '24}
}

",https://doi.org/10.1145/3652920.3652944,10.1145/3652920.3652944,acm,2024
820,On the Opportunities and Challenges of Foundation Models for GeoAI (Vision Paper),"@article{10.1145/3653070,
author = {Mai, Gengchen and Huang, Weiming and Sun, Jin and Song, Suhang and Mishra, Deepak and Liu, Ninghao and Gao, Song and Liu, Tianming and Cong, Gao and Hu, Yingjie and Cundy, Chris and Li, Ziyuan and Zhu, Rui and Lao, Ni},
title = {On the Opportunities and Challenges of Foundation Models for GeoAI (Vision Paper)},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {2374-0353},
url = {https://doi.org/10.1145/3653070},
doi = {10.1145/3653070},
abstract = {Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have not yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial domains, including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality, such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, the task-agnostic large learning models (LLMs) can outperform task-specific fully supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image–based urban noise intensity classification, and remote sensing image scene classification), existing FMs still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing an FM for GeoAI is to address the multimodal nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal FM that can reason over various types of geospatial data through geospatial alignments. We conclude this article by discussing the unique risks and challenges to developing such a model for GeoAI.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = {jul},
articleno = {11},
numpages = {46},
keywords = {Foundation models, geospatial artificial intelligence, multimodal learning}
}

",https://doi.org/10.1145/3653070,10.1145/3653070,acm,2024
821,,"@inproceedings{10.1145/3653666.3656065,
author = {Smith, Julie M.},
title = {""I'm Sorry, but I Can't Assist"": Bias in Generative AI},
year = {2024},
isbn = {9798400706264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653666.3656065},
doi = {10.1145/3653666.3656065},
abstract = {Research Questions: (1) Is there a pattern of racial bias in student advising recommendations made by generative AI? (2) What safeguards can promote equity when using generative AI in high-stakes decision-making? Methodology: Using lists of names associated with various ethnic/racial groups, we asked ChatGPT and Claude AI for recommendations for colleges and majors for each student. Results: ChatGPT was more likely to recommend STEM majors to some student groups. ChatGPT did not show systematic bias in various metrics of school quality, but Claude AI did. There were also overall differences in the colleges recommended by Claude AI and ChatGPT. Implications: We provide cautions and recommendations for using generative AI in high-stakes tasks.},
booktitle = {Proceedings of the 2024 on RESPECT Annual Conference},
pages = {75–80},
numpages = {6},
keywords = {artificial intelligence, generative ai, large language models, quity, racism, student advising},
location = {Atlanta, GA, USA},
series = {RESPECT 2024}
}

",https://doi.org/10.1145/3653666.3656065,10.1145/3653666.3656065,acm,2024
822,Beyond AI Hype: A Hands-on Workshop Series for Enhancing AI Literacy in Middle and High School Students,"@inproceedings{10.1145/3653666.3656075,
author = {Okolo, Chinasa T.},
title = {Beyond AI Hype: A Hands-on Workshop Series for Enhancing AI Literacy in Middle and High School Students},
year = {2024},
isbn = {9798400706264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653666.3656075},
doi = {10.1145/3653666.3656075},
abstract = {The increasing usage of AI in high-stakes decision-making underscores a pressing need for various stakeholders to understand AI, learn how to identify AI-generated content, and become aware of its societal risks. We detail outcomes from engaging underrepresented secondary school students in a 5-day workshop series consisting of brief lectures, hands-on activities, and short research assignments. We find that the workshop improved students' knowledge about AI and the ethical implications of using these technologies. Our work highlights policy implications and outlines actionable efforts needed to advance AI literacy, with the workshop content being developed into an open-source AI literacy curriculum.},
booktitle = {Proceedings of the 2024 on RESPECT Annual Conference},
pages = {86–93},
numpages = {8},
keywords = {ai literacy, ai pedagogy, computing education, equity, generative ai, human-centered ai, technology ethics},
location = {Atlanta, GA, USA},
series = {RESPECT 2024}
}

",https://doi.org/10.1145/3653666.3656075,10.1145/3653666.3656075,acm,2024
823,MTL-TRANSFER: Leveraging Multi-task Learning and Transferred Knowledge for Improving Fault Localization and Program Repair,"@article{10.1145/3654441,
author = {Wang, Xu and Yu, Hongwei and Meng, Xiangxin and Cao, Hongliang and Zhang, Hongyu and Sun, Hailong and Liu, Xudong and Hu, Chunming},
title = {MTL-TRANSFER: Leveraging Multi-task Learning and Transferred Knowledge for Improving Fault Localization and Program Repair},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3654441},
doi = {10.1145/3654441},
abstract = {Fault localization (FL) and automated program repair (APR) are two main tasks of automatic software debugging. Compared with traditional methods, deep learning-based approaches have been demonstrated to achieve better performance in FL and APR tasks. However, the existing deep learning-based FL methods ignore the deep semantic features or only consider simple code representations. And for APR tasks, existing template-based APR methods are weak in selecting the correct fix templates for more effective program repair, which are also not able to synthesize patches via the embedded end-to-end code modification knowledge obtained by training models on large-scale bug-fix code pairs. Moreover, in most of FL and APR methods, the model designs and training phases are performed separately, leading to ineffective sharing of updated parameters and extracted knowledge during the training process. This limitation hinders the further improvement in the performance of FL and APR tasks. To solve the above problems, we propose a novel approach called MTL-TRANSFER, which leverages a multi-task learning strategy to extract deep semantic features and transferred knowledge from different perspectives. First, we construct a large-scale open-source bug datasets and implement 11 multi-task learning models for bug detection and patch generation sub-tasks on 11 commonly used bug types, as well as one multi-classifier to learn the relevant semantics for the subsequent fix template selection task. Second, an MLP-based ranking model is leveraged to fuse spectrum-based, mutation-based and semantic-based features to generate a sorted list of suspicious statements. Third, we combine the patches generated by the neural patch generation sub-task from the multi-task learning strategy with the optimized fix template selecting order gained from the multi-classifier mentioned above. Finally, the more accurate FL results, the optimized fix template selecting order, and the expanded patch candidates are combined together to further enhance the overall performance of APR tasks. Our extensive experiments on widely-used benchmark Defects4J show that MTL-TRANSFER outperforms all baselines in FL and APR tasks, proving the effectiveness of our approach. Compared with our previously proposed FL method TRANSFER-FL (which is also the state-of-the-art statement-level FL method), MTL-TRANSFER increases the faults hit by 8/11/12 on Top-1/3/5 metrics (92/159/183 in total). And on APR tasks, the number of successfully repaired bugs of MTL-TRANSFER under the perfect localization setting reaches 75, which is 8 more than our previous APR method TRANSFER-PR. Furthermore, another experiment to simulate the actual repair scenarios shows that MTL-TRANSFER can successfully repair 15 and 9 more bugs (56 in total) compared with TBar and TRANSFER, which demonstrates the effectiveness of the combination of our optimized FL and APR components.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {148},
numpages = {31},
keywords = {Fault localization, automated program repair, deep neural networks, transfer learning, multi-task learning, neural machine translation}
}

",https://doi.org/10.1145/3654441,10.1145/3654441,acm,2024
824,SchemaPile: A Large Collection of Relational Database Schemas,"@article{10.1145/3654975,
author = {D\""{o}hmen, Till and Geacu, Radu and Hulsebos, Madelon and Schelter, Sebastian},
title = {SchemaPile: A Large Collection of Relational Database Schemas},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654975},
doi = {10.1145/3654975},
abstract = {Access to fine-grained schema information is crucial for understanding how relational databases are designed and used in practice, and for building systems that help users interact with them. Furthermore, such information is required as training data to leverage the potential of large language models (LLMs) for improving data preparation, data integration and natural language querying. Existing single-table corpora such as GitTables provide insights into how tables are structured in-the-wild, but lack detailed schema information about how tables relate to each other, as well as metadata like data types or integrity constraints. On the other hand, existing multi-table (or database schema) datasets are rather small and attribute-poor, leaving it unclear to what extent they actually represent typical real-world database schemas.In order to address these challenges, we present SchemaPile, a corpus of 221,171 database schemas, extracted from SQL files on GitHub. It contains 1.7 million tables with 10 million column definitions, 700 thousand foreign key relationships, seven million integrity constraints, and data content for more than 340 thousand tables. We conduct an in-depth analysis on the millions of schema metadata properties in our corpus, as well as its highly diverse language and topic distribution. In addition, we showcase the potential of corpus to improve a variety of data management applications, e.g., fine-tuning LLMs for schema-only foreign key detection, improving CSV header detection and evaluating multi-dialect SQL parsers. We publish the code and data for recreating SchemaPile and a permissively licensed subset SchemaPile-Perm.},
journal = {Proc. ACM Manag. Data},
month = {may},
articleno = {172},
numpages = {25},
keywords = {csv parsing, dataset, foreign key detection, large language models, relational database schemas, sql parsing}
}

",https://doi.org/10.1145/3654975,10.1145/3654975,acm,2024
825,2025 EAAI Mentored Undergraduate Research Challenge: Playing Word Association Games,"@article{10.1145/3655032.3655035,
author = {Freedman, Richard G.},
title = {2025 EAAI Mentored Undergraduate Research Challenge: Playing Word Association Games},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
url = {https://doi.org/10.1145/3655032.3655035},
doi = {10.1145/3655032.3655035},
abstract = {The topic for EAAI 2025's Mentored Undergraduate Research Challenge is PlayingWord Association Games. What does that mean? Where are the applications? How can you get started? We break down the topic, discuss applications, and explore project ideas in this column.},
journal = {AI Matters},
month = {may},
pages = {16–25},
numpages = {10}
}

",https://doi.org/10.1145/3655032.3655035,10.1145/3655032.3655035,acm,2024
826,Book Review: Understanding Large Language Models: Learning Their Underlying Concepts and Technologies,"@article{10.1145/3655032.3655036,
author = {Rogers, David S.},
title = {Book Review: Understanding Large Language Models: Learning Their Underlying Concepts and Technologies},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
url = {https://doi.org/10.1145/3655032.3655036},
doi = {10.1145/3655032.3655036},
abstract = {Understanding Large Language Models: Learning Their Underlying Concepts and Technologies is written by Thimira Amaratunga and published by Apress, ©2023, paperback, ISBN-13 (pbk): 979-8-8688-0016-0, 156 pp., $44.99.},
journal = {AI Matters},
month = {may},
pages = {26–27},
numpages = {2}
}

",https://doi.org/10.1145/3655032.3655036,10.1145/3655032.3655036,acm,2024
827,Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention,"@inproceedings{10.1145/3655693.3655694,
author = {Prosser, Ellie and Edwards, Matthew},
title = {Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3655693.3655694},
doi = {10.1145/3655693.3655694},
abstract = {Powerful generative Large Language Models (LLMs) are becoming popular tools amongst the general public as question-answering systems, and are being utilised by vulnerable groups such as children. With children increasingly interacting with these tools, it is imperative for researchers to scrutinise the safety of LLMs, especially for applications that could lead to serious outcomes, such as online child safety queries. In this paper, the efficacy of LLMs for online grooming prevention is explored both for identifying and avoiding grooming through advice generation, and the impact of prompt design on model performance is investigated by varying the provided context and prompt specificity. In results reflecting over 6,000 LLM interactions, we find that no models were clearly appropriate for online grooming prevention, with an observed lack of consistency in behaviours, and potential for harmful answer generation, especially from open-source models. We outline where and how models fall short, providing suggestions for improvement, and identify prompt designs that heavily altered model performance in troubling ways, with findings that can be used to inform best practice usage guides.},
booktitle = {Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
pages = {1–10},
numpages = {10},
keywords = {advice generation, large language models, online child safety, online grooming detection, prompt design, prompt engineering},
location = {Xanthi, Greece},
series = {EICC '24}
}

",https://doi.org/10.1145/3655693.3655694,10.1145/3655693.3655694,acm,2024
828,Hacc-Man: An Arcade Game for Jailbreaking LLMs,"@inproceedings{10.1145/3656156.3665432,
author = {Valentim, Matheus and Falk, Jeanette and Inie, Nanna},
title = {Hacc-Man: An Arcade Game for Jailbreaking LLMs},
year = {2024},
isbn = {9798400706325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656156.3665432},
doi = {10.1145/3656156.3665432},
abstract = {The recent leaps in complexity and fluency of Large Language Models (LLMs) mean that, for the first time in human history, people can interact with computers using natural language alone. This creates monumental possibilities of automation and accessibility of computing, but also raises severe security and safety threats: When everyone can interact with LLMs, everyone can potentially break into the systems running LLMs. All it takes is creative use of language. This paper presents Hacc-Man, a game which challenges its players to “jailbreak” an LLM: subvert the LLM to output something that it is not intended to. Jailbreaking is at the intersection between creative problem solving and LLM security. The purpose of the game is threefold: 1. To heighten awareness of the risks of deploying fragile LLMs in everyday systems, 2. To heighten people’s self-efficacy in interacting with LLMs, and 3. To discover the creative problem solving strategies, people deploy in this novel context.},
booktitle = {Companion Publication of the 2024 ACM Designing Interactive Systems Conference},
pages = {338–341},
numpages = {4},
keywords = {LLM security, arcade games., creative problem solving, creativity, hacking, jailbreaking, red teaming},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24 Companion}
}

",https://doi.org/10.1145/3656156.3665432,10.1145/3656156.3665432,acm,2024
829,NetConfEval: Can LLMs Facilitate Network Configuration?,"@article{10.1145/3656296,
author = {Wang, Changjie and Scazzariello, Mariano and Farshin, Alireza and Ferlin, Simone and Kosti\'{c}, Dejan and Chiesa, Marco},
title = {NetConfEval: Can LLMs Facilitate Network Configuration?},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT2},
url = {https://doi.org/10.1145/3656296},
doi = {10.1145/3656296},
abstract = {This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices &amp; development of routing algorithms and minimizing errors. We design a set of benchmarks (NetConfEval) to examine the effectiveness of different models in facilitating and automating network configuration. More specifically, we focus on the scenarios where LLMs translate high-level policies, requirements, and descriptions (i.e., specified in natural language) into low-level network configurations &amp; Python code. NetConfEval considers four tasks that could potentially facilitate network configuration, such as (i) generating high-level requirements into a formal specification format, (ii) generating API/function calls from high-level requirements, (iii) developing routing algorithms based on high-level descriptions, and (iv) generating low-level configuration for existing and new protocols based on input documentation. Learning from the results of our study, we propose a set of principles to design LLM-based systems to configure networks. Finally, we present two GPT-4-based prototypes to (i) automatically configure P4-enabled devices from a set of high-level requirements and (ii) integrate LLMs into existing network synthesizers.},
journal = {Proc. ACM Netw.},
month = {jun},
articleno = {7},
numpages = {25},
keywords = {benchmark, code generation, function calling, large language models (llms), network configuration, network synthesizer, p4, rag, routing algorithms}
}

",https://doi.org/10.1145/3656296,10.1145/3656296,acm,2024
830,Exploring the Profile of University Assessments Flagged as Containing AI-Generated Material,"@article{10.1145/3656478,
author = {Gooch, Daniel and Waugh, Kevin and Richards, Mike and Slaymaker, Mark and Woodthorpe, John},
title = {Exploring the Profile of University Assessments Flagged as Containing AI-Generated Material},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2153-2184},
url = {https://doi.org/10.1145/3656478},
doi = {10.1145/3656478},
journal = {ACM Inroads},
month = {may},
pages = {39–47},
numpages = {9}
}

",https://doi.org/10.1145/3656478,10.1145/3656478,acm,2024
831,"Playwriting with Large Language Models: Perceived Features, Interaction Strategies and Outcomes","@inproceedings{10.1145/3656650.3656688,
author = {Grigis, Paolo and De Angeli, Antonella},
title = {Playwriting with Large Language Models: Perceived Features, Interaction Strategies and Outcomes},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656688},
doi = {10.1145/3656650.3656688},
abstract = {Large Language Models (LLMs) are sparking debates about creativity, intellectual property, and artistic integrity. This paper focuses on creativity, defined as consensual agreement among domain experts. It presents an inductive analysis of seven semi-structured interviews with professional playwrights who engaged in a longitudinal project with the aim of writing a theatre script using commercial systems. Overall, participants regarded LLMs as unsuitable for playwrighting. However, they enjoyed the experience and identified utility for editorial tasks and brainstorming. A significant obstacle was associated with the politics embedded in LLMs. Not only did these systems avoid a language that could offend sensibilities, but they also refused to engage in taboos and conflicts, which are the core of dramaturgy. Other system features (speed, exploitation, and unpredictability) were sometimes considered conducive and sometimes detrimental to creativity. Participants experienced difficulties and tried to build common ground by trial and error. Often, this strategy evolved into role play: the playwright instructed the LLM to enact characters. The interaction provided hints of inspiration and fostered suspension of disbelief and ontological reflection. However, it often led to technology rejection. Comparing and contrasting our insights with related work, we conclude by opening new directions for research at the boundaries of HCI and AI.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {38},
numpages = {9},
keywords = {Creative AI, Creativity, Roleplay, Suspension of Disbelief, Theatre, Unpredictability},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

",https://doi.org/10.1145/3656650.3656688,10.1145/3656650.3656688,acm,2024
832,Development of the AI Implementation Framework in Taipei City,"@inproceedings{10.1145/3657054.3657065,
author = {Lee, Dasheng and Chao, Shih-Lung and Chen, Hui-Min},
title = {Development of the AI Implementation Framework in Taipei City},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657065},
doi = {10.1145/3657054.3657065},
abstract = {Taipei City has been experimenting with the use of Artificial Intelligence (AI) tools to enhance its smart capabilities, aiming to increase citizen satisfaction. This initiative is part of the city's Smart City Proof of Concept (PoC) projects, which have been progressively rolled out since 2015. Most of these projects incorporate AI tools or algorithms, such as the combination of the Internet of Things (IoT) with AI to form AIoT, or the application of Large Language Models (LLMs). The objective is to leverage the latest technological developments to achieve a smarter Taipei. This study analyzes the execution of 302 PoC projects, categorizing them into 22 technological segments that together form an AI framework for smart city construction applications. This framework corresponds to 15 major issues of concern to Taipei's residents, with the potential to address or mitigate 13 of them. According to the IMD Smart City Index Report 2023, Taipei's smart city rating improved from a B in 2021 to an A in 2023, indicating progress. The results demonstrate that the AI framework derived from dissecting multiple PoC projects can effectively enhance the city's smart construction ratings. This framework, aligned with major municipal concerns, proposes solutions driven by AI, guiding Taipei's digital transformation into a smarter city and enabling its citizens to enjoy an improved quality of life.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {90–103},
numpages = {14},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

",https://doi.org/10.1145/3657054.3657065,10.1145/3657054.3657065,acm,2024
833,Ensuring Transparency in Using ChatGPT for Public Sentiment Analysis,"@inproceedings{10.1145/3657054.3657128,
author = {Tsai, Chun-Hua and Nandy, Gargi and House, Deanna and Carroll, John},
title = {Ensuring Transparency in Using ChatGPT for Public Sentiment Analysis},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657128},
doi = {10.1145/3657054.3657128},
abstract = {The advancement of generative AI, involving the utilization of large language models (LLMs) like ChatGPT to assess public opinion and sentiment, has become increasingly prevalent. However, this upsurge in usage raises significant questions about the transparency and interpretability of the predictions made by these LLM Models. Hence, this paper explores the imperative of ensuring transparency in the application of ChatGPT for public sentiment analysis. To tackle these challenges, we propose using a lexicon-based model as a surrogate to approximate both global and local predictions. Through case studies, we demonstrate how transparency mechanisms, bolstered by the lexicon-based model, can be seamlessly integrated into ChatGPT’s deployment for sentiment analysis. Drawing on the results of our study, we further discuss the implications for future research involving the utilization of LLMs in governmental functions, policymaking, and public engagement.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {627–636},
numpages = {10},
keywords = {AI Ethics and Governance, CDC, COVID, Civic Engagement},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

",https://doi.org/10.1145/3657054.3657128,10.1145/3657054.3657128,acm,2024
834,An Integrated Usability Framework for Evaluating Open Government Data Portals: Comparative Analysis of EU and GCC Countries,"@inproceedings{10.1145/3657054.3657159,
author = {Molodtsov, Fillip and Nikiforova, Anastasija},
title = {An Integrated Usability Framework for Evaluating Open Government Data Portals: Comparative Analysis of EU and GCC Countries},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657159},
doi = {10.1145/3657054.3657159},
abstract = {This study explores the critical role of open government data (OGD) portals in fostering transparency and collaboration between diverse stakeholders. Recognizing the challenges of usability, communication with diverse populations, and strategic value creation, this paper develops an integrated framework for evaluating OGD portal effectiveness that accommodates user diversity (regardless of their data literacy and language), evaluates collaboration and participation, and opportunities to explore and understand the data provided through them. The framework is validated by applying it to 33 national portals across European Union and Gulf Cooperation Council (GCC) countries, as a result of which we rank OGD portals, identify some good practices that lower-performing portals can learn from, and common shortcomings. The study unveils the competitive and innovative nature of GCC OGD portals, pinpointing specific improvement areas such as multilingual support and data understandability. The findings underscore the growing trend of exposing data quality metrics and advocate for enhanced two-way communication channels between users and portal representatives. Overall, the study contributes to accelerating the development of user-friendly, collaborative, and sustainable OGD portals while addressing gaps identified in previous research.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {899–908},
numpages = {10},
keywords = {European Union, Framework, GCC, Gulf Cooperation Council, OGD portal, Open data, Open data ecosystem, Open data portal, Open government data, Open government data portal, Sustainability, Usability},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

",https://doi.org/10.1145/3657054.3657159,10.1145/3657054.3657159,acm,2024
835,A Multi-Label Classifier for Online Petition Systems,"@inproceedings{10.1145/3657054.3657250,
author = {Buryakov, Daniil and Kovacs, Mate and Serd\""{u}lt, Uwe and Kryssanov, Victor},
title = {A Multi-Label Classifier for Online Petition Systems},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657250},
doi = {10.1145/3657054.3657250},
abstract = {Online petitions are an important means for citizens to express their concerns and to interact with government entities. Due to the increase in the number of petitions, manually attributing them to the competent unit in public administration creates a bottleneck, leading to response delays, and potentially even errors. To address this problem, a multi-label classifier using fine-tuned BERT model is suggested. The proposed model, trained on a dataset from the Taiwanese Join Platform, performs reasonably well in predicting the governmental departments in charge of petitions, even when trained on an imbalanced and rather small dataset. The obtained model manages to effectively process petitions and predicts responsible departments, achieving F1 score of 0.61 averaged over 12 categories. The proposed approach would potentially improve government responsiveness, optimize resource allocation, and facilitate online petition processing. Future work would focus on improving the model’s generalization capabilities.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {156–164},
numpages = {9},
keywords = {E-Governance, Large Language Model, Machine Learning, Multi-Labeling, Online Petitions},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

",https://doi.org/10.1145/3657054.3657250,10.1145/3657054.3657250,acm,2024
836,SAMANTHA: A chatbot to assist users in training tasks to prevent workplace hazards,"@inproceedings{10.1145/3657242.3658587,
author = {Contreras Aguilar, David and Medina, Fernando and Oyanedel, Mauricio and Salam\'{o}, Maria and S\`{a}nchez-Marr\`{e}, Miquel},
title = {SAMANTHA: A chatbot to assist users in training tasks to prevent workplace hazards},
year = {2024},
isbn = {9798400717871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657242.3658587},
doi = {10.1145/3657242.3658587},
abstract = {In businesses, preventing workplace hazards becomes crucial. In order to limit negative effects on people, society, and the economy, it is crucial for both the organization and its employees to reduce accidents and occupational illnesses. Staff training programs are essential to a company’s preventative system. In this paper, we introduce SAMANTHA, an AI chatbot that helps reduce occupational dangers in the mining industry. Using pre-trained Large Language Models (LLMs), SAMANTHA assists users with training as well as daily work tasks, aiming to help employees in any circumstance to enhance well-being at work. Despite SAMANTHA’s concentration on the mining industry, its framework is sufficiently general to be readily applied to other industries. When SAMANTHA’s learning model is compared to the pre-trained ChatGPT3.5 model, it is clear that the suggested chatbot can accurately respond to users, and the evaluation conducted with real users indicates that they are satisfied with it.},
booktitle = {Proceedings of the XXIV International Conference on Human Computer Interaction},
articleno = {11},
numpages = {8},
keywords = {AI-powered Chatbot, ChatGPT, Large Language Models, Prevention of occupational risks},
location = {A Coru\~{n}a, Spain},
series = {Interacci\'{o}n '24}
}

",https://doi.org/10.1145/3657242.3658587,10.1145/3657242.3658587,acm,2024
837,"Evaluating the Effectiveness of LLMs in Introductory Computer Science
  Education: A Semester-Long Field Study","<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10.1145/3657604.3662036</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10.1145/3657604.3662036"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",http://arxiv.org/pdf/2404.13414v3.pdf,10.1145/3657604.3662036,arxiv,2024
838,"Towards Educator-Driven Tutor Authoring: Generative AI Approaches for
  Creating Intelligent Tutor Interfaces","<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10.1145/3657604.3664694</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10.1145/3657604.3664694"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",http://arxiv.org/pdf/2405.14713v1.pdf,10.1145/3657604.3664694,arxiv,2024
839,ChatGPT and Bard Performance on the POSCOMP Exam,"@inproceedings{10.1145/3658271.3658320,
author = {Saldanha, Mateus Santos and Digiampietri, Luciano Antonio},
title = {ChatGPT and Bard Performance on the POSCOMP Exam},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658320},
doi = {10.1145/3658271.3658320},
abstract = {Context: Modern chatbots, built upon advanced language models, have achieved remarkable proficiency in answering questions across diverse fields. Problem: Understanding the capabilities and limitations of these chatbots is a significant challenge, particularly as they are integrated into different information systems, including those in education. Solution: In this study, we conducted a quantitative assessment of the ability of two prominent chatbots, ChatGPT and Bard, to solve POSCOMP questions. IS Theory: The IS theory used in this work is Information processing theory. Method: We used a total of 271 questions from the last five POSCOMP exams that did not rely on graphic content as our materials. We presented these questions to the two chatbots in two formats: directly as they appeared in the exam and with additional context. In the latter case, the chatbots were informed that they were answering a multiple-choice question from a computing exam. Summary of Results: On average, chatbots outperformed human exam-takers by more than 20%. Interestingly, both chatbots performed better, in average, without additional context added to the prompt. They exhibited similar performance levels, with a slight advantage observed for ChatGPT. Contributions and Impact in the IS area: The primary contribution to the field involves the exploration of the capabilities and limitations of chatbots in addressing computing-related questions. This information is valuable for individuals developing Information Systems with the assistance of such chatbots or those relying on technologies built upon these capabilities.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {49},
numpages = {10},
keywords = {Bard, ChatBot, ChatGPT, Computer Science Examination, Large Language Model},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

",https://doi.org/10.1145/3658271.3658320,10.1145/3658271.3658320,"acm, scopus",2024
840,Impacts of the Usage of Generative Artificial Intelligence on Software Development Process,"@inproceedings{10.1145/3658271.3658337,
author = {Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos},
title = {Impacts of the Usage of Generative Artificial Intelligence on Software Development Process},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658337},
doi = {10.1145/3658271.3658337},
abstract = {Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {65},
numpages = {9},
keywords = {ChatGPT, Copilot, Generative AI, Software Engineering, Software Process},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

",https://doi.org/10.1145/3658271.3658337,10.1145/3658271.3658337,acm,2024
841,How Do Information Technology Professionals Use Generative Artificial Intelligence?,"@inproceedings{10.1145/3658321.3658367,
author = {Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos},
title = {How Do Information Technology Professionals Use Generative Artificial Intelligence?},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658321.3658367},
doi = {10.1145/3658321.3658367},
abstract = {Context: The emergence of generative Artificial Intelligence (AI) and, more recently, the dissemination of Copilot, ChatGPT-3 and similar tools have broadened the discussion about the possibility of using generative AI tools in many professional segments such as health, education, and technological area. Problem: Although some studies explore the potential of generative AI tools to assist Information Technology (IT) professionals in executing specific tasks, they do not delve into the professionals’ characteristics or collect information about multiple generative AI tools usage. Solution: Considering the possibilities brought by generative AI, this study aims to shed light on the perception of IT professionals about generative AI tools and characterize these professionals’ profiles. IS Theory: This research is based on the Technology Acceptance Model. Method: A survey research was carried out with IT professionals so as to identify how these professionals are using generative AI and gather information about these professionals’ profiles. Results: Results show that 70,5% (43 out of 61) of the respondents use some generative AI tool, the majority of whom are software development professionals, and, despite the problems faced when using these tools, 86% of these professionals recommend using them. Contribution: In this study the profile of the IT professionals using generative AI was identified, it was then possible to evaluate the acceptance of such tools among these professionals and identify the main reasons why some of them are not yet using generative AI.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {56},
numpages = {9},
keywords = {Generative AI, IT Professional, Survey},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

",https://doi.org/10.1145/3658321.3658367,10.1145/3658321.3658367,acm,2024
842,ShennongMGS: An LLM-based Chinese Medication Guidance System,"@article{10.1145/3658451,
author = {Dou, Yutao and Huang, Yuwei and Zhao, Xiongjun and Zou, Haitao and Shang, Jiandong and Lu, Ying and Yang, Xiaolin and Xiao, Jian and Peng, Shaoliang},
title = {ShennongMGS: An LLM-based Chinese Medication Guidance System},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2158-656X},
url = {https://doi.org/10.1145/3658451},
doi = {10.1145/3658451},
abstract = {The rapidly evolving field of Large Language Models (LLMs) holds immense promise for healthcare, particularly in medication guidance and adverse drug reaction prediction. Despite their potential, existing LLMs face challenges in dealing with complex polypharmacy scenarios and often grapple with data lag issues. To address these limitations, we introduce an LLM-based Chinese medication guidance system, called ShennongMGS, specifically tailored for robust medication guidance and adverse drug reaction predictions. Our system transforms multi-source heterogeneous medication information into a knowledge graph and employs a two-stage training strategy to construct a specialised LLM (ShennongGPT). This method enables the simulation of professional pharmacists’ decision-making processes and incorporates the capability for knowledge self-updating, thereby significantly enhancing drug safety and the overall quality of medical services. Rigorously evaluated by medical professionals and artificial intelligence experts, our method demonstrates superiority, outperforming existing general and specialised LLMs in performance.},
note = {Just Accepted},
journal = {ACM Trans. Manage. Inf. Syst.},
month = {apr},
keywords = {Large Language Model, Model Fine-tuning, Medication Guidance, Chinese Medical System, Natural Language Processing, Software System}
}

",https://doi.org/10.1145/3658451,10.1145/3658451,acm,2024
843,BatFix: Repairing language model-based transpilation,"@article{10.1145/3658668,
author = {Ramos, Daniel and Lynce, In\^{e}s and Manquinho, Vasco and Martins, Ruben and Le Goues, Claire},
title = {BatFix: Repairing language model-based transpilation},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3658668},
doi = {10.1145/3658668},
abstract = {To keep up with changes in requirements, frameworks, and coding practices, software organizations might need to migrate code from one language to another. Source-to-source migration, or transpilation, is often a complex, manual process. Transpilation requires expertise both in the source and target language, making it highly laborious and costly. Languages models for code generation and transpilation are becoming increasingly popular. However, despite capturing code-structure well, code generated by language models is often spurious and contains subtle problems. We propose BatFix, a novel approach that augments language models for transpilation by leveraging program repair and synthesis to fix the code generated by these models. BatFix takes as input both the original program, the target program generated by the machine translation model, and a set of test cases and outputs a repaired program that passes all test cases. Experimental results show that our approach is agnostic to language models and programming languages. BatFix can locate bugs spawning multiple lines and synthesize patches for syntax and semantic bugs for programs migrated from Java to C++ and Python to C++ from multiple language models, including, OpenAI’s Codex.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {161},
numpages = {29},
keywords = {Program analysis, automated refactoring, machine learning, transpilation}
}

",https://doi.org/10.1145/3658668,10.1145/3658668,acm,2024
844,From Classification to Clinical Insights: Towards Analyzing and Reasoning About Mobile and Behavioral Health Data With Large Language Models,"@article{10.1145/3659604,
author = {Englhardt, Zachary and Ma, Chengqian and Morris, Margaret E. and Chang, Chun-Cheng and Xu, Xuhai ""Orson"" and Qin, Lianhui and McDuff, Daniel and Liu, Xin and Patel, Shwetak and Iyer, Vikram},
title = {From Classification to Clinical Insights: Towards Analyzing and Reasoning About Mobile and Behavioral Health Data With Large Language Models},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659604},
doi = {10.1145/3659604},
abstract = {Passively collected behavioral health data from ubiquitous sensors could provide mental health professionals valuable insights into patient's daily lives, but such efforts are impeded by disparate metrics, lack of interoperability, and unclear correlations between the measured signals and an individual's mental health. To address these challenges, we pioneer the exploration of large language models (LLMs) to synthesize clinically relevant insights from multi-sensor data. We develop chain-of-thought prompting methods to generate LLM reasoning on how data pertaining to activity, sleep and social interaction relate to conditions such as depression and anxiety. We then prompt the LLM to perform binary classification, achieving accuracies of 61.1%, exceeding the state of the art. We find models like GPT-4 correctly reference numerical data 75% of the time.While we began our investigation by developing methods to use LLMs to output binary classifications for conditions like depression, we find instead that their greatest potential value to clinicians lies not in diagnostic classification, but rather in rigorous analysis of diverse self-tracking data to generate natural language summaries that synthesize multiple data streams and identify potential concerns. Clinicians envisioned using these insights in a variety of ways, principally for fostering collaborative investigation with patients to strengthen the therapeutic alliance and guide treatment. We describe this collaborative engagement, additional envisioned uses, and associated concerns that must be addressed before adoption in real-world contexts.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {may},
articleno = {56},
numpages = {25},
keywords = {Passive sensing, clinical insights, large-language-models, mental health}
}

",https://doi.org/10.1145/3659604,10.1145/3659604,acm,2024
845,A Digital Companion Architecture for Ambient Intelligence,"@article{10.1145/3659610,
author = {Garcia, Kimberly and Vontobel, Jonathan and Mayer, Simon},
title = {A Digital Companion Architecture for Ambient Intelligence},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659610},
doi = {10.1145/3659610},
abstract = {Ambient Intelligence (AmI) focuses on creating environments capable of proactively and transparently adapting to users and their activities. Traditionally, AmI focused on the availability of computational devices, the pervasiveness of networked environments, and means to interact with users. In this paper, we propose a renewed AmI architecture that takes into account current technological advancements while focusing on proactive adaptation for assisting and protecting users. This architecture consist of four phases: Perceive, Interpret, Decide, and Interact. The AmI systems we propose, called Digital Companions (DC), can be embodied in a variety of ways (e.g., through physical robots or virtual agents) and are structured according to these phases to assist and protect their users. We further categorize DCs into Expert DCs and Personal DCs, and show that this induces a favorable separation of concerns in AmI systems, where user concerns (including personal user data and preferences) are handled by Personal DCs and environment concerns (including interfacing with environmental artifacts) are assigned to Expert DCs; this separation has favorable privacy implications as well. Herein, we introduce this architecture and validate it through a prototype in an industrial scenario where robots and humans collaborate to perform a task.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {may},
articleno = {66},
numpages = {26},
keywords = {ambient intelligence, architecture, connected devices, digital companion systems, industrial environments, knowledge graph, mixed reality, scene graph generation algorithm}
}

",https://doi.org/10.1145/3659610,10.1145/3659610,acm,2024
846,G-VOILA: Gaze-Facilitated Information Querying in Daily Scenarios,"@article{10.1145/3659623,
author = {Wang, Zeyu and Shi, Yuanchun and Wang, Yuntao and Yao, Yuchen and Yan, Kun and Wang, Yuhan and Ji, Lei and Xu, Xuhai and Yu, Chun},
title = {G-VOILA: Gaze-Facilitated Information Querying in Daily Scenarios},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659623},
doi = {10.1145/3659623},
abstract = {Modern information querying systems are progressively incorporating multimodal inputs like vision and audio. However, the integration of gaze --- a modality deeply linked to user intent and increasingly accessible via gaze-tracking wearables --- remains underexplored. This paper introduces a novel gaze-facilitated information querying paradigm, named G-VOILA, which synergizes users' gaze, visual field, and voice-based natural language queries to facilitate a more intuitive querying process. In a user-enactment study involving 21 participants in 3 daily scenarios (p = 21, scene = 3), we revealed the ambiguity in users' query language and a gaze-voice coordination pattern in users' natural query behaviors with G-VOILA. Based on the quantitative and qualitative findings, we developed a design framework for the G-VOILA paradigm, which effectively integrates the gaze data with the in-situ querying context. Then we implemented a G-VOILA proof-of-concept using cutting-edge deep learning techniques. A follow-up user study (p = 16, scene = 2) demonstrates its effectiveness by achieving both higher objective score and subjective score, compared to a baseline without gaze data. We further conducted interviews and provided insights for future gaze-facilitated information querying systems.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {may},
articleno = {78},
numpages = {33},
keywords = {gaze tracking, information query, information retrieval, large language models, smart glasses}
}

",https://doi.org/10.1145/3659623,10.1145/3659623,acm,2024
847,Digital Forms for All: A Holistic Multimodal Large Language Model Agent for Health Data Entry,"@article{10.1145/3659624,
author = {Cuadra, Andrea and Breuch, Justine and Estrada, Samantha and Ihim, David and Hung, Isabelle and Askaryar, Derek and Hassanien, Marwan and Fessele, Kristen L. and Landay, James A.},
title = {Digital Forms for All: A Holistic Multimodal Large Language Model Agent for Health Data Entry},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659624},
doi = {10.1145/3659624},
abstract = {Digital forms help us access services and opportunities, but they are not equally accessible to everyone, such as older adults or those with sensory impairments. Large language models (LLMs) and multimodal interfaces offer a unique opportunity to increase form accessibility. Informed by prior literature and needfinding, we built a holistic multimodal LLM agent for health data entry. We describe the process of designing and building our system, and the results of a study with older adults (N =10). All participants, regardless of age or disability status, were able to complete a standard 47-question form independently using our system---one blind participant said it was ""a prayer answered."" Our video analysis revealed how different modalities provided alternative interaction paths in complementary ways (e.g., the buttons helped resolve transcription errors and speech helped provide more options when the pre-canned answer choices were insufficient). We highlight key design guidelines, such as designing systems that dynamically adapt to individual needs.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {may},
articleno = {72},
numpages = {39},
keywords = {Accessibility, Artifact or System, Field Study, Health - Clinical, Input Techniques, Interaction Design, Mobile Devices: Phones/Tablets, Older Adults, Prototyping/Implementation, Qualitative Methods, Text/Speech/Language, User Experience Design}
}

",https://doi.org/10.1145/3659624,10.1145/3659624,acm,2024
848,Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,"@article{10.1145/3659625,
author = {Yang, Ziqi and Xu, Xuhai and Yao, Bingsheng and Rogers, Ethan and Zhang, Shao and Intille, Stephen and Shara, Nawar and Gao, Guodong Gordon and Wang, Dakuo},
title = {Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659625},
doi = {10.1145/3659625},
abstract = {Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {may},
articleno = {73},
numpages = {35},
keywords = {Large-language-model, Older adults, Patient-provider communication}
}

",https://doi.org/10.1145/3659625,10.1145/3659625,acm,2024
849,Prototyping a Zoomorphic Interactive Robot Companion with Emotion Recognition and Affective Voice Interaction for Elderly People,"@article{10.1145/3660244,
author = {Schnitzer, Benjamin and Vural, Umut Can and Schnitzer, Bastian and Sardar, Muhammad Usman and Fuerst, Oren and Korn, Oliver},
title = {Prototyping a Zoomorphic Interactive Robot Companion with Emotion Recognition and Affective Voice Interaction for Elderly People},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {EICS},
url = {https://doi.org/10.1145/3660244},
doi = {10.1145/3660244},
abstract = {An aging society paired with a skilled labor shortage, particularly in European countries, requires a rethinking of deprecated structures. Intelligent assistive technologies, specifically socially assistive robots, addressing the gap between caretakers and elderly people in need of care have moved into the focus of debate due to their potentials to reduce costs, improve independence, and eventually raise quality of life. In this work, we outline the potentials of zoomorphic robot companions combining intelligent conversational abilities and emotion recognition. We then describe the prototyping of an emotion-sensing zoomorphic interactive robot companion including the development and implementation of a multimodal emotion recognition framework. This framework uses speech emotion recognition, sentiment analysis, and affective voice interaction based on a large language model. The prototyping has been accompanied by two studies on elderly peoples' design preferences regarding the proposed feature set as well as different embodiments to find the appropriate casing for the robot companion. This work provides valuable insights into the prototyping and can thus support future research endeavors in this area.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {jun},
articleno = {242},
numpages = {32},
keywords = {Affective Computing, Elderly People, Health, Intelligent Assistive Technology, Socially Assistive Robots, Speech Emotion Recognition, Zoomorphic Embodiment}
}

",https://doi.org/10.1145/3660244,10.1145/3660244,acm,2024
850,A Chatbot Won't Judge Me: An Exploratory Study of Self-disclosing Chatbots in Introductory Computer Science Classes,"@inproceedings{10.1145/3660650.3660662,
author = {Goddard, Quinn and Moton, Nathan and Hudson, Jonathan and He, Helen Ai},
title = {A Chatbot Won't Judge Me: An Exploratory Study of Self-disclosing Chatbots in Introductory Computer Science Classes},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660662},
doi = {10.1145/3660650.3660662},
abstract = {Students in introductory Computer Science (CS) courses sometimes struggle with learning course content, but feel these struggles are uniquely theirs. To foster a more inclusive CS culture and normalize challenges in the learning process, we designed a conversational agent (“chatbot”) that self-discloses information about the chatbot’s own imaginary struggles with learning course material. Inspired by previous work in the mental health domain where humans reciprocated disclosure when a chatbot disclosed sensitive information, our goal was to promote student self-disclosure of learning challenges and to help students feel less alone. To inform design, we first conducted three focus groups with CS students on themes of identity and belonging. Based on these findings, we designed a self-disclosing chatbot (“Mibi”) and deployed it in a pilot summer course (40 students) and a larger course (460 students) in the fall semester of 2023. Our work is the first real-world deployment of a chatbot in higher education for promoting student wellbeing, rather than assisting with practical course content. We highlight findings from this exploratory study, sharing how students engaged with Mibi, where it succeeded, where it has room to grow, and how that can inform future iterations of this promising new classroom companion for student mental health.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {9},
numpages = {7},
keywords = {CS1/CS2, Chatbot, Computer Science, Mental well-being, Qualitative, Self-Disclosure},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

",https://doi.org/10.1145/3660650.3660662,10.1145/3660650.3660662,acm,2024
851,An End-to-End Framework for Multi-Docs Chatbot using Llama2,"@inproceedings{10.1145/3660853.3660921,
author = {Joshi, Purvika and Sati, Subhangi and Sar, Ayan and Aich, Sumit and Choudhury, Tanupriya and Kotecha, Ketan and Ozseven, Turgut},
title = {An End-to-End Framework for Multi-Docs Chatbot using Llama2},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660853.3660921},
doi = {10.1145/3660853.3660921},
abstract = {The evolution of conversational agents, in particular the case with chatbots, has experienced huge boosts in recent years, enabling a variety of tasks and allowing users to enjoy much more interaction. This research presents a sequential model for a Chatbot of multiple documents that is based on the best of the Llama2 mod-el. The document classification framework intends to offer a user-oriented as well as a versatile conversational approach that draws on data from several fields. Through proper implementation of state-of-the-art natural language processing technology, the chatbot can understand users' inquiries, retrieve the required in-formation from the uploaded files, and respond fluently and understandably. It provides document management processes, like file handling of PDF, DOCX, etc., which enables the user to work with almost all file types and formats. And that directly uses Hugging Face Transformers in such processes as text embed-ding and conversational generation. One of the key components of the system is the FAISS tool that allows for vector storage and retrieval keeping the chatbot operating efficiently in the process of searching and retrieving information from vast document collections. In summary, the work provided here lays out the foundations of the multi-doc system which is a powerful tool that can be used to improve the deployments and information search tasks, with the effect of boost-ing user engagement and productivity.},
booktitle = {Proceedings of the Cognitive Models and Artificial Intelligence Conference},
pages = {232–236},
numpages = {5},
keywords = {Chatbot, Generative AI, LLM, Natural Language Processing},
location = {undefinedstanbul, Turkiye},
series = {AICCONF '24}
}

",https://doi.org/10.1145/3660853.3660921,10.1145/3660853.3660921,acm,2024
852,Evaluation of Code Generation for Simulating Participant Behavior in Experience Sampling Method by Iterative In-Context Learning of a Large Language Model,"@article{10.1145/3661143,
author = {Khanshan, Alireza and Van Gorp, Pieter and Markopoulos, Panos},
title = {Evaluation of Code Generation for Simulating Participant Behavior in Experience Sampling Method by Iterative In-Context Learning of a Large Language Model},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {EICS},
url = {https://doi.org/10.1145/3661143},
doi = {10.1145/3661143},
abstract = {The Experience Sampling Method (ESM) is commonly used to understand behaviors, thoughts, and feelings in the wild by collecting self-reports. Sustaining sufficient response rates, especially in long-running studies remains challenging. To avoid low response rates and dropouts, experimenters rely on their experience, proposed methodologies from earlier studies, trial and error, or the scarcely available participant behavior data from previous ESM protocols. This approach often fails in finding the acceptable study parameters, resulting in redesigning the protocol and repeating the experiment. Research has shown the potential of machine learning to personalize ESM protocols such that ESM prompts are delivered at opportune moments, leading to higher response rates. The corresponding training process is hindered due to the scarcity of open data in the ESM domain, causing a cold start, which could be mitigated by simulating participant behavior. Such simulations provide training data and insights for the experimenters to update their study design choices. Creating this simulation requires behavioral science, psychology, and programming expertise. Large language models (LLMs) have emerged as facilitators for information inquiry and programming, albeit random and occasionally unreliable. We aspire to assess the readiness of LLMs in an ESM use case. We conducted research using GPT-3.5 turbo-16k to tackle an ESM simulation problem. We explored several prompt design alternatives to generate ESM simulation programs, evaluated the output code in terms of semantics and syntax, and interviewed ESM practitioners. We found that engineering LLM-enabled ESM simulations have the potential to facilitate data generation, but they perpetuate trust and reliability challenges.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {jun},
articleno = {255},
numpages = {19},
keywords = {Behavior Simulation, Experience Sampling Method, Large Language Model, Prompt Engineering}
}

",https://doi.org/10.1145/3661143,10.1145/3661143,acm,2024
853,Significant Productivity Gains through Programming with Large Language Models,"@article{10.1145/3661145,
author = {Weber, Thomas and Brandmaier, Maximilian and Schmidt, Albrecht and Mayer, Sven},
title = {Significant Productivity Gains through Programming with Large Language Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {EICS},
url = {https://doi.org/10.1145/3661145},
doi = {10.1145/3661145},
abstract = {Large language models like GPT and Codex drastically alter many daily tasks, including programming, where they can rapidly generate code from natural language or informal specifications. Thus, they will change what it means to be a programmer and how programmers act during software development. This work explores how AI assistance for code generation impacts productivity. In our user study (N=24), we asked programmers to complete Python programming tasks supported by a) an auto-complete interface using GitHub Copilot, b) a conversational system using GPT-3, and c) traditionally with just the web browser. Aside from significantly increasing productivity metrics, participants displayed distinctive usage patterns and strategies, highlighting that the form of presentation and interaction affects how users engage with these systems. Our findings emphasize the benefits of AI-assisted coding and highlight the different design challenges for these systems.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {jun},
articleno = {256},
numpages = {29},
keywords = {github copilot, gpt, language models, programming, software development, user study}
}

",https://doi.org/10.1145/3661145,10.1145/3661145,acm,2024
854,The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews,"@inproceedings{10.1145/3661167.3661172,
author = {Huotala, Aleksi and Kuutila, Miikka and Ralph, Paul and M\""{a}ntyl\""{a}, Mika},
title = {The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661172},
doi = {10.1145/3661167.3661172},
abstract = {Context: Systematic review (SR) is a popular research method in software engineering (SE). However, conducting an SR takes an average of 67 weeks. Thus, automating any step of the SR process could reduce the effort associated with SRs. Objective: Our objective is to investigate the extent to which Large Language Models (LLMs) can accelerate title-abstract screening by (1) simplifying abstracts for human screeners, and (2) automating title-abstract screening entirely. Method: We performed an experiment where human screeners performed title-abstract screening for 20 papers with both original and simplified abstracts from a prior SR. The experiment with human screeners was reproduced by instructing GPT-3.5 and GPT-4 LLMs to perform the same screening tasks. We also studied whether different prompting techniques (Zero-shot (ZS), One-shot (OS), Few-shot (FS), and Few-shot with Chain-of-Thought (FS-CoT) prompting) improve the screening performance of LLMs. Lastly, we studied if redesigning the prompt used in the LLM reproduction of title-abstract screening leads to improved screening performance. Results: Text simplification did not increase the screeners’ screening performance, but reduced the time used in screening. Screeners’ scientific literacy skills and researcher status predict screening performance. Some LLM and prompt combinations perform as well as human screeners in the screening tasks. Our results indicate that a more recent LLM (GPT-4) is better than its predecessor LLM (GPT-3.5). Additionally, Few-shot and One-shot prompting outperforms Zero-shot prompting. Conclusion: Using LLMs for text simplification in the screening process does not significantly improve human performance. Using LLMs to automate title-abstract screening seems promising, but current LLMs are not significantly more accurate than human screeners. To recommend the use of LLMs in the screening process of SRs, more research is needed. We recommend future SR studies to publish replication packages with screening data to enable more conclusive experimenting with LLM screening.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {262–271},
numpages = {10},
keywords = {ChatGPT, GPT-3.5, GPT-4, LLMs, Screening Process of Systematic Reviews, Text Simplification},
location = {Salerno, Italy},
series = {EASE '24}
}

",https://doi.org/10.1145/3661167.3661172,10.1145/3661167.3661172,acm,2024
855,Gamifying Business Process Modeling Education: A Longitudinal Study,"@inproceedings{10.1145/3661167.3661272,
author = {Garaccione, Giacomo and Coppola, Riccardo and Ardito, Luca},
title = {Gamifying Business Process Modeling Education: A Longitudinal Study},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661272},
doi = {10.1145/3661167.3661272},
abstract = {Gamification, the practice consisting of adapting game elements and features in non-recreational contexts to increase user motivation and interest, has become increasingly common in recent years in the different fields of Software Engineering such as development, requirements definition, testing, and education. Among the different educational fields to which gamification has been applied, process modeling is currently not much explored: there are few examples of game-like approaches used for teaching process modeling, and such examples have yet to be applied for the duration of an entire course to assess possible benefits. We thus describe the use of BIPMIN, a platform that implements elements regularly used in gamified tools such as levels, avatars, and leaderboards, in an Information Systems course, where students used the tool to perform practical BPMN modeling exercises over the whole duration of the course to get feedback on their modeling strategies. The students’ opinions have been gathered in the form of an end-of-course questionnaire and have been analyzed following the Straussian grounded theory approach to assess the general sentiment regarding usability, appreciation, and possible issues and improvement areas of the tool. The gathered results are encouraging, as they show that the tool has been well received and that its features that help student understanding the reasons behind their errors have been perceived as helpful for learning and improving BPMN modeling.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {580–589},
numpages = {10},
keywords = {BPMN, Gamification, Process Modeling, Software Engineering Education, Software Modeling},
location = {Salerno, Italy},
series = {EASE '24}
}

",https://doi.org/10.1145/3661167.3661272,10.1145/3661167.3661272,acm,2024
856,An Empirical Study on How Large Language Models Impact Software Testing Learning,"@inproceedings{10.1145/3661167.3661273,
author = {Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon},
title = {An Empirical Study on How Large Language Models Impact Software Testing Learning},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661273},
doi = {10.1145/3661167.3661273},
abstract = {Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {555–564},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant},
location = {Salerno, Italy},
series = {EASE '24}
}

",https://doi.org/10.1145/3661167.3661273,10.1145/3661167.3661273,acm,2024
857,Securing Agile: Assessing the Impact of Security Activities on Agile Development,"@inproceedings{10.1145/3661167.3661280,
author = {Thool, Arpit and Brown, Chris},
title = {Securing Agile: Assessing the Impact of Security Activities on Agile Development},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661280},
doi = {10.1145/3661167.3661280},
abstract = {Software systems are expected to be secure and robust. To verify and ensure software security, it is vital to include security activities, or development practices to detect and prevent security vulnerabilities, into the software development process. Agile software development is a popular software engineering (SE) process used by many organizations and development teams. However, while Agile aims to be a lightweight and responsive process, security activities are typically more cumbersome and involve more documentation and tools–violating the core principles of Agile. This work investigates the impact of security activities on various aspects of Agile development. To understand how software engineers perceive incorporating security practices into Agile methodologies, we distributed an online survey to collect data from software practitioners with experience working in Agile teams. Our results from 34 survey participants show most software practitioners believe security activities are beneficial to development overall but lack confidence in their impact on the security of software systems. Our findings provide insight into how security activities affect Agile development and provide implications to help SE teams better incorporate security activities into implementing Agile development processes.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {668–678},
numpages = {11},
keywords = {Agile, Security Activities, Software Engineering},
location = {Salerno, Italy},
series = {EASE '24}
}

",https://doi.org/10.1145/3661167.3661280,10.1145/3661167.3661280,acm,2024
858,Are Large Language Models Capable of Causal Reasoning for Sensing Data Analysis?,"@inproceedings{10.1145/3662006.3662064,
author = {Hu, Zhizhang and Zhang, Yue and Rossi, Ryan and Yu, Tong and Kim, Sungchul and Pan, Shijia},
title = {Are Large Language Models Capable of Causal Reasoning for Sensing Data Analysis?},
year = {2024},
isbn = {9798400706639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662006.3662064},
doi = {10.1145/3662006.3662064},
abstract = {The correlation analysis between socioeconomic factors and environmental impact is essential for policy making to ensure sustainability and economic development simultaneously. With the development of Internet of Things (IoT), citizen science IoT monitoring provides valuable environmental measurements, such as PM 2.5 for air quality monitoring. However, socioeconomic factors are usually interconnected and confound each other, making accurate correlation analysis challenging. To isolate this information on an individual socioeconomic factor, we need to mitigate the confounding effect (e.g., propensity score matching) of other factors on the environmental sensing data. Large language models (LLMs) have shown remarkable capabilities in data reasoning, making us wonder if they can conduct causal reasoning and answer questions like ""What is the most important socioeconomic factor that impacts regional air quality?""In this paper, we present a new evaluation framework named ""Order-of-Thought"" based on Bloom's Taxonomy pedagogical framework to quantify the LLMs' ability for causal reasoning. We apply this evaluation framework with both natural language-based and program-based prompting strategies. Our evaluation uncovers the exceptional potentials of LLMs in causal reasoning for sensing data analysis, offering valuable insights regarding their capabilities and limitations, and providing useful directions to further achieve a higher-order thought.},
booktitle = {Proceedings of the Workshop on Edge and Mobile Foundation Models},
pages = {24–29},
numpages = {6},
keywords = {Causal Data Reasoning, Large Language Model},
location = {Minato-ku, Tokyo, Japan},
series = {EdgeFM '24}
}

",https://doi.org/10.1145/3662006.3662064,10.1145/3662006.3662064,acm,2024
859,,"@inproceedings{10.1145/3663384.3663389,
author = {Drosos, Ian and Sarkar, Advait and Xu, Xiaotong and Negreanu, Carina and Rintel, Sean and Tankelevitch, Lev},
title = {""It's like a rubber duck that talks back"": Understanding Generative AI-Assisted Data Analysis Workflows through a Participatory Prompting Study},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663389},
doi = {10.1145/3663384.3663389},
abstract = {Generative AI tools can help users with many tasks. One such task is data analysis, which is notoriously challenging for non-expert end-users due to its expertise requirements, and where AI holds much potential, such as finding relevant data sources, proposing analysis strategies, and writing analysis code. To understand how data analysis workflows can be assisted or impaired by generative AI, we conducted a study (n=15) using Bing Chat via participatory prompting. Participatory prompting is a recently developed methodology in which users and researchers reflect together on tasks through co-engagement with generative AI. In this paper we demonstrate the value of the participatory prompting method. We found that generative AI benefits the information foraging and sensemaking loops of data analysis in specific ways, but also introduces its own barriers and challenges, arising from the difficulties of query formulation, specifying context, and verifying results.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {16},
numpages = {21},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

",https://doi.org/10.1145/3663384.3663389,10.1145/3663384.3663389,acm,2024
860,Non-Expert Programmers in the Generative AI Future,"@inproceedings{10.1145/3663384.3663393,
author = {Feldman, Molly Q and Anderson, Carolyn Jane},
title = {Non-Expert Programmers in the Generative AI Future},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663393},
doi = {10.1145/3663384.3663393},
abstract = {Generative AI is rapidly transforming the practice of programming. At the same time, our understanding of who writes programs, for what purposes, and how they program, has been evolving. By facilitating natural-language-to-code interactions, large language models for code have the potential to open up programming work to a broader range of workers. While existing work finds productivity benefits for expert programmers, interactions with non-experts are less well-studied. In this paper, we consider the future of programming for non-experts through a controlled study of 67 non-programmers. Our study reveals multiple barriers to effective use of large language models of code for non-experts, including several aspects of technical communication. Comparing our results to a prior study of beginning programmers illuminates the ways in which a traditional introductory programming class does and does not equip students to effectively work with generative AI. Drawing on our empirical findings, we lay out a vision for how to empower non-expert programmers to leverage generative AI for a more equitable future of programming.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {15},
numpages = {19},
keywords = {CS1, Code LLMs, Generative AI, mixed methods, non-experts},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

",https://doi.org/10.1145/3663384.3663393,10.1145/3663384.3663393,acm,2024
861,AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas,"@inproceedings{10.1145/3663384.3663398,
author = {He, Jessica and Houde, Stephanie and Gonzalez, Gabriel E. and Silva Moran, Dar\'{\i}o Andr\'{e}s and Ross, Steven I. and Muller, Michael and Weisz, Justin D.},
title = {AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663398},
doi = {10.1145/3663384.3663398},
abstract = {The introduction of generative AI into multi-user applications raises novel considerations for the future of collaborative work. How might collaborative work practices change? How might we incorporate generative AI into shared tools with users’ needs at the forefront? We examine these questions in the context of a remote team conducting ideation tasks – an example of collaborative work enabled by a shared digital workspace. We conducted a user study with 17 professionals experienced with virtual group ideation workshops. Our study examined their use of the Collaborative Canvas, a virtual canvas tool with integrated generative AI capabilities that we created as a probe. Participants saw value in using generative AI to assist with group facilitation and to augment perspectives and ideas. However, they worried about losing human perspectives and critical thinking, as well as reputational harms resulting from harmful AI outputs. Participants shared suggestions for appropriate ways to incorporate generative AI capabilities within multi-user applications and identified needs for transparency of content ownership, private digital spaces, and specialized AI capabilities. Based on participants’ insights, we share implications and opportunities for the incorporation of generative AI into collaborative work in ways that place user needs at the forefront.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {9},
numpages = {14},
keywords = {Brainstorming, Future of work, Generative AI, Group ideation, Mixed initiative, Shared virtual canvas},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

",https://doi.org/10.1145/3663384.3663398,10.1145/3663384.3663398,acm,2024
862,"Teacher, Trainer, Counsel, Spy: How Generative AI can Bridge or Widen the Gaps in Worker-Centric Digital Phenotyping of Wellbeing","@inproceedings{10.1145/3663384.3663401,
author = {Das Swain, Vedant and Saha, Koustuv},
title = {Teacher, Trainer, Counsel, Spy: How Generative AI can Bridge or Widen the Gaps in Worker-Centric Digital Phenotyping of Wellbeing},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663401},
doi = {10.1145/3663384.3663401},
abstract = {The increasing integration of computing technologies in the workplace has also seen the conceptualization and development of data-driven and algorithmic tools that aim to improve workers’ wellbeing and performance. However, both research and practice have revealed several gaps in the effectiveness and deployment of these tools. Meanwhile, the recent advances in generative AI have highlighted the tremendous capabilities of large language models (LLMs) in processing large volumes of data in producing human-interactive natural language content. This paper explores the opportunities for LLMs in facilitating worker-centered design for Wellbeing Assessment Tools (WATs). In particular, we map features of LLMs against known challenges of WAT. We highlight how the LLMs can bridge or even widen the gaps in worker-centeric WAT. This paper aims to inspire new research directions focused on empowering workers and anticipating harms in integrating LLMs with workplace technologies.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {3},
numpages = {13},
keywords = {LLMs, generative AI, large language models, worker performance, worker wellbeing, workplace},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

",https://doi.org/10.1145/3663384.3663401,10.1145/3663384.3663401,acm,2024
863,Developing Time Series Forecasting Models with Generative Large Language Models,"@article{10.1145/3663485,
author = {Morales-Garc\'{\i}a, Juan and Llanes, Antonio and Arcas-T\'{u}nez, Francisco and Terroso-S\'{a}enz, Fernando},
title = {Developing Time Series Forecasting Models with Generative Large Language Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3663485},
doi = {10.1145/3663485},
abstract = {Nowadays, Generative Large Language Models (GLLMs) have made a significant impact in the field of Artificial Intelligence (AI). One of the domains extensively explored for these models is their ability as generators of functional source code for software projects. Nevertheless, their potential as assistants to write the code needed to generate and model Machine Learning (ML) or Deep Learning (DL) architectures has not been fully explored to date. For this reason, this work focuses on evaluating the extent to which different tools based on GLLMs, such as ChatGPT or Copilot, are able to correctly define the source code necessary to generate viable predictive models. The use case defined is the forecasting of a time series that reports the indoor temperature of a greenhouse. The results indicate that, while it is possible to achieve good accuracy metrics with simple predictive models generated by GLLMs, the composition of predictive models with complex architectures using GLLMs is still far from improving the accuracy of predictive models generated by human data scientists.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {may},
keywords = {Deep Learning, Generative Large Language Models (GLLMs), ChatGPT, Copilot, Time series forecasting}
}

",https://doi.org/10.1145/3663485,10.1145/3663485,acm,2024
864,A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5,"@inproceedings{10.1145/3663649.3664368,
author = {Aerts, Willem and Fletcher, George and Miedema, Daphne},
title = {A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664368},
doi = {10.1145/3663649.3664368},
abstract = {SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {13–19},
numpages = {7},
keywords = {Assessment, ChatGPT, Education, LLM, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

",https://doi.org/10.1145/3663649.3664368,10.1145/3663649.3664368,acm,2024
865,Integrating LLMs into Database Systems Education,"@inproceedings{10.1145/3663649.3664371,
author = {Prakash, Kishore and Rao, Shashwat and Hamza, Rayan and Lukich, Jack and Chaudhari, Vatsal and Nandi, Arnab},
title = {Integrating LLMs into Database Systems Education},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664371},
doi = {10.1145/3663649.3664371},
abstract = {Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {33–39},
numpages = {7},
keywords = {ChatGPT, database systems education, foundation models, intro to db, large language models, llm, undergrad databases},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

",https://doi.org/10.1145/3663649.3664371,10.1145/3663649.3664371,acm,2024
866,Measuring User Experience Inclusivity in Human-AI Interaction via Five User Problem-Solving Styles,"@article{10.1145/3663740,
author = {Anderson, Andrew and Noa Guevara, Jimena and Moussaoui, Fatima and Li, Tianyi and Vorvoreanu, Mihaela and Burnett, Margaret},
title = {Measuring User Experience Inclusivity in Human-AI Interaction via Five User Problem-Solving Styles},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2160-6455},
url = {https://doi.org/10.1145/3663740},
doi = {10.1145/3663740},
abstract = {Motivations: Recent research has emerged on generally how to improve AI products’ Human-AI Interaction (HAI) User Experience (UX), but relatively little is known about HAI-UX inclusivity. For example, what kinds of users are supported, and who are left out? What product changes would make it more inclusive?Objectives: To help fill this gap, we present an approach to measuring what kinds of diverse users an AI product leaves out and how to act upon that knowledge. To bring actionability to the results, the approach focuses on users’ problem-solving diversity. Thus, our specific objectives were: (1) to show how the measure can reveal which participants with diverse problem-solving styles were left behind in a set of AI products; and (2) to relate participants’ problem-solving diversity to their demographic diversity, specifically gender and age.Methods: We performed 18 experiments, discarding two that failed manipulation checks. Each experiment was a 2x2 factorial experiment with online participants, comparing two AI products: one deliberately violating one of 18 HAI guideline and the other applying the same guideline. For our first objective, we used our measure to analyze how much each AI product gained/lost HAI-UX inclusivity compared to its counterpart, where inclusivity meant supportiveness to participants with particular problem-solving styles. For our second objective, we analyzed how participants’ problem-solving styles aligned with their gender identities and ages.Results &amp; Implications: Participants’ diverse problem-solving styles revealed six types of inclusivity results: (1) the AI products that followed an HAI guideline were almost always more inclusive across diversity of problem-solving styles than the products that did not follow that guideline—but “who” got most of the inclusivity varied widely by guideline and by problem-solving style; (2) when an AI product had risk implications, four variables’ values varied in tandem: participants’ feelings of control, their (lack of) suspicion, their trust in the product, and their certainty while using the product; (3) the more control an AI product offered users, the more inclusive it was; (4) whether an AI product was learning from “my” data or other people’s affected how inclusive that product was; (5) participants’ problem-solving styles skewed differently by gender and age group; and (6) almost all of the results suggested actions that HAI practitioners could take to improve their products’ inclusivity further. Together, these results suggest that a key to improving the demographic inclusivity of an AI product (e.g., across a wide range of genders, ages, etc.) can often be obtained by improving the product’s support of diverse problem-solving styles.},
note = {Just Accepted},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {may},
keywords = {Intelligent User Interfaces, Human-Computer Interaction}
}

",https://doi.org/10.1145/3663740,10.1145/3663740,acm,2024
867,Are Large Language Models the New Interface for Data Pipelines?,"@inproceedings{10.1145/3663741.3664785,
author = {Barbon Junior, Sylvio and Ceravolo, Paolo and Groppe, Sven and Jarrar, Mustafa and Maghool, Samira and S\`{e}des, Florence and Sahri, Soror and Van Keulen, Maurice},
title = {Are Large Language Models the New Interface for Data Pipelines?},
year = {2024},
isbn = {9798400706790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663741.3664785},
doi = {10.1145/3663741.3664785},
abstract = {A Language Model is a term that encompasses various types of models designed to understand and generate human communication. Large Language Models (LLMs) have gained significant attention due to their ability to process text with human-like fluency and coherence, making them valuable for a wide range of data-related tasks fashioned as pipelines. The capabilities of LLMs in natural language understanding and generation, combined with their scalability, versatility, and state-of-the-art performance, enable innovative applications across various AI-related fields, including eXplainable Artificial Intelligence (XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG). Furthermore, we believe these models can extract valuable insights and make data-driven decisions at scale, a practice commonly referred to as Big Data Analytics (BDA). In this position paper, we provide some discussions in the direction of unlocking synergies among these technologies, which can lead to more powerful and intelligent AI solutions, driving improvements in data pipelines across a wide range of applications and domains integrating humans, computers, and knowledge.},
booktitle = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
articleno = {6},
numpages = {6},
keywords = {Automated Machine Learning, Big Data Analytic, Human-Computer Interaction, Knowledge Graphs, Natural Language Understanding, eXplainable Artificial Intelligence},
location = {Santiago, AA, Chile},
series = {BiDEDE '24}
}

",https://doi.org/10.1145/3663741.3664785,10.1145/3663741.3664785,acm,2024
868,Smart Science Needs Linked Open Data with a Dash of Large Language Models and Extended Relations,"@inproceedings{10.1145/3663742.3663971,
author = {Jamil, Hasan M.},
title = {Smart Science Needs Linked Open Data with a Dash of Large Language Models and Extended Relations},
year = {2024},
isbn = {9798400706806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663742.3663971},
doi = {10.1145/3663742.3663971},
abstract = {Quality scientific inquiries depend on access to data distributed over the entire globe. Linked open data (LOD) and FAIRness play major roles in ensuring access to data that scientists need to answer interesting questions. However, a data model and a query language to compute responses to complex scientific inquiries remain outstanding. As the recent emergence of large language models (LLM) reshape how we interact with machines, an intriguing prospect of posing scientific inquiries to smart machines suddenly appears realizable in which a natural language ChatBot is empowered with a LOD knowledgebase as its data source. In this paper, we introduce a model for an LLM interpreter, called ProAb, that aims to answer natural language scientific queries using a structured query language called Needle in which the LOD is viewed as a set of tables. We discuss the contours of ProAb, present its preliminary and experimental design, and highlight its salient features using an illustrative example. It should be apparent that a full automation of ProAb is feasible with further research.},
booktitle = {Proceedings of the Seventh International Workshop on Exploiting Artificial Intelligence Techniques for Data Management},
articleno = {1},
numpages = {11},
keywords = {Extended Relational Model, Intelligent User Interface, Large Language Model, Query Processing, Structured Query Language},
location = {Santiago, AA, Chile},
series = {aiDM '24}
}

",https://doi.org/10.1145/3663742.3663971,10.1145/3663742.3663971,acm,2024
869,Confidential Computing or Cryptographic Computing? Tradeoffs between cryptography and hardware enclaves,"@article{10.1145/3664295,
author = {Popa, Raluca Ada},
title = {Confidential Computing or Cryptographic Computing? Tradeoffs between cryptography and hardware enclaves},
year = {2024},
issue_date = {March/April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/3664295},
doi = {10.1145/3664295},
abstract = {Secure computation via MPC/homomorphic encryption versus hardware enclaves presents tradeoffs involving deployment, security, and performance. Regarding performance, it matters a lot which workload you have in mind. For simple workloads such as simple summations, low-degree polynomials, or simple machine-learning tasks, both approaches can be ready to use in practice, but for rich computations such as complex SQL analytics or training large machine-learning models, only the hardware enclave approach is at this moment practical enough for many real-world deployment scenarios.},
journal = {Queue},
month = {may},
pages = {108–132},
numpages = {25}
}

",https://doi.org/10.1145/3664295,10.1145/3664295,acm,2024
870,Unpacking Human-AI interactions: From interaction primitives to a design space,"@article{10.1145/3664522,
author = {Tsiakas, Konstantinos and Murray-Rust, Dave},
title = {Unpacking Human-AI interactions: From interaction primitives to a design space},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2160-6455},
url = {https://doi.org/10.1145/3664522},
doi = {10.1145/3664522},
abstract = {This paper aims to develop a semi-formal representation for Human-AI (HAI) interactions, by building a set of interaction primitives which can specify the information exchanges between users and AI systems during their interaction. We show how these primitives can be combined into a set of interaction patterns which can capture common interactions between humans and AI/ML models. The motivation behind this is twofold: firstly, to provide a compact generalisation of existing practices for the design and implementation of HAI interactions; and secondly, to support the creation of new interactions by extending the design space of HAI interactions. Taking into consideration frameworks, guidelines and taxonomies related to human-centered design and implementation of AI systems, we define a vocabulary for describing information exchanges based on the model’s characteristics and interactional capabilities. Based on this vocabulary, a message passing model for interactions between humans and models is presented, which we demonstrate can account for existing HAI interaction systems and approaches. Finally, we build this into design patterns which can describe common interactions between users and models, and we discuss how this approach can be used towards a design space for HAI interactions that creates new possibilities for designs as well as keeping track of implementation issues and concerns.},
note = {Just Accepted},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {jun},
keywords = {Human-AI interaction, interaction patterns, explainable AI, human-in-the-loop, hybrid intelligence}
}

",https://doi.org/10.1145/3664522,10.1145/3664522,acm,2024
871,Neural Machine Translation for Low-Resource Languages from a Chinese-centric Perspective: A Survey,"@article{10.1145/3665244,
author = {Zhang, Jinyi and Su, Ke and Li, Haowei and Mao, Jiannan and Tian, Ye and Wen, Feng and Guo, Chong and Matsumoto, Tadahiro},
title = {Neural Machine Translation for Low-Resource Languages from a Chinese-centric Perspective: A Survey},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {6},
issn = {2375-4699},
url = {https://doi.org/10.1145/3665244},
doi = {10.1145/3665244},
abstract = {Machine translation–the automatic transformation of one natural language (source language) into another (target language) through computational means–occupies a central role in computational linguistics and stands as a cornerstone of research within the field of Natural Language Processing (NLP). In recent years, the prominence of Neural Machine Translation (NMT) has grown exponentially, offering an advanced framework for machine translation research. It is noted for its superior translation performance, especially when tackling the challenges posed by low-resource language pairs that suffer from a limited corpus of data resources. This article offers an exhaustive exploration of the historical trajectory and advancements in NMT, accompanied by an analysis of the underlying foundational concepts. It subsequently provides a concise demarcation of the unique characteristics associated with low-resource languages and presents a succinct review of pertinent translation models and their applications, specifically within the context of languages with low-resources. Moreover, this article delves deeply into machine translation techniques, highlighting approaches tailored for Chinese-centric low-resource languages. Ultimately, it anticipates upcoming research directions in the realm of low-resource language translation.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {jun},
articleno = {80},
numpages = {60},
keywords = {Low-resource languages, neural machine translation, unsupervised learning, transfer learning, multilingual translation, large language models, Chinese-centric languages}
}

",https://doi.org/10.1145/3665244,10.1145/3665244,acm,2024
872,"A few Thoughts on the Use of ChatGPT, GPT 3.5, GPT-4 and LLMs in Parliaments: Reflecting on the results of experimenting with LLMs in the parliamentarian context","@article{10.1145/3665333,
author = {Lucke, J\""{o}rn Von and Frank, Sander},
title = {A few Thoughts on the Use of ChatGPT, GPT 3.5, GPT-4 and LLMs in Parliaments: Reflecting on the results of experimenting with LLMs in the parliamentarian context},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665333},
doi = {10.1145/3665333},
abstract = {Starting in November 2022 with the free provision of ChatGPT, large language models (LLM) are now publicly available. This has significantly increased the number of publications which scopes potential changes caused by the application of generative artificial intelligence (AI) in various societal domains. The private use of AI and the economic integration of generative LLMs have increased significantly. However, for parliamentarians and parliamentary professionals, the technology often remains abstract, impacting everyday work only peripherally. Due to the special responsibility of parliaments, governments, and administrations as the organizational instances of society, and through the inherent legitimations by society itself, there is a necessity to examine the implications of the use of generative LLMs within these institutions and traditional structures as well as their influence on political system logic. The paper analyzes the responses that the generative LLMs GPT 3.5 and GPT 4 have provided via ChatGPT, based on the same input command (prompt) over different times. The responses help to assess how LLMs can be used in the parliamentary context, to reflect what dangers exist as well as to respond to the question on how a business model of an AI department in parliament might look like. Furthermore, it shall be explored whether there are fluctuations in the quality of the responses and how these should be evaluated against the backdrop of the need for accurate and precise workflows in parliamentary operations. Ultimately, the paper aims to provide an answer as to whether the application of ChatGPT together with the LLMs GPT-3.5 and GPT-4 could already deliver this necessary quality and consistency for the parliamentarian working environment today.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = {may},
keywords = {large language model, ChatGPT, GPT 3.5, GPT-4, parliament}
}

",https://doi.org/10.1145/3665333,10.1145/3665333,acm,2024
873,Accelerating Scientific Paper Skimming with Augmented Intelligence Through Customizable Faceted Highlights,"@article{10.1145/3665648,
author = {Fok, Raymond and Soldaini, Luca and Trier, Cassidy and Bransom, Erin and MacMillan, Kelsey and Cheng, Evie and Kambhamettu, Hita and Bragg, Jonathan and Lo, Kyle and Hearst, Marti A. and Head, Andrew and Weld, Daniel S.},
title = {Accelerating Scientific Paper Skimming with Augmented Intelligence Through Customizable Faceted Highlights},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2160-6455},
url = {https://doi.org/10.1145/3665648},
doi = {10.1145/3665648},
abstract = {Scholars need to keep up with an exponentially increasing flood of scientific papers. To aid this challenge, we introduce Scim, a novel intelligent interface that helps scholars skim papers to rapidly review and gain a cursory understanding of its contents. Scim supports the skimming process by highlighting salient content within a paper, directing a scholar’s attention. These automatically-extracted highlights are faceted by content type, evenly distributed across a paper, and have a density configurable by scholars. We evaluate Scim with an in-lab usability study and a longitudinal diary study, revealing how its highlights facilitate the more efficient construction of a conceptualization of a paper. Finally, we describe the process of scaling highlights from their conception within Scim, a research prototype, to production on over 521,000 papers within the Semantic Reader, a publicly-available augmented reading interface for scientific papers. We conclude by discussing design considerations and tensions for the design of future skimming tools with augmented intelligence.},
note = {Just Accepted},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {may},
keywords = {Intelligent reading interfaces, skimming, highlights, scientific papers}
}

",https://doi.org/10.1145/3665648,10.1145/3665648,acm,2024
874,A Reasoning and Value Alignment Test to Assess Advanced GPT Reasoning,"@article{10.1145/3670691,
author = {McIntosh, Timothy R. and Liu, Tong and Susnjak, Teo and Watters, Paul and Halgamuge, Malka N.},
title = {A Reasoning and Value Alignment Test to Assess Advanced GPT Reasoning},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2160-6455},
url = {https://doi.org/10.1145/3670691},
doi = {10.1145/3670691},
abstract = {In response to diverse perspectives on Artificial General Intelligence (AGI), ranging from potential safety and ethical concerns to more extreme views about the threats it poses to humanity, this research presents a generic method to gauge the reasoning capabilities of Artificial Intelligence (AI) models as a foundational step in evaluating safety measures. Recognizing that AI reasoning measures cannot be wholly automated, due to factors such as cultural complexity, we conducted an extensive examination of five commercial Generative Pre-trained Transformers (GPTs), focusing on their comprehension and interpretation of culturally intricate contexts. Utilizing our novel “Reasoning and Value Alignment Test”, we assessed the GPT models’ ability to reason in complex situations and grasp local cultural subtleties. Our findings have indicated that, although the models have exhibited high levels of human-like reasoning, significant limitations remained, especially concerning the interpretation of cultural contexts. This paper also explored potential applications and use-cases of our Test, underlining its significance in AI training, ethics compliance, sensitivity auditing, and AI-driven cultural consultation. We concluded by emphasizing its broader implications in the AGI domain, highlighting the necessity for interdisciplinary approaches, wider accessibility to various GPT models, and a profound understanding of the interplay between GPT reasoning and cultural sensitivity.},
note = {Just Accepted},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {jun},
keywords = {Large Language Model (LLM), Cultural Sensitivity, Reasoning and Value Alignment Test, AI Training and Assessment, Cross-Cultural AI Applications, AI Model Limitations}
}

",https://doi.org/10.1145/3670691,10.1145/3670691,acm,2024
875,ID.8: Co-Creating Visual Stories with Generative AI,"@article{10.1145/3672277,
author = {Antony, Victor Nikhil and Huang, Chien-Ming},
title = {ID.8: Co-Creating Visual Stories with Generative AI},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2160-6455},
url = {https://doi.org/10.1145/3672277},
doi = {10.1145/3672277},
abstract = {Storytelling is an integral part of human culture and significantly impacts cognitive and socio-emotional development and connection. Despite the importance of interactive visual storytelling, the process of creating such content requires specialized skills and is labor-intensive. This paper introduces ID.8, an open-source system designed for the co-creation of visual stories with generative AI. We focus on enabling an inclusive storytelling experience by simplifying the content creation process and allowing for customization. Our user evaluation confirms a generally positive user experience in domains such as enjoyment and exploration, while highlighting areas for improvement, particularly in immersiveness, alignment, and partnership between the user and the AI system. Overall, our findings indicate promising possibilities for empowering people to create visual stories with generative AI. This work contributes a novel content authoring system, ID.8, and insights into the challenges and potential of using generative AI for multimedia content creation.},
note = {Just Accepted},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {jun},
keywords = {Storytelling, Generative AI, Creativity}
}

",https://doi.org/10.1145/3672277,10.1145/3672277,acm,2024
876,Self-planning Code Generation with Large Language Models,"@article{10.1145/3672456,
author = {Jiang, Xue and Dong, Yihong and Wang, Lecheng and Zheng, Fang and Shang, Qiwei and Li, Ge and Jin, Zhi and Jiao, Wenpin},
title = {Self-planning Code Generation with Large Language Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672456},
doi = {10.1145/3672456},
abstract = {Although large language models (LLMs) have demonstrated impressive ability in code generation, they are still struggling to address the complicated intent provided by humans. It is widely acknowledged that humans typically employ planning to decompose complex problems and schedule solution steps prior to implementation. To this end, we introduce planning into code generation to help the model understand complex intent and reduce the difficulty of problem-solving. This paper proposes a self-planning code generation approach with large language models, which consists of two phases, namely planning phase and implementation phase. Specifically, in the planning phase, LLM plans out concise solution steps from the intent combined with few-shot prompting. Subsequently, in the implementation phase, the model generates code step by step, guided by the preceding solution steps. We conduct extensive experiments on various code-generation benchmarks across multiple programming languages. Experimental results show that self-planning code generation achieves a relative improvement of up to 25.4% in Pass@1 compared to direct code generation, and up to 11.9% compared to Chain-of-Thought of code generation. Moreover, our self-planning approach also enhances the quality of the generated code with respect to correctness, readability, and robustness, as assessed by humans.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun}
}

",https://doi.org/10.1145/3672456,10.1145/3672456,acm,2024
877,Revealing the Unseen: AI Chain on LLMs for Predicting Implicit Data Flows to Generate Data Flow Graphs in Dynamically-Typed Code,"@article{10.1145/3672458,
author = {Huang, Qing and Luo, Zhiwen and Xing, Zhenchang and Zeng, Jinshan and Chen, Jieshan and Xu, Xiwei and Chen, Yong},
title = {Revealing the Unseen: AI Chain on LLMs for Predicting Implicit Data Flows to Generate Data Flow Graphs in Dynamically-Typed Code},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672458},
doi = {10.1145/3672458},
abstract = {Data flow graphs (DFGs) capture definitions (defs) and uses across program blocks, which is a fundamental program representation for program analysis, testing and maintenance. However, dynamically-typed programming languages like Python present implicit data flow issues that make it challenging to determine def-use flow information at compile time. Static analysis methods like Soot and WALA are inadequate for handling these issues, and manually enumerating comprehensive heuristic rules is impractical. Large pre-trained language models (LLMs) offer a potential solution, as they have powerful language understanding and pattern matching abilities, allowing them to predict implicit data flow by analyzing code context and relationships between variables, functions, and statements in code. We propose leveraging LLMs’ in-context learning ability to learn implicit rules and patterns from code representation and contextual information to solve implicit data flow problems. To further enhance the accuracy of LLMs, we design a five-step Chain of Thought (CoT) and break it down into an AI chain, with each step corresponding to a separate AI unit to generate accurate DFGs for Python code. Our approach’s performance is thoroughly assessed, demonstrating the effectiveness of each AI unit in the AI Chain. Compared to static analysis, our method achieves 82% higher def coverage and 58% higher use coverage in DFG generation on implicit data flow. We also prove the indispensability of each unit in the AI Chain. Overall, our approach offers a promising direction for building software engineering tools by utilizing foundation models, eliminating significant engineering and maintenance effort, but focusing on identifying problems for AI to solve.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
keywords = {Data Flow Graph, AI Chain, Large Language Model}
}

",https://doi.org/10.1145/3672458,10.1145/3672458,acm,2024
878,Self-collaboration Code Generation via ChatGPT,"@article{10.1145/3672459,
author = {Dong, Yihong and Jiang, Xue and Jin, Zhi and Li, Ge},
title = {Self-collaboration Code Generation via ChatGPT},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672459},
doi = {10.1145/3672459},
abstract = {Although Large Language Models (LLMs) have demonstrated remarkable code-generation ability, they still struggle with complex tasks. In real-world software development, humans usually tackle complex tasks through collaborative teamwork, a strategy that significantly controls development complexity and enhances software quality. Inspired by this, we present a self-collaboration framework for code generation employing LLMs, exemplified by ChatGPT. Specifically, through role instructions, 1) Multiple LLM agents act as distinct ‘experts’, each responsible for a specific subtask within a complex task; 2) Specify the way to collaborate and interact, so that different roles form a virtual team to facilitate each other’s work, ultimately the virtual team addresses code generation tasks collaboratively without the need for human intervention. To effectively organize and manage this virtual team, we incorporate software-development methodology into the framework. Thus, we assemble an elementary team consisting of three LLM roles (i.e., analyst, coder, and tester) responsible for software development’s analysis, coding, and testing stages. We conduct comprehensive experiments on various code-generation benchmarks. Experimental results indicate that self-collaboration code generation relatively improves 29.9%-47.1% Pass@1 compared to the base LLM agent. Moreover, we showcase that self-collaboration could potentially enable LLMs to efficiently handle complex repository-level tasks that are not readily solved by the single LLM agent.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
keywords = {Code Generation, Large Language Models, Multi-Agent Collaboration, Software Development}
}

",https://doi.org/10.1145/3672459,10.1145/3672459,acm,2024
879,In Silico Human Mobility Data Science: Leveraging Massive Simulated Mobility Data (Vision Paper),"@article{10.1145/3672557,
author = {Z\""{u}fle, Andreas and Pfoser, Dieter and Wenk, Carola and Crooks, Andrew and Kavak, Hamdi and Anderson, Taylor and Kim, Joon-Seok and Holt, Nathan and DiAntonio, Andrew},
title = {In Silico Human Mobility Data Science: Leveraging Massive Simulated Mobility Data (Vision Paper)},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2374-0353},
url = {https://doi.org/10.1145/3672557},
doi = {10.1145/3672557},
abstract = {Human mobility data science using trajectories or check-ins of individuals has many applications. Recently, we have seen a plethora of research efforts that tackle these applications. However, research progress in this field is limited by a lack of large and representative datasets. The largest and most commonly used dataset of individual human trajectories captures fewer than 200 individuals while data sets of individual human check-ins capture fewer than 100 check-ins per city per day. Thus, it is not clear if findings from the human mobility data science community would generalize to large populations. Since obtaining massive, representative, and individual-level human mobility data is hard to come by due to privacy considerations, the vision of this paper is to embrace the use of data generated by large-scale socially realistic microsimulations. Informed by both real data and leveraging social and behavioral theories, massive spatially explicit microsimulations may allow us to simulate entire megacities at the person level. The simulated worlds, which do not capture any identifiable personal information, allow us to perform “in silico” experiments using the simulated world as a sandbox in which we have perfect information and perfect control without jeopardizing the privacy of any actual individual. In silico experiments have become commonplace in other scientific domains such as chemistry and biology, permitting experiments that foster the understanding of concepts without any harm to individuals. This work describes challenges and opportunities for leveraging massive and realistic simulated alternate worlds for in silico human mobility data science.},
note = {Just Accepted},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = {jun},
keywords = {Spatial Simulation, Mobility Data Science, Trajectory Data, Location Based Social Network Data, In Silico}
}

",https://doi.org/10.1145/3672557,10.1145/3672557,acm,2024
880,The Social Cognition Ability Evaluation of LLMs: A Dynamic Gamified Assessment and Hierarchical Social Learning Measurement Approach,"@article{10.1145/3673238,
author = {Ni, Qin and Yu, Yangze and Ma, Yiming and Lin, Xin and Deng, Ciping and Wei, Tingjiang and Xuan, Mo},
title = {The Social Cognition Ability Evaluation of LLMs: A Dynamic Gamified Assessment and Hierarchical Social Learning Measurement Approach},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3673238},
doi = {10.1145/3673238},
abstract = {Large Language Model(LLM) has shown amazing abilities in reasoning tasks, theory of mind(ToM) has been tested in many studies as part of reasoning tasks, and social learning, which is closely related to theory of mind, are still lack of investigation. However, the test methods and materials make the test results unconvincing. We propose a dynamic gamified assessment(DGA) and hierarchical social learning measurement to test ToM and social learning capacities in LLMs. The test for ToM consists of five parts. First, we extract ToM tasks from ToM experiments and then design game rules to satisfy the ToM task requirement. After that, we design ToM questions to match the game’s rules and use these to generate test materials. Finally, we go through the above steps to test the model. To assess the social learning ability, we introduce a novel set of social rules (three in total). Experiment results demonstrate that, except GPT-4, LLMs performed poorly on the ToM test but showed a certain level of social learning ability in social learning measurement.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {jun},
keywords = {Large Language Model, theory of mind, social learning, DGA, and hierarchical social learning measurement}
}

",https://doi.org/10.1145/3673238,10.1145/3673238,acm,2024
881,Evaluating ChatGPT-4 Vision on Brazil’s National Undergraduate Computer Science Exam,"@article{10.1145/3674149,
author = {Mendon\c{c}a, Nabor C.},
title = {Evaluating ChatGPT-4 Vision on Brazil’s National Undergraduate Computer Science Exam},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674149},
doi = {10.1145/3674149},
abstract = {The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI’s most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil’s 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam’s open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model’s reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. A positive correlation between the model’s performance in multiple-choice questions and the performance distribution of the human participants suggests multimodal LLMs can provide a useful tool for question testing and refinement. However, the involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model’s accuracy and ensuring the fairness of high-stakes educational exams. The paper’s research materials are publicly available at .},
note = {Just Accepted},
journal = {ACM Trans. Comput. Educ.},
month = {jun},
keywords = {Multimodal Generative AI, ChatGPT-4 Vision, Educational Assessment, Computer Science Education}
}

",https://doi.org/10.1145/3674149,10.1145/3674149,acm,2024
882,Technical Report Column,"@article{10.1145/3674159.3674162,
author = {Kelley, Dean},
title = {Technical Report Column},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {2},
issn = {0163-5700},
url = {https://doi.org/10.1145/3674159.3674162},
doi = {10.1145/3674159.3674162},
abstract = {Welcome to the Technical Reports Column. If your institution publishes technical reports that you'd like to have included here, please contact me at the email address above.},
journal = {SIGACT News},
month = {jun},
pages = {25–37},
numpages = {13}
}

",https://doi.org/10.1145/3674159.3674162,10.1145/3674159.3674162,acm,2024
883,ForestQB: Enhancing Linked Data Exploration through Graphical and Conversational UIs Integration,"@article{10.1145/3675759,
author = {Mussa, Omar and Rana, Omer and Goossens, Benoit and Orozco Ter Wengel, Pablo and Perera, Charith},
title = {ForestQB: Enhancing Linked Data Exploration through Graphical and Conversational UIs Integration},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675759},
doi = {10.1145/3675759},
abstract = {This paper introduces the Forest Query Builder (ForestQB), an innovative toolkit designed to enhance the exploration and application of observational Linked Data (LD) within the field of wildlife research and conservation. Addressing the challenges faced by non-experts in navigating Resource Description Framework (RDF) triplestores and executing SPARQL queries, ForestQB employs a novel integrated approach. This approach combines a graphical user interface (GUI) with a conversational user interface (CUI), thereby greatly simplifying the process of query formulation and making observational LD accessible to users without expertise in RDF or SPARQL. Developed through insights derived from a comprehensive ethnographic study involving wildlife researchers, ForestQB is specifically designed to improve the accessibility of SPARQL endpoints and facilitate the exploration of observational LD in wildlife research contexts. To evaluate the effectiveness of our approach, we conducted a user experiment. The results of this evaluation affirm that ForestQB is not only efficient and user-friendly but also plays a crucial role in eliminating barriers for users, facilitating the effective use of observational LD in wildlife conservation and extending its benefits to wider domains. (GitHub Link)},
note = {Just Accepted},
journal = {ACM J. Comput. Sustain. Soc.},
month = {jun},
keywords = {Linked Data, SPARQL, RDF, Query Builder, Visual Querying}
}

",https://doi.org/10.1145/3675759,10.1145/3675759,acm,2024
884,ChatGPT on ChatGPT: An Exploratory Analysis of its Performance in the Public Sector Workplace,"@article{10.1145/3676281,
author = {Wang, Jieshu and Kiran, Elif and Aurora, S.R. and Simeone, Michael and Lobo, Jose},
title = {ChatGPT on ChatGPT: An Exploratory Analysis of its Performance in the Public Sector Workplace},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676281},
doi = {10.1145/3676281},
abstract = {This study explores the impact of Generative Artificial Intelligence (GenAI), in particular, ChatGPT, on the public sector workforce in the United States, focusing on task replacement, assistance potential, and the evolving landscape of skills. Utilizing GPT-4 to evaluate 1,022 core tasks across 51 public sector occupations, we provide an exploratory analysis of the roles susceptible to ChatGPT automation and those in which ChatGPT can augment human efforts. Our findings reveal that while 63% of tasks are resistant to ChatGPT replacement, primarily due to their requirement for physical presence, emotional intelligence, and complex decision-making, tasks that are routine, rule-based, and involving basic content generation show a high potential for automation. The study also identifies key skills that will remain vital, those likely to become obsolete, and new skills that will emerge as essential, highlighting the need for a strategic approach to workforce development in the face of AI advancements. In particular, our findings underscore the growing importance of skills in applying AI technologies and the ability to validate and interpret AI-generated content for humans to remain competitive. We offer insights into public-sector-specific impacts and propose a methodological framework for future research, emphasizing the importance of adapting educational curricula and policies to prepare for an AI-integrated future.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = {jul},
keywords = {Public sector, Workforce, Artificial intelligence, Large language models, ChatGPT, Future of work}
}

",https://doi.org/10.1145/3676281,10.1145/3676281,acm,2024
885,Large language models: a primer and gastroenterology applications,"@article{2-s2.0-85186205690,
  title={Large language models: a primer and gastroenterology applications},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186205690&origin=inward,10.1177/17562848241227031,scopus,2024
886,ChatGPT and large language models in academia: opportunities and challenges,"@article{2-s2.0-85165261615,
  title={ChatGPT and large language models in academia: opportunities and challenges},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85165261615&origin=inward,10.1186/s13040-023-00339-9,scopus,2023
887,Text Data Augmentation for Deep Learning," @article{Shorten_2021, title={Text Data Augmentation for Deep Learning}, volume={8}, ISSN={2196-1115}, url={http://dx.doi.org/10.1186/s40537-021-00492-0}, DOI={10.1186/s40537-021-00492-0}, number={1}, journal={Journal of Big Data}, publisher={Springer Science and Business Media LLC}, author={Shorten, Connor and Khoshgoftaar, Taghi M. and Furht, Borko}, year={2021}, month=jul }
",https://link.springer.com/article/10.1186/s40537-021-00492-0,10.1186/s40537-021-00492-0,springer,2021
888,Tabular and latent space synthetic data generation: a literature review," @article{Fonseca_2023, title={Tabular and latent space synthetic data generation: a literature review}, volume={10}, ISSN={2196-1115}, url={http://dx.doi.org/10.1186/s40537-023-00792-7}, DOI={10.1186/s40537-023-00792-7}, number={1}, journal={Journal of Big Data}, publisher={Springer Science and Business Media LLC}, author={Fonseca, Joao and Bacao, Fernando}, year={2023}, month=jul }
",https://link.springer.com/article/10.1186/s40537-023-00792-7,10.1186/s40537-023-00792-7,springer,2023
889,Enhancing academic performance prediction with temporal graph networks for massive open online courses," @article{Huang_2024, title={Enhancing academic performance prediction with temporal graph networks for massive open online courses}, volume={11}, ISSN={2196-1115}, url={http://dx.doi.org/10.1186/s40537-024-00918-5}, DOI={10.1186/s40537-024-00918-5}, number={1}, journal={Journal of Big Data}, publisher={Springer Science and Business Media LLC}, author={Huang, Qionghao and Chen, Jili}, year={2024}, month=apr }
",https://link.springer.com/article/10.1186/s40537-024-00918-5,10.1186/s40537-024-00918-5,springer,2024
890,"Students’ voices on generative AI: perceptions, benefits, and challenges in higher education"," @article{Chan_2023, title={Students’ voices on generative AI: perceptions, benefits, and challenges in higher education}, volume={20}, ISSN={2365-9440}, url={http://dx.doi.org/10.1186/s41239-023-00411-8}, DOI={10.1186/s41239-023-00411-8}, number={1}, journal={International Journal of Educational Technology in Higher Education}, publisher={Springer Science and Business Media LLC}, author={Chan, Cecilia Ka Yuk and Hu, Wenjie}, year={2023}, month=jul }
",https://link.springer.com/article/10.1186/s41239-023-00411-8,10.1186/s41239-023-00411-8,springer,2023
891,AI-generated feedback on writing: insights into efficacy and ENL student preference," @article{Escalante_2023, title={AI-generated feedback on writing: insights into efficacy and ENL student preference}, volume={20}, ISSN={2365-9440}, url={http://dx.doi.org/10.1186/s41239-023-00425-2}, DOI={10.1186/s41239-023-00425-2}, number={1}, journal={International Journal of Educational Technology in Higher Education}, publisher={Springer Science and Business Media LLC}, author={Escalante, Juan and Pack, Austin and Barrett, Alex}, year={2023}, month=oct }
",https://link.springer.com/article/10.1186/s41239-023-00425-2,10.1186/s41239-023-00425-2,springer,2023
892,Role of AI chatbots in education: systematic literature review," @article{Labadze_2023, title={Role of AI chatbots in education: systematic literature review}, volume={20}, ISSN={2365-9440}, url={http://dx.doi.org/10.1186/s41239-023-00426-1}, DOI={10.1186/s41239-023-00426-1}, number={1}, journal={International Journal of Educational Technology in Higher Education}, publisher={Springer Science and Business Media LLC}, author={Labadze, Lasha and Grigolia, Maya and Machaidze, Lela}, year={2023}, month=oct }
",https://link.springer.com/article/10.1186/s41239-023-00426-1,10.1186/s41239-023-00426-1,springer,2023
893,Students’ perceptions of using ChatGPT in a physics class as a virtual tutor," @article{Ding_2023, title={Students’ perceptions of using ChatGPT in a physics class as a virtual tutor}, volume={20}, ISSN={2365-9440}, url={http://dx.doi.org/10.1186/s41239-023-00434-1}, DOI={10.1186/s41239-023-00434-1}, number={1}, journal={International Journal of Educational Technology in Higher Education}, publisher={Springer Science and Business Media LLC}, author={Ding, Lu and Li, Tong and Jiang, Shiyan and Gapud, Albert}, year={2023}, month=dec }
",https://link.springer.com/article/10.1186/s41239-023-00434-1,10.1186/s41239-023-00434-1,springer,2023
894,"A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour"," @article{Bond_2024, title={A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour}, volume={21}, ISSN={2365-9440}, url={http://dx.doi.org/10.1186/s41239-023-00436-z}, DOI={10.1186/s41239-023-00436-z}, number={1}, journal={International Journal of Educational Technology in Higher Education}, publisher={Springer Science and Business Media LLC}, author={Bond, Melissa and Khosravi, Hassan and De Laat, Maarten and Bergdahl, Nina and Negrea, Violeta and Oxley, Emily and Pham, Phuong and Chong, Sin Wang and Siemens, George}, year={2024}, month=jan }
",https://link.springer.com/article/10.1186/s41239-023-00436-z,10.1186/s41239-023-00436-z,springer,2024
895,"Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education"," @article{Walter_2024, title={Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education}, volume={21}, ISSN={2365-9440}, url={http://dx.doi.org/10.1186/s41239-024-00448-3}, DOI={10.1186/s41239-024-00448-3}, number={1}, journal={International Journal of Educational Technology in Higher Education}, publisher={Springer Science and Business Media LLC}, author={Walter, Yoshija}, year={2024}, month=feb }
",https://link.springer.com/article/10.1186/s41239-024-00448-3,10.1186/s41239-024-00448-3,springer,2024
896,Exploring LLM-based Automated Repairing of Ansible Script in Edge-Cloud Infrastructures," @article{Kwon_2023, title={Exploring LLM-based Automated Repairing of Ansible Script in Edge-Cloud Infrastructures}, ISSN={1540-9589}, url={http://dx.doi.org/10.13052/jwe1540-9589.2263}, DOI={10.13052/jwe1540-9589.2263}, journal={Journal of Web Engineering}, publisher={River Publishers}, author={Kwon, Sunjae and Lee, Sungu and Kim, Taehyoun and Ryu, Duksan and Baik, Jongmoon}, year={2023}, month=dec }
",http://dx.doi.org/10.13052/jwe1540-9589.2263,10.13052/jwe1540-9589.2263,web_of_science,2023
897,"Music Curriculum Research Using a Large Language Model, Cloud Computing and Data Mining Technologies"," @article{Shang_2024, title={Music Curriculum Research Using a Large Language Model, Cloud Computing and Data Mining Technologies}, ISSN={1540-9589}, url={http://dx.doi.org/10.13052/jwe1540-9589.2323}, DOI={10.13052/jwe1540-9589.2323}, journal={Journal of Web Engineering}, publisher={River Publishers}, author={Shang, Yuting}, year={2024}, month=apr, pages={251–274} }
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504109,10.13052/jwe1540-9589.2323,ieee,2024
898,Evaluating a large language model’s ability to solve programming exercises from an introductory bioinformatics course,"@article{2-s2.0-85173538194,
  title={Evaluating a large language model’s ability to solve programming exercises from an introductory bioinformatics course},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173538194&origin=inward,10.1371/journal.pcbi.1011511,scopus,2023
899,Practical Application of AI and Large Language Models in Software Engineering Education,"@article{2-s2.0-85184992259,
  title={Practical Application of AI and Large Language Models in Software Engineering Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184992259&origin=inward,10.14569/IJACSA.2024.0150168,scopus,2024
900,How Large Language Models Will Disrupt Data Management,"@article{10.14778/3611479.3611527,
author = {Fernandez, Raul Castro and Elmore, Aaron J. and Franklin, Michael J. and Krishnan, Sanjay and Tan, Chenhao},
title = {How Large Language Models Will Disrupt Data Management},
year = {2023},
issue_date = {July 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611479.3611527},
doi = {10.14778/3611479.3611527},
abstract = {Large language models (LLMs), such as GPT-4, are revolutionizing software's ability to understand, process, and synthesize language. The authors of this paper believe that this advance in technology is significant enough to prompt introspection in the data management community, similar to previous technological disruptions such as the advents of the world wide web, cloud computing, and statistical machine learning. We argue that the disruptive influence that LLMs will have on data management will come from two angles. (1) A number of hard database problems, namely, entity resolution, schema matching, data discovery, and query synthesis, hit a ceiling of automation because the system does not fully understand the semantics of the underlying data. Based on large training corpora of natural language, structured data, and code, LLMs have an unprecedented ability to ground database tuples, schemas, and queries in real-world concepts. We will provide examples of how LLMs may completely change our approaches to these problems. (2) LLMs blur the line between predictive models and information retrieval systems with their ability to answer questions. We will present examples showing how large databases and information retrieval systems have complementary functionality.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {3302–3309},
numpages = {8}
}

",https://doi.org/10.14778/3611479.3611527,10.14778/3611479.3611527,acm,2023
901,FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language,"@article{10.14778/3632093.3632111,
author = {Singh, Mukul and Cambronero, Jos\'{e} and Gulwani, Sumit and Le, Vu and Negreanu, Carina and Nouri, Elnaz and Raza, Mohammad and Verbruggen, Gust},
title = {FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language},
year = {2023},
issue_date = {November 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3632093.3632111},
doi = {10.14778/3632093.3632111},
abstract = {Formatting is an important property in tables for visualization, presentation, and analysis. Spreadsheet software allows users to automatically format their tables by writing data-dependent conditional formatting (CF) rules. Writing such rules is often challenging for users as it requires understanding and implementing the underlying logic. We present FormaT5, a transformer-based model that can generate a CF rule given the target table and a natural language description of the desired formatting logic. We find that user descriptions for these tasks are often under-specified or ambiguous, making it harder for code generation systems to accurately learn the desired rule in a single step. To tackle this problem of under-specification and minimise argument errors, FormaT5 learns to predict placeholders though an abstention objective. These placeholders can then be filled by a second model or, when examples of rows that should be formatted are available, by a programming-by-example system. To evaluate FormaT5 on diverse and real scenarios, we create an extensive benchmark of 1053 CF tasks, containing real-world descriptions collected from four different sources. We release our benchmarks to encourage research in this area. Abstention and filling allow FormaT5 to outperform 8 different neural approaches on our benchmarks, both with and without examples. Our results illustrate the value of building domain-specific learning systems.},
journal = {Proc. VLDB Endow.},
month = {nov},
pages = {497–510},
numpages = {14}
}

",https://doi.org/10.14778/3632093.3632111,10.14778/3632093.3632111,acm,2023
902,Dear ChatGPT - can you teach me how to program an app for laboratory medicine?,"@article{2-s2.0-85193251497,
  title={Dear ChatGPT - can you teach me how to program an app for laboratory medicine?},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193251497&origin=inward,10.1515/labmed-2024-0034,scopus,2024
903,Practical Sentiment Analysis for Education: The Power of Student Crowdsourcing,"@article{2-s2.0-85189644676,
  title={Practical Sentiment Analysis for Education: The Power of Student Crowdsourcing},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189644676&origin=inward,10.1609/aaai.v38i21.30356,scopus,2024
904,Detecting AI-Generated Code Assignments Using Perplexity of Large Language Models,"@article{2-s2.0-85189634956,
  title={Detecting AI-Generated Code Assignments Using Perplexity of Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189634956&origin=inward,10.1609/aaai.v38i21.30361,scopus,2024
905,"A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students'
  Formative Assessment Responses in Science"," @article{Cohn_2024, title={A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students’ Formative Assessment Responses in Science}, volume={38}, ISSN={2159-5399}, url={http://dx.doi.org/10.1609/aaai.v38i21.30364}, DOI={10.1609/aaai.v38i21.30364}, number={21}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, publisher={Association for the Advancement of Artificial Intelligence (AAAI)}, author={Cohn, Clayton and Hutchins, Nicole and Le, Tuan and Biswas, Gautam}, year={2024}, month=mar, pages={23182–23190} }
",http://arxiv.org/pdf/2403.14565v1.pdf,10.1609/aaai.v38i21.30364,arxiv,2024
906,ChatGPT-Generated Code Assignment Detection Using Perplexity of Large Language Models,"@article{2-s2.0-85189633186,
  title={ChatGPT-Generated Code Assignment Detection Using Perplexity of Large Language Models},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85189633186&origin=inward,10.1609/aaai.v38i21.30527,scopus,2024
907,"ChatGPT: potential, prospects, and limitations"," @article{Zhou_2023, title={ChatGPT: potential, prospects, and limitations}, volume={25}, ISSN={2095-9230}, url={http://dx.doi.org/10.1631/FITEE.2300089}, DOI={10.1631/fitee.2300089}, number={1}, journal={Frontiers of Information Technology &amp; Electronic Engineering}, publisher={Zhejiang University Press}, author={Zhou, Jie and Ke, Pei and Qiu, Xipeng and Huang, Minlie and Zhang, Junping}, year={2023}, month=feb, pages={6–11} }
",https://link.springer.com/article/10.1631/FITEE.2300089,10.1631/FITEE.2300089,springer,2023
908,Parallel intelligent education with ChatGPT," @article{Wang_2023, title={ChatGPT辅助的平行智能教育}, volume={25}, ISSN={2095-9230}, url={http://dx.doi.org/10.1631/FITEE.2300166}, DOI={10.1631/fitee.2300166}, number={1}, journal={Frontiers of Information Technology &amp; Electronic Engineering}, publisher={Zhejiang University Press}, author={Wang, Jiacun and Tang, Ying and Hare, Ryan and Wang, Fei-Yue}, year={2023}, month=jun, pages={12–18} }
",https://link.springer.com/article/10.1631/FITEE.2300166,10.1631/FITEE.2300166,springer,2023
909,Six-Writings multimodal processing with pictophonetic coding to enhance Chinese language models," @article{Weigang_2024, title={“六书”多模态处理的形声表征以完善汉语语言模型}, volume={25}, ISSN={2095-9230}, url={http://dx.doi.org/10.1631/FITEE.2300384}, DOI={10.1631/fitee.2300384}, number={1}, journal={Frontiers of Information Technology &amp; Electronic Engineering}, publisher={Zhejiang University Press}, author={Weigang, Li and Marinho, Mayara Chew and Li, Denise Leyi and De Oliveira, Vitor Vasconcelos}, year={2024}, month=jan, pages={84–105} }
",https://link.springer.com/article/10.1631/FITEE.2300384,10.1631/FITEE.2300384,springer,2024
910,Large language model and domain-specific model collaboration for smart education," @article{Luo_2024, title={Large language model and domain-specific model collaboration for smart education}, volume={25}, ISSN={2095-9230}, url={http://dx.doi.org/10.1631/FITEE.2300747}, DOI={10.1631/fitee.2300747}, number={3}, journal={Frontiers of Information Technology &amp; Electronic Engineering}, publisher={Zhejiang University Press}, author={Luo, Yawei and Yang, Yi}, year={2024}, month=mar, pages={333–341} }
",https://link.springer.com/article/10.1631/FITEE.2300747,10.1631/FITEE.2300747,springer,2024
911,"Sora for foundation robots with parallel intelligence: three world models, three robotic systems"," @article{Fan_2024, title={Sora for foundation robots with parallel intelligence: three world models, three robotic systems}, ISSN={2095-9230}, url={http://dx.doi.org/10.1631/FITEE.2400144}, DOI={10.1631/fitee.2400144}, journal={Frontiers of Information Technology &amp; Electronic Engineering}, publisher={Zhejiang University Press}, author={Fan, Lili and Guo, Chao and Tian, Yonglin and Zhang, Hui and Zhang, Jun and Wang, Fei-Yue}, year={2024}, month=apr }
",https://link.springer.com/article/10.1631/FITEE.2400144,10.1631/FITEE.2400144,springer,2024
912,Automatic Generation of Socratic Subquestions for Teaching Math Word Problems,"@inproceedings{shridhar-etal-2022-automatic,
    title = {""Automatic Generation of Socratic Subquestions for Teaching Math Word Problems""},
    editor = {""Goldberg, Yoav  and},
    month = {dec},
    year = {""2022""},
    address = {""Abu Dhabi, United Arab Emirates""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2022.emnlp-main.277""},
    author = {""Shridhar, Kumar  and},
    booktitle = {""Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""4136--4149""},
    abstract = {""Socratic questioning is an educational method that allows students to discover answers to complex problems by asking them a series of thoughtful questions. Generation of didactically sound questions is challenging, requiring understanding of the reasoning process involved in the problem. We hypothesize that such questioning strategy can not only enhance the human performance, but also assist the math word problem (MWP) solvers.In this work, we explore the ability of large language models (LMs) in generating sequential questions for guiding math word problem-solving. We propose various guided question generation schemes based on input conditioning and reinforcement learning.On both automatic and human quality evaluations, we find that LMs constrained with desirable question properties generate superior questions and improve the overall performance of a math word problem solver. We conduct a preliminary user study to examine the potential value of such question generation models in the education domain. Results suggest that the difficulty level of problems plays an important role in determining whether questioning improves or hinders human performance. We discuss the future of using such questioning strategies in education.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2022.emnlp-main.277""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2022.emnlp-main.277,10.18653/v1/2022.emnlp-main.277,acl,2022
913,{ELQA}: A Corpus of Metalinguistic Questions and Answers about {E}nglish,"@inproceedings{behzad-etal-2023-elqa,
    title = {""{ELQA}: A Corpus of Metalinguistic Questions and Answers about {E}nglish""},
    editor = {""Rogers, Anna  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.acl-long.113""},
    author = {""Behzad, Shabnam  and},
    booktitle = {""Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)""},
    pages = {""2031--2047""},
    abstract = {""We present ELQA, a corpus of questions and answers in and about the English language. Collected from two online forums, the {\textgreater}70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology. The answers include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect) usage examples. Unlike most NLP datasets, this corpus is metalinguistic{---}it consists of language about language. As such, it can facilitate investigations of the metalinguistic capabilities of NLU models, as well as educational applications in the language learning domain. To study this, we define a free-form question answering task on our dataset and conduct evaluations on multiple LLMs (Large Language Models) to analyze their capacity to generate metalinguistic answers.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.acl-long.113""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.acl-long.113,10.18653/v1/2023.acl-long.113,acl,2023
914,Teaching Small Language Models to Reason,"@inproceedings{magister-etal-2023-teaching,
    title = {""Teaching Small Language Models to Reason""},
    editor = {""Rogers, Anna  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.acl-short.151""},
    author = {""Magister, Lucie Charlotte  and},
    booktitle = {""Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)""},
    pages = {""1773--1781""},
    abstract = {""Chain of thought prompting successfully improves the reasoning capabilities of large language models, achieving state of the art results on a range of datasets. However, these reasoning capabilities only appear to emerge in models with at least tens of billions of parameters. In this paper, we explore the transfer of such reasoning capabilities to smaller models via knowledge distillation, also investigating model and dataset size trade-off. Specifically, we finetune a student model on the chain of thought outputs generated by a larger teacher model. Our experiments show that the proposed method improves task performance across arithmetic, commonsense and symbolic reasoning datasets. For example, the accuracy of T5 XXL on GSM8K improves from 8.11{\%} to 21.99{\%} and 18.42{\%} when finetuned on PaLM 540B and GPT-3 175B generated chains of thought, respectively.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.acl-short.151""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.acl-short.151,10.18653/v1/2023.acl-short.151,acl,2023
915,{A}rab{I}cros: {AI}-Powered {A}rabic Crossword Puzzle Generation for Educational Applications,"@inproceedings{zeinalipour-etal-2023-arabicros,
    title = {""{A}rab{I}cros: {AI}-Powered {A}rabic Crossword Puzzle Generation for Educational Applications""},
    editor = {""Sawaf, Hassan  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore (Hybrid)""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.arabicnlp-1.23""},
    author = {""Zeinalipour, Kamyar  and},
    booktitle = {""Proceedings of ArabicNLP 2023""},
    pages = {""288--301""},
    abstract = {""This paper presents the first Arabic crossword puzzle generator driven by advanced AI technology. Leveraging cutting-edge large language models including GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system generates distinctive and challenging clues. Based on a dataset comprising over 50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot learning strategies, and rigorous quality-checking protocols to enforce the generation of high-quality clue-answer pairs. Importantly, educational crosswords contribute to enhancing memory, expanding vocabulary, and promoting problem-solving skills, thereby augmenting the learning experience through a fun and engaging approach, reshaping the landscape of traditional learning methods. The overall system can be exploited as a powerful educational tool that amalgamates AI and innovative learning techniques, heralding a transformative era for Arabic crossword puzzles and the intersection of technology and education.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.arabicnlp-1.23""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.arabicnlp-1.23,10.18653/v1/2023.arabicnlp-1.23,acl,2023
916,Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series,"@inproceedings{baffour-etal-2023-analyzing,
    title = {""Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.21""},
    author = {""Baffour, Perpetual  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""242--246""},
    abstract = {""This paper analyzes winning solutions from the Feedback Prize competition series hosted from 2021-2022. The competition sought to improve Assisted Writing Feedback Tools (AWFTs) by crowdsourcing Large Language Model (LLM) solutions for evaluating student writing. The winning models are freely available for incorporation into educational applications, but the models need to be assessed for performance and other factors. This study reports the performance accuracy of Feedback Prize-winning models based on demographic factors such as student race/ethnicity, economic disadvantage, and English Language Learner status. Two competitions are analyzed. The first, which focused on identifying discourse elements, demonstrated minimal bias based on students{'} demographic factors. However, the second competition, which aimed to predict discourse effectiveness, exhibited moderate bias.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.21""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.21,10.18653/v1/2023.bea-1.21,acl,2023
917,{SIGHT}: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts,"@inproceedings{wang-etal-2023-sight,
    title = {""{SIGHT}: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.27""},
    author = {""Wang, Rose  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""315--351""},
    abstract = {""Lectures are a learning experience for both students and teachers. Students learn from teachers about the subject material, while teachers learn from students about how to refine their instruction. Unfortunately, online student feedback is unstructured and abundant, making it challenging for teachers to learn and improve. We take a step towards tackling this challenge. First, we contribute a dataset for studying this problem: SIGHT is a large dataset of 288 math lecture transcripts and 15,784 comments collected from the Massachusetts Institute of Technology OpenCourseWare (MIT OCW) YouTube channel. Second, we develop a rubric for categorizing feedback types using qualitative analysis. Qualitative analysis methods are powerful in uncovering domain-specific insights, however they are costly to apply to large data sources. To overcome this challenge, we propose a set of best practices for using large language models (LLMs) to cheaply classify the comments at scale. We observe a striking correlation between the model{'}s and humans{'} annotation: Categories with consistent human annotations (0.9 inter-rater reliability, IRR) also display higher human-model agreement (0.7), while categories with less consistent human annotations (0.7-0.8 IRR) correspondingly demonstrate lower human-model agreement (0.3-0.5). These techniques uncover useful student feedback from thousands of comments, costing around {\$}0.002 per comment. We conclude by discussing exciting future directions on using online student feedback and improving automated annotation techniques for qualitative research.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.27""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.27,10.18653/v1/2023.bea-1.27,acl,2023
918,Automated evaluation of written discourse coherence using {GPT}-4,"@inproceedings{naismith-etal-2023-automated,
    title = {""Automated evaluation of written discourse coherence using {GPT}-4""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.32""},
    author = {""Naismith, Ben  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""394--403""},
    abstract = {""The popularization of large language models (LLMs) such as OpenAI{'}s GPT-3 and GPT-4 have led to numerous innovations in the field of AI in education. With respect to automated writing evaluation (AWE), LLMs have reduced challenges associated with assessing writing quality characteristics that are difficult to identify automatically, such as discourse coherence. In addition, LLMs can provide rationales for their evaluations (ratings) which increases score interpretability and transparency. This paper investigates one approach to producing ratings by training GPT-4 to assess discourse coherence in a manner consistent with expert human raters. The findings of the study suggest that GPT-4 has strong potential to produce discourse coherence ratings that are comparable to human ratings, accompanied by clear rationales. Furthermore, the GPT-4 ratings outperform traditional NLP coherence metrics with respect to agreement with human ratings. These results have implications for advancing AWE technology for learning and assessment.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.32""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.32,10.18653/v1/2023.bea-1.32,acl,2023
919,Generating Better Items for Cognitive Assessments Using Large Language Models,"@inproceedings{laverghetta-jr-licato-2023-generating,
    title = {""Generating Better Items for Cognitive Assessments Using Large Language Models""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.34""},
    author = {""Laverghetta Jr., Antonio  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""414--428""},
    abstract = {""Writing high-quality test questions (items) is critical to building educational measures but has traditionally also been a time-consuming process. One promising avenue for alleviating this is automated item generation, whereby methods from artificial intelligence (AI) are used to generate new items with minimal human intervention. Researchers have explored using large language models (LLMs) to generate new items with equivalent psychometric properties to human-written ones. But can LLMs generate items with improved psychometric properties, even when existing items have poor validity evidence? We investigate this using items from a natural language inference (NLI) dataset. We develop a novel prompting strategy based on selecting items with both the best and worst properties to use in the prompt and use GPT-3 to generate new NLI items. We find that the GPT-3 items show improved psychometric properties in many cases, whilst also possessing good content, convergent and discriminant validity evidence. Collectively, our results demonstrate the potential of employing LLMs to ease the item development process and suggest that the careful use of prompting may allow for iterative improvement of item quality.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.34""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.34,10.18653/v1/2023.bea-1.34,acl,2023
920,Reviewriter: {AI}-Generated Instructions For Peer Review Writing,"@inproceedings{su-etal-2023-reviewriter,
    title = {""Reviewriter: {AI}-Generated Instructions For Peer Review Writing""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.5""},
    author = {Su, Xiaotian  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""57--71""},
    abstract = {""Large Language Models (LLMs) offer novel opportunities for educational applications that have the potential to transform traditional learning for students. Despite AI-enhanced applications having the potential to provide personalized learning experiences, more studies are needed on the design of generative AI systems and evidence for using them in real educational settings. In this paper, we design, implement and evaluate {\textbackslash}texttt{Reviewriter}, a novel tool to provide students with AI-generated instructions for writing peer reviews in German. Our study identifies three key aspects: a) we provide insights into student needs when writing peer reviews with generative models which we then use to develop a novel system to provide adaptive instructions b) we fine-tune three German language models on a selected corpus of 11,925 student-written peer review texts in German and choose German-GPT2 based on quantitative measures and human evaluation, and c) we evaluate our tool with fourteen students, revealing positive technology acceptance based on quantitative measures. Additionally, the qualitative feedback presents the benefits and limitations of generative AI in peer review writing.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.5""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.5,10.18653/v1/2023.bea-1.5,acl,2023
921,Evaluating Reading Comprehension Exercises Generated by {LLM}s: A Showcase of {C}hat{GPT} in Education Applications,"@inproceedings{xiao-etal-2023-evaluating,
    title = {""Evaluating Reading Comprehension Exercises Generated by {LLM}s: A Showcase of {C}hat{GPT} in Education Applications""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.52""},
    author = {""Xiao, Changrong  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""610--625""},
    abstract = {""The recent advancement of pre-trained Large Language Models (LLMs), such as OpenAI{'}s ChatGPT, has led to transformative changes across fields. For example, developing intelligent systems in the educational sector that leverage the linguistic capabilities of LLMs demonstrates a visible potential. Though researchers have recently explored how ChatGPT could possibly assist in student learning, few studies have applied these techniques to real-world classroom settings involving teachers and students. In this study, we implement a reading comprehension exercise generation system that provides high-quality and personalized reading materials for middle school English learners in China. Extensive evaluations of the generated reading passages and corresponding exercise questions, conducted both automatically and manually, demonstrate that the system-generated materials are suitable for students and even surpass the quality of existing human-written ones. By incorporating first-hand feedback and suggestions from experienced educators, this study serves as a meaningful pioneering application of ChatGPT, shedding light on the future design and implementation of LLM-based systems in the educational context.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.52""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.52,10.18653/v1/2023.bea-1.52,acl,2023
922,Assessing the efficacy of large language models in generating accurate teacher responses,"@inproceedings{hicke-etal-2023-assessing,
    title = {""Assessing the efficacy of large language models in generating accurate teacher responses""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.60""},
    author = {""Hicke, Yann  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""745--755""},
    abstract = {""(Tack et al., 2023) organized the shared task hosted by the 18th Workshop on Innovative Use of NLP for Building Educational Applications on generation of teacher language in educational dialogues. Following the structure of the shared task, in this study, we attempt to assess the generative abilities of large language models in providing informative and helpful insights to students, thereby simulating the role of a knowledgeable teacher. To this end, we present an extensive evaluation of several benchmarking generative models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT. Additionally, to optimize for pedagogical quality, we fine-tuned the Flan-T5 model using reinforcement learning. Our experimental findings on the Teacher-Student Chatroom Corpus subset indicate the efficacy of GPT-4 over other fine-tuned models, measured using BERTScore and DialogRPT. We hypothesize that several dataset characteristics, including sampling, representativeness, and dialog completeness, pose significant challenges to fine-tuning, thus contributing to the poor generalizability of the fine-tuned models. Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on the model{'}s ability to showcase pedagogical skills.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.60""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.60,10.18653/v1/2023.bea-1.60,acl,2023
923,{RETUYT}-{I}n{C}o at {BEA} 2023 Shared Task: Tuning Open-Source {LLM}s for Generating Teacher Responses,"@inproceedings{baladon-etal-2023-retuyt,
    title = {""{RETUYT}-{I}n{C}o at {BEA} 2023 Shared Task: Tuning Open-Source {LLM}s for Generating Teacher Responses""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.61""},
    author = {""Balad{\'o}n, Alexis  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""756--765""},
    abstract = {""This paper presents the results of our participation in the BEA 2023 shared task, which focuses on generating AI teacher responses in educational dialogues. We conducted experiments using several Open-Source Large Language Models (LLMs) and explored fine-tuning techniques along with prompting strategies, including Few-Shot and Chain-of-Thought approaches. Our best model was ranked 4.5 in the competition with a BertScore F1 of 0.71 and a DialogRPT final (avg) of 0.35. Nevertheless, our internal results did not exactly correlate with those obtained in the competition, which showed the difficulty in evaluating this task. Other challenges we faced were data leakage on the train set and the irregular format of the conversations.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.61""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.61,10.18653/v1/2023.bea-1.61,acl,2023
924,Enhancing Human Summaries for Question-Answer Generation in Education,"@inproceedings{gonzalez-etal-2023-enhancing,
    title = {""Enhancing Human Summaries for Question-Answer Generation in Education""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.9""},
    author = {""Gonzalez, Hannah  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""108--118""},
    abstract = {""We address the problem of generating high-quality question-answer pairs for educational materials. Previous work on this problem showed that using summaries as input improves the quality of question generation (QG) over original textbook text and that human-written summaries result in higher quality QG than automatic summaries. In this paper, a) we show that advances in Large Language Models (LLMs) are not yet sufficient to generate quality summaries for QG and b) we introduce a new methodology for enhancing bullet point student notes into fully fledged summaries and find that our methodology yields higher quality QG. We conducted a large-scale human annotation study of generated question-answer pairs for the evaluation of our methodology. In order to aid in future research, we release a new dataset of 9.2K human annotations of generated questions.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.9""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.bea-1.9,10.18653/v1/2023.bea-1.9,acl,2023
925,Opportunities and Challenges in Neural Dialog Tutoring,"@inproceedings{macina-etal-2023-opportunities,
    title = {""Opportunities and Challenges in Neural Dialog Tutoring""},
    editor = {""Vlachos, Andreas  and},
    month = {may},
    year = {""2023""},
    address = {""Dubrovnik, Croatia""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.eacl-main.173""},
    author = {""Macina, Jakub  and},
    booktitle = {""Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics""},
    pages = {""2357--2372""},
    abstract = {""Designing dialog tutors has been challenging as it involves modeling the diverse and complex pedagogical strategies employed by human tutors. Although there have been significant recent advances in neural conversational systems using large language models and growth in available dialog corpora, dialog tutoring has largely remained unaffected by these advances. In this paper, we rigorously analyze various generative language models on two dialog tutoring datasets for language learning using automatic and human evaluations to understand the new opportunities brought by these advances as well as the challenges we must overcome to build models that would be usable in real educational settings. We find that although current approaches can model tutoring in constrained learning scenarios when the number of concepts to be taught and possible teacher strategies are small, they perform poorly in less constrained scenarios. Our human quality evaluation shows that both models and ground-truth annotations exhibit low performance in terms of equitable tutoring, which measures learning opportunities for students and how engaging the dialog is. To understand the behavior of our models in a real tutoring setting, we conduct a user study using expert annotators and find a significantly large number of model reasoning errors in 45{\%} of conversations. Finally, we connect our findings to outline future work.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.eacl-main.173""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.eacl-main.173,10.18653/v1/2023.eacl-main.173,acl,2023
926,Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency,"@inproceedings{zelikman-etal-2023-generating,
    title = {""Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.135""},
    author = {""Zelikman, Eric  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""2190--2205""},
    abstract = {""Developing an educational test can be expensive and time-consuming, as each item must be written by experts and then evaluated by collecting hundreds of student responses. Moreover, many tests require multiple distinct sets of questions administered throughout the school year to closely monitor students{'} progress, known as parallel tests. In this study, we focus on tests of silent sentence reading efficiency, used to assess students{'} reading ability over time. To generate high-quality parallel tests, we propose to fine-tune large language models (LLMs) to simulate how previous students would have responded to unseen items. With these simulated responses, we can estimate each item{'}s difficulty and ambiguity. We first use GPT-4 to generate new test items following a list of expert-developed rules and then apply a fine-tuned LLM to filter the items based on criteria from psychological measurements. We also propose an optimal-transport-inspired technique for generating parallel tests and show the generated tests closely correspond to the original test{'}s difficulty and reliability based on crowdworker responses. Our evaluation of a generated test with 234 students from grades 2 to 8 produces test scores highly correlated (r=0.93) to those of a standard test form written by human experts and evaluated across thousands of K-12 students.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.135""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.emnlp-main.135,10.18653/v1/2023.emnlp-main.135,acl,2023
927,On the Automatic Generation and Simplification of Children{'}s Stories,"@inproceedings{valentini-etal-2023-automatic,
    title = {""On the Automatic Generation and Simplification of Children{'}s Stories""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.218""},
    author = {""Valentini, Maria  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""3588--3598""},
    abstract = {""With recent advances in large language models (LLMs), the concept of automatically generating children{'}s educational materials has become increasingly realistic. Working toward the goal of age-appropriate simplicity in generated educational texts, we first examine the ability of several popular LLMs to generate stories with properly adjusted lexical and readability levels. We find that, in spite of the growing capabilities of LLMs, they do not yet possess the ability to limit their vocabulary to levels appropriate for younger age groups. As a second experiment, we explore the ability of state-of-the-art lexical simplification models to generalize to the domain of children{'}s stories and, thus, create an efficient pipeline for their automatic generation. In order to test these models, we develop a dataset of child-directed lexical simplification instances, with examples taken from the LLM-generated stories in our first experiment. We find that, while the strongest-performing current lexical simplification models do not perform as well on material designed for children due to their reliance on large language models behind the scenes, some models that still achieve fairly strong results on general data can mimic or even improve their performance on children-directed data with proper fine-tuning, which we conduct using our newly created child-directed simplification dataset.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.218""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.emnlp-main.218,10.18653/v1/2023.emnlp-main.218,acl,2023
928,{``}Mistakes Help Us Grow{''}: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms,"@inproceedings{handa-etal-2023-mistakes,
    title = {""{``}Mistakes Help Us Grow{''}: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.549""},
    author = {""Handa, Kunal  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""8877--8897""},
    abstract = {""Teachers{'} growth mindset supportive language (GMSL){---}rhetoric emphasizing that one{'}s skills can be improved over time{---}has been shown to significantly reduce disparities in academic achievement and enhance students{'} learning outcomes. Although teachers espouse growth mindset principles, most find it difficult to adopt GMSL in their practice due the lack of effective coaching in this area. We explore whether large language models (LLMs) can provide automated, personalized coaching to support teachers{'} use of GMSL. We establish an effective coaching tool to reframe unsupportive utterances to GMSL by developing (i) a parallel dataset containing GMSL-trained teacher reframings of unsupportive statements with an accompanying annotation guide, (ii) a GMSL prompt framework to revise teachers{'} unsupportive language, and (iii) an evaluation framework grounded in psychological theory for evaluating GMSL with the help of students and teachers. We conduct a large-scale evaluation involving 174 teachers and 1,006 students, finding that both teachers and students perceive GMSL-trained teacher and model reframings as more effective in fostering a growth mindset and promoting challenge-seeking behavior, among other benefits. We also find that model-generated reframings outperform those from the GMSL-trained teachers. These results show promise for harnessing LLMs to provide automated GMSL feedback for teachers and, more broadly, LLMs{'} potentiality for supporting students{'} learning in the classroom. Our findings also demonstrate the benefit of large-scale human evaluations when applying LLMs in educational domains.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.549""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.emnlp-main.549,10.18653/v1/2023.emnlp-main.549,acl,2023
929,Hidding the Ghostwriters: An Adversarial Evaluation of {AI}-Generated Student Essay Detection,"@inproceedings{peng-etal-2023-hidding,
    title = {""Hidding the Ghostwriters: An Adversarial Evaluation of {AI}-Generated Student Essay Detection""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.644""},
    author = {""Peng, Xinlin  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""10406--10419""},
    abstract = {""Large language models (LLMs) have exhibited remarkable capabilities in text generation tasks. However, the utilization of these models carries inherent risks, including but not limited to plagiarism, the dissemination of fake news, and issues in educational exercises. Although several detectors have been proposed to address these concerns, their effectiveness against adversarial perturbations, specifically in the context of student essay writing, remains largely unexplored. This paper aims to bridge this gap by constructing AIG-ASAP, an AI-generated student essay dataset, employing a range of text perturbation methods that are expected to generate high-quality essays while evading detection. Through empirical experiments, we assess the performance of current AIGC detectors on the AIG-ASAP dataset. The results reveal that the existing detectors can be easily circumvented using straightforward automatic adversarial attacks. Specifically, we explore word substitution and sentence substitution perturbation methods that effectively evade detection while maintaining the quality of the generated essays. This highlights the urgent need for more accurate and robust methods to detect AI-generated student essays in the education domain. Code and data are released for public use.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.644""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.emnlp-main.644,10.18653/v1/2023.emnlp-main.644,acl,2023
930,Large Language Models Only Pass Primary School Exams in {I}ndonesia: A Comprehensive Test on {I}ndo{MMLU},"@inproceedings{koto-etal-2023-large,
    title = {""Large Language Models Only Pass Primary School Exams in {I}ndonesia: A Comprehensive Test on {I}ndo{MMLU}""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.760""},
    author = {""Koto, Fajri  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""12359--12374""},
    abstract = {""Although large language models (LLMs) are often pre-trained on large-scale multilingual texts, their reasoning abilities and real-world knowledge are mainly evaluated based on English datasets. Assessing LLM capabilities beyond English is increasingly vital but hindered due to the lack of suitable datasets. In this work, we introduce IndoMMLU, the first multi-task language understanding benchmark for Indonesian culture and languages, which consists of questions from primary school to university entrance exams in Indonesia. By employing professional teachers, we obtain 14,981 questions across 64 tasks and education levels, with 46{\%} of the questions focusing on assessing proficiency in the Indonesian language and knowledge of nine local languages and cultures in Indonesia. Our empirical evaluations show that GPT-3.5 only manages to pass the Indonesian primary school level, with limited knowledge of local Indonesian languages and culture. Other smaller models such as BLOOMZ and Falcon perform at even lower levels.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.760""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.emnlp-main.760,10.18653/v1/2023.emnlp-main.760,acl,2023
931,Let {GPT} be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation,"@inproceedings{liang-etal-2023-gpt,
    title = {""Let {GPT} be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.889""},
    author = {""Liang, Zhenwen  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""14384--14396""},
    abstract = {""In this paper, we present a novel approach for distilling math word problem solving capabilities from large language models (LLMs) into smaller, more efficient student models. Our approach is designed to consider the student model{'}s weaknesses and foster a tailored learning experience by generating targeted exercises aligned with educational science principles, such as knowledge tracing and personalized learning. Concretely, we let GPT-3 be a math tutor and run two steps iteratively: 1) assessing the student model{'}s current learning status on a GPT-generated exercise book, and 2) improving the student model by training it with tailored exercise samples generated by GPT-3. Experimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and PaLM) in accuracy across three distinct benchmarks while employing significantly fewer parameters. Furthermore, we provide a comprehensive analysis of the various components within our methodology to substantiate their efficacy.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.889""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.emnlp-main.889,10.18653/v1/2023.emnlp-main.889,acl,2023
932,{E}du{Q}uick: A Dataset Toward Evaluating Summarization of Informal Educational Content for Social Media,"@inproceedings{kolagar-etal-2023-eduquick,
    title = {""{E}du{Q}uick: A Dataset Toward Evaluating Summarization of Informal Educational Content for Social Media""},
    editor = {Deutsch, Daniel  and},
    month = {nov},
    year = {""2023""},
    address = {""Bali, Indonesia""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.eval4nlp-1.4""},
    author = {""Kolagar, Zahra  and},
    booktitle = {""Proceedings of the 4th Workshop on Evaluation and Comparison of NLP Systems""},
    pages = {""32--48""},
    abstract = {""This study explores the capacity of large language models (LLMs) to efficiently generate summaries of informal educational content tailored for platforms like TikTok. It also investigates how both humans and LLMs assess the quality of these summaries, based on a series of experiments, exploring the potential replacement of human evaluation with LLMs. Furthermore, the study delves into how experienced content creators perceive the utility of automatic summaries for TikTok videos. We employ strategic prompt selection techniques to guide LLMs in producing engaging summaries based on the characteristics of viral TikTok content, including hashtags, captivating hooks, storytelling, and user engagement. The study leverages OpenAI{'}s GPT-4 model to generate TikTok content summaries, aiming to align them with the essential features identified. By employing this model and incorporating human evaluation and expert assessment, this research endeavors to shed light on the intricate dynamics of modern content creation, where AI and human ingenuity converge. Ultimately, it seeks to enhance strategies for disseminating and evaluating educational information effectively in the realm of social media.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.eval4nlp-1.4""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.eval4nlp-1.4,10.18653/v1/2023.eval4nlp-1.4,acl,2023
933,Teaching the Pre-trained Model to Generate Simple Texts for Text Simplification,"@inproceedings{sun-etal-2023-teaching,
    title = {""Teaching the Pre-trained Model to Generate Simple Texts for Text Simplification""},
    editor = {""Rogers, Anna  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-acl.595""},
    author = {""Sun, Renliang  and},
    booktitle = {""Findings of the Association for Computational Linguistics: ACL 2023""},
    pages = {""9345--9355""},
    abstract = {""Randomly masking text spans in ordinary texts in the pre-training stage hardly allows models to acquire the ability to generate simple texts. It can hurt the performance of pre-trained models on text simplification tasks. In this paper, we propose a new continued pre-training strategy to teach the pre-trained model to generate simple texts. We continue pre-training BART, a representative model, to obtain SimpleBART. It consistently and significantly improves the results on lexical simplification, sentence simplification, and document-level simplification tasks over BART. At the end, we compare SimpleBART with several representative large language models (LLMs).""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-acl.595""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-acl.595,10.18653/v1/2023.findings-acl.595,acl,2023
934,Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach,"@inproceedings{zhang-etal-2023-exploring-cognitive,
    title = {""Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.111""},
    author = {""Zhang, Zheyuan  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""1643--1650""},
    abstract = {""Large Language Models (LLMs) have not only exhibited exceptional performance across various tasks, but also demonstrated sparks of intelligence. Recent studies have focused on assessing their capabilities on human exams and revealed their impressive competence in different domains. However, cognitive research on the overall knowledge structure of LLMs is still lacking. In this paper, based on educational diagnostic assessment method, we conduct an evaluation using MoocRadar, a meticulously annotated human test dataset based on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain insights of their cognitive capabilities. This research emphasizes the significance of investigating LLMs{'} knowledge and understanding the disparate cognitive patterns of LLMs. By shedding light on models{'} knowledge, researchers can advance development and utilization of LLMs in a more informed and effective manner.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.111""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.111,10.18653/v1/2023.findings-emnlp.111,acl,2023
935,Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning,"@inproceedings{yen-hsu-2023-three,
    title = {""Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.201""},
    author = {""Yen, An-Zi  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""3055--3069""},
    abstract = {""Due to the remarkable language understanding and generation abilities of large language models (LLMs), their use in educational applications has been explored. However, little work has been done on investigating the pedagogical ability of LLMs in helping students to learn mathematics. In this position paper, we discuss the challenges associated with employing LLMs to enhance students{'} mathematical problem-solving skills by providing adaptive feedback. Apart from generating the wrong reasoning processes, LLMs can misinterpret the meaning of the question, and also exhibit difficulty in understanding the given questions{'} rationales when attempting to correct students{'} answers. Three research questions are formulated.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.201""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.201,10.18653/v1/2023.findings-emnlp.201,acl,2023
936,{M}ath{D}ial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems,"@inproceedings{macina-etal-2023-mathdial,
    title = {""{M}ath{D}ial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.372""},
    author = {""Macina, Jakub  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""5602--5621""},
    abstract = {""While automatic dialogue tutors hold great potential in making education personalized and more accessible, research on such systems has been hampered by a lack of sufficiently large and high-quality datasets. Collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this, we propose a framework to generate such dialogues by pairing human teachers with a Large Language Model (LLM) prompted to represent common student errors. We describe how we use this framework to collect MathDial, a dataset of 3k one-to-one teacher-student tutoring dialogues grounded in multi-step math reasoning problems. While models like GPT-3 are good problem solvers, they fail at tutoring because they generate factually incorrect feedback or are prone to revealing solutions to students too early. To overcome this, we let teachers provide learning opportunities to students by guiding them using various scaffolding questions according to a taxonomy of teacher moves. We demonstrate MathDial and its extensive annotations can be used to finetune models to be more effective tutors (and not just solvers). We confirm this by automatic and human evaluation, notably in an interactive setting that measures the trade-off between student solving success and telling solutions. The dataset is released publicly.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.372""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.372,10.18653/v1/2023.findings-emnlp.372,acl,2023
937,Distilling {C}hat{GPT} for Explainable Automated Student Answer Assessment,"@inproceedings{li-etal-2023-distilling,
    title = {""Distilling {C}hat{GPT} for Explainable Automated Student Answer Assessment""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.399""},
    author = {""Li, Jiazheng  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""6007--6026""},
    abstract = {""Providing explainable and faithful feedback is crucial for automated student answer assessment. In this paper, we introduce a novel framework that explores using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation. We identify the appropriate instructions by prompting ChatGPT with different templates to collect the rationales, where inconsistent rationales are refined to align with marking standards. The refined ChatGPT outputs enable us to fine-tune a smaller language model that simultaneously assesses student answers and provides rationales. Extensive experiments on the benchmark dataset show that the proposed method improves the overall QWK score by 11{\%} compared to ChatGPT. Furthermore, our thorough analysis and human evaluation demonstrate that the rationales generated by our proposed method are comparable to those of ChatGPT. Our approach provides a viable solution to achieve explainable automated assessment in education""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.399""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.399,10.18653/v1/2023.findings-emnlp.399,acl,2023
938,{C}onic10{K}: A Challenging Math Problem Understanding and Reasoning Dataset,"@inproceedings{wu-etal-2023-conic10k,
    title = {""{C}onic10{K}: A Challenging Math Problem Understanding and Reasoning Dataset""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.427""},
    author = {""Wu, Haoyi  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""6444--6458""},
    abstract = {""Mathematical understanding and reasoning are crucial tasks for assessing the capabilities of artificial intelligence (AI). However, existing benchmarks either require just a few steps of reasoning, or only contain a small amount of data in one specific topic, making it hard to analyse AI{'}s behaviour with reference to different problems within a specific topic in detail. In this work, we propose Conic10K, a challenging math problem dataset on conic sections in Chinese senior high school education. Our dataset contains various problems with different reasoning depths, while only the knowledge from conic sections is required. Since the dataset only involves a narrow range of knowledge, it is easy to separately analyse the knowledge a model possesses and the reasoning ability it has. For each problem, we provide a high-quality formal representation, the reasoning steps, and the final solution. Experiments show that existing large language models, including GPT-4, exhibit weak performance on complex reasoning. We hope that our findings could inspire more advanced techniques for precise natural language understanding and reasoning. Our dataset and codes are available at https://github.com/whyNLP/Conic10K.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.427""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.427,10.18653/v1/2023.findings-emnlp.427,acl,2023
939,Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses,"@inproceedings{fan-etal-2023-exploring,
    title = {""Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.496""},
    author = {""Fan, Aysa  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""7406--7421""},
    abstract = {""In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses. We designed targeted prompts for GPT4, guiding it to generate code-tracing questions based on code snippets and descriptions. We established a set of human evaluation metrics to assess the quality of questions produced by the model compared to those created by human experts. Our analysis provides insights into the capabilities and potential of LLMs in generating diverse code-tracing questions. Additionally, we present a unique dataset of human and LLM-generated tracing questions, serving as a valuable resource for both the education and NLP research communities. This work contributes to the ongoing dialogue on the potential uses of LLMs in educational settings.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.496""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.496,10.18653/v1/2023.findings-emnlp.496,acl,2023
940,Salespeople vs {S}ales{B}ot: Exploring the Role of Educational Value in Conversational Recommender Systems,"@inproceedings{murakhovska-etal-2023-salespeople,
    title = {""Salespeople vs {S}ales{B}ot: Exploring the Role of Educational Value in Conversational Recommender Systems""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.657""},
    author = {""Murakhovs{'}ka, Lidiya  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""9823--9838""},
    abstract = {""Making big purchases requires consumers to research or consult a salesperson to gain domain expertise. However, existing conversational recommender systems (CRS) often overlook users{'} lack of background knowledge, focusing solely on gathering preferences. In this work, we define a new problem space for conversational agents that aim to provide both product recommendations and educational value through mixed-type mixed-initiative dialog. We introduce SalesOps, a framework that facilitates the simulation and evaluation of such systems by leveraging recent advancements in large language models (LLMs). We build SalesBot and ShopperBot, a pair of LLM-powered agents that can simulate either side of the framework. A comprehensive human study compares SalesBot against professional salespeople, revealing that although SalesBot approaches professional performance in terms of fluency and informativeness, it lags behind in recommendation quality. We emphasize the distinct limitations both face in providing truthful information, highlighting the challenges of ensuring faithfulness in the CRS context. We release our code and make all data available.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.657""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.657,10.18653/v1/2023.findings-emnlp.657,acl,2023
941,Unraveling Downstream Gender Bias from Large Language Models: A Study on {AI} Educational Writing Assistance,"@inproceedings{wambsganss-etal-2023-unraveling,
    title = {""Unraveling Downstream Gender Bias from Large Language Models: A Study on {AI} Educational Writing Assistance""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.689""},
    author = {Wambsganss, Thiemo  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""10275--10288""},
    abstract = {""Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one in-classroom group with recommender system feature-based suggestions and four groups recruited from Prolific {--} a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis and Word Embedding Association Tests (WEAT), we evaluate the gender bias at various stages of the pipeline: in reviews written by students, in suggestions generated by the models, and in model embeddings directly. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students{'} responses.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.689""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.689,10.18653/v1/2023.findings-emnlp.689,acl,2023
942,{D}etect{LLM}: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text,"@inproceedings{su-etal-2023-detectllm,
    title = {""{D}etect{LLM}: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.827""},
    author = {""Su, Jinyan  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""12395--12412""},
    abstract = {""With the rapid progress of Large language models (LLMs) and the huge amount of text they generate, it becomes impractical to manually distinguish whether a text is machine-generated. The growing use of LLMs in social media and education, prompts us to develop methods to detect machine-generated text, preventing malicious use such as plagiarism, misinformation, and propaganda. In this paper, we introduce two novel zero-shot methods for detecting machine-generated text by leveraging the Log-Rank information. One is called DetectLLM-LRR, which is fast and efficient, and the other is called DetectLLM-NPR, which is more accurate, but slower due to the need for perturbations. Our experiments on three datasets and seven language models show that our proposed methods improve over the state of the art by 3.9 and 1.75 AUROC points absolute. Moreover, DetectLLM-NPR needs fewer perturbations than previous work to achieve the same level of performance, which makes it more practical for real-world use. We also investigate the efficiency-performance trade-off based on users{'} preference for these two measures and provide intuition for using them in practice effectively. We release the data and the code of both methods in https://github.com/mbzuai-nlp/DetectLLM.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.827""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.827,10.18653/v1/2023.findings-emnlp.827,acl,2023
943,Toxicity in chatgpt: Analyzing persona-assigned language models,"@inproceedings{deshpande-etal-2023-toxicity,
    title = {""Toxicity in chatgpt: Analyzing persona-assigned language models""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.88""},
    author = {""Deshpande, Ameet  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""1236--1270""},
    abstract = {""Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Legislation has recognized its significance and recently drafted a {``}Blueprint For An AI Bill Of Rights{''} which calls for domain experts to identify risks and potential impact of AI systems. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to $6\times$, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others ($3\times$ more) irrespective of the assigned persona, reflecting discriminatory biases in the model. Our findings show that multiple provisions in the legislative blueprint are being violated, and we hope that the broader AI community rethinks the efficacy of current safety guardrails and develops better techniques that lead to robust, safe, and trustworthy AI.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.88""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.findings-emnlp.88,10.18653/v1/2023.findings-emnlp.88,acl,2023
944,"Comprehensiveness, Accuracy, and Readability of Exercise Recommendations Provided by an AI-Based Chatbot: Mixed Methods Study"," @article{Zaleski_2024, title={Comprehensiveness, Accuracy, and Readability of Exercise Recommendations Provided by an AI-Based Chatbot: Mixed Methods Study}, volume={10}, ISSN={2369-3762}, url={http://dx.doi.org/10.2196/51308}, DOI={10.2196/51308}, journal={JMIR Medical Education}, publisher={JMIR Publications Inc.}, author={Zaleski, Amanda L and Berkowsky, Rachel and Craig, Kelly Jean Thomas and Pescatello, Linda S}, year={2024}, month=jan, pages={e51308} }
",http://dx.doi.org/10.2196/51308,10.2196/51308,"web_of_science, scopus",2024
945,Training AI Model that Suggests Python Code from Student Requests in Natural Language,"@article{2-s2.0-85185477197,
  title={Training AI Model that Suggests Python Code from Student Requests in Natural Language},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185477197&origin=inward,10.2197/ipsjjip.32.69,scopus,2024
946,Graduate Teacher Education Students Use and Evaluate ChatGPT as an Essay-Writing Tool,"@article{2-s2.0-85196078419,
  title={Graduate Teacher Education Students Use and Evaluate ChatGPT as an Essay-Writing Tool},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196078419&origin=inward,10.24059/olj.v28i2.4373,scopus,2024
947,DISCOVERING INSIGHTS IN LEARNING ANALYTICS THROUGH A MIXED-METHODS FRAMEWORK: APPLICATION TO COMPUTER PROGRAMMING EDUCATION,"@article{2-s2.0-85173949352,
  title={DISCOVERING INSIGHTS IN LEARNING ANALYTICS THROUGH A MIXED-METHODS FRAMEWORK: APPLICATION TO COMPUTER PROGRAMMING EDUCATION},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173949352&origin=inward,10.28945/5182,scopus,2023
948,THE CRISIS OF ARTIFICIAL INTELLIGENCE: A NEW DIGITAL HUMANITIES CURRICULUM FOR HUMAN-CENTRED AI,"@article{2-s2.0-85178898335,
  title={THE CRISIS OF ARTIFICIAL INTELLIGENCE: A NEW DIGITAL HUMANITIES CURRICULUM FOR HUMAN-CENTRED AI},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85178898335&origin=inward,10.3366/ijhac.2023.0310,scopus,2023
949,Revisiting the political biases of ChatGPT," @article{Fujimoto_2023, title={Revisiting the political biases of ChatGPT}, volume={6}, ISSN={2624-8212}, url={http://dx.doi.org/10.3389/frai.2023.1232003}, DOI={10.3389/frai.2023.1232003}, journal={Frontiers in Artificial Intelligence}, publisher={Frontiers Media SA}, author={Fujimoto, Sasuke and Takemoto, Kazuhiro}, year={2023}, month=oct }
",http://dx.doi.org/10.3389/frai.2023.1232003,10.3389/frai.2023.1232003,web_of_science,2023
950,"ChatGPT in Veterinary Medicine: A Practical Guidance of Generative
  Artificial Intelligence in Clinics, Education, and Research"," @article{Chu_2024, title={ChatGPT in veterinary medicine: a practical guidance of generative artificial intelligence in clinics, education, and research}, volume={11}, ISSN={2297-1769}, url={http://dx.doi.org/10.3389/fvets.2024.1395934}, DOI={10.3389/fvets.2024.1395934}, journal={Frontiers in Veterinary Science}, publisher={Frontiers Media SA}, author={Chu, Candice P.}, year={2024}, month=jun }
",http://arxiv.org/pdf/2403.14654v1.pdf,10.3389/fvets.2024.1395934,"arxiv, scopus",2024
951,"ChatGPT for Education and Research: Opportunities, Threats, and Strategies"," @article{Rahman_2023, title={ChatGPT for Education and Research: Opportunities, Threats, and Strategies}, volume={13}, ISSN={2076-3417}, url={http://dx.doi.org/10.3390/app13095783}, DOI={10.3390/app13095783}, number={9}, journal={Applied Sciences}, publisher={MDPI AG}, author={Rahman, Md. Mostafizer and Watanobe, Yutaka}, year={2023}, month=may, pages={5783} }
",http://dx.doi.org/10.3390/app13095783,10.3390/app13095783,"web_of_science, scopus",2023
952,Voice-Controlled Robotics in Early Education: Implementing and Validating Child-Directed Interactions Using a Collaborative Robot and Artificial Intelligence,"@article{2-s2.0-85192750799,
  title={Voice-Controlled Robotics in Early Education: Implementing and Validating Child-Directed Interactions Using a Collaborative Robot and Artificial Intelligence},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85192750799&origin=inward,10.3390/app14062408,scopus,2024
953,The Impact of Large Language Models on Programming Education and Student Learning Outcomes," @article{Jo_t_2024, title={The Impact of Large Language Models on Programming Education and Student Learning Outcomes}, volume={14}, ISSN={2076-3417}, url={http://dx.doi.org/10.3390/app14104115}, DOI={10.3390/app14104115}, number={10}, journal={Applied Sciences}, publisher={MDPI AG}, author={Jošt, Gregor and Taneski, Viktor and Karakatič, Sašo}, year={2024}, month=may, pages={4115} }
",http://dx.doi.org/10.3390/app14104115,10.3390/app14104115,"web_of_science, scopus",2024
954,Teamwork Conflict Management Training and Conflict Resolution Practice via Large Language Models," @article{Aggrawal_2024, title={Teamwork Conflict Management Training and Conflict Resolution Practice via Large Language Models}, volume={16}, ISSN={1999-5903}, url={http://dx.doi.org/10.3390/fi16050177}, DOI={10.3390/fi16050177}, number={5}, journal={Future Internet}, publisher={MDPI AG}, author={Aggrawal, Sakhi and Magana, Alejandra J.}, year={2024}, month=may, pages={177} }
",http://dx.doi.org/10.3390/fi16050177,10.3390/fi16050177,"web_of_science, scopus",2024
955,Qualitative Research Methods for Large Language Models: Conducting Semi-Structured Interviews with ChatGPT and BARD on Computer Science Education,"@article{2-s2.0-85180688010,
  title={Qualitative Research Methods for Large Language Models: Conducting Semi-Structured Interviews with ChatGPT and BARD on Computer Science Education},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180688010&origin=inward,10.3390/informatics10040078,scopus,2023
956,Computer Science Education in ChatGPT Era: Experiences from an Experiment in a Programming Course for Novice Programmers,"@article{2-s2.0-85187912327,
  title={Computer Science Education in ChatGPT Era: Experiences from an Experiment in a Programming Course for Novice Programmers},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85187912327&origin=inward,10.3390/math12050629,scopus,2024
957,Creative Use of OpenAI in Education: Case Studies from Game Development," @article{French_2023, title={Creative Use of OpenAI in Education: Case Studies from Game Development}, volume={7}, ISSN={2414-4088}, url={http://dx.doi.org/10.3390/mti7080081}, DOI={10.3390/mti7080081}, number={8}, journal={Multimodal Technologies and Interaction}, publisher={MDPI AG}, author={French, Fiona and Levi, David and Maczo, Csaba and Simonaityte, Aiste and Triantafyllidis, Stefanos and Varda, Gergo}, year={2023}, month=aug, pages={81} }
",http://dx.doi.org/10.3390/mti7080081,10.3390/mti7080081,"web_of_science, scopus",2023
958,Generative AI for Customizable Learning Experiences,"@article{2-s2.0-85190279516,
  title={Generative AI for Customizable Learning Experiences},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190279516&origin=inward,10.3390/su16073034,scopus,2024
959,Survey of Causal Inference for Knowledge Graphs and Large Language Models,"@article{2-s2.0-85184923445,
  title={Survey of Causal Inference for Knowledge Graphs and Large Language Models},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184923445&origin=inward,10.3778/j.issn.1673-9418.2307065,scopus,2023
960,Potentiality of generative AI tools in higher education: Evaluating ChatGPT's viability as a teaching assistant for introductory programming courses,"@article{2-s2.0-85196750884,
  title={Potentiality of generative AI tools in higher education: Evaluating ChatGPT's viability as a teaching assistant for introductory programming courses},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85196750884&origin=inward,10.3934/steme.2024011,scopus,2024
961,"AI-enhanced Auto-correction of Programming Exercises: How Effective is
  GPT-3.5?"," @article{Azaiz_2023, title={AI-Enhanced Auto-Correction of Programming Exercises: How Effective is GPT-3.5?}, volume={13}, ISSN={2192-4880}, url={http://dx.doi.org/10.3991/ijep.v13i8.45621}, DOI={10.3991/ijep.v13i8.45621}, number={8}, journal={International Journal of Engineering Pedagogy (iJEP)}, publisher={International Association of Online Engineering (IAOE)}, author={Azaiz, Imen and Deckarm, Oliver and Strickroth, Sven}, year={2023}, month=dec, pages={67–83} }
",http://arxiv.org/pdf/2311.10737v1.pdf,10.3991/ijep.v13i8.45621,"arxiv, web_of_science, scopus",2023
962,Unleashing the potential: Positive impacts of generative AI on learning and teaching,"@article{2-s2.0-85182290018,
  title={Unleashing the potential: Positive impacts of generative AI on learning and teaching},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85182290018&origin=inward,10.4018/979-8-3693-0074-9.ch002,scopus,2023
963,"A comprehensive review on large language models exploring applications, challenges, limitations, and future prospects","@article{2-s2.0-85195008648,
  title={A comprehensive review on large language models exploring applications, challenges, limitations, and future prospects},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195008648&origin=inward,10.4018/979-8-3693-3502-4.ch002,scopus,2024
964,Fooling MOSS Detection with Pretrained Language Models,"@misc{https://doi.org/10.48550/arxiv.2201.07406,
  doi = {10.48550/ARXIV.2201.07406},
  url = {https://arxiv.org/abs/2201.07406},
  author = {Biderman, Stella and Raff, Edward},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Fooling MOSS Detection with Pretrained Language Models},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2201.07406v2.pdf,10.48550/arXiv.2201.07406,arxiv,2022
965,"Reshaping Robot Trajectories Using Natural Language Commands: A Study of
  Multi-Modal Data Alignment Using Transformers","@misc{https://doi.org/10.48550/arxiv.2203.13411,
  doi = {10.48550/ARXIV.2203.13411},
  url = {https://arxiv.org/abs/2203.13411},
  author = {Bucker, Arthur and Figueredo, Luis and Haddadin, Sami and Kapoor, Ashish and Ma, Shuang and Bonatti, Rogerio},
  keywords = {Robotics (cs.RO), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Systems and Control (eess.SY), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2203.13411v1.pdf,10.48550/arXiv.2203.13411,arxiv,2022
966,"From Human Days to Machine Seconds: Automatically Answering and
  Generating Machine Learning Final Exams","@misc{https://doi.org/10.48550/arxiv.2206.05442,
  doi = {10.48550/ARXIV.2206.05442},
  url = {https://arxiv.org/abs/2206.05442},
  author = {Drori, Iddo and Zhang, Sarah J. and Shuttleworth, Reece and Zhang, Sarah and Tyser, Keith and Chin, Zad and Lantigua, Pedro and Surbehera, Saisamrit and Hunter, Gregory and Austin, Derek and Tang, Leonard and Hicke, Yann and Simhon, Sage and Karnik, Sathwik and Granberry, Darnell and Udell, Madeleine},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2206.05442v7.pdf,10.48550/arXiv.2206.05442,arxiv,2022
967,Repairing Bugs in Python Assignments Using Large Language Models,"@misc{https://doi.org/10.48550/arxiv.2209.14876,
  doi = {10.48550/ARXIV.2209.14876},
  url = {https://arxiv.org/abs/2209.14876},
  author = {Zhang, Jialu and Cambronero, José and Gulwani, Sumit and Le, Vu and Piskac, Ruzica and Soares, Gustavo and Verbruggen, Gust},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Repairing Bugs in Python Assignments Using Large Language Models},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2209.14876v1.pdf,10.48550/arXiv.2209.14876,arxiv,2022
968,"Robosourcing Educational Resources -- Leveraging Large Language Models
  for Learnersourcing","@misc{https://doi.org/10.48550/arxiv.2211.04715,
  doi = {10.48550/ARXIV.2211.04715},
  url = {https://arxiv.org/abs/2211.04715},
  author = {Denny, Paul and Sarsa, Sami and Hellas, Arto and Leinonen, Juho},
  keywords = {Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Robosourcing Educational Resources -- Leveraging Large Language Models for Learnersourcing},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2211.04715v1.pdf,10.48550/arXiv.2211.04715,arxiv,2022
969,"""I think this is the most disruptive technology"": Exploring Sentiments
  of ChatGPT Early Adopters using Twitter Data","@misc{https://doi.org/10.48550/arxiv.2212.05856,
  doi = {10.48550/ARXIV.2212.05856},
  url = {https://arxiv.org/abs/2212.05856},
  author = {Haque, Mubin Ul and Dharmadasa, Isuru and Sworna, Zarrin Tasnim and Rajapakse, Roshan Namal and Ahmad, Hussain},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {""I think this is the most disruptive technology"": Exploring Sentiments of ChatGPT Early Adopters using Twitter Data},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2212.05856v1.pdf,10.48550/arXiv.2212.05856,arxiv,2022
970,"Red teaming ChatGPT via Jailbreaking: Bias, Robustness, Reliability and
  Toxicity","@misc{https://doi.org/10.48550/arxiv.2301.12867,
  doi = {10.48550/ARXIV.2301.12867},
  url = {https://arxiv.org/abs/2301.12867},
  author = {Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Xing, Zhenchang},
  keywords = {Computation and Language (cs.CL), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Red teaming ChatGPT via Jailbreaking: Bias, Robustness, Reliability and Toxicity},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2301.12867v4.pdf,10.48550/arXiv.2301.12867,arxiv,2023
971,"Generating High-Precision Feedback for Programming Syntax Errors using
  Large Language Models","@misc{https://doi.org/10.48550/arxiv.2302.04662,
  doi = {10.48550/ARXIV.2302.04662},
  url = {https://arxiv.org/abs/2302.04662},
  author = {Phung, Tung and Cambronero, José and Gulwani, Sumit and Kohn, Tobias and Majumdar, Rupak and Singla, Adish and Soares, Gustavo},
  keywords = {Programming Languages (cs.PL), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Generating High-Precision Feedback for Programming Syntax Errors using Large Language Models},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2302.04662v2.pdf,10.48550/arXiv.2302.04662,arxiv,2023
972,"Leveraging Large Language Model and Story-Based Gamification in
  Intelligent Tutoring System to Scaffold Introductory Programming Courses: A
  Design-Based Research Study","@misc{https://doi.org/10.48550/arxiv.2302.12834,
  doi = {10.48550/ARXIV.2302.12834},
  url = {https://arxiv.org/abs/2302.12834},
  author = {Cao, Chen},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Leveraging Large Language Model and Story-Based Gamification in Intelligent Tutoring System to Scaffold Introductory Programming Courses: A Design-Based Research Study},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2302.12834v1.pdf,10.48550/arXiv.2302.12834,arxiv,2023
973,"Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions
  about Code","@misc{https://doi.org/10.48550/arxiv.2303.08033,
  doi = {10.48550/ARXIV.2303.08033},
  url = {https://arxiv.org/abs/2303.08033},
  author = {Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Sakr, Majd},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions about Code},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2303.08033v1.pdf,10.48550/arXiv.2303.08033,arxiv,2023
974,Capabilities of GPT-4 on Medical Challenge Problems,"@misc{https://doi.org/10.48550/arxiv.2303.13375,
  doi = {10.48550/ARXIV.2303.13375},
  url = {https://arxiv.org/abs/2303.13375},
  author = {Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Capabilities of GPT-4 on Medical Challenge Problems},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2303.13375v2.pdf,10.48550/arXiv.2303.13375,arxiv,2023
975,GPT is becoming a Turing machine: Here are some ways to program it,"@misc{https://doi.org/10.48550/arxiv.2303.14310,
  doi = {10.48550/ARXIV.2303.14310},
  url = {https://arxiv.org/abs/2303.14310},
  author = {Jojic, Ana and Wang, Zhen and Jojic, Nebojsa},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {GPT is becoming a Turing machine: Here are some ways to program it},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2303.14310v1.pdf,10.48550/arXiv.2303.14310,arxiv,2023
976,Advances in apparent conceptual physics reasoning in GPT-4,"@misc{https://doi.org/10.48550/arxiv.2303.17012,
  doi = {10.48550/ARXIV.2303.17012},
  url = {https://arxiv.org/abs/2303.17012},
  author = {West, Colin G.},
  keywords = {Physics Education (physics.ed-ph), Artificial Intelligence (cs.AI), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Advances in apparent conceptual physics reasoning in GPT-4},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2303.17012v3.pdf,10.48550/arXiv.2303.17012,arxiv,2023
977,AceCoder: Utilizing Existing Code to Enhance Code Generation,"@misc{https://doi.org/10.48550/arxiv.2303.17780,
  doi = {10.48550/ARXIV.2303.17780},
  url = {https://arxiv.org/abs/2303.17780},
  author = {Li, Jia and Zhao, Yunfei and Li, Yongmin and Li, Ge and Jin, Zhi},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {AceCoder: Utilizing Existing Code to Enhance Code Generation},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2303.17780v3.pdf,10.48550/arXiv.2303.17780,arxiv,2023
978,Teaching Large Language Models to Self-Debug,"@misc{https://doi.org/10.48550/arxiv.2304.05128,
  doi = {10.48550/ARXIV.2304.05128},
  url = {https://arxiv.org/abs/2304.05128},
  author = {Chen, Xinyun and Lin, Maxwell and Schärli, Nathanael and Zhou, Denny},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Teaching Large Language Models to Self-Debug},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2304.05128v2.pdf,10.48550/arXiv.2304.05128,arxiv,2023
979,"Solving Math Word Problems by Combining Language Models With Symbolic
  Solvers","@misc{https://doi.org/10.48550/arxiv.2304.09102,
  doi = {10.48550/ARXIV.2304.09102},
  url = {https://arxiv.org/abs/2304.09102},
  author = {He-Yueya, Joy and Poesia, Gabriel and Wang, Rose E. and Goodman, Noah D.},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Solving Math Word Problems by Combining Language Models With Symbolic Solvers},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2304.09102v1.pdf,10.48550/arXiv.2304.09102,arxiv,2023
980,"Thinking beyond chatbots' threat to education: Visualizations to
  elucidate the writing and coding process","@misc{https://doi.org/10.48550/arxiv.2304.14342,
  doi = {10.48550/ARXIV.2304.14342},
  url = {https://arxiv.org/abs/2304.14342},
  author = {Adhikari, Badri},
  keywords = {Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Thinking beyond chatbots' threat to education: Visualizations to elucidate the writing and coding process},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2304.14342v1.pdf,10.48550/arXiv.2304.14342,arxiv,2023
981,Experiences with Remote Examination Formats in Light of GPT-4,"@misc{https://doi.org/10.48550/arxiv.2305.02198,
  doi = {10.48550/ARXIV.2305.02198},
  url = {https://arxiv.org/abs/2305.02198},
  author = {Dobslaw, Felix and Bergh, Peter},
  keywords = {Computers and Society (cs.CY), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Experiences with Remote Examination Formats in Light of GPT-4},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2305.02198v1.pdf,10.48550/arXiv.2305.02198,arxiv,2023
982,"PaD: Program-aided Distillation Can Teach Small Models Reasoning Better
  than Chain-of-thought Fine-tuning","@misc{https://doi.org/10.48550/arxiv.2305.13888,
  doi = {10.48550/ARXIV.2305.13888},
  url = {https://arxiv.org/abs/2305.13888},
  author = {Zhu, Xuekai and Qi, Biqing and Zhang, Kaiyan and Long, Xinwei and Lin, Zhouhan and Zhou, Bowen},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2305.13888v2.pdf,10.48550/arXiv.2305.13888,arxiv,2023
983,"StudentEval: A Benchmark of Student-Written Prompts for Large Language
  Models of Code","@misc{https://doi.org/10.48550/arxiv.2306.04556,
  doi = {10.48550/ARXIV.2306.04556},
  url = {https://arxiv.org/abs/2306.04556},
  author = {Babe, Hannah McLean and Nguyen, Sydney and Zi, Yangtian and Guha, Arjun and Feldman, Molly Q and Anderson, Carolyn Jane},
  keywords = {Machine Learning (cs.LG), Human-Computer Interaction (cs.HC), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2306.04556v1.pdf,10.48550/arXiv.2306.04556,arxiv,2023
984,"Exploring the MIT Mathematics and EECS Curriculum Using Large Language
  Models","@misc{https://doi.org/10.48550/arxiv.2306.08997,
  doi = {10.48550/ARXIV.2306.08997},
  url = {https://arxiv.org/abs/2306.08997},
  author = {Zhang, Sarah J. and Florin, Samuel and Lee, Ariel N. and Niknafs, Eamon and Marginean, Andrei and Wang, Annie and Tyser, Keith and Chin, Zad and Hicke, Yann and Singh, Nikhil and Udell, Madeleine and Kim, Yoon and Buonassisi, Tonio and Solar-Lezama, Armando and Drori, Iddo},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2306.08997v2.pdf,10.48550/arXiv.2306.08997,arxiv,2023
985,"Can We Trust AI-Generated Educational Content? Comparative Analysis of
  Human and AI-Generated Learning Resources","@misc{https://doi.org/10.48550/arxiv.2306.10509,
  doi = {10.48550/ARXIV.2306.10509},
  url = {https://arxiv.org/abs/2306.10509},
  author = {Denny, Paul and Khosravi, Hassan and Hellas, Arto and Leinonen, Juho and Sarsa, Sami},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Can We Trust AI-Generated Educational Content? Comparative Analysis of Human and AI-Generated Learning Resources},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2306.10509v2.pdf,10.48550/arXiv.2306.10509,arxiv,2023
986,"Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4,
  and Human Tutors","@misc{https://doi.org/10.48550/arxiv.2306.17156,
  doi = {10.48550/ARXIV.2306.17156},
  url = {https://arxiv.org/abs/2306.17156},
  author = {Phung, Tung and Pădurean, Victor-Alexandru and Cambronero, José and Gulwani, Sumit and Kohn, Tobias and Majumdar, Rupak and Singla, Adish and Soares, Gustavo},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2306.17156v3.pdf,10.48550/arXiv.2306.17156,arxiv,2023
987,"Large Language Models (GPT) for automating feedback on programming
  assignments","@misc{https://doi.org/10.48550/arxiv.2307.00150,
  doi = {10.48550/ARXIV.2307.00150},
  url = {https://arxiv.org/abs/2307.00150},
  author = {Pankiewicz, Maciej and Baker, Ryan S.},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Large Language Models (GPT) for automating feedback on programming assignments},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2307.00150v1.pdf,10.48550/arXiv.2307.00150,arxiv,2023
988,What Should Data Science Education Do with Large Language Models?,"@misc{https://doi.org/10.48550/arxiv.2307.02792,
  doi = {10.48550/ARXIV.2307.02792},
  url = {https://arxiv.org/abs/2307.02792},
  author = {Tu, Xinming and Zou, James and Su, Weijie J. and Zhang, Linjun},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {What Should Data Science Education Do with Large Language Models?},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2307.02792v2.pdf,10.48550/arXiv.2307.02792,arxiv,2023
989,"Detecting LLM-Generated Text in Computing Education: A Comparative Study
  for ChatGPT Cases","@misc{https://doi.org/10.48550/arxiv.2307.07411,
  doi = {10.48550/ARXIV.2307.07411},
  url = {https://arxiv.org/abs/2307.07411},
  author = {Orenstrakh, Michael Sheinman and Karnalim, Oscar and Suarez, Carlos Anibal and Liut, Michael},
  keywords = {Computation and Language (cs.CL), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Detecting LLM-Generated Text in Computing Education: A Comparative Study for ChatGPT Cases},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2307.07411v1.pdf,10.48550/arXiv.2307.07411,arxiv,2023
990,Generative Type Inference for Python,"@misc{https://doi.org/10.48550/arxiv.2307.09163,
  doi = {10.48550/ARXIV.2307.09163},
  url = {https://arxiv.org/abs/2307.09163},
  author = {Peng, Yun and Wang, Chaozheng and Wang, Wenxuan and Gao, Cuiyun and Lyu, Michael R.},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Generative Type Inference for Python},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2307.09163v1.pdf,10.48550/arXiv.2307.09163,arxiv,2023
991,"Promptly: Using Prompt Problems to Teach Learners How to Effectively
  Utilize AI Code Generators","@misc{https://doi.org/10.48550/arxiv.2307.16364,
  doi = {10.48550/ARXIV.2307.16364},
  url = {https://arxiv.org/abs/2307.16364},
  author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Promptly: Using Prompt Problems to Teach Learners How to Effectively Utilize AI Code Generators},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2307.16364v1.pdf,10.48550/arXiv.2307.16364,arxiv,2023
992,"Large Language Models for Education: Grading Open-Ended Questions Using
  ChatGPT","@article{https://doi.org/10.48550/arxiv.2307.16696,
  doi = {10.48550/ARXIV.2307.16696},
  url = {https://arxiv.org/abs/2307.16696},
  author = {Pinto, Gustavo and Cardoso-Pereira, Isadora and Ribeiro, Danilo Monteiro and Lucena, Danilo and de Souza, Alberto and Gama, Kiev},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Large Language Models for Education: Grading Open-Ended Questions Using ChatGPT},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2307.16696v2.pdf,10.48550/arXiv.2307.16696,arxiv,2023
993,"Performance of Large Language Models in a Computer Science Degree
  Program","@misc{https://doi.org/10.48550/arxiv.2308.02432,
  doi = {10.48550/ARXIV.2308.02432},
  url = {https://arxiv.org/abs/2308.02432},
  author = {Krüger, Tim and Gref, Michael},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Performance of Large Language Models in a Computer Science Degree Program},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2308.02432v1.pdf,10.48550/arXiv.2308.02432,arxiv,2023
994,Evaluating ChatGPT and GPT-4 for Visual Programming,"@misc{https://doi.org/10.48550/arxiv.2308.02522,
  doi = {10.48550/ARXIV.2308.02522},
  url = {https://arxiv.org/abs/2308.02522},
  author = {Singla, Adish},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Evaluating ChatGPT and GPT-4 for Visual Programming},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2308.02522v1.pdf,10.48550/arXiv.2308.02522,arxiv,2023
995,Exploiting Code Symmetries for Learning Program Semantics,"@misc{https://doi.org/10.48550/arxiv.2308.03312,
  doi = {10.48550/ARXIV.2308.03312},
  url = {https://arxiv.org/abs/2308.03312},
  author = {Pei, Kexin and Li, Weichen and Jin, Qirui and Liu, Shuyang and Geng, Scott and Cavallaro, Lorenzo and Yang, Junfeng and Jana, Suman},
  keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Programming Languages (cs.PL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Exploiting Code Symmetries for Learning Program Semantics},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2308.03312v8.pdf,10.48550/arXiv.2308.03312,arxiv,2023
996,"CodeHelp: Using Large Language Models with Guardrails for Scalable
  Support in Programming Classes","@misc{https://doi.org/10.48550/arxiv.2308.06921,
  doi = {10.48550/ARXIV.2308.06921},
  url = {https://arxiv.org/abs/2308.06921},
  author = {Liffiton, Mark and Sheese, Brad and Savelka, Jaromir and Denny, Paul},
  keywords = {Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2308.06921v1.pdf,10.48550/arXiv.2308.06921,arxiv,2023
997,"ChatLogo: A Large Language Model-Driven Hybrid Natural-Programming
  Language Interface for Agent-based Modeling and Programming","@misc{https://doi.org/10.48550/arxiv.2308.08102,
  doi = {10.48550/ARXIV.2308.08102},
  url = {https://arxiv.org/abs/2308.08102},
  author = {Chen, John and Wilensky, Uri},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {ChatLogo: A Large Language Model-Driven Hybrid Natural-Programming Language Interface for Agent-based Modeling and Programming},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2308.08102v1.pdf,10.48550/arXiv.2308.08102,arxiv,2023
998,"Large Language Models in Introductory Programming Education: ChatGPT's
  Performance and Implications for Assessments","@misc{https://doi.org/10.48550/arxiv.2308.08572,
  doi = {10.48550/ARXIV.2308.08572},
  url = {https://arxiv.org/abs/2308.08572},
  author = {Kiesler, Natalie and Schiffner, Daniel},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Large Language Models in Introductory Programming Education: ChatGPT's Performance and Implications for Assessments},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2308.08572v1.pdf,10.48550/arXiv.2308.08572,arxiv,2023
999,"Large Language Models on Wikipedia-Style Survey Generation: an
  Evaluation in NLP Concepts","@article{https://doi.org/10.48550/arxiv.2308.10410,
  doi = {10.48550/ARXIV.2308.10410},
  url = {https://arxiv.org/abs/2308.10410},
  author = {Gao, Fan and Jiang, Hang and Yang, Rui and Zeng, Qingcheng and Lu, Jinghui and Blum, Moritz and Liu, Dairui and She, Tianwei and Jiang, Yuang and Li, Irene},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Zero v1.0 Universal}
}
",http://arxiv.org/pdf/2308.10410v4.pdf,10.48550/arXiv.2308.10410,arxiv,2023
1000,"Elucidating STEM Concepts through Generative AI: A Multi-modal
  Exploration of Analogical Reasoning","@article{https://doi.org/10.48550/arxiv.2308.10454,
  doi = {10.48550/ARXIV.2308.10454},
  url = {https://arxiv.org/abs/2308.10454},
  author = {Cao, Chen and Ding, Zijian and Lee, Gyeong-Geon and Jiao, Jiajun and Lin, Jionghao and Zhai, Xiaoming},
  keywords = {Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Elucidating STEM Concepts through Generative AI: A Multi-modal Exploration of Analogical Reasoning},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2308.10454v1.pdf,10.48550/arXiv.2308.10454,arxiv,2023
1001,"Exploring the Potential of Large Language Models to Generate Formative
  Programming Feedback","@misc{https://doi.org/10.48550/arxiv.2309.00029,
  doi = {10.48550/ARXIV.2309.00029},
  url = {https://arxiv.org/abs/2309.00029},
  author = {Kiesler, Natalie and Lohr, Dominic and Keuning, Hieke},
  keywords = {Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Exploring the Potential of Large Language Models to Generate Formative Programming Feedback},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2309.00029v1.pdf,10.48550/arXiv.2309.00029,arxiv,2023
1002,"Evaluating the Impact of ChatGPT on Exercises of a Software Security
  Course","@misc{https://doi.org/10.48550/arxiv.2309.10085,
  doi = {10.48550/ARXIV.2309.10085},
  url = {https://arxiv.org/abs/2309.10085},
  author = {Li, Jingyue and Meland, Per Håkon and Notland, Jakob Svennevik and Storhaug, André and Tysse, Jostein Hjortland},
  keywords = {Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Evaluating the Impact of ChatGPT on Exercises of a Software Security Course},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2309.10085v1.pdf,10.48550/arXiv.2309.10085,arxiv,2023
1003,"Teach AI How to Code: Using Large Language Models as Teachable Agents
  for Programming Education","@misc{https://doi.org/10.48550/arxiv.2309.14534,
  doi = {10.48550/ARXIV.2309.14534},
  url = {https://arxiv.org/abs/2309.14534},
  author = {Jin, Hyoungwook and Lee, Seonghee and Shin, Hyungyu and Kim, Juho},
  keywords = {Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2309.14534v3.pdf,10.48550/arXiv.2309.14534,arxiv,2023
1004,PLMM: Personal Large Language Models on Mobile Devices,"@misc{https://doi.org/10.48550/arxiv.2309.14726,
  doi = {10.48550/ARXIV.2309.14726},
  url = {https://arxiv.org/abs/2309.14726},
  author = {Gong, Yuanhao},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Computational Engineering, Finance, and Science (cs.CE), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {PLMM: Personal Large Language Models on Mobile Devices},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2309.14726v2.pdf,10.48550/arXiv.2309.14726,arxiv,2023
1005,"Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4
  Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation","@misc{https://doi.org/10.48550/arxiv.2310.03780,
  doi = {10.48550/ARXIV.2310.03780},
  url = {https://arxiv.org/abs/2310.03780},
  author = {Phung, Tung and Pădurean, Victor-Alexandru and Singh, Anjali and Brooks, Christopher and Cambronero, José and Gulwani, Sumit and Singla, Adish and Soares, Gustavo},
  keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2310.03780v3.pdf,10.48550/arXiv.2310.03780,arxiv,2023
1006,"GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using
  Large Language Models","@misc{https://doi.org/10.48550/arxiv.2310.06225,
  doi = {10.48550/ARXIV.2310.06225},
  url = {https://arxiv.org/abs/2310.06225},
  author = {Silva, Bruno and Nunes, Leonardo and Estevão, Roberto and Aski, Vijay and Chandra, Ranveer},
  keywords = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using Large Language Models},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2310.06225v2.pdf,10.48550/arXiv.2310.06225,arxiv,2023
1007,"Examining the Potential and Pitfalls of ChatGPT in Science and
  Engineering Problem-Solving","@misc{https://doi.org/10.48550/arxiv.2310.08773,
  doi = {10.48550/ARXIV.2310.08773},
  url = {https://arxiv.org/abs/2310.08773},
  author = {Wang, Karen D. and Burkholder, Eric and Wieman, Carl and Salehi, Shima and Haber, Nick},
  keywords = {Artificial Intelligence (cs.AI), Computational Engineering, Finance, and Science (cs.CE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Examining the Potential and Pitfalls of ChatGPT in Science and Engineering Problem-Solving},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2310.08773v2.pdf,10.48550/arXiv.2310.08773,arxiv,2023
1008,"Large Language Models for In-Context Student Modeling: Synthesizing
  Student's Behavior in Visual Programming","@misc{https://doi.org/10.48550/arxiv.2310.10690,
  doi = {10.48550/ARXIV.2310.10690},
  url = {https://arxiv.org/abs/2310.10690},
  author = {Nguyen, Manh Hung and Tschiatschek, Sebastian and Singla, Adish},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Large Language Models for In-Context Student Modeling: Synthesizing Student's Behavior in Visual Programming},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2310.10690v3.pdf,10.48550/arXiv.2310.10690,arxiv,2023
1009,"Impact of Guidance and Interaction Strategies for LLM Use on Learner
  Performance and Perception","@misc{https://doi.org/10.48550/arxiv.2310.13712,
  doi = {10.48550/ARXIV.2310.13712},
  url = {https://arxiv.org/abs/2310.13712},
  author = {Kumar, Harsh and Musabirov, Ilya and Reza, Mohi and Shi, Jiakai and Wang, Xinyuan and Williams, Joseph Jay and Kuzminykh, Anastasia and Liut, Michael},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2310.13712v2.pdf,10.48550/arXiv.2310.13712,arxiv,2023
1010,"Unleashing the potential of prompt engineering in Large Language Models:
  a comprehensive review","@misc{https://doi.org/10.48550/arxiv.2310.14735,
  doi = {10.48550/ARXIV.2310.14735},
  url = {https://arxiv.org/abs/2310.14735},
  author = {Chen, Banghao and Zhang, Zhaofeng and Langrené, Nicolas and Zhu, Shengxin},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.7},
  title = {Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2310.14735v4.pdf,10.48550/arXiv.2310.14735,arxiv,2023
1011,"Open-Ended Instructable Embodied Agents with Memory-Augmented Large
  Language Models","@misc{https://doi.org/10.48550/arxiv.2310.15127,
  doi = {10.48550/ARXIV.2310.15127},
  url = {https://arxiv.org/abs/2310.15127},
  author = {Sarch, Gabriel and Wu, Yue and Tarr, Michael J. and Fragkiadaki, Katerina},
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2310.15127v2.pdf,10.48550/arXiv.2310.15127,arxiv,2023
1012,"Exploring the Potential of Large Language Models in Generating
  Code-Tracing Questions for Introductory Programming Courses","@misc{https://doi.org/10.48550/arxiv.2310.15317,
  doi = {10.48550/ARXIV.2310.15317},
  url = {https://arxiv.org/abs/2310.15317},
  author = {Fan, Aysa Xuemo and Zhang, Ranran Haoran and Paquette, Luc and Zhang, Rui},
  keywords = {Computation and Language (cs.CL), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2310.15317v1.pdf,10.48550/arXiv.2310.15317,arxiv,2023
1013,"Efficient Classification of Student Help Requests in Programming Courses
  Using Large Language Models","@misc{https://doi.org/10.48550/arxiv.2310.20105,
  doi = {10.48550/ARXIV.2310.20105},
  url = {https://arxiv.org/abs/2310.20105},
  author = {Savelka, Jaromir and Denny, Paul and Liffiton, Mark and Sheese, Brad},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Efficient Classification of Student Help Requests in Programming Courses Using Large Language Models},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2310.20105v1.pdf,10.48550/arXiv.2310.20105,arxiv,2023
1014,Students' Perspective on AI Code Completion: Benefits and Challenges,"@misc{https://doi.org/10.48550/arxiv.2311.00177,
  doi = {10.48550/ARXIV.2311.00177},
  url = {https://arxiv.org/abs/2311.00177},
  author = {Takerngsaksiri, Wannita and Warusavitarne, Cleshan and Yaacoub, Christian and Hou, Matthew Hee Keng and Tantithamthavorn, Chakkrit},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Students' Perspective on AI Code Completion: Benefits and Challenges},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2311.00177v2.pdf,10.48550/arXiv.2311.00177,arxiv,2023
1015,"More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve
  Visually Diverse Images of Parsons Problems","@misc{https://doi.org/10.48550/arxiv.2311.04926,
  doi = {10.48550/ARXIV.2311.04926},
  url = {https://arxiv.org/abs/2311.04926},
  author = {Hou, Irene and Man, Owen and Mettille, Sophie and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2311.04926v1.pdf,10.48550/arXiv.2311.04926,arxiv,2023
1016,Prompt Problems: A New Programming Exercise for the Generative AI Era,"@misc{https://doi.org/10.48550/arxiv.2311.05943,
  doi = {10.48550/ARXIV.2311.05943},
  url = {https://arxiv.org/abs/2311.05943},
  author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
  keywords = {Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2311.05943v1.pdf,10.48550/arXiv.2311.05943,arxiv,2023
1017,"From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer
  Multiple-choice Questions for Programming Classes in Higher Education","@misc{https://doi.org/10.48550/arxiv.2311.09518,
  doi = {10.48550/ARXIV.2311.09518},
  url = {https://arxiv.org/abs/2311.09518},
  author = {Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Sakr, Majd},
  keywords = {Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer Multiple-choice Questions for Programming Classes in Higher Education},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2311.09518v1.pdf,10.48550/arXiv.2311.09518,arxiv,2023
1018,"From Concept to Manufacturing: Evaluating Vision-Language Models for
  Engineering Design","@misc{https://doi.org/10.48550/arxiv.2311.12668,
  doi = {10.48550/ARXIV.2311.12668},
  url = {https://arxiv.org/abs/2311.12668},
  author = {Picard, Cyril and Edwards, Kristen M. and Doris, Anna C. and Man, Brandon and Giannone, Giorgio and Alam, Md Ferdous and Ahmed, Faez},
  keywords = {Artificial Intelligence (cs.AI), Computational Engineering, Finance, and Science (cs.CE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {From Concept to Manufacturing: Evaluating Vision-Language Models for Engineering Design},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2311.12668v1.pdf,10.48550/arXiv.2311.12668,arxiv,2023
1019,"Decoding Logic Errors: A Comparative Study on Bug Detection by Students
  and Large Language Models","@misc{https://doi.org/10.48550/arxiv.2311.16017,
  doi = {10.48550/ARXIV.2311.16017},
  url = {https://arxiv.org/abs/2311.16017},
  author = {MacNeil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2311.16017v1.pdf,10.48550/arXiv.2311.16017,arxiv,2023
1020,"Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in
  the Age of Artificial Intelligence","@misc{https://doi.org/10.48550/arxiv.2312.01109,
  doi = {10.48550/ARXIV.2312.01109},
  url = {https://arxiv.org/abs/2312.01109},
  author = {Dunder, Nora and Lundborg, Saga and Viberg, Olga and Wong, Jacqueline},
  keywords = {Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.0},
  title = {Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2312.01109v1.pdf,10.48550/arXiv.2312.01109,arxiv,2023
1021,"Real Customization or Just Marketing: Are Customized Versions of Chat
  GPT Useful?","@misc{https://doi.org/10.48550/arxiv.2312.03728,
  doi = {10.48550/ARXIV.2312.03728},
  url = {https://arxiv.org/abs/2312.03728},
  author = {Garrido-Merchán, Eduardo C. and Arroyo-Barrigüete, Jose L. and Borrás-Pala, Francisco and Escobar-Torres, Leandro and de Ibarreta, Carlos Martínez and Ortiz-Lozano, Jose María and Rua-Vieites, Antonio},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Real Customization or Just Marketing: Are Customized Versions of Chat GPT Useful?},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2312.03728v1.pdf,10.48550/arXiv.2312.03728,arxiv,2023
1022,"Can ChatGPT Play the Role of a Teaching Assistant in an Introductory
  Programming Course?","@misc{https://doi.org/10.48550/arxiv.2312.07343,
  doi = {10.48550/ARXIV.2312.07343},
  url = {https://arxiv.org/abs/2312.07343},
  author = {{Anishka} and Mehta, Atharva and Gupta, Nipun and Balachandran, Aarav and Kumar, Dhruv and Jalote, Pankaj},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2312.07343v2.pdf,10.48550/arXiv.2312.07343,arxiv,2023
1023,"Next-Step Hint Generation for Introductory Programming Using Large
  Language Models","@misc{https://doi.org/10.48550/arxiv.2312.10055,
  doi = {10.48550/ARXIV.2312.10055},
  url = {https://arxiv.org/abs/2312.10055},
  author = {Roest, Lianne and Keuning, Hieke and Jeuring, Johan},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Next-Step Hint Generation for Introductory Programming Using Large Language Models},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2312.10055v1.pdf,10.48550/arXiv.2312.10055,arxiv,2023
1024,"Students' Perceptions and Preferences of Generative Artificial
  Intelligence Feedback for Programming","@misc{https://doi.org/10.48550/arxiv.2312.11567,
  doi = {10.48550/ARXIV.2312.11567},
  url = {https://arxiv.org/abs/2312.11567},
  author = {Zhang, Zhengdong and Dong, Zihan and Shi, Yang and Matsuda, Noboru and Price, Thomas and Xu, Dongkuan},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Students' Perceptions and Preferences of Generative Artificial Intelligence Feedback for Programming},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2312.11567v1.pdf,10.48550/arXiv.2312.11567,arxiv,2023
1025,A Survey on Large Language Models for Software Engineering,"@misc{https://doi.org/10.48550/arxiv.2312.15223,
  doi = {10.48550/ARXIV.2312.15223},
  url = {https://arxiv.org/abs/2312.15223},
  author = {Zhang, Quanjun and Fang, Chunrong and Xie, Yang and Zhang, Yaxin and Yang, Yun and Sun, Weisong and Yu, Shengcheng and Chen, Zhenyu},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Survey on Large Language Models for Software Engineering},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2312.15223v1.pdf,10.48550/arXiv.2312.15223,arxiv,2023
1026,The Earth is Flat? Unveiling Factual Errors in Large Language Models,"@misc{https://doi.org/10.48550/arxiv.2401.00761,
  doi = {10.48550/ARXIV.2401.00761},
  url = {https://arxiv.org/abs/2401.00761},
  author = {Wang, Wenxuan and Shi, Juluan and Tu, Zhaopeng and Yuan, Youliang and Huang, Jen-tse and Jiao, Wenxiang and Lyu, Michael R.},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The Earth is Flat? Unveiling Factual Errors in Large Language Models},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2401.00761v1.pdf,10.48550/arXiv.2401.00761,arxiv,2024
1027,Quokka: An Open-source Large Language Model ChatBot for Material Science,"@misc{https://doi.org/10.48550/arxiv.2401.01089,
  doi = {10.48550/ARXIV.2401.01089},
  url = {https://arxiv.org/abs/2401.01089},
  author = {Yang, Xianjun and Wilson, Stephen D. and Petzold, Linda},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computational Engineering, Finance, and Science (cs.CE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Quokka: An Open-source Large Language Model ChatBot for Material Science},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2401.01089v1.pdf,10.48550/arXiv.2401.01089,arxiv,2024
1028,"Evaluating Large Language Models on the GMAT: Implications for the
  Future of Business Education","@misc{https://doi.org/10.48550/arxiv.2401.02985,
  doi = {10.48550/ARXIV.2401.02985},
  url = {https://arxiv.org/abs/2401.02985},
  author = {Ashrafimoghari, Vahid and Gürkan, Necdet and Suchow, Jordan W.},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2401.02985v1.pdf,10.48550/arXiv.2401.02985,arxiv,2024
1029,"LLM-Powered Code Vulnerability Repair with Reinforcement Learning and
  Semantic Reward","@misc{https://doi.org/10.48550/arxiv.2401.03374,
  doi = {10.48550/ARXIV.2401.03374},
  url = {https://arxiv.org/abs/2401.03374},
  author = {Islam, Nafis Tanveer and Khoury, Joseph and Seong, Andrew and Karkevandi, Mohammad Bahrami and Parra, Gonzalo De La Torre and Bou-Harb, Elias and Najafirad, Peyman},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2401.03374v2.pdf,10.48550/arXiv.2401.03374,arxiv,2024
1030,"Assessing AI Detectors in Identifying AI-Generated Code: Implications
  for Education","@misc{https://doi.org/10.48550/arxiv.2401.03676,
  doi = {10.48550/ARXIV.2401.03676},
  url = {https://arxiv.org/abs/2401.03676},
  author = {Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2401.03676v1.pdf,10.48550/arXiv.2401.03676,arxiv,2024
1031,Automated Assessment of Students' Code Comprehension using LLMs,"@misc{https://doi.org/10.48550/arxiv.2401.05399,
  doi = {10.48550/ARXIV.2401.05399},
  url = {https://arxiv.org/abs/2401.05399},
  author = {Oli, Priti and Banjade, Rabin and Chapagain, Jeevan and Rus, Vasile},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Automated Assessment of Students' Code Comprehension using LLMs},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2401.05399v1.pdf,10.48550/arXiv.2401.05399,arxiv,2023
1032,"Sleeper Agents: Training Deceptive LLMs that Persist Through Safety
  Training","@misc{https://doi.org/10.48550/arxiv.2401.05566,
  doi = {10.48550/ARXIV.2401.05566},
  url = {https://arxiv.org/abs/2401.05566},
  author = {Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and MacDiarmid, Monte and Lanham, Tamera and Ziegler, Daniel M. and Maxwell, Tim and Cheng, Newton and Jermyn, Adam and Askell, Amanda and Radhakrishnan, Ansh and Anil, Cem and Duvenaud, David and Ganguli, Deep and Barez, Fazl and Clark, Jack and Ndousse, Kamal and Sachan, Kshitij and Sellitto, Michael and Sharma, Mrinank and DasSarma, Nova and Grosse, Roger and Kravec, Shauna and Bai, Yuntao and Witten, Zachary and Favaro, Marina and Brauner, Jan and Karnofsky, Holden and Christiano, Paul and Bowman, Samuel R. and Graham, Logan and Kaplan, Jared and Mindermann, Sören and Greenblatt, Ryan and Shlegeris, Buck and Schiefer, Nicholas and Perez, Ethan},
  keywords = {Cryptography and Security (cs.CR), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2401.05566v3.pdf,10.48550/arXiv.2401.05566,arxiv,2024
1033,"Seven Failure Points When Engineering a Retrieval Augmented Generation
  System","@misc{https://doi.org/10.48550/arxiv.2401.05856,
  doi = {10.48550/ARXIV.2401.05856},
  url = {https://arxiv.org/abs/2401.05856},
  author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2401.05856v1.pdf,10.48550/arXiv.2401.05856,arxiv,2024
1034,"Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code
  Generation","@misc{https://doi.org/10.48550/arxiv.2401.06391,
  doi = {10.48550/ARXIV.2401.06391},
  url = {https://arxiv.org/abs/2401.06391},
  author = {Wang, Chong and Zhang, Jian and Feng, Yebo and Li, Tianlin and Sun, Weisong and Liu, Yang and Peng, Xin},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2401.06391v2.pdf,10.48550/arXiv.2401.06391,arxiv,2024
1035,"Survey of Natural Language Processing for Education: Taxonomy,
  Systematic Review, and Future Trends","@misc{https://doi.org/10.48550/arxiv.2401.07518,
  doi = {10.48550/ARXIV.2401.07518},
  url = {https://arxiv.org/abs/2401.07518},
  author = {Lan, Yunshi and Li, Xinyuan and Du, Hanyue and Lu, Xuesong and Gao, Ming and Qian, Weining and Zhou, Aoying},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2401.07518v3.pdf,10.48550/arXiv.2401.07518,arxiv,2024
1036,"Adapting Large Language Models for Education: Foundational Capabilities,
  Potentials, and Challenges","@misc{https://doi.org/10.48550/arxiv.2401.08664,
  doi = {10.48550/ARXIV.2401.08664},
  url = {https://arxiv.org/abs/2401.08664},
  author = {Li, Qingyao and Fu, Lingyue and Zhang, Weiming and Chen, Xianyu and Yu, Jingwei and Xia, Wei and Zhang, Weinan and Tang, Ruiming and Yu, Yong},
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2401.08664v3.pdf,10.48550/arXiv.2401.08664,arxiv,2023
1037,"Interactions with Prompt Problems: A New Way to Teach Programming with
  Large Language Models","@misc{https://doi.org/10.48550/arxiv.2401.10759,
  doi = {10.48550/ARXIV.2401.10759},
  url = {https://arxiv.org/abs/2401.10759},
  author = {Prather, James and Denny, Paul and Leinonen, Juho and Smith, David H. and Reeves, Brent N. and MacNeil, Stephen and Becker, Brett A. and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Kimmel, Bailey},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Interactions with Prompt Problems: A New Way to Teach Programming with Large Language Models},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2401.10759v1.pdf,10.48550/arXiv.2401.10759,arxiv,2024
1038,"""The teachers are confused as well"": A Multiple-Stakeholder Ethics
  Discussion on Large Language Models in Computing Education","@misc{https://doi.org/10.48550/arxiv.2401.12453,
  doi = {10.48550/ARXIV.2401.12453},
  url = {https://arxiv.org/abs/2401.12453},
  author = {Zhou, Kyrie Zhixuan and Kilhoffer, Zachary and Sanfilippo, Madelyn Rose and Underwood, Ted and Gumusel, Ece and Wei, Mengyi and Choudhry, Abhinav and Xiong, Jinjun},
  keywords = {Computers and Society (cs.CY), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {""The teachers are confused as well"": A Multiple-Stakeholder Ethics Discussion on Large Language Models in Computing Education},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2401.12453v1.pdf,10.48550/arXiv.2401.12453,arxiv,2024
1039,"TPD: Enhancing Student Language Model Reasoning via Principle Discovery
  and Guidance","@misc{https://doi.org/10.48550/arxiv.2401.13849,
  doi = {10.48550/ARXIV.2401.13849},
  url = {https://arxiv.org/abs/2401.13849},
  author = {Wang, Haorui and Zhang, Rongzhi and Li, Yinghao and Kong, Lingkai and Zhuang, Yuchen and Chen, Xiusi and Zhang, Chao},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2401.13849v1.pdf,10.48550/arXiv.2401.13849,arxiv,2024
1040,"An Empirical Study on Usage and Perceptions of LLMs in a Software
  Engineering Project","@misc{https://doi.org/10.48550/arxiv.2401.16186,
  doi = {10.48550/ARXIV.2401.16186},
  url = {https://arxiv.org/abs/2401.16186},
  author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences, D.2.3},
  title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2401.16186v1.pdf,10.48550/arXiv.2401.16186,arxiv,2024
1041,Generative AI for Data Science 101: Coding Without Learning To Code,"@misc{https://doi.org/10.48550/arxiv.2401.17647,
  doi = {10.48550/ARXIV.2401.17647},
  url = {https://arxiv.org/abs/2401.17647},
  author = {Bien, Jacob and Mukherjee, Gourab},
  keywords = {Other Statistics (stat.OT), Computation (stat.CO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Generative AI for Data Science 101: Coding Without Learning To Code},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2401.17647v1.pdf,10.48550/arXiv.2401.17647,arxiv,2024
1042,"""Which LLM should I use?"": Evaluating LLMs for tasks performed by
  Undergraduate Computer Science Students","@misc{https://doi.org/10.48550/arxiv.2402.01687,
  doi = {10.48550/ARXIV.2402.01687},
  url = {https://arxiv.org/abs/2402.01687},
  author = {Agarwal, Vibhor and Garg, Madhav Krishan and Dharmavaram, Sahiti and Kumar, Dhruv},
  keywords = {Computers and Society (cs.CY), Human-Computer Interaction (cs.HC), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {""Which LLM should I use?"": Evaluating LLMs for tasks performed by Undergraduate Computer Science Students},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2402.01687v2.pdf,10.48550/arXiv.2402.01687,arxiv,2024
1043,"When Geoscience Meets Generative AI and Large Language Models:
  Foundations, Trends, and Future Challenges","@misc{https://doi.org/10.48550/arxiv.2402.03349,
  doi = {10.48550/ARXIV.2402.03349},
  url = {https://arxiv.org/abs/2402.03349},
  author = {Hadid, Abdenour and Chakraborty, Tanujit and Busby, Daniel},
  keywords = {Geophysics (physics.geo-ph), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Atmospheric and Oceanic Physics (physics.ao-ph), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {When Geoscience Meets Generative AI and Large Language Models: Foundations, Trends, and Future Challenges},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2402.03349v1.pdf,10.48550/arXiv.2402.03349,arxiv,2024
1044,"Using Large Language Models for Student-Code Guided Test Case Generation
  in Computer Science Education","@misc{https://doi.org/10.48550/arxiv.2402.07081,
  doi = {10.48550/ARXIV.2402.07081},
  url = {https://arxiv.org/abs/2402.07081},
  author = {Kumar, Nischal Ashok and Lan, Andrew},
  keywords = {Computation and Language (cs.CL), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Using Large Language Models for Student-Code Guided Test Case Generation in Computer Science Education},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2402.07081v1.pdf,10.48550/arXiv.2402.07081,arxiv,2024
1045,"QACP: An Annotated Question Answering Dataset for Assisting Chinese
  Python Programming Learners","@misc{https://doi.org/10.48550/arxiv.2402.07913,
  doi = {10.48550/ARXIV.2402.07913},
  url = {https://arxiv.org/abs/2402.07913},
  author = {Xiao, Rui and Han, Lu and Zhou, Xiaoying and Wang, Jiong and Zong, Na and Zhang, Pengyu},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {QACP: An Annotated Question Answering Dataset for Assisting Chinese Python Programming Learners},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2402.07913v2.pdf,10.48550/arXiv.2402.07913,arxiv,2024
1046,"Improving Assessment of Tutoring Practices using Retrieval-Augmented
  Generation","@misc{https://doi.org/10.48550/arxiv.2402.14594,
  doi = {10.48550/ARXIV.2402.14594},
  url = {https://arxiv.org/abs/2402.14594},
  author = {Han, Zifei FeiFei and Lin, Jionghao and Gurung, Ashish and Thomas, Danielle R. and Chen, Eason and Borchers, Conrad and Gupta, Shivang and Koedinger, Kenneth R.},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Human-Computer Interaction (cs.HC), Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2402.14594v1.pdf,10.48550/arXiv.2402.14594,arxiv,2024
1047,"Automated Generation of Multiple-Choice Cloze Questions for Assessing
  English Vocabulary Using GPT-turbo 3.5","@article{https://doi.org/10.48550/arxiv.2403.02078,
  doi = {10.48550/ARXIV.2403.02078},
  url = {https://arxiv.org/abs/2403.02078},
  author = {Wang, Qiao and Rose, Ralph and Orita, Naho and Sugawara, Ayaka},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2403.02078v1.pdf,10.48550/arXiv.2403.02078,arxiv,2024
1048,Feedback-Generation for Programming Exercises With GPT-4,"@misc{https://doi.org/10.48550/arxiv.2403.04449,
  doi = {10.48550/ARXIV.2403.04449},
  url = {https://arxiv.org/abs/2403.04449},
  author = {Azaiz, Imen and Kiesler, Natalie and Strickroth, Sven},
  keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Feedback-Generation for Programming Exercises With GPT-4},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2403.04449v1.pdf,10.48550/arXiv.2403.04449,arxiv,2024
1049,Teaching Machines to Code: Smart Contract Translation with LLMs,"@misc{https://doi.org/10.48550/arxiv.2403.09740,
  doi = {10.48550/ARXIV.2403.09740},
  url = {https://arxiv.org/abs/2403.09740},
  author = {Karanjai, Rabimba and Xu, Lei and Shi, Weidong},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Teaching Machines to Code: Smart Contract Translation with LLMs},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2403.09740v1.pdf,10.48550/arXiv.2403.09740,arxiv,2024
1050,"Evaluating the Application of Large Language Models to Generate Feedback
  in Programming Education","@misc{https://doi.org/10.48550/arxiv.2403.09744,
  doi = {10.48550/ARXIV.2403.09744},
  url = {https://arxiv.org/abs/2403.09744},
  author = {Jacobs, Sven and Jaschke, Steffen},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Evaluating the Application of Large Language Models to Generate Feedback in Programming Education},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2403.09744v1.pdf,10.48550/arXiv.2403.09744,arxiv,2024
1051,"Using Generative Text Models to Create Qualitative Codebooks for Student
  Evaluations of Teaching","@misc{https://doi.org/10.48550/arxiv.2403.11984,
  doi = {10.48550/ARXIV.2403.11984},
  url = {https://arxiv.org/abs/2403.11984},
  author = {Katz, Andrew and Gerhardt, Mitchell and Soledad, Michelle},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Using Generative Text Models to Create Qualitative Codebooks for Student Evaluations of Teaching},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2403.11984v1.pdf,10.48550/arXiv.2403.11984,arxiv,2024
1052,"Predicting Learning Performance with Large Language Models: A Study in
  Adult Literacy","@misc{https://doi.org/10.48550/arxiv.2403.14668,
  doi = {10.48550/ARXIV.2403.14668},
  url = {https://arxiv.org/abs/2403.14668},
  author = {Zhang, Liang and Lin, Jionghao and Borchers, Conrad and Sabatini, John and Hollander, John and Cao, Meng and Hu, Xiangen},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Predicting Learning Performance with Large Language Models: A Study in Adult Literacy},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2403.14668v1.pdf,10.48550/arXiv.2403.14668,arxiv,2024
1053,Bioinformatics and Biomedical Informatics with ChatGPT: Year One Review,"@misc{https://doi.org/10.48550/arxiv.2403.15274,
  doi = {10.48550/ARXIV.2403.15274},
  url = {https://arxiv.org/abs/2403.15274},
  author = {Wang, Jinge and Cheng, Zien and Yao, Qiuming and Liu, Li and Xu, Dong and Hu, Gangqing},
  keywords = {Other Quantitative Biology (q-bio.OT), Artificial Intelligence (cs.AI), FOS: Biological sciences, FOS: Biological sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Bioinformatics and Biomedical Informatics with ChatGPT: Year One Review},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2403.15274v2.pdf,10.48550/arXiv.2403.15274,arxiv,2024
1054,"Just another copy and paste? Comparing the security vulnerabilities of
  ChatGPT generated code and StackOverflow answers","@misc{https://doi.org/10.48550/arxiv.2403.15600,
  doi = {10.48550/ARXIV.2403.15600},
  url = {https://arxiv.org/abs/2403.15600},
  author = {Hamer, Sivana and d'Amorim, Marcelo and Williams, Laurie},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2403.15600v1.pdf,10.48550/arXiv.2403.15600,arxiv,2024
1055,"Designing Child-Centric AI Learning Environments: Insights from
  LLM-Enhanced Creative Project-Based Learning","@misc{https://doi.org/10.48550/arxiv.2403.16159,
  doi = {10.48550/ARXIV.2403.16159},
  url = {https://arxiv.org/abs/2403.16159},
  author = {Zha, Siyu and Qiao, Yuehan and Hu, Qingyu and Li, Zhongsheng and Gong, Jiangtao and Xu, Yingqing},
  keywords = {Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Designing Child-Centric AI Learning Environments: Insights from LLM-Enhanced Creative Project-Based Learning},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2403.16159v2.pdf,10.48550/arXiv.2403.16159,arxiv,2024
1056,"An Exploratory Study on Upper-Level Computing Students' Use of Large
  Language Models as Tools in a Semester-Long Project","@misc{https://doi.org/10.48550/arxiv.2403.18679,
  doi = {10.48550/ARXIV.2403.18679},
  url = {https://arxiv.org/abs/2403.18679},
  author = {Tanay, Ben Arie and Arinze, Lexy and Joshi, Siddhant S. and Davis, Kirsten A. and Davis, James C.},
  keywords = {Software Engineering (cs.SE), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {An Exploratory Study on Upper-Level Computing Students' Use of Large Language Models as Tools in a Semester-Long Project},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2403.18679v2.pdf,10.48550/arXiv.2403.18679,arxiv,2024
1057,"Peer-aided Repairer: Empowering Large Language Models to Repair Advanced
  Student Assignments","@misc{https://doi.org/10.48550/arxiv.2404.01754,
  doi = {10.48550/ARXIV.2404.01754},
  url = {https://arxiv.org/abs/2404.01754},
  author = {Zhao, Qianhui and Liu, Fang and Zhang, Li and Liu, Yang and Yan, Zhen and Chen, Zhenghao and Zhou, Yufei and Jiang, Jing and Li, Ge},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Peer-aided Repairer: Empowering Large Language Models to Repair Advanced Student Assignments},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2404.01754v1.pdf,10.48550/arXiv.2404.01754,arxiv,2024
1058,CSEPrompts: A Benchmark of Introductory Computer Science Prompts,"@misc{https://doi.org/10.48550/arxiv.2404.02540,
  doi = {10.48550/ARXIV.2404.02540},
  url = {https://arxiv.org/abs/2404.02540},
  author = {Raihan, Nishat and Goswami, Dhiman and Puspo, Sadiya Sayara Chowdhury and Newman, Christian and Ranasinghe, Tharindu and Zampieri, Marcos},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CSEPrompts: A Benchmark of Introductory Computer Science Prompts},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2404.02540v2.pdf,10.48550/arXiv.2404.02540,arxiv,2024
1059,Analyzing LLM Usage in an Advanced Computing Class in India,"@misc{https://doi.org/10.48550/arxiv.2404.04603,
  doi = {10.48550/ARXIV.2404.04603},
  url = {https://arxiv.org/abs/2404.04603},
  author = {Arora, Chaitanya and Venaik, Utkarsh and Singh, Pavit and Goyal, Sahil and Tyagi, Jatin and Goel, Shyama and Singhal, Ujjwal and Kumar, Dhruv},
  keywords = {Human-Computer Interaction (cs.HC), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Analyzing LLM Usage in an Advanced Computing Class in India},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2404.04603v1.pdf,10.48550/arXiv.2404.04603,arxiv,2024
1060,Physics Event Classification Using Large Language Models,"@misc{https://doi.org/10.48550/arxiv.2404.05752,
  doi = {10.48550/ARXIV.2404.05752},
  url = {https://arxiv.org/abs/2404.05752},
  author = {Fanelli, Cristiano and Giroux, James and Moran, Patrick and Nayak, Hemalata and Suresh, Karthik and Walter, Eric},
  keywords = {Data Analysis, Statistics and Probability (physics.data-an), Machine Learning (cs.LG), High Energy Physics - Experiment (hep-ex), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Physics Event Classification Using Large Language Models},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2404.05752v1.pdf,10.48550/arXiv.2404.05752,arxiv,2024
1061,Explaining EDA synthesis errors with LLMs,"@misc{https://doi.org/10.48550/arxiv.2404.07235,
  doi = {10.48550/ARXIV.2404.07235},
  url = {https://arxiv.org/abs/2404.07235},
  author = {Qiu, Siyu and Tan, Benjamin and Pearce, Hammond},
  keywords = {Hardware Architecture (cs.AR), Artificial Intelligence (cs.AI), Programming Languages (cs.PL), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Explaining EDA synthesis errors with LLMs},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2404.07235v1.pdf,10.48550/arXiv.2404.07235,arxiv,2024
1062,Fine Tuning LLM for Enterprise: Practical Guidelines and Recommendations,"@misc{https://doi.org/10.48550/arxiv.2404.10779,
  doi = {10.48550/ARXIV.2404.10779},
  url = {https://arxiv.org/abs/2404.10779},
  author = {J, Mathav Raj and VM, Kushala and Warrier, Harikrishna and Gupta, Yogesh},
  keywords = {Software Engineering (cs.SE), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Fine Tuning LLM for Enterprise: Practical Guidelines and Recommendations},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2404.10779v1.pdf,10.48550/arXiv.2404.10779,arxiv,2024
1063,"Fact :Teaching MLLMs with Faithful, Concise and Transferable Rationales","@misc{https://doi.org/10.48550/arxiv.2404.11129,
  doi = {10.48550/ARXIV.2404.11129},
  url = {https://arxiv.org/abs/2404.11129},
  author = {Gao, Minghe and Chen, Shuang and Pang, Liang and Yao, Yuan and Dang, Jisheng and Zhang, Wenqiao and Li, Juncheng and Tang, Siliang and Zhuang, Yueting and Chua, Tat-Seng},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Fact :Teaching MLLMs with Faithful, Concise and Transferable Rationales},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2404.11129v1.pdf,10.48550/arXiv.2404.11129,arxiv,2024
1064,"Leveraging Large Language Model as Simulated Patients for Clinical
  Education","@misc{https://doi.org/10.48550/arxiv.2404.13066,
  doi = {10.48550/ARXIV.2404.13066},
  url = {https://arxiv.org/abs/2404.13066},
  author = {Li, Yanzeng and Zeng, Cheng and Zhong, Jialun and Zhang, Ruoyu and Zhang, Minhao and Zou, Lei},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Leveraging Large Language Model as Simulated Patients for Clinical Education},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2404.13066v2.pdf,10.48550/arXiv.2404.13066,arxiv,2024
1065,NExT: Teaching Large Language Models to Reason about Code Execution,"@misc{https://doi.org/10.48550/arxiv.2404.14662,
  doi = {10.48550/ARXIV.2404.14662},
  url = {https://arxiv.org/abs/2404.14662},
  author = {Ni, Ansong and Allamanis, Miltiadis and Cohan, Arman and Deng, Yinlin and Shi, Kensen and Sutton, Charles and Yin, Pengcheng},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Programming Languages (cs.PL), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {NExT: Teaching Large Language Models to Reason about Code Execution},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2404.14662v1.pdf,10.48550/arXiv.2404.14662,arxiv,2024
1066,"CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models
  of Code","@misc{https://doi.org/10.48550/arxiv.2404.15639,
  doi = {10.48550/ARXIV.2404.15639},
  url = {https://arxiv.org/abs/2404.15639},
  author = {Guan, Batu and Wan, Yao and Bi, Zhangqian and Wang, Zheng and Zhang, Hongyu and Sui, Yulei and Zhou, Pan and Sun, Lichao},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2404.15639v1.pdf,10.48550/arXiv.2404.15639,arxiv,2024
1067,How LLMs Aid in UML Modeling: An Exploratory Study with Novice Analysts,"@misc{https://doi.org/10.48550/arxiv.2404.17739,
  doi = {10.48550/ARXIV.2404.17739},
  url = {https://arxiv.org/abs/2404.17739},
  author = {Wang, Beian and Wang, Chong and Liang, Peng and Li, Bing and Zeng, Cheng},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {How LLMs Aid in UML Modeling: An Exploratory Study with Novice Analysts},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2404.17739v2.pdf,10.48550/arXiv.2404.17739,arxiv,2024
1068,AI-powered Code Review with LLMs: Early Results,"@misc{https://doi.org/10.48550/arxiv.2404.18496,
  doi = {10.48550/ARXIV.2404.18496},
  url = {https://arxiv.org/abs/2404.18496},
  author = {Rasheed, Zeeshan and Sami, Malik Abdul and Waseem, Muhammad and Kemell, Kai-Kristian and Wang, Xiaofeng and Nguyen, Anh and Systä, Kari and Abrahamsson, Pekka},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {AI-powered Code Review with LLMs: Early Results},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2404.18496v1.pdf,10.48550/arXiv.2404.18496,arxiv,2024
1069,"HELPER-X: A Unified Instructable Embodied Agent to Tackle Four
  Interactive Vision-Language Domains with Memory-Augmented Language Models","@misc{https://doi.org/10.48550/arxiv.2404.19065,
  doi = {10.48550/ARXIV.2404.19065},
  url = {https://arxiv.org/abs/2404.19065},
  author = {Sarch, Gabriel and Somani, Sahil and Kapoor, Raghav and Tarr, Michael J. and Fragkiadaki, Katerina},
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {HELPER-X: A Unified Instructable Embodied Agent to Tackle Four Interactive Vision-Language Domains with Memory-Augmented Language Models},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2404.19065v1.pdf,10.48550/arXiv.2404.19065,arxiv,2024
1070,"Improving LLM Classification of Logical Errors by Integrating Error
  Relationship into Prompts","@misc{https://doi.org/10.48550/arxiv.2404.19336,
  doi = {10.48550/ARXIV.2404.19336},
  url = {https://arxiv.org/abs/2404.19336},
  author = {Lee, Yanggyu and Jeong, Suchae and Kim, Jihie},
  keywords = {Artificial Intelligence (cs.AI), Programming Languages (cs.PL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Improving LLM Classification of Logical Errors by Integrating Error Relationship into Prompts},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2404.19336v2.pdf,10.48550/arXiv.2404.19336,arxiv,2024
1071,"Generating Feedback-Ladders for Logical Errors in Programming using
  Large Language Models","@misc{https://doi.org/10.48550/arxiv.2405.00302,
  doi = {10.48550/ARXIV.2405.00302},
  url = {https://arxiv.org/abs/2405.00302},
  author = {Heickal, Hasnain and Lan, Andrew},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Generating Feedback-Ladders for Logical Errors in Programming using Large Language Models},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2405.00302v3.pdf,10.48550/arXiv.2405.00302,arxiv,2024
1072,ChatGPT in Data Visualization Education: A Student Perspective,"@misc{https://doi.org/10.48550/arxiv.2405.00748,
  doi = {10.48550/ARXIV.2405.00748},
  url = {https://arxiv.org/abs/2405.00748},
  author = {Kim, Nam Wook and Ko, Hyung-Kwon and Myers, Grace and Bach, Benjamin},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {ChatGPT in Data Visualization Education: A Student Perspective},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2405.00748v1.pdf,10.48550/arXiv.2405.00748,arxiv,2024
1073,"From Keyboard to Chatbot: An AI-powered Integration Platform with
  Large-Language Models for Teaching Computational Thinking for Young Children","@misc{https://doi.org/10.48550/arxiv.2405.00750,
  doi = {10.48550/ARXIV.2405.00750},
  url = {https://arxiv.org/abs/2405.00750},
  author = {Lee, Changjae and Xiong, Jinjun},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {From Keyboard to Chatbot: An AI-powered Integration Platform with Large-Language Models for Teaching Computational Thinking for Young Children},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2405.00750v1.pdf,10.48550/arXiv.2405.00750,arxiv,2024
1074,"FOKE: A Personalized and Explainable Education Framework Integrating
  Foundation Models, Knowledge Graphs, and Prompt Engineering","@misc{https://doi.org/10.48550/arxiv.2405.03734,
  doi = {10.48550/ARXIV.2405.03734},
  url = {https://arxiv.org/abs/2405.03734},
  author = {Hu, Silan and Wang, Xiaoning},
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), Applications (stat.AP), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {FOKE: A Personalized and Explainable Education Framework Integrating Foundation Models, Knowledge Graphs, and Prompt Engineering},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2405.03734v1.pdf,10.48550/arXiv.2405.03734,arxiv,2024
1075,"Open Source Language Models Can Provide Feedback: Evaluating LLMs'
  Ability to Help Students Using GPT-4-As-A-Judge","@misc{https://doi.org/10.48550/arxiv.2405.05253,
  doi = {10.48550/ARXIV.2405.05253},
  url = {https://arxiv.org/abs/2405.05253},
  author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Denny, Paul},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2405.05253v1.pdf,10.48550/arXiv.2405.05253,arxiv,2024
1076,Benchmarking Educational Program Repair,"@misc{https://doi.org/10.48550/arxiv.2405.05347,
  doi = {10.48550/ARXIV.2405.05347},
  url = {https://arxiv.org/abs/2405.05347},
  author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Leinonen, Juho and Hellas, Arto and Denny, Paul},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Benchmarking Educational Program Repair},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2405.05347v1.pdf,10.48550/arXiv.2405.05347,arxiv,2024
1077,"Leveraging Lecture Content for Improved Feedback: Explorations with
  GPT-4 and Retrieval Augmented Generation","@misc{https://doi.org/10.48550/arxiv.2405.06681,
  doi = {10.48550/ARXIV.2405.06681},
  url = {https://arxiv.org/abs/2405.06681},
  author = {Jacobs, Sven and Jaschke, Steffen},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Leveraging Lecture Content for Improved Feedback: Explorations with GPT-4 and Retrieval Augmented Generation},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2405.06681v1.pdf,10.48550/arXiv.2405.06681,arxiv,2024
1078,Automating Code Adaptation for MLOps -- A Benchmarking Study on LLMs,"@misc{https://doi.org/10.48550/arxiv.2405.06835,
  doi = {10.48550/ARXIV.2405.06835},
  url = {https://arxiv.org/abs/2405.06835},
  author = {Patel, Harsh and Ramanan, Buvaneswari A. and Khan, Manzoor A. and Williams, Thomas and Friedman, Brian and Drabeck, Lawrence},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Automating Code Adaptation for MLOps -- A Benchmarking Study on LLMs},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2405.06835v1.pdf,10.48550/arXiv.2405.06835,arxiv,2024
1079,"Interpreting Latent Student Knowledge Representations in Programming
  Assignments","@misc{https://doi.org/10.48550/arxiv.2405.08213,
  doi = {10.48550/ARXIV.2405.08213},
  url = {https://arxiv.org/abs/2405.08213},
  author = {Fernandez, Nigel and Lan, Andrew},
  keywords = {Computation and Language (cs.CL), Computers and Society (cs.CY), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Interpreting Latent Student Knowledge Representations in Programming Assignments},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2405.08213v1.pdf,10.48550/arXiv.2405.08213,arxiv,2024
1080,"Hybrid Context Retrieval Augmented Generation Pipeline: LLM-Augmented
  Knowledge Graphs and Vector Database for Accreditation Reporting Assistance","@misc{https://doi.org/10.48550/arxiv.2405.15436,
  doi = {10.48550/ARXIV.2405.15436},
  url = {https://arxiv.org/abs/2405.15436},
  author = {Edwards, Candace},
  keywords = {Information Retrieval (cs.IR), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Hybrid Context Retrieval Augmented Generation Pipeline: LLM-Augmented Knowledge Graphs and Vector Database for Accreditation Reporting Assistance},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2405.15436v1.pdf,10.48550/arXiv.2405.15436,arxiv,2024
1081,ChatGPT Code Detection: Techniques for Uncovering the Source of Code,"@misc{https://doi.org/10.48550/arxiv.2405.15512,
  doi = {10.48550/ARXIV.2405.15512},
  url = {https://arxiv.org/abs/2405.15512},
  author = {Oedingen, Marc and Engelhardt, Raphael C. and Denz, Robin and Hammer, Maximilian and Konen, Wolfgang},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {ChatGPT Code Detection: Techniques for Uncovering the Source of Code},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2405.15512v1.pdf,10.48550/arXiv.2405.15512,arxiv,2024
1082,"Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via
  Code Rewriting","@misc{https://doi.org/10.48550/arxiv.2405.16133,
  doi = {10.48550/ARXIV.2405.16133},
  url = {https://arxiv.org/abs/2405.16133},
  author = {Ye, Tong and Du, Yangkai and Ma, Tengfei and Wu, Lingfei and Zhang, Xuhong and Ji, Shouling and Wang, Wenhai},
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2405.16133v2.pdf,10.48550/arXiv.2405.16133,arxiv,2024
1083,Chain of Tools: Large Language Model is an Automatic Multi-tool Learner,"@misc{https://doi.org/10.48550/arxiv.2405.16533,
  doi = {10.48550/ARXIV.2405.16533},
  url = {https://arxiv.org/abs/2405.16533},
  author = {Shi, Zhengliang and Gao, Shen and Chen, Xiuyi and Feng, Yue and Yan, Lingyong and Shi, Haibo and Yin, Dawei and Chen, Zhumin and Verberne, Suzan and Ren, Zhaochun},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Chain of Tools: Large Language Model is an Automatic Multi-tool Learner},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2405.16533v1.pdf,10.48550/arXiv.2405.16533,arxiv,2024
1084,Towards Integrating Emerging AI Applications in SE Education,"@misc{https://doi.org/10.48550/arxiv.2405.18062,
  doi = {10.48550/ARXIV.2405.18062},
  url = {https://arxiv.org/abs/2405.18062},
  author = {Vierhauser, Michael and Groher, Iris and Antensteiner, Tobias and Sauerwein, Clemens},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Towards Integrating Emerging AI Applications in SE Education},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}
",http://arxiv.org/pdf/2405.18062v2.pdf,10.48550/arXiv.2405.18062,arxiv,2024
1085,"Analyzing Chat Protocols of Novice Programmers Solving Introductory
  Programming Tasks with ChatGPT","@misc{https://doi.org/10.48550/arxiv.2405.19132,
  doi = {10.48550/ARXIV.2405.19132},
  url = {https://arxiv.org/abs/2405.19132},
  author = {Scholl, Andreas and Schiffner, Daniel and Kiesler, Natalie},
  keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
",http://arxiv.org/pdf/2405.19132v1.pdf,10.48550/arXiv.2405.19132,arxiv,2024
1086,"A Survey Study on the State of the Art of Programming Exercise
  Generation using Large Language Models","@misc{https://doi.org/10.48550/arxiv.2405.20183,
  doi = {10.48550/ARXIV.2405.20183},
  url = {https://arxiv.org/abs/2405.20183},
  author = {Frankford, Eduard and Höhn, Ingo and Sauerwein, Clemens and Breu, Ruth},
  keywords = {Artificial Intelligence (cs.AI), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Survey Study on the State of the Art of Programming Exercise Generation using Large Language Models},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2405.20183v1.pdf,10.48550/arXiv.2405.20183,arxiv,2024
1087,An Automatic Question Usability Evaluation Toolkit,"@misc{https://doi.org/10.48550/arxiv.2405.20529,
  doi = {10.48550/ARXIV.2405.20529},
  url = {https://arxiv.org/abs/2405.20529},
  author = {Moore, Steven and Costello, Eamon and Nguyen, Huy A. and Stamper, John},
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {An Automatic Question Usability Evaluation Toolkit},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2405.20529v1.pdf,10.48550/arXiv.2405.20529,arxiv,2024
1088,"Experiences from Integrating Large Language Model Chatbots into the
  Classroom","@misc{https://doi.org/10.48550/arxiv.2406.04817,
  doi = {10.48550/ARXIV.2406.04817},
  url = {https://arxiv.org/abs/2406.04817},
  author = {Hellas, Arto and Leinonen, Juho and Leppänen, Leo},
  keywords = {Computers and Society (cs.CY), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Experiences from Integrating Large Language Model Chatbots into the Classroom},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2406.04817v1.pdf,10.48550/arXiv.2406.04817,arxiv,2024
1089,"Hints-In-Browser: Benchmarking Language Models for Programming Feedback
  Generation","@misc{https://doi.org/10.48550/arxiv.2406.05053,
  doi = {10.48550/ARXIV.2406.05053},
  url = {https://arxiv.org/abs/2406.05053},
  author = {Kotalwar, Nachiket and Gotovos, Alkis and Singla, Adish},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2406.05053v1.pdf,10.48550/arXiv.2406.05053,arxiv,2024
1090,"Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer
  Science Exam","@article{https://doi.org/10.48550/arxiv.2406.09671,
  doi = {10.48550/ARXIV.2406.09671},
  url = {https://arxiv.org/abs/2406.09671},
  author = {Mendonça, Nabor C.},
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2406.09671v1.pdf,10.48550/arXiv.2406.09671,arxiv,2024
1091,"Beyond the Hype: A Cautionary Tale of ChatGPT in the Programming
  Classroom","@article{https://doi.org/10.48550/arxiv.2406.11104,
  doi = {10.48550/ARXIV.2406.11104},
  url = {https://arxiv.org/abs/2406.11104},
  author = {Oosterwyk, Grant and Tsibolane, Pitso and Kautondokwa, Popyeni and Canani, Ammar},
  keywords = {Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Beyond the Hype: A Cautionary Tale of ChatGPT in the Programming Classroom},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2406.11104v1.pdf,10.48550/arXiv.2406.11104,arxiv,2024
1092,"CREF: An LLM-based Conversational Software Repair Framework for
  Programming Tutors","@misc{https://doi.org/10.48550/arxiv.2406.13972,
  doi = {10.48550/ARXIV.2406.13972},
  url = {https://arxiv.org/abs/2406.13972},
  author = {Yang, Boyang and Tian, Haoye and Pian, Weiguo and Yu, Haoran and Wang, Haitao and Klein, Jacques and Bissyandé, Tegawendé F. and Jin, Shunfu},
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CREF: An LLM-based Conversational Software Repair Framework for Programming Tutors},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2406.13972v1.pdf,10.48550/arXiv.2406.13972,arxiv,2024
1093,"ICAL: Continual Learning of Multimodal Agents by Transforming
  Trajectories into Actionable Insights","@misc{https://doi.org/10.48550/arxiv.2406.14596,
  doi = {10.48550/ARXIV.2406.14596},
  url = {https://arxiv.org/abs/2406.14596},
  author = {Sarch, Gabriel and Jang, Lawrence and Tarr, Michael J. and Cohen, William W. and Marino, Kenneth and Fragkiadaki, Katerina},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {ICAL: Continual Learning of Multimodal Agents by Transforming Trajectories into Actionable Insights},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
",http://arxiv.org/pdf/2406.14596v1.pdf,10.48550/arXiv.2406.14596,arxiv,2024
1094,CS1-LLM: Integrating LLMs into CS1 Instruction,"@misc{https://doi.org/10.48550/arxiv.2406.15379,
  doi = {10.48550/ARXIV.2406.15379},
  url = {https://arxiv.org/abs/2406.15379},
  author = {Vadaparty, Annapurna and Zingaro, Daniel and Smith, David H. and Padala, Mounika and Alvarado, Christine and Benario, Jamie Gorson and Porter, Leo},
  keywords = {Computers and Society (cs.CY), Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CS1-LLM: Integrating LLMs into CS1 Instruction},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
",http://arxiv.org/pdf/2406.15379v1.pdf,10.48550/arXiv.2406.15379,arxiv,2024
1095,Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions About Code,"@article{2-s2.0-85150767704,
  title={Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions About Code},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85150767704&origin=inward,10.5220/0011996900003470,scopus,2023
1096,Davinci Goes to Bebras: A Study on the Problem Solving Ability of GPT-3,"@article{2-s2.0-85160866835,
  title={Davinci Goes to Bebras: A Study on the Problem Solving Ability of GPT-3},
  author={N/A},
  journal={N/A},
  year={2023},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85160866835&origin=inward,10.5220/0012007500003470,scopus,2023
1097,Academia and Industry Synergy: Addressing Integrity Challenge in Programming Education,"@article{2-s2.0-85190799281,
  title={Academia and Industry Synergy: Addressing Integrity Challenge in Programming Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85190799281&origin=inward,10.5220/0012451000003636,scopus,2024
1098,The Impact of Structured Prompt-Driven Generative AI on Learning Data Analysis in Engineering Students,"@article{2-s2.0-85193980577,
  title={The Impact of Structured Prompt-Driven Generative AI on Learning Data Analysis in Engineering Students},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85193980577&origin=inward,10.5220/0012693000003693,scopus,2024
1099,Generative AI for Productivity in Industry and Education,"@article{2-s2.0-85194191340,
  title={Generative AI for Productivity in Industry and Education},
  author={N/A},
  journal={N/A},
  year={2024},
  volume={N/A},
  pages={N/A},
  doi={N/A}
}",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85194191340&origin=inward,10.5220/0012736200003708,scopus,2024
1127,11 - From synapses to ephapsis: Embodied cognition and wearable personal assistants,"@incollection{ORMANDY2024205,
title = {11 - From synapses to ephapsis: Embodied cognition and wearable personal assistants},
editor = {Robert Kozma and Cesare Alippi and Yoonsuck Choe and Francesco Carlo Morabito},
booktitle = {Artificial Intelligence in the Age of Neural Networks and Brain Computing (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {205-222},
year = {2024},
isbn = {978-0-323-96104-2},
doi = {https://doi.org/10.1016/B978-0-323-96104-2.00005-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323961042000051},
author = {Roman Ormandy},
keywords = {Embodied cognition, Ephapsis, Motor action, Neural populations, Neural dynamics, Resonance, Synapses, Wearable assistants},
abstract = {Despite their significant successes, neural networks typically represent relatively static memory structures and solve static classification problems. The next step in the evolution of AI systems will be the capture of the dynamic aspects of cognition. The dynamics are embodied in the ephaptic fields of the neocortex and limbic system, formed by the vast populations of resonating electric dipoles comprised of a multitude of ion channels present on the surface of each neuron. These ion-based e-fields form dynamic brainwaves, which synchronize distant areas of the cortex at the speed of light (orders of magnitude faster than axonal pulse speed) via resonance in the beta, theta, and gamma range. They are quite important for the understanding of the working of the brain. Ephaptic fields are also a perfect bridge to the motor behavior of organisms. This chapter shows that it is not only walking and grasping which is motor based, but also that vision, speech, and in fact, all perception and even memory are grounded in motor action. This has deep implications for the design of AI-based personal assistants. This chapter argues that field approach, ephapsis, and motor action are indispensable if the goal for the future generations of wearable sensor-based personal assistants is the real-time capture of user intent. Multimodal correlation of motor sensors of user daily activities is the essential ingredient, which so far eluded AI researchers and precluded wearable assistants from a wider user adoption. It turns out that thinking is embodied indeed. We discuss how recent developments in making movies from chat and merging large language models AI and 3D, can lead to a new generation of personal assistants, where metaverse, AI, and AR are coming together in the most surprising ways.}
}
",https://www.sciencedirect.com/science/article/pii/B9780323961042000051,https://doi.org/10.1016/B978-0-323-96104-2.00005-1,science_direct,2024
1128,Chapter 7 - Deployment roadmap of proactive human–robot collaboration,"@incollection{LI2024149,
title = {Chapter 7 - Deployment roadmap of proactive human–robot collaboration},
editor = {Shufei Li and Pai Zheng and Lihui Wang},
booktitle = {Proactive Human-Robot Collaboration Toward Human-Centric Smart Manufacturing},
publisher = {Elsevier},
pages = {149-192},
year = {2024},
isbn = {978-0-443-13943-7},
doi = {https://doi.org/10.1016/B978-0-44-313943-7.00014-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443139437000144},
author = {Shufei Li and Pai Zheng and Lihui Wang},
keywords = {Deployment roadmap of proactive human–robot collaboration, Scene perception, Knowledge representation, Decision making, Collaborative control},
abstract = {This chapter presents a stepwise procedure for the development of Proactive HRC systems comprising four key modules: scene perception, knowledge representation, decision making, and collaborative control. For each module, we provide a comprehensive research roadmap of related technologies and offer an advanced algorithm as a feasible solution. The perception module is dedicated to perceiving the human–robot–workspace environment, as detailed in Section 7.1. Meanwhile, knowledge representation focuses on acquiring semantic knowledge of manufacturing tasks and transferring human expertise to robots for cognitive inference, as illustrated in Section 7.2. In Section 7.3, we delve into the decision-making module, which empowers the HRC system to make intelligent decisions for optimized trajectory planning and human information support, adapting to changing environmental conditions. Additionally, Section 7.4 provides an overview of various algorithms for robot collaborative control at the operational level. These four aspects have witnessed the widespread adoption of cutting-edge cognitive computing techniques such as deep learning, reinforcement learning, transfer learning, large language model, etc., resulting in significant enhancements to Proactive HRC system performance.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443139437000144,https://doi.org/10.1016/B978-0-44-313943-7.00014-4,science_direct,2024
1129,Index,"@incollection{2024285,
title = {Index},
editor = {Shufei Li and Pai Zheng and Lihui Wang},
booktitle = {Proactive Human-Robot Collaboration Toward Human-Centric Smart Manufacturing},
publisher = {Elsevier},
pages = {285-293},
year = {2024},
isbn = {978-0-443-13943-7},
doi = {https://doi.org/10.1016/B978-0-44-313943-7.00018-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443139437000181}
}
",https://www.sciencedirect.com/science/article/pii/B9780443139437000181,https://doi.org/10.1016/B978-0-44-313943-7.00018-1,science_direct,2024
1130,Chapter 2 - The human factor,"@incollection{MACKENZIE202431,
title = {Chapter 2 - The human factor},
editor = {I. Scott MacKenzie},
booktitle = {Human-Computer Interaction (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
pages = {31-91},
year = {2024},
isbn = {978-0-443-14096-9},
doi = {https://doi.org/10.1016/B978-0-44-314096-9.00008-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443140969000087},
author = {I. Scott MacKenzie},
keywords = {human senses, perception, motor responses, cognition, memory, chunking, language, reaction time, visual search, skilled performance, attention, human error, outliers},
abstract = {This chapter examines the human factor in interactive computing systems. We begin with a brief review of human sensory, perceptual, cognitive, and motor processes. Human memory is examined from the perspective long-term and short-term memory, with short-term memory limited to about seven (±2) units or chunks. Language, and in particular written language, is examined from an information perspective in terms of entropy and redundancy. Human performance in simple reaction and visual search tasks is studied and illustrated through the setup and results of an experiment. Skilled performance, attention, and human error are presented and discussed using examples in computing.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443140969000087,https://doi.org/10.1016/B978-0-44-314096-9.00008-7,science_direct,2024
1131,Chapter Eleven - Designing meaningful metrics to demonstrate ethical supervision of autonomous systems: How do you measure that?,"@incollection{BRUTZMAN2024189,
title = {Chapter Eleven - Designing meaningful metrics to demonstrate ethical supervision of autonomous systems: How do you measure that?},
editor = {Peggy Wu and Michael Salpukas and Hsin-Fu Wu and Shannon Ellsworth},
booktitle = {Trolley Crash},
publisher = {Academic Press},
pages = {189-208},
year = {2024},
isbn = {978-0-443-15991-6},
doi = {https://doi.org/10.1016/B978-0-44-315991-6.00017-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443159916000170},
author = {Don Brutzman and Curtis Blais},
keywords = {Ethics, ethical AI, autonomy, metrics, negligence, human–machine teams, Autonomous Vehicle Command Language (AVCL), Mission Execution Ontology (MEO), Dimensions of Autonomous Decision Making (DADM), TestDevOps, virtual environments, trust},
abstract = {Design and testing of meaningful metrics for artificial intelligence (AI) guiding ethical robots holds fundamental importance for useful progress and trustable operations. Moral responsibility and authority for ethical behaviors by remote autonomous systems ultimately lies with the humans responsible for unleashing individual robots. Lines of success or failure are sharply defined when delegating tasks to robots which have the capacity for life-saving or lethal force. Goals, constraints, and metrics that are commonly defined and shared by humans and robots can be mutually understood, formally verifiable as consistent, and further testable in repeatable ways. Metrics for AI are essential, as illustrated by the diverse topics explored throughout this book. It is interesting that commonplace gaps in applied AI often derive from “Here are the measurements we know how to take” which are too easily over-extrapolated or over-simplified into conclusions matching prior preconceptions. In other words, legacy metrics are appealing but might not broadly apply to general situations. We assert that necessary subsequent questions are “How do we define meaningful objectives and outcomes for a current autonomous system?” and “How do we measure those characteristics that indicate expected success/failure?” Since testing drives system evolution, such questions then become “Once we can measure meaningful results, how do we assemble exemplars into test suites that confirm successful completion across ongoing system lifecycles?” This chapter explores potential design principles for metrics that test ethical AI systems, in both real and virtual system frameworks. Such comprehensive test frameworks are essential for achieving meaningful human authority over autonomous robots. Final success is measurable when trust is achieved.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443159916000170,https://doi.org/10.1016/B978-0-44-315991-6.00017-0,science_direct,2024
1132,Chapter 1 - History of graph computing and graph databases,"@incollection{SUN20241,
title = {Chapter 1 - History of graph computing and graph databases},
editor = {Ricky Sun},
booktitle = {The Essential Criteria of Graph Databases},
publisher = {Elsevier},
pages = {1-32},
year = {2024},
isbn = {978-0-443-14162-1},
doi = {https://doi.org/10.1016/B978-0-443-14162-1.00004-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443141621000040},
author = {Ricky Sun},
keywords = {Big data, Graph thinking, Graph database, Graph computing, Knowledge graph, Network analysis},
abstract = {This chapter introduces the core concept throughout this book—graph thinking. Concrete and visualized real-world examples were given in the first section to facilitate the readers to understand the depth and breadth of the concept, and how to put it to work. The first section is completed with a review of the historical development of graph theory and technologies. The second section gives an overview of how data processing technologies and frameworks have evolved from relational databases to big-data frameworks and eventually to graph databases, and insights into their differences. The final section focuses on introducing the amazing and unprecedented capabilities of graph databases, again, with real-world practical examples. This section ended with a comparison of graph computing and graph databases, hoping to clarify any potential confusion between the two topics.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443141621000040,https://doi.org/10.1016/B978-0-443-14162-1.00004-0,science_direct,2024
1133,Chapter 6 - Artificial intelligence in breast cancer: An opportunity for early diagnosis,"@incollection{MALLA202373,
title = {Chapter 6 - Artificial intelligence in breast cancer: An opportunity for early diagnosis},
editor = {Ganji Purnachandra Nagaraju and Venkatesan Amouda and Ampasala {Dinakara Rao}},
booktitle = {Computational Methods in Drug Discovery and Repurposing for Cancer Therapy},
publisher = {Academic Press},
pages = {73-89},
year = {2023},
isbn = {978-0-443-15280-1},
doi = {https://doi.org/10.1016/B978-0-443-15280-1.00004-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443152801000042},
author = {Rama Rao Malla and Vedavathi Katneni},
keywords = {Artificial intelligence, Breast cancer, Deep learning, Diagnosis, Machine learning},
abstract = {One of the serious women's cancer types across the globe is breast cancer (BC). It occurs due to complex heterogeneity as well as multiple etiological factors. Early diagnosis will increase the survival of the patients and reduce mortality to a great extent. Generally, different types of biopsy procedures, mammography, ultrasonography, PET scan, and magnetic resonance imaging (MRI) scan are used to detect breast tumors. However, for the accurate diagnosis of BC, there is a complex necessity for a reliable system. Nowadays, a combination of artificial intelligence (AI), especially a machine learning (ML) approach with digital imaging techniques, has assisted in reducing the false diagnoses of BC. This review presents the fundamentals of ML algorithms and ML models for BC prediction, model assessment, and current knowledge on ML-based approaches for BC diagnosis. Finally, it presents the challenges and scope of AI in precision medicine for BC. Therefore, AI could be useful for achieving ground-breaking progress in precision medicine for BC.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443152801000042,https://doi.org/10.1016/B978-0-443-15280-1.00004-2,science_direct,2023
1134,Chapter 12 - Assessing and implementing trustworthy AI across multiple dimensions,"@incollection{GOLDSTEEN2024229,
title = {Chapter 12 - Assessing and implementing trustworthy AI across multiple dimensions},
editor = {Santi Caballé and Joan Casas-Roma and Jordi Conesa},
booktitle = {Ethics in Online AI-based Systems},
publisher = {Academic Press},
pages = {229-257},
year = {2024},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-18851-0},
doi = {https://doi.org/10.1016/B978-0-443-18851-0.00001-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443188510000019},
author = {Abigail Goldsteen and Ariel Farkash and Michael Hind},
keywords = {Ethical AI, trustworthy AI, privacy, AI governance, machine learning, regulations, compliance},
abstract = {Artificial intelligence (AI) systems have become more and more prevalent in everyday life, especially in enterprise settings. These systems have grown increasingly more accurate and efficient, but at the same time more complex and less understandable. Broad adoption of AI systems requires humans to trust them. This depends on the ability to ensure that AI systems are fair, robust, explainable, accountable, and respectful of the privacy of individuals and will cause no harm. To this end, many tools and techniques have been developed for both assessing AI models and mitigating any potential risks they may pose. This chapter surveys the existing approaches and technologies available to tackle each of the dimensions of Trustworthy AI to create more ethical AI systems. Moreover, it touches on the challenges and possible solutions to significantly combine various aspects of these dimensions, indicating areas for further research.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443188510000019,https://doi.org/10.1016/B978-0-443-18851-0.00001-9,science_direct,2024
1135,Chapter 13 - Artificial intelligence and basic human needs: the shadow aspects of emerging technology,"@incollection{TAN2024259,
title = {Chapter 13 - Artificial intelligence and basic human needs: the shadow aspects of emerging technology},
editor = {Santi Caballé and Joan Casas-Roma and Jordi Conesa},
booktitle = {Ethics in Online AI-based Systems},
publisher = {Academic Press},
pages = {259-278},
year = {2024},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-18851-0},
doi = {https://doi.org/10.1016/B978-0-443-18851-0.00004-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443188510000044},
author = {Tay Keong Tan},
keywords = {Artificial intelligence, autonomous vehicles, facial recognition, AI writing assistant, AI image generator, human needs},
abstract = {While advancing artificial intelligence (AI) applications have brought ease and benefit to human life in meeting our physical needs, it is less obvious how they would impact psychological needs. This study analyzes three emerging technologies—autonomous vehicles; facial recognition systems; and AI writing or image generators—from the perspective of six fundamental human needs; certainty, variety, significance, connection, growth, and contribution. Our core human needs can greatly influence the acceptability, feasibility, and utility of these technologies. A prognosis of the human needs implications of AI can help algorithm designers, policymakers, regulators, and end users mitigate the risks and accentuate its benefits.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443188510000044,https://doi.org/10.1016/B978-0-443-18851-0.00004-4,science_direct,2024
1136,Chapter 1 - Adverse effects of intelligent support of CSCL—the ethics of conversational agents,"@incollection{THIERFELDER20243,
title = {Chapter 1 - Adverse effects of intelligent support of CSCL—the ethics of conversational agents},
editor = {Santi Caballé and Joan Casas-Roma and Jordi Conesa},
booktitle = {Ethics in Online AI-based Systems},
publisher = {Academic Press},
pages = {3-23},
year = {2024},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-18851-0},
doi = {https://doi.org/10.1016/B978-0-443-18851-0.00015-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443188510000159},
author = {Birk Thierfelder and Pantelis M. Papadopoulos and Armin Weinberger and Stavros Demetriadis and Stergios Tegos},
keywords = {CSCL, education, chatbots, ethical AI, Artificial Intelligence, AI framework, conversational agent},
abstract = {The requirement for scaffolded guidance in computer-supported collaborative learning (CSCL) has prompted researchers to investigate the potential of using AI-supported conversational agents (CAs) or chatbots as a means of supporting learners in CSCL environments. Recent advances in the field have shown promise for the development of adaptive systems that can effectively guide learners throughout the CSCL process. However, CSCL research has problems communicating how such technologies are helping or hindering constructive, ethical collaborations. AI ethics, being a fractured field, with many parallel high-level frameworks, demands to be broken down each time by designers in order to arrive at domain- and discipline-specific ethical AI guidelines and/or measurable standards for practical use. The abstract nature of AI ethics may generate dilemmas when coming into contact with the field of pedagogical ethics in an educational setting such as CSCL. We present points of friction using practical examples (edge cases) and highlight considerations for educators that may give an out, taking both angles into account.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443188510000159,https://doi.org/10.1016/B978-0-443-18851-0.00015-9,science_direct,2024
1137,Contents,"@incollection{2024v,
title = {Contents},
editor = {Santi Caballé and Joan Casas-Roma and Jordi Conesa},
booktitle = {Ethics in Online AI-based Systems},
publisher = {Academic Press},
pages = {v-xiii},
year = {2024},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-18851-0},
doi = {https://doi.org/10.1016/B978-0-443-18851-0.00025-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443188510000251}
}
",https://www.sciencedirect.com/science/article/pii/B9780443188510000251,https://doi.org/10.1016/B978-0-443-18851-0.00025-1,science_direct,2024
1138,Index,"@incollection{2024383,
title = {Index},
editor = {Santi Caballé and Joan Casas-Roma and Jordi Conesa},
booktitle = {Ethics in Online AI-based Systems},
publisher = {Academic Press},
pages = {383-397},
year = {2024},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-18851-0},
doi = {https://doi.org/10.1016/B978-0-443-18851-0.00027-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443188510000275}
}
",https://www.sciencedirect.com/science/article/pii/B9780443188510000275,https://doi.org/10.1016/B978-0-443-18851-0.00027-5,science_direct,2024
1139,Chapter Six - Emotional AI: Neuroethics and Socially aligned networks,"@incollection{KREBSZ2024101,
title = {Chapter Six - Emotional AI: Neuroethics and Socially aligned networks},
editor = {Muskan Garg and Deepika Koundal},
booktitle = {Emotional AI and Human-AI Interactions in Social Networking},
publisher = {Academic Press},
pages = {101-130},
year = {2024},
isbn = {978-0-443-19096-4},
doi = {https://doi.org/10.1016/B978-0-443-19096-4.00002-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044319096400002X},
author = {Markus Krebsz and Divya Dwivedi},
keywords = {ChatGPT, Consciousness, Diverse inputs and multistakeholder feedback, Freedom of thought, Generative AI, IoT (Internet-of-things), Neuro-rights, Neuroethics, Sentience, Socially aligned networks, Spiritual AI, Thought-related and neural data},
abstract = {A new term, socially aligned networks, going beyond pure social media is introduced which considers the alignment of participants' common interests and ways how users communicate, create, compete, and/or challenge each other within technological ecosystems such as online services, gaming suites, metaverse or virtual/augmented-/extended-reality spaces. The current scope and predicted growth of the world digital population is considered in light of Big Tech companies' domination of social media as well as continuing digital exclusion. The ethical studies’ landscape is mapped by looking at comparative studies in this relatively new field and with the aim of establishing a suitable ethic principles baseline for such socially aligned networks further illustrated by human–AI interface case studies. Beyond establishing a suitable ethic principles baseline for such socially aligned networks, current advances in neuroethics are considered within the context of emotional AI and human–AI interactions. Neuroethics principles are considered within the context of different philosophical schools, leading to a discussion of relatively new neurorights. An interconnection of morality, ethics, and spirituality is discussed, together with immature legal frameworks and ethical boundaries for Internet of things (IoT) devices. In conclusion, neuroethics are considered a suitable blueprint for socially aligned networks and highlighting that regulation alone is likely not going to be sufficient on its own, particularly when considering the rapid growth of generative AI.}
}
",https://www.sciencedirect.com/science/article/pii/B978044319096400002X,https://doi.org/10.1016/B978-0-443-19096-4.00002-X,science_direct,2024
1140,Index,"@incollection{2024301,
title = {Index},
editor = {Muskan Garg and Deepika Koundal},
booktitle = {Emotional AI and Human-AI Interactions in Social Networking},
publisher = {Academic Press},
pages = {301-306},
year = {2024},
isbn = {978-0-443-19096-4},
doi = {https://doi.org/10.1016/B978-0-443-19096-4.20001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443190964200011}
}
",https://www.sciencedirect.com/science/article/pii/B9780443190964200011,https://doi.org/10.1016/B978-0-443-19096-4.20001-1,science_direct,2024
1141,1 - Power and artificial intelligence: transformation of the global public health ecosystem,"@incollection{MONLEZUN20241,
title = {1 - Power and artificial intelligence: transformation of the global public health ecosystem},
editor = {Dominique J. Monlezun},
booktitle = {Responsible Artificial Intelligence Re-engineering the Global Public Health Ecosystem},
publisher = {Morgan Kaufmann},
pages = {1-65},
year = {2024},
isbn = {978-0-443-21597-1},
doi = {https://doi.org/10.1016/B978-0-443-21597-1.00001-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443215971000019},
author = {Dominique J. Monlezun},
keywords = {Global public health ecosystem, global health, public health, healthcare, artificial intelligence, deglobalization, decolonization, COVID-19, population health, precision public health, system optimization},
abstract = {This chapter introduces the book’s unique value proposition as the first comprehensive global analysis of how artificial intelligence (AI) is transforming modern health generally—and how it specifically can revolutionize the decolonized global public health ecosystem to equitably empower the world to solve our era’s defining challenges undermining the health of humanity, from climate change to conflicts, debt crises to deglobalization, and demographic collapse to arrested development. In addition, this chapter outlines the historical evolution, from public health’s early days focused on premodern quarantines to the 19th century’s early modern vaccines and workplace safety, to the 20th century’s late modern globalization following World War II, and 21st-century global public health as data-driven sustainable development, digitalized and institutionalized by the United Nations, World Health Organization, and related public–private partnerships. This chapter considers the anticolonial and COVID-19 critiques of this process and the current global public health ecosystem, setting the stage for the “Great COVID Reset” to foster a human security–based approach to scale responsible AI globally by respecting diverse identities, agency, and values, locally. This chapter introduces this approach, the Personalist Liberalism, as the person-centered, health-based political economic framework to understand the emergent future of health in the context of our world’s structural power imbalances between peoples, elites, institutions, corporations, and governments. It summarizes these themes and trends amid the emerging primary categories for AI use cases illustrating them, including population health, precision public health, and system optimization, to set the stage for the remainder of the book focusing on the ecosystem’s main constitutive domains. Finally, this chapter outlines the structure of the book—focused on responsible AI reengineering a global public health ecosystem as a common home for all humanity—with these domains as the components of a home: design (financing and integral development), framework (data architecture and political economics), inhabitants (culture and demographics), and foundation (security and ethics).}
}
",https://www.sciencedirect.com/science/article/pii/B9780443215971000019,https://doi.org/10.1016/B978-0-443-21597-1.00001-9,science_direct,2024
1142,5 - Framework part II: artificial intelligence + political economics,"@incollection{MONLEZUN2024133,
title = {5 - Framework part II: artificial intelligence + political economics},
editor = {Dominique J. Monlezun},
booktitle = {Responsible Artificial Intelligence Re-engineering the Global Public Health Ecosystem},
publisher = {Morgan Kaufmann},
pages = {133-184},
year = {2024},
isbn = {978-0-443-21597-1},
doi = {https://doi.org/10.1016/B978-0-443-21597-1.00005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443215971000056},
author = {Dominique J. Monlezun},
keywords = {Political economics, determinants of health, managed strategic competition, medical diplomacy, supply chain resilience, large language models, clean energy, de-risking, diversification, multilateralism, deterrence, defense, development},
abstract = {This chapter considers the political economic or meta-determinants of health for the global public health ecosystem, critical for the scale, scope, and speed of coordinated actions (including in consensus-based governance and financing) to generate equitable and effective global health solutions to urgent shared challenges. Rising international separation and tensions between democracies and autocracies in addition to the Global North and the Global South undermines the health of these regimes and regions and that of humanity. This chapter thus considers global health and artificial intelligence (AI) in their political economic context in the strategic competition of dominant power players, particularly with the governments, militaries, and corporations of the United States and China which account for most of the global health financing and programs along with that of AI’s development and deployment. Failures in managed strategic competition can not only undermine the cooperation required for the AI-driven global public health ecosystem, but they may even imperil it through accelerated and even catastrophic conflicts. This chapter therefore considers the history and foreseeable future of the global public health ecosystem from the structural perspective of political economics, including the underlying values that may provide a durable foundation for coordinated health action. It additionally considers emergent solutions and advances for the health ecosystem toward this including with human security and data sovereignty within Political Liberalism articulating a bridge between the above blocs, while addressing health determinants integrally and globally: social determinants of health, political determinants of health, economic determinants of health, commercial determinants of health, and digital determinants of health. Specific advances include shared global governance, affordable clean energy transition, and affordable AI digital transformation for sustainable development (with deference and deterrence guardrails maximizing cooperation, managing strategic competition, and minimizing conflict). The chapter additionally considers medical diplomacy, multilateral development, deep medicine, large language models (including ChatGPT), commercial fusion, and digital supply chain resilience (with diversification and de-risking), in the context of moving away from an imperial ideological values-driven ruler-based world order to a more sovereign integral values-driven rules-based world order.}
}
",https://www.sciencedirect.com/science/article/pii/B9780443215971000056,https://doi.org/10.1016/B978-0-443-21597-1.00005-6,science_direct,2024
1164,Contents,"@article{2023iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {221},
pages = {iii-xiv},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(23)00901-8},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923009018}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923009018,https://doi.org/10.1016/S1877-0509(23)00901-8,science_direct,2023
1165,Contents,"@article{2023iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {225},
pages = {iii-xxxi},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(23)01659-9},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923016599}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923016599,https://doi.org/10.1016/S1877-0509(23)01659-9,science_direct,2023
1166,Contents,"@article{2024iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {231},
pages = {iii-x},
year = {2024},
note = {14th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 13th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (EUSPN/ICTH 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(23)02274-3},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923022743}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923022743,https://doi.org/10.1016/S1877-0509(23)02274-3,science_direct,2024
1167,Contents,"@article{2024iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {232},
pages = {iii-xxi},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(24)00329-6},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924003296}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924003296,https://doi.org/10.1016/S1877-0509(24)00329-6,science_direct,2024
1168,Contents,"@article{2024iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {237},
pages = {iii-ix},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(24)01221-3},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924012213}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924012213,https://doi.org/10.1016/S1877-0509(24)01221-3,science_direct,2024
1169,Chapter Eight - Irregular situations in real-world intelligent systems,"@incollection{MISHRA2024253,
title = {Chapter Eight - Irregular situations in real-world intelligent systems},
editor = {Shiho Kim and Ganesh Chandra Deka},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {134},
pages = {253-283},
year = {2024},
booktitle = {Artificial Intelligence and Machine Learning for Open-world Novelty},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2023.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0065245823000438},
author = {Ashutosh Mishra and Shiho Kim},
keywords = {Artificial intelligence, Future mobility, Intelligent systems, Irregular situations, Privacy and safety, SOTIF},
abstract = {Real-world is full of uncertainty. This uncertainty introduces examples of irregular situations (situations that are contrary to the normal routine). Artificial intelligence (AI) has greatly benefited society through automation and intelligent systems. However, real-world situations often involve elements of unpredictability and irregularity, which can pose challenges for AI systems. To address these challenges, researchers have developed various techniques to improve the robustness and adaptability of AI systems. These include methods for handling uncertainty, data pre-processing, explainable AI, safety-critical AI, etc. However, despite these efforts, many open questions and challenges must be addressed to make AI systems more robust and adaptable to real-world situations. In this work, we have defined the possible irregular situations (IS) and introduced the potential solutions to countermeasure such situations. Here, we have surveyed the IS in image, audio, olfactory, and motion intelligence. Further, we have investigated a few of the way-outs and solutions. In addition, we have demonstrated the IS in automated driving depending upon the level of autonomy in autonomous vehicles (AVs) and discussed the safety and privacy issues with a consideration of the safety of the intended functionality (SOTIF) standard. These findings will undoubtedly facilitate research in the direction of future mobility.}
}
",https://www.sciencedirect.com/science/article/pii/S0065245823000438,https://doi.org/10.1016/bs.adcom.2023.04.006,science_direct,2024
1170,A multi-disjunctive-graph model-based memetic algorithm for the distributed job shop scheduling problem,"@article{WANG2024102401,
title = {A multi-disjunctive-graph model-based memetic algorithm for the distributed job shop scheduling problem},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102401},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102401},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624000491},
author = {Sihan Wang and Xinyu Li and Liang Gao and Jiahang Li},
keywords = {Distributed job shop scheduling problem, Multi-disjunctive-graph model, Memetic algorithm, Encoding scheme, Neighborhood structure},
abstract = {With the influence of the digital economy, the traditional manufacturing model is undergoing a shift towards a distributed manufacturing model. This transition involves multiple workshops across diverse geographic regions. The core of distributed manufacturing is the concept of decentralized management and execution, which includes various stages, resources, and tasks within the production process. A key technology in this domain is the distributed shop scheduling problem. Notably, the distributed job shop scheduling problem (DJSSP), considering job shops, is widespread in real distributed manufacturing processes and is difficult to solve as an NP-hard problem. Although several heuristic solvers and metaheuristic algorithms have attempted to address this problem, currently two sub-problems included in the problem, factory allocation and sequence of operations, are treated separately and the description of the problem is incomplete. This paper introduces a multi-disjunctive-graph model-based memetic algorithm (MDGMBMA) developed for DJSSP to minimize the makespan. The multi-disjunctive-graph model is proposed to fully represent the DJSSP solution space. Additionally, an innovative encoding method is proposed to achieve an adequate search of the solution space, and two decoding strategies are proposed to address the search and evaluation demands of the algorithm. Furthermore, based on the property of critical job exchange between factories, a specialized critical job exchange-based neighborhood structure is designed to enhance the efficiency of the tabu search. To evaluate the performance of the MDGMBMA, numerical results from 240 large instances (ranging from 2 to 4 factories) derived from well-known JSSP benchmarks are compared against recently published discrete metaheuristic algorithms. The experimental results indicate that the proposed algorithm performs effectively in solving DJSSP.}
}
",https://www.sciencedirect.com/science/article/pii/S1474034624000491,https://doi.org/10.1016/j.aei.2024.102401,science_direct,2024
1171,Harnessing customized AI to create voice of customer via GPT3.5,"@article{SHAHIN2024102462,
title = {Harnessing customized AI to create voice of customer via GPT3.5},
journal = {Advanced Engineering Informatics},
volume = {61},
pages = {102462},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102462},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624001101},
author = {Mohammad Shahin and F. Frank Chen and Ali Hosseinzadeh},
keywords = {ChatGPT, VoC, Lean Six Sigma, Industry 5.0, Artificial General Intelligence},
abstract = {The integration of customer feedback is universally acknowledged as crucial in the product development process. Yet, traditional feedback collection methods employed by companies, such as interviews and surveys, have remained mainly unchanged and come with limitations. Interviews often fail to accurately capture customers' needs due to communication barriers, while surveys prompt only incremental changes instead of inspiring innovation. This challenge is compounded in the service industry, where feedback is intangible and more difficult to quantify. Text analysis presents a promising solution to delve into customer preferences more deeply, providing insights that can guide the development of new products and services. Our research advances the use of generative AI, specifically the GPT engine, beyond its conventional role as a chatbot. We innovate by adapting it to extract actionable insights from customer-service interactions, offering real-time, valuable data for decision-making and representing a significant leap forward in Voice of the Customer (VoC) analysis.}
}
",https://www.sciencedirect.com/science/article/pii/S1474034624001101,https://doi.org/10.1016/j.aei.2024.102462,science_direct,2024
1172,"Data Collection, data mining and transfer of learning based on customer temperament-centered complaint handling system and one-of-a-kind complaint handling dataset","@article{LEE2024102520,
title = {Data Collection, data mining and transfer of learning based on customer temperament-centered complaint handling system and one-of-a-kind complaint handling dataset},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102520},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102520},
url = {https://www.sciencedirect.com/science/article/pii/S147403462400168X},
author = {Ching-Hung Lee and Xuejiao Zhao},
keywords = {Customer Complaint Handling System, Customer Temperament, Data Mining, Correspondence Analysis, Interactive marketing},
abstract = {One of the most significant sources of information from customers is customer complaints. Successful and effective complaint management can end complaint crises and ensure client loyalty, which is a sign of great service performance. In this paper, we proposed a novel customer temperament-centered and e-CCH system-based data collection and data mining method titled “3D” model for customer complaint data analysis. Three phases are (1) Development and launch of e-Customer Complaint Handling system, (2) Data collection and transfer of learning by e-Customer Complaint Handling system, and (3) Data mining by e-Customer Complaint Handling system. An advanced electronic Customer Complaint Handling System called the e-CCH system was then developed and launched. This system adapts the seasonal associations model based on Hippocrates's customer temperament theory to the whole stages of customer complaint reporting and handling. With this system, we conducted a dataset collection work from restaurant chains of two brands over four years. As a result, we collect thousands of real-world temperament-centred customer complaint cases by four years to form the one-of-a-kind CCH dataset. This one-of-a-kind CCH dataset was open-sourced with detailed customer complaint attributes and heuristic decision-making for valuable industrial handling manner. After further analysis of this dataset, we found that customers with different temperament types tend to have different types of complaints. In addition, adapting the temperament theory to the e-CCH system can classify customer types better and provide personalized solutions. To our best knowledge, this rich and the one-of-a-kind CCH dataset reported in this paper is the first comprehensive study of customer complaint handling in an industrial service management context. Meanwhile, data mining with cross analysis and correspondence analysis and an ChatGPT experiment for transfer of learning based on this yearly and one-of-a-kind industrial customer complaint dataset was analyzed and discussed. In addition, how this dataset may contribute to more realistic complaint-handling theoretic studies for better service failure recovery and interactive marketing is discussed in-depth.}
}
",https://www.sciencedirect.com/science/article/pii/S147403462400168X,https://doi.org/10.1016/j.aei.2024.102520,science_direct,2024
1173,The defeat of the Winograd Schema Challenge,"@article{KOCIJAN2023103971,
title = {The defeat of the Winograd Schema Challenge},
journal = {Artificial Intelligence},
volume = {325},
pages = {103971},
year = {2023},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.103971},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223001170},
author = {Vid Kocijan and Ernest Davis and Thomas Lukasiewicz and Gary Marcus and Leora Morgenstern},
keywords = {Commonsense reasoning, Winograd Schema Challenge},
abstract = {The Winograd Schema Challenge—a set of twin sentences involving pronoun reference disambiguation that seem to require the use of commonsense knowledge—was proposed by Hector Levesque in 2011. By 2019, a number of AI systems, based on large pre-trained transformer-based language models and fine-tuned on these kinds of problems, achieved better than 90% accuracy. In this paper, we review the history of the Winograd Schema Challenge and discuss the lasting contributions of the flurry of research that has taken place on the WSC in the last decade. We discuss the significance of various datasets developed for WSC, and the research community's deeper understanding of the role of surrogate tasks in assessing the intelligence of an AI system.}
}
",https://www.sciencedirect.com/science/article/pii/S0004370223001170,https://doi.org/10.1016/j.artint.2023.103971,science_direct,2023
1174,"Language, common sense, and the Winograd schema challenge","@article{BROWNING2023104031,
title = {Language, common sense, and the Winograd schema challenge},
journal = {Artificial Intelligence},
volume = {325},
pages = {104031},
year = {2023},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.104031},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223001777},
author = {Jacob Browning and Yann LeCun},
keywords = {Winograd schema challenge, Artificial intelligence, Common-sense, Disambiguation, Symbolic AI, Large language models},
abstract = {Since the 1950s, philosophers and AI researchers have held that disambiguating natural language sentences depended on common sense. In 2012, the Winograd Schema Challenge was established to evaluate the common-sense reasoning abilities of a machine by testing its ability to disambiguate sentences. The designers argued only a system capable of “thinking in the full-bodied sense” would be able to pass the test. However, by 2023, the original authors concede the test has been soundly defeated by large language models which still seem to lack common sense of full-bodied thinking. In this paper, we argue that disambiguating sentences only seemed like a good test of common-sense based on a certain picture of the relationship between linguistic comprehension and semantic knowledge—one typically associated with the early computational theory of mind and Symbolic AI. If this picture is rejected, as it is by most LLM researchers, then disambiguation ceases to look like a comprehensive test of common-sense and instead appear only to test linguistic competence. The upshot is that any linguistic test, not just disambiguation, is unlikely to tell us much about common sense or genuine intelligence.}
}
",https://www.sciencedirect.com/science/article/pii/S0004370223001777,https://doi.org/10.1016/j.artint.2023.104031,science_direct,2023
1175,Exploratory machine learning with unknown unknowns,"@article{ZHAO2024104059,
title = {Exploratory machine learning with unknown unknowns},
journal = {Artificial Intelligence},
volume = {327},
pages = {104059},
year = {2024},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.104059},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223002059},
author = {Peng Zhao and Jia-Wei Shan and Yu-Jie Zhang and Zhi-Hua Zhou},
keywords = {Exploratory machine learning, Unknown unknowns, Robust AI, Robustness},
abstract = {In conventional supervised learning, a training dataset is given with ground-truth labels from a known label set, and the learned model will classify unseen instances to known labels. This paper studies a new problem setting in which there are unknown classes in the training data misperceived as other labels, and thus their existence appears unknown from the given supervision. We attribute the unknown unknowns to the fact that the training dataset is badly advised by the incompletely perceived label space due to the insufficient feature information. To this end, we propose the exploratory machine learning, which examines and investigates training data by actively augmenting the feature space to discover potentially hidden classes. Our method consists of three ingredients including rejection model, feature exploration, and model cascade. We provide theoretical analysis to justify its superiority, and validate the effectiveness on both synthetic and real datasets.}
}
",https://www.sciencedirect.com/science/article/pii/S0004370223002059,https://doi.org/10.1016/j.artint.2023.104059,science_direct,2024
1176,A multi-graph representation for event extraction,"@article{HUANG2024104144,
title = {A multi-graph representation for event extraction},
journal = {Artificial Intelligence},
volume = {332},
pages = {104144},
year = {2024},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2024.104144},
url = {https://www.sciencedirect.com/science/article/pii/S0004370224000808},
author = {Hui Huang and Yanping Chen and Chuan Lin and Ruizhang Huang and Qinghua Zheng and Yongbin Qin},
keywords = {Event extraction, Multigraph, Argument multiplexing, Event representation},
abstract = {Event extraction has a trend in identifying event triggers and arguments in a unified framework, which has the advantage of avoiding the cascading failure in pipeline methods. The main problem is that joint models usually assume a one-to-one relationship between event triggers and arguments. It leads to the argument multiplexing problem, in which an argument mention can serve different roles in an event or shared by different events. To address this problem, we propose a multigraph-based event extraction framework. It allows parallel edges between any nodes, which is effective to represent semantic structures of an event. The framework enables the neural network to map a sentence(s) into a structurized semantic representation, which encodes multi-overlapped events. After evaluated on four public datasets, our method achieves the state-of-the-art performance, outperforming all compared models. Analytical experiments show that the multigraph representation is effective to address the argument multiplexing problem and helpful to advance the discriminability of the neural network for event extraction.}
}
",https://www.sciencedirect.com/science/article/pii/S0004370224000808,https://doi.org/10.1016/j.artint.2024.104144,science_direct,2024
1177,Exploring the psychology of LLMs’ moral and legal reasoning,"@article{ALMEIDA2024104145,
title = {Exploring the psychology of LLMs’ moral and legal reasoning},
journal = {Artificial Intelligence},
volume = {333},
pages = {104145},
year = {2024},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2024.104145},
url = {https://www.sciencedirect.com/science/article/pii/S000437022400081X},
author = {Guilherme F.C.F. Almeida and José Luiz Nunes and Neele Engelmann and Alex Wiegmann and Marcelo de Araújo},
keywords = {AI Ethics, Experimental jurisprudence, Ethics of artificial intelligence, Machine Behavior, Moral psychology, Machine psychology, Large language models},
abstract = {Large language models (LLMs) exhibit expert-level performance in tasks across a wide range of different domains. Ethical issues raised by LLMs and the need to align future versions makes it important to know how state of the art models reason about moral and legal issues. In this paper, we employ the methods of experimental psychology to probe into this question. We replicate eight studies from the experimental literature with instances of Google's Gemini Pro, Anthropic's Claude 2.1, OpenAI's GPT-4, and Meta's Llama 2 Chat 70b. We find that alignment with human responses shifts from one experiment to another, and that models differ amongst themselves as to their overall alignment, with GPT-4 taking a clear lead over all other models we tested. Nonetheless, even when LLM-generated responses are highly correlated to human responses, there are still systematic differences, with a tendency for models to exaggerate effects that are present among humans, in part by reducing variance. This recommends caution with regards to proposals of replacing human participants with current state-of-the-art LLMs in psychological research and highlights the need for further research about the distinctive aspects of machine psychology.}
}
",https://www.sciencedirect.com/science/article/pii/S000437022400081X,https://doi.org/10.1016/j.artint.2024.104145,science_direct,2024
1178,Intelligent decision support systems for dementia care: A scoping review,"@article{ANDARGOLI2024102815,
title = {Intelligent decision support systems for dementia care: A scoping review},
journal = {Artificial Intelligence in Medicine},
volume = {150},
pages = {102815},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102815},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000575},
author = {Amirhossein Eslami Andargoli and Nalika Ulapane and Tuan Anh Nguyen and Nadeem Shuakat and John Zelcer and Nilmini Wickramasinghe},
keywords = {Artificial intelligence, Decision support systems, Analytics, Dementia, Alzheimer},
abstract = {In the context of dementia care, Artificial Intelligence (AI) powered clinical decision support systems have the potential to enhance diagnosis and management. However, the scope and challenges of applying these technologies remain unclear. This scoping review aims to investigate the current state of AI applications in the development of intelligent decision support systems for dementia care. We conducted a comprehensive scoping review of empirical studies that utilised AI-powered clinical decision support systems in dementia care. The results indicate that AI applications in dementia care primarily focus on diagnosis, with limited attention to other aspects outlined in the World Health Organization (WHO) Global Action Plan on the Public Health Response to Dementia 2017–2025 (GAPD). A trifecta of challenges, encompassing data availability, cost considerations, and AI algorithm performance, emerges as noteworthy barriers in adoption of AI applications in dementia care. To address these challenges and enhance AI reliability, we propose a novel approach: a digital twin-based patient journey model. Future research should address identified gaps in GAPD action areas, navigate data-related obstacles, and explore the implementation of digital twins. Additionally, it is imperative to emphasize that addressing trust and combating the stigma associated with AI in healthcare should be a central focus of future research directions.}
}
",https://www.sciencedirect.com/science/article/pii/S0933365724000575,https://doi.org/10.1016/j.artmed.2024.102815,science_direct,2024
1179,Challenges and strategies for wide-scale artificial intelligence (AI) deployment in healthcare practices: A perspective for healthcare organizations,"@article{ESMAEILZADEH2024102861,
title = {Challenges and strategies for wide-scale artificial intelligence (AI) deployment in healthcare practices: A perspective for healthcare organizations},
journal = {Artificial Intelligence in Medicine},
volume = {151},
pages = {102861},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102861},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001039},
author = {Pouyan Esmaeilzadeh},
keywords = {Artificial intelligence, AI, Deployment challenges, Healthcare, Data, Ethics, Law},
abstract = {Healthcare organizations have realized that Artificial intelligence (AI) can provide a competitive edge through personalized patient experiences, improved patient outcomes, early diagnosis, augmented clinician capabilities, enhanced operational efficiencies, or improved medical service accessibility. However, deploying AI-driven tools in the healthcare ecosystem could be challenging. This paper categorizes AI applications in healthcare and comprehensively examines the challenges associated with deploying AI in medical practices at scale. As AI continues to make strides in healthcare, its integration presents various challenges, including production timelines, trust generation, privacy concerns, algorithmic biases, and data scarcity. The paper highlights that flawed business models and wrong workflows in healthcare practices cannot be rectified merely by deploying AI-driven tools. Healthcare organizations should re-evaluate root problems such as misaligned financial incentives (e.g., fee-for-service models), dysfunctional medical workflows (e.g., high rates of patient readmissions), poor care coordination between different providers, fragmented electronic health records systems, and inadequate patient education and engagement models in tandem with AI adoption. This study also explores the need for a cultural shift in viewing AI not as a threat but as an enabler that can enhance healthcare delivery and create new employment opportunities while emphasizing the importance of addressing underlying operational issues. The necessity of investments beyond finance is discussed, emphasizing the importance of human capital, continuous learning, and a supportive environment for AI integration. The paper also highlights the crucial role of clear regulations in building trust, ensuring safety, and guiding the ethical use of AI, calling for coherent frameworks addressing transparency, model accuracy, data quality control, liability, and ethics. Furthermore, this paper underscores the importance of advancing AI literacy within academia to prepare future healthcare professionals for an AI-driven landscape. Through careful navigation and proactive measures addressing these challenges, the healthcare community can harness AI's transformative power responsibly and effectively, revolutionizing healthcare delivery and patient care. The paper concludes with a vision and strategic suggestions for the future of healthcare with AI, emphasizing thoughtful, responsible, and innovative engagement as the pathway to realizing its full potential to unlock immense benefits for healthcare organizations, physicians, nurses, and patients while proactively mitigating risks.}
}
",https://www.sciencedirect.com/science/article/pii/S0933365724001039,https://doi.org/10.1016/j.artmed.2024.102861,science_direct,2024
1180,Application of machine learning in affordable and accessible insulin management for type 1 and 2 diabetes: A comprehensive review,"@article{EGHBALIZARCH2024102868,
title = {Application of machine learning in affordable and accessible insulin management for type 1 and 2 diabetes: A comprehensive review},
journal = {Artificial Intelligence in Medicine},
volume = {151},
pages = {102868},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102868},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001106},
author = {Maryam Eghbali-Zarch and Sara Masoud},
keywords = {Insulin treatment, Diabetes management, Insulin affordability, Machine learning, Supervised learning},
abstract = {Proper insulin management is vital for maintaining stable blood sugar levels and preventing complications associated with diabetes. However, the soaring costs of insulin present significant challenges to ensuring affordable management. This paper conducts a comprehensive review of current literature on the application of machine learning (ML) in insulin management for diabetes patients, particularly focusing on enhancing affordability and accessibility within the United States. The review encompasses various facets of insulin management, including dosage calculation and response, prediction of blood glucose and insulin sensitivity, initial insulin estimation, resistance prediction, treatment adherence, complications, hypoglycemia prediction, and lifestyle modifications. Additionally, the study identifies key limitations in the utilization of ML within the insulin management literature and suggests future research directions aimed at furthering accessible and affordable insulin treatments. These proposed directions include exploring insurance coverage, optimizing insulin type selection, assessing the impact of biosimilar insulin and market competition, considering mental health factors, evaluating insulin delivery options, addressing cost-related issues affecting insulin usage and adherence, and selecting appropriate patient cost-sharing programs. By examining the potential of ML in addressing insulin management affordability and accessibility, this work aims to envision improved and cost-effective insulin management practices. It not only highlights existing research gaps but also offers insights into future directions, guiding the development of innovative solutions that have the potential to revolutionize insulin management and benefit patients reliant on this life-saving treatment.}
}
",https://www.sciencedirect.com/science/article/pii/S0933365724001106,https://doi.org/10.1016/j.artmed.2024.102868,science_direct,2024
1181,"The AI ethics of digital COVID-19 diagnosis and their legal, medical, technological, and operational managerial implications","@article{BARTENSCHLAGER2024102873,
title = {The AI ethics of digital COVID-19 diagnosis and their legal, medical, technological, and operational managerial implications},
journal = {Artificial Intelligence in Medicine},
volume = {152},
pages = {102873},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102873},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001155},
author = {Christina C. Bartenschlager and Ulrich M. Gassner and Christoph Römmele and Jens O. Brunner and Kerstin Schlögl-Flierl and Paula Ziethmann},
keywords = {AI ethics, Digital diagnosis of COVID-19, Interdisciplinary stakeholders},
abstract = {The COVID-19 pandemic has given rise to a broad range of research from fields alongside and beyond the core concerns of infectiology, epidemiology, and immunology. One significant subset of this work centers on machine learning-based approaches to supporting medical decision-making around COVID-19 diagnosis. To date, various challenges, including IT issues, have meant that, notwithstanding this strand of research on digital diagnosis of COVID-19, the actual use of these methods in medical facilities remains incipient at best, despite their potential to relieve pressure on scarce medical resources, prevent instances of infection, and help manage the difficulties and unpredictabilities surrounding the emergence of new mutations. The reasons behind this research-application gap are manifold and may imply an interdisciplinary dimension. We argue that the discipline of AI ethics can provide a framework for interdisciplinary discussion and create a roadmap for the application of digital COVID-19 diagnosis, taking into account all disciplinary stakeholders involved. This article proposes such an ethical framework for the practical use of digital COVID-19 diagnosis, considering legal, medical, operational managerial, and technological aspects of the issue in accordance with our diverse research backgrounds and noting the potential of the approach we set out here to guide future research.}
}
",https://www.sciencedirect.com/science/article/pii/S0933365724001155,https://doi.org/10.1016/j.artmed.2024.102873,science_direct,2024
1182,Transformers and large language models in healthcare: A review,"@article{NERELLA2024102900,
title = {Transformers and large language models in healthcare: A review},
journal = {Artificial Intelligence in Medicine},
volume = {154},
pages = {102900},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102900},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001428},
author = {Subhash Nerella and Sabyasachi Bandyopadhyay and Jiaqing Zhang and Miguel Contreras and Scott Siegel and Aysegul Bumin and Brandon Silva and Jessica Sena and Benjamin Shickel and Azra Bihorac and Kia Khezeli and Parisa Rashidi},
keywords = {Transformers, Healthcare, Electronic Health Records, Large Language Models, Medical Imaging, Natural Language Processing},
abstract = {With Artificial Intelligence (AI) increasingly permeating various aspects of society, including healthcare, the adoption of the Transformers neural network architecture is rapidly changing many applications. Transformer is a type of deep learning architecture initially developed to solve general-purpose Natural Language Processing (NLP) tasks and has subsequently been adapted in many fields, including healthcare. In this survey paper, we provide an overview of how this architecture has been adopted to analyze various forms of healthcare data, including clinical NLP, medical imaging, structured Electronic Health Records (EHR), social media, bio-physiological signals, biomolecular sequences. Furthermore, which have also include the articles that used the transformer architecture for generating surgical instructions and predicting adverse outcomes after surgeries under the umbrella of critical care. Under diverse settings, these models have been used for clinical diagnosis, report generation, data reconstruction, and drug/protein synthesis. Finally, we also discuss the benefits and limitations of using transformers in healthcare and examine issues such as computational cost, model interpretability, fairness, alignment with human values, ethical implications, and environmental impact.}
}
",https://www.sciencedirect.com/science/article/pii/S0933365724001428,https://doi.org/10.1016/j.artmed.2024.102900,science_direct,2024
1183,Pre-trained language models in medicine: A survey,"@article{LUO2024102904,
title = {Pre-trained language models in medicine: A survey},
journal = {Artificial Intelligence in Medicine},
volume = {154},
pages = {102904},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102904},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001465},
author = {Xudong Luo and Zhiqi Deng and Binxia Yang and Michael Y. Luo},
keywords = {Natural language processing, Medical science, Healthcare, Pre-trained language model, BERT, GPT},
abstract = {With the rapid progress in Natural Language Processing (NLP), Pre-trained Language Models (PLM) such as BERT, BioBERT, and ChatGPT have shown great potential in various medical NLP tasks. This paper surveys the cutting-edge achievements in applying PLMs to various medical NLP tasks. Specifically, we first brief PLMS and outline the research of PLMs in medicine. Next, we categorise and discuss the types of tasks in medical NLP, covering text summarisation, question-answering, machine translation, sentiment analysis, named entity recognition, information extraction, medical education, relation extraction, and text mining. For each type of task, we first provide an overview of the basic concepts, the main methodologies, the advantages of applying PLMs, the basic steps of applying PLMs application, the datasets for training and testing, and the metrics for task evaluation. Subsequently, a summary of recent important research findings is presented, analysing their motivations, strengths vs weaknesses, similarities vs differences, and discussing potential limitations. Also, we assess the quality and influence of the research reviewed in this paper by comparing the citation count of the papers reviewed and the reputation and impact of the conferences and journals where they are published. Through these indicators, we further identify the most concerned research topics currently. Finally, we look forward to future research directions, including enhancing models’ reliability, explainability, and fairness, to promote the application of PLMs in clinical practice. In addition, this survey also collect some download links of some model codes and the relevant datasets, which are valuable references for researchers applying NLP techniques in medicine and medical professionals seeking to enhance their expertise and healthcare service through AI technology.}
}
",https://www.sciencedirect.com/science/article/pii/S0933365724001465,https://doi.org/10.1016/j.artmed.2024.102904,science_direct,2024
1184,Attention-based multimodal sentiment analysis and emotion recognition using deep neural networks,"@article{ASLAM2023110494,
title = {Attention-based multimodal sentiment analysis and emotion recognition using deep neural networks},
journal = {Applied Soft Computing},
volume = {144},
pages = {110494},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110494},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623005124},
author = {Ajwa Aslam and Allah Bux Sargano and Zulfiqar Habib},
keywords = {Sentiment analysis, Emotion recognition, Multimodal attention, Deep neural networks},
abstract = {There has been a growing interest in multimodal sentiment analysis and emotion recognition in recent years due to its wide range of practical applications. Multiple modalities allow for the integration of complementary information, improving the accuracy and precision of sentiment and emotion recognition tasks. However, working with multiple modalities presents several challenges, including handling data source heterogeneity, fusing information, aligning and synchronizing modalities, and designing effective feature extraction techniques that capture discriminative information from each modality. This paper introduces a novel framework called “Attention-based Multimodal Sentiment Analysis and Emotion Recognition (AMSAER)” to address these challenges. This framework leverages intra-modality discriminative features and inter-modality correlations in visual, audio, and textual modalities. It incorporates an attention mechanism to facilitate sentiment and emotion classification based on visual, textual, and acoustic inputs by emphasizing relevant aspects of the task. The proposed approach employs separate models for each modality to automatically extract discriminative semantic words, image regions, and audio features. A deep hierarchical model is then developed, incorporating intermediate fusion to learn hierarchical correlations between the modalities at bimodal and trimodal levels. Finally, the framework combines four distinct models through decision-level fusion to enable multimodal sentiment analysis and emotion recognition. The effectiveness of the proposed framework is demonstrated through extensive experiments conducted on the publicly available Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset. The results confirm a notable performance improvement compared to state-of-the-art methods, attaining 85% and 93% accuracy for sentiment analysis and emotion classification, respectively. Additionally, when considering class-wise accuracy, the results indicate that the “angry” emotion and “positive” sentiment are classified more effectively than the other emotions and sentiments, achieving 96.80% and 93.14% accuracy, respectively.}
}
",https://www.sciencedirect.com/science/article/pii/S1568494623005124,https://doi.org/10.1016/j.asoc.2023.110494,science_direct,2023
1185,Def-DReL: Towards a sustainable serverless functions deployment strategy for fog-cloud environments using deep reinforcement learning,"@article{DEHURY2024111179,
title = {Def-DReL: Towards a sustainable serverless functions deployment strategy for fog-cloud environments using deep reinforcement learning},
journal = {Applied Soft Computing},
volume = {152},
pages = {111179},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.111179},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623011973},
author = {Chinmaya Kumar Dehury and Shivananda Poojara and Satish Narayana Srirama},
keywords = {Serverless computing, Fog computing, Cloud computing, Deep reinforcement learning, Serverless function deployment, Function offloading},
abstract = {Modern cloud applications are composed of tens of thousands of environment-agnostic serverless functions that can be deployed in either a fog or cloud environment. The key to sustaining fog computing is to offload the maximum amounts of computation to the cloud, and accommodate as many users as possible without compromising quality of service (QoS). However, recent research mainly focuses on assigning maximum resources to serverless applications from the fog node and not taking full advantage of the cloud environment, leading to a lack of sustainability in fog computing. As a way to fill this research gap, we explored what percentage of a user’s request should be handled by fog and cloud. As a result, we proposed Def-DReL, a Systematic Deployment of Serverless Functions in Fog and Cloud environments using Deep Reinforcement Learning, by taking into account several real-life parameters, including distance from a nearby fog node and latency, priority of the user, priority of serverless applications, and resource usage. Def-DReL’s performance is further compared with that of recent related algorithms. Simulation and comparison results clearly demonstrate a lesser number of serverless functions from each user (with approximately 10% improvement) being deployed in the fog node, resulting in accommodating limited fog resources to more number of users. The other simulation results show its superiority over other algorithms as well as its applicability to real-life scenarios.}
}
",https://www.sciencedirect.com/science/article/pii/S1568494623011973,https://doi.org/10.1016/j.asoc.2023.111179,science_direct,2024
1186,Towards unbalanced multiclass intrusion detection with hybrid sampling methods and ensemble classification,"@article{LE2024111517,
title = {Towards unbalanced multiclass intrusion detection with hybrid sampling methods and ensemble classification},
journal = {Applied Soft Computing},
volume = {157},
pages = {111517},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111517},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624002916},
author = {Thi-Thu-Huong Le and Yeongjae Shin and Myeongkil Kim and Howon Kim},
keywords = {Intrusion detection, Unbalanced data, Ensemble classification, Undersampling, Oversampling, Hybrid sampling},
abstract = {Intrusion Detection Systems (IDS) play a crucial role in securing computer networks against malicious activities. However, their efficacy is consistently hindered by the persistent challenge of class imbalance in real-world datasets. While various methods, such as resampling techniques, ensemble methods, cost-sensitive learning, data augmentation, and so on, have individually addressed imbalance classification issues, there exists a notable gap in the literature for effective hybrid methodologies aimed at enhancing IDS performance. To bridge this gap, our research introduces an innovative methodology that integrates hybrid undersampling and oversampling strategies within an ensemble classification framework. This novel approach is designed to harmonize dataset distributions and optimize IDS performance, particularly in intricate multi-class scenarios. In-depth evaluations were conducted using well-established intrusion detection datasets, including the Car Hacking: Attack and Defense Challenge 2020 (CHADC2020) and IoTID20. Our results showcase the remarkable efficacy of the proposed methodology, revealing significant improvements in precision, recall, and F1-score metrics. Notably, the hybrid-ensemble method demonstrated an exemplary average F1 score exceeding 98% for both datasets, underscoring its exceptional capability to substantially enhance intrusion detection accuracy. In summary, this research represents a significant contribution to the field of IDS, providing a robust solution to the pervasive challenge of class imbalance. The hybrid framework not only strengthens IDS efficacy but also illuminates the seamless integration of undersampling and oversampling within ensemble classifiers, paving the way for fortified network defenses.}
}
",https://www.sciencedirect.com/science/article/pii/S1568494624002916,https://doi.org/10.1016/j.asoc.2024.111517,science_direct,2024
1187,The fusion of fuzzy theories and natural language processing: A state-of-the-art survey,"@article{LIU2024111818,
title = {The fusion of fuzzy theories and natural language processing: A state-of-the-art survey},
journal = {Applied Soft Computing},
volume = {162},
pages = {111818},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111818},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624005921},
author = {Ming Liu and Hongjun Zhang and Zeshui Xu and Kun Ding},
keywords = {Fuzzy theory, Natural language processing, Fusion, Artificial intelligence},
abstract = {Recent years have witnessed a drastic surge in natural language processing (NLP), which is a popular research orientation in artificial intelligence. In contrast to precise numbers, human language is very complex and diverse, with millions of expressions, both spoken and written. It is due to this ambiguity and imprecision that most of the problems in NLP relating to cognition, translation, and understanding are non-trivial. Fuzzy theory, which accepts the fact that ambiguity exists, aims to address and actively quantify conceptual vagueness into messages that can be processed by computers. Following the thread of recent studies, we systematically review the fusion of fuzzy theory and NLP technologies from the aspects of commonly used fuzzy theories in NLP, the NLP tasks fuzzy theories are applied to, the application fields of fusion and the basic paradigms of fusion. Towards the end of this paper, we delineate the constraints and obstacles encountered in current researches, while also endeavoring to suggest avenues for enhancement that may serve as a reference for subsequent scholarly inquiry.}
}
",https://www.sciencedirect.com/science/article/pii/S1568494624005921,https://doi.org/10.1016/j.asoc.2024.111818,science_direct,2024
1188,Large language models for human–robot interaction: A review,"@article{ZHANG2023100131,
title = {Large language models for human–robot interaction: A review},
journal = {Biomimetic Intelligence and Robotics},
volume = {3},
number = {4},
pages = {100131},
year = {2023},
issn = {2667-3797},
doi = {https://doi.org/10.1016/j.birob.2023.100131},
url = {https://www.sciencedirect.com/science/article/pii/S2667379723000451},
author = {Ceng Zhang and Junxin Chen and Jiatong Li and Yanhong Peng and Zebing Mao},
keywords = {Large language models, Human–robot interaction, Task completion, Considerations and challenges},
abstract = {The fusion of large language models and robotic systems has introduced a transformative paradigm in human–robot interaction, offering unparalleled capabilities in natural language understanding and task execution. This review paper offers a comprehensive analysis of this nascent but rapidly evolving domain, spotlighting the recent advances of Large Language Models (LLMs) in enhancing their structures and performances, particularly in terms of multimodal input handling, high-level reasoning, and plan generation. Moreover, it probes the current methodologies that integrate LLMs into robotic systems for complex task completion, from traditional probabilistic models to the utilization of value functions and metrics for optimal decision-making. Despite these advancements, the paper also reveals the formidable challenges that confront the field, such as contextual understanding, data privacy and ethical considerations. To our best knowledge, this is the first study to comprehensively analyze the advances and considerations of LLMs in Human–Robot Interaction (HRI) based on recent progress, which provides potential avenues for further research.}
}
",https://www.sciencedirect.com/science/article/pii/S2667379723000451,https://doi.org/10.1016/j.birob.2023.100131,science_direct,2023
1189,Issue 112: A Note from the Editor-in-Chief,"@article{JORGE2023A1,
title = {Issue 112: A Note from the Editor-in-Chief},
journal = {Computers & Graphics},
volume = {112},
pages = {A1-A4},
year = {2023},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2023.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0097849323000833},
author = {Joaquim Jorge}
}
",https://www.sciencedirect.com/science/article/pii/S0097849323000833,https://doi.org/10.1016/j.cag.2023.06.002,science_direct,2023
1190,XR technologies to enhance the emotional skills of people with autism spectrum disorder: A systematic review,"@article{POGLITSCH2024103942,
title = {XR technologies to enhance the emotional skills of people with autism spectrum disorder: A systematic review},
journal = {Computers & Graphics},
volume = {121},
pages = {103942},
year = {2024},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2024.103942},
url = {https://www.sciencedirect.com/science/article/pii/S0097849324000773},
author = {Christian Poglitsch and Saeed Safikhani and Erin List and Johanna Pirker},
keywords = {Extended reality (XR), Virtual reality (VR), Augmented reality (AR), Autism spectrum disorder, Emotional skills, Emotion recognition},
abstract = {In this paper, we present a systematic review of the applications of (1) Extended Reality (XR), (2) Augmented Reality (AR), and (3) Virtual Reality (VR) technologies to enhance emotion recognition and emotion expression in people with Autism Spectrum Disorder (ASD). ASD can affect various abilities, and poses challenges to the recognition of emotions in others, which is often referred to as “social blindness”. Treating this condition typically requires intensive one-on-one or small-group therapy sessions, which can be costly and limited in terms of availability. With the growing number of diagnoses of ASD, concerns have risen regarding a potential “lost generation” that may face difficulties in fulfilling its potential. Through this comprehensive review, we aim to provide an overview of innovative approaches that use XR technologies to improve the learning experience of individuals with ASD.}
}
",https://www.sciencedirect.com/science/article/pii/S0097849324000773,https://doi.org/10.1016/j.cag.2024.103942,science_direct,2024
1191,Do background characteristics matter in Children's mastery of digital literacy? A cognitive diagnosis model analysis,"@article{LIANG2021106850,
title = {Do background characteristics matter in Children's mastery of digital literacy? A cognitive diagnosis model analysis},
journal = {Computers in Human Behavior},
volume = {122},
pages = {106850},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106850},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221001734},
author = {Qianru Liang and Jimmy {de la Torre} and Nancy Law},
keywords = {Digital literacy, Background characteristics, Cognitive diagnosis models, Three-step analysis approach, Latent logistic regression},
abstract = {This study aims to investigate the mastery profiles of digital literacy skills of Hong Kong primary students using a general cognitive diagnosis model (CDM) framework. In particular, the relationship between the mastery of each digital skill and a number of students' background characteristics is explored using a three-step approach. The current study analyzes data collected from 642 Grade 3 students in Hong Kong using a newly developed digital literacy assessment (DLA). CDMs are fitted to the data to determine students' mastery profiles of five digital skills, as well as test properties; subsequently latent logistic regression analyses were implemented to determine the relationship between skill mastery and the covariates. Results indicate that CDM analysis is an appropriate method to analyze the DLA performance data, which exhibited measurement invariance across gender and socioeconomic status (SES). Despite low mastery proportions for all digital skills, students' skill mastery can be accurately classified. Finally, the latent logistic regression results indicate that children's background characteristics (i.e., gender, educational aspiration, home language, SES, and access to digital devices) are differentially related to their mastery of each digital skill.}
}
",https://www.sciencedirect.com/science/article/pii/S0747563221001734,https://doi.org/10.1016/j.chb.2021.106850,science_direct,2021
1192,Exploring relationship development with social chatbots: A mixed-method study of replika,"@article{PENTINA2023107600,
title = {Exploring relationship development with social chatbots: A mixed-method study of replika},
journal = {Computers in Human Behavior},
volume = {140},
pages = {107600},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2022.107600},
url = {https://www.sciencedirect.com/science/article/pii/S0747563222004204},
author = {Iryna Pentina and Tyler Hancock and Tianling Xie},
keywords = {Social chatbot, Relationship development, Attachment, Anthropomorphism, Authenticity, Replika},
abstract = {This mixed-method investigation proposes and empirically tests a human-Artificial Intelligence (AI) relationship development model in the context of social chatbots. Utilizing data from representative populations and employing method triangulation, the study uniquely combines existing human-computer interaction theoretical concepts (Computers are Social Actors, Perceived Social Presence, and Parasocial Interaction) with interpersonal relationship theories (Social Penetration and Attachment Theories) to advance an explanatory model of human – AI relationship development mechanism. We identify AI Anthropomorphism and AI Authenticity as antecedents, AI Social Interaction as a mediator, and Attachment to AI as an outcome of this process, moderated by the AI usage motivations. Meaningful theoretical, managerial, and societal implications, as well as suggestions for chatbot designers and future research are provided.}
}
",https://www.sciencedirect.com/science/article/pii/S0747563222004204,https://doi.org/10.1016/j.chb.2022.107600,science_direct,2023
1193,How to leverage anthropomorphism for chatbot service interfaces: The interplay of communication style and personification,"@article{JANSON2023107954,
title = {How to leverage anthropomorphism for chatbot service interfaces: The interplay of communication style and personification},
journal = {Computers in Human Behavior},
volume = {149},
pages = {107954},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107954},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003059},
author = {Andreas Janson},
keywords = {Chatbots, Conversational agents, Anthropomorphic design, Social presence, Empathy, Trust},
abstract = {Although chatbots are oftentimes used in customer service encounters, interactions are oftentimes perceived as not satisfactory. One key aspect for designing chatbots is the use of anthropomorphic design elements. In this experimental study, we examine the two anthropomorphic chatbot design elements of personification, which includes a human-like appearance, and social orientation of communication style, which means a more sensitive and extensive communication. We tested the influence of the two design elements on social presence, satisfaction, trust and empathy towards a chatbot. First, the results show a significant influence of both anthropomorphic design elements on social presence. Second, our findings illustrate that social presence influences trusting beliefs, empathy, and satisfaction. Third, social presence acts as a mediator for both anthropomorphic design elements for satisfaction with a chatbot. Our implications provide a better understanding of anthropomorphic chatbot design elements when designing chatbots for short-term interactions, and we offer actionable implications for practice that enable more effective chatbot implementations.}
}
",https://www.sciencedirect.com/science/article/pii/S0747563223003059,https://doi.org/10.1016/j.chb.2023.107954,science_direct,2023
1194,A Machine's ethos? An inquiry into artificial ethos and trust,"@article{SKAUGSAETRA2024108108,
title = {A Machine's ethos? An inquiry into artificial ethos and trust},
journal = {Computers in Human Behavior},
volume = {153},
pages = {108108},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.108108},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223004594},
author = {Henrik {Skaug Sætra}},
keywords = {Ethos, Trust, Reliance, Rhetoric, Human-machine interaction, Human-robot-interaction},
abstract = {Every day we trust other individuals as we engage in social interactions in which various desirable outcomes depend on others acting the way we hope, or they have indicated. Trust extends beyond specific individuals, however, as we might trust unknown others – individuals, institutions, corporations, and governments. Some also say that we trust various artifacts, such as machines. But what is the basis of trust, and can we really trust technology? Trust is intimately connected to the notion ethos from the study of rhetoric and human persuasion, which is often used to describe various characteristics of the speaker, the audience, the relationship between the speaker and the audience, and the wider context in which communication and interaction occurs. In this article I explore to what degree machines can be considered to have ethos, and consequently whether ethos is a useful concept for understanding persuasive and credibility-related situations in HMI and by extension key aspects of human-machine trust. This allows us to draw on a long lineage of research from, for example, rhetoric, communication studies, and cognitive and social psychology to better understand the usefulness – or not – of using the notion of trust to describe our relationship with machines.}
}
",https://www.sciencedirect.com/science/article/pii/S0747563223004594,https://doi.org/10.1016/j.chb.2023.108108,science_direct,2024
1195,Beyond traditional interviews: Psychometric analysis of asynchronous video interviews for personality and interview performance evaluation using machine learning,"@article{KOUTSOUMPIS2024108128,
title = {Beyond traditional interviews: Psychometric analysis of asynchronous video interviews for personality and interview performance evaluation using machine learning},
journal = {Computers in Human Behavior},
volume = {154},
pages = {108128},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.108128},
url = {https://www.sciencedirect.com/science/article/pii/S074756322300479X},
author = {Antonis Koutsoumpis and Sina Ghassemi and Janneke K. Oostrom and Djurre Holtrop and Ward {van Breda} and Tianyi Zhang and Reinout E. {de Vries}},
keywords = {Artificial intelligence, Asynchronous video interview, Personality, Trait activation theory, Algorithmic bias},
abstract = {With the advent of new technology, traditional job interviews have been supplemented by asynchronous video interviews (AVIs). However, research on psychometric properties of AVIs is limited. In this study, 710 participants completed a mock AVI responding to eight personality questions (Extraversion, Conscientiousness). We collected self- and observer reports of personality, interview performance ratings, attractiveness, and AVI meta-information (e.g., professional attire, audio quality). Then, we automatically extracted the words, facial expressions, and voice characteristics from the videos and trained machine learning models to predict the personality traits and interview performance. Our algorithm explained substantially more variance in observer reports of Extraversion and Conscientiousness (average R2 = 0.32) and interview performance (R2 = 0.44), than self-reported Extraversion and Conscientiousness (average R2 = 0.12). Consistent with Trait Activation Theory, the explained variance in personality traits increased when participants responded to trait-relevant, compared to trait-irrelevant, questions. The test-retest reliability of our algorithm was somewhat stable over a time period of seven months, but lower than desired reliability standards in personnel selection. We examined potential sources of bias, including age, gender, and attractiveness, and found some instances of algorithmic bias (e.g., gender differences were often amplified in favor of women).}
}
",https://www.sciencedirect.com/science/article/pii/S074756322300479X,https://doi.org/10.1016/j.chb.2023.108128,science_direct,2024
1196,The automated model of comprehension version 4.0 – Validation studies and integration of ChatGPT,"@article{CORLATESCU2024108154,
title = {The automated model of comprehension version 4.0 – Validation studies and integration of ChatGPT},
journal = {Computers in Human Behavior},
volume = {154},
pages = {108154},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108154},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000219},
author = {Dragos-Georgian Corlatescu and Micah Watanabe and Stefan Ruseti and Mihai Dascalu and Danielle S. McNamara},
keywords = {Natural language processing, Reading comprehension, Automated model of comprehension, ChatGPT, Large language models},
abstract = {Modeling reading comprehension processes is a critical task for Learning Analytics, as accurate models of the reading process can be used to match students to texts, identify appropriate interventions, and predict learning outcomes. This paper introduces an improved version of the Automated Model of Comprehension, namely version 4.0. AMoC has its roots in two theoretical models of the comprehension process (i.e., the Construction-Integration model and the Landscape model), and the new version leverages state-of-the-art Large Language models, more specifically ChatGPT, to have a better contextualization of the text and a simplified construction of the underlying graph model. Besides showcasing the usage of the model, the study introduces three in-depth psychological validations that argue for the model's adequacy in modeling reading comprehension. In these studies, we demonstrated that AMoC is in line with the theoretical background proposed by the Construction-Integration and Landscape models, and it is better at replicating results from previous human psychological experiments than its predecessor. Thus, AMoC v4.0 can be further used as an educational tool to, for example, help teachers design better learning materials personalized for student profiles. Additionally, we release the code from AMoC v4.0 as open source in a Google Collab Notebook and a GitHub repository.}
}
",https://www.sciencedirect.com/science/article/pii/S0747563224000219,https://doi.org/10.1016/j.chb.2024.108154,science_direct,2024
1197,Using machine learning for continuous updating of meta-analysis in educational context,"@article{CHERNIKOVA2024108215,
title = {Using machine learning for continuous updating of meta-analysis in educational context},
journal = {Computers in Human Behavior},
volume = {156},
pages = {108215},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108215},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000839},
author = {Olga Chernikova and Matthias Stadler and Ivan Melev and Frank Fischer},
keywords = {Machine learning, Abstract screening, Systematic literature review, Meta-analysis},
abstract = {Machine learning and learning analytics are powerful tools that not only support researchers in the detailed measurement and enhancement of learning processes in various learning environments, but also enable the aggregation and synthesis of evidence regarding effective educational practices. This paper describes the development and application of machine learning algorithms aimed at semi-automatic selection of abstracts for a meta-analysis on the effects of simulation-based learning in higher education. The goal was to reduce the workload while also maintaining the transparency and objectivity of the selection process. The algorithms were trained, validated, and tested on a set of 3187 studies on simulation-based learning found in medical and educational databases collected before April 2018. Subsequently, they were utilized to classify abstracts for a follow-up meta-analysis consisting of 2373 studies (published between 2018 and 2020). The aim of training the algorithms was to predict studies’ abstract eligibility based on words and combinations of words used in these abstracts. The application of the algorithms reduced the number of studies that had to be manually screened from 2373 to 711. A total of 458 studies from automatically selected abstracts were included in the full-text screening, indicating the high precision of the algorithms (also compared to the performance of human raters). We conclude that machine learning algorithms can be trained and used to classify abstracts for their eligibility, significantly reducing the workload for the researchers without diminishing objectivity and quality when updating systematic literature reviews with or without a meta-analysis.}
}
",https://www.sciencedirect.com/science/article/pii/S0747563224000839,https://doi.org/10.1016/j.chb.2024.108215,science_direct,2024
1198,The End is the Beginning is the End: The closed-loop learning analytics framework,"@article{SAILER2024108305,
title = {The End is the Beginning is the End: The closed-loop learning analytics framework},
journal = {Computers in Human Behavior},
volume = {158},
pages = {108305},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108305},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224001730},
author = {Michael Sailer and Manuel Ninaus and Stefan E. Huber and Elisabeth Bauer and Samuel Greiff},
keywords = {Learning analytics, Multimodal, Artificial intelligence, Education, Adaptivity, Personalization},
abstract = {This article provides a comprehensive review of current practices and methodologies within the field of learning analytics, structured around a dedicated closed-loop framework. This framework effectively integrates various aspects of learning analytics into a cohesive framework, emphasizing the interplay between data collection, processing and analysis, as well as adaptivity and personalization, all connected by the learners involved and underpinned by educational and psychological theory. In reviewing each step of the closed loop, the article delves into the advancements in data collection, exploring how technological progress has expanded data collection methods, particularly focusing on the potential of multimodal data acquisition and how theory can inform this step. The processing and analysis step is thoroughly reviewed, highlighting a range of methods including machine learning and AI, and discussing the critical balance between prediction accuracy and interpretability. The adaptivity and personalization step examines the current state of research, underscoring significant gaps and the necessity for theory-informed, personalized learning interventions. Overall, the article underscores the importance of interdisciplinarity in learning analytics, advocating for the integration of insights from various fields to address challenges such as ethical data usage and the creation of quality learning experiences. This framework and review aim to guide future research and practice in learning analytics, promoting the development of effective, learner-centric educational environments driven by balancing data-driven insights and theoretical understanding.}
}
",https://www.sciencedirect.com/science/article/pii/S0747563224001730,https://doi.org/10.1016/j.chb.2024.108305,science_direct,2024
1199,Trust and reliance on AI — An experimental study on the extent and costs of overreliance on AI,"@article{KLINGBEIL2024108352,
title = {Trust and reliance on AI — An experimental study on the extent and costs of overreliance on AI},
journal = {Computers in Human Behavior},
pages = {108352},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108352},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224002206},
author = {Artur Klingbeil and Cassandra Grützner and Philipp Schreck},
keywords = {Human-computer interaction, Behavioral experiment, Reliance behavior, Trust attitude, Overreliance, Algorithm appreciation},
abstract = {Decision-making is undergoing rapid changes due to the introduction of artificial intelligence (AI), as AI recommender systems can help mitigate human flaws and increase decision accuracy and efficiency. However, AI can also commit errors or suffer from algorithmic bias. Hence, blind trust in technologies carries risks, as users may follow detrimental advice resulting in undesired consequences. Building upon research on algorithm appreciation and trust in AI, the current study investigates whether users who receive AI advice in an uncertain situation overrely on this advice — to their own detriment and that of other parties. In a domain-independent, incentivized, and interactive behavioral experiment, we find that the mere knowledge of advice being generated by an AI causes people to overrely on it, that is, to follow AI advice even when it contradicts available contextual information as well as their own assessment. Frequently, this overreliance leads not only to inefficient outcomes for the advisee, but also to undesired effects regarding third parties. The results call into question how AI is being used in assisted decision making, emphasizing the importance of AI literacy and effective trust calibration for productive deployment of such systems.}
}
",https://www.sciencedirect.com/science/article/pii/S0747563224002206,https://doi.org/10.1016/j.chb.2024.108352,science_direct,2024
1208,Globalization and regulatory change: The interplay of laws and technologies in E-commerce in Southeast Asia,"@article{KIM2019105315,
title = {Globalization and regulatory change: The interplay of laws and technologies in E-commerce in Southeast Asia},
journal = {Computer Law & Security Review},
volume = {35},
number = {5},
pages = {105315},
year = {2019},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2019.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0267364918304308},
author = {Heejin Kim},
keywords = {Electronic commerce law, The use and recognition of electronic signatures, Technological neutrality, ASEAN law and policy, Domestic regulatory adaptation},
abstract = {Electronic commerce has brought about business and technological changes globally, and these global changes have given rise to major legal reforms across nations. In the fast-changing global digital economy, states need strategies to maintain competitiveness of their markets while simultaneously ensuring the secure and effective use of technologies involved in conducting electronic transactions. This paper examines how the use and recognition of electronic signatures are regulated in Southeast Asia – the region that has shown the most significant growth in global e-commerce in past few years. Based on a comparative analysis of the laws of four representative ASEAN member states – namely Singapore, Thailand, Malaysia, and Vietnam, this paper argues that there is a regional trend towards adopting more liberal and technology-neutral standards for electronic signatures. Electronic signature regulation in Southeast Asia is now built upon limited technological neutrality (or the so-called “two-tiered” approach) as a shared regulatory understanding, but this approach is operationalized differently in each state due to distinctive national contexts. Within the common legal framework, each state has developed its own system of control and management with respect to higher-level signatures (using advanced technologies). The principle of technological neutrality, a concept originally developed for the regulation of technologies in response to the liberalization of telecommunications market, has been the central theme of discussions on the e-transactions policy-making scene. As the author shows, in the process through which states localize the global standards of technological neutrality, ASEAN as a vehicle of regulatory change has played an essential role in translating this principle to the national context.}
}
",https://www.sciencedirect.com/science/article/pii/S0267364918304308,https://doi.org/10.1016/j.clsr.2019.03.009,science_direct,2019
1209,A call for introducing LegalTech in the classroom,"@article{IRELAND2020105399,
title = {A call for introducing LegalTech in the classroom},
journal = {Computer Law & Security Review},
volume = {36},
pages = {105399},
year = {2020},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2020.105399},
url = {https://www.sciencedirect.com/science/article/pii/S0267364920300042},
author = {Chris Ireland and Ryan Hockley},
keywords = {LawTech, LegalTech, Tech, Innovation, LLB, Classroom},
abstract = {Change is coming to the way the business of law is conducted. It is an unavoidable reality that the delivery of professional legal services is on the cusp of major disruption. The way law firms and in-house legal teams operate is predicted to change dramatically. It is theorised that a majority of the aforementioned change will come from the adoption of more sophisticated technology by law firms and the courts. Technological change has already made some lawyer hours obsolete, and this trend is only expected to continue. Given this incoming wave of change, there exists a strong justification for the inclusion of legaltech in the undergraduate LLB curriculum. This article asses the feasibility of such an inclusion and provides suggestions for what institutions could be doing to support their users.}
}
",https://www.sciencedirect.com/science/article/pii/S0267364920300042,https://doi.org/10.1016/j.clsr.2020.105399,science_direct,2020
1210,Conducting research with school children and data in line with “ethical principles” lawyers at work in the ethics management of the H2020 mathisis project,"@article{MANTOVANI2020105451,
title = {Conducting research with school children and data in line with “ethical principles” lawyers at work in the ethics management of the H2020 mathisis project},
journal = {Computer Law & Security Review},
volume = {38},
pages = {105451},
year = {2020},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2020.105451},
url = {https://www.sciencedirect.com/science/article/pii/S026736492030056X},
author = {Eugenio Mantovani and István Böröcz and Paul {de Hert}},
keywords = {School children, School children with special needs, Ethical principles, Research, National schooling systems, Personal data protection law},
abstract = {Recent advancements in human-computer interaction, machine learning and in artificial intelligence hold the potential to influence both the curriculum and the pedagogy of school children. While the impacts of new technologies remain uncertain, ongoing research and innovation projects are already developing and testing such technologies in schools. This article builds on the experience of the authors as advisors for a Horizon 2020 (H2020) project conducting research with schoolchildren in twenty schools across the United Kingdom, Italy and Spain (the project MaTHiSiS). This contribution presents and discusses how the authors lived up to the obligation of conducting research in line with “ethical principles”.}
}
",https://www.sciencedirect.com/science/article/pii/S026736492030056X,https://doi.org/10.1016/j.clsr.2020.105451,science_direct,2020
1211,"Law versus technology: Blockchain, GDPR, and tough tradeoffs","@article{TATAR2020105454,
title = {Law versus technology: Blockchain, GDPR, and tough tradeoffs},
journal = {Computer Law & Security Review},
volume = {38},
pages = {105454},
year = {2020},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2020.105454},
url = {https://www.sciencedirect.com/science/article/pii/S0267364920300595},
author = {Unal Tatar and Yasir Gokce and Brian Nussbaum},
keywords = {General data protection regulation, GPDR, Blockchain, Privacy, Personal information, Privacy by design, Privacy by default, Right to be forgotten, Data controller},
abstract = {Inconsistency between the way in which the law is structured, and the way in which technologies actually operate is always an interesting and useful topic to explore. When a law conflicts with a business model, the solution will often be changing the business model. However, when the law comes into conflict with the architecture of hardware and software, it is less clear how the problem will be managed. In this paper, we analyze the contradiction of blockchain technology and the requirements of GDPR. The three contradictions we examine are (i) right to be forgotten versus irreversibility/immutability of records, (ii) data protection by design versus tamper-proofness and transparency of blockchain, and (iii) data controller versus decentralized nodes. We highlight that the conflicts can be handled through focusing on commonalities of GDPR and the blockchain, developing new approaches and interpretations, and tailoring the blockchain technology according to the needs of data protection law.}
}
",https://www.sciencedirect.com/science/article/pii/S0267364920300595,https://doi.org/10.1016/j.clsr.2020.105454,science_direct,2020
1212,Players’ rights to game mods: Towards a more balanced copyright regime,"@article{DENG2021105634,
title = {Players’ rights to game mods: Towards a more balanced copyright regime},
journal = {Computer Law & Security Review},
volume = {43},
pages = {105634},
year = {2021},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2021.105634},
url = {https://www.sciencedirect.com/science/article/pii/S0267364921001072},
author = {Zhaoxia Deng and Yahong Li},
keywords = {Player contributed content, Game mods, Terms of service, Social benefits/harm, Right of modding, Community-based approach},
abstract = {In the context of video game, there is a notable convergence between the users and producers of content. There is also a tension between control over created content and innovative uses of that content, which arises from the gap existed between copyright law and the emerging practices of online communities. This paper examines a distinct form of player-contributed content, namely game Mods, through the perspective of social welfare rather than that of content creators. It argues that law is not the only factor affecting copyright owners’ decision-making behavior; social and economic factors also play an essential role. These factors explain why game developers may tolerate or even encourage minor alterations to their works but prohibit total conversion of the Mods. Given that the existing law and terms of service cannot serve as “effective cure” for regulating game Mods, this paper explores the social and economic factors that impact how game corporations address modding, framing these factors in a four-quadrant model according to the relative benefits and harm of Mods to game developers and users/modders. The inconsistency between the letter of the law and its practical application in the modding context suggests a need for law reform. Based on the findings of the above examinations, this paper proposes a two-pronged solution to the modding problem. The first prong concerns the social benefit of game Mods, aiming at changing the copyright regime from being exclusive to non-exclusive, which confers on gamers the legal right to modify video games without permission but obliges them to remunerate the original developers for commercial use of those Mods. The second prong concerns the potential social harm of game Mods and proposes a community-based approach, under which game operators are imposed a common law duty to monitor infringement and to ensure the fair implementation of game developers’ terms of service.}
}
",https://www.sciencedirect.com/science/article/pii/S0267364921001072,https://doi.org/10.1016/j.clsr.2021.105634,science_direct,2021
1213,Legalization of live game streaming through statutory licence in China,"@article{DENG2022105714,
title = {Legalization of live game streaming through statutory licence in China},
journal = {Computer Law & Security Review},
volume = {46},
pages = {105714},
year = {2022},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2022.105714},
url = {https://www.sciencedirect.com/science/article/pii/S0267364922000619},
author = {Zhaoxia Deng and Jyh-An Lee},
keywords = {Live game streaming, Copyright infringement, Performer, Right of performance, Statutory licensing mechanism},
abstract = {Live game streaming depends on the use of audiovisual images of the games play, which may infringe the copyright of game developers. In recent years, there has been a surge in copyright litigation initiated by game developers against players/streamers in China. The courts needed to resolve several fundamental copyright issues in these cases, such as those pertaining to copyright subject matter, economic right, and copyright limitation. This article provides an in-depth exploration on copyright doctrines relevant to live game streaming industry, following by a proposal of new statutory licensing mechanism specifically for live game streaming. We argue that the proposal can properly balance various interests of different stakeholders in the game industry, such as incentive and proper reasonable compensation for developers, platforms’ dissemination of entertaining information to the audiences, and gamers’ development of professional skills. Under this mechanism, streamers would be allowed to stream games without permission and streaming platform operators would be automatically licensed for game streaming and obliged to remunerate game developers. Compared to the traditional “one-to-one” licensing, the proposed licensing scheme would effectively reduce transaction costs and improve licensing efficiency.}
}
",https://www.sciencedirect.com/science/article/pii/S0267364922000619,https://doi.org/10.1016/j.clsr.2022.105714,science_direct,2022
1214,The European AI liability directives – Critique of a half-hearted approach and lessons for the future,"@article{HACKER2023105871,
title = {The European AI liability directives – Critique of a half-hearted approach and lessons for the future},
journal = {Computer Law & Security Review},
volume = {51},
pages = {105871},
year = {2023},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2023.105871},
url = {https://www.sciencedirect.com/science/article/pii/S026736492300081X},
author = {Philipp Hacker},
keywords = {Artificial intelligence, ChatGPT, Product liability, EU law, AI act, Sustainability, Innovation, Large generative AI models},
abstract = {The optimal liability framework for AI systems remains an unsolved problem across the globe. With ChatGPT and other large generative models taking the technology to the next level, solutions are urgently needed. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive (AILD) and a revision of the Product Liability Directive (PLD). They constitute the final cornerstone of AI regulation in the EU. Crucially, the liability proposals and the proposed EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a “Brussels effect” in AI regulation, with significant consequences for the US and other countries. Against this background, this paper makes three novel contributions. First, it examines in detail the liability proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments to the proposed AI liability framework. They are collected in a concise Annex at the end of the paper. I argue, inter alia, that the dichotomy between the fault-based AILD Proposal and the supposedly strict liability PLD Proposal is fictional and should be abandoned; that an EU framework for AI liability should comprise one fully harmonizing regulation instead of two insufficiently coordinated directives; and that the current proposals unjustifiably collapse fundamental distinctions between social and individual risk by equating high-risk AI systems in the AI Act with those under the liability framework. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. More specifically, I make four key proposals. Effective compensation should be ensured by combining truly strict liability for certain high-risk AI systems with general presumptions of defectiveness, fault and causality in cases involving SMEs or non-high-risk AI systems. The paper introduces a novel distinction between illegitimate- and legitimate-harm models to delineate strict liability's scope. Truly strict liability should be reserved for high-risk AI systems that, from a social perspective, should not cause harm (illegitimate-harm models, e.g., autonomous vehicles or medical AI). Models meant to cause some unavoidable harm by ranking and rejecting individuals (legitimate-harm models, e.g., credit scoring or insurance scoring) may merely face rebuttable presumptions of defectiveness and causality. General-purpose AI systems and Foundation Models should only be subjected to high-risk regulation, including liability for high-risk AI systems, in specific high-risk use cases for which they are deployed. Consumers, in turn, ought to be liable based on regular fault, in general. Furthermore, innovation and legal certainty should be fostered through a comprehensive regime of safe harbours, defined quantitatively to the best extent possible. Moreover, trustworthy AI remains an important goal for AI regulation. Hence, the liability framework must specifically extend to non-discrimination cases and provide for clear rules concerning explainability (XAI). Finally, awareness for the climate effects of AI, and digital technology more broadly, is rapidly growing in computer science. In diametrical opposition to this shift in discourse and understanding, however, EU legislators have long neglected environmental sustainability in both the draft AI Act and the proposed liability regime. To counter this, I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but also sustainable AI (SAI).}
}
",https://www.sciencedirect.com/science/article/pii/S026736492300081X,https://doi.org/10.1016/j.clsr.2023.105871,science_direct,2023
1215,The ALTAI checklist as a tool to assess ethical and legal implications for a trustworthy AI development in education,"@article{FEDELE2024105986,
title = {The ALTAI checklist as a tool to assess ethical and legal implications for a trustworthy AI development in education},
journal = {Computer Law & Security Review},
volume = {53},
pages = {105986},
year = {2024},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2024.105986},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924000530},
author = {Andrea Fedele and Clara Punzi and Stefano Tramacere},
keywords = {Trustworthy AI, Education, Vulnerability, AI regulation, AI accountability, eXplainable AI},
abstract = {The rapid proliferation of Artificial Intelligence (AI) applications in various domains of our lives has prompted a need for a shift towards a human-centered and trustworthy approach to AI. In this study we employ the Assessment List for Trustworthy Artificial Intelligence (ALTAI) checklist to evaluate the trustworthiness of Artificial Intelligence for Student Performance Prediction (AI4SPP), an AI-powered system designed to detect students at risk of school failure. We strongly support the ethical and legal development of AI and propose an implementation design where the user can choose to have access to each level of a three-tier outcome bundle: the AI prediction alone, the prediction along with its confidence level, and, lastly, local explanations for each grade prediction together with the previous two information. AI4SPP aims to raise awareness among educators and students regarding the factors contributing to low school performance, thereby facilitating the implementation of interventions not only to help students, but also to address biases within the school community. However, we also emphasize the ethical and legal concerns that could arise from a misuse of the AI4SPP tool. First of all, the collection and analysis of data, which is essential for the development of AI models, may lead to breaches of privacy, thus causing particularly adverse consequences in the case of vulnerable individuals. Furthermore, the system’s predictions may be influenced by unacceptable discrimination based on gender, ethnicity, or socio-economic background, leading to unfair actions. The ALTAI checklist serves as a valuable self-assessment tool during the design phase of AI systems, by means of which commonly overlooked weaknesses can be highlighted and addressed. In addition, the same checklist plays a crucial role throughout the AI system life cycle. Continuous monitoring of sensitive features within the dataset, alongside survey assessments to gauge users’ responses to the systems, is essential for gathering insights and intervening accordingly. We argue that adopting a critical approach to AI development is essential for societal progress, believing that it can evolve and accelerate over time without impeding openness to new technologies. By aligning with ethical principles and legal requirements, AI systems can make significant contributions to education while mitigating potential risks and ensuring a fair and inclusive learning environment.}
}
",https://www.sciencedirect.com/science/article/pii/S0267364924000530,https://doi.org/10.1016/j.clsr.2024.105986,science_direct,2024
1216,ChatGPT in healthcare: A taxonomy and systematic review,"@article{LI2024108013,
title = {ChatGPT in healthcare: A taxonomy and systematic review},
journal = {Computer Methods and Programs in Biomedicine},
volume = {245},
pages = {108013},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108013},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724000087},
author = {Jianning Li and Amin Dada and Behrus Puladi and Jens Kleesiek and Jan Egger},
keywords = {ChatGPT, Healthcare, NLP, Transformer, LLM, OpenAI, Taxonomy, Bard, BERT, LLaMA},
abstract = {The recent release of ChatGPT, a chat bot research project/product of natural language processing (NLP) by OpenAI, stirs up a sensation among both the general public and medical professionals, amassing a phenomenally large user base in a short time. This is a typical example of the ‘productization’ of cutting-edge technologies, which allows the general public without a technical background to gain firsthand experience in artificial intelligence (AI), similar to the AI hype created by AlphaGo (DeepMind Technologies, UK) and self-driving cars (Google, Tesla, etc.). However, it is crucial, especially for healthcare researchers, to remain prudent amidst the hype. This work provides a systematic review of existing publications on the use of ChatGPT in healthcare, elucidating the ‘status quo’ of ChatGPT in medical applications, for general readers, healthcare professionals as well as NLP scientists. The large biomedical literature database PubMed is used to retrieve published works on this topic using the keyword ‘ChatGPT’. An inclusion criterion and a taxonomy are further proposed to filter the search results and categorize the selected publications, respectively. It is found through the review that the current release of ChatGPT has achieved only moderate or ‘passing’ performance in a variety of tests, and is unreliable for actual clinical deployment, since it is not intended for clinical applications by design. We conclude that specialized NLP models trained on (bio)medical datasets still represent the right direction to pursue for critical clinical applications.}
}
",https://www.sciencedirect.com/science/article/pii/S0169260724000087,https://doi.org/10.1016/j.cmpb.2024.108013,science_direct,2024
1217,The emergence of compositionality in a brain-inspired cognitive architecture,"@article{SCHNEIDER2024101215,
title = {The emergence of compositionality in a brain-inspired cognitive architecture},
journal = {Cognitive Systems Research},
volume = {86},
pages = {101215},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101215},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724000081},
author = {Howard Schneider},
keywords = {Compositionality, Brain-Inspired Cognitive Architecture (BICA), Artificial Intelligence (AI), Language evolution, Large Language Model (LLM), Neurosymbolic computing},
abstract = {Compositionality can be considered as finding (or creating) the correct meaning of the constituents of a non-simple language expression or visual image. The Causal Cognitive Architecture is a brain-inspired cognitive architecture (BICA). It is not a traditional artificial neural network architecture, nor a traditional symbolic AI system but instead uses spatial navigation maps as its fundamental circuits. In previously described versions of the architecture, sensory inputs are compared in each existing sensory system against previous stored navigation maps for that sensory system, and the best navigation map is chosen and then updated with the new sensory inputs and a best multisensory navigation map is similarly created and used as the working navigation map. Instinctive and learned small procedures are triggered by input sensory inputs as well as matched navigation maps, and in the Navigation Module operate on the working navigation map and produce an output signal. By feeding back intermediate results in the Navigation Module it has been shown previously how causal and analogical behaviors emerge from the architecture. In new work, the Navigation Module is duplicated in a biologically plausible manner. It becomes possible to compositionally process information in the duplicated Navigation Module, and as a result compositional language comprehension and behavior readily emerge. A formalization and simulation of the architecture is presented. A demonstration example, and its negation, are explored of solving a compositional problem requiring the placement of an object in a specific location with regard to other objects. Future work is discussed using large language models to create navigation maps. Given the mammalian brain inspiration of the architecture, it suggests that it is indeed feasible for modest genetic changes to have allowed the emergence of compositional language in humans.}
}
",https://www.sciencedirect.com/science/article/pii/S1389041724000081,https://doi.org/10.1016/j.cogsys.2024.101215,science_direct,2024
1218,Educational models for cognition: Methodology of modeling intellectual skills for intelligent tutoring systems,"@article{SYCHEV2024101261,
title = {Educational models for cognition: Methodology of modeling intellectual skills for intelligent tutoring systems},
journal = {Cognitive Systems Research},
pages = {101261},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101261},
url = {https://www.sciencedirect.com/science/article/pii/S138904172400055X},
author = {Oleg Sychev},
keywords = {Reasoning modeling, Constraint-based modeling, Intelligent tutoring systems},
abstract = {Automation of teaching people new skills requires modeling of human reasoning because human cognition involves active reasoning over the new subject domain to acquire skills that will later become automatic. The article presents Thought Process Trees — a language for modeling human reasoning that was created to facilitate the development of intelligent tutoring systems, which can perform the same reasoning that is expected of a student and find deficiencies in their line of thinking, providing explanatory messages and allowing them to learn from performance errors. The methodology of building trees which better reflect human learning is discussed, with examples of design choices during the modeling process and their consequences. The characteristics of educational modeling that impact building subject-domain models for intelligent tutoring systems are discussed. The trees were formalized and served as a basis for developing a framework for constructing intelligent tutoring systems. This significantly lowered the time required to build and debug a constraint-based subject-domain model. The framework has already been used to develop five intelligent tutoring systems and their prototypes and is being used to develop more of them.}
}
",https://www.sciencedirect.com/science/article/pii/S138904172400055X,https://doi.org/10.1016/j.cogsys.2024.101261,science_direct,2024
1219,API comparison knowledge extraction via prompt-tuned language model,"@article{YANG2023101200,
title = {API comparison knowledge extraction via prompt-tuned language model},
journal = {Journal of Computer Languages},
volume = {75},
pages = {101200},
year = {2023},
issn = {2590-1184},
doi = {https://doi.org/10.1016/j.cola.2023.101200},
url = {https://www.sciencedirect.com/science/article/pii/S2590118423000102},
author = {Yangrui Yang and Yaping Zhu and Sisi Chen and Pengpeng Jian},
keywords = {Knowledge extraction, API entity, Semantic relation, Joint extraction},
abstract = {Application Programming Interfaces (APIs) are frequent in software engineering domain texts, such as API references and Stack Overflow. These APIs and the comparison knowledge between them are not only important for solving programming issues (e.g., question answering), but they are also organized into structured knowledge to support many software engineering tasks (e.g., API misuse detection). As a result, extracting API comparison knowledge (API entities and semantic relations) from texts is essential. Existing rule-based and sequence labeling-based approaches must manually enumerate all linguistic patterns or label a large amount of data. Therefore, they involve a significant labor overhead and are exacerbated by morphological and common-word ambiguity. In contrast to matching or labeling API entities and relations, we formulates heterogeneous API extraction and API relation extraction tasks as a sequence-to-sequence generation task. It proposes APICKnow, an API entity-relation joint extraction model based on the large language model. To improve our model’s performance and quick learning ability, we adopt the prompt learning method to stimulate APICKnow to recognize API entities and relations. We systematically evaluate APICKnow on a set of sentences from Stack Overflow. The experimental results show that APICKnow can outperform the state-of-the-art baselines, and APICKnow has a quick learning ability and strong generalization ability.}
}
",https://www.sciencedirect.com/science/article/pii/S2590118423000102,https://doi.org/10.1016/j.cola.2023.101200,science_direct,2023
1220,An empirical approach to understand the role of emotions in code comprehension,"@article{SINGH2024101269,
title = {An empirical approach to understand the role of emotions in code comprehension},
journal = {Journal of Computer Languages},
volume = {79},
pages = {101269},
year = {2024},
issn = {2590-1184},
doi = {https://doi.org/10.1016/j.cola.2024.101269},
url = {https://www.sciencedirect.com/science/article/pii/S2590118424000121},
author = {Divjot Singh and Ashutosh Mishra and Ashutosh Aggarwal},
keywords = {Code comprehension, Systematic literature review, Emotions, Cognitive skills},
abstract = {Programming and cognitive skills are two pivotal abilities of programmers to maintain software products. First, this study included a systematic literature review on code comprehension, emotions, cognitive psychology, and belief-desire-intention domains to analyse various code comprehension monitoring techniques, performance metrics, and computational methodologies. Second, a case study is conducted to examine the influence of various emotional stages on programmers’ programming and cognitive skills while comprehending the software code. The categorization of the participants is done empirically based on their expertism level, and the same results are verified using various machine learning models and performance metrics.}
}
",https://www.sciencedirect.com/science/article/pii/S2590118424000121,https://doi.org/10.1016/j.cola.2024.101269,science_direct,2024
1221,"JAPPI: An unsupervised endpoint application identification methodology for improved Zero Trust models, risk score calculations and threat detection","@article{HEINO2024110606,
title = {JAPPI: An unsupervised endpoint application identification methodology for improved Zero Trust models, risk score calculations and threat detection},
journal = {Computer Networks},
volume = {250},
pages = {110606},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110606},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624004389},
author = {Jenny Heino and Christian Jalio and Antti Hakkala and Seppo Virtanen},
keywords = {Network security, Intrusion detection, Machine learning, Zero Trust, Risk score},
abstract = {The surge in global digitalization triggered by COVID-19 has led to a significant increase in internet traffic and has precipitated a rapid transformation of the network security landscape. Despite being increasingly difficult, accurate traffic inspection is vital for ensuring productivity while reliably protecting internal assets. Endpoint application identification enables high accuracy inspection and detection by providing network security solutions with specific context on individual connections. However, achieving it in real-time with standard fingerprinting methods based only on client-side traffic has proven to be a challenging problem with no comprehensive solution thus far. In this article, we present a new methodology for identifying endpoint applications from network traffic, utilizing machine learning. Our methodology leverages similarities in the pre-hash string of the JA3 algorithm for fingerprinting application specific TLS Client Hello messages. By utilizing well-known clustering algorithms it is possible to identify the underlying TLS libraries and the application from the traffic remarkably better than with simple string-based matching. Our model can categorize 99,5% of the traffic in a controlled network, and 93,8% in an uncontrolled network, compared to 0,1% and 0,2% using simple string matching. Our methodology is especially effective for enhancing Zero Trust models, calculating a risk score for network events, and improving threat detection accuracy in network security solutions.}
}
",https://www.sciencedirect.com/science/article/pii/S1389128624004389,https://doi.org/10.1016/j.comnet.2024.110606,science_direct,2024
1222,GPT-aided diagnosis on agricultural image based on a new light YOLOPC,"@article{QING2023108168,
title = {GPT-aided diagnosis on agricultural image based on a new light YOLOPC},
journal = {Computers and Electronics in Agriculture},
volume = {213},
pages = {108168},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.108168},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923005562},
author = {Jiajun Qing and Xiaoling Deng and Yubin Lan and Zhikai Li},
keywords = {Citrus pests and diseases, Lightweight, Large language models},
abstract = {Large Language Models (LLM) have been extensively studied for their ability to engage in textual dialogue and have shown promising results in various fields. However, the agricultural industry has yet to fully integrate LLM into its practice due to the dominance of visual images in agricultural data that cannot be effectively processed by LLM designed for text. Additionally, traditional image classification networks have limitations in understanding crop etiology and disease, hindering accurate diagnosis. Furthermore, the mixture of diseases can also interfere with the network's prediction. Therefore, accurately analyzing pests and diseases in agricultural scenarios and providing diagnostic reports remains a challenge. To address this issue, a novel approach that combines the deep logical reasoning capabilities of GPT-4 with the visual understanding capabilities of the YOLO (You Only Look Once) network was proposed in this study. Additionally, a new lightweight variant of YOLO, called YOLOPC, and a novel image-to-text mapping method for adapting YOLO and GPT were introduced. The experimental results demonstrate that YOLOPC, with approximately 75% fewer parameters than YOLOv5-nano, achieves a 94.5% accuracy rate. The GPT induction and reasoning module demonstrates 90% reasoning accuracy in generating agricultural diagnostic reports with text assistance. In the future, it is likely that a higher-performance GPT model will be released. The combination of GPT with agricultural scenarios will become the cornerstone of large-scale agricultural diagnostic models. The proposed method will benefit the development of large-scale models in the agricultural field.}
}
",https://www.sciencedirect.com/science/article/pii/S0168169923005562,https://doi.org/10.1016/j.compag.2023.108168,science_direct,2023
1223,Evaluation of Large language model performance on the Multi-Specialty Recruitment Assessment (MSRA) exam,"@article{TSOUTSANIS2024107794,
title = {Evaluation of Large language model performance on the Multi-Specialty Recruitment Assessment (MSRA) exam},
journal = {Computers in Biology and Medicine},
volume = {168},
pages = {107794},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107794},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523012593},
author = {Panagiotis Tsoutsanis and Aristotelis Tsoutsanis},
keywords = {Large language models, Artificial intelligence, Medical education, Medical exam},
abstract = {Introduction
AI-powered platforms have gained prominence in medical education and training, offering diverse applications from surgical performance assessment to exam preparation. This research paper examines the capabilities of Large Language Models (LLMs), including Llama 2, Google Bard, Bing Chat, and ChatGPT-3.5, in answering multiple-choice questions of the Clinical Problem Solving (CPS) paper of the Multi-Specialty Recruitment Assessment (MSRA) exam.
Methods
Using a dataset of 100 CPS questions from ten subject categories, we assessed the LLMs' performance against medical doctors preparing for the exam.
Results
Results showed that Bing Chat outperformed all other LLMs and even surpassed human users from the Qbank question bank. Conversely, Llama 2's performance was inferior to human users. Google Bard and ChatGPT 3.5 did not exhibit statistically significant differences in correct response rates compared to human candidates. Pairwise comparisons demonstrated Bing Chat's significant superiority over Llama 2, Google Bard, and ChatGPT 3.5. However, no significant differences were found between Llama 2 and Google Bard, Llama 2, and ChatGPT-3.5, and Google Bard and ChatGPT-3.5.
Discussion
Freely available LLMs have already demonstrated that they can perform as well or even outperform human users in answering MSRA exam questions. Bing Chat emerged as a particularly strong performer. The study also highlights the potential for enhancing LLMs' medical knowledge acquisition through tailored fine-tuning. Medical knowledge tailored LLMs such as Med-PaLM, have already shown promising results.
Conclusion
We provided valuable insights into LLMs' competence in answering medical MCQs and their potential integration into medical education and assessment processes.}
}
",https://www.sciencedirect.com/science/article/pii/S0010482523012593,https://doi.org/10.1016/j.compbiomed.2023.107794,science_direct,2024
1224,Beyond human in neurosurgical exams: ChatGPT's success in the Turkish neurosurgical society proficiency board exams,"@article{SAHIN2024107807,
title = {Beyond human in neurosurgical exams: ChatGPT's success in the Turkish neurosurgical society proficiency board exams},
journal = {Computers in Biology and Medicine},
volume = {169},
pages = {107807},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107807},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523012726},
author = {Mustafa Caglar Sahin and Alperen Sozer and Pelin Kuzucu and Tolga Turkmen and Merve Buke Sahin and Ekin Sozer and Ozan Yavuz Tufek and Kerem Nernekli and Hakan Emmez and Emrah Celtikci},
keywords = {Artificial intelligence, Board, ChatGPT, Education, Exam, Machine learning, Large language model},
abstract = {Chat Generative Pre-Trained Transformer (ChatGPT) is a sophisticated natural language model that employs advanced deep learning techniques and is trained on extensive datasets to produce responses akin to human conversation for user inputs. In this study, ChatGPT's success in the Turkish Neurosurgical Society Proficiency Board Exams (TNSPBE) is compared to the actual candidates who took the exam, along with identifying the types of questions it answered incorrectly, assessing the quality of its responses, and evaluating its performance based on the difficulty level of the questions. Scores of all 260 candidates were recalculated according to the exams they took and included questions in those exams for ranking purposes of this study. The average score of the candidates for a total of 523 questions is 62.02 ± 0.61 compared to ChatGPT, which was 78.77. We have concluded that in addition to ChatGPT's higher response rate, there was also a correlation with the increase in clarity regardless of the difficulty level of the questions with Clarity 1.5, 2.0, 2.5, and 3.0. In the participants, however, there is no such increase in parallel with the increase in clarity.}
}
",https://www.sciencedirect.com/science/article/pii/S0010482523012726,https://doi.org/10.1016/j.compbiomed.2023.107807,science_direct,2024
1225,MedChatZH: A tuning LLM for traditional Chinese medicine consultations,"@article{TAN2024108290,
title = {MedChatZH: A tuning LLM for traditional Chinese medicine consultations},
journal = {Computers in Biology and Medicine},
volume = {172},
pages = {108290},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108290},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524003743},
author = {Yang Tan and Zhixing Zhang and Mingchen Li and Fei Pan and Hao Duan and Zijie Huang and Hua Deng and Zhuohang Yu and Chen Yang and Guoyang Shen and Peng Qi and Chengyuan Yue and Yuxian Liu and Liang Hong and Huiqun Yu and Guisheng Fan and Yun Tang},
keywords = {Generative large language models (LLMs), Question-answering (QA), Dialogue model, Traditional Chinese medical QA, Fine-tuning},
abstract = {Generative Large Language Models (LLMs) have achieved significant success in various natural language processing tasks, including Question-Answering (QA) and dialogue systems. However, most models are trained on English data and lack strong generalization in providing answers in Chinese. This limitation is especially evident in specialized domains like traditional Chinese medical QA, where performance suffers due to the absence of fine-tuning and high-quality datasets. To address this, we introduce MedChatZH, a dialogue model optimized for Chinese medical QA based on transformer decoder with LLaMA architecture. Continued pre-training on a curated corpus of Chinese medical books is followed by fine-tuning with a carefully selected medical instruction dataset, resulting in MedChatZH outperforming several Chinese dialogue baselines on a real-world medical dialogue dataset. Our model, code, and dataset are publicly available on GitHub (https://github.com/tyang816/MedChatZH) to encourage further research in traditional Chinese medicine and LLMs.}
}
",https://www.sciencedirect.com/science/article/pii/S0010482524003743,https://doi.org/10.1016/j.compbiomed.2024.108290,science_direct,2024
1226,Xiaoqing: A Q&A model for glaucoma based on LLMs,"@article{XUE2024108399,
title = {Xiaoqing: A Q&A model for glaucoma based on LLMs},
journal = {Computers in Biology and Medicine},
volume = {174},
pages = {108399},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108399},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524004839},
author = {Xiaojuan Xue and Deshiwei Zhang and Chengyang Sun and Yiqiao Shi and Rongsheng Wang and Tao Tan and Peng Gao and Sujie Fan and Guangtao Zhai and Menghan Hu and Yue Wu},
keywords = {Glaucoma, Large Language Models (LLMs), Medical NLP system, Ophthalmology question and answer system},
abstract = {Glaucoma is one of the leading cause of blindness worldwide. Individuals affected by glaucoma, including patients and their family members, frequently encounter a deficit in dependable support beyond the confines of clinical environments. Seeking advice via the internet can be a difficult task due to the vast amount of disorganized and unstructured material available on these sites, nevertheless. This research explores how Large Language Models (LLMs) can be leveraged to better serve medical research and benefit glaucoma patients. We introduce Xiaoqing, a Natural Language Processing (NLP) model specifically tailored for the glaucoma field, detailing its development and deployment. To evaluate its effectiveness, we conducted two forms of experiments: comparative and experiential. In the comparative analysis, we presented 22 glaucoma-related questions in simplified Chinese to three medical NLP models (Xiaoqing LLMs, HuaTuo, Ivy GPT) and two general models (ChatGPT-3.5 and ChatGPT-4), covering a range of topics from basic glaucoma knowledge to treatment, surgery, research, management standards, and patient lifestyle. Responses were assessed for informativeness and readability. The experiential experiment involved glaucoma patients and non-patients interacting with Xiaoqing, collecting and analyzing their questions and feedback on the same criteria. The findings demonstrated that Xiaoqing notably outperformed the other models in terms of informativeness and readability, suggesting that Xiaoqing is a significant advancement in the management and treatment of glaucoma in China. We also provide a Web-based version of Xiaoqing, allowing readers to directly experience its functionality. The Web-based Xiaoqing is available at https://qa.glaucoma-assistant.com//qa.}
}",https://www.sciencedirect.com/science/article/pii/S0010482524004839,https://doi.org/10.1016/j.compbiomed.2024.108399,science_direct,2024
1227,Linguistic-based Mild Cognitive Impairment detection using Informative Loss,"@article{POURRAMEZANFARD2024108606,
title = {Linguistic-based Mild Cognitive Impairment detection using Informative Loss},
journal = {Computers in Biology and Medicine},
volume = {176},
pages = {108606},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108606},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524006917},
author = {Ali {Pourramezan Fard} and Mohammad H. Mahoor and Muath Alsuhaibani and Hiroko H. Dodge},
keywords = {Mild Cognitive Impairment classification, Informative Loss function, Natural Language Processing, Transformers, Linguistic features detection, I-CONECT dataset},
abstract = {This paper presents a deep learning method using Natural Language Processing (NLP) techniques, to distinguish between Mild Cognitive Impairment (MCI) and Normal Cognitive (NC) conditions in older adults. We propose a framework that analyzes transcripts generated from video interviews collected within the I-CONECT study project, a randomized controlled trial aimed at improving cognitive functions through video chats. Our proposed NLP framework consists of two Transformer-based modules, namely Sentence Embedding (SE) and Sentence Cross Attention (SCA). First, the SE module captures contextual relationships between words within each sentence. Subsequently, the SCA module extracts temporal features from a sequence of sentences. This feature is then used by a Multi-Layer Perceptron (MLP) for the classification of subjects into MCI or NC. To build a robust model, we propose a novel loss function, called InfoLoss, that considers the reduction in entropy by observing each sequence of sentences to ultimately enhance the classification accuracy. The results of our comprehensive model evaluation using the I-CONECT dataset show that our framework can distinguish between MCI and NC with an average area under the curve of 84.75%.}
}
",https://www.sciencedirect.com/science/article/pii/S0010482524006917,https://doi.org/10.1016/j.compbiomed.2024.108606,science_direct,2024
1228,Good machine learning practices: Learnings from the modern pharmaceutical discovery enterprise,"@article{MAKAROV2024108632,
title = {Good machine learning practices: Learnings from the modern pharmaceutical discovery enterprise},
journal = {Computers in Biology and Medicine},
volume = {177},
pages = {108632},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108632},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524007170},
author = {Vladimir Makarov and Christophe Chabbert and Elina Koletou and Fotis Psomopoulos and Natalja Kurbatova and Samuel Ramirez and Chas Nelson and Prashant Natarajan and Bikalpa Neupane},
keywords = {Artificial intelligence, Machine learning, Pharmaceutical, Drug discovery, Best practice, Life sciences},
abstract = {Machine Learning (ML) and Artificial Intelligence (AI) have become an integral part of the drug discovery and development value chain. Many teams in the pharmaceutical industry nevertheless report the challenges associated with the timely, cost effective and meaningful delivery of ML and AI powered solutions for their scientists. We sought to better understand what these challenges were and how to overcome them by performing an industry wide assessment of the practices in AI and Machine Learning. Here we report results of the systematic business analysis of the personas in the modern pharmaceutical discovery enterprise in relation to their work with the AI and ML technologies. We identify 23 common business problems that individuals in these roles face when they encounter AI and ML technologies at work, and describe best practices (Good Machine Learning Practices) that address these issues.}
}
",https://www.sciencedirect.com/science/article/pii/S0010482524007170,https://doi.org/10.1016/j.compbiomed.2024.108632,science_direct,2024
1229,Artificial intelligence in perinatal mental health research: A scoping review,"@article{KWOK2024108685,
title = {Artificial intelligence in perinatal mental health research: A scoping review},
journal = {Computers in Biology and Medicine},
volume = {177},
pages = {108685},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108685},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524007704},
author = {Wai Hang Kwok and Yuanpeng Zhang and Guanjin Wang},
keywords = {Perinatal, Mental health, Artificial intelligence, ML, Natural language processing, Review},
abstract = {The intersection of Artificial Intelligence (AI) and perinatal mental health research presents promising avenues, yet uncovers significant challenges for innovation. This review explicitly focuses on this multidisciplinary field and undertakes a comprehensive exploration of existing research therein. Through a scoping review guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, we searched relevant literature spanning a decade (2013–2023) and selected fourteen studies for our analysis. We first provide an overview of the main AI techniques and their development, including traditional methods across different categories, as well as recent emerging methods in the field. Then, through our analysis of the literature, we summarize the predominant AI and ML techniques adopted and their applications in perinatal mental health studies, such as identifying risk factors, predicting perinatal mental health disorders, voice assistants, and Q&A chatbots. We also discuss existing limitations and potential challenges that hinder AI technologies from improving perinatal mental health outcomes, and suggest several promising directions for future research to meet real needs in the field and facilitate the translation of research into clinical settings.}
}
",https://www.sciencedirect.com/science/article/pii/S0010482524007704,https://doi.org/10.1016/j.compbiomed.2024.108685,science_direct,2024
1230,Developing and validating a knowledge-based AI assessment system for learning clinical core medical knowledge in otolaryngology,"@article{SU2024108765,
title = {Developing and validating a knowledge-based AI assessment system for learning clinical core medical knowledge in otolaryngology},
journal = {Computers in Biology and Medicine},
volume = {178},
pages = {108765},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108765},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524008503},
author = {Jun-Ming Su and Su-Yi Hsu and Te-Yung Fang and Pa-Chun Wang},
keywords = {Otolaryngology, Clinical core medical knowledge, Knowledge-based AI approaches, Adaptive assessment, Knowledge aggregation},
abstract = {Background
Clinical core medical knowledge (CCMK) learning is essential for medical trainees. Adaptive assessment systems can facilitate self-learning, but extracting experts' CCMK is challenging, especially using modern data-driven artificial intelligence (AI) approaches (e.g., deep learning).
Objectives
This study aims to develop a multi-expert knowledge–aggregated adaptive assessment scheme (MEKAS) using knowledge-based AI approaches to facilitate the learning of CCMK in otolaryngology (CCMK-OTO) and validate its effectiveness through a one-month training program for CCMK-OTO education at a tertiary referral hospital.
Methods
The MEKAS utilized the repertory grid technique and case-based reasoning to aggregate experts' knowledge to construct a representative CCMK base, thereby enabling adaptive assessment for CCMK-OTO training. The effects of longitudinal training were compared between the experimental group (EG) and the control group (CG). Both groups received a normal training program (routine meeting, outpatient/operation room teaching, and classroom teaching), while EG received MEKAS for self-learning. The EG comprised 22 UPGY trainees (6 postgraduate [PGY] and 16 undergraduate [UGY] trainees) and 8 otolaryngology residents (ENT-R); the CG comprised 24 UPGY trainees (8 PGY and 16 UGY trainees). The training effectiveness was compared through pre- and post-test CCMK-OTO scores, and user experiences were evaluated using a technology acceptance model-based questionnaire.
Results
Both UPGY (z = −3.976, P < 0.001) and ENT-R (z = −2.038, P = 0.042) groups in EG exhibited significant improvements in their CCMK-OTO scores, while UPGY in CG did not (z = −1.204, P = 0.228). The UPGY group in EG also demonstrated a substantial improvement compared to the UPGY group in CG (z = −4.943, P < 0.001). The EG participants were highly satisfied with the MEKAS system concerning self-learning assistance, adaptive testing, perceived satisfaction, intention to use, perceived usefulness, perceived ease of use, and perceived enjoyment, rating it between an overall average of 3.8 and 4.1 out of 5.0 on all scales.
Conclusions
The MEKAS system facilitates CCMK-OTO learning and provides an efficient knowledge aggregation scheme that can be applied to other medical subjects to efficiently build adaptive assessment systems for CCMK learning. Larger-scale validation across diverse institutions and settings is warranted further to assess MEKAS's scalability, generalizability, and long-term impact.}
}
",https://www.sciencedirect.com/science/article/pii/S0010482524008503,https://doi.org/10.1016/j.compbiomed.2024.108765,science_direct,2024
1231,Trust aware energy management system for smart homes appliances,"@article{QURESHI2022107641,
title = {Trust aware energy management system for smart homes appliances},
journal = {Computers & Electrical Engineering},
volume = {97},
pages = {107641},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107641},
url = {https://www.sciencedirect.com/science/article/pii/S004579062100567X},
author = {Kashif Naseer Qureshi and Adi Alhudhaif and Adil Hussain and Saleem Iqbal and Gwanggil Jeon},
keywords = {Smart homes, Energy consumption, Technologies, Scheduling, System, Cost, Appliances, Trust},
abstract = {Smart grids have gained popularity to manage energy resources on the consumption side. Energy management on the home side is still under consideration where the system controls the home appliances intelligently with cost-effective and manageable processes. This paper presents a Trust-aware Energy Management System for Smart Homes (TEMSH) by using smart scheduling and time management based on controllable and uncontrollable appliances management. This system is based on advanced communication technologies and security mechanisms. The trust mechanism provides the authentication services at the edge level to secure the user data from any type of unauthorized access and data leakage. The proposed system is deployed on houses to analyze the overall energy consumption and appliances. The results indicate the proposed system is more feasible for home appliances and able to manage and reduce the energy cost by around 55% cumulative Cost in the shape of bills and best for a green environment. The proposed system will be feasible to control the energy crises all over the world and reduce energy utilization and cost at the home level.}
}
",https://www.sciencedirect.com/science/article/pii/S004579062100567X,https://doi.org/10.1016/j.compeleceng.2021.107641,science_direct,2022
1232,Financial sentiment classification with fresh and hot public opinions,"@article{CAO2023108955,
title = {Financial sentiment classification with fresh and hot public opinions},
journal = {Computers and Electrical Engineering},
volume = {111},
pages = {108955},
year = {2023},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2023.108955},
url = {https://www.sciencedirect.com/science/article/pii/S0045790623003798},
author = {Shiyang Cao and Xiao Ma and Jiangfeng Zeng and Ming Yi},
keywords = {Financial sentiment analysis, Fresh and hot opinions, Temporal modeling, Fresh-hot bilinear pooling},
abstract = {Financial sentiment analysis aims to extract public opinion about an institution to help financial researchers make better decisions. To predict sentiment more accurately, it is necessary for models to improve their capability to capture long-term temporal information and support multi-user interaction. However, existing methods only analyze sentiment based on one comment from a user, which fails to fully exploit the latent emotions of the public, and they lack effective temporal modeling and interaction capabilities. In this paper, we analyze a company from two perspectives to alleviate the above issues: (1) the fresh opinions can reflect timely public attitudes towards a company, while (2) the hot opinions provide the most influential views. A comprehensive exploration of fresh and hot financial sentiment can help researchers make more accurate determinations. To this end, we propose a novel financial sentiment classification framework (FSCN), that can capture temporal information and interact with the opinions of users to make a more comprehensive decision. Our approach takes into account the inherent temporal dependencies in public opinions and combines both views of information to achieve an accurate classification of financial sentiment. Specifically, the FSCN contains (1) a multi-opinion extractor to filter and extract features from massively fresh and hot opinions, respectively. (2) a fresh-hot bilinear pooling (FHBP) module to effectively fuse fresh and hot features. Additionally, to verify the effectiveness of the proposed method, we crawl data from the Internet and create a real-world public opinion dataset that consists of 79,350 comments from 837 companies. Extensive experiments demonstrate that our framework achieves state-of-the-art results on this real-world dataset and is capable of providing reliable service in the financial system. Codes will be released at https://github.com/zjfgh2015/FSCN.}
}
",https://www.sciencedirect.com/science/article/pii/S0045790623003798,https://doi.org/10.1016/j.compeleceng.2023.108955,science_direct,2023
1233,Thai-language chatbot security: Detecting instruction attacks with XLM-RoBERTa and Bi-GRU,"@article{VAJROBOL2024109186,
title = {Thai-language chatbot security: Detecting instruction attacks with XLM-RoBERTa and Bi-GRU},
journal = {Computers and Electrical Engineering},
volume = {116},
pages = {109186},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109186},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624001149},
author = {Vajratiya Vajrobol and Brij B. Gupta and Akshat Gaurav},
keywords = {Instruction attack, Chatbot, Thai language, Bi-GRU, XLM-roBERTa},
abstract = {Instruction attack is a malicious attempt to manipulate a chatbot by providing misleading or harmful prompts to achieve unintended outcomes. Detecting instruction attacks is crucial to protect the integrity and safety of chatbot interactions. In this study, we focus on identifying different types of instruction attacks which includes Goal Hijacking, Prompt Leaking, Reverse Exposure, Role Play Instruction and Unsafe Instruction Topic. Given the widening threat scope and the lack of research thus far in this field in a Thai language-oriented context, our intentions are to develop an effective defence system. We suggest an innovative approach: combining XLM-RoBERTa, a state-of-the art language model, with a Bidirectional Gated Recurrent Unit (Bi-GRU). By combining rigorous experimentation and comprehensive evaluation, our method provides outstanding accuracy of 96.52% , precision 96.50% , Recall and F1-score 96.41%. This research contributes to creating a safer and more trustworthy environment for chatbot-mediated interactions in the Thai language context.}
}
",https://www.sciencedirect.com/science/article/pii/S0045790624001149,https://doi.org/10.1016/j.compeleceng.2024.109186,science_direct,2024
1234,Walkthrough phishing detection techniques,"@article{SINGH2024109374,
title = {Walkthrough phishing detection techniques},
journal = {Computers and Electrical Engineering},
volume = {118},
pages = {109374},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109374},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624003021},
author = {Tejveer Singh and Manoj Kumar and Santosh Kumar},
keywords = {Phishing, Machine learning, Deep learning, Features, Cyber threat, Social engineering, Internet users, Cyber vulnerabilities, Phishing countermeasures, User authentication},
abstract = {Phishing has emerged as a significant cyber threat, resulting in huge financial frauds for internet users annually. This malicious activity uses social engineering and upgraded methodologies (like file archiver in the browser, content injection, calendar phishing, more convincing fake websites or emails, voice manipulation, or other tools designed to deceive and exploit the target’s confidence) to extract sensitive information from unsuspected victims. In order to mitigate these attacks, several methods and tools have been devised; various detection techniques and block phishing websites, and browser extensions that notify users about suspicious websites. Our work elaborates on meticulous analysis of the detection of phishing attacks by classifying them into four broader categories based on the adopted methodologies like List-Based Detection, Heuristic-Based Detection, machine learning (ML)-based, and deep learning (DL)-based. Additionally, it summarizes the popular devised schemes, highlighting their advantages and limitations, and how these are suitable for the different types of deployments.}
}
",https://www.sciencedirect.com/science/article/pii/S0045790624003021,https://doi.org/10.1016/j.compeleceng.2024.109374,science_direct,2024
1235,A ChatGPT-MATLAB framework for numerical modeling in geotechnical engineering applications,"@article{KIM2024106237,
title = {A ChatGPT-MATLAB framework for numerical modeling in geotechnical engineering applications},
journal = {Computers and Geotechnics},
volume = {169},
pages = {106237},
year = {2024},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2024.106237},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X24001733},
author = {Daehyun Kim and Taegu Kim and Yejin Kim and Yong-Hoon Byun and Tae Sup Yun},
keywords = {ChatGPT, Numerical modeling, Automated Programming, Artificial Intelligence (AI), Large Language Model (LLM)},
abstract = {ChatGPT has recently emerged as a representative of Large Language Models (LLMs) that have brought evolutionary changes to our society, and the effectiveness of ChatGPT in various applications has been increasingly reported. This study aimed to explore the potential of employing programming performance driven by ChatGPT responses to conversational prompts in the field of geotechnical engineering. The tested examples included the analysis of seepage flow and slope stability, and the image processing of X-ray computed tomographic image for partially saturated sand. For each case, the prompt was initially fed by a narrative explanation of the problem attributes such as geometry, initial conditions, and boundary conditions to generate the MATLAB code that was in turn executed to evaluate the correctness and functionality. Any errors and unanticipated results were further refined by additional prompts until the correct outcome was achieved. ChatGPT was able to generate the numerical code at a considerable level, demonstrating creditable awareness of the refining process, when meticulous prompts were provided based on a comprehensive understanding of given problems. While ChatGPT may not be able to replace the entire process of programming, it can help minimize sloppy syntax errors and assist in designing a basic framework for logical programming.}
}
",https://www.sciencedirect.com/science/article/pii/S0266352X24001733,https://doi.org/10.1016/j.compgeo.2024.106237,science_direct,2024
1238,Text mining tool for translating terms of contract into technical specifications: Development and application in the railway sector,"@article{FANTONI2021103357,
title = {Text mining tool for translating terms of contract into technical specifications: Development and application in the railway sector},
journal = {Computers in Industry},
volume = {124},
pages = {103357},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2020.103357},
url = {https://www.sciencedirect.com/science/article/pii/S0166361520305911},
author = {G. Fantoni and E. Coli and F. Chiarello and R. Apreda and F. Dell’Orletta and G. Pratelli},
keywords = {Contract terms, Technical requirements, Tendering, Computational science, Text mining, Natural language processing},
abstract = {Tenders or technical terms contain a large quantity of both technical, legal, managerial information mixed in a nested and complex net of relationships. Extracting technical and design information from a document whose aim is both legal and technical, and that is written using several specific jargons, is not a trivial task: the purpose of the research is to try to detect, extract, split and assign information from the text of a tender in an automatic way. It means being able to understand technical and legal terms and organize them in multiple ways: according to product structure, internal organisational structure, etc. The focus is in providing a handy tool that could speed up and facilitate human analysis and allow tackling also the process of transforming customer’s requirements into design specifications. The approach chosen to overcome the various issues is to support state-of-the-art Computational Linguistic tools with a wide Knowledge Base. The latter has been constructed both manually and automatically and comprises not only keywords but also concepts, relationships and regular expressions. The implementation of the methodology has been carried out during a project for AnsaldoBreda S.p.A. (now Hitachi Rail Europe). A case study about the tender for a high-speed train has been included to show the functioning and output of the entire software system.}
}
",https://www.sciencedirect.com/science/article/pii/S0166361520305911,https://doi.org/10.1016/j.compind.2020.103357,science_direct,2021
1239,Harnessing GPT-4 for generation of cybersecurity GRC policies: A focus on ransomware attack mitigation,"@article{MCINTOSH2023103424,
title = {Harnessing GPT-4 for generation of cybersecurity GRC policies: A focus on ransomware attack mitigation},
journal = {Computers & Security},
volume = {134},
pages = {103424},
year = {2023},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103424},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823003346},
author = {Timothy McIntosh and Tong Liu and Teo Susnjak and Hooman Alavizadeh and Alex Ng and Raza Nowrozy and Paul Watters},
keywords = {GPT, Cybersecurity policies, Ransomware, Policy generation, GRC},
abstract = {This study investigated the potential of Generative Pre-trained Transformers (GPTs), a state-of-the-art large language model, in generating cybersecurity policies to deter and mitigate ransomware attacks that perform data exfiltration. We compared the effectiveness, efficiency, completeness, and ethical compliance of GPT-generated Governance, Risk and Compliance (GRC) policies, with those from established security vendors and government cybersecurity agencies, using game theory, cost-benefit analysis, coverage ratio, and multi-objective optimization. Our findings demonstrated that GPT-generated policies could outperform human-generated policies in certain contexts, particularly when provided with tailored input prompts. To address the limitations of our study, we conducted our analysis with thorough human moderation, tailored input prompts, and the inclusion of legal and ethical experts. Based on these results, we made recommendations for corporates considering the incorporation of GPT in their GRC policy making.}
}
",https://www.sciencedirect.com/science/article/pii/S0167404823003346,https://doi.org/10.1016/j.cose.2023.103424,science_direct,2023
1240,Investigating ChatGPT and cybersecurity: A perspective on topic modeling and sentiment analysis,"@article{OKEY2023103476,
title = {Investigating ChatGPT and cybersecurity: A perspective on topic modeling and sentiment analysis},
journal = {Computers & Security},
volume = {135},
pages = {103476},
year = {2023},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103476},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823003863},
author = {Ogobuchi Daniel Okey and Ekikere Umoren Udo and Renata Lopes Rosa and Demostenes Zegarra Rodríguez and João Henrique Kleinschmidt},
keywords = {ChatGPT, Cybersecurity, Sentiment analysis, Generative pre-trained transformers, Artificial intelligence, Data security},
abstract = {In early 2023, the Artificial Intelligence (AI) industry experienced a significant advancement with the emergence of OpenAI's ChatGPT, a research product that demonstrated remarkable capabilities and garnered widespread attention. ChatGPT is an advanced chatbot powered by the Generative Pretrained Transformers (GPT) architecture, designed to generate human-like conversations encompassing a wide range of knowledge domains. Many AI researchers are currently engaging with the new technology to understand its functionality and limitations. Various expressions across a range of social media platforms, including Twitter, YouTube, Facebook, and numerous others, are currently under investigation. This research seeks to analyze the opinions of ChatGPT users as it regards cybersecurity. This research is important due to its contribution towards gaining enhanced understanding and devising intricate improvements for the chatbot. The Latent Dirichlet Allocation (LDA) algorithm is utilized to extract relevant topics from the texts. Additionally, to analyze user opinions and decipher the sentiments as either positive, negative, or neutral, we use the Natural language tool kit Valence Aware Dictionary for sEntiment Reasoning (NLTK's VADER) and Robustly Optimized BERT Pretraining Approach (roBERTa) libraries. The data used is obtained from Twitter via the SNScrape library, which aided in the retrieval of over 700,000 tweets via the search terms #chatgptsecurity, #chatgpthackers, #chatgptcybersecurity, and #chatgptcyberthreats. The analysis of the results by the VADER model shows 43.8% positive, 36.3% neutral, and 19.9% negative sentiments. Similarly, the roBERTa model shows 14.1% positive, 53.2% neutral, and 32.7% negative. These results show that there is an ongoing concern about ChatGPT and cybersecurity, especially in malware code generation, hacking, intelligence gathering, and phishing attacks.}
}
",https://www.sciencedirect.com/science/article/pii/S0167404823003863,https://doi.org/10.1016/j.cose.2023.103476,science_direct,2023
1241,Exploring perceptions of decision-makers and specialists in defensive machine learning cybersecurity applications: The need for a standardised approach,"@article{ALSHAIKH2024103694,
title = {Exploring perceptions of decision-makers and specialists in defensive machine learning cybersecurity applications: The need for a standardised approach},
journal = {Computers & Security},
volume = {139},
pages = {103694},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103694},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823006041},
author = {Omar Alshaikh and Simon Parkinson and Saad Khan},
keywords = {Machine learning, Cybersecurity, Capabilities, ML application, Perception, Cybercrime, Thematic analysis, Themes},
abstract = {Machine learning (ML) utilisation has achieved a vast global impact. This is evident in the cybersecurity sector, where ML has wide-ranging applications, such as identifying and blocking threats, uncovering unusual software and user behaviour, and many others. However, the increase in successful cyberattacks demonstrates that the effectiveness of ML in cybersecurity applications can be questioned. Although the attacks may be new, ML is often adopted due to its ability to handle diverse and often unforeseen situations – a capability that is not possible using traditional rule-based security mechanisms. As both the rate of attacks and adoption of ML solutions are increasing, there is a need to determine whether ML-based security solutions are meeting the expectations of businesses and whether businesses are genuinely aware of the ML capabilities and limitations. Moreover, current literature shows a significant variation in how ML solutions are evaluated in cybersecurity applications, which might result in a poor understanding of ML capabilities. This paper explores the common perceptions and observations of decision-makers and specialists using ML for cybersecurity regarding its capabilities, implementation, evaluation, and communication. A semi-structured interview is conducted with individuals in various managerial positions to perform this investigation. The finding of this study reveals a pressing need for a standard to manifest ML capabilities. As significant variation in the understanding of Machine Learning Cyber Security (MLCS) capabilities is observed, a standard could help better communicate MLCS capabilities. It is observed that external influences heavily impact ML adoption decisions, potentially leading to misinterpretation of ML capabilities.}
}
",https://www.sciencedirect.com/science/article/pii/S0167404823006041,https://doi.org/10.1016/j.cose.2023.103694,science_direct,2024
1242,Defending novice user privacy: An evaluation of default web browser configurations,"@article{RADIVOJEVIC2024103784,
title = {Defending novice user privacy: An evaluation of default web browser configurations},
journal = {Computers & Security},
volume = {140},
pages = {103784},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103784},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824000853},
author = {Kristina Radivojevic and Nicholas Clark and Anna Klempay and Paul Brenner},
keywords = {Desktop browsers, Privacy, Novice users},
abstract = {Cyber novices often enter sensitive data into web browsers for routine activities such as online shopping and bill payments, making them targets for malicious entities, including cybercriminals and oppressive governments. The proliferation of online advertising technologies further exacerbates privacy concerns by exploiting user data for marketing or surveillance, frequently without explicit consent. It is crucial to regularly ensure the latest features of default configurations, which are most relevant for novice users, adequately address growing privacy demands given the centrality of web browsers to internet usage. Our work scrutinizes the privacy claims of 14 desktop browsers and their default configurations, from mainstream options like Chrome to those prioritizing privacy, such as Brave. We validate these claims through a suite of privacy tests on two operating systems commonly used by cyber novices. Based on our findings, we categorize browsers into three tiers of privacy protection. We conclude by outlining future browser design principles and offering privacy-centric recommendations tailored for novice users.}
}
",https://www.sciencedirect.com/science/article/pii/S0167404824000853,https://doi.org/10.1016/j.cose.2024.103784,science_direct,2024
1243,ChatGPT or Bard: Who is a better Certified Ethical Hacker?,"@article{RAMAN2024103804,
title = {ChatGPT or Bard: Who is a better Certified Ethical Hacker?},
journal = {Computers & Security},
volume = {140},
pages = {103804},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103804},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824001056},
author = {Raghu Raman and Prasad Calyam and Krishnashree Achuthan},
keywords = {Ethical hacking, Policy, Social behavior, Readability, Similarity analysis, Cybersecurity generative ai},
abstract = {In this study, we compare two leading Generative AI (GAI) tools, ChatGPT and Bard, specifically in Cybersecurity, using a robust set of standardized questions from a validated Certified Ethical Hacking (CEH) dataset. In the rapidly evolving domain of Generative AI (GAI) and large language models (LLM), a comparative analysis of tools becomes essential to measure their performance. We determine the Comprehensiveness, Clarity, and Conciseness of the AI-generated responses through a detailed questioning-based framework. The study revealed an overall accuracy rate of 80.8 % for ChatGPT and 82.6 % for Bard, indicating comparable capabilities and specific differences. Bard slightly outperformed ChatGPT in accuracy, while ChatGPT exhibited superiority in Comprehensiveness, Clarity, and Conciseness of responses. Introducing a confirmation query like “Are you sure?” increased accuracy for both generative AI tools, illustrating the potential of iterative query processing in enhancing GAI tools' effectiveness. The readability evaluation placed both tools at a college reading level, with Bard marginally more accessible. While evaluating certain questions, a distinct pattern emerged where Bard provided generic denials of assistance while ChatGPT referenced “ethics.” This discrepancy illustrates the contrasting philosophies of the developers of these tools, with Bard possibly following stricter guidelines, especially in sensitive topics like Cybersecurity. We explore the implications and identify key areas for future research that become increasingly relevant as GAI tools see broader adoption.}
}
",https://www.sciencedirect.com/science/article/pii/S0167404824001056,https://doi.org/10.1016/j.cose.2024.103804,science_direct,2024
1244,XLMR4MD: New Vietnamese dataset and framework for detecting the consistency of description and permission in Android applications using large language models,"@article{NGUYEN2024103814,
title = {XLMR4MD: New Vietnamese dataset and framework for detecting the consistency of description and permission in Android applications using large language models},
journal = {Computers & Security},
volume = {140},
pages = {103814},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103814},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824001159},
author = {Qui Ngoc Nguyen and Nguyen Tan Cam and Kiet {Van Nguyen}},
keywords = {Large language models, App Android, Security policy, Application permissions, Application description, Deep learning},
abstract = {Google Play and other application marketplaces have various Android applications and metadata. Among these, description information and privacy policy help explain the application's functionality. They also describe the permission of the application, especially those related to sensitive information. Detecting the inconsistency between the description of the application and privacy information and the permission extracted in the application's source code helps users decide whether to install and use the application. In this research, we propose a new method based on a pre-trained language model to detect inconsistencies between the permission extracted from the description application and privacy policy and the permission extracted from the application's source code (file APK). Related works focus on models of large-scale datasets, especially for resource-rich languages such as English. However, a language with low resources, like Vietnamese, needs more datasets for the task. To solve this problem, we propose the ViDPApp dataset (Description and Privacy Policy of Applications on Vietnamese domains), a high-quality dataset that humans manually annotate with 12,000+ sentences with an inter-annotator agreement (IAA) of over 85%. In addition, we proposed XLMR4MD, a new framework using large language models, outperforming powerful machine models (LSTM, Bi-GRU-LSTM-CNN, WikiBERT, DistilBERT, mBERT, and PhoBERT) and achieving the best with 84.04% F1 score in detecting inconsistencies between Android application permission and description. This framework can be fine-tuned for 100 languages, which benefits low-resource languages like Vietnamese. The dataset is available for research purposes.}
}
",https://www.sciencedirect.com/science/article/pii/S0167404824001159,https://doi.org/10.1016/j.cose.2024.103814,science_direct,2024
1245,Fostering security-related citizenship through the employee-supervisor relationship: An examination of supervisor security embodiment,"@article{DAVIS2024103896,
title = {Fostering security-related citizenship through the employee-supervisor relationship: An examination of supervisor security embodiment},
journal = {Computers & Security},
volume = {142},
pages = {103896},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103896},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824001986},
author = {Joshua M. Davis and Deepti Agrawal and Rebekah Austin},
keywords = {Supervisor security embodiment, Social identity theory of leadership, Leader-member exchange, Behavioral information security},
abstract = {Organizational information security performance is increasingly dependent on employees’ security-related citizenship behaviors that stretch beyond the scope of formal organizational prescription and control. Unfortunately, cultivating enactment of these valued behaviors has proven challenging for many companies. The literature has recognized workplace relationships as important determinants of behavioral security outcomes and extra-role security behaviors (ERBs) in particular. Taken further, an employee's relationship with the immediate supervisor is recognized as one of the most influential relational factors shaping a variety of workplace behaviors, including those related to security. Consistent with these notions, scholars have called for making the employee-supervisor relationship a more central component of behavioral security research and practice. Currently however, beyond recognition of this relationship's importance, the knowledge base is unclear about how it shapes ERB enactment. Because employees view supervisors as both organizational agents and as individuals in their own rights, this relationship has the potential to drive productive or counterproductive security behaviors, depending on how aligned the supervisor's security values are with those of the organization. Yet, the security literature has given surprisingly little consideration to the notion that employees can differ in the extent to which they perceive supervisors as embodying organizational information security values. Responding to this gap, the current study examines how employee-supervisor relations and perceived security-related value alignment between supervisors and the broader organization shape employees’ commitment to organizational information security and ultimately, ERB enactment. Grounded in the social identity theory of leadership (SITL), a research model is developed that positions high-quality employee-supervisor exchange as a direct antecedent of affective commitment to organizational information security, which then serves as a central intrinsic motivational mechanism driving ERB enactment. Further, rooted in SITL's principles on leader prototypicality and supervisor organizational embodiment, employee-perceived value alignment between the immediate supervisor and the organization as a whole—referred to here as supervisor security embodiment (SSE)—is introduced as a critical boundary condition influencing the extent to which employee-supervisor relations drive commitment. Results from model testing empirically demonstrate the value of SSE in explicating how this important relationship shapes workplace ERB enactment, through its influence on affective commitment to organizational information security performance.}
}
",https://www.sciencedirect.com/science/article/pii/S0167404824001986,https://doi.org/10.1016/j.cose.2024.103896,science_direct,2024
1246,"From COBIT to ISO 42001: Evaluating cybersecurity frameworks for opportunities, risks, and regulatory compliance in commercializing large language models","@article{MCINTOSH2024103964,
title = {From COBIT to ISO 42001: Evaluating cybersecurity frameworks for opportunities, risks, and regulatory compliance in commercializing large language models},
journal = {Computers & Security},
pages = {103964},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103964},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824002694},
author = {Timothy R. McIntosh and Teo Susnjak and Tong Liu and Paul Watters and Dan Xu and Dongwei Liu and Raza Nowrozy and Malka N. Halgamuge},
keywords = {Cybersecurity frameworks, Large language models, Risk management, AI governance, Cyber resilience, Information security},
abstract = {This study investigated the integration readiness of four predominant cybersecurity Governance, Risk and Compliance (GRC) frameworks - NIST CSF 2.0, COBIT 2019, ISO 27001:2022, and the latest ISO 42001:2023 - for the opportunities, risks, and regulatory compliance when adopting Large Language Models (LLMs), using qualitative content analysis and expert validation. Our analysis, with both LLMs and human experts in the loop, uncovered potential for LLM integration together with inadequacies in LLM risk oversight of those frameworks. Comparative gap analysis has highlighted that the new ISO 42001:2023, specifically designed for Artificial Intelligence (AI) management systems, provided most comprehensive facilitation for LLM opportunities, whereas COBIT 2019 aligned most closely with the European Union AI Act. Nonetheless, our findings suggested that all evaluated frameworks would benefit from enhancements to more effectively and more comprehensively address the multifaceted risks associated with LLMs, indicating a critical and time-sensitive need for their continuous evolution. We propose integrating human-expert-in-the-loop validation processes as crucial for enhancing cybersecurity frameworks to support secure and compliant LLM integration, and discuss implications for the continuous evolution of cybersecurity GRC frameworks to support the secure integration of LLMs.}
}
",https://www.sciencedirect.com/science/article/pii/S0167404824002694,https://doi.org/10.1016/j.cose.2024.103964,science_direct,2024
1247,"A contemporary review on chatbots, AI-powered virtual conversational agents, ChatGPT: Applications, open challenges and future research directions","@article{CASHEEKAR2024100632,
title = {A contemporary review on chatbots, AI-powered virtual conversational agents, ChatGPT: Applications, open challenges and future research directions},
journal = {Computer Science Review},
volume = {52},
pages = {100632},
year = {2024},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2024.100632},
url = {https://www.sciencedirect.com/science/article/pii/S1574013724000169},
author = {Avyay Casheekar and Archit Lahiri and Kanishk Rath and Kaushik Sanjay Prabhakar and Kathiravan Srinivasan},
keywords = {Computational intelligence, Artificial intelligence, Chatbots, Conversational agents, ChatGPT},
abstract = {This review paper offers an in-depth analysis of AI-powered virtual conversational agents, specifically focusing on OpenAI’s ChatGPT. The main contributions of this paper are threefold: (i) an exhaustive review of prior literature on chatbots, (ii) a background of chatbots including existing chatbots/conversational agents like ChatGPT, and (iii) a UI/UX design analysis of prominent chatbots. Another contribution of this review is the comprehensive exploration of ChatGPT’s applications across a multitude of sectors, including education, business, public health, and more. This review highlights the transformative potential of ChatGPT, despite the challenges it faces such as hallucination, biases in training data, jailbreaks, and anonymous data collection. The review paper then presents a comprehensive survey of prior literature reviews on chatbots, identifying gaps in the prior work and highlighting the need for further research in areas such as chatbot evaluation, user experience, and ethical considerations. The paper also provides a detailed analysis of the UI/UX design of prominent chatbots, including their conversational flow, visual design, and user engagement. The paper also identifies key future research directions, including mitigating language bias, enhancing ethical decision-making capabilities, improving user interaction and personalization, and developing robust governance frameworks. By solving these issues, we can ensure that AI chatbots like ChatGPT are used responsibly and effectively across a broad variety of applications. This review will be a valuable resource for researchers and practitioners in understanding the current state and future potential of AI chatbots like ChatGPT.}
}
",https://www.sciencedirect.com/science/article/pii/S1574013724000169,https://doi.org/10.1016/j.cosrev.2024.100632,science_direct,2024
1248,"A survey on detecting mental disorders with natural language processing: Literature review, trends and challenges","@article{MONTEJORAEZ2024100654,
title = {A survey on detecting mental disorders with natural language processing: Literature review, trends and challenges},
journal = {Computer Science Review},
volume = {53},
pages = {100654},
year = {2024},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2024.100654},
url = {https://www.sciencedirect.com/science/article/pii/S1574013724000388},
author = {Arturo Montejo-Ráez and M. Dolores Molina-González and Salud María Jiménez-Zafra and Miguel Ángel García-Cumbreras and Luis Joaquín García-López},
keywords = {Mental disorders detection, Natural language processing, Machine learning, Survey},
abstract = {For years, the scientific community has researched monitoring approaches for the detection of certain mental disorders and risky behaviors, like depression, eating disorders, gambling, and suicidal ideation among others, in order to activate prevention or mitigation strategies and, in severe cases, clinical treatment. Natural Language Processing is one of the most active disciplines dealing with the automatic detection of mental disorders. This paper offers a comprehensive and extensive review of research works on Natural Language Processing applied to the identification of some mental disorders. To this end, we have identified from a literature review, which are the main types of features used to represent the texts, the machine learning algorithms that are preferred or the most targeted social media platforms, among other aspects. Besides, the paper reports on scientific forums and projects focused on the automatic detection of these problems over the most popular social networks. Thus, this compilation provides a broad view of the matter, summarizing main strategies, and significant findings, but, also, recognizing some of the weaknesses in the research works published so far, serving as clues for future research.}
}
",https://www.sciencedirect.com/science/article/pii/S1574013724000388,https://doi.org/10.1016/j.cosrev.2024.100654,science_direct,2024
1249,A BERT-Based Sequential POI Recommender system in Social Media,"@article{NOORIAN2024103766,
title = {A BERT-Based Sequential POI Recommender system in Social Media},
journal = {Computer Standards & Interfaces},
volume = {87},
pages = {103766},
year = {2024},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2023.103766},
url = {https://www.sciencedirect.com/science/article/pii/S0920548923000478},
author = {A. Noorian},
keywords = {BERT, POI Route, Context-Aware, Deep Neural Networks, Personalization, Sequential recommendation},
abstract = {Route schema is challenging for tourists because they must choose Points of Interest (POIs) in unknown areas that meet their preferences and limitations. Historically, sequential methods were utilized to generate recommendations based on previous user interactions. Despite their efficacy, however, such left-to-right unidirectional models are suboptimal due to the following factors: a) user behavior sequences are restricted in their ability to utilize hidden representations in unidirectional architectures; b) a rigidly ordered sequence is frequently assumed but is not always possible. This paper proposes a novel personalized sequential recommendation model, termed BERTSeqHybrid, which utilizes Bidirectional Encoder Representations from Transformers (BERT) to circumvent these limitations. In addition to contextual data from POIs, asymmetric schemas, and topic modeling are employed to improve the user-user similarity model. Furthermore, a novel method for evaluating user preferences is proposed utilizing explicit demographic data to mitigate the cold start problem. In the experimental evaluation, the developed methodology, which was applied to two different datasets (Yelp and Flickr), produced superior root mean square error RMSE, F-Score, mean average precision (MAP), and normalized discounted cumulative gain (NDCG) indexes.}
}
",https://www.sciencedirect.com/science/article/pii/S0920548923000478,https://doi.org/10.1016/j.csi.2023.103766,science_direct,2024
1250,BMSE: Blockchain-based multi-keyword searchable encryption for electronic medical records,"@article{SHEN2024103824,
title = {BMSE: Blockchain-based multi-keyword searchable encryption for electronic medical records},
journal = {Computer Standards & Interfaces},
volume = {89},
pages = {103824},
year = {2024},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2023.103824},
url = {https://www.sciencedirect.com/science/article/pii/S0920548923001058},
author = {Fanfan Shen and Lin Shi and Jun Zhang and Chao Xu and Yong Chen and Yanxiang He},
keywords = {Blockchain, Multiple keyword, Searchable encryption, K-means},
abstract = {The storage of electronic medical records (EMRs) is an area of extensive research, and healthcare systems often delegate this task to cloud service providers (CSP). Typically, CSP transmits the encrypted EMRs to a cloud server with a searchable encryption scheme for easy retrieval. However, the enormous power held by centralized CSP poses a potential threat to patients’ personal privacy, as it can lead to unauthorized access and misuse of medical data by both CSP and data users, such as doctors. This paper proposes a blockchain-based multi-keyword searchable encryption (BMSE) electronic medical record solution. The scheme consists of two parts. On the one hand, our solution involves the integration of blockchain technology and the utilization of advanced encryption standard (AES) for symmetric data encryption. Additionally, we employ attribute-based encryption (ABE) to encrypt the search index. This approach aims to address the issue of excessive power held by centralized CSP, which can potentially result in the compromise of patients’ privacy. On the other hand, we use the K-means algorithm to cluster the documents, and use the relevance score of keywords and documents as the search index to solve the problem of low efficiency of the existing multi-keyword searchable encryption schemes. Finally, we verify the safety of BMSE through safety analysis, and the experimental analysis shows that BMSE improves the search efficiency.}
}
",https://www.sciencedirect.com/science/article/pii/S0920548923001058,https://doi.org/10.1016/j.csi.2023.103824,science_direct,2024
1251,Is mouse dynamics information credible for user behavior research? An empirical investigation,"@article{KURIC2024103849,
title = {Is mouse dynamics information credible for user behavior research? An empirical investigation},
journal = {Computer Standards & Interfaces},
volume = {90},
pages = {103849},
year = {2024},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2024.103849},
url = {https://www.sciencedirect.com/science/article/pii/S0920548924000187},
author = {Eduard Kuric and Peter Demcak and Matus Krajcovic and Peter Nemcek},
keywords = {Mouse configuration, Measurement, Data validity, User behavior modeling, Biological sex classification, Machine learning},
abstract = {Mouse dynamics, information on user’s interaction with a computer mouse, are in vogue in machine learning for purposes such as recommendations, personalization, prediction of user characteristics and behavioral biometrics. We point out a blind spot in current works involving mouse dynamics that originates in underestimating the gravity of the characteristics of the mouse device and configuration on the data that mouse dynamics are inferred from. In a controlled study with N=32 participants, across three kinds of mouse interaction activities, we collect data for mouse dynamics utilizing a variety of mouse parameter configurations. We show that mouse dynamics commonly used in studies can be significantly altered by differences in mouse parameters. Out of 108 evaluated mouse dynamics metrics, 95 and 84 are affected between two conducted studies. A machine learning model’s performance can be warped by the mouse parameters being used. We demonstrate on a prediction task that mouse parameters cannot be approached uniformly and without consideration. We discuss methodological implications — how mouse dynamics studies should account for the diversity of mouse-related conditions.}
}
",https://www.sciencedirect.com/science/article/pii/S0920548924000187,https://doi.org/10.1016/j.csi.2024.103849,science_direct,2024
1252,A knowledge-sharing platform for space resources,"@article{DASILVEIRA2024102286,
title = {A knowledge-sharing platform for space resources},
journal = {Data & Knowledge Engineering},
volume = {151},
pages = {102286},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102286},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24000107},
author = {Marcos {Da Silveira} and Louis Deladiennee and Emmanuel Scolan and Cedric Pruski},
keywords = {Knowledge engineering, Knowledge graph, Ontology, Space resources},
abstract = {The ever-increasing interest of academia, industry, and government institutions in space resource information highlights the difficulty of finding, accessing, integrating, and reusing this information. Although information is regularly published on the internet, it is disseminated on many different websites and in different formats, including scientific publications, patents, news, and reports. We are currently developing a knowledge management and sharing platform for space resources. This tool, which relies on the combined use of knowledge graphs and ontologies, formalises the domain knowledge contained in the above-mentioned documents and makes it more readily available to the community. In this article, we describe the concepts and techniques of knowledge extraction and management adopted during the design and implementation of the platform.}
}
",https://www.sciencedirect.com/science/article/pii/S0169023X24000107,https://doi.org/10.1016/j.datak.2024.102286,science_direct,2024
1253,To prompt or not to prompt: Navigating the use of Large Language Models for integrating and modeling heterogeneous data,"@article{REMADI2024102313,
title = {To prompt or not to prompt: Navigating the use of Large Language Models for integrating and modeling heterogeneous data},
journal = {Data & Knowledge Engineering},
volume = {152},
pages = {102313},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102313},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24000375},
author = {Adel Remadi and Karim {El Hage} and Yasmina Hobeika and Francesca Bugiotti},
keywords = {Data engineering, Large language models, Conceptual schema modeling, Entity resolution, Data integration, Property graph models},
abstract = {Manually integrating data of diverse formats and languages is vital to many artificial intelligence applications. However, the task itself remains challenging and time-consuming. This paper highlights the potential of Large Language Models (LLMs) to streamline data extraction and resolution processes. Our approach aims to address the ongoing challenge of integrating heterogeneous data sources, encouraging advancements in the field of data engineering. Applied on the specific use case of learning disorders in higher education, our research demonstrates LLMs’ capability to effectively extract data from unstructured sources. It is then further highlighted that LLMs can enhance data integration by providing the ability to resolve entities originating from multiple data sources. Crucially, the paper underscores the necessity of preliminary data modeling decisions to ensure the success of such technological applications. By merging human expertise with LLM-driven automation, this study advocates for the further exploration of semi-autonomous data engineering pipelines.}
}
",https://www.sciencedirect.com/science/article/pii/S0169023X24000375,https://doi.org/10.1016/j.datak.2024.102313,science_direct,2024
1254,Large language models: Expectations for semantics-driven systems engineering,"@article{BUCHMANN2024102324,
title = {Large language models: Expectations for semantics-driven systems engineering},
journal = {Data & Knowledge Engineering},
volume = {152},
pages = {102324},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102324},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X2400048X},
author = {Robert Buchmann and Johann Eder and Hans-Georg Fill and Ulrich Frank and Dimitris Karagiannis and Emanuele Laurenzi and John Mylopoulos and Dimitris Plexousakis and Maribel Yasmina Santos},
keywords = {Large language models, Systems engineering, Conceptual modeling, Knowledge engineering},
abstract = {The hype of Large Language Models manifests in disruptions, expectations or concerns in scientific communities that have focused for a long time on design-oriented research. The current experiences with Large Language Models and associated products (e.g. ChatGPT) lead to diverse positions regarding the foreseeable evolution of such products from the point of view of scholars who have been working with designed abstractions for most of their careers - typically relying on deterministic design decisions to ensure systems and automation reliability. Such expectations are collected in this paper in relation to a flavor of systems engineering that relies on explicit knowledge structures, introduced here as “semantics-driven systems engineering”. The paper was motivated by the panel discussion that took place at CAiSE 2023 in Zaragoza, Spain, during the workshop on Knowledge Graphs for Semantics-driven Systems Engineering (KG4SDSE). The workshop brought together Conceptual Modeling researchers with an interest in specific applications of Knowledge Graphs and the semantic enrichment benefits they can bring to systems engineering. The panel context and consensus are summarized at the end of the paper, preceded by a proposed research agenda considering the expressed positions.}
}
",https://www.sciencedirect.com/science/article/pii/S0169023X2400048X,https://doi.org/10.1016/j.datak.2024.102324,science_direct,2024
1256,Predicting student dropout in subscription-based online learning environments: The beneficial impact of the logit leaf model,"@article{COUSSEMENT2020113325,
title = {Predicting student dropout in subscription-based online learning environments: The beneficial impact of the logit leaf model},
journal = {Decision Support Systems},
volume = {135},
pages = {113325},
year = {2020},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2020.113325},
url = {https://www.sciencedirect.com/science/article/pii/S0167923620300804},
author = {Kristof Coussement and Minh Phan and Arno {De Caigny} and Dries F. Benoit and Annelies Raes},
keywords = {Learning analytics, Proactive student management, Subscription-based online learning, Student dropout, Logit leaf model, Machine learning},
abstract = {Online learning has been adopted rapidly by educational institutions and organizations. Despite its many advantages, including 24/7 access, high flexibility, rich content, and low cost, online learning suffers from high dropout rates that hamper pedagogical and economic goal outcomes. Enhanced student dropout prediction tools would help providers proactively detect students at risk of leaving and identify factors that they might address to help students continue their learning experience. Therefore, this study seeks to improve student dropout predictions, with three main contributions. First, it benchmarks a recently proposed logit leaf model (LLM) algorithm against eight other algorithms, using a real-life data set of 10,554 students of a global subscription-based online learning provider. The LLM outperforms all other methods in finding a balance between predictive performance and comprehensibility. Second, a new multilevel informative visualization of the LLM adds novel benefits, relative to a standard LLM visualization. Third, this research specifies the impacts of student demographics; classroom characteristics; and academic, cognitive, and behavioral engagement variables on student dropout. In reviewing LLM segments, these results show that different insights emerge for various student segments with different learning patterns. This notable result can be used to personalize student retention campaigns.}
}
",https://www.sciencedirect.com/science/article/pii/S0167923620300804,https://doi.org/10.1016/j.dss.2020.113325,science_direct,2020
1257,A decision support framework to incorporate textual data for early student dropout prediction in higher education,"@article{PHAN2023113940,
title = {A decision support framework to incorporate textual data for early student dropout prediction in higher education},
journal = {Decision Support Systems},
volume = {168},
pages = {113940},
year = {2023},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2023.113940},
url = {https://www.sciencedirect.com/science/article/pii/S0167923623000155},
author = {Minh Phan and Arno {De Caigny} and Kristof Coussement},
keywords = {Decision support framework, Learning analytics, Student dropout prediction, Textual data, doc2vec, Segmentation},
abstract = {Managing student dropout in higher education is critical, considering its substantial impacts on students' lives, academic institutions, and society as a whole. Using predictive modeling can be instrumental for this task, as a means to identify dropouts proactively on the basis of student characteristics and their academic performance. To enhance these predictions, textual student feedback also might be relevant; this article proposes a hybrid decision support framework that combines predictive modeling with student segmentation efforts. A real-life data set from a French higher education institution, containing information of 14,391 students and 62,545 feedback documents, confirms the superior performance of the proposed framework, in terms of the area under the curve and top decile lift, compared with various benchmarks. In contributing to decision support system research, this study (1) proposes a new framework for automatic, data-driven segmentation of students based on textual data; (2) compares multiple text representation methods and confirms that incorporating student textual feedback data improves the predictive performance of student dropout models; and (3) establishes useful insights to help decision-makers anticipate and manage student dropout behaviors.}
}
",https://www.sciencedirect.com/science/article/pii/S0167923623000155,https://doi.org/10.1016/j.dss.2023.113940,science_direct,2023
1258,Complex business ecosystem intelligence using AI-powered visual analytics,"@article{BASOLE2024114133,
title = {Complex business ecosystem intelligence using AI-powered visual analytics},
journal = {Decision Support Systems},
volume = {178},
pages = {114133},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2023.114133},
url = {https://www.sciencedirect.com/science/article/pii/S0167923623002087},
author = {Rahul C. Basole and Hyunwoo Park and C. David Seuss},
keywords = {Business ecosystem, Artificial intelligence, Text mining, Complex networks, Interactive visualization},
abstract = {Business ecosystems are complex, dynamic systems characterized by a multitude of entities, including companies, ventures, and technologies, as well as activities and trends. Understanding the state of business ecosystems is an increasingly critical strategic imperative for many decision makers, but it is a resource-intensive activity as relevant information sources are dispersed, often highly unstructured, and not integrated or curated to deliver actionable insights. In this research, we present the design and implementation of an interactive visual analytic system that integrates artificial intelligence and graph visualization techniques to augment decision makers’ understanding of the complex public narrative associated with business ecosystems entities. Our system is driven by a real-time content engine of 100,000+ global data sources including press releases, news articles, industry reports, analyst blogs in multiple languages organized across several domain-specific repositories. Following a user-specified query, the engine extracts both domain-agnostic and domain-specific entities and concepts for each document in the result set. We then model and visualize the resulting data as a dynamic, multipartite network and implement graph pruning algorithms and interactive data controls to enable users to interactively explore and discover the underlying business ecosystem from multiple perspectives. We illustrate and discuss the value of our system using representative use cases. Our study makes multiple contributions to visual decision support theory and practice, including mining unstructured data, constructing and interacting with knowledge graphs, and designing visual analytic tools for ecosystem intelligence. We conclude the study with implications and future research opportunities.}
}
",https://www.sciencedirect.com/science/article/pii/S0167923623002087,https://doi.org/10.1016/j.dss.2023.114133,science_direct,2024
1259,Blockchain and big data integration design for traceability and carbon footprint management in the fishery supply chain,"@article{ALWI2024100481,
title = {Blockchain and big data integration design for traceability and carbon footprint management in the fishery supply chain},
journal = {Egyptian Informatics Journal},
volume = {26},
pages = {100481},
year = {2024},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2024.100481},
url = {https://www.sciencedirect.com/science/article/pii/S1110866524000446},
author = {Aslan Alwi and Nugroho Adi Sasongko and  Suprapto and Yaya Suryana and Hendro Subagyo},
keywords = {Blockchain, Big data, ETL design, Data warehouse, Fisheries, Supply chain, Anonymity, Immutability, Carbon footprint, Sustainability, Traceability},
abstract = {The utilization of blockchain technology in the fishing industry has been extensively studied and implemented to address issues such as illegal fishing and carbon emissions control. However, integrating blockchain with the vast amounts of data in the fishing supply chain poses significant challenges. Challenges include managing extensive data such as photos or videos for product traceability throughout their lifecycle, compounded by the growing complexity of cross-border trade and market expansion. Additionally, blockchain's storage capacity limitations present hurdles in fully accommodating and comprehensively storing detailed supply data from a complex and expanding supply chain. While solutions like the Interplanetary File System (IPFS) have been explored for large data storage on the blockchain, this paper proposes a directly integrated blockchain solution tailored for the challenges of fishing with big data. We introduce a novel big data design that preserves blockchain's anonymity and immutability features, addressing storage limitations while maintaining the architecture's purpose. Furthermore, our proposal integrates product supply chain traceability with carbon footprint tracking, enabling comprehensive assessment based on quality, sustainability, and carbon footprint criteria. Despite the proposed solution needing to be tested in real-life situations, we conducted rigorous testing through simulation, white-box evaluation, and complexity analysis. The results demonstrate the potential of our solution to address challenges faced in fisheries supply chains, providing valuable insights for future practical implementation and validation efforts.}
}
",https://www.sciencedirect.com/science/article/pii/S1110866524000446,https://doi.org/10.1016/j.eij.2024.100481,science_direct,2024
1260,"Explainable AI for Operational Research: A defining framework, methods, applications, and a research agenda","@article{DEBOCK2024249,
title = {Explainable AI for Operational Research: A defining framework, methods, applications, and a research agenda},
journal = {European Journal of Operational Research},
volume = {317},
number = {2},
pages = {249-272},
year = {2024},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2023.09.026},
url = {https://www.sciencedirect.com/science/article/pii/S0377221723007294},
author = {Koen W. {De Bock} and Kristof Coussement and Arno De Caigny and Roman Słowiński and Bart Baesens and Robert N. Boute and Tsan-Ming Choi and Dursun Delen and Mathias Kraus and Stefan Lessmann and Sebastián Maldonado and David Martens and María Óskarsdóttir and Carla Vairetti and Wouter Verbeke and Richard Weber},
keywords = {Decision analysis, XAI, Explainable artificial intelligence, Interpretable machine learning, XAIOR},
abstract = {The ability to understand and explain the outcomes of data analysis methods, with regard to aiding decision-making, has become a critical requirement for many applications. For example, in operational research domains, data analytics have long been promoted as a way to enhance decision-making. This study proposes a comprehensive, normative framework to define explainable artificial intelligence (XAI) for operational research (XAIOR) as a reconciliation of three subdimensions that constitute its requirements: performance, attributable, and responsible analytics. In turn, this article offers in-depth overviews of how XAIOR can be deployed through various methods with respect to distinct domains and applications. Finally, an agenda for future XAIOR research is defined.}
}
",https://www.sciencedirect.com/science/article/pii/S0377221723007294,https://doi.org/10.1016/j.ejor.2023.09.026,science_direct,2024
1261,Assessing growth potential of careers with occupational mobility network and ensemble framework,"@article{LIU2024107306,
title = {Assessing growth potential of careers with occupational mobility network and ensemble framework},
journal = {Engineering Applications of Artificial Intelligence},
volume = {127},
pages = {107306},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107306},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623014902},
author = {Jiamin Liu and Tao Wang and Feng Yao and Witold Pedrycz and Yanjie Song and Renjie He},
keywords = {Human capital, Occupational mobility network, Growth potential of career, Machine learning},
abstract = {The growth potential of a career reflects its future prospects and is an important consideration for individuals and organizations when career planning. There is still a lack of quantitative assessment tools for growth potential of careers. In this study, considering the key role of human capital in human resource management, as well as the excellent performance of complex network and machine learning in big data analysis and prediction, a career growth potential assessment model with human capital ensemble is proposed through human capital-based occupational mobility network and ensemble learning. First, an occupational mobility network is constructed based on online professional dataset to associate occupations with each other. Then, five dimensions of human capital measurements are designed to quantify human capital in terms of education, experience, social capital, occupational size, and concentration. These are then combined with the occupational mobility network to create a new network that depicts human capital flows among occupations. Finally, an ensemble framework for assessing career growth potential is constructed to integrate multidimensional human capital information in the network and obtain quantitative scores of growth potential. This study is the original attempt to adopt a data-driven idea and an intelligent approach to understand career growth potential. The experimental results show that it also makes a useful exploration for modeling human capital flows and intelligent assessment of career prospects.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197623014902,https://doi.org/10.1016/j.engappai.2023.107306,science_direct,2024
1262,A dual-stream recurrence-attention network with global–local awareness for emotion recognition in textual dialog,"@article{LI2024107530,
title = {A dual-stream recurrence-attention network with global–local awareness for emotion recognition in textual dialog},
journal = {Engineering Applications of Artificial Intelligence},
volume = {128},
pages = {107530},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107530},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623017141},
author = {Jiang Li and Xiaoping Wang and Zhigang Zeng},
keywords = {Dialog emotion recognition, Recurrent neural network, Multi-head attention network, Dialog system, Dual-stream network},
abstract = {In real-world dialog systems, the ability to understand the user’s emotions and interact anthropomorphically is of great significance. Emotion Recognition in Conversation (ERC) is one of the key ways to accomplish this goal and has attracted growing attention. How to model the context in a conversation is a central aspect and a major challenge of ERC tasks. Most existing approaches struggle to adequately incorporate both global and local contextual information, and their network structures are overly sophisticated. For this reason, we propose a simple and effective Dual-stream Recurrence-Attention Network (DualRAN), which is based on Recurrent Neural Network (RNN) and Multi-head ATtention network (MAT). DualRAN eschews the complex components of current methods and focuses on combining recurrence-based methods with attention-based ones. DualRAN is a dual-stream structure mainly consisting of local- and global-aware modules, modeling a conversation simultaneously from distinct perspectives. In addition, we develop two single-stream network variants for DualRAN, i.e., SingleRANv1 and SingleRANv2. According to the experimental findings, DualRAN boosts the weighted F1 scores by 1.43% and 0.64% on the IEMOCAP and MELD datasets, respectively, in comparison to the strongest baseline. On two other datasets (i.e., EmoryNLP and DailyDialog), our method also attains competitive results.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197623017141,https://doi.org/10.1016/j.engappai.2023.107530,science_direct,2024
1263,Blockchain-based auditing of legal decisions supported by explainable AI and generative AI tools,"@article{SACHAN2024107666,
title = {Blockchain-based auditing of legal decisions supported by explainable AI and generative AI tools},
journal = {Engineering Applications of Artificial Intelligence},
volume = {129},
pages = {107666},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107666},
url = {https://www.sciencedirect.com/science/article/pii/S095219762301850X},
author = {Swati Sachan and Xi {Liu (Lisa)}},
keywords = {Legal, Law, Explainable AI, Blockchain, Generative AI, Responsible AI},
abstract = {Generative AI tools powered by Large Language Models (LLMs) have demonstrated advanced capabilities in understanding and articulating legal facts closer to the level of legal practitioners. However, scholars hold contrasting views on the reliability of the reasoning behind a decision derived from LLMs due to its black-box nature. Law firms are vigilant in recognizing the potential risks of violating confidentiality and inappropriate exposure of sensitive legal data through the prompt sent to Generative AI. This research attempts to find an equilibrium between responsible usage and control of human legal professionals over content produced by Generative AI through regular audits. It investigates the potential of Generative AI in drafting correspondence for pre-litigation decisions derived from an eXplainable AI (XAI) algorithm. This research presents an end-to-end process of designing the architecture and methodology for a blockchain-based auditing system. It detects unauthorized alterations of data repositories containing the decisions by an XAI model and automated textual explanation by Generative AI. The automated auditing by blockchain facilitates responsible usage of AI technologies and reduces discrepancies in tracing the accountability of adversarial decisions. It conceptualizes the two algorithms. First, strategic on-chain (within blockchain) and off-chain (outside blockchain) data storage in compliance with the data protection laws and critical requirements of stakeholders in a legal firm. Second, auditing by comparison of the unique signature as Merkle roots of files stored off-chain with their immutable blockchain counterpart. A case study on liability cases under tort law demonstrates the system implementation results.}
}
",https://www.sciencedirect.com/science/article/pii/S095219762301850X,https://doi.org/10.1016/j.engappai.2023.107666,science_direct,2024
1264,A comprehensive review of synthetic data generation in smart farming by using variational autoencoder and generative adversarial network,"@article{AKKEM2024107881,
title = {A comprehensive review of synthetic data generation in smart farming by using variational autoencoder and generative adversarial network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {131},
pages = {107881},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.107881},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624000393},
author = {Yaganteeswarudu Akkem and Saroj Kumar Biswas and Aruna Varanasi},
keywords = {Variational autoencoders, Generative adversarial networks, Smart farming},
abstract = {In this study, we propose the use of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to generate synthetic data for crop recommendation (CR). CR is critical in agriculture, assisting farmers in making informed decisions about crop cultivation, considering factors like soil conditions, weather patterns etc. Unfortunately, the availability of labeled data for CR is often limited, posing a significant challenge in training accurate recommendation models. VAEs and GANs are employed to create synthetic data that closely mirrors real-world crop data. VAEs are utilized to extract latent representation from the input data, enabling the generation of new samples with similar characteristics. GANs play a crucial role in generating data by training a generator network to produce synthetic samples that closely resemble real data, while a discriminator network distinguishes between genuine and synthetic data. The generated synthetic data serves as a valuable resource to prepare datasets for CR, enhancing the performance of recommendation models. Our research explores the effectiveness of VAEs and GANs in producing high-quality synthetic CR data, facilitating improved training and evaluation of recommendation systems. This paper presents the architecture and training process of the proposed models and evaluates the quality and utility of the generated synthetic data using various experiments, including visualizations such as heatmaps, scatter plots, cumulative sum per feature plots, and distribution per feature plots. The results of this study hold the potential to make a significant contribution to the field of agriculture by providing a reliable and abundant source of training data for CR systems.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624000393,https://doi.org/10.1016/j.engappai.2024.107881,science_direct,2024
1265,AGCVT-prompt for sentiment classification: Automatically generating chain of thought and verbalizer in prompt learning,"@article{GU2024107907,
title = {AGCVT-prompt for sentiment classification: Automatically generating chain of thought and verbalizer in prompt learning},
journal = {Engineering Applications of Artificial Intelligence},
volume = {132},
pages = {107907},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.107907},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624000654},
author = {Xu Gu and Xiaoliang Chen and Peng Lu and Zonggen Li and Yajun Du and Xianyong Li},
keywords = {Large language models, Prompt learning, Sentiment classification, Chain of thought},
abstract = {Large language models (LLMs) have revolutionized natural language processing, but they require significant data and hardware resources. Prompt learning offers a solution by enabling a single model for multiple downstream tasks. However, current prompt learning methods rely on costly prompt templates for training. This is a challenge for tasks like sentiment classification, where high-quality templates are hard to create and pseudo-token composed templates can be expensive to train. Recent studies on the chain of thought (COT) have shown that enhancing the presentation of certain aspects of the reasoning process can improve the performance of LLMs. With this in mind, this research introduces the auto-generated COT and verbalizer templates (AGCVT-Prompt) technique, which clusters unlabeled texts according to their identified topic and sentiment. Subsequently, it generates dual verbalizers and formulates both topic and sentiment prompt templates, utilizing the categories discerned within the text and verbalizers. This method significantly improves the transparency and interpretability of the model’s decision-making processes. The AGCVT-Prompt technique was evaluated against conventional prompt learning and advanced sentiment classification methods, using state-of-the-art LLMs on both Chinese and English datasets. The results showed superior performance in all evaluations. Specifically, the AGCVT-Prompt method outperformed previous prompt learning techniques in few-shot learning scenarios, providing higher zero-shot and few-shot learning capabilities. Additionally, AGCVT-Prompt was utilized to analyze network comments about Corona Virus Disease 2019, providing valuable insights. These findings indicate that AGCVT-Prompt is a promising alternative for sentiment classification tasks, particularly in situations where labeled data is scarce.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624000654,https://doi.org/10.1016/j.engappai.2024.107907,science_direct,2024
1266,AraCovTexFinder: Leveraging the transformer-based language model for Arabic COVID-19 text identification,"@article{HOSSAIN2024107987,
title = {AraCovTexFinder: Leveraging the transformer-based language model for Arabic COVID-19 text identification},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {107987},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.107987},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624001453},
author = {Md. Rajib Hossain and Mohammed Moshiul Hoque and Nazmul Siddique and M. Ali Akber Dewan},
keywords = {Natural language processing, Low-resource text identification, Text processing, Language model, Arabic covid text, Ablation study, Late-fusion},
abstract = {In light of the pandemic, the identification and processing of COVID-19-related text have emerged as critical research areas within the field of Natural Language Processing (NLP). With a growing reliance on online portals and social media for information exchange and interaction, a surge in online textual content, comprising disinformation, misinformation, fake news, and rumors has led to the phenomenon of an infodemic on the World Wide Web. Arabic, spoken by over 420 million people worldwide, stands as a significant low-resource language, lacking efficient tools or applications for the detection of COVID-19-related text. Additionally, the identification of COVID-19 text is an essential prerequisite task for detecting fake and toxic content associated with COVID-19. This gap hampers crucial COVID information retrieval and processing necessary for policymakers and health authorities. Addressing this issue, this paper introduces an intelligent Arabic COVID-19 text identification system named ‘AraCovTexFinder,’ leveraging a fine-tuned fusion-based transformer model. Recognizing the challenges posed by a scarcity of related text corpora, substantial morphological variations in the language, and a deficiency of well-tuned hyperparameters, the proposed system aims to mitigate these hurdles. To support the proposed method, two corpora are developed: an Arabic embedding corpus (AraEC) and an Arabic COVID-19 text identification corpus (AraCoV). The study evaluates the performance of six transformer-based language models (mBERT, XML-RoBERTa, mDeBERTa-V3, mDistilBERT, BERT-Arabic, and AraBERT), 12 deep learning models (combining Word2Vec, GloVe, and FastText embedding with CNN, LSTM, VDCNN, and BiLSTM), and the newly introduced model AraCovTexFinder. Through extensive evaluation, AraCovTexFinder achieves a high accuracy of 98.89 ± 0.001%, outperforming other baseline models, including transformer-based language and deep learning models. This research highlights the importance of specialized tools in low-resource languages to combat the infodemic relating to COVID-19, which can assist policymakers and health authorities in making informed decisions.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624001453,https://doi.org/10.1016/j.engappai.2024.107987,science_direct,2024
1267,A comparative analysis of knowledge injection strategies for large language models in the scholarly domain,"@article{CADEDDU2024108166,
title = {A comparative analysis of knowledge injection strategies for large language models in the scholarly domain},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108166},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108166},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624003245},
author = {Andrea Cadeddu and Alessandro Chessa and Vincenzo {De Leo} and Gianni Fenu and Enrico Motta and Francesco Osborne and Diego {Reforgiato Recupero} and Angelo Salatino and Luca Secchi},
keywords = {Knowledge injection, Knowledge graphs, Large language models, Transformers, BERT, Classification, Natural language processing},
abstract = {In recent years, transformer-based models have emerged as powerful tools for natural language processing tasks, demonstrating remarkable performance in several domains. However, they still present significant limitations. These shortcomings become more noticeable when dealing with highly specific and complex concepts, particularly within the scientific domain. For example, transformer models have particular difficulties when processing scientific articles due to the domain-specific terminologies and sophisticated ideas often encountered in scientific literature. To overcome these challenges and further enhance the effectiveness of transformers in specific fields, researchers have turned their attention to the concept of knowledge injection. Knowledge injection is the process of incorporating outside knowledge into transformer models to improve their performance on certain tasks. In this paper, we present a comprehensive study of knowledge injection strategies for transformers within the scientific domain. Specifically, we provide a detailed overview and comparative assessment of four primary methodologies, evaluating their efficacy in the task of classifying scientific articles. For this purpose, we constructed a new benchmark including both 24K labelled papers and a knowledge graph of 9.2K triples describing pertinent research topics. We also developed a full codebase to easily re-implement all knowledge injection strategies in different domains. A formal evaluation indicates that the majority of the proposed knowledge injection methodologies significantly outperform the baseline established by Bidirectional Encoder Representations from Transformers.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624003245,https://doi.org/10.1016/j.engappai.2024.108166,science_direct,2024
1268,GraphRec-based Korean expert recommendation using author contribution index and the paper abstracts in marine,"@article{LEE2024108219,
title = {GraphRec-based Korean expert recommendation using author contribution index and the paper abstracts in marine},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108219},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108219},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624003774},
author = {Jeong-Wook Lee and Jae-Hoon Kim},
keywords = {Recommendation system, Marine expert recommendation system, Graph neural networks},
abstract = {Expert recommendation systems recommend specialized experts in a particular field to users based on the knowledge of those experts. However, these systems are limited by the number of experts available and the potential for subjective evaluation, which may result in inappropriate recommendations. Furthermore, we explore the evolution from traditional to deep learning-based recommendation systems, emphasizing graph-based recommendation systems. Nonetheless, deep learning-based systems require large amounts of data, and marine expert recommendation training data are scarce. To address these issues, we constructed and utilized marine expert data in this study. The dataset contains abstracts of marine-related papers and information on their authors. Graphs were generated by assessing the similarity among the abstracts, representing them in a graph format indicative of this similarity, and using the author contribution index to depict the relationship between the abstracts and their respective authors. Various similarity methods and abstract embedding techniques were experimentally explored to realize performance optimization. In the experiments, the optimized model achieved a mean absolute error of 0.7556 and a root-mean-squared error of 1.0421. Notably, this study highlights the limitations of traditional evaluation metrics and proposes the averaged mean reciprocal rank as a suitable alternative. This metric facilitates the quantitative evaluation of model performance on newly created data, obviating a comparison model. Finally, applying the newly constructed data to the GraphRec model by using their graphical representation significantly improves the system performance.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624003774,https://doi.org/10.1016/j.engappai.2024.108219,science_direct,2024
1269,Enhancing large language model capabilities for rumor detection with Knowledge-Powered Prompting,"@article{YAN2024108259,
title = {Enhancing large language model capabilities for rumor detection with Knowledge-Powered Prompting},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108259},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108259},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624004172},
author = {Yeqing Yan and Peng Zheng and Yongjun Wang},
keywords = {Social networks, Rumor detection, Knowledge augmentation, Prompt tuning, Large language model},
abstract = {Amid the proliferation of misinformation on social networks, automated rumor detection has emerged as a pivotal and pressing research domain. Nonetheless, current methodologies are hindered by constrained feature representations and limited adaptability in effectively addressing diverse and unconventional rumors. The incorporation of large-scale language models holds the promise of delivering heightened semantic comprehension and broader adaptability. Regrettably, prevailing general-purpose prompting approaches frequently fall short in furnishing adequate domain-specific context and guidance, thereby restricting their utility in the context of rumor detection. To ameliorate these concerns, we introduce the Knowledge-Powered Prompting strategy, which imparts task-relevant prompts and context to the model by amalgamating domain expertise with large-scale language models. This fusion equips the model to better align with the exigencies of rumor detection, mitigating the challenges posed by sensitivity to semantic subtleties and a paucity of training samples. In particular, we devise exploration prompts and bolster the prompt representation with a dynamic knowledge injection module, thereby facilitating profound reasoning about pivotal entities. Subsequently, we extract valuable external knowledge through the filtration of interactions between knowledge and claim, thereby diminishing the impact of noise. Concurrently, we undertake joint optimization, encompassing multi-task prompt population and categorical judgment objectives, fostering synergistic semantic modeling and discriminative assessments. Empirical evaluations reveal that our methodology substantially outperforms existing models.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624004172,https://doi.org/10.1016/j.engappai.2024.108259,science_direct,2024
1270,Exploring the adoption of the metaverse and chat generative pre-trained transformer: A single-valued neutrosophic Dombi Bonferroni-based method for the selection of software development strategies,"@article{ONDEN2024108378,
title = {Exploring the adoption of the metaverse and chat generative pre-trained transformer: A single-valued neutrosophic Dombi Bonferroni-based method for the selection of software development strategies},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108378},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108378},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624005360},
author = {Abdullah Önden and Karahan Kara and İsmail Önden and Galip Cihan Yalçın and Vladimir Simic and Dragan Pamucar},
keywords = {Virtual reality, Metaverse, Natural language processing, Single-valued neutrosophic sets, Alternative ranking order method accounting for two-step normalization},
abstract = {The contemporary era has witnessed remarkable developments that seek to transform and reshape traditional software development methodologies. Notably, artificial intelligence (AI) supported software development as well as software development in virtual reality environments have gained considerable prominence. This article introduces software development strategies to examine how software developers and companies respond to this transformation. Also, an advanced decision model is developed using the alternative ranking order method accounting for two-step normalization (AROMAN) method and further analyzed with the single-valued neutrosophic set-based AROMAN technique. The single-valued neutrosophic weighted Dombi Bonferroni operator is employed in the analysis process. This research offers two case studies investigating the preferences of developers and managers in software development strategies. The first case study examines the preferences of developers, while the second focuses on the preferences of managers. In both case studies, three fundamental software development methods are presented. These include the “traditional developers approach”, “AI-supported developers approach”, and “mixed reality and AI-supported developers approach”. These methods are ranked based on expert opinions concerning 10 criteria that influence the software development process. In both case studies, “output quality” is identified as the most influential criterion. From the perspective of software development methods, in both case studies, the “mixed reality and AI-supported developers approach” is identified as the most effective. Recommendations are provided for developers and managers. The findings also have significant implications for guiding developers and managers in making informed decisions and optimizing software development practices to align with the evolving AI and virtual reality landscape.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624005360,https://doi.org/10.1016/j.engappai.2024.108378,science_direct,2024
1271,Prompt-based learning framework for zero-shot cross-lingual text classification,"@article{FENG2024108481,
title = {Prompt-based learning framework for zero-shot cross-lingual text classification},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108481},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108481},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624006390},
author = {Kai Feng and Lan Huang and Kangping Wang and Wei Wei and Rui Zhang},
keywords = {Cross-lingual text classification, Cross-lingual text representation, Prompt learning},
abstract = {Cross-lingual text classification is a challenging task that aims to train classifiers with data in one language, known as the source language, and apply the acquired knowledge to data in another language, referred to as the target language. Recent advancements in multilingual pre-trained language models (PLMs) have made significant progress in addressing cross-lingual issues, and the application of prompt-based learning has further improved task performance. However, these models still face challenges such as the gap between cross-lingual classification tasks and pre-training tasks of PLMs, as well as issues related to scarce resources and data noise, which hinder the full exploitation of the implicit knowledge in PLMs. In this paper, we propose a Prompt-based Cross-lingual Learning (PCL) framework that combines language-agnostic continuous prompt learning with self-learning process. Specifically, PCL framework leverages language-agnostic prompts and PLMs to achieve semantic transfer between source and target languages. To enhance the semantic relationship between prompts and category labels, a label attention module is introduced. Additionally, a set of self-training rules is proposed, which includes a scoring function. In a few-shot setting, noisy data is dynamically filtered through scoring and ranking of the data. During each training iteration, both the model and scoring function weights are updated, further improving the discrimination capability of the model. In summary, the proposed PCL framework builds upon cross-lingual prompt learning, effectively removing noisy data and applying it to zero-shot cross-lingual text classification, which is beneficial for engineering applications. The findings of this study have implications for prompt learning method. The PCL framework achieves state-of-the-art performance in cross-lingual text classification task, with a 14% performance improvement compared to basic soft prompt learning. This demonstrates its potential in addressing classification problems in resource-limited scenarios.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624006390,https://doi.org/10.1016/j.engappai.2024.108481,science_direct,2024
1272,Computer vision tools for early post-disaster assessment: Enhancing generalizability,"@article{SOLEIMANI2024108855,
title = {Computer vision tools for early post-disaster assessment: Enhancing generalizability},
journal = {Engineering Applications of Artificial Intelligence},
volume = {136},
pages = {108855},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108855},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624010133},
author = {Rojiar Soleimani and Mohammad Hesam Soleimani-Babakamali and Shuochuan Meng and Onur Avci and Ertugrul Taciroglu},
keywords = {Natural hazards, Data fusion, Aerial damage assessment, Ensemble learning, Disaster response, Disaster recovery},
abstract = {Remote sensing data, particularly satellite imagery, have made early, post-hazard aerial damage assessment possible due to its fast availability and extensive coverage. Despite breakthroughs in using deep computer vision with satellite image inputs, achieving high generalizability across diverse hazards and locations remains the main obstacle to effectively deploying early assessment tools in real-world scenarios, as the same hazard can manifest differently across various landscapes and urban textures. This challenge may be overlooked when working with curated datasets with minimal (test-to-train) shifts in urban textures and hazard damage features (e.g., due to undersized study regions), leaving models ill-prepared for real-world scenarios. The primary objective of this study was to understand non-trivial generalizability challenges by taking the 2023 Turkiye earthquake and the Maui wildfire incidents as “training” and “unseen test” events that simulated a demanding scenario. Subsequently, strategies such as augmenting image channels with damage proxy maps, data fusion, deep ensemble learning, and Test Time Augmentation were exclusively designed and implemented to address those challenges. These measures significantly improved the damage detection, with or without severity classification, with F1 scores increased from 0.71 to 0.82 and 0.40 to 0.87, respectively. Furthermore, and through data fusion, the proposed framework accommodates estimating socioeconomic loss metrics at the individual building level, supporting both response and recovery phases. This research has the potential to enhance the effectiveness of rapid aerial damage assessment models, ultimately aiding in more efficient and targeted disaster response and recovery efforts. Data, models, and codes are available at https://github.com/TRG-AI4Good/Lahaina_Generalizability.}
}
",https://www.sciencedirect.com/science/article/pii/S0952197624010133,https://doi.org/10.1016/j.engappai.2024.108855,science_direct,2024
1273,HydroRTC: A web-based data transfer and communication library for collaborative data processing and sharing in the hydrological domain,"@article{ERAZORAMIREZ2024106068,
title = {HydroRTC: A web-based data transfer and communication library for collaborative data processing and sharing in the hydrological domain},
journal = {Environmental Modelling & Software},
volume = {178},
pages = {106068},
year = {2024},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2024.106068},
url = {https://www.sciencedirect.com/science/article/pii/S1364815224001294},
author = {Carlos {Erazo Ramirez} and Yusuf Sermet and Muneeb Shahid and Ibrahim Demir},
keywords = {Satellite data, Sensor data, Decentralized data distribution, Collaborative data exchange, Distributed data processing, Large scale peer to peer data sharing, WebRTC, Web sockets, Hydrology},
abstract = {The exponential growth in data generated by satellites, radars, sensors, and analysis and reanalysis from model outputs for the hydrological domain requires efficient real-time data management and distribution mechanisms. This paper introduces HydroRTC, a web-based data transfer and communication library designed to accelerate large-scale data sharing and analysis. Leveraging next-generation web technologies like WebSockets, WebRTC and Node.js, the library enables seamless peer-to-peer sharing, smart data transmission, and large dataset streaming. Three primary scenarios are presented as use cases, demonstrating the potential of HydroRTC as server-to-peer with intelligent data scheduling and large data streaming, peer-to-peer data sharing, and peer-to-server for data exchange. HydroRTC offers a promising solution for collaborative infrastructures in the hydrological and environmental domain, allowing real-time and high-throughput data sharing and transfer for enhancing research efficiency and collaboration capabilities.}
}
",https://www.sciencedirect.com/science/article/pii/S1364815224001294,https://doi.org/10.1016/j.envsoft.2024.106068,science_direct,2024
1274,"ChatGPT for digital forensic investigation: The good, the bad, and the unknown","@article{SCANLON2023301609,
title = {ChatGPT for digital forensic investigation: The good, the bad, and the unknown},
journal = {Forensic Science International: Digital Investigation},
volume = {46},
pages = {301609},
year = {2023},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2023.301609},
url = {https://www.sciencedirect.com/science/article/pii/S266628172300121X},
author = {Mark Scanlon and Frank Breitinger and Christopher Hargreaves and Jan-Niclas Hilgert and John Sheppard},
keywords = {ChatGPT, Digital forensics, Artificial intelligence, Generative pre-trained transformers (GPT), Large language models (LLM)},
abstract = {The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of domains has become a topic of much discussion in the scientific community and society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take instructions, or prompts, from users and generate answers and solutions based on very large volumes of text-based training data. This paper assesses the impact and potential impact of ChatGPT on the field of digital forensics, specifically looking at its latest pre-trained LLM, GPT-4. A series of experiments are conducted to assess its capability across several digital forensic use cases including artefact understanding, evidence searching, code generation, anomaly detection, incident response, and education. Across these topics, its strengths and risks are outlined and a number of general conclusions are drawn. Overall this paper concludes that while there are some potential low-risk applications of ChatGPT within digital forensics, many are either unsuitable at present, since the evidence would need to be uploaded to the service, or they require sufficient knowledge of the topic being asked of the tool to identify incorrect assumptions, inaccuracies, and mistakes. However, to an appropriately knowledgeable user, it could act as a useful supporting tool in some circumstances.}
}
",https://www.sciencedirect.com/science/article/pii/S266628172300121X,https://doi.org/10.1016/j.fsidi.2023.301609,science_direct,2023
1275,DFRWS EU 10-year review and future directions in Digital Forensic Research,"@article{BREITINGER2024301685,
title = {DFRWS EU 10-year review and future directions in Digital Forensic Research},
journal = {Forensic Science International: Digital Investigation},
volume = {48},
pages = {301685},
year = {2024},
note = {DFRWS EU 2024 - Selected Papers from the 11th Annual Digital Forensics Research Conference Europe},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2023.301685},
url = {https://www.sciencedirect.com/science/article/pii/S2666281723002044},
author = {Frank Breitinger and Jan-Niclas Hilgert and Christopher Hargreaves and John Sheppard and Rebekah Overdorf and Mark Scanlon},
keywords = {Digital forensics research, Digital forensic science, DFRWS, Research trends, Future directions},
abstract = {Conducting a systematic literature review and comprehensive analysis, this paper surveys all 135 peer-reviewed articles published at the Digital Forensics Research Conference Europe (DFRWS EU) spanning the decade since its inaugural running (2014–2023). This comprehensive study of DFRWS EU articles encompasses sub-disciplines such as digital forensic science, device forensics, techniques and fundamentals, artefact forensics, multimedia forensics, memory forensics, and network forensics. Quantitative analysis of the articles’ co-authorships, geographical spread and citation metrics are outlined. The analysis presented offers insights into the evolution of digital forensic research efforts over these ten years and informs some identified future research directions.}
}
",https://www.sciencedirect.com/science/article/pii/S2666281723002044,https://doi.org/10.1016/j.fsidi.2023.301685,science_direct,2024
1277,Continuous agile cyber–physical systems architectures based on digital twins,"@article{VODYAHO2024350,
title = {Continuous agile cyber–physical systems architectures based on digital twins},
journal = {Future Generation Computer Systems},
volume = {153},
pages = {350-359},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2023.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X23004326},
author = {Alexander Vodyaho and Nataly Zhukova and Radhakrishnan Delhibabu and Alexey Subbotin},
keywords = {Compute continuum, Digital twin, Digital twin networks, Digital threads, Model synthesis, Continuous architecture, Agile architecture, cyber-physical system},
abstract = {Modern cyber-physical systems, for the most part, are large-scale multilevel heterogeneous distributed systems that integrate subsystems of different kinds and are built on the Internet of Things platforms, where system structure and behavior are not constant. Managing such systems and keeping them in working condition throughout their lifetime is a difficult task. The proposed article discusses one of the possible approaches to solving this problem, based on the use of well-known continuous and agile architecture paradigms. However, there are currently no effective mechanisms for implementing these paradigms. The proposed article suggests a new approach to implementing continuous agile architectures by utilizing digital twins and proposes a reference architecture for a run-time dynamic digital twin. This method is unique because it builds a series of dynamic digital twins that model the system in real time, utilizing data about system events. Build the first models using the models used in earlier stages of the system lifecycle. This gives the following opportunities: i) a way to use dynamic digital twins to implement the continuous agile architecture paradigm; ii) a generalized three-level model of the life cycle of the continuous agile architecture; iii) a reference architecture for dynamic digital twins; and iv) a set of models that are all about using dynamic digital twins. The suggested approach enables the management of heterogeneous multilevel cyber-physical systems with variable structure and behavior variability.}
}
",https://www.sciencedirect.com/science/article/pii/S0167739X23004326,https://doi.org/10.1016/j.future.2023.11.024,science_direct,2024
1278,"Understanding insiders in cloud adopted organizations: A survey on taxonomies, incident analysis, defensive solutions, challenges","@article{S2024427,
title = {Understanding insiders in cloud adopted organizations: A survey on taxonomies, incident analysis, defensive solutions, challenges},
journal = {Future Generation Computer Systems},
volume = {158},
pages = {427-446},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.04.033},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24001614},
author = {Asha S. and Shanmugapriya D.},
keywords = {Insider threat, Malicious insider threat, Masqueraders, Traitors, Unintentional insider threat},
abstract = {In cybersecurity, one of the most significant challenges is an insider threat, in which existing researchers must provide an extensive solution aiming at an enhanced security network. This study proposes a comprehensive taxonomy as well as a state-of-the-art research categorization according to the contribution of insider threat incidents and the defensive mechanism utilized against such insiders. The major objective of a proposed categorization is to provide structural information in the field of insider threat based on past research theories for analyzing literature review. The proposed categorization is classified into four groups: (i) dataset analysis, (ii) incident analysis, (iii) defensive solution, and (iv) encountered challenges. However, the respective taxonomies and annotations are included for complete insight into insiders. i.e., existing studies on systematic taxonomy based on incidents of insider threats are presented. The major contribution of this study in the area of insider threat is to deliver the following knowledge to upcoming domain specific researchers: (i) taxonomy in an innovative systematic approach concerning the categories of incidents and determine the possible defensive mechanism against insiders. (ii) a study on available benchmark datasets used by existing research for evaluating the defensive mechanisms. (iii) a brief description of past solutions and frameworks to model insider behavior with the aim of studying existing defensive mechanisms, and (iv) a short discussion of challenges encountered by defensive solutions based on existing research in the area of insider threat.}
}
",https://www.sciencedirect.com/science/article/pii/S0167739X24001614,https://doi.org/10.1016/j.future.2024.04.033,science_direct,2024
1279,Estimation of realized volatility of cryptocurrencies using CEEMDAN-RF-LSTM,"@article{WANG2024219,
title = {Estimation of realized volatility of cryptocurrencies using CEEMDAN-RF-LSTM},
journal = {Future Generation Computer Systems},
volume = {158},
pages = {219-229},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.04.043},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24001729},
author = {Huiqing Wang and Yongrong Huang and Zhide Chen and Xu Yang and Xun Yi and Hai Dong and Xuechao Yang},
keywords = {CEEMDAN, Random forest, LSTM, Cryptocurrency, Realized volatility},
abstract = {Predicting cryptocurrency volatility is crucial for investors, traders, and decision-makers but is complicated by the market’s high non-linearity, volatility, and noise. This paper presents a novel approach, the CEEMDAN-RF-LSTM hybrid model, which is the first to combine the strengths of Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN), Random Forest (RF), and Long Short-Term Memory Network (LSTM) to predict the Realized Volatility (RV) of mainstream cryptocurrencies. The model exploits CEEMDAN’s proficiency in processing non-linear and non-stationary signals, RF’s exceptional feature selection capabilities, and LSTM’s distinctive advantages in dealing with time-series problems. Applied to actual transaction data for Bitcoin (BTC), Ethereum (ETH), and Binance Coin (BNB), empirical results show the superior performance of our model in predicting actual cryptocurrency volatility. These findings contribute to the academic understanding of cryptocurrency volatility and provide practical guidance for quantitative trading strategy development, offering fresh insights and methodologies for related research fields.}
}
",https://www.sciencedirect.com/science/article/pii/S0167739X24001729,https://doi.org/10.1016/j.future.2024.04.043,science_direct,2024
1280,Batched sparse and mixed-precision linear algebra interface for efficient use of GPU hardware accelerators in scientific applications,"@article{LUSZCZEK2024359,
title = {Batched sparse and mixed-precision linear algebra interface for efficient use of GPU hardware accelerators in scientific applications},
journal = {Future Generation Computer Systems},
volume = {160},
pages = {359-374},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24003017},
author = {Piotr Luszczek and Ahmad Abdelfattah and Hartwig Anzt and Atsushi Suzuki and Stanimire Tomov},
keywords = {Batched computations, Numerical linear algebra, BLAS, Hardware accelerators, Mixed-precision computing},
abstract = {Batched Sparse Linear Algebra has become an emergent processing mode on modern hardware accelerators based on Graphics Processing Units (GPUs) developed over the years to serve as the main compute devices in the largest computing clusters and supercomputers. We propose a set solver interface designs for batched sparse numerical solvers on these hardware accelerators. We motivate our specific designs by both their use in scientific applications of national importance and also by the possibility of implementing them in an efficient and portable manner with multiple options for vendor-specific optimizations. We present the C language interface calls for the linker-agnostic interchange of functional entry points. We also show how using C++ for the batched solvers simplifies the interface design while giving the user much broader set of opportunities for customization, testing, and debugging. We also cover in our proposals the option of exploiting multiple floating-point arithmetic precisions to directly match the application needs in terms of accuracy. Finally, a selected sample of performance experiments show how our proposed interface can be efficiently implemented to outperform the available alternatives many times over. In the end, we plan for an ongoing evolution of our newly proposed interface standard to keep up with the updates in programming languages, accelerator hardware, and application needs.}
}
",https://www.sciencedirect.com/science/article/pii/S0167739X24003017,https://doi.org/10.1016/j.future.2024.06.004,science_direct,2024
1281,European AI and EO convergence via a novel community-driven framework for data-intensive innovation,"@article{TROUMPOUKIS2024505,
title = {European AI and EO convergence via a novel community-driven framework for data-intensive innovation},
journal = {Future Generation Computer Systems},
volume = {160},
pages = {505-521},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24003133},
author = {Antonis Troumpoukis and Iraklis Klampanos and Despina-Athanasia Pantazi and Mohanad Albughdadi and Vasileios Baousis and Omar Barrilero and Alexandra Bojor and Pedro Branco and Lorenzo Bruzzone and Andreina Chietera and Philippe Fournand and Richard Hall and Michele Lazzarini and Adrian Luna and Alexandros Nousias and Christos Perentis and George Petrakis and Dharmen Punjani and David Röbl and George Stamoulis and Eleni Tsalapati and Indrė Urbanavičiūtė and Giulio Weikmann and Xenia Ziouvelou and Marcin Ziółkowski and Manolis Koubarakis and Vangelis Karkaletsis},
keywords = {Artificial Intelligence, Earth observation, DIAS, Applications, Case-study, Methodology, Platform},
abstract = {Artificial Intelligence (AI) represents a collection of tools and methodologies that have the potential to revolutionise various aspects of human activity. Earth observation (EO) data, including satellite and in-situ, are essential in a number of high impact applications, ranging from security and energy to agriculture and health. In this paper, we present the AI4Copernicus framework for bridging the two domains within the European context to enable data-centred innovation. In order to achieve this goal, AI4Copernicus has developed and enriches the European AI-on-demand platform with a number of application bootstrapping services and tools to accelerate uptake and innovation, whilst it provides integration over AI-on-Demand services and the Copernicus ecosystem, targeting the highly successful Data and Information Access Service (DIAS) Cloud platforms. More specifically, by employing procedures for onboarding and validating models and tools, and by utilising a host of meticulously reviewed and supervised open calls-enabled projects, and containerisation best-practices, AI4Copernicus deployed and made available several products on DIAS platforms. Moreover, these products and resources have been made available on the AI-on-Demand platform catalogue for discovery, use and further development. The AI4Copernicus framework is being used by a number of business-driven projects and SMEs spanning several application domains. This article provides an overview of the European AI and EO context as well as the AI4Copernicus technological framework and tools offered. Further, we present real world use-cases as well as a community-centred evaluation of our framework based on usage and feedback received from several projects.}
}
",https://www.sciencedirect.com/science/article/pii/S0167739X24003133,https://doi.org/10.1016/j.future.2024.06.013,science_direct,2024
1282,"A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly","@article{YAO2024100211,
title = {A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly},
journal = {High-Confidence Computing},
volume = {4},
number = {2},
pages = {100211},
year = {2024},
issn = {2667-2952},
doi = {https://doi.org/10.1016/j.hcc.2024.100211},
url = {https://www.sciencedirect.com/science/article/pii/S266729522400014X},
author = {Yifan Yao and Jinhao Duan and Kaidi Xu and Yuanfang Cai and Zhibo Sun and Yue Zhang},
keywords = {Large Language Model (LLM), LLM security, LLM privacy, ChatGPT, LLM attacks, LLM vulnerabilities},
abstract = {Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into “The Good” (beneficial LLM applications), “The Bad” (offensive applications), and “The Ugly” (vulnerabilities of LLMs and their defenses). We have some interesting findings. For example, LLMs have proven to enhance code security (code vulnerability detection) and data privacy (data confidentiality protection), outperforming traditional methods. However, they can also be harnessed for various attacks (particularly user-level attacks) due to their human-like reasoning abilities. We have identified areas that require further research efforts. For example, Research on model and parameter extraction attacks is limited and often theoretical, hindered by LLM parameter scale and confidentiality. Safe instruction tuning, a recent development, requires more exploration. We hope that our work can shed light on the LLMs’ potential to both bolster and jeopardize cybersecurity.}
}
",https://www.sciencedirect.com/science/article/pii/S266729522400014X,https://doi.org/10.1016/j.hcc.2024.100211,science_direct,2024
1283,"Performance and exploration of ChatGPT in medical examination, records and education in Chinese: Pave the way for medical AI","@article{WANG2023105173,
title = {Performance and exploration of ChatGPT in medical examination, records and education in Chinese: Pave the way for medical AI},
journal = {International Journal of Medical Informatics},
volume = {177},
pages = {105173},
year = {2023},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105173},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623001910},
author = {Hongyan Wang and WeiZhen Wu and Zhi Dou and Liangliang He and Liqiang Yang},
abstract = {Background
Although chat generative pre-trained transformer (ChatGPT) has made several successful attempts in the medical field, most notably in answering medical questions in English, no studies have evaluated ChatGPT's performance in a Chinese context for a medical task.
Objective
The aim of this study was to evaluate ChatGPT’s ability to understand medical knowledge in Chinese, as well as its potential to serve as an electronic health infrastructure for medical development, by evaluating its performance in medical examinations, records, and education.
Method
The Chinese (CNMLE) and English (ENMLE) datasets of the China National Medical Licensing Examination and the Chinese dataset (NEEPM) of the China National Entrance Examination for Postgraduate Clinical Medicine Comprehensive Ability were used to evaluate the performance of ChatGPT (GPT-3.5 and GPT-4). We assessed answer accuracy, verbal fluency, and the classification of incorrect responses owing to hallucinations on multiple occasions. In addition, we tested ChatGPT's performance on discharge summaries and group learning in a Chinese context on a small scale.
Results
The accuracy of GPT-3.5 in CNMLE, ENMLE, and NEEPM was 56% (56/100), 76% (76/100), and 62% (62/100), respectively, compared to that of GPT-4, which was of 84% (84/100), 86% (86/100), and 82% (82/100). The verbal fluency of all the ChatGPT responses exceeded 95%. Among the GPT-3.5 incorrect responses, the proportions of open-domain hallucinations were 66 % (29/44), 54 % (14/24), and 63 % (24/38), whereas close-domain hallucinations accounted for 34 % (15/44), 46 % (14/24), and 37 % (14/38), respectively. By contrast, GPT-4 open-domain hallucinations accounted for 56% (9/16), 43% (6/14), and 83% (15/18), while close-domain hallucinations accounted for 44% (7/16), 57% (8/14), and 17% (3/18), respectively. In the discharge summary, ChatGPT demonstrated logical coherence, however GPT-3.5 could not fulfill the quality requirements, while GPT-4 met the qualification of 60% (6/10). In group learning, the verbal fluency and interaction satisfaction with ChatGPT were 100% (10/10).
Conclusion
ChatGPT based on GPT-4 is at par with Chinese medical practitioners who passed the CNMLE and at the standard required for admission to clinical medical graduate programs in China. The GPT-4 shows promising potential for discharge summarization and group learning. Additionally, it shows high verbal fluency, resulting in a positive human–computer interaction experience. GPT-4 significantly improves multiple capabilities and reduces hallucinations compared to the previous GPT-3.5 model, with a particular leap forward in the Chinese comprehension capability of medical tasks. Artificial intelligence (AI) systems face the challenges of hallucinations, legal risks, and ethical issues. However, we discovered ChatGPT's potential to promote medical development as an electronic health infrastructure, paving the way for Medical AI to become necessary.}
}
",https://www.sciencedirect.com/science/article/pii/S1386505623001910,https://doi.org/10.1016/j.ijmedinf.2023.105173,science_direct,2023
1284,"Generative artificial intelligence in healthcare: A scoping review on benefits, challenges and applications","@article{MOULAEI2024105474,
title = {Generative artificial intelligence in healthcare: A scoping review on benefits, challenges and applications},
journal = {International Journal of Medical Informatics},
volume = {188},
pages = {105474},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105474},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001370},
author = {Khadijeh Moulaei and Atiye Yadegari and Mahdi Baharestani and Shayan Farzanbakhsh and Babak Sabet and Mohammad {Reza Afrash}},
keywords = {Generative artificial intelligence, Health, Artificial intelligence},
abstract = {Background
Generative artificial intelligence (GAI) is revolutionizing healthcare with solutions for complex challenges, enhancing diagnosis, treatment, and care through new data and insights. However, its integration raises questions about applications, benefits, and challenges. Our study explores these aspects, offering an overview of GAI's applications and future prospects in healthcare.
Methods
This scoping review searched Web of Science, PubMed, and Scopus . The selection of studies involved screening titles, reviewing abstracts, and examining full texts, adhering to the PRISMA-ScR guidelines throughout the process.
Results
From 1406 articles across three databases, 109 met inclusion criteria after screening and deduplication. Nine GAI models were utilized in healthcare, with ChatGPT (n = 102, 74 %), Google Bard (Gemini) (n = 16, 11 %), and Microsoft Bing AI (n = 10, 7 %) being the most frequently employed. A total of 24 different applications of GAI in healthcare were identified, with the most common being “offering insights and information on health conditions through answering questions” (n = 41) and “diagnosis and prediction of diseases” (n = 17). In total, 606 benefits and challenges were identified, which were condensed to 48 benefits and 61 challenges after consolidation. The predominant benefits included “Providing rapid access to information and valuable insights” and “Improving prediction and diagnosis accuracy”, while the primary challenges comprised “generating inaccurate or fictional content”, “unknown source of information and fake references for texts”, and “lower accuracy in answering questions”.
Conclusion
This scoping review identified the applications, benefits, and challenges of GAI in healthcare. This synthesis offers a crucial overview of GAI's potential to revolutionize healthcare, emphasizing the imperative to address its limitations.}
}
",https://www.sciencedirect.com/science/article/pii/S1386505624001370,https://doi.org/10.1016/j.ijmedinf.2024.105474,science_direct,2024
1285,Have we found a solution for health misinformation? A ten-year systematic review of health misinformation literature 2013–2022,"@article{ZHANG2024105478,
title = {Have we found a solution for health misinformation? A ten-year systematic review of health misinformation literature 2013–2022},
journal = {International Journal of Medical Informatics},
volume = {188},
pages = {105478},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105478},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001412},
author = {Shiyi Zhang and Huiyu Zhou and Yimei Zhu},
keywords = {Misinformation, Health misinformation, Trust, Solutions to health misinformation},
abstract = {Background
Health misinformation (HM) has emerged as a prominent social issue in recent years, driven by declining public trust, popularisation of digital media platforms and escalating public health crisis. Since the Covid-19 pandemic, HM has raised critical concerns due to its significant impacts on both individuals and society as a whole. A comprehensive understanding of HM and HM-related studies would be instrumental in identifying possible solutions to address HM and the associated challenges.
Methods
Following the PRISMA procedure, 11,739 papers published from January 2013 to December 2022 were retrieved from five electronic databases, and 813 papers matching the inclusion criteria were retained for further analysis. This article critically reviewed HM-related studies, detailing the factors facilitating HM creation and dissemination, negative impacts of HM, solutions to HM, and research methods employed in those studies.
Results
A growing number of studies have focused on HM since 2013. Results of this study highlight that trust plays a significant while latent role in the circuits of HM, facilitating the creation and dissemination of HM, exacerbating the negative impacts of HM and amplifying the difficulty in addressing HM.
Conclusion
For health authorities and governmental institutions, it is essential to systematically build public trust in order to reduce the probability of individuals acceptation of HM and to improve the effectiveness of misinformation correction. Future studies should pay more attention to the role of trust in how to address HM.}
}
",https://www.sciencedirect.com/science/article/pii/S1386505624001412,https://doi.org/10.1016/j.ijmedinf.2024.105478,science_direct,2024
1286,Ethics-based AI auditing: A systematic literature review on conceptualizations of ethical principles and knowledge contributions to stakeholders,"@article{LAINE2024103969,
title = {Ethics-based AI auditing: A systematic literature review on conceptualizations of ethical principles and knowledge contributions to stakeholders},
journal = {Information & Management},
volume = {61},
number = {5},
pages = {103969},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.103969},
url = {https://www.sciencedirect.com/science/article/pii/S037872062400051X},
author = {Joakim Laine and Matti Minkkinen and Matti Mäntymäki},
keywords = {Artificial intelligence, Auditing, AI ethics, AI governance, AI auditing, Ethics-based AI auditing, Systematic literature review},
abstract = {This systematic literature review synthesizes the conceptualizations of ethical principles in AI auditing literature and the knowledge contributions to the stakeholders of AI auditing. We explain how the literature discusses fairness, transparency, non-maleficence, responsibility, privacy, trust, beneficence, and freedom/autonomy. Conceptualizations vary along social/technical- and process/outcome-oriented dimensions. The main stakeholders of ethics-based AI auditing are system developers and deployers, the wider public, researchers, auditors, AI system users, and regulators. AI auditing provides three types of knowledge contributions to stakeholders: 1) guidance; 2) methods, tools, and frameworks; and 3) awareness and empowerment.}
}
",https://www.sciencedirect.com/science/article/pii/S037872062400051X,https://doi.org/10.1016/j.im.2024.103969,science_direct,2024
1287,Market Value and Environmental Performance of Carbon Management Systems: An International Investigation,"@article{RUSH2024103997,
title = {Market Value and Environmental Performance of Carbon Management Systems: An International Investigation},
journal = {Information & Management},
pages = {103997},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.103997},
url = {https://www.sciencedirect.com/science/article/pii/S037872062400079X},
author = {Daniel E. Rush and Nigel P. Melville and Christie M Fuller},
keywords = {Business value, Carbon management, Event study, Green IS, Green IT, Greenhouse gas emissions, International research},
abstract = {This study examines the financial and environmental effects of carbon management systems (CMSs) used in publicly traded companies worldwide. Market reactions to companies that announce the adoption of a CMS are analyzed, as are changes in greenhouse gas (GHG) emissions for CMS adopters. A method for conducting international event studies is introduced, and a Monte Carlo simulation indicates that such a method may be necessary to avoid bias. Empirical results suggest that CMS adoption announcements might not generate positive abnormal returns across a variety of specifications. In contrast, estimation results suggest that adoption of a CMS may mitigate increases in GHG emissions.}
}
",https://www.sciencedirect.com/science/article/pii/S037872062400079X,https://doi.org/10.1016/j.im.2024.103997,science_direct,2024
1288,Generative pretrained transformer 4: an innovative approach to facilitate value-based healthcare,"@article{LYU202410,
title = {Generative pretrained transformer 4: an innovative approach to facilitate value-based healthcare},
journal = {Intelligent Medicine},
volume = {4},
number = {1},
pages = {10-15},
year = {2024},
issn = {2667-1026},
doi = {https://doi.org/10.1016/j.imed.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667102623000608},
author = {Han Lyu and Zhixiang Wang and Jia Li and Jing Sun and Xinghao Wang and Pengling Ren and Linkun Cai and Zhenchang Wang and Max Wintermark},
keywords = {Generative pretrained transformer 4 model, Natural language processing, Medical imaging, Appropriateness},
abstract = {Objective
Appropriate medical imaging is important for value-based care. We aim to evaluate the performance of generative pretrained transformer 4 (GPT-4), an innovative natural language processing model, providing appropriate medical imaging automatically in different clinical scenarios.
Methods
Institutional Review Boards (IRB) approval was not required due to the use of nonidentifiable data. Instead, we used 112 questions from the American College of Radiology (ACR) Radiology-TEACHES Program as prompts, which is an open-sourced question and answer program to guide appropriate medical imaging. We included 69 free-text case vignettes and 43 simplified cases. For the performance evaluation of GPT-4 and GPT-3.5, we considered the recommendations of ACR guidelines as the gold standard, and then three radiologists analyzed the consistency of the responses from the GPT models with those of the ACR. We set a five-score criterion for the evaluation of the consistency. A paired t-test was applied to assess the statistical significance of the findings.
Results
For the performance of the GPT models in free-text case vignettes, the accuracy of GPT-4 was 92.9%, whereas the accuracy of GPT-3.5 was just 78.3%. GPT-4 can provide more appropriate suggestions to reduce the overutilization of medical imaging than GPT-3.5 (t = 3.429, P = 0.001). For the performance of the GPT models in simplified scenarios, the accuracy of GPT-4 and GPT-3.5 was 66.5% and 60.0%, respectively. The differences were not statistically significant (t = 1.858, P = 0.070). GPT-4 was characterized by longer reaction times (27.1 s in average) and extensive responses (137.1 words on average) than GPT-3.5.
Conclusion
As an advanced tool for improving value-based healthcare in clinics, GPT-4 may guide appropriate medical imaging accurately and efficiently.}
}
",https://www.sciencedirect.com/science/article/pii/S2667102623000608,https://doi.org/10.1016/j.imed.2023.09.001,science_direct,2024
1289,Application of ChatGPT in multilingual medical education: How does ChatGPT fare in 2023's Iranian residency entrance examination,"@article{KHORSHIDI2023101314,
title = {Application of ChatGPT in multilingual medical education: How does ChatGPT fare in 2023's Iranian residency entrance examination},
journal = {Informatics in Medicine Unlocked},
volume = {41},
pages = {101314},
year = {2023},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2023.101314},
url = {https://www.sciencedirect.com/science/article/pii/S2352914823001600},
author = {Hamid Khorshidi and Afshin Mohammadi and David M. Yousem and Jamileh Abolghasemi and Golnoosh Ansari and Mohammad Mirza-Aghazadeh-Attari and U Rajendra Acharya and Ali {Abbasian Ardakani}},
keywords = {ChatGPT, USMLE, Medical education, Language model},
abstract = {Background
ChatGPT is a large language model (LLM) artificial intelligence instrument trained on massive amounts of text data extracted from the internet and/or user input. In the present article, we aim to apply the latest version of ChatGPT to the Iranian Medical Residency Examination.
Methods
The Iranian Medical Residency Examination is composed of 200 multichoice questions covering all domains of medicine. We used ChatGPT to translate questions into English, French, and Spanish. We fed the questions as multiple-choice questions and allowed ChatGPT to provide comprehensive answers and justifications for its choices.
Results
ChatGPT was able to answer 161 (81.3% = 161/198) questions correctly when the Persian language was used. When the questions were translated into English, French, and Spanish, ChatGPT answered six, one, and five additional questions correctly, respectively. When comparing the different languages, there was no significant difference in the functioning of ChatGPT in different languages using either the McNemar test or the Binomial test.
Conclusion
ChatGPT can deliver above-average performance in the Iranian Medical Residency Examination, demonstrating its potential for using language models in medicine.}
}
",https://www.sciencedirect.com/science/article/pii/S2352914823001600,https://doi.org/10.1016/j.imu.2023.101314,science_direct,2023
1290,Detecting ChatGPT in published documents: Chatbot catchphrases and buzzwords,"@article{CIACCIO2024101516,
title = {Detecting ChatGPT in published documents: Chatbot catchphrases and buzzwords},
journal = {Informatics in Medicine Unlocked},
pages = {101516},
year = {2024},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2024.101516},
url = {https://www.sciencedirect.com/science/article/pii/S2352914824000728},
author = {Edward J. Ciaccio},
keywords = {artificial intelligence, chatbot, ChatGPT, detection, GPTZero},
abstract = {Background
Nowadays, chatbot-written text can be present in academic documents, even without attribution. Development of an accurate manual screening paradigm would be helpful.
Method
In a series of four test manuscripts suspected of containing chatbot-written text, N=93 peculiar catchphrases were highlighted, and Google Search was used to find articles with each catchphrase. Paragraphs with the catchphrase in recent documents were checked for chatbot origin using the GPTZero detector. For paragraphs confirmed by GPTZero as likely to be chatbot-associated, the following statistics were recorded (N=50): the number of articles published with each catchphrase paragraph for time periods 2012-2014, 2015-2017, 2020-2022 (after GPT introduction), and 2023-March 2024 (after ChatGPT introduction), the citations per article, the publishing journal Impact Factor, and the document section in which the chatbot phrase appeared.
Results
N=86/93 suspected peculiar phrasings had paragraphs with chatbot association by GPTZero (92.5%). The mean number of published articles containing a chatbot-associated paragraph was 21.7 for 2012-2014, 25.6 for 2015-2017, and 43.2 for 2020-2022 versus 67.2 for 2023- March 2024 (p = 0.004). 75% of chatbot-containing articles studied were published in Impact Factor journals. The mean journal Impact Factor was 4.99, with some articles published in Impact Factor 10+ journals. Chatbot phrasing was commonly found in Abstracts and Introductions, but also in Methods, Results/Discussion, Limitations, and Conclusions.
Conclusions
Chatbot content often has peculiar phrasing that typically appears in other chatbot-associated documents as well. It is possible to manually detect odd chatbot phrasings. Chatbot content is increasing, and is present in top journals.}
}
",https://www.sciencedirect.com/science/article/pii/S2352914824000728,https://doi.org/10.1016/j.imu.2024.101516,science_direct,2024
1291,"ChatGPT: Jack of all trades, master of none","@article{KOCON2023101861,
title = {ChatGPT: Jack of all trades, master of none},
journal = {Information Fusion},
volume = {99},
pages = {101861},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101861},
url = {https://www.sciencedirect.com/science/article/pii/S156625352300177X},
author = {Jan Kocoń and Igor Cichecki and Oliwier Kaszyca and Mateusz Kochanek and Dominika Szydło and Joanna Baran and Julita Bielaniewicz and Marcin Gruza and Arkadiusz Janz and Kamil Kanclerz and Anna Kocoń and Bartłomiej Koptyra and Wiktoria Mieleszczenko-Kowszewicz and Piotr Miłkowski and Marcin Oleksy and Maciej Piasecki and Łukasz Radliński and Konrad Wojtasik and Stanisław Woźniak and Przemysław Kazienko},
keywords = {ChatGPT, GPT-4, Natural language processing (NLP), Semantic NLP tasks, Pragmatic NLP tasks, Subjective NLP tasks, Natural language inference (NLI), Sentiment analysis, Offensive content, Emotion recognition, Humor detection, Stance detection, Word sense disambiguation (WSD), Question answering (QA), Model personalization, Text classification, SOTA analysis, Large language model, Prompting},
abstract = {OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT’s capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few-shot evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower than for ChatGPT. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability to personalize ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool’s usefulness to society and how the learning and validation procedures for such systems should be established.}
}
",https://www.sciencedirect.com/science/article/pii/S156625352300177X,https://doi.org/10.1016/j.inffus.2023.101861,science_direct,2023
1292,A review of deep learning techniques for speech processing,"@article{MEHRISH2023101869,
title = {A review of deep learning techniques for speech processing},
journal = {Information Fusion},
volume = {99},
pages = {101869},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101869},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523001859},
author = {Ambuj Mehrish and Navonil Majumder and Rishabh Bharadwaj and Rada Mihalcea and Soujanya Poria},
keywords = {Deep learning, Speech processing, Transformers, Survey, Trends},
abstract = {The field of speech processing has undergone a transformative shift with the advent of deep learning. The use of multiple processing layers has enabled the creation of models capable of extracting intricate features from speech data. This development has paved the way for unparalleled advancements in speech recognition, text-to-speech synthesis, automatic speech recognition, and emotion recognition, propelling the performance of these tasks to unprecedented heights. The power of deep learning techniques has opened up new avenues for research and innovation in the field of speech processing, with far-reaching implications for a range of industries and applications. This review paper provides a comprehensive overview of the key deep learning models and their applications in speech-processing tasks. We begin by tracing the evolution of speech processing research, from early approaches, such as MFCC and HMM, to more recent advances in deep learning architectures, such as CNNs, RNNs, transformers, conformers, and diffusion models. We categorize the approaches and compare their strengths and weaknesses for solving speech-processing tasks. Furthermore, we extensively cover various speech-processing tasks, datasets, and benchmarks used in the literature and describe how different deep-learning networks have been utilized to tackle these tasks. Additionally, we discuss the challenges and future directions of deep learning in speech processing, including the need for more parameter-efficient, interpretable models and the potential of deep learning for multimodal speech processing. By examining the field’s evolution, comparing and contrasting different approaches, and highlighting future directions and challenges, we hope to inspire further research in this exciting and rapidly advancing field.}
}
",https://www.sciencedirect.com/science/article/pii/S1566253523001859,https://doi.org/10.1016/j.inffus.2023.101869,science_direct,2023
1293,"Connecting the dots in trustworthy Artificial Intelligence: From AI principles, ethics, and key requirements to responsible AI systems and regulation","@article{DIAZRODRIGUEZ2023101896,
title = {Connecting the dots in trustworthy Artificial Intelligence: From AI principles, ethics, and key requirements to responsible AI systems and regulation},
journal = {Information Fusion},
volume = {99},
pages = {101896},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101896},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523002129},
author = {Natalia Díaz-Rodríguez and Javier {Del Ser} and Mark Coeckelbergh and Marcos {López de Prado} and Enrique Herrera-Viedma and Francisco Herrera},
keywords = {Trustworthy AI, AI ethics, Responsible AI systems, AI regulation, Regulatory sandbox},
abstract = {Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system’s entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system’s life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple perspective: What each requirement for trustworthy AI is, Why it is needed, and How each requirement can be implemented in practice. On the other hand, a practical approach to implement trustworthy AI systems allows defining the concept of responsibility of AI-based systems facing the law, through a given auditing process. Therefore, a responsible AI system is the resulting notion we introduce in this work, and a concept of utmost necessity that can be realized through auditing processes, subject to the challenges posed by the use of regulatory sandboxes. Our multidisciplinary vision of trustworthy AI culminates in a debate on the diverging views published lately about the future of AI. Our reflections in this matter conclude that regulation is a key for reaching a consensus among these views, and that trustworthy and responsible AI systems will be crucial for the present and future of our society.}
}
",https://www.sciencedirect.com/science/article/pii/S1566253523002129,https://doi.org/10.1016/j.inffus.2023.101896,science_direct,2023
1294,A pre-trained multi-representation fusion network for molecular property prediction,"@article{ZHANG2024102092,
title = {A pre-trained multi-representation fusion network for molecular property prediction},
journal = {Information Fusion},
volume = {103},
pages = {102092},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102092},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523004086},
author = {Haohui Zhang and Juntong Wu and Shichao Liu and Shen Han},
keywords = {Molecular property prediction, Graph neural networks, Multi-modal fusion, Unsupervised pre-training},
abstract = {In the field of machine learning and cheminformatics, the prediction of molecular properties holds significant importance. Molecules can be represented in various formats, including 1D SMILES string, 2D graph, and 3D conformation. Numerous models have been proposed for different representations to accomplish molecular property prediction. However, most recent works have focused on one or two representations or combining embedding vectors from different perspectives in an unsophisticated manner. To address this issue, we present PremuNet, a novel pre-trained multi-representation fusion network for molecular property prediction. PremuNet can extract comprehensive molecular information from multiple views and combine them interactively through pre-training and fine-tuning. The framework of PremuNet consists of two branches: a Transformer-GNN branch that extracts SMILES and graph information, and a Fusion Net branch that extracts topology and geometry information, called PremuNet-L and PremuNet-H respectively. We employ masked self-supervised methods to enable the model to learn information fusion and achieve enhanced performance in downstream tasks. The proposed model has been evaluated on eight molecular property prediction tasks, including five classification and three regression tasks, and attained state-of-the-art performance in most cases. Additionally, we conduct the ablation studies to demonstrate the effect of each view and the branch combination approaches.}
}
",https://www.sciencedirect.com/science/article/pii/S1566253523004086,https://doi.org/10.1016/j.inffus.2023.102092,science_direct,2024
1295,"From image to language: A critical analysis of Visual Question Answering (VQA) approaches, challenges, and opportunities","@article{ISHMAM2024102270,
title = {From image to language: A critical analysis of Visual Question Answering (VQA) approaches, challenges, and opportunities},
journal = {Information Fusion},
volume = {106},
pages = {102270},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102270},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524000484},
author = {Md. Farhan Ishmam and Md. Sakib Hossain Shovon and M.F. Mridha and Nilanjan Dey},
keywords = {Visual Question Answering, Vision language pre-training, Multimodal learning, Multimodal large language models},
abstract = {The multimodal task of Visual Question Answering (VQA) encompassing elements of Computer Vision (CV) and Natural Language Processing (NLP), aims to generate answers to questions on any visual input. Over time, the scope of VQA has expanded from datasets focusing on an extensive collection of natural images to datasets featuring synthetic images, video, 3D environments, and various other visual inputs. The emergence of large pre-trained networks has shifted the early VQA approaches relying on feature extraction and fusion schemes to vision language pre-training (VLP) techniques. However, there is a lack of comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods. Furthermore, the VLP challenges in the lens of VQA haven’t been thoroughly explored, leaving room for potential open problems to emerge. Our work presents a survey in the domain of VQA that delves into the intricacies of VQA datasets and methods over the field’s history, introduces a detailed taxonomy to categorize the facets of VQA, and highlights the recent trends, challenges, and scopes for improvement. We further generalize VQA to multimodal question answering, explore tasks related to VQA, and present a set of open problems for future investigation. The work aims to navigate both beginners and experts by shedding light on the potential avenues of research and expanding the boundaries of the field.}
}
",https://www.sciencedirect.com/science/article/pii/S1566253524000484,https://doi.org/10.1016/j.inffus.2024.102270,science_direct,2024
1296,GPT-4V with emotion: A zero-shot benchmark for Generalized Emotion Recognition,"@article{LIAN2024102367,
title = {GPT-4V with emotion: A zero-shot benchmark for Generalized Emotion Recognition},
journal = {Information Fusion},
volume = {108},
pages = {102367},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102367},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524001453},
author = {Zheng Lian and Licai Sun and Haiyang Sun and Kang Chen and Zhuofan Wen and Hao Gu and Bin Liu and Jianhua Tao},
keywords = {Generalized Emotion Recognition (GER), GPT-4 with Vision (GPT-4V), Zero-shot benchmark, Multimodal fusion, Temporal modeling},
abstract = {Recently, GPT-4 with Vision (GPT-4V) has demonstrated remarkable visual capabilities across various tasks, but its performance in emotion recognition has not been fully evaluated. To bridge this gap, we present the quantitative evaluation results of GPT-4V on 21 benchmark datasets covering 6 tasks: visual sentiment analysis, tweet sentiment analysis, micro-expression recognition, facial emotion recognition, dynamic facial emotion recognition, and multimodal emotion recognition. This paper collectively refers to these tasks as “Generalized Emotion Recognition (GER)”. Through experimental analysis, we observe that GPT-4V exhibits strong visual understanding capabilities in GER tasks. Meanwhile, GPT-4V shows the ability to integrate multimodal clues and exploit temporal information, which is also critical for emotion recognition. However, it is worth noting that GPT-4V is primarily designed for general domains and cannot recognize micro-expressions that require specialized knowledge. To the best of our knowledge, this paper provides the first quantitative assessment of GPT-4V for GER tasks. We have open-sourced the code and encourage subsequent researchers to broaden the evaluation scope by including more tasks and datasets. Our code and evaluation results are available at: https://github.com/zeroQiaoba/gpt4v-emotion.}
}
",https://www.sciencedirect.com/science/article/pii/S1566253524001453,https://doi.org/10.1016/j.inffus.2024.102367,science_direct,2024
1297,"A comprehensive survey of research towards AI-enabled unmanned aerial systems in pre-, active-, and post-wildfire management","@article{BOROUJENI2024102369,
title = {A comprehensive survey of research towards AI-enabled unmanned aerial systems in pre-, active-, and post-wildfire management},
journal = {Information Fusion},
volume = {108},
pages = {102369},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102369},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524001477},
author = {Sayed Pedram Haeri Boroujeni and Abolfazl Razi and Sahand Khoshdel and Fatemeh Afghah and Janice L. Coen and Leo O’Neill and Peter Fule and Adam Watts and Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis},
keywords = {Wildfire management, Artificial intelligence (AI), Unmanned aerial vehicle (UAV), Machine learning, Deep learning (DL), Reinforcement learning (RL), Computer vision},
abstract = {Wildfires have emerged as one of the most destructive natural disasters worldwide, causing catastrophic losses. These losses have underscored the urgent need to improve public knowledge and advance existing techniques in wildfire management. Recently, the use of Artificial Intelligence (AI) in wildfires, propelled by the integration of Unmanned Aerial Vehicles (UAVs) and deep learning models, has created an unprecedented momentum to implement and develop more effective wildfire management. Although existing survey papers have explored learning-based approaches in wildfire, drone use in disaster management, and wildfire risk assessment, a comprehensive review emphasizing the application of AI-enabled UAV systems and investigating the role of learning-based methods throughout the overall workflow of multi-stage wildfire management, including pre-fire (e.g., vision-based vegetation fuel measurement), active-fire (e.g., fire growth modeling), and post-fire tasks (e.g., evacuation planning) is notably lacking. This survey synthesizes and integrates state-of-the-science reviews and research at the nexus of wildfire observations and modeling, AI, and UAVs — topics at the forefront of advances in wildfire management, elucidating the role of AI in performing monitoring and actuation tasks from pre-fire, through the active-fire stage, to post-fire management. To this aim, we provide an extensive analysis of the existing remote sensing systems with a particular focus on the UAV advancements, device specifications, and sensor technologies relevant to wildfire management. We also examine the pre-fire and post-fire management approaches, including fuel monitoring, prevention strategies, as well as evacuation planning, damage assessment, and operation strategies. Additionally, we review and summarize a wide range of computer vision techniques in active-fire management, with an emphasis on Machine Learning (ML), Reinforcement Learning (RL), and Deep Learning (DL) algorithms for wildfire classification, segmentation, detection, and monitoring tasks. Ultimately, we underscore the substantial advancement in wildfire modeling through the integration of cutting-edge AI techniques and UAV-based data, providing novel insights and enhanced predictive capabilities to understand dynamic wildfire behavior.}
}
",https://www.sciencedirect.com/science/article/pii/S1566253524001477,https://doi.org/10.1016/j.inffus.2024.102369,science_direct,2024
1298,EduCross: Dual adversarial bipartite hypergraph learning for cross-modal retrieval in multimodal educational slides,"@article{LI2024102428,
title = {EduCross: Dual adversarial bipartite hypergraph learning for cross-modal retrieval in multimodal educational slides},
journal = {Information Fusion},
volume = {109},
pages = {102428},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102428},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524002069},
author = {Ming Li and Siwei Zhou and Yuting Chen and Changqin Huang and Yunliang Jiang},
keywords = {Dual generative adversarial network, Cross-modal retrieval, Deep bipartite hypergraph learning, Framelet transform, Multimodal educational slides},
abstract = {In the digital education landscape, cross-modal retrieval (CMR) from multimodal educational slides represents a significant challenge, particularly because of the complex nature of academic content, which includes images, diagrams, equations, and tables across various subjects such as mathematics and biology. Current CMR systems are primarily designed for “(natural) image to text” interactions (or vice versa) and inadequately address real-world educational scenarios. This study presents EduCross, a novel framework devised to enhance CMR within multimodal educational slides, which is a domain in which traditional retrieval systems fall short. Recognizing the imperative for a system that is tailored to the educational context, EduCross integrates dual adversarial bipartite hypergraph learning, harnessing the capabilities of generative adversarial networks with figure-text dual channels. This powerful combination facilitates robust bidirectional mapping, allowing for the precise association of figures with their descriptive spoken language segments and ensuring a comprehensive CMR experience. Specifically, we develop framelet-based deep bipartite hypergraph neural networks that effectively manage the high-order relationships between diverse educational content types and various types of slide figures. Our experimental results underscore the superior performance of EduCross, demonstrating its effectiveness through the use of the real Multimodal Lecture Presentations dataset that mirrors authentic educational settings. These outcomes highlight the significant advancements of EduCross over existing methods, marking a leap forward in the accurate retrieval of multimodal educational content.}
}
",https://www.sciencedirect.com/science/article/pii/S1566253524002069,https://doi.org/10.1016/j.inffus.2024.102428,science_direct,2024
1299,"Health informatics to enhance the healthcare industry's culture: An extensive analysis of its features, contributions, applications and limitations","@article{JAVAID2024,
title = {Health informatics to enhance the healthcare industry's culture: An extensive analysis of its features, contributions, applications and limitations},
journal = {Informatics and Health},
year = {2024},
issn = {2949-9534},
doi = {https://doi.org/10.1016/j.infoh.2024.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949953424000092},
author = {Mohd Javaid and Abid Haleem and Ravi Pratap Singh},
keywords = {Healthcare Informatics, Artificial Intelligence, Technologies, Applications, Medical, Patient},
abstract = {Background
Health informatics is a fast-growing area in the healthcare sector. It concerns the technologies, tools, equipment, and procedures required to gather, store, retrieve, and use health data and medical data. Healthcare informatics provides patients, nurses, hospital administrators, physicians, insurance providers, and other stakeholders with electronic access to medical records through health information technologies (HIT). Health informatics combines nursing science with data science and analytical disciplines to gather, handle, interpret, and convey data, bringing together specialists and making health information accessible and meaningful.
Methods
This research is an outcome of an extensive scopic review, which has been conducted by identifying research and development through search keywords such as “Health informatics,” “Technologies,” and “Healthcare” from databases of Scopus, PubMed, Google Scholar, ResearchGate, and other research platforms. Further, the most relevant papers are identified and studied.
Findings
This paper explores health informatics, its technologies, and their need in the present healthcare domain. It also identifies vital aspects, characteristics, and versatile contributions of health informatics to the healthcare sector. Further, the paper identifies and discusses significant health informatics applications in the healthcare field. Patients' health information can be effectively analysed individually or in groups using health informatics technologies to meet diverse requirements.
Interpretation
Effective use of health informatics improves practice management as information is quickly shared among healthcare professionals, patients and other stakeholders. Healthcare informatics specialists' knowledge of utilising data to assist choice-making and creating best practices. It enables healthcare organisations to identify specific data offering the appropriate information for the given therapy, procedure, or training. Informatics in healthcare also addresses issues at the macro level of the organisation and also at the personal level of patient care via innovative technologies and best practices.}
}
",https://www.sciencedirect.com/science/article/pii/S2949953424000092,https://doi.org/10.1016/j.infoh.2024.05.001,science_direct,2024
1300,Memorization and generalization in neural code intelligence models,"@article{RABIN2023107066,
title = {Memorization and generalization in neural code intelligence models},
journal = {Information and Software Technology},
volume = {153},
pages = {107066},
year = {2023},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.107066},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922001756},
author = {Md Rafiqul Islam Rabin and Aftab Hussain and Mohammad Amin Alipour and Vincent J. Hellendoorn},
keywords = {Machine learning, Software engineering, Memorization and generalization, Empirical results, Models of code},
abstract = {Context:
Deep Neural Networks (DNNs) are increasingly being used in software engineering and code intelligence tasks. These are powerful tools that are capable of learning highly generalizable patterns from large datasets through millions of parameters. At the same time, their large capacity can render them prone to memorizing data points. Recent work suggests that the memorization risk manifests especially strongly when the training dataset is noisy, involving many ambiguous or questionable samples, and memorization is the only recourse.
Objective:
The goal of this paper is to evaluate and compare the extent of memorization and generalization in neural code intelligence models. It aims to provide insights on how memorization may impact the learning behavior of neural models in code intelligence systems.
Method:
To observe the extent of memorization in models, we add random noise to the original training dataset and use various metrics to quantify the impact of noise on various aspects of training and testing. We evaluate several state-of-the-art neural code intelligence models and benchmarks based on Java, Python, and Ruby codebases.
Results:
Our results highlight important risks: millions of trainable parameters allow the neural networks to memorize anything, including noisy data, and provide a false sense of generalization. We observed all models manifest some forms of memorization. This can be potentially troublesome in most code intelligence tasks where they rely on rather noise-prone and repetitive data sources, such as code from GitHub.
Conclusion:
To the best of our knowledge, we provide the first study to quantify memorization effects in the domain of software engineering and code intelligence systems. This work raises awareness and provides new insights into important issues of training neural models in code intelligence systems that are usually overlooked by software engineering researchers.}
}
",https://www.sciencedirect.com/science/article/pii/S0950584922001756,https://doi.org/10.1016/j.infsof.2022.107066,science_direct,2023
1301,Improving domain-specific neural code generation with few-shot meta-learning,"@article{YANG2024107365,
title = {Improving domain-specific neural code generation with few-shot meta-learning},
journal = {Information and Software Technology},
volume = {166},
pages = {107365},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107365},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923002203},
author = {Zhen Yang and Jacky Wai Keung and Zeyu Sun and Yunfei Zhao and Ge Li and Zhi Jin and Shuo Liu and Yishu Li},
keywords = {Code generation, Few-shot learning, Meta-learning, Transfer learning},
abstract = {Context:
Neural code generation aims to automatically generate code snippets guided by Natural Language Descriptions (NLDs). In recent years, various neural code generation models for mainstream Programming Languages (PLs), such as Java and Python, have been proposed and demonostrated significant success in prior studies. Nonetheless, due to the scarcity of available training examples for some domain-specific PLs, such as Solidity, Bash, and Clojure, simply adopting previous neural models may lead to overfitting and inadequate learning.
Objective:
To overcome this challenge, we propose MetaCoder, a novel meta-learning code generation approach that efficiently extracts general-purpose knowledge from a large-scale source language and rapidly adapts to domain-specific scenarios, even with relatively few samples.
Method:
MetaCoder employs MAML, a powerful few-shot meta-learning method, to construct a transfer learning framework. This framework learns general-purpose knowledge from large-scale source languages and applies it in domain-specific target languages. To acquire more general-purpose knowledge, heterogeneous sub-tasks are constructed from the source language during the pre-training phase of MAML. As such, combining with CodeBERT and K-means, we design an unsupervised category assignment method for code generation samples, thereby exploiting the n-way k-shot rule to construct the heterogeneous sub-tasks. Consequently, MetaCoder can be applied to the code generation field.
Results:
We evaluate MetaCoder with both tree-based (e.g., TreeGen) and sequence-based (e.g., CodeGPT) backbones on two domain-specific PLs, including Solidity and Bash. Extensive experiments demonstrate the superior performance of our approach compared to baselines and verified its capability of code generation visually in practice.
Conclusion:
MetaCoder effectively extracts general-purpose knowledge from large-scale source languages, thereby enhancing model performance. Therefore, we highly recommend MetaCoder as a code generation approach for domain-specific PLs.}
}
",https://www.sciencedirect.com/science/article/pii/S0950584923002203,https://doi.org/10.1016/j.infsof.2023.107365,science_direct,2024
1302,Technical risk model of machine learning based software project development - A multinational empirical study using modified Delphi-AHP method,"@article{LIN2024107449,
title = {Technical risk model of machine learning based software project development - A multinational empirical study using modified Delphi-AHP method},
journal = {Information and Software Technology},
volume = {171},
pages = {107449},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107449},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924000545},
author = {Ching-Te Lin and Sun-Jen Huang},
keywords = {Technical risk assessment, Machine learning, Software project development, Modified Delphi, AHP},
abstract = {Context
The development of machine learning (ML) based software projects has increased significantly over the past decade, introducing new technical risks that rarely or never appear in traditional software development projects.
Objective
This research aims to identify and prioritize the technical risk factors that may lead to the failure of ML-based software development projects.
Method
First, a literature review was conducted to compile a preliminary list of technical risk factors for ML-based software project development. Then, two rounds of the modified Delphi process were conducted with 17 ML experts to review and verify the completeness and appropriateness of the preliminary technical risk factors. A hierarchy of five technical risk categories with 22 technical risk factors was concluded for the analytic hierarchy process (AHP). Then, three rounds of online AHP questionnaires were administered. The consistency ratio (CR) was used to check the respondents’ answers, and the quartile deviation (QD) was applied to assess the consensus on all 96 questions. Finally, we prioritized the technical risk categories and associated technical risk factors.
Results
We found that ""data availability and quality"" ranked as the top technical risk category in terms of severity, probability, and impact rankings of the five technical risk categories. Furthermore, all four technical risk factors within this category also occupied the top four positions of impact ranking.
Conclusion
The research results highlight the crucial role of the four data availability and quality risk factors for the failure of ML-based software project development. The proposed technical risk model of ML-based software project development with the identified severity and probability priorities may provide practitioners and research community with a clear overview, highlighting areas demanding priority attention to effectively mitigate project failure risks. These findings have broader implications for improving the success rates of ML-based software projects across various domains.}
}
",https://www.sciencedirect.com/science/article/pii/S0950584924000545,https://doi.org/10.1016/j.infsof.2024.107449,science_direct,2024
1303,Automating modern code review processes with code similarity measurement,"@article{KARTAL2024107490,
title = {Automating modern code review processes with code similarity measurement},
journal = {Information and Software Technology},
volume = {173},
pages = {107490},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107490},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924000958},
author = {Yusuf Kartal and E. Kaan Akdeniz and Kemal Özkan},
keywords = {Modern code review, Vectorization, Code similarity, Information retrieval},
abstract = {Context:
Modern code review is a critical component in software development processes, as it ensures security, detects errors early and improves code quality. However, manual reviews can be time-consuming and unreliable. Automated code review can address these issues. Although deep-learning methods have been used to recommend code review comments, they are expensive to train and employ. Instead, information retrieval (IR)-based methods for automatic code review are showing promising results in efficiency, effectiveness, and flexibility.
Objective:
Our main objective is to determine the optimal combination of the vectorization method and similarity to measure what gives the best results in an automatic code review, thereby improving the performance of IR-based methods.
Method:
Specifically, we investigate different vectorization methods (Word2Vec, Doc2Vec, Code2Vec, and Transformer) that differ from previous research (TF-IDF and Bag-of-Words), and similarity measures (Cosine, Euclidean, and Manhattan) to capture the semantic similarities between code texts. We evaluate the performance of these methods using standard metrics, such as Blue, Meteor, and Rouge-L, and include the run-time of the models in our results.
Results:
Our results demonstrate that the Transformer model outperforms the state-of-the-art method in all standard metrics and similarity measurements, achieving a 19.1% improvement in providing exact matches and a 6.2% improvement in recommending reviews closer to human reviews.
Conclusion:
Our findings suggest that the Transformer model is a highly effective and efficient approach for recommending code review comments that closely resemble those written by humans, providing valuable insight for developing more efficient and effective automated code review systems.}
}
",https://www.sciencedirect.com/science/article/pii/S0950584924000958,https://doi.org/10.1016/j.infsof.2024.107490,science_direct,2024
1304,A vulnerability detection framework by focusing on critical execution paths,"@article{CHENG2024107517,
title = {A vulnerability detection framework by focusing on critical execution paths},
journal = {Information and Software Technology},
volume = {174},
pages = {107517},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107517},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924001228},
author = {Jianxin Cheng and Yizhou Chen and Yongzhi Cao and Hanpin Wang},
keywords = {Vulnerability detection, Software security, Code representation, Control flow graph, Deep learning},
abstract = {Context:
Vulnerability detection is critical to ensure software security, and detecting vulnerabilities in smart contract code is currently gaining massive attention. Existing deep learning-based vulnerability detection methods represent the code as a code structure graph and eliminate vulnerability-irrelevant nodes. Then, they learn vulnerability-related code features from the simplified graph for vulnerability detection. However, this simplified graph struggles to represent relatively complete structural information of code, which may affect the performance of existing vulnerability detection methods.
Objective:
In this paper, we present a novel Vulnerability Detection framework based on Critical Execution Paths (VDCEP), which aims to improve smart contract vulnerability detection.
Method:
Firstly, given a code structure graph, we deconstruct it into multiple execution paths that reflect rich structural information of code. To reduce irrelevant code information, a path selection strategy is employed to identify critical execution paths that may contain vulnerable code information. Secondly, a feature extraction module is adopted to learn feature representations of critical paths. Finally, we feed all path feature representations into a classifier for vulnerability detection. Also, the feature weights of paths are provided to measure their importance in vulnerability detection.
Results:
We evaluate VDCEP on a large dataset with four types of smart contract vulnerabilities. Results show that VDCEP outperforms 14 representative vulnerability detection methods by 5.34%–60.88% in F1-score. The ablation studies analyze the effects of our path selection strategy and feature extraction module on VDCEP. Moreover, VDCEP still outperforms ChatGPT by 34.46% in F1-score.
Conclusion:
Compared to existing vulnerability detection methods, VDCEP is more effective in detecting smart contract vulnerabilities by utilizing critical execution paths. Besides, we can provide interpretable details about vulnerability detection by analyzing the path feature weights.}
}
",https://www.sciencedirect.com/science/article/pii/S0950584924001228,https://doi.org/10.1016/j.infsof.2024.107517,science_direct,2024
1305,"ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope","@article{RAY2023121,
title = {ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope},
journal = {Internet of Things and Cyber-Physical Systems},
volume = {3},
pages = {121-154},
year = {2023},
issn = {2667-3452},
doi = {https://doi.org/10.1016/j.iotcps.2023.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S266734522300024X},
author = {Partha Pratim Ray},
keywords = {ChatGPT, Language model, GPT-3.5, Generative AI, Conversational AI, Context understanding, Natural language processing},
abstract = {In recent years, artificial intelligence (AI) and machine learning have been transforming the landscape of scientific research. Out of which, the chatbot technology has experienced tremendous advancements in recent years, especially with ChatGPT emerging as a notable AI language model. This comprehensive review delves into the background, applications, key challenges, and future directions of ChatGPT. We begin by exploring its origins, development, and underlying technology, before examining its wide-ranging applications across industries such as customer service, healthcare, and education. We also highlight the critical challenges that ChatGPT faces, including ethical concerns, data biases, and safety issues, while discussing potential mitigation strategies. Finally, we envision the future of ChatGPT by exploring areas of further research and development, focusing on its integration with other technologies, improved human-AI interaction, and addressing the digital divide. This review offers valuable insights for researchers, developers, and stakeholders interested in the ever-evolving landscape of AI-driven conversational agents. This study explores the various ways ChatGPT has been revolutionizing scientific research, spanning from data processing and hypothesis generation to collaboration and public outreach. Furthermore, the paper examines the potential challenges and ethical concerns surrounding the use of ChatGPT in research, while highlighting the importance of striking a balance between AI-assisted innovation and human expertise. The paper presents several ethical issues in existing computing domain and how ChatGPT can invoke challenges to such notion. This work also includes some biases and limitations of ChatGPT. It is worth to note that despite of several controversies and ethical concerns, ChatGPT has attracted remarkable attentions from academia, research, and industries in a very short span of time.}
}
",https://www.sciencedirect.com/science/article/pii/S266734522300024X,https://doi.org/10.1016/j.iotcps.2023.04.003,science_direct,2023
1306,Exploring the competence of ChatGPT for customer and patient service management,"@article{HALEEM2024392,
title = {Exploring the competence of ChatGPT for customer and patient service management},
journal = {Intelligent Pharmacy},
volume = {2},
number = {3},
pages = {392-414},
year = {2024},
issn = {2949-866X},
doi = {https://doi.org/10.1016/j.ipha.2024.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949866X24000480},
author = {Abid Haleem and Mohd Javaid and Ravi Pratap Singh},
keywords = {Artificial intelligence (AI), ChatGPT, Applications, Healthcare, Customer, Patient},
abstract = {The modern language generation model ChatGPT, created by Open Artificial Intelligence (AI), is recognised for its capacity to comprehend context and produce pertinent content. This model is built on the transformer architecture, which enables it to process massive volumes of data and produce text that is both cohesive and illuminating. Service is a crucial component everywhere as it provides the basis for establishing client rapport and offering aid and support. In healthcare, the application of ChatGPT for patient service support has been one of the most significant advances in recent years. ChatGPT can help overcome language obstacles and improve patient satisfaction by facilitating communication with healthcare personnel and understanding of care. It can assist in enhancing the entire patient experience by offering personalised information and support to patients and making it more straightforward for them to communicate with healthcare professionals. Its goal can be to expedite and streamline service by promptly and accurately responding to customers. Businesses of all sizes increasingly use ChatGPT since it allows them to provide 24/7 customer support without requiring human contact. This paper briefly discusses ChatGPT and the need for better services. Various perspectives on improving customer and patient services through ChatGPT are discussed. The article also discussed the major key enablers of ChatGPT for refining customer and patient assistance. Further, the paper identifies and discusses the critical application areas of ChatGPT for customer and patient service. With its ability to handle several requests simultaneously, respond quickly and accurately to client questions, and gain knowledge from every interaction, ChatGPT is revolutionising customer and patient service. Its accessibility and compatibility with various communication channels make it a desirable solution for businesses looking to improve support. As technology advances, ChatGPT is positioned to become an essential tool for businesses wishing to provide speedy and customised service. Although ChatGPT may give convincing solutions, the chance of providing accurate and updated information poses a problem for its usage in service jobs that need accurate and up-to-date information. In future, various services will become better and more efficient due to ChatGPT and AI.}
}
",https://www.sciencedirect.com/science/article/pii/S2949866X24000480,https://doi.org/10.1016/j.ipha.2024.03.002,science_direct,2024
1308,The state of human-centered NLP technology for fact-checking,"@article{DAS2023103219,
title = {The state of human-centered NLP technology for fact-checking},
journal = {Information Processing & Management},
volume = {60},
number = {2},
pages = {103219},
year = {2023},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103219},
url = {https://www.sciencedirect.com/science/article/pii/S030645732200320X},
author = {Anubrata Das and Houjiang Liu and Venelin Kovatchev and Matthew Lease},
keywords = {Natural Language Processing, Misinformation, Disinformation, Explainability, Human-AI teaming},
abstract = {Misinformation threatens modern society by promoting distrust in science, changing narratives in public health, heightening social polarization, and disrupting democratic elections and financial markets, among a myriad of other societal harms. To address this, a growing cadre of professional fact-checkers and journalists provide high-quality investigations into purported facts. However, these largely manual efforts have struggled to match the enormous scale of the problem. In response, a growing body of Natural Language Processing (NLP) technologies have been proposed for more scalable fact-checking. Despite tremendous growth in such research, however, practical adoption of NLP technologies for fact-checking still remains in its infancy today. In this work, we review the capabilities and limitations of the current NLP technologies for fact-checking. Our particular focus is to further chart the design space for how these technologies can be harnessed and refined in order to better meet the needs of human fact-checkers. To do so, we review key aspects of NLP-based fact-checking: task formulation, dataset construction, modeling, and human-centered strategies, such as explainable models and human-in-the-loop approaches. Next, we review the efficacy of applying NLP-based fact-checking tools to assist human fact-checkers. We recommend that future research include collaboration with fact-checker stakeholders early on in NLP research, as well as incorporation of human-centered design practices in model development, in order to further guide technology development for human use and practical adoption. Finally, we advocate for more research on benchmark development supporting extrinsic evaluation of human-centered fact-checking technologies.}
}
",https://www.sciencedirect.com/science/article/pii/S030645732200320X,https://doi.org/10.1016/j.ipm.2022.103219,science_direct,2023
1309,"A meta-analysis of third-person perception related to distorted information: Synthesizing the effect, antecedents, and consequences","@article{CHEN2023103425,
title = {A meta-analysis of third-person perception related to distorted information: Synthesizing the effect, antecedents, and consequences},
journal = {Information Processing & Management},
volume = {60},
number = {5},
pages = {103425},
year = {2023},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103425},
url = {https://www.sciencedirect.com/science/article/pii/S0306457323001620},
author = {Meng Chen and Weihua Yu and Ke Liu},
keywords = {Misinformation, Disinformation, Third-person perception/effect, Meta-analysis},
abstract = {In the long run of fighting distorted information, empowering Internet users is believed to be an economic and sustainable solution. The effectiveness of this approach relies on the assumption that Internet users pay close attention to and hold unbiased perceptions of the distorted information. To obtain a systematic examination of people's perceptions of the distorted information, we performed a two-part meta-analysis based on 24 articles with 20,777 participants across three continents. Drawing on the third-person perception/effect (TPP/TPE) framework, Part I synthesized the literature examining the perpetual gap of distorted information's influence on self and others. Based on 28 effect sizes, the results confirmed a strong third-person perception related to distorted information (d = 0.614, p <.0001). Factors identified as moderating the effect magnitude include distorted information type, TPP operationalization, and study context. Part II was a synthesis of 63 effect sizes examining the potential antecedents and consequences of distorted information TPP. The results indicated that media use, distorted information exposure, and efficacy beliefs are predictors of distorted information TPP. However, policy support, proposed as a potential consequence, was not found to be so. The implications of our findings and directions for future research are discussed.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457323001620,https://doi.org/10.1016/j.ipm.2023.103425,science_direct,2023
1310,Citation prediction by leveraging transformers and natural language processing heuristics,"@article{BUSCALDI2024103583,
title = {Citation prediction by leveraging transformers and natural language processing heuristics},
journal = {Information Processing & Management},
volume = {61},
number = {1},
pages = {103583},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103583},
url = {https://www.sciencedirect.com/science/article/pii/S0306457323003205},
author = {Davide Buscaldi and Danilo Dessí and Enrico Motta and Marco Murgia and Francesco Osborne and Diego {Reforgiato Recupero}},
keywords = {Citation prediction, Transformers architecture, Mask-filling, Named entity recognition, BERT},
abstract = {In scientific papers, it is common practice to cite other articles to substantiate claims, provide evidence for factual assertions, reference limitations, and research gaps, and fulfill various other purposes. When authors include a citation in a given sentence, there are two considerations they need to take into account: (i) where in the sentence to place the citation and (ii) which citation to choose to support the underlying claim. In this paper, we focus on the first task as it allows multiple potential approaches that rely on the researcher’s individual style and the specific norms and conventions of the relevant scientific community. We propose two automatic methodologies that leverage transformers architecture for either solving a Mask-Filling problem or a Named Entity Recognition problem. On top of the results of the proposed methodologies, we apply ad-hoc Natural Language Processing heuristics to further improve their outcome. We also introduce s2orc-9K, an open dataset for fine-tuning models on this task. A formal evaluation demonstrates that the generative approach significantly outperforms five alternative methods when fine-tuned on the novel dataset. Furthermore, this model’s results show no statistically significant deviation from the outputs of three senior researchers.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457323003205,https://doi.org/10.1016/j.ipm.2023.103583,science_direct,2024
1311,A cross-guidance cross-lingual model on generated parallel corpus for classical Chinese machine reading comprehension,"@article{XIANG2024103607,
title = {A cross-guidance cross-lingual model on generated parallel corpus for classical Chinese machine reading comprehension},
journal = {Information Processing & Management},
volume = {61},
number = {2},
pages = {103607},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103607},
url = {https://www.sciencedirect.com/science/article/pii/S0306457323003448},
author = {Junyi Xiang and Maofu Liu and Qiyuan Li and Chen Qiu and Huijun Hu},
keywords = {Classical Chinese machine reading comprehension, Chinese diachronic gap, Cross-guidance cross-lingual model, Parallel corpus generation},
abstract = {Chinese diachronic gap is a key issue in classical Chinese machine reading comprehension (CCMRC). Preceding work on bridging this gap has been mostly restricted to limited monolingual classical Chinese corpora pre-training and lexical knowledge integration, which require a great deal of human resources. In this paper, we propose a cross-guidance cross-lingual model (CGCLM), pre-trained on a classical and modern Chinese parallel corpus generated from a large language model, to bridge the Chinese diachronic gap and reduce the manual effort. The CGCLM facilitates accurate translation by providing in-context examples and feedback based on the longest common substring between source and target sentences, thereby avoiding untranslated Chinese words. Specifically, we consider three pre-training tasks, i.e., cross-masked language modeling, linguistic label cross-prediction, and semantic cross-aware translation language modeling. The knowledge acquired from masked tokens uncovering and linguistic label predicting can lead to the implicit semantic alignment between two language styles. Taking advantage of the semantic similarity between the same syntactic levels of parallel pairs, cross-aware modeling integrates and transmits contextualized semantic information. We utilize an 18.6G monolingual corpus to create a 37.2G parallel corpus. Manual evaluation has resulted in only acceptable discrepancies between our generated and human-edited parallel corpora. Extensive experimental results show that our proposed model outperforms the state-of-the-art by an average accuracy of 3.13%, 2.44%, and 2.17% on CCMRC, classical Chinese language understanding evaluation (CCLUE), and modern Chinese language understanding evaluation (MCLUE) tasks.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457323003448,https://doi.org/10.1016/j.ipm.2023.103607,science_direct,2024
1312,Utilizing cognitive signals generated during human reading to enhance keyphrase extraction from microblogs,"@article{YAN2024103614,
title = {Utilizing cognitive signals generated during human reading to enhance keyphrase extraction from microblogs},
journal = {Information Processing & Management},
volume = {61},
number = {2},
pages = {103614},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103614},
url = {https://www.sciencedirect.com/science/article/pii/S0306457323003515},
author = {Xinyi Yan and Yingyi Zhang and Chengzhi Zhang},
keywords = {Automatic Keyphrase Extraction (AKE), Human readings behavior, EEG, Eye-tracking, Cognitive signal},
abstract = {Microblogging platforms have seen exponential growth, leading to an abundance of user-generated content. The challenge now is to efficiently extract crucial information from this vast and dispersed text data. It also serves as the goal of our research on Automatic Keyphrase Extraction (AKE) for microblog. Eye-tracking signals, that reflect users' tendency to prioritize certain words while reading, have been employed to enhance AKE performance from microblogs. However, relying solely on eye-tracking has its limitations owing to constraints in physiological mechanism support, acquisition techniques, and feature decoding. Consequently, we propose the integration of electroencephalogram (EEG) signals with eye-tracking signals to improve microblogs-based AKE, thereby overcoming the aforementioned limitations. Our first step is identifying specific features present in cognitive signals generated during human reading. We selected EEG signals (8 features) and eye-tracking signals (17 features) from the cognitive language processing corpus ZUCO, to examine the efficacy when they are combined with the microblogs-based AKE. To avoid cognitive signal distortion by certain model structures, we introduced these signals at the inputs of the soft attention layer and at the query vectors of the self-attention layer. For evaluation, we performed several AKE tests on microblogs with various combinations of cognitive signals. The results demonstrate a consistent enhancement in the performance of AKE due to cognitive signals generated during human reading, regardless of different feature combinations and models. Specifically, EEG signals exhibited the most significant improvement. However, combining EEG signals with eye-tracking signals yielded results that fell between the performance levels of the two signal types, indicating that their integration might have some synergistic effects. Further investigation is needed to understand the underlying mechanisms responsible for this outcome. The code and dataset for this paper can be accessed at https://github.com/yan-xinyi/AKE.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457323003515,https://doi.org/10.1016/j.ipm.2023.103614,science_direct,2024
1313,Dialogue summarization enhanced response generation for multi-domain task-oriented dialogue systems,"@article{WANG2024103668,
title = {Dialogue summarization enhanced response generation for multi-domain task-oriented dialogue systems},
journal = {Information Processing & Management},
volume = {61},
number = {3},
pages = {103668},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103668},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324000281},
author = {Lifang Wang and Meng Zhao and Hongru Ji and Zejun Jiang and Ronghan Li and Zhongtian Hu and Xinyu Lu},
keywords = {Task-oriented dialogue system, Dialogue summarization, Response generation, Pre-trained language model},
abstract = {Task-oriented dialogue systems (TOD) are blossoming with the advances in pre-trained language models (PrLM). Recently, research on PrLM-based multi-domain TOD has arisen with many outstanding outcomes. However, three challenges still need to be thoroughly studied. First, most current works regard dialogue state tracking as a generative problem supervised by concatenated slot-value sequences, impairing the models’ domain adaption because of the discrepancy between PrLM’s natural text inputs and spliced slot-value spans. Second, most existing works seldom specifically consider how to deal with long and involved dialogue history caused by multiple task domains. Third, few studies are concerned with enhancing the model’s reasoning ability to handle intricate contexts. To alleviate these issues, we propose a dialogue summarization enhanced response generation framework for multi-domain TOD. Specifically, we offer a novel summarization model that employs the query and the generated summarization from the previous turn to obtain beneficial information for the current turn, which is then combined with the entire dialogue history to produce the final summary. Then, the generated dialogue summarization is fed to the response decoder as dialogue states and key dialogue histories through the designed dynamic fusion mechanism to yield responses. Experimental results indicate that the proposed model for response generation task outperforms the baseline models in both automatic and human evaluations on two public datasets.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457324000281,https://doi.org/10.1016/j.ipm.2024.103668,science_direct,2024
1314,The prominent and heterogeneous gender disparities in scientific novelty: Evidence from biomedical doctoral theses,"@article{LIU2024103743,
title = {The prominent and heterogeneous gender disparities in scientific novelty: Evidence from biomedical doctoral theses},
journal = {Information Processing & Management},
volume = {61},
number = {4},
pages = {103743},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103743},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001031},
author = {Meijun Liu and Zihan Xie and Alex Jie Yang and Chao Yu and Jian Xu and Ying Ding and Yi Bu},
keywords = {Scientific novelty, Ph.D. graduates, Gender disparities, Doctoral theses, Quantile regression analyses, Mentorship},
abstract = {Scientific novelty is the essential driving force for research breakthroughs and innovation. However, little is known about how early-career scientists pursue novel research paths, and the gender disparities in this process. To address this research gap, this study investigates a comprehensive dataset of 277,288 doctoral theses in the biomedical sciences authored by US Ph.D. graduates. Spanning from 1980 to 2016, the data originates from the ProQuest Dissertations & Theses Database. This study aims to shed light on Ph.D. students’ pursuit of scientific novelty in their doctoral theses and assess gender-related differences in this process. Using a combinatorial approach and a pre-trained Bio-BERT model, we quantify the scientific novelty of doctoral theses based on bio-entities. Applying fractional logistic and quantile regression models, this study reveals a decreasing trend in scientific novelty over time and heterogeneous gender disparities in doctoral theses. Specifically, female students consistently exhibit lower scientific novelty levels than their male peers. Under the supervision of female advisors, students tend to produce doctoral theses that exhibit lower levels of novelty compared to those supervised by male advisors. The significant interaction effect of female students and female advisors suggests that female advisors may amplify gender disparities in scientific novelty. Moreover, heterogeneous gender disparities in scientific novelty are identified, with non-top-tier universities displaying more pronounced disparities, while the gender differences at higher percentile ranges of scientific novelty scores were comparatively more minor. These findings indicate a potential underrepresentation of early-career female scientists pursuing novel research. Notably, the outcomes of this study hold significant policy implications for advancing the careers of female scientists.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457324001031,https://doi.org/10.1016/j.ipm.2024.103743,science_direct,2024
1315,Integrating learners’ knowledge background to improve course recommendation fairness: A multi-graph recommendation method based on contrastive learning,"@article{MA2024103750,
title = {Integrating learners’ knowledge background to improve course recommendation fairness: A multi-graph recommendation method based on contrastive learning},
journal = {Information Processing & Management},
volume = {61},
number = {4},
pages = {103750},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103750},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001109},
author = {Wenjun Ma and Wen Chen and Liuxing Lu and Xiaomao Fan},
keywords = {Course recommendation, Algorithmic fairness, Contrastive learning, Knowledge graph, MOOC},
abstract = {Massive Open Online Course (MOOC) recommendations that fail to align with the learners’ prior knowledge have the potential to adversely affect educational outcomes. Despite the advancements in deep learning-based course recommendation (CR) methods, there remains a lack of comprehensive examination concerning the biases associated with the diverse knowledge backgrounds of learners. Furthermore, the phenomenon of popularity bias exists in current CR systems. In light of the above issues, this study proposes a model called Contrastive Learning and Graph Convolution Network-based Attentive Decay Network (CLGADN), which aims to improve fairness in CR by taking into account the learners’ knowledge backgrounds. Specifically, (1) CLGADN employs contrastive learning to recognize the diverse knowledge backgrounds of learners and to address the challenge of popularity bias within CR, and (2) A monotonic attention decay mechanism is incorporated into the CLGADN to account for the knowledge forgetting curve, acknowledging that the knowledge learners have recently acquired shapes their understanding of the new course, more than the knowledge obtained in the past. Real-world XuetangX data are used to evaluate the proposed method. Experimental results reveal that (1) the CLGADN outperforms other recent CR methods regarding accuracy and fairness, achieving 74.73% on HR@10, 48.35% on NDCG@10, 41.45% on MRR, and 3.9% on TotalScore, a metric for evaluating whether the recommendations align with the learner’s knowledge background, and (2) Multi-graph contrastive learning can improve fairness by dealing with the issues of sparse data and popularity bias. This study provides insights for MOOC platforms enhancing the fairness of CR algorithms by considering the varied knowledge backgrounds of different users. It can potentially mitigate the negative effects on learners’ educational outcomes by recommending courses aligned with their knowledge backgrounds.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457324001109,https://doi.org/10.1016/j.ipm.2024.103750,science_direct,2024
1316,DCTM: Dual Contrastive Topic Model for identifiable topic extraction,"@article{WANG2024103785,
title = {DCTM: Dual Contrastive Topic Model for identifiable topic extraction},
journal = {Information Processing & Management},
volume = {61},
number = {5},
pages = {103785},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103785},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001456},
author = {Rui Wang and Peng Ren and Xing Liu and Shuyu Chang and Haiping Huang},
keywords = {Contrastive learning, Neural-based topic model, Topic modeling},
abstract = {The recent advanced Contrastive Neural Topic Model (CNTM) was proposed to tackle topic collapse through document-level contrastive learning. However, limited by its usage of the Logistic-Normal prior in topic space and document level contrastive learning, it is less capable of disentangling semantically similar topics. To address the limitation, we propose a novel Dual Contrastive Topic Model (DCTM) that utilizes the Dirichlet prior to capture interpretable patterns. Besides, it incorporates dual (document-level and topic-level) contrastive learning on the topic distribution matrix which helps generate discriminative topic representations and mine identifiable topics. Our proposed DCTM outperforms the state-of-the-art neural topic models in terms of topic coherence and diversity, which is verified by extensive experimentation on three publicly available text corpora. In detail, the proposed DCTM surpasses baselines on almost all the used topic coherence metrics (CP, CA, NPMI for 20Newsgroups, CP, CA, NPMI and UCI for Grolier and DBPedia), and it also obtains higher topic diversity with 1 datasets respectively. Moreover, when performing text clustering, DCTM also achieves significant improvements, with observed increases of more than 1% (20Newsgroups) and 6% (DBPedia) in accuracy.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457324001456,https://doi.org/10.1016/j.ipm.2024.103785,science_direct,2024
1317,BB-GeoGPT: A framework for learning a large language model for geographic information science,"@article{ZHANG2024103808,
title = {BB-GeoGPT: A framework for learning a large language model for geographic information science},
journal = {Information Processing & Management},
volume = {61},
number = {5},
pages = {103808},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103808},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001675},
author = {Yifan Zhang and Zhiyun Wang and Zhengting He and Jingxuan Li and Gengchen Mai and Jianfeng Lin and Cheng Wei and Wenhao Yu},
keywords = {Large language model, GIS knowledge corpus, Domain adaptation, Self-instruct instructions},
abstract = {Large language models (LLMs) exhibit impressive capabilities across diverse tasks in natural language processing. Nevertheless, challenges arise such as large model parameter size and limited model accessibility through APIs such as ChatGPT and GPT-4, which prohibits the model deployment on mobile devices and domain adaptation or fine-tuning. Moreover, while LLMs excel in general domains, their performance in specialized fields such as GIS may not always align with the expectations of domain experts. This is primarily attributed to the diverse disciplinary origins of the training data, which often lack comprehensive coverage and treatment of knowledge specific to individual disciplines (e.g., GIS). Therefore, there is a crucial need to train and adapt LLMs specifically designed for different professional fields. In this paper, our focus is on the GIS domain, where we introduce BB(BaBy)-GeoGPT, a large language model with GIS-specific knowledge. To achieve this goal, we curated a comprehensive set of resources, comprising model pretraining data (BB-GeoPT, 26,907 documents), supervised fine-tuning data (BB-GeoSFT, 35,876 instructions), and evaluation data (BB-GeoEval, 600 objective questions and 150 subjective questions). BB-GeoGPT is developed by first adapting an open-source general-domain LLM, the LLaMA-2-7B model, to our pretraining data. Subsequently, we use instruction tuning to further fine-tune the model on our BB-GeoSFT. Through extensive experiments on the evaluation dataset, BB-GeoGPT demonstrates improvements ranging from 10.55% to 47.57% for objective questions and from 7.87% to 27.73% for subjective questions, when compared to general LLMs of similar size in terms of accuracy. Moreover, our data collection strategy and the amassed data can serve as a foundation for advancing LLM research in the GIS domain, fostering further development.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457324001675,https://doi.org/10.1016/j.ipm.2024.103808,science_direct,2024
1318,Are LLMs good at structured outputs? A benchmark for evaluating structured output capabilities in LLMs,"@article{LIU2024103809,
title = {Are LLMs good at structured outputs? A benchmark for evaluating structured output capabilities in LLMs},
journal = {Information Processing & Management},
volume = {61},
number = {5},
pages = {103809},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103809},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001687},
author = {Yu Liu and Duantengchuan Li and Kaili Wang and Zhuoran Xiong and Fobo Shi and Jian Wang and Bing Li and Bo Hang},
keywords = {Large language model, Structured output capability, Benchmark dataset, Q&A interaction, Causal graph},
abstract = {Existing benchmarks for Large Language Models (LLMs) mostly focus on general or specific domain capabilities, overlooking structured output capabilities. We introduce SoEval, a benchmark for assessing LLMs’ ability to generate structured outputs like JSON, XML, and lists. SoEval contains 3.7K entries in Chinese and English, covering 13 types of structured output tasks across 20 subjects. In experiments, we found that while current mainstream LLMs have deficiencies in structured output, GPT-4 outperforms them in this aspect. GPT-4 achieved an average score of 0.4 on SoEval, representing a 24% enhancement over the next best-performing model. At the same time, the performance of current mainstream models on English tasks is also better than on Chinese tasks. We also report the performance of mainstream large models on different structured output types and task subjects. The benchmark construction code and SoEval dataset are open-sourced at https://github.com/MoranCoder95/SoEval.}
}
",https://www.sciencedirect.com/science/article/pii/S0306457324001687,https://doi.org/10.1016/j.ipm.2024.103809,science_direct,2024
1319,EarthVQANet: Multi-task visual question answering for remote sensing image understanding,"@article{WANG2024422,
title = {EarthVQANet: Multi-task visual question answering for remote sensing image understanding},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {212},
pages = {422-439},
year = {2024},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2024.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0924271624001990},
author = {Junjue Wang and Ailong Ma and Zihang Chen and Zhuo Zheng and Yuting Wan and Liangpei Zhang and Yanfei Zhong},
keywords = {Visual question answering, Semantic segmentation, Multi-modal fusion, Multi-task learning, Knowledge reasoning},
abstract = {Monitoring and managing Earth’s surface resources is critical to human settlements, encompassing essential tasks such as city planning, disaster assessment, etc. To accurately recognize the categories and locations of geographical objects and reason about their spatial or semantic relations , we propose a multi-task framework named EarthVQANet, which jointly addresses segmentation and visual question answering (VQA) tasks. EarthVQANet contains a hierarchical pyramid network for segmentation and semantic-guided attention for VQA, in which the segmentation network aims to generate pixel-level visual features and high-level object semantics, and semantic-guided attention performs effective interactions between visual features and language features for relational modeling. For accurate relational reasoning, we design an adaptive numerical loss that incorporates distance sensitivity for counting questions and mines hard-easy samples for classification questions, balancing the optimization. Experimental results on the EarthVQA dataset (city planning for Wuhan, Changzhou, and Nanjing in China), RSVQA dataset (basic statistics for general objects), and FloodNet dataset (disaster assessment for Texas in America attacked by Hurricane Harvey) show that EarthVQANet surpasses 11 general and remote sensing VQA methods. EarthVQANet simultaneously achieves segmentation and reasoning, providing a solid benchmark for various remote sensing applications. Data is available at http://rsidea.whu.edu.cn/EarthVQA.htm}
}
",https://www.sciencedirect.com/science/article/pii/S0924271624001990,https://doi.org/10.1016/j.isprsjprs.2024.05.001,science_direct,2024
1320,Efficient intent classification and entity recognition for university administrative services employing deep learning models,"@article{RIZOU2023200247,
title = {Efficient intent classification and entity recognition for university administrative services employing deep learning models},
journal = {Intelligent Systems with Applications},
volume = {19},
pages = {200247},
year = {2023},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2023.200247},
url = {https://www.sciencedirect.com/science/article/pii/S2667305323000728},
author = {S. Rizou and A. Theofilatos and A. Paflioti and E. Pissari and I. Varlamis and G. Sarigiannidis and K.Ch. Chatzisavvas},
keywords = {Named Entity Recognition, Intent Extraction, Natural Language Understanding, Deep Learning, LSTM networks, Transformer networks, Conversational Agents},
abstract = {The design and implementation of a domain specific conversational agent requires efficient Natural Language Understanding (NLU). The task is harder when multiple languages have to be supported, and training datasets can be beneficial. This work focuses on the development of an intelligent system, an automated multilingual customer service conversational agent (chatbot) for university students, which supports both Greek and English and combines Intent Classification or Intent Extraction (IE) and Named Entity Recognition (NER) to understand the content (i.e. type of actions conveyed and respective entities) of users' messages. We focus on the development of the fundamental tasks required by a conversational agent to provide customer services in the education industry and manage requests with instant responses and increased customer satisfaction. Instead of handling IE and NER separately, as it is common in the related work, we develop a joint model that combines Bidirectional Long Short-Term Memory (BiLSTM) and Conditional Random Fields (CRF) layers and generates outputs both for IE and NER. We introduce a novel, open access dataset for customer services in education industry, the UniWay dataset, that has been used for training and evaluating our model, comprises students' questions in English and Greek about essential information related to their studies. A comparative evaluation of the proposed model versus state-of-the-art standalone and joint model solutions in UniWay and xSID datasets, results in improvement of the performance for the IE task up to 1.4% and it is on par with the state-of-the-art for the NER task. These results justify the intuition that closed domains can benefit from less sophisticated architectures, but less costly in terms of computational and memory resources, that jointly resolve multiple NLU tasks.}
}
",https://www.sciencedirect.com/science/article/pii/S2667305323000728,https://doi.org/10.1016/j.iswa.2023.200247,science_direct,2023
1321,Combining low-code development with ChatGPT to novel no-code approaches: A focus-group study,"@article{MARTINS2023200289,
title = {Combining low-code development with ChatGPT to novel no-code approaches: A focus-group study},
journal = {Intelligent Systems with Applications},
volume = {20},
pages = {200289},
year = {2023},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2023.200289},
url = {https://www.sciencedirect.com/science/article/pii/S266730532300114X},
author = {José Martins and Frederico Branco and Henrique Mamede},
keywords = {Low-code, No-code, Artificial intelligence, Software models, ChatGPT, LLM},
abstract = {Low-code tools are a trend in software development for business solutions due to their agility and ease of use. There are a certain number of vendors with such solutions. Still, in most Western countries, there is a clear need for the existence of greater quantities of certified and experienced professionals to work with those tools. This means that companies with more resources can attract and maintain those professionals, whilst other smaller organizations must rely on an endless search for this scarce resource. We will present and validate a model designed to transform ChatGPT into a low-code developer, addressing the demand for a more skilled human resource solution. This innovative tool underwent rigorous validation via a focus group study, engaging a panel of highly experienced experts. Their invaluable insights and feedback on the proposed model were systematically gathered and meticulously analysed.}
}
",https://www.sciencedirect.com/science/article/pii/S266730532300114X,https://doi.org/10.1016/j.iswa.2023.200289,science_direct,2023
1322,Claude 2.0 large language model: Tackling a real-world classification problem with a new iterative prompt engineering approach,"@article{CARUCCIO2024200336,
title = {Claude 2.0 large language model: Tackling a real-world classification problem with a new iterative prompt engineering approach},
journal = {Intelligent Systems with Applications},
volume = {21},
pages = {200336},
year = {2024},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2024.200336},
url = {https://www.sciencedirect.com/science/article/pii/S2667305324000127},
author = {Loredana Caruccio and Stefano Cirillo and Giuseppe Polese and Giandomenico Solimando and Shanmugam Sundaramurthy and Genoveffa Tortora},
keywords = {Claude 2.0, Large language model, Online learning, Machine learning, Massive online analytics, Forest cover-type},
abstract = {In the last year, Large Language Models (LLMs) have transformed the way of tackling problems, opening up new perspectives in various works and research fields, due to their ability to generate and understand human languages. In this regard, the recent release of Claude 2.0 has contributed to the processing of more complex prompts. In this scenario, the goal of this paper is to evaluate the effectiveness of Claude 2.0 in a specific classification task. In particular, we considered the Forest cover-type problem, concerning the prediction of a cover-type value according to the geospatial characterization of target worldwide areas. To this end, we propose a novel iterative prompt template engineering approach, which integrates files by exploiting prompts and evaluates the quality of responses provided by the LLM. Moreover, we conducted several comparative analyses to evaluate the effectiveness of Claude 2.0 with respect to online and batch learning models. The results demonstrated that, although some online and batch models performed better than Claude 2.0, the new iterative prompt engineering approach improved the quality of responses, leading to better performance with increases ranging from 14% to 32% in terms of accuracy, precision, recall, and F1-score.}
}
",https://www.sciencedirect.com/science/article/pii/S2667305324000127,https://doi.org/10.1016/j.iswa.2024.200336,science_direct,2024
1323,A comprehensive survey of robust deep learning in computer vision,"@article{LIU2023175,
title = {A comprehensive survey of robust deep learning in computer vision},
journal = {Journal of Automation and Intelligence},
volume = {2},
number = {4},
pages = {175-195},
year = {2023},
issn = {2949-8554},
doi = {https://doi.org/10.1016/j.jai.2023.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S294985542300045X},
author = {Jia Liu and Yaochu Jin},
keywords = {Robustness, Deep learning, Computer vision, Survey, Adversarial attack, Adversarial defenses},
abstract = {Deep learning has presented remarkable progress in various tasks. Despite the excellent performance, deep learning models remain not robust, especially to well-designed adversarial examples, limiting deep learning models employed in security-critical applications. Therefore, how to improve the robustness of deep learning has attracted increasing attention from researchers. This paper investigates the progress on the threat of deep learning and the techniques that can enhance the model robustness in computer vision. Unlike previous relevant survey papers summarizing adversarial attacks and defense technologies, this paper also provides an overview of the general robustness of deep learning. Besides, this survey elaborates on the current robustness evaluation approaches, which require further exploration. This paper also reviews the recent literature on making deep learning models resistant to adversarial examples from an architectural perspective, which was rarely mentioned in previous surveys. Finally, interesting directions for future research are listed based on the reviewed literature. This survey is hoped to serve as the basis for future research in this topical field.}
}
",https://www.sciencedirect.com/science/article/pii/S294985542300045X,https://doi.org/10.1016/j.jai.2023.10.002,science_direct,2023
1324,Developing a deep learning natural language processing algorithm for automated reporting of adverse drug reactions,"@article{MCMASTER2023104265,
title = {Developing a deep learning natural language processing algorithm for automated reporting of adverse drug reactions},
journal = {Journal of Biomedical Informatics},
volume = {137},
pages = {104265},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104265},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422002702},
author = {Christopher McMaster and Julia Chan and David F.L. Liew and Elizabeth Su and Albert G. Frauman and Wendy W. Chapman and Douglas E.V. Pires},
keywords = {Natural language processing, Machine learning, Adverse drug reactions, Transfer learning},
abstract = {The detection of adverse drug reactions (ADRs) is critical to our understanding of the safety and risk-benefit profile of medications. With an incidence that has not changed over the last 30 years, ADRs are a significant source of patient morbidity, responsible for 5%–10% of acute care hospital admissions worldwide. Spontaneous reporting of ADRs has long been the standard method of reporting, however this approach is known to have high rates of under-reporting, a problem that limits pharmacovigilance efforts. Automated ADR reporting presents an alternative pathway to increase reporting rates, although this may be limited by over-reporting of other drug-related adverse events. We developed a deep learning natural language processing algorithm to identify ADRs in discharge summaries at a single academic hospital centre. Our model was developed in two stages: first, a pre-trained model (DeBERTa) was further pre-trained on 1.1 million unlabelled clinical documents; secondly, this model was fine-tuned to detect ADR mentions in a corpus of 861 annotated discharge summaries. This model was compared to a version without the pre-training step, and a previously published RoBERTa model pretrained on MIMIC III, which has demonstrated strong performance on other pharmacovigilance tasks. To ensure that our algorithm could differentiate ADRs from other drug-related adverse events, the annotated corpus was enriched for both validated ADR reports and confounding drug-related adverse events using. The final model demonstrated good performance with a ROC–AUC of 0.955 (95% CI 0.933 - 0.978) for the task of identifying discharge summaries containing ADR mentions, significantly outperforming the two comparator models.}
}
",https://www.sciencedirect.com/science/article/pii/S1532046422002702,https://doi.org/10.1016/j.jbi.2022.104265,science_direct,2023
1325,DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language Processing,"@article{GAO2023104286,
title = {DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language Processing},
journal = {Journal of Biomedical Informatics},
volume = {138},
pages = {104286},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104286},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423000072},
author = {Yanjun Gao and Dmitriy Dligach and Timothy Miller and John Caskey and Brihat Sharma and Matthew M. Churpek and Majid Afshar},
keywords = {Natural language processing, Clinical diagnostic reasoning, Clinical diagnostic decision support, Clinical natural language processing benchmark},
abstract = {The meaningful use of electronic health records (EHR) continues to progress in the digital era with clinical decision support systems augmented by artificial intelligence. A priority in improving provider experience is to overcome information overload and reduce the cognitive burden so fewer medical errors and cognitive biases are introduced during patient care. One major type of medical error is diagnostic error due to systematic or predictable errors in judgement that rely on heuristics. The potential for clinical natural language processing (cNLP) to model diagnostic reasoning in humans with forward reasoning from data to diagnosis and potentially reduce cognitive burden and medical error has not been investigated. Existing tasks to advance the science in cNLP have largely focused on information extraction and named entity recognition through classification tasks. We introduce a novel suite of tasks coined as Diagnostic Reasoning Benchmarks, Dr.Bench, as a new benchmark for developing and evaluating cNLP models with clinical diagnostic reasoning ability. The suite includes six tasks from ten publicly available datasets addressing clinical text understanding, medical knowledge reasoning, and diagnosis generation. DR.BENCH is the first clinical suite of tasks designed to be a natural language generation framework to evaluate pre-trained language models for diagnostic reasoning. The goal of DR. BENCH is to advance the science in cNLP to support downstream applications in computerized diagnostic decision support and improve the efficiency and accuracy of healthcare providers during patient care. We fine-tune and evaluate the state-of-the-art generative models on DR.BENCH. Experiments show that with domain adaptation pre-training on medical knowledge, the model demonstrated opportunities for improvement when evaluated in DR. BENCH. We share DR. BENCH as a publicly available GitLab repository with a systematic approach to load and evaluate models for the cNLP community. We also discuss the carbon footprint produced during the experiments and encourage future work on DR.BENCH to report the carbon footprint.}
}
",https://www.sciencedirect.com/science/article/pii/S1532046423000072,https://doi.org/10.1016/j.jbi.2023.104286,science_direct,2023
1326,Learning entity-oriented representation for biomedical relation extraction,"@article{HU2023104527,
title = {Learning entity-oriented representation for biomedical relation extraction},
journal = {Journal of Biomedical Informatics},
volume = {147},
pages = {104527},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104527},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423002484},
author = {Ying Hu and Yanping Chen and Yongbin Qin and Ruizhang Huang},
keywords = {Biomedical natural language processing, Overlapping semantics, Information extraction},
abstract = {Biomedical Relation Extraction (BioRE) aims to automatically extract semantic relations for given entity pairs and is of great significance in biomedical research. Current popular methods often utilize pretrained language models to extract semantic features from individual input instances, which frequently suffer from overlapping semantics. Overlapping semantics refers to the situation in which a sentence contains multiple entity pairs that share the same context, leading to highly similar information between these entity pairs. In this study, we propose a model for learning Entity-oriented Representation (EoR) that aims to improve the performance of the model by enhancing the discriminability between entity pairs. It contains three modules: sentence representation, entity-oriented representation, and output. The first module learns the global semantic information of the input instance; the second module focuses on extracting the semantic information of the sentence from the target entities; and the third module enhances distinguishability among entity pairs and classifies the relation type. We evaluated our approach on four BioRE tasks with eight datasets, and the experiments showed that our EoR achieved state-of-the-art performance for PPI, DDI, CPI, and DPI tasks. Further analysis demonstrated the benefits of entity-oriented semantic information in handling multiple entity pairs in the BioRE task.}
}
",https://www.sciencedirect.com/science/article/pii/S1532046423002484,https://doi.org/10.1016/j.jbi.2023.104527,science_direct,2023
1327,Retrieval augmentation of large language models for lay language generation,"@article{GUO2024104580,
title = {Retrieval augmentation of large language models for lay language generation},
journal = {Journal of Biomedical Informatics},
volume = {149},
pages = {104580},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104580},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423003015},
author = {Yue Guo and Wei Qiu and Gondy Leroy and Sheng Wang and Trevor Cohen},
keywords = {Large language models, Retrieval-augmented model, Lay language summary, Background explanation, Text generation},
abstract = {The complex linguistic structures and specialized terminology of expert-authored content limit the accessibility of biomedical literature to the general public. Automated methods have the potential to render this literature more interpretable to readers with different educational backgrounds. Prior work has framed such lay language generation as a summarization or simplification task. However, adapting biomedical text for the lay public includes the additional and distinct task of background explanation: adding external content in the form of definitions, motivation, or examples to enhance comprehensibility. This task is especially challenging because the source document may not include the required background knowledge. Furthermore, background explanation capabilities have yet to be formally evaluated, and little is known about how best to enhance them. To address this problem, we introduce Retrieval-Augmented Lay Language (RALL) generation, which intuitively fits the need for external knowledge beyond that in expert-authored source documents. In addition, we introduce CELLS, the largest (63k pairs) and broadest-ranging (12 journals) parallel corpus for lay language generation. To evaluate RALL, we augmented state-of-the-art text generation models with information retrieval of either term definitions from the UMLS and Wikipedia, or embeddings of explanations from Wikipedia documents. Of these, embedding-based RALL models improved summary quality and simplicity while maintaining factual correctness, suggesting that Wikipedia is a helpful source for background explanation in this context. We also evaluated the ability of both an open-source Large Language Model (Llama 2) and a closed-source Large Language Model (GPT-4) in background explanation, with and without retrieval augmentation. Results indicate that these LLMs can generate simplified content, but that the summary quality is not ideal. Taken together, this work presents the first comprehensive study of background explanation for lay language generation, paving the path for disseminating scientific knowledge to a broader audience. Our code and data are publicly available at: https://github.com/LinguisticAnomalies/pls_retrieval.}
}
",https://www.sciencedirect.com/science/article/pii/S1532046423003015,https://doi.org/10.1016/j.jbi.2023.104580,science_direct,2024
1328,Evaluation of ChatGPT-generated medical responses: A systematic review and meta-analysis,"@article{WEI2024104620,
title = {Evaluation of ChatGPT-generated medical responses: A systematic review and meta-analysis},
journal = {Journal of Biomedical Informatics},
volume = {151},
pages = {104620},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104620},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000388},
author = {Qiuhong Wei and Zhengxiong Yao and Ying Cui and Bo Wei and Zhezhen Jin and Ximing Xu},
keywords = {ChatGPT, Large language model, Medicine, Evaluation},
abstract = {Objective
Large language models (LLMs) such as ChatGPT are increasingly explored in medical domains. However, the absence of standard guidelines for performance evaluation has led to methodological inconsistencies. This study aims to summarize the available evidence on evaluating ChatGPT’s performance in answering medical questions and provide direction for future research.
Methods
An extensive literature search was conducted on June 15, 2023, across ten medical databases. The keyword used was “ChatGPT,” without restrictions on publication type, language, or date. Studies evaluating ChatGPT's performance in answering medical questions were included. Exclusions comprised review articles, comments, patents, non-medical evaluations of ChatGPT, and preprint studies. Data was extracted on general study characteristics, question sources, conversation processes, assessment metrics, and performance of ChatGPT. An evaluation framework for LLM in medical inquiries was proposed by integrating insights from selected literature. This study is registered with PROSPERO, CRD42023456327.
Results
A total of 3520 articles were identified, of which 60 were reviewed and summarized in this paper and 17 were included in the meta-analysis. ChatGPT displayed an overall integrated accuracy of 56 % (95 % CI: 51 %–60 %, I2 = 87 %) in addressing medical queries. However, the studies varied in question resource, question-asking process, and evaluation metrics. As per our proposed evaluation framework, many studies failed to report methodological details, such as the date of inquiry, version of ChatGPT, and inter-rater consistency.
Conclusion
This review reveals ChatGPT's potential in addressing medical inquiries, but the heterogeneity of the study design and insufficient reporting might affect the results’ reliability. Our proposed evaluation framework provides insights for the future study design and transparent reporting of LLM in responding to medical questions.}
}
",https://www.sciencedirect.com/science/article/pii/S1532046424000388,https://doi.org/10.1016/j.jbi.2024.104620,science_direct,2024
1329,"Identifying social determinants of health from clinical narratives: A study of performance, documentation ratio, and potential bias","@article{YU2024104642,
title = {Identifying social determinants of health from clinical narratives: A study of performance, documentation ratio, and potential bias},
journal = {Journal of Biomedical Informatics},
volume = {153},
pages = {104642},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104642},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000601},
author = {Zehao Yu and Cheng Peng and Xi Yang and Chong Dang and Prakash Adekkanattu and Braja {Gopal Patra} and Yifan Peng and Jyotishman Pathak and Debbie L. Wilson and Ching-Yuan Chang and Wei-Hsuan Lo-Ciganic and Thomas J. George and William R. Hogan and Yi Guo and Jiang Bian and Yonghui Wu},
keywords = {Social determinants of health, Large language model, Transformer, Clinical concept extraction, Natural language processing, Cancer},
abstract = {Objective
To develop a natural language processing (NLP) package to extract social determinants of health (SDoH) from clinical narratives, examine the bias among race and gender groups, test the generalizability of extracting SDoH for different disease groups, and examine population-level extraction ratio.
Methods
We developed SDoH corpora using clinical notes identified at the University of Florida (UF) Health. We systematically compared 7 transformer-based large language models (LLMs) and developed an open-source package – SODA (i.e., SOcial DeterminAnts) to facilitate SDoH extraction from clinical narratives. We examined the performance and potential bias of SODA for different race and gender groups, tested the generalizability of SODA using two disease domains including cancer and opioid use, and explored strategies for improvement. We applied SODA to extract 19 categories of SDoH from the breast (n = 7,971), lung (n = 11,804), and colorectal cancer (n = 6,240) cohorts to assess patient-level extraction ratio and examine the differences among race and gender groups.
Results
We developed an SDoH corpus using 629 clinical notes of cancer patients with annotations of 13,193 SDoH concepts/attributes from 19 categories of SDoH, and another cross-disease validation corpus using 200 notes from opioid use patients with 4,342 SDoH concepts/attributes. We compared 7 transformer models and the GatorTron model achieved the best mean average strict/lenient F1 scores of 0.9122 and 0.9367 for SDoH concept extraction and 0.9584 and 0.9593 for linking attributes to SDoH concepts. There is a small performance gap (∼4%) between Males and Females, but a large performance gap (>16 %) among race groups. The performance dropped when we applied the cancer SDoH model to the opioid cohort; fine-tuning using a smaller opioid SDoH corpus improved the performance. The extraction ratio varied in the three cancer cohorts, in which 10 SDoH could be extracted from over 70 % of cancer patients, but 9 SDoH could be extracted from less than 70 % of cancer patients. Individuals from the White and Black groups have a higher extraction ratio than other minority race groups.
Conclusions
Our SODA package achieved good performance in extracting 19 categories of SDoH from clinical narratives. The SODA package with pre-trained transformer models is available at https://github.com/uf-hobi-informatics-lab/SODA_Docker.}
}
",https://www.sciencedirect.com/science/article/pii/S1532046424000601,https://doi.org/10.1016/j.jbi.2024.104642,science_direct,2024
1330,Opportunities for incorporating intersectionality into biomedical informatics,"@article{BEARDONTWALK2024104653,
title = {Opportunities for incorporating intersectionality into biomedical informatics},
journal = {Journal of Biomedical Informatics},
volume = {154},
pages = {104653},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104653},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000716},
author = {Oliver J. {Bear Don't Walk} and Amandalynne Paullada and Avery Everhart and Reggie Casanova-Perez and Trevor Cohen and Tiffany Veinot},
keywords = {Biomedical Informatics, Intersectionality, Qualitative research, Quantitative research, Mixed-methods research, Systems of privilege and oppression},
abstract = {Many approaches in biomedical informatics (BMI) rely on the ability to define, gather, and manipulate biomedical data to support health through a cyclical research-practice lifecycle. Researchers within this field are often fortunate to work closely with healthcare and public health systems to influence data generation and capture and have access to a vast amount of biomedical data. Many informaticists also have the expertise to engage with stakeholders, develop new methods and applications, and influence policy. However, research and policy that explicitly seeks to address the systemic drivers of health would more effectively support health. Intersectionality is a theoretical framework that can facilitate such research. It holds that individual human experiences reflect larger socio-structural level systems of privilege and oppression, and cannot be truly understood if these systems are examined in isolation. Intersectionality explicitly accounts for the interrelated nature of systems of privilege and oppression, providing a lens through which to examine and challenge inequities. In this paper, we propose intersectionality as an intervention into how we conduct BMI research. We begin by discussing intersectionality’s history and core principles as they apply to BMI. We then elaborate on the potential for intersectionality to stimulate BMI research. Specifically, we posit that our efforts in BMI to improve health should address intersectionality’s five key considerations: (1) systems of privilege and oppression that shape health; (2) the interrelated nature of upstream health drivers; (3) the nuances of health outcomes within groups; (4) the problematic and power-laden nature of categories that we assign to people in research and in society; and (5) research to inform and support social change.}
}
",https://www.sciencedirect.com/science/article/pii/S1532046424000716,https://doi.org/10.1016/j.jbi.2024.104653,science_direct,2024
1331,"Unveiling security, privacy, and ethical concerns of ChatGPT","@article{WU2024102,
title = {Unveiling security, privacy, and ethical concerns of ChatGPT},
journal = {Journal of Information and Intelligence},
volume = {2},
number = {2},
pages = {102-115},
year = {2024},
issn = {2949-7159},
doi = {https://doi.org/10.1016/j.jiixd.2023.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S2949715923000707},
author = {Xiaodong Wu and Ran Duan and Jianbing Ni},
keywords = {ChatGPT, Large language model (LLM), Security, Privacy, Ethics},
abstract = {This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.}
}
",https://www.sciencedirect.com/science/article/pii/S2949715923000707,https://doi.org/10.1016/j.jiixd.2023.10.007,science_direct,2024
1332,Connecting the indispensable roles of IoT and artificial intelligence in smart cities: A survey,"@article{NGUYEN2024261,
title = {Connecting the indispensable roles of IoT and artificial intelligence in smart cities: A survey},
journal = {Journal of Information and Intelligence},
volume = {2},
number = {3},
pages = {261-285},
year = {2024},
issn = {2949-7159},
doi = {https://doi.org/10.1016/j.jiixd.2024.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949715924000039},
author = {Hoang Nguyen and Dina Nawara and Rasha Kashef},
keywords = {Smart city, Internet of Things, Artificial intelligence, Machine learning, Deep learning},
abstract = {The pace of society development is faster than ever before, and the smart city paradigm has also emerged, which aims to enable citizens to live in more sustainable cities that guarantee well-being and a comfortable living environment. This has been done by a network of new technologies hosted in real time to track the activities and provide smart solutions for the incoming requests or problems of the citizens. One of the most often used methodologies for creating a smart city is the Internet of Things (IoT). Therefore, the IoT-enabled smart city research topic, which consists of many different domains such as transportation, healthcare, and agriculture, has recently attracted increasing attention in the research community. Further, advances in artificial intelligence (AI) significantly contribute to the growth of IoT. In this paper, we first present the smart city concept, the background of smart city development and the components of the IoT-based smart city. This is followed up by a literature review of the research literature on the most recent IoT-enabled smart cities developments and breakthroughs empowered by AI techniques to highlight the current stage, major trends and unsolved challenges of adopting AI-driven IoT technologies for the establishment of desirable smart cities. Finally, we summarize the paper with a discussion of future research to provide recommendations for research direction in the smart city domain.}
}
",https://www.sciencedirect.com/science/article/pii/S2949715924000039,https://doi.org/10.1016/j.jiixd.2024.01.003,science_direct,2024
1333,A comprehensive evaluation on the benefits of context based password cracking for digital forensics,"@article{KANTA2024103809,
title = {A comprehensive evaluation on the benefits of context based password cracking for digital forensics},
journal = {Journal of Information Security and Applications},
volume = {84},
pages = {103809},
year = {2024},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103809},
url = {https://www.sciencedirect.com/science/article/pii/S2214212624001121},
author = {Aikaterini Kanta and Iwen Coisel and Mark Scanlon},
keywords = {Password, Dictionary, Contextual information, Password cracking, Wordlist},
abstract = {Password-based authentication systems have many weaknesses, yet they remain overwhelmingly used and their announced disappearance is still undated. The system admin overcomes the imperfection by skilfully enforcing a strong password policy and sane password management on the server side. But in the end, the user behind the password is still responsible for the password’s strength. A poor choice can have dramatic consequences for the user or even for the service behind, especially considering critical infrastructure. On the other hand, law enforcement can benefit from a suspect’s weak decisions to recover digital content stored in an encrypted format. Generic password cracking procedures can support law enforcement in this matter — however, these approaches quickly demonstrate their limitations. This article proves that more targeted approaches can be used in combination with traditional strategies to increase the likelihood of success when contextual information is available and can be exploited.}
}
",https://www.sciencedirect.com/science/article/pii/S2214212624001121,https://doi.org/10.1016/j.jisa.2024.103809,science_direct,2024
1334,Adoption and impacts of generative artificial intelligence: Theoretical underpinnings and research agenda,"@article{GUPTA2024100232,
title = {Adoption and impacts of generative artificial intelligence: Theoretical underpinnings and research agenda},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {1},
pages = {100232},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000211},
author = {Ruchi Gupta and Kiran Nair and Mahima Mishra and Blend Ibrahim and Seema Bhardwaj},
keywords = {ChatGPT, Adoption, Generative AI, Chatbots},
abstract = {Large language models (LLMs) have received considerable interest in the field of natural language processing (NLP) owing to their remarkable ability to generate clear, consistent, and contextually relevant materials. Among the numerous LLMs, ChatGPT (Generative Pre-trained Transformer for Chatbots) is emerging as a prominent prospective tool for developing conversational agents such as chatbots. However, there is a need for a clear conceptual understanding of ChatGPT's potential implications for the industry and its role in marketing. This study explores the adoption of ChatGPT in marketing and examines theories that may influence its adoption by marketers and consumers, as well as its implications for marketers. This study discusses how ChatGPT may allow for more personalized and engaging content, better customer experience, and improved ROI. However, adoption also brings challenges, including ethical considerations and the need for new skill development. This study also discusses future research opportunities for the adoption of ChatGPT and other generative artificial intelligence technologies in marketing. The goal is to provide insights for organizations that consider implementing these technologies, and to contribute to the literature on the adoption of Artificial Intelligence (AI) and the use of Generative AI in marketing.}
}
",https://www.sciencedirect.com/science/article/pii/S2667096824000211,https://doi.org/10.1016/j.jjimei.2024.100232,science_direct,2024
1335,Balancing act: Tackling organized retail fraud on e-commerce platforms with imbalanced learning text models,"@article{MUTEMI2024100256,
title = {Balancing act: Tackling organized retail fraud on e-commerce platforms with imbalanced learning text models},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {2},
pages = {100256},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100256},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000454},
author = {Abed Mutemi and Fernando Bacao},
keywords = {Fraud detection, Machine learning, Text classification, E-commerce, Text mining, Natural language processing, Word representation learning, Text data augmentation},
abstract = {As online shopping expands rapidly, so does the prevalence of fraud, resulting in significant losses for retailers. According to the 2020 National Retail Federation (NRF) report, organized retail crime costs retailers nearly $800,000 per billion in sales, with an expected global annual increase of over fourteen percent. This paper introduces a text-based fraud detection framework to mitigate these losses efficiently. The framework comprises four key components: text preprocessing, representation, knowledge extraction via machine learning algorithms, and model evaluation. By integrating data augmentation techniques, the framework enhances classifier performance in detecting fraud. The proposed method, employing a combination of FastText and Random Forest classifiers, achieves an impressive F1 score of 0.833 and AUC score of 0.99 on an augmented dataset, surpassing conventional keyword-based models. Informed by best practices in fraud detection, this scalable framework promises a solution to combat the escalating fraud associated with the exponential growth of online shopping.}
}
",https://www.sciencedirect.com/science/article/pii/S2667096824000454,https://doi.org/10.1016/j.jjimei.2024.100256,science_direct,2024
1336,Enhanced DSSM (deep semantic structure modelling) technique for job recommendation,"@article{MISHRA20227790,
title = {Enhanced DSSM (deep semantic structure modelling) technique for job recommendation},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {9},
pages = {7790-7802},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821001853},
author = {Ravita Mishra and Sheetal Rathi},
keywords = {Content Based Filtering (CB), BM25, Collaborative Filtering (CF), DSSM (Deep semantic structure modeling), Hybrid Filtering (HF), Adam Optimizer, LSTM ( Long Short Term Memory ).},
abstract = {Now a day’s recommendation system take care of the issue of the massive amount of information overload problem and it provides the services to the candidates to concentrate on relevant information on job domain only. The job recommender system plays an important role in the recruitment process of fresher as well as experienced today. Existing job recommender system mainly focuses on content-based filtering to extricate profile content and on collaborative filtering to capture the behaviour of the user in the form of rating. Dynamic nature of job market leads cold start and scalability issues. This problem can be addressed by item-based collaborative filtering with a machine learning technique, it learns job embedding vector and finds similar jobs content-wise. Existing model in job recommender domain uses the confining model to address the cold start and scalability issue and provide better recommendation, but they fail to accept the complex relationships between job description and candidate profile. In this paper, we are proposing a Deep Semantic Structure Algorithm that overcome the issue of the existing system. Deep semantic structure modelling (DSSM) system uses the semantic representation of sparse data and it represent the job description and skill entities in character trigram format which increases the efficacy of the system. We are comparing the results to three variation of DSSM model with two different dataset (Naukari.com and CareerBuilder. com) and it gives satisfactory results. Experimental results shows that the DSSM Embedding model and its other variants are provides promising results in solving cold start problem in comparison with several variants of embedding model. We used Xavier initializer to initialise the model parameter and Adam optimizer to optimize the system performance.}
}
",https://www.sciencedirect.com/science/article/pii/S1319157821001853,https://doi.org/10.1016/j.jksuci.2021.07.018,science_direct,2022
1337,SRL-ACO: A text augmentation framework based on semantic role labeling and ant colony optimization,"@article{ONAN2023101611,
title = {SRL-ACO: A text augmentation framework based on semantic role labeling and ant colony optimization},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {7},
pages = {101611},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101611},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823001659},
author = {Aytuğ Onan},
keywords = {Data augmentation, Text classification, Deep learning, Sarcasm identification},
abstract = {The process of creating high-quality labeled data is crucial for training machine-learning models, but it can be a time-consuming and labor-intensive process. Moreover, manual annotation by human annotators can lead to varying degrees of competency, training, and experience, which can result in inconsistent labeling and arbitrary standards. To address these challenges, researchers have been exploring automated methods for enhancing training and testing datasets. This paper proposes SRL-ACO, a novel text augmentation framework that leverages Semantic Role Labeling (SRL) and Ant Colony Optimization (ACO) techniques to generate additional training data for natural language processing (NLP) models. The framework uses SRL to identify the semantic roles of words in a sentence and ACO to generate new sentences that preserve these roles. SRL-ACO can enhance the accuracy of NLP models by generating additional data without requiring manual data annotation. The paper presents experimental results demonstrating the effectiveness of SRL-ACO on seven text classification datasets for sentiment analysis, toxic text detection and sarcasm identification. The results show that SRL-ACO improves the performance of a classifier on different NLP tasks. These results demonstrate that SRL-ACO has the potential to enhance the quality and quantity of training data for various NLP tasks.}
}
",https://www.sciencedirect.com/science/article/pii/S1319157823001659,https://doi.org/10.1016/j.jksuci.2023.101611,science_direct,2023
1338,"Decoding ChatGPT: A taxonomy of existing research, current challenges, and possible future directions","@article{SOHAIL2023101675,
title = {Decoding ChatGPT: A taxonomy of existing research, current challenges, and possible future directions},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {8},
pages = {101675},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101675},
url = {https://www.sciencedirect.com/science/article/pii/S131915782300229X},
author = {Shahab Saquib Sohail and Faiza Farhat and Yassine Himeur and Mohammad Nadeem and Dag Øivind Madsen and Yashbir Singh and Shadi Atalla and Wathiq Mansoor},
keywords = {ChatGPT, Large language models (LLMs), Generative Pre-trained Transformer (GPT), AI Generated Content (AIGC), Systematic review, Trustworthy AI},
abstract = {Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022. It has shown impressive performance in various domains, including passing exams and creative writing. However, challenges and concerns related to biases and trust persist. In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications. We critically analyze the existing literature, identifying common approaches employed in the studies. Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges. We also discuss crucial issues related to ChatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas. Furthermore, we identify potential future directions for ChatGPT research, proposing solutions to current challenges and speculating on expected advancements. By fully leveraging the capabilities of ChatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society.}
}
",https://www.sciencedirect.com/science/article/pii/S131915782300229X,https://doi.org/10.1016/j.jksuci.2023.101675,science_direct,2023
1339,Enhanced subgraph matching for large graphs using candidate region-based decomposition and ordering,"@article{ANSARI2023101694,
title = {Enhanced subgraph matching for large graphs using candidate region-based decomposition and ordering},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {8},
pages = {101694},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101694},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823002483},
author = {Zubair Ali Ansari and Md. Aslam Parwez and Irfan Rashid Thoker and  Jahiruddin},
keywords = {Subgraph isomorphism, Graph search, Eccentricity, Candidate region ordering, Large graph, Embedding, Straggler query},
abstract = {The subgraph matching problem associated with large graphs is an emerging research challenge in graph search due to the growing size of the web, social, and metabolic graphs, and the wide availability of graph databases. Such problems involve finding all instances (aka embedding) of the small-sized query graph in the associated large-sized reference graph. Many state-of-the-art algorithms, including VF3, RI, CFL-Match, and Glasgow, exist to solve subgraph matching problem. RI is one of the fastest subgraph matching algorithms focusing mainly on time efficiency performance measures. However, other performance measures, such as the number of found instances of the query graph (embedding count), the method of ordering the query graph’s vertices, and the number of recursive calls, are crucial for the efficiency and effectiveness of the subgraph matching. In this paper, the RI+ algorithm is proposed as an enhanced version of RI, which has been designed using candidate region-based decomposition and ordering. Three novel candidate region orderings have been introduced, namely vertex-count, density, and average-path-length, based on the structural properties of the candidate regions. On empirical analysis of RI+ on real-world data sets, it was observed that RI+ shows significant improvement in efficiency and effectiveness over RI on both performance evaluation measures, namely, embedding count and search time. The influence of the proposed candidate region orderings on the search time of RI+ was also analyzed, revealing that a suitable candidate region ordering has the potential to improve the search time of the proposed algorithm.}
}
",https://www.sciencedirect.com/science/article/pii/S1319157823002483,https://doi.org/10.1016/j.jksuci.2023.101694,science_direct,2023
1340,EnhancedBERT: A feature-rich ensemble model for Arabic word sense disambiguation with statistical analysis and optimized data collection,"@article{KADDOURA2024101911,
title = {EnhancedBERT: A feature-rich ensemble model for Arabic word sense disambiguation with statistical analysis and optimized data collection},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {1},
pages = {101911},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101911},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823004652},
author = {Sanaa Kaddoura and Reem Nassar},
keywords = {Arabic natural language processing, Word sense disambiguation, Machine learning, Knowledge-based, BERT, Performance evaluation},
abstract = {Accurate assignment of meaning to a word based on its context, known as Word Sense Disambiguation (WSD), remains challenging across languages. Extensive research aims to develop automated methods for determining word senses in different contexts. However, the literature lacks the presence of datasets generated for the Arabic language WSD. This paper presents a dataset comprising a hundred polysemous Arabic words. Each word in the dataset encompasses 3–8 distinct senses, with ten example sentences per sense. Some statistical operations are conducted to gain insights into the dataset, enlightening its characteristics and properties. Subsequently, a novel WSD approach is proposed to utilize similarity measures and find the overlap between contextual information and dictionary definitions. The proposed method uses the power of BERT, a pre-trained language model, to enable effective Arabic word disambiguation. In training, new features are integrated to improve the model's ability to differentiate between various senses of words. The proposed BERT models are combined to compose an ensemble model architecture to improve the classification performances. The performance of the WSD system outperforms state-of-the-art systems, achieving an approximate F1-score of 96 %. Statistical analyses are performed to evaluate the overall performance of the WSD approach by providing additional information on model predictions. A case study was implemented to test the effectiveness of WSD in sentiment analysis, a downstream task.}
}
",https://www.sciencedirect.com/science/article/pii/S1319157823004652,https://doi.org/10.1016/j.jksuci.2023.101911,science_direct,2024
1341,MTLink: Adaptive multi-task learning based pre-trained language model for traceability link recovery between issues and commits,"@article{DENG2024101958,
title = {MTLink: Adaptive multi-task learning based pre-trained language model for traceability link recovery between issues and commits},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {2},
pages = {101958},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.101958},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824000478},
author = {Yang Deng and Bangchao Wang and Qiang Zhu and Junping Liu and Jiewen Kuang and Xingfu Li},
keywords = {Issue-commit link recovery, Multi-teacher knowledge distillation, Adaptive multi-task},
abstract = {Traceability links between issues and commits (issue-commit links recovery (ILR)) play a significant role in software maintenance tasks by enhancing developers’ observability in practice. Recent advancements in large language models, particularly pre-trained models, have improved the effectiveness of automated ILR. However, these models’ large parameter sizes and extended training time pose challenges in large software projects. Besides, existing methods often overlook the association and distinction among artifacts, leading to the generation of erroneous links. To mitigate these problems, this paper proposes a novel link recovery method called MTLink. It utilizes multi-teacher knowledge distillation (MTKD) to compress the model and employs an adaptive multi-task strategy to reduce information loss and improve link accuracy. Experiments are conducted on four open-source projects. The results show that (i) MTLink outperforms state-of-the-art methods; (ii) The multi-teacher knowledge distillation maintains accuracy despite model size reduction; (iii) The adaptive multi-task tracing method effectively handles confusion caused by similar artifacts and balances each task. In conclusion, MTLink offers an efficient solution for ILR in software traceability. The code is available at https://zenodo.org/records/10321150.}
}
",https://www.sciencedirect.com/science/article/pii/S1319157824000478,https://doi.org/10.1016/j.jksuci.2024.101958,science_direct,2024
1342,"Sentiment analysis methods, applications, and challenges: A systematic literature review","@article{MAO2024102048,
title = {Sentiment analysis methods, applications, and challenges: A systematic literature review},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {4},
pages = {102048},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102048},
url = {https://www.sciencedirect.com/science/article/pii/S131915782400137X},
author = {Yanying Mao and Qun Liu and Yu Zhang},
keywords = {Sentiment analysis, Methods, Applications, Large language models, Challenges},
abstract = {With the expansion of Internet-based applications, the number of comments shows explosive growth. Analyzing the attitudes and emotions behind comments provides powerful assistance for businesses, governments, and scholars. However, it is hard to effectively extract user’s attitude from the massive amounts of comments. Sentiment analysis (SA) provides an automatic, fast and efficient tool to identify reviewers’ opinions and sentiments. However, the existing literature reviews cover a limited number of studies or have a narrow field of studies for sentiment analysis. This paper provided a systematic literature review of sentiment analysis methods, applications, and challenges. This systematic literature review gives insights into the goal of the sentiment analysis task, offers comparisons of different techniques, investigates the application domains of sentiment analysis, highlights the challenges and limitations encountered by scholars, provides suggestions on possible solutions and explores the future research directions. The study’s findings emphasize the significant role of artificial intelligence technologies in automatic text sentiment analysis and highlight the importance of sentiment analysis in people’s production and life. This research not only contributes to the existing sentiment analysis knowledge body but also provides references to scholars and practitioners in choosing a suitable methodology and good practices to perform sentiment analysis.}
}
",https://www.sciencedirect.com/science/article/pii/S131915782400137X,https://doi.org/10.1016/j.jksuci.2024.102048,science_direct,2024
1343,DTL-IDS: An optimized Intrusion Detection Framework using Deep Transfer Learning and Genetic Algorithm,"@article{LATIF2024103784,
title = {DTL-IDS: An optimized Intrusion Detection Framework using Deep Transfer Learning and Genetic Algorithm},
journal = {Journal of Network and Computer Applications},
volume = {221},
pages = {103784},
year = {2024},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2023.103784},
url = {https://www.sciencedirect.com/science/article/pii/S1084804523002035},
author = {Shahid Latif and Wadii Boulila and Anis Koubaa and Zhuo Zou and Jawad Ahmad},
keywords = {Cybersecurity, Genetic Algorithm, IIoT, Intrusion Detection, Transfer learning},
abstract = {In the dynamic field of the Industrial Internet of Things (IIoT), the networks are increasingly vulnerable to a diverse range of cyberattacks. This vulnerability necessitates the development of advanced intrusion detection systems (IDSs). Addressing this need, our research contributes to the existing cybersecurity literature by introducing an optimized Intrusion Detection System based on Deep Transfer Learning (DTL), specifically tailored for heterogeneous IIoT networks. Our framework employs a tri-layer architectural approach that synergistically integrates Convolutional Neural Networks (CNNs), Genetic Algorithms (GA), and bootstrap aggregation ensemble techniques. The methodology is executed in three critical stages: First, we convert a state-of-the-art cybersecurity dataset, Edge_IIoTset, into image data, thereby facilitating CNN-based analytics. Second, GA is utilized to fine-tune the hyperparameters of each base learning model, enhancing the model’s adaptability and performance. Finally, the outputs of the top-performing models are amalgamated using ensemble techniques, bolstering the robustness of the IDS. Through rigorous evaluation protocols, our framework demonstrated exceptional performance, reliably achieving a 100% attack detection accuracy rate. This result establishes our framework as highly effective against 14 distinct types of cyberattacks. The findings bear significant implications for the ongoing development of secure, efficient, and adaptive IDS solutions in the complex landscape of IIoT networks.}
}
",https://www.sciencedirect.com/science/article/pii/S1084804523002035,https://doi.org/10.1016/j.jnca.2023.103784,science_direct,2024
1344,"Exploring the integration of edge computing and blockchain IoT: Principles, architectures, security, and applications","@article{NGUYEN2024103884,
title = {Exploring the integration of edge computing and blockchain IoT: Principles, architectures, security, and applications},
journal = {Journal of Network and Computer Applications},
volume = {226},
pages = {103884},
year = {2024},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2024.103884},
url = {https://www.sciencedirect.com/science/article/pii/S1084804524000614},
author = {Tri Nguyen and Huong Nguyen and Tuan {Nguyen Gia}},
keywords = {Edge computing, Blockchain, Internet-of-thing, Architecture, Security, Application},
abstract = {IoT systems are widely used in various applications, including healthcare, agriculture, manufacturing, and smart cities. However, these systems still have limitations, such as lack of security, high latency, energy inefficiency, the inefficiency of bandwidth utilization, and shortage of automaticity. The integration of edge computing and blockchain into IoT has been proposed to address these limitations. Yet, this integration is challenging and has not been deeply investigated. This paper aims to conduct a review of the integration of edge computing and blockchain into IoT systems. To the best of our knowledge, this is the first review paper that covers all aspects of system architectures and categories of blockchain-based edge deployment, complete security requirements, including confidentiality, integrity, authentication, authorization/access control, privacy, trust/confidence, transparency, availability, secure automaticity, and tolerance, and applications of blockchain-based edge potential usages with consideration of security requirements. Additionally, this review provides comprehensive discussions of challenges and insights into the future direction of blockchain-based edge IoT systems. The review aims to serve as an entry point for non-expert readers and researchers to various aspects of blockchain-based edge IoT systems.}
}
",https://www.sciencedirect.com/science/article/pii/S1084804524000614,https://doi.org/10.1016/j.jnca.2024.103884,science_direct,2024
1345,ChatGPT and the rise of generative AI: Threat to academic integrity?,"@article{EKE2023100060,
title = {ChatGPT and the rise of generative AI: Threat to academic integrity?},
journal = {Journal of Responsible Technology},
volume = {13},
pages = {100060},
year = {2023},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2023.100060},
url = {https://www.sciencedirect.com/science/article/pii/S2666659623000033},
author = {Damian Okaibedi Eke},
keywords = {ChatGPT, Large language models, OpenAI, Academic integrity, Generative AI},
abstract = {The emergence of OpenAI's ChatGPT has put intense spotlight on Generative AI (Gen-AI) systems and their possible impacts on Academic integrity. This paper provides an overview of the current arguments around ChatGPT and Academic integrity and concludes that although these technologies are capable of revolutionising academia, the way ChatGPT and other generative AI systems are used could surely undermine academic integrity. However, to ensure that the risks to academic integrity are mitigated for greater maximisation, institutional and multi-stakeholder efforts are required.}
}
",https://www.sciencedirect.com/science/article/pii/S2666659623000033,https://doi.org/10.1016/j.jrt.2023.100060,science_direct,2023
1346,Do we really need a “Digital Humanism”? A critique based on post-human philosophy of technology and socio-legal techniques,"@article{BUONGIORNO2024100080,
title = {Do we really need a “Digital Humanism”? A critique based on post-human philosophy of technology and socio-legal techniques},
journal = {Journal of Responsible Technology},
volume = {18},
pages = {100080},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100080},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000064},
author = {Federica Buongiorno and Xenia Chiaramonte},
keywords = {Digital humanism, Posthumanism, AI, Accountability, Hybrids},
abstract = {Few concepts have been subjected to as intense scrutiny in contemporary discourse as that of “humanism.” While these critiques have acknowledged the importance of retaining certain key aspects of humanism, such as rights, freedom, and human dignity, the term has assumed ambivalence, especially in light of post-colonial and gender studies, that cannot be ignored. The “Vienna Manifesto on Digital Humanism,” as well as the recent volume (2022) titled Perspectives on Digital Humanism, bear a complex imprint of this ambivalence. In this contribution, we aim to bring to the forefront and decipher this underlying trace, by considering alternative (non-humanistic) ways to understand human-technologies relations, beyond the dominant neoliberal paradigm (paragraphs 1 and 2); we then analyse those relations within the specific context of legal studies (paragraphs 3 and 4), one in which the interdependency of humans and non-humans shows a specific and complex form of “fundamental ambivalence.”}
}
",https://www.sciencedirect.com/science/article/pii/S2666659624000064,https://doi.org/10.1016/j.jrt.2024.100080,science_direct,2024
1347,"Infrastructural justice for responsible software engineering,","@article{ROBINSON2024100087,
title = {Infrastructural justice for responsible software engineering,},
journal = {Journal of Responsible Technology},
volume = {19},
pages = {100087},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100087},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000131},
author = {Sarah Robinson and Jim Buckley and Luigina Ciolfi and Conor Linehan and Clare McInerney and Bashar Nuseibeh and John Twomey and Irum Rauf and John McCarthy},
keywords = {Responsible software engineering, Infrastructure, Social connection model of responsibility, Installed base, Deepfake technology},
abstract = {In recent years, we have seen many examples of software products unintentionally causing demonstrable harm. Many guidelines for ethical and responsible computing have been developed in response. Dominant approaches typically attribute liability and blame to individual companies or actors, rather than understanding how the working practices, norms, and cultural understandings in the software industry contribute to such outcomes. In this paper, we propose an understanding of responsibility that is infrastructural, relational, and cultural; thus, providing a foundation to better enable responsible software engineering into the future. Our approach draws on Young's (2006) social connection model of responsibility and Star and Ruhleder's (1994) concept of infrastructure. By bringing these theories together we introduce a concept called infrastructural injustice, which offers a new way for software engineers to consider their opportunities for responsible action with respect to society and the planet. We illustrate the utility of this approach by applying it to an Open-Source software communities’ development of Deepfake technology, to find key leverage points of responsibility that are relevant to both Deepfake technology and software engineering more broadly.}
}
",https://www.sciencedirect.com/science/article/pii/S2666659624000131,https://doi.org/10.1016/j.jrt.2024.100087,science_direct,2024
1348,Ethical management of human-AI interaction: Theory development review,"@article{HEYDER2023101772,
title = {Ethical management of human-AI interaction: Theory development review},
journal = {The Journal of Strategic Information Systems},
volume = {32},
number = {3},
pages = {101772},
year = {2023},
issn = {0963-8687},
doi = {https://doi.org/10.1016/j.jsis.2023.101772},
url = {https://www.sciencedirect.com/science/article/pii/S0963868723000185},
author = {Teresa Heyder and Nina Passlack and Oliver Posegga},
keywords = {Artificial intelligence, Ethics, Human-AI interaction, Theoretical review, Sociomateriality},
abstract = {AI-based technologies have changed the nature of the symbiosis between humans and AI, and so strategic management of human-AI interaction in organizations requires deeper ethical considerations. Aligning AI with human values requires a systematic understanding of the ethical management of human-AI interaction. We conduct a theoretical review, from a sociotechnical perspective, and analyze ethical management of human-AI interaction through the lens of sociomateriality. Our systematic approach helps explain and clarify the interdependencies between two ethical perspectives – duty and virtue ethics – in sociotechnical systems. We also provide a theoretical framework that leads to seven avenues for future research.}
}
",https://www.sciencedirect.com/science/article/pii/S0963868723000185,https://doi.org/10.1016/j.jsis.2023.101772,science_direct,2023
1349,GitHub Copilot AI pair programmer: Asset or Liability?,"@article{MORADIDAKHEL2023111734,
title = {GitHub Copilot AI pair programmer: Asset or Liability?},
journal = {Journal of Systems and Software},
volume = {203},
pages = {111734},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111734},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223001292},
author = {Arghavan {Moradi Dakhel} and Vahid Majdinasab and Amin Nikanjam and Foutse Khomh and Michel C. Desmarais and Zhen Ming (Jack) Jiang},
keywords = {Code completion, Language model, GitHub copilot, Testing},
abstract = {Automatic program synthesis is a long-lasting dream in software engineering. Recently, a promising Deep Learning (DL) based solution, called Copilot, has been proposed by OpenAI and Microsoft as an industrial product. Although some studies evaluate the correctness of Copilot solutions and report its issues, more empirical evaluations are necessary to understand how developers can benefit from it effectively. In this paper, we study the capabilities of Copilot in two different programming tasks: (i) generating (and reproducing) correct and efficient solutions for fundamental algorithmic problems, and (ii) comparing Copilot’s proposed solutions with those of human programmers on a set of programming tasks. For the former, we assess the performance and functionality of Copilot in solving selected fundamental problems in computer science, like sorting and implementing data structures. In the latter, a dataset of programming problems with human-provided solutions is used. The results show that Copilot is capable of providing solutions for almost all fundamental algorithmic problems, however, some solutions are buggy and non-reproducible. Moreover, Copilot has some difficulties in combining multiple methods to generate a solution. Comparing Copilot to humans, our results show that the correct ratio of humans’ solutions is greater than Copilot’s suggestions, while the buggy solutions generated by Copilot require less effort to be repaired. Based on our findings, if Copilot is used by expert developers in software projects, it can become an asset since its suggestions could be comparable to humans’ contributions in terms of quality. However, Copilot can become a liability if it is used by novice developers who may fail to filter its buggy or non-optimal solutions due to a lack of expertise.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121223001292,https://doi.org/10.1016/j.jss.2023.111734,science_direct,2023
1350,Out of the BLEU: How should we assess quality of the Code Generation models?,"@article{EVTIKHIEV2023111741,
title = {Out of the BLEU: How should we assess quality of the Code Generation models?},
journal = {Journal of Systems and Software},
volume = {203},
pages = {111741},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111741},
url = {https://www.sciencedirect.com/science/article/pii/S016412122300136X},
author = {Mikhail Evtikhiev and Egor Bogomolov and Yaroslav Sokolov and Timofey Bryksin},
keywords = {Code generation, Metrics, Neural networks, Code similarity},
abstract = {In recent years, researchers have created and introduced a significant number of various code generation models. As human evaluation of every new model version is unfeasible, the community adopted automatic evaluation metrics such as BLEU to approximate the results of human judgement. These metrics originate from the machine translation domain and it is unclear whether they are applicable for the code generation tasks and how well they agree with the human evaluation on this task. There are also other metrics, CodeBLEU and RUBY, developed to estimate the similarity of code, that take into account the properties of source code. However, for these metrics there are hardly any studies on their agreement with the human evaluation. Despite all that, minimal differences in the metric scores have been used in recent papers to claim superiority of some code generation models over the others. In this paper, we present a study on the applicability of six metrics—BLEU, ROUGE-L, METEOR, ChrF, CodeBLEU, and RUBY—for evaluation of code generation models. We conduct a study on two different code generation datasets and use human annotators to assess the quality of all models run on these datasets. The results indicate that for the CoNaLa dataset of Python one-liners, none of the metrics can correctly emulate human judgement on which model is better with >95% certainty if the difference in model scores is less than 5 points. For the HearthStone dataset, which consists of classes of a particular structure, a difference in model scores of at least 2 points is enough to claim the superiority of one model over the other. Our findings suggest that the ChrF metric is a better fit for the evaluation of code generation models than the commonly used BLEU and CodeBLEU. Yet, finding a metric for code generation that closely agrees with humans requires additional work.}
}
",https://www.sciencedirect.com/science/article/pii/S016412122300136X,https://doi.org/10.1016/j.jss.2023.111741,science_direct,2023
1351,A survey on machine learning techniques applied to source code,"@article{SHARMA2024111934,
title = {A survey on machine learning techniques applied to source code},
journal = {Journal of Systems and Software},
volume = {209},
pages = {111934},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111934},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223003291},
author = {Tushar Sharma and Maria Kechagia and Stefanos Georgiou and Rohit Tiwari and Indira Vats and Hadi Moazen and Federica Sarro},
keywords = {Machine learning for software engineering, Source code analysis, Deep learning, Datasets, Tools},
abstract = {The advancements in machine learning techniques have encouraged researchers to apply these techniques to a myriad of software engineering tasks that use source code analysis, such as testing and vulnerability detection. Such a large number of studies hinders the community from understanding the current research landscape. This paper aims to summarize the current knowledge in applied machine learning for source code analysis. We review studies belonging to twelve categories of software engineering tasks and corresponding machine learning techniques, tools, and datasets that have been applied to solve them. To do so, we conducted an extensive literature search and identified 494 studies. We summarize our observations and findings with the help of the identified studies. Our findings suggest that the use of machine learning techniques for source code analysis tasks is consistently increasing. We synthesize commonly used steps and the overall workflow for each task and summarize machine learning techniques employed. We identify a comprehensive list of available datasets and tools useable in this context. Finally, the paper discusses perceived challenges in this area, including the availability of standard datasets, reproducibility and replicability, and hardware resources. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121223003291,https://doi.org/10.1016/j.jss.2023.111934,science_direct,2024
1352,A survey of energy concerns for software engineering,"@article{LEE2024111944,
title = {A survey of energy concerns for software engineering},
journal = {Journal of Systems and Software},
volume = {210},
pages = {111944},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111944},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223003394},
author = {Sung Une Lee and Niroshinie Fernando and Kevin Lee and Jean-Guy Schneider},
keywords = {Software engineering, Energy, Green, Sustainability},
abstract = {There is growing attention to energy efficiency in the software engineering field. This has been driven by modern technologies, for example, Internet of Things (IoT), Social Networking Services (SNS) and quantum computing. In addition to this, recent trends and concerns such as Environment, Social, and Governance (ESG) and human/societal/environmental well-being for responsible Artificial Intelligence (AI) have accelerated the use of energy efficient software. Despite this, energy concerns in this field have been less explored and studied. This limitation results in falling short to address and overcome greenability issues at the software level, and leaving critical challenges to be solved in this space. This study aims to address this limitation and fill the gap between previous studies. We survey green in software engineering framed by the ten knowledge areas of software engineering to not only cover the entire development life-cycle but also widen the scope of discussion to software process, method, and model management. Based on our comprehensive investigation, we discuss open challenges, trade-offs and implications of this study for both researchers and practitioners.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121223003394,https://doi.org/10.1016/j.jss.2023.111944,science_direct,2024
1353,Promoting open science in test-driven software experiments,"@article{KESSEL2024111971,
title = {Promoting open science in test-driven software experiments},
journal = {Journal of Systems and Software},
volume = {212},
pages = {111971},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.111971},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224000141},
author = {Marcus Kessel and Colin Atkinson},
keywords = {Software, Engineering, Empirical, Experimentation, Observation, Behavior, Reproducibility, Replication, Data structures, Open science, Large language models, Machine learning, Generative artificial intelligence, Benchmark, Language-to-code, HumanEval, Automation, Measurement},
abstract = {A core principle of open science is the clear, concise and accessible publication of empirical data, including “raw” observational data as well as processed results. However, in empirical software engineering there are no established standards (de jure or de facto) for representing and “opening” observations collected in test-driven software experiments — that is, experiments involving the execution of software subjects in controlled scenarios. Execution data is therefore usually represented in ad hoc ways, often making it abstruse and difficult to access without significant manual effort. In this paper we present new data structures designed to address this problem by clearly defining, correlating and representing the stimuli and responses used to execute software subjects in test-driven experiments. To demonstrate their utility, we show how they can be used to promote the repetition, replication and reproduction of experimental evaluations of AI-based code completion tools. We also show how the proposed data structures facilitate the incremental expansion of execution data sets, and thus promote their repurposing for new experiments addressing new research questions.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224000141,https://doi.org/10.1016/j.jss.2024.111971,science_direct,2024
1354,Extracting goal models from natural language requirement specifications,"@article{DAS2024111981,
title = {Extracting goal models from natural language requirement specifications},
journal = {Journal of Systems and Software},
volume = {211},
pages = {111981},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.111981},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224000244},
author = {Souvick Das and Novarun Deb and Agostino Cortesi and Nabendu Chaki},
keywords = {Natural language requirements, Natural language processing, Transformer model, Entity type recognition, Contextual vector, Synonymy vector},
abstract = {Unstructured (or, semi-structured) natural language is mostly used to capture the requirement specifications both for legacy software systems and for modern day software systems. The adoption of a formal approach to the specification of the requirements, using goal models, enables rigorous and formal inspections while analyzing the requirements for satisfiability, consistency, completeness, conflicts and ambiguities. However, such a formal approach is often considered burdening for the analysts’ activity as it requires additional skills, and is therefore, discarded a priori. This works aims to bridge the gap between natural language requirement specifications and efficient goal model analysis techniques. We propose a framework that uses extensive natural language processing techniques to transform a set of unstructured natural language requirement specifications to the corresponding goal model. We combine techniques such as parts-of-speech tagging, dependency parsing, contextual and synonymy vector generation with the FiBER transformer model. An extensive unbiased crowd-sourced evaluation of the proposed framework has been performed, showing an acceptability rate (total and partial combined) of 95%. Time and space analyses of our framework also demonstrate the scalability of the proposed solution.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224000244,https://doi.org/10.1016/j.jss.2024.111981,science_direct,2024
1355,A/B testing: A systematic literature review,"@article{QUIN2024112011,
title = {A/B testing: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {211},
pages = {112011},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112011},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224000542},
author = {Federico Quin and Danny Weyns and Matthias Galster and Camila Costa Silva},
keywords = {A/B testing, Systematic literature review, A/B test engineering},
abstract = {A/B testing, also referred to as online controlled experimentation or continuous experimentation, is a form of hypothesis testing where two variants of a piece of software are compared in the field from an end user’s point of view. A/B testing is widely used in practice to enable data-driven decision making for software development. While a few studies have explored different facets of research on A/B testing, no comprehensive study has been conducted on the state-of-the-art in A/B testing. Such a study is crucial to provide a systematic overview of the field of A/B testing driving future research forward. To address this gap and provide an overview of the state-of-the-art in A/B testing, this paper reports the results of a systematic literature review that analyzed primary studies. The research questions focused on the subject of A/B testing, how A/B tests are designed and executed, what roles stakeholders have in this process, and the open challenges in the area. Analysis of the extracted data shows that the main targets of A/B testing are algorithms, visual elements, and workflow and processes. Single classic A/B tests are the dominating type of tests, primarily based in hypothesis tests. Stakeholders have three main roles in the design of A/B tests: concept designer, experiment architect, and setup technician. The primary types of data collected during the execution of A/B tests are product/system data, user-centric data, and spatio-temporal data. The dominating use of the test results are feature selection, feature rollout, continued feature development, and subsequent A/B test design. Stakeholders have two main roles during A/B test execution: experiment coordinator and experiment assessor. The main reported open problems are related to the enhancement of proposed approaches and their usability. From our study we derived three interesting lines for future research: strengthen the adoption of statistical methods in A/B testing, improving the process of A/B testing, and enhancing the automation of A/B testing.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224000542,https://doi.org/10.1016/j.jss.2024.112011,science_direct,2024
1356,Exploring the REIT architecture for requirements elicitation interview training with robotic and virtual tutors,"@article{GORER2024112018,
title = {Exploring the REIT architecture for requirements elicitation interview training with robotic and virtual tutors},
journal = {Journal of Systems and Software},
volume = {212},
pages = {112018},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112018},
url = {https://www.sciencedirect.com/science/article/pii/S016412122400061X},
author = {Binnur Görer and Fatma Başak Aydemir},
keywords = {Software engineering education, Requirements elicitation interview training, Empirical evaluation, Generic architecture, Robotic tutor, Virtual tutor},
abstract = {Requirements elicitation interviews are a widely adopted technique where the interview success depends on the interviewer’s preparedness and communication skills. Students can enhance these skills through practice interviews. However, organizing practice interviews for many students presents scalability challenges, given the time and effort required to involve stakeholders in each session. To address this, we propose REIT, an extensible architecture for Requirements Elicitation Interview Training system leveraging technologies such as robots and voice systems. REIT has components to support both the interview phase, wherein students act as interviewers while the system assumes the role of an interviewee, and the feedback phase, during which the system assesses students’ performance and offers contextual and behavioral feedback to enhance their interviewing skills. We demonstrate the applicability of REIT through two implementations: RoREIT with a physical robotic agent and VoREIT with a virtual voice-only agent. We empirically evaluated both instances with a group of graduate students. The participants appreciated both systems. They demonstrated higher learning gain when trained with RoREIT, but they found VoREIT more engaging and easier to use. These findings indicate that each system has distinct benefits and drawbacks, suggesting that educators can customize REIT for various settings, considering preferences and available resources.}
}
",https://www.sciencedirect.com/science/article/pii/S016412122400061X,https://doi.org/10.1016/j.jss.2024.112018,science_direct,2024
1357,Research artifacts in software engineering publications: Status and trends,"@article{LIU2024112032,
title = {Research artifacts in software engineering publications: Status and trends},
journal = {Journal of Systems and Software},
volume = {213},
pages = {112032},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112032},
url = {https://www.sciencedirect.com/science/article/pii/S016412122400075X},
author = {Mugeng Liu and Xiaolong Huang and Wei He and Yibing Xie and Jie M. Zhang and Xiang Jing and Zhenpeng Chen and Yun Ma},
keywords = {Research artifact, Empirical study, Software engineering, Code smell},
abstract = {The Software Engineering (SE) community has been embracing the open science policy and encouraging researchers to disclose artifacts in their publications. However, the status and trends of artifact practice and quality remain unclear, lacking insights on further improvement. In this paper, we present an empirical study to characterize the research artifacts in SE publications. Specifically, we manually collect 1,487 artifacts from all 2,196 papers published in top-tier SE conferences (ASE, FSE, ICSE, and ISSTA) from 2017 to 2022. We investigate the common practices (e.g., URL location and format, storage websites), maintenance activities (e.g., last update time and URL validity), popularity (e.g., the number of stars on GitHub and characteristics), and quality (e.g., documentation and code smell) of these artifacts. Based on our analysis, we reveal a rise in publications providing artifacts. The usage of Zenodo for sharing artifacts has significantly increased. However, artifacts stored in GitHub tend to receive few stars, indicating a limited influence on real-world SE applications. We summarize the results and provide suggestions to different stakeholders in conjunction with current guidelines.}
}
",https://www.sciencedirect.com/science/article/pii/S016412122400075X,https://doi.org/10.1016/j.jss.2024.112032,science_direct,2024
1358,GPTSniffer: A CodeBERT-based classifier to detect source code written by ChatGPT,"@article{NGUYEN2024112059,
title = {GPTSniffer: A CodeBERT-based classifier to detect source code written by ChatGPT},
journal = {Journal of Systems and Software},
volume = {214},
pages = {112059},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112059},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001043},
author = {Phuong T. Nguyen and Juri {Di Rocco} and Claudio {Di Sipio} and Riccardo Rubei and Davide {Di Ruscio} and Massimiliano {Di Penta}},
keywords = {ChatGPT, Code classification, CodeBERT, Pre-trained Models},
abstract = {Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it to solve development issues. However, while offering a practical solution to programming problems, ChatGPT should be used primarily as a supporting tool (e.g., in software education) rather than as a replacement for humans. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content need to be adapted to work effectively with code. This paper presents GPTSniffer– a novel approach to the detection of source code written by AI – built on top of CodeBERT. We conducted an empirical study to investigate the feasibility of automated identification of AI-generated code, and the factors that influence this ability. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, outperforming two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps boost the prediction. We conclude that GPTSniffer can be leveraged in different contexts, e.g., in software engineering education, where teachers use the tool to detect cheating and plagiarism, or in development, where AI-generated code may require peculiar quality assurance activities.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224001043,https://doi.org/10.1016/j.jss.2024.112059,science_direct,2024
1359,Beyond code: Is there a difference between comments in visual and textual languages?,"@article{BOLL2024112087,
title = {Beyond code: Is there a difference between comments in visual and textual languages?},
journal = {Journal of Systems and Software},
volume = {215},
pages = {112087},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112087},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001328},
author = {Alexander Boll and Pooja Rani and Alexander Schultheiß and Timo Kehrer},
keywords = {Documentation, Graphical, Diagram, Knowledge-transfer, Simulink, Model-driven engineering, Comment clones, Taxonomy},
abstract = {Code comments are crucial for program comprehension and maintenance. To better understand the nature and content of comments, previous work proposed taxonomies of comment information for textual languages, notably classical programming languages. However, paradigms such as model-driven or model-based engineering often promote the use of visual languages, to which existing taxonomies are not directly applicable. Taking MATLAB/Simulink as a representative of a sophisticated and widely used modeling environment, we extend a multi-language comment taxonomy onto new (visual) comment types and two new languages: Simulink and MATLAB. Furthermore, we outline Simulink commenting practices and compare them to textual languages. We analyze 259,267 comments from 9095 Simulink models and 17,792 MATLAB scripts. We identify the comment types, their usage frequency, classify comment information, and analyze their correlations with model metrics. We manually analyze 757 comments to extend the taxonomy. We also analyze commenting guidelines and developer adherence to them. Our extended taxonomy, SCoT (Simulink Comment Taxonomy), contains 25 categories. We find that Simulink comments, although often duplicated, are used at all model hierarchy levels. Of all comment types, Annotations are used most often; Notes scarcely. Our results indicate that Simulink developers, instead of extending comments, add new ones, and rarely follow commenting guidelines. Overall, we find Simulink comment information comparable to textual languages, which highlights commenting practice similarity across languages.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224001328,https://doi.org/10.1016/j.jss.2024.112087,science_direct,2024
1360,Semantic interoperability for an AI-based applications platform for smart hospitals using HL7 FHIR,"@article{RIGAS2024112093,
title = {Semantic interoperability for an AI-based applications platform for smart hospitals using HL7 FHIR},
journal = {Journal of Systems and Software},
volume = {215},
pages = {112093},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112093},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001389},
author = {Emmanouil S. Rigas and Paris Lagakis and Makis Karadimas and Evangelos Logaras and Dimitra Latsou and Magda Hatzikou and Athanasios Poulakidas and Antonis Billis and Panagiotis D. Bamidis},
keywords = {Semantic, Interoperability, FHIR, Smart hospital, Digital healthcare, Artificial intelligence, Application platform},
abstract = {The digitization of the healthcare domain has the potential to drastically improve healthcare services, reduce the time to diagnosis, and lower costs. However, digital applications for the healthcare domain need to be interoperable to maximize their potential. Additionally, with the rapid expansion of Artificial Intelligence (AI) and, specifically, Machine Learning (ML), large amounts of diverse types of data are being utilized. Thus, to achieve interoperability in such applications, the adoption of common semantic data models becomes imperative. In this paper, we describe the adoption of such a common semantic data model, using the well-known Health Level Seven Fast Health Interoperability Resources (HL7 FHIR) standard, in a platform that assists in the creation and storage of a plethora of AI-based applications for several medical conditions. The FHIR server’s efficiency is being showcased by using it in an application predicting coronary artery stenosis as well as for managing the platform’s key performance indicators.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224001389,https://doi.org/10.1016/j.jss.2024.112093,science_direct,2024
1361,Mining for cost awareness in the infrastructure as code artifacts of cloud-based applications: An exploratory study,"@article{FEITOSA2024112112,
title = {Mining for cost awareness in the infrastructure as code artifacts of cloud-based applications: An exploratory study},
journal = {Journal of Systems and Software},
volume = {215},
pages = {112112},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112112},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001572},
author = {Daniel Feitosa and Matei-Tudor Penca and Massimiliano Berardi and Rares-Dorian Boza and Vasilios Andrikopoulos},
keywords = {Cloud computing, Cost awareness, Mining software repositories, Cloud orchestration},
abstract = {Context:
Cloud computing’s rise as the primary platform for software development and delivery is largely driven by the potential cost savings. However, it is surprising that no empirical evidence has been collected to determine whether cost awareness permeates the development process and how it manifests in practice.
Objective:
This study aims to provide empirical evidence of cost awareness by mining open source repositories of cloud-based applications. The focus is on Infrastructure-as-Code artifacts that automate software (re)deployment on the cloud.
Methods:
A systematic examination of 152735 repositories yielded 2010 relevant hits. We then analyzed 538 relevant commits and 208 relevant issues using inductive and deductive coding and corroborated findings with discussions from Stack Overflow.
Results:
The findings indicate that developers are not only concerned with the cost of their application deployments but also take actions to reduce these costs beyond selecting cheaper cloud services. We also identify research areas for future consideration.
Conclusion:
Although we focus on a particular Infrastructure-as-Code technology (Terraform), the findings can be applicable to cloud-based application development in general. The provided empirical grounding can serve developers seeking to reduce costs through service selection, resource allocation, deployment optimization, and other techniques.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224001572,https://doi.org/10.1016/j.jss.2024.112112,science_direct,2024
1362,Confix: Combining node-level fix templates and masked language model for automatic program repair,"@article{XIAO2024112116,
title = {Confix: Combining node-level fix templates and masked language model for automatic program repair},
journal = {Journal of Systems and Software},
volume = {216},
pages = {112116},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112116},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001614},
author = {Jianmao Xiao and Zhipeng Xu and Shiping Chen and Gang Lei and Guodong Fan and Yuanlong Cao and Shuiguang Deng and Zhiyong Feng},
keywords = {Automatic program repair, Fix templates, Masked language model},
abstract = {Automatic program repair (APR) is a promising technique to fix program defects by generating patches. In the current APR techniques, template-based and learning-based techniques have demonstrated different advantages. Template-based APR techniques rely on pre-defined fix templates, providing higher controllability but limited by the variety of templates and edit expressiveness. In contrast, learning-based APR techniques treat repair as a neural machine translation task, improving the edit expressiveness through training neural networks. However, this technique also faces the influence of quality and variety of training data, leading to numerous errors and redundant code generation. To overcome their limitations, this paper proposes an innovative APR technique called Confix. Confix first constructs a code information tree to assist in mining edit changes during historical repair. It then further enriches the types of fix templates using node information in the tree. Afterward, Confix defines masked lines based on node-level fix templates to control the scope of patch generation, avoiding redundant semantic code generation. Finally, Confix leverages the powerful edit expressiveness of the masked language model and combines it with fix strategies to generate correct patches more efficiently and accurately. Experimental results show that Confix exhibits state-of-the-art performance on the Defects4J 1.2 and QuixBugs benchmarks.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224001614,https://doi.org/10.1016/j.jss.2024.112116,science_direct,2024
1363,Enhancing empirical software performance engineering research with kernel-level events: A comprehensive system tracing approach,"@article{NOFERESTI2024112117,
title = {Enhancing empirical software performance engineering research with kernel-level events: A comprehensive system tracing approach},
journal = {Journal of Systems and Software},
volume = {216},
pages = {112117},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112117},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001626},
author = {Morteza Noferesti and Naser Ezzati-Jivan},
keywords = {Empirical software engineering, Software performance engineering, Kernel-level tracing, Software reliability, Performance monitoring},
abstract = {Performance engineering is a proactive and systematic approach aimed at designing, building, and enhancing software systems to ensure their efficient and reliable operation. It involves observing and measuring the operational behavior of a software system without interference, assessing performance metrics like response times, throughput, and resource utilization. This entails delving into kernel-level events related to performance monitoring, which play a significant role in understanding system behavior and diagnosing performance-related issues. Kernel-level events offer insights into how both the operating system and hardware resources are utilized. This information empowers system administrators, developers, and performance analysts to optimize and troubleshoot the system effectively. A critical aspect of performance analysis is root cause analysis, which involves delving deep into kernel-level events connected to performance monitoring. These events provide valuable insights into the utilization of operating system and hardware resources, equipping system administrators, developers, and performance analysts with tools to effectively troubleshoot and optimize the system. Our study introduces an innovative artifact that captures kernel-level events using Elasticsearch and Kibana, facilitating comprehensive performance analysis under diverse scenarios. By defining both Light-load and Heavy-load scenarios and simulating CPU, I/O, Network, and Memory noise, we offer researchers a realistic environment to explore innovative approaches to system performance enhancement. The artifact comprises both kernel events and system calls, resulting in a cumulative count of 24,263,691 events. The proposed artifact can serve three distinct applications. The first application emphasizes performance analysis by utilizing kernel events for monitoring. The second application targets noise detection and root cause analysis, again using kernel events. Finally, the third application investigates software phase detection through monitoring at the kernel level. These applications demonstrate that through our artifact, researchers can effectively analyze performance, detect and address performance noise, and identify software phases, contributing to the advancement of performance engineering methodologies. All the system configurations, scripts, and traces can be found in the artifact GitHub repository.11URL: https://github.com/mnoferestibrocku/dataset-repo.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224001626,https://doi.org/10.1016/j.jss.2024.112117,science_direct,2024
1364,Data preparation for Deep Learning based Code Smell Detection: A systematic literature review,"@article{ZHANG2024112131,
title = {Data preparation for Deep Learning based Code Smell Detection: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {216},
pages = {112131},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112131},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001766},
author = {Fengji Zhang and Zexian Zhang and Jacky Wai Keung and Xiangru Tang and Zhen Yang and Xiao Yu and Wenhua Hu},
keywords = {Code smell detection, Deep learning, Data preparation, Systematic literature review},
abstract = {Code Smell Detection (CSD) plays a crucial role in improving software quality and maintainability. And Deep Learning (DL) techniques have emerged as a promising approach for CSD due to their superior performance. However, the effectiveness of DL-based CSD methods heavily relies on the quality of the training data. Despite its importance, little attention has been paid to analyzing the data preparation process. This systematic literature review analyzes the data preparation techniques used in DL-based CSD methods. We identify 36 relevant papers published by December 2023 and provide a thorough analysis of the critical considerations in constructing CSD datasets, including data requirements, collection, labeling, and cleaning. We also summarize seven primary challenges and corresponding solutions in the literature. Finally, we offer actionable recommendations for preparing and accessing high-quality CSD data, emphasizing the importance of data diversity, standardization, and accessibility. This survey provides valuable insights for researchers and practitioners to harness the full potential of DL techniques in CSD.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224001766,https://doi.org/10.1016/j.jss.2024.112131,science_direct,2024
1365,Impermanent identifiers: Enhanced source code comprehension and refactoring,"@article{GUERRA2024112137,
title = {Impermanent identifiers: Enhanced source code comprehension and refactoring},
journal = {Journal of Systems and Software},
volume = {216},
pages = {112137},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112137},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001821},
author = {Eduardo Martins Guerra and André A.S. Ivo and Fernando O. Pereira and Romain Robbes and Andrea Janes and Fábio Fagundes Silveira},
keywords = {Source code identifiers, Program comprehension, Software refactoring, Software evolution},
abstract = {In response to the prevailing challenges in contemporary software development, this article introduces an innovative approach to code augmentation centered around Impermanent Identifiers. The primary goal is to enhance the software development experience by introducing dynamic identifiers that adapt to changing contexts, facilitating more efficient interactions between developers and source code, ultimately advancing comprehension, maintenance, and collaboration in software development. Additionally, this study rigorously evaluates the adoption and acceptance of Impermanent Identifiers within the software development landscape. Through a comprehensive empirical examination, we investigate how developers perceive and integrate this approach into their daily programming practices, exploring perceived benefits, potential barriers, and factors influencing its adoption. In summary, this article charts a new course for code augmentation, proposing Impermanent Identifiers as its cornerstone while assessing their feasibility and acceptance among developers. This interdisciplinary research seeks to contribute to the continuous improvement of software development practices and the progress of code augmentation technology.}
}
",https://www.sciencedirect.com/science/article/pii/S0164121224001821,https://doi.org/10.1016/j.jss.2024.112137,science_direct,2024
1366,Customizing SVM as a base learner with AdaBoost ensemble to learn from multi-class problems: A hybrid approach AdaBoost-MSVM,"@article{MEHMOOD2021106845,
title = {Customizing SVM as a base learner with AdaBoost ensemble to learn from multi-class problems: A hybrid approach AdaBoost-MSVM},
journal = {Knowledge-Based Systems},
volume = {217},
pages = {106845},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.106845},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121001088},
author = {Zafar Mehmood and Sohail Asghar},
keywords = {Machine learning classifiers, Class overlapping, Imbalanced distribution of data, Imbalanced problem, Decomposition techniques},
abstract = {Learning from a multi-class problem has not been an easy task for most of the classifiers, because of multiple issues. In the complex multi-class scenarios, samples of different classes overlap with each other by sharing attribute, and hence the visibility of least represented samples decrease even more. Learning from imbalanced data studied extensively in the research community, however, the overlapping issues and the co-occurrence impact of overlapping with data imbalance have received comparatively less attention, even though their joint impact is more thoughtful on classifiers’ performance. In this paper, we introduce a modified SVM, MSVM to use as a base classifier with the AdaBoost ensemble classifier (MSVM-AdB) to enhance the learning capability of the ensemble classifier. To implement the proposed technique, we divide the multi-class dataset into overlapping and non-overlapping region. The overlapping region is further filter into the Critical and less Critical region depending upon their sample contribution in the overlapped region. The MSVM is designed to map the overlapped samples in a higher dimension by modifying the kernel mapping function of the standard SVM by using the mean distance of the Critical region samples. To highlight the learning enhancement of the MSVM-AdB, we use 20 real datasets with varying imbalance ratio and the overlapping degree to compare the significance of the AdaBoost-MSVM with the standard SVM, and AdaBoost with standard base classifiers. Experimental results show the superiority of the MSVM-AdB on a collection of benchmark datasets to its standard counterpart classifiers.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705121001088,https://doi.org/10.1016/j.knosys.2021.106845,science_direct,2021
1367,Robust and explainable identification of logical fallacies in natural language arguments,"@article{SOURATI2023110418,
title = {Robust and explainable identification of logical fallacies in natural language arguments},
journal = {Knowledge-Based Systems},
volume = {266},
pages = {110418},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110418},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123001685},
author = {Zhivar Sourati and Vishnu Priya {Prasanna Venkatesh} and Darshan Deshpande and Himanshu Rawlani and Filip Ilievski and Hông-Ân Sandlin and Alain Mermoud},
keywords = {Logical fallacy, Explainability, Case-based reasoning, Knowledge injection, Data augmentation, Robustness},
abstract = {The spread of misinformation, propaganda, and flawed argumentation has been amplified in the Internet era. Given the volume of data and the subtlety of identifying violations of argumentation norms, supporting information analytics tasks, like content moderation, with trustworthy methods that can identify logical fallacies is essential. In this paper, we formalize prior theoretical work on logical fallacies into a comprehensive three-stage evaluation framework of detection, coarse-grained, and fine-grained classification. We adapt existing evaluation datasets for each stage of the evaluation. We employ three families of robust and explainable methods based on prototype reasoning, instance-based reasoning, and knowledge injection. The methods combine language models with background knowledge and explainable mechanisms. Moreover, we address data sparsity with strategies for data augmentation and curriculum learning. Our three-stage framework natively consolidates prior datasets and methods from existing tasks, like propaganda detection, serving as an overarching evaluation testbed. We extensively evaluate these methods on our datasets, focusing on their robustness and explainability. Our results provide insight into the strengths and weaknesses of the methods on different components and fallacy classes, indicating that fallacy identification is a challenging task that may require specialized forms of reasoning to capture various classes. We share our open-source code and data on GitHub to support further work on logical fallacy identification.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705123001685,https://doi.org/10.1016/j.knosys.2023.110418,science_direct,2023
1368,PERCY: A post-hoc explanation-based score for logic rule dissemination consistency assessment in sentiment classification,"@article{GUPTA2023110685,
title = {PERCY: A post-hoc explanation-based score for logic rule dissemination consistency assessment in sentiment classification},
journal = {Knowledge-Based Systems},
volume = {275},
pages = {110685},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110685},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123004355},
author = {Shashank Gupta and Mohamed Reda Bouadjenek and Antonio Robles-Kelly},
keywords = {Logic rules dissemination, Sentiment classification, Explainable AI},
abstract = {Disseminating and incorporating logic rules into deep neural networks has been extensively explored for sentiment classification in recent years. In particular, most methods and algorithms proposed for this purpose rely on a specific component that aims to capture and model logic rules, followed by a sequence model to process the input sequence. While the authors of these methods claim that they effectively capture syntactic structures that affect sentiment classification, they only show improvement in accuracy to support their claims without further analysis. Focusing on various syntactic structures, particularly contrastive discourse relations such as the A-but-B structure, we introduce the PERCY score, a novel Post-hoc Explanation-based Rule ConsistencY Score to analyze and study the ability of several of these methods to identify these structures in a given sentence, and to make their classification decisions based on the appropriate conjunct. Specifically, we explore the use of model-agnostic post-hoc explanation frameworks to explain the predictions of any classifier in an interpretable and faithful manner. These model explainability frameworks provide feature attribution scores to estimate each word’s impact on the final classification decision. Then, they are combined to check whether the model has based its decision on the right conjunct. Our experiments show that (a) accuracy – or any other performance metric – can be misleading in assessing the ability of logic rule dissemination methods to base their decisions on the right conjunct, (b) not all analyzed methods effectively capture syntactic structures, (c) often, the underlying sequence model is what captures the structure, and (d) for the best method, less than 25% of the test examples are classified based on the appropriate conjunct, indicating that a lot of research needs to be done on this topic. Finally, we experimentally demonstrate that the PERCY scores calculated are robust and stable w.r.t. the feature-attribution frameworks used.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705123004355,https://doi.org/10.1016/j.knosys.2023.110685,science_direct,2023
1369,Deep transfer learning for automatic speech recognition: Towards better generalization,"@article{KHEDDAR2023110851,
title = {Deep transfer learning for automatic speech recognition: Towards better generalization},
journal = {Knowledge-Based Systems},
volume = {277},
pages = {110851},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110851},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123006019},
author = {Hamza Kheddar and Yassine Himeur and Somaya Al-Maadeed and Abbes Amira and Faycal Bensaali},
keywords = {Automatic speech recognition, Deep transfer learning, Fine-tuning, Domain adaptation, Models fusion, Large language model},
abstract = {Automatic speech recognition (ASR) has recently become an important challenge when using deep learning (DL). It requires large-scale training datasets and high computational and storage resources. Moreover, DL techniques and machine learning (ML) approaches in general, hypothesize that training and testing data come from the same domain, with the same input feature space and data distribution characteristics. This assumption, however, is not applicable in some real-world artificial intelligence (AI) applications. Moreover, there are situations where gathering real data is challenging, expensive, or rarely occurring, which cannot meet the data requirements of DL models. deep transfer learning (DTL) has been introduced to overcome these issues, which helps develop high-performing models using real datasets that are small or slightly different but related to the training data. This paper presents a comprehensive survey of DTL-based ASR frameworks to shed light on the latest developments and helps academics and professionals understand current challenges. Specifically, after presenting the DTL background, a well-designed taxonomy is adopted to inform the state-of-the-art. A critical analysis is then conducted to identify the limitations and advantages of each framework. Moving on, a comparative study is introduced to highlight the current challenges before deriving opportunities for future research.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705123006019,https://doi.org/10.1016/j.knosys.2023.110851,science_direct,2023
1370,Prompt-based event relation identification with Constrained Prefix ATTention mechanism,"@article{ZHANG2023111072,
title = {Prompt-based event relation identification with Constrained Prefix ATTention mechanism},
journal = {Knowledge-Based Systems},
volume = {281},
pages = {111072},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.111072},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123008225},
author = {Hang Zhang and Wenjun Ke and Jianwei Zhang and Zhizhao Luo and Hewen Ma and Zhen Luan and Peng Wang},
keywords = {Event relation identification, Prompt tuning, Pre-trained language model, Template generation, Information extraction},
abstract = {Event Relation Identification (ERI) aims at mining the inter-event dependencies expressed in event-mentioned sentences. The main challenge of this task lies in recognizing the implicit clue for utterances without context words indicating the relation definitely. When confronting a lack of training samples, mainstream techniques fail to efficiently capture the subtle relations between events because the parameters of neural networks cannot be adequately fitted. Although there is a rising trend of using prompt learning to alleviate such issues, existing methods lack optimization of the prompt and prompts-tuning process. These deficiencies lead to two weaknesses: co-occurrence interference and amphibolous prompting. To this end, this paper proposes a Constrained Prefix ATTention mechanism (CPATT) and incorporates it into the traditional prompt-tuning process. In this fashion, our approach integrates context semantic features into dynamic prompts to mitigate co-occurrence interference. Moreover, CPATT supervises the guide effect of prompts via incorporating mutual exclusivity between categories into the loss function. The experimental results on two widely used datasets demonstrate that our method outperforms all state-of-the-art baselines, including GPT3.5-turbo, in terms of intra- and inter-sentence event relation identification tasks.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705123008225,https://doi.org/10.1016/j.knosys.2023.111072,science_direct,2023
1371,MDM: Meta diffusion model for hard-constrained text generation,"@article{KE2024111147,
title = {MDM: Meta diffusion model for hard-constrained text generation},
journal = {Knowledge-Based Systems},
volume = {283},
pages = {111147},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.111147},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123008973},
author = {Wenjun Ke and Yikai Guo and Qi Liu and Wanyi Chen and Peng Wang and Haoran Luo and Zhizhao Luo},
keywords = {Hard-constrained text generation, Diffusion model, Meta-learning},
abstract = {Hard-constrained text generation (Hard-CTG) task aims to generate text with given keywords, which is helpful for summarization, data augmentation, story writing, etc. Existing Hard-CTG models face two significant challenges. Firstly, hard-CTG models based on the editing method suffer from error propagation, resulting in low generation quality. Secondly, Hard-CTG models utilizing the prompt method cannot guarantee high keyword coverage. To tackle these challenges, we propose Meta Diffusion Model (MDM), a non-autoregressive diffusion model with novel meta-learning module. Specifically, we fix the embedding of keywords in the generation process, while all non-keyword tokens evolve simultaneously and contribute to each other towards the target sentence under given keywords, addressing the above issues. Moreover, existing diffusion models for the text domain have an inconsistency in the training and inference stages. To unify the training and inference processes, we present an adaptively denoising method derived from meta-learning, and further improves generation quality. Experiments on three representative datasets demonstrate that our method achieves state-of-the-art performance evaluated on empirical metrics. Especially, compared with strong baselines, MDM significantly improves the BLEU-4, CIDEr, and ROUGE by 0.48%—11.56%, 17.33%—82.87%, and 23.15%–29.78%, respectively. In terms of keyword coverage, our MDM outperforms ChatGPT by 2.93%–7.88%.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705123008973,https://doi.org/10.1016/j.knosys.2023.111147,science_direct,2024
1372,Knowledge-based Dual External Attention Network for peptide detectability prediction,"@article{ZHANG2024111378,
title = {Knowledge-based Dual External Attention Network for peptide detectability prediction},
journal = {Knowledge-Based Systems},
volume = {286},
pages = {111378},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111378},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124000133},
author = {Xiaocai Zhang and Hui Peng and Tao Tang and Yuansheng Liu and Yang Wang and Jianjia Zhang},
keywords = {Peptide, Detectability prediction, Knowledge, Attention, Deep learning},
abstract = {Accurate prediction of peptide detectability plays a crucial role in various proteomics data analyses such as peptide identification and protein quantification. To improve the precision of peptide detectability prediction, we propose a novel approach called the Knowledge-based Dual External Attention Network (KDEAN). KDEAN introduces several innovative elements to enhance its representation and prediction capabilities. Firstly, it extracts valuable knowledge-based features from peptide sequences to facilitate the pattern recognition process. Secondly, KDEAN adopted dual networks to separately train peptide sequences from both the forward and backward directions, capturing comprehensive information. Thirdly, an external attention mechanism is utilized to identify and understand the connections between different peptide samples. The structure of KDEAN enables long-term dependency learning from both directions of the peptide sequences. Extensive evaluations on four testing datasets demonstrate that KDEAN outperforms existing methods, achieving a higher average performance in peptide detectability prediction. Additionally, comprehensive ablation studies confirm the effectiveness and advantages of key components in KDEAN, including knowledge-based feature representation, dual network architecture, and external attention.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124000133,https://doi.org/10.1016/j.knosys.2024.111378,science_direct,2024
1373,FL-OTCSEnc: Towards secure federated learning with deep compressed sensing,"@article{WU2024111534,
title = {FL-OTCSEnc: Towards secure federated learning with deep compressed sensing},
journal = {Knowledge-Based Systems},
volume = {291},
pages = {111534},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111534},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124001692},
author = {Leming Wu and Yaochu Jin and Yuping Yan and Kuangrong Hao},
keywords = {Federated learning, Deep compressed sensing, Privacy preservation, Homomorphic encryption},
abstract = {In recent years, federated learning has made significant progress in preserving data privacy. In this paradigm, clients train local models without sharing their raw data, thereby substantially mitigating the vulnerability to private data exposure. However, it is still possible to infer clients’ raw data by leveraging the gradient parameters exchanged between the clients and the server. To address this problem, this paper proposes a novel algorithm that introduces deep compressed sensing into federated learning to support one time encryption, called FL-OTCSEnc, to secure the communication data exchanged between the clients and the server. The process starts by creating a dataset of deep learning model parameters and training a system for both encryption and decryption using deep compressed sensing. This system is then used to secure the communication between clients and the server in federated learning, by encrypting and decrypting the data exchanged. To enhance the security of the proposed algorithm, we introduce an assessment method for evaluating the security level of the clients, facilitating the selection of suitable candidates for deployment within distributed training encryption and decryption models that are updated in real time. To enhance the accuracy of the decrypted deep network model, we introduce a tandem loss function in the training process. Moreover, this paper proves that the proposed end-to-end encryption method satisfies additive homomorphic encryption properties. Extensive experiments demonstrate that the deep compressed sensing encryption in federated learning achieves promising results without increasing the computational complexity.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124001692,https://doi.org/10.1016/j.knosys.2024.111534,science_direct,2024
1374,Higher-order GNN with Local Inflation for entity alignment,"@article{CHEN2024111634,
title = {Higher-order GNN with Local Inflation for entity alignment},
journal = {Knowledge-Based Systems},
volume = {293},
pages = {111634},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111634},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124002697},
author = {Jianrui Chen and Luheng Yang and Zhihui Wang and Maoguo Gong},
keywords = {Graph neural network, Local inflation, Higher-order, Entity alignment},
abstract = {In the age of massive data, the construction of knowledge graph has increasingly become a forceful support for the downstream applications of artificial intelligence. However, the information of entities in knowledge graphs is usually incomplete, so it is urgent to supplement the relations of entities through entity alignment task. Frustratingly, the current entity alignment models are facing serious challenges. First, some models only focus on structural features and other auxiliary information (e.g., attributes, images and descriptions), but ignore the features of the entity itself can be scaled resulting in over-smoothing issue. Second, most models utilize higher-order networks to aggregate neighborhood information by stacking layers, but the training cost of these models are drastically higher. Third, most models are supervised or semi-supervised, but there are few pre-aligned seeds for alignment, which greatly limits the improvement of model performance. Hence, to address the above three issues, we propose a Higher-Order Graph Neural Network with Local Inflation for entity alignment, named HOLI-GNN. Specifically, we introduce a local inflation mechanism, which enlarges the each feature of entities to mitigate the impact of over-smoothing caused by neighborhood aggregation. Additionally, we propose a novel higher-order encoder to capture higher-order information. Furthermore, our model also employ currently popular iteration strategy to increase labeled entity pairs, which can markedly promote the performance of align task. Finally, we perform comprehensive experiments to validate the effectiveness of our model on benchmark datasets. The results strongly indicate that our model exhibits better performance than the state-of-the-art models.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124002697,https://doi.org/10.1016/j.knosys.2024.111634,science_direct,2024
1375,SigCo: Eliminate the inter-class competition via sigmoid for learning with noisy labels,"@article{CHEN2024111651,
title = {SigCo: Eliminate the inter-class competition via sigmoid for learning with noisy labels},
journal = {Knowledge-Based Systems},
volume = {294},
pages = {111651},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111651},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124002867},
author = {Ang Chen and Feng Xu and Tao Zeng and Xin Lyu and Xin Li},
keywords = {Noisy label, Inter-class competition problem, Sigmoid classifier, Noise-adaptive learning strategy, Co-training mechanism},
abstract = {Accurate predictions from deep neural networks are crucial for distinguishing clean data and correcting noisy labels in current label noise learning methods. However, the conventional Softmax classifier used in most relevant works is highly sensitive to label noise due to its inherent competition-prompting mechanism, i.e., similar categories are encouraged to compete for limited confidence scores during class activation, especially between the noisy classes and the ground-truth, which can inevitably lead to suboptimal predictions and eventually hamper model performance. To address this inter-class competition problem, we propose a novel Sigmoid-based Sample Selection and Correction method named SigCo for learning with noisy labels. Different from previous works, we develop a Sigmoid-based network in which each Sigmoid classifier independently predicts its respective class, improving the reliability of the selection and correction process through more accurate predictions. Besides, in order to mitigate the negative impact of noisy labels, we design a noise-adaptive learning strategy by imposing stringent class masking constraints on clean samples to enhance the learning of discriminative features, while adopting a loose masking strategy for noisy data to improve the robustness to label noise. Additionally, we introduce a co-training strategy between our Sigmoid-based network and the conventional Softmax-based network to implicitly boost the generalization capability of the model. Extensive experiments on synthetic and real-world benchmarks show that SigCo consistently outperforms state-of-the-art methods. Especially on CIFAR-100N with 80% and 90% symmetric noise ratios, it improves test accuracy by 5.10% and 18.44%, respectively.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124002867,https://doi.org/10.1016/j.knosys.2024.111651,science_direct,2024
1376,Fake news detection in low-resource languages: A novel hybrid summarization approach,"@article{ALGHAMDI2024111884,
title = {Fake news detection in low-resource languages: A novel hybrid summarization approach},
journal = {Knowledge-Based Systems},
volume = {296},
pages = {111884},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111884},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124005185},
author = {Jawaher Alghamdi and Yuqing Lin and Suhuai Luo},
keywords = {Fake news detection, Multilingual NLP, Pre-trained language models, Content summarization},
abstract = {The proliferation of fake news across languages and domains on social media platforms poses a significant societal threat. Current automatic detection methods for low-resource languages (e.g., Swahili, Indonesian and other low-resource languages) face limitations due to two factors: sequential length restrictions in pre-trained language models (PLMs) like multilingual bidirectional encoder representation from transformers (mBERT), and the presence of noisy training data. This work proposes a novel and efficient multilingual fake news detection (MFND) approach that addresses these challenges. Our solution leverages a hybrid extractive and abstractive summarization strategy to extract only the most relevant content from news articles. This significantly reduces data length while preserving crucial information for fake news classification. The pre-processed data is then fed into mBERT for classification. Extensive evaluations on a publicly available multilingual dataset demonstrate the superiority of our approach compared to state-of-the-art (SOTA) methods. Our analysis, both quantitative and qualitative, highlights the strengths of this method, achieving new performance benchmarks and emphasizing the impact of content condensation on model accuracy and efficiency. This framework paves the way for faster, more accurate MFND, fostering more robust information ecosystems.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124005185,https://doi.org/10.1016/j.knosys.2024.111884,science_direct,2024
1377,Railway accident causation prediction with improved transformer model based on lexical information and contextual relationships,"@article{JIANG2024111897,
title = {Railway accident causation prediction with improved transformer model based on lexical information and contextual relationships},
journal = {Knowledge-Based Systems},
volume = {296},
pages = {111897},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111897},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124005318},
author = {Bin Jiang and Keming Wang},
keywords = {Railway safety, Causal analysis, Natural language processing, Deep learning, Data analysis},
abstract = {The railway system is a prime example of a safety-critical system. Predicting the causes of railway accidents holds immense significance in enhancing railway transportation safety. Previous approaches to railway causation analysis have encountered huge challenges regarding data processing and analytical capabilities. To address this concern, this paper proposes an innovative deep model framework based on the Transformer architecture that utilizes historical data on railway equipment accidents to predict the causes behind such incidents. Firstly, this paper proposes the utilization of Convolutional Block Attention in the domain of text processing, serving as a lexical encoder to augment word semantics acquisition in accident texts. Subsequently, in order to address the deficiency of traditional Transformers that lack positional representation information, we propose incorporating a BiGRU (Bidirectional Gated Recurrent Unit) as a contextual positional information encoder to capture contextual positional information in railway accident data effectively. Finally, considering that accident data reports are discrete tabular data, this study suggests employing cue word techniques for preprocessing accident data to alleviate the model's learning burden. We applied the proposed model to the FRA (Federal Railroad Administration) dataset. The results demonstrate that our model surpasses the current state-of-the-art language models, exhibiting superior performance compared to the optimal model with a notable improvement of 3.56%, 0.42%, and 0.76% in Precision, Recall, and F1-score, respectively. Furthermore, our model accurately predicts accident categories prone to misjudgment even when trained on limited data, outperforming existing language models. The study findings will contribute to the prevention and management of railway accidents.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124005318,https://doi.org/10.1016/j.knosys.2024.111897,science_direct,2024
1378,SDRNet: Camouflaged object detection with independent reconstruction of structure and detail,"@article{GUAN2024112051,
title = {SDRNet: Camouflaged object detection with independent reconstruction of structure and detail},
journal = {Knowledge-Based Systems},
volume = {299},
pages = {112051},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112051},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124006853},
author = {Juwei Guan and Xiaolin Fang and Tongxin Zhu and Weiqi Qian},
keywords = {Camouflaged object detection, Structure and detail reconstruction, Feature enhancement, Feature fusion, Feature decomposition},
abstract = {The simultaneous reconstruction of structure and detail is a prevalent strategy in camouflaged object detection. However, the reconstruction features required for structure and detail exhibit disparities, a facet overlooked in existing methods. Therefore, we present a novel methodology, termed SDRNet, which employs a dual-branch approach for the independent reconstruction of structure and detail, aiming to discern camouflaged targets and their edges. Specifically, we propose a decomposition block to segregate encoded features into distinct structure and detail components. Furthermore, structure enhancement block and detail enhancement block are proposed as feature enhancement methods to boost the capacity of structure and detail information. Subsequently, the introduced structure fusion block and detail fusion block progressively amalgamate the enhanced features. Additionally, the shared feature block is designed to serve as a bridge for the interaction between structure and detail information. Experimental results demonstrate that SDRNet outperforms existing state-of-the-art methods significantly on benchmark datasets. Our code is available at https://github.com/whyandbecause/SDRNet/.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124006853,https://doi.org/10.1016/j.knosys.2024.112051,science_direct,2024
1379,ProFPN: Progressive feature pyramid network with soft proposal assignment for object detection,"@article{KE2024112078,
title = {ProFPN: Progressive feature pyramid network with soft proposal assignment for object detection},
journal = {Knowledge-Based Systems},
volume = {299},
pages = {112078},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112078},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124007123},
author = {Junjie Ke and Lihuo He and Bo Han and Jie Li and Xinbo Gao},
keywords = {Feature pyramid, Object detection, Soft proposal assignment},
abstract = {Benefitting from the development of pyramidal feature learning, current state-of-the-art multi-scale detection paradigm has become proficient in detecting objects of varying scales. However, feature pyramid network (FPN), in spite of constructing multi-scale features with strong semantics, still suffers from limited performance caused by insufficient detail exploitation, information loss, limited receptive fields and hard proposal assignment, which can be mainly categorized into semantic level and instance level. To address these limitations, this paper analyzes the structural components that inhibit multi-scale feature representation and then presents a multi-stage progressive FPN (ProFPN) along with a novel RoI feature representation method called soft proposal assignment. In the semantic level, the bottom-up interaction module is first proposed to address to insufficient exploitation of high resolution features. In the bottom-up interaction module, global context attention blocks are utilized to interact adjacent-level features with detail information in a bottom-up progressive manner. After that, the top-down transfer module is designed to mitigate semantic information loss of high-level features. In the top-down transfer module, multi-branch asymmetric dilated blocks are adopted in a top-down progressive manner, which expands receptive fields to capture more object poses. In the instance level, to overcome the hard assignment of object proposals, a nonparametric strategy named soft proposal assignment is proposed to leverage the scale of each object proposal to generate dynamic weights for RoI features from adjacent levels. Comprehensive experiments conducted on MS COCO dataset demonstrate the superiority of ProFPN. By adding negligible extra FLOPs, the proposed ProFPN outperforms most pyramid-based methods. Moreover, due to the design of inherited feature utilization in ProFPN, transformer-based detectors have witnessed a substantial increase in detecting small objects while simultaneously achieving significant reductions in FLOPs. The source code of the proposed method is available at https://github.com/GingerCohle/ProFPN.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124007123,https://doi.org/10.1016/j.knosys.2024.112078,science_direct,2024
1380,EBERT: A lightweight expression-enhanced large-scale pre-trained language model for mathematics education,"@article{DUAN2024112118,
title = {EBERT: A lightweight expression-enhanced large-scale pre-trained language model for mathematics education},
journal = {Knowledge-Based Systems},
pages = {112118},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112118},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124007524},
author = {Zhiyi Duan and Hengnian Gu and Yuan Ke and Dongdai Zhou},
keywords = {Pre-trained model, Question&Answer tree, Expression enhanced matrix, Question&Answer matching},
abstract = {Within the realm of mathematics education, there exist several challenging supervised tasks that educators and researchers encounter, such as question difficulty prediction and mathematical expression understanding. To address these challenges, researchers have introduced unsupervised pre-trained models specifically tailored for mathematics education, yielding promising outcomes. However, the existing literature fails to consider the domain-specific characteristics of mathematics, particularly the structural features in pre-trained corpora and extensive expressions, which makes them costly expensive and time-consuming. To tackle this problem, we propose a lightweight expression-enhanced large-scale pre-trained language model, called EBERT, for mathematics education. Specifically, we select a large number of expression-enriched exercises to further pre-train the original BERT. To depict the inherent structural features existed in expressions, the initial step involves the creation of an Operator Tree for each expression. Subsequently, each exercise is transformed into a corresponding Question&Answer tree (QAT) to serve as the model input. Notably, to ensure the preservation of semantic integrity within the QAT, a specialized Expression Enhanced Matrix is devised to confine the visibility of individual tokens. Additionally, a new pre-training task, referred to as Question&Answer Matching, is introduced to capture exercise-related structural information at the semantic level. Through three downstream tasks in mathematical education, we prove that EBERT outperforms several state-of-the-art baselines (such as MathBERT and GPT-3) in terms of ACC and F1-score.}
}
",https://www.sciencedirect.com/science/article/pii/S0950705124007524,https://doi.org/10.1016/j.knosys.2024.112118,science_direct,2024
1381,Advances in medical image analysis with vision Transformers: A comprehensive review,"@article{AZAD2024103000,
title = {Advances in medical image analysis with vision Transformers: A comprehensive review},
journal = {Medical Image Analysis},
volume = {91},
pages = {103000},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2023.103000},
url = {https://www.sciencedirect.com/science/article/pii/S1361841523002608},
author = {Reza Azad and Amirhossein Kazerouni and Moein Heidari and Ehsan Khodapanah Aghdam and Amirali Molaei and Yiwei Jia and Abin Jose and Rijo Roy and Dorit Merhof},
keywords = {Transformers, Medical image analysis, Vision transformers, Deep neural networks},
abstract = {The remarkable performance of the Transformer architecture in natural language processing has recently also triggered broad interest in Computer Vision. Among other merits, Transformers are witnessed as capable of learning long-range dependencies and spatial correlations, which is a clear advantage over convolutional neural networks (CNNs), which have been the de facto standard in Computer Vision problems so far. Thus, Transformers have become an integral part of modern medical image analysis. In this review, we provide an encyclopedic review of the applications of Transformers in medical imaging. Specifically, we present a systematic and thorough review of relevant recent Transformer literature for different medical image analysis tasks, including classification, segmentation, detection, registration, synthesis, and clinical report generation. For each of these applications, we investigate the novelty, strengths and weaknesses of the different proposed strategies and develop taxonomies highlighting key properties and contributions. Further, if applicable, we outline current benchmarks on different datasets. Finally, we summarize key challenges and discuss different future research directions. In addition, we have provided cited papers with their corresponding implementations in https://github.com/mindflow-institue/Awesome-Transformer.}
}
",https://www.sciencedirect.com/science/article/pii/S1361841523002608,https://doi.org/10.1016/j.media.2023.103000,science_direct,2024
1382,When brain-inspired AI meets AGI,"@article{ZHAO2023100005,
title = {When brain-inspired AI meets AGI},
journal = {Meta-Radiology},
volume = {1},
number = {1},
pages = {100005},
year = {2023},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2023.100005},
url = {https://www.sciencedirect.com/science/article/pii/S295016282300005X},
author = {Lin Zhao and Lu Zhang and Zihao Wu and Yuzhong Chen and Haixing Dai and Xiaowei Yu and Zhengliang Liu and Tuo Zhang and Xintao Hu and Xi Jiang and Xiang Li and Dajiang Zhu and Dinggang Shen and Tianming Liu},
abstract = {Artificial General Intelligence (AGI) has been a long-standing goal of humanity, with the aim of creating machines capable of performing any intellectual task that humans can do. To achieve this, AGI researchers draw inspiration from the human brain and seek to replicate its principles in intelligent machines. Brain-inspired artificial intelligence is a field that has emerged from this endeavor, combining insights from neuroscience, psychology, and computer science to develop more efficient and powerful AI systems. In this article, we provide a comprehensive overview of brain-inspired AI from the perspective of AGI. We begin with the current progress in brain-inspired AI and its extensive connection with AGI. We then cover the important characteristics for both human intelligence and AGI (e.g., scaling, multimodality, and reasoning). We discuss important technologies toward achieving AGI in current AI systems, such as in-context learning and prompt tuning. We also investigate the evolution of AGI systems from both algorithmic and infrastructural perspectives. Finally, we explore the limitations and future of AGI.}
}
",https://www.sciencedirect.com/science/article/pii/S295016282300005X,https://doi.org/10.1016/j.metrad.2023.100005,science_direct,2023
1383,The impact of ChatGPT and LLMs on medical imaging stakeholders: Perspectives and use cases,"@article{YANG2023100007,
title = {The impact of ChatGPT and LLMs on medical imaging stakeholders: Perspectives and use cases},
journal = {Meta-Radiology},
volume = {1},
number = {1},
pages = {100007},
year = {2023},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2023.100007},
url = {https://www.sciencedirect.com/science/article/pii/S2950162823000073},
author = {Jiancheng Yang and Hongwei Bran Li and Donglai Wei},
keywords = {ChatGPT, LLM, Foundation models, Medical imaging},
abstract = {This study investigates the transformative potential of Large Language Models (LLMs), such as OpenAI ChatGPT, in medical imaging. With the aid of public data, these models, which possess remarkable language understanding and generation capabilities, are augmenting the interpretive skills of radiologists, enhancing patient-physician communication, and streamlining clinical workflows. The paper introduces an analytic framework for presenting the complex interactions between LLMs and the broader ecosystem of medical imaging stakeholders, including businesses, insurance entities, governments, research institutions, and hospitals (nicknamed BIGR-H). Through detailed analyses, illustrative use cases, and discussions on the broader implications and future directions, this perspective seeks to raise discussion in strategic planning and decision-making in the era of AI-enabled healthcare.}
}
",https://www.sciencedirect.com/science/article/pii/S2950162823000073,https://doi.org/10.1016/j.metrad.2023.100007,science_direct,2023
1384,Summary of ChatGPT-Related research and perspective towards the future of large language models,"@article{LIU2023100017,
title = {Summary of ChatGPT-Related research and perspective towards the future of large language models},
journal = {Meta-Radiology},
volume = {1},
number = {2},
pages = {100017},
year = {2023},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2023.100017},
url = {https://www.sciencedirect.com/science/article/pii/S2950162823000176},
author = {Yiheng Liu and Tianle Han and Siyuan Ma and Jiayue Zhang and Yuanyuan Yang and Jiaming Tian and Hao He and Antong Li and Mengshen He and Zhengliang Liu and Zihao Wu and Lin Zhao and Dajiang Zhu and Xiang Li and Ning Qiang and Dingang Shen and Tianming Liu and Bao Ge},
abstract = {This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and GPT-4) research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.}
}
",https://www.sciencedirect.com/science/article/pii/S2950162823000176,https://doi.org/10.1016/j.metrad.2023.100017,science_direct,2023
1385,"A comprehensive survey of ChatGPT: Advancements, applications, prospects, and challenges","@article{NAZIR2023100022,
title = {A comprehensive survey of ChatGPT: Advancements, applications, prospects, and challenges},
journal = {Meta-Radiology},
volume = {1},
number = {2},
pages = {100022},
year = {2023},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2023.100022},
url = {https://www.sciencedirect.com/science/article/pii/S295016282300022X},
author = {Anam Nazir and Ze Wang},
keywords = {Large Language Models (LLMs), Generative Pre-trained Transformers (GPT), Natural language processing (NLP), Contextual learning, Trustworthy conversational agents, Human-computer interaction, ChatGPT},
abstract = {Large Language Models (LLMs) especially when combined with Generative Pre-trained Transformers (GPT) represent a groundbreaking in natural language processing. In particular, ChatGPT, a state-of-the-art conversational language model with a user-friendly interface, has garnered substantial attention owing to its remarkable capability for generating human-like responses across a variety of conversational scenarios. This survey offers an overview of ChatGPT, delving into its inception, evolution, and key technology. We summarize the fundamental principles that underpin ChatGPT, encompassing its introduction in conjunction with GPT and LLMs. We also highlight the specific characteristics of GPT models with details of their impressive language understanding and generation capabilities. We then summarize applications of ChatGPT in a few representative domains. In parallel to the many advantages that ChatGPT can provide, we discuss the limitations and challenges along with potential mitigation strategies. Despite various controversial arguments and ethical concerns, ChatGPT has drawn significant attention from research industries and academia in a very short period. The survey concludes with an envision of promising avenues for future research in the field of ChatGPT. It is worth noting that knowing and addressing the challenges faced by ChatGPT will mount the way for more reliable and trustworthy conversational agents in the years to come.}
}
",https://www.sciencedirect.com/science/article/pii/S295016282300022X,https://doi.org/10.1016/j.metrad.2023.100022,science_direct,2023
1386,Artificial general intelligence for radiation oncology,"@article{LIU2023100045,
title = {Artificial general intelligence for radiation oncology},
journal = {Meta-Radiology},
volume = {1},
number = {3},
pages = {100045},
year = {2023},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2023.100045},
url = {https://www.sciencedirect.com/science/article/pii/S2950162823000450},
author = {Chenbin Liu and Zhengliang Liu and Jason Holmes and Lu Zhang and Lian Zhang and Yuzhen Ding and Peng Shu and Zihao Wu and Haixing Dai and Yiwei Li and Dinggang Shen and Ninghao Liu and Quanzheng Li and Xiang Li and Dajiang Zhu and Tianming Liu and Wei Liu},
keywords = {Large foundation model, AGI, SAM, Radiation oncology, Medical imaging},
abstract = {The emergence of artificial general intelligence (AGI) is transforming radiation oncology. As prominent vanguards of AGI, large language models (LLMs) such as GPT-4 and PaLM 2 can process extensive texts and large vision models (LVMs) such as the Segment Anything Model (SAM) can process extensive imaging data to enhance the efficiency and precision of radiation therapy. This paper explores full-spectrum applications of AGI across radiation oncology including initial consultation, simulation, treatment planning, treatment delivery, treatment verification, and patient follow-up. The fusion of vision data with LLMs also creates powerful multimodal models that elucidate nuanced clinical patterns. Together, AGI promises to catalyze a shift towards data-driven, personalized radiation therapy. However, these models should complement human expertise and care. This paper provides an overview of how AGI can transform radiation oncology to elevate the standard of patient care in radiation oncology, with the key insight being AGI's ability to exploit multimodal clinical data at scale.}
}
",https://www.sciencedirect.com/science/article/pii/S2950162823000450,https://doi.org/10.1016/j.metrad.2023.100045,science_direct,2023
1387,"The general intelligence of GPT–4, its knowledge diffusive and societal influences, and its governance","@article{JAHANIYEKTA2024100078,
title = {The general intelligence of GPT–4, its knowledge diffusive and societal influences, and its governance},
journal = {Meta-Radiology},
volume = {2},
number = {2},
pages = {100078},
year = {2024},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2950162824000316},
author = {Mohammad Mahdi {Jahani Yekta}},
keywords = {GPT–4, Artificial general intelligence, Knowledge diffusion, Interpretability and explainability, Societal influences, Governance},
abstract = {Recent breakthroughs in artificial intelligence (AI) research include advancements in natural language processing (NLP) achieved by large language models (LLMs), and; in particular, generative pre–trained transformer (GPT) architectures. The latest GPT developed by OpenAI, GPT–4, has shown remarkable intelligence across various domains and tasks. It exhibits capabilities in abstraction, comprehension, vision, computer coding, mathematics, and more, suggesting it to be a significant step towards artificial general intelligence (AGI), a level of AI that possesses capabilities similar to human intelligence. This paper explores this AGI, its knowledge diffusive and societal influences, and its governance. In addition to coverage of the major associated topics studied in the literature, and making up for their loopholes, we scrutinize how GPT-4 can facilitate the diffusion of knowledge across different areas of science by promoting their interpretability and explainability (IE) to inexperts. Where applicable, the topics are also accompanied by their specific potential implications on medical imaging.}
}
",https://www.sciencedirect.com/science/article/pii/S2950162824000316,https://doi.org/10.1016/j.metrad.2024.100078,science_direct,2024
1388,Opportunities and challenges in the application of large artificial intelligence models in radiology,"@article{PAN2024100080,
title = {Opportunities and challenges in the application of large artificial intelligence models in radiology},
journal = {Meta-Radiology},
volume = {2},
number = {2},
pages = {100080},
year = {2024},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2024.100080},
url = {https://www.sciencedirect.com/science/article/pii/S295016282400033X},
author = {Liangrui Pan and Zhenyu Zhao and Ying Lu and Kewei Tang and Liyong Fu and Qingchun Liang and Shaoliang Peng},
keywords = {Artificial intelligence large models, Radiology, Progress, Challenges},
abstract = {Influenced by ChatGPT, artificial intelligence (AI) large models have witnessed a global upsurge in large model research and development. As people enjoy the convenience by this AI large model, more and more large models in subdivided fields are gradually being proposed, especially large models in radiology imaging field. This article first introduces the development history of large models, technical details, workflow, working principles of multimodal large models and working principles of video generation large models. Secondly, we summarize the latest research progress of AI large models in radiology education, radiology report generation, applications of unimodal and multimodal radiology. Finally, this paper also summarizes some of the challenges of large AI models in radiology, with the aim of better promoting the rapid revolution in the field of radiography.}
}
",https://www.sciencedirect.com/science/article/pii/S295016282400033X,https://doi.org/10.1016/j.metrad.2024.100080,science_direct,2024
1389,"The linguistic summarization and the interpretability, scalability of fuzzy representations of multilevel semantic structures of word-domains","@article{NGUYEN2021103641,
title = {The linguistic summarization and the interpretability, scalability of fuzzy representations of multilevel semantic structures of word-domains},
journal = {Microprocessors and Microsystems},
volume = {81},
pages = {103641},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103641},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120307882},
author = {Cat Ho Nguyen and Thi Lan Pham and Tu N. Nguyen and Cam Ha Ho and Thu Anh Nguyen},
keywords = {Fuzzy sets, Hedge algebras, Human-computer interaction, Knowledge discovery, Linguistic data summarization, Natural languages},
abstract = {ABSTRACT
The effect of the linguistic (L-) summarization mined from a given dataset D by a human-made method M strongly depends on the fuzzy sets constructed to represent the L-words of dataset attributes. One can observe that the semantics of words is objective (commonly understood the same between human experts,) and word-domains of dataset attributes have their inherent semantic structures. It suggests that to limit the intuitive human influences on such construction, in this study, it requires that the constructed fuzzy set (fs-) representations of the declared word-sets should be the isomorphic images of their words. Such fs-representations of the word-domains are called, in this study, interpretable based on the concept of interpretability in the math-logical theories of A. Tarski et al. It requires the interpretability of the inherent semantic structures of the declared word-sets in their fs-representations structures. With this new feature, the study proposes a data-summarization method that can reveal L-distributions of fuzzy groups of objects represented by a given dataset to the desired dataset L-attribute. The set of all such mined LSs satisfies essential specific human usual L-knowledge, the scalability of its current attributes word-sets, and the current knowledge itself. An experimental study using the Bank Marketing dataset taken from the UCI dataset repository is performed to show the specific advantages of the proposed method.}
}
",https://www.sciencedirect.com/science/article/pii/S0141933120307882,https://doi.org/10.1016/j.micpro.2020.103641,science_direct,2021
1390,Security provision for protecting intelligent sensors and zero touch devices by using blockchain method for the smart cities,"@article{UNNISA2022104503,
title = {Security provision for protecting intelligent sensors and zero touch devices by using blockchain method for the smart cities},
journal = {Microprocessors and Microsystems},
volume = {90},
pages = {104503},
year = {2022},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2022.104503},
url = {https://www.sciencedirect.com/science/article/pii/S0141933122000631},
author = {Khaleeq {Un Nisa} and Adi Alhudhaif and Kashif Naseer Qureshi and Hassan Jalil Hadi and Gwanggil Jeon},
keywords = {Authentication, Botnet, Ddos, Brute force, Port scanning, Corda virtual machine, Mirai, Manufacturer usage description, Owasp, Vulnerability},
abstract = {Internet of Things (IoT) networks has gained popularity due to their amazing and cost-effective services and one of the main areas in smart cities. The stability of these networks is based on stable and secure data transmission without any vulnerabilities present used devices. Distributed Denial of Services (DDoS) attacks have brought critical interruptions in IoT services and significantly damage the network. In DDoS attacks, attackers utilize botnets, with the capability of frequently exploiting the millions of IoT devices around the globe. After the source code of Mirai malware is loaded on GitHub, the threats are significantly increased. Manufacturer Usage Description (MUD) is an embedded software standard for IoT device makers to advertise device specifications, including the intended communication patterns when it connects to the network. Even though the MUD mechanism is promising exertion, still there is a need for evaluating its viability, recognize its limits, and upgrade its architecture to reduce shortcomings in its architecture as well as to increase its effectiveness. This standard neither identifies the vulnerability path before the creation of the MUD profile. Thus, it is possible to exploit an IoT device even after the MUD profile is issued to the device by manipulating the vulnerabilities in the device. By keeping in mind this situation, this paper discusses the limitations of MUD in detail and proposed a framework to identify the patch and default vulnerabilities by using blockchain method before the generation/creation of MUD profiles. The proposed framework can also mitigate open ports, DDoS attacks, and Brute force attacks. The experiment results show the identification, elimination, and sharing of vulnerability report with vendors and significantly minimized the risk of IoT device exploitation.}
}
",https://www.sciencedirect.com/science/article/pii/S0141933122000631,https://doi.org/10.1016/j.micpro.2022.104503,science_direct,2022
1391,Considerations for adapting higher education technology courses for AI large language models: A critical review of the impact of ChatGPT,"@article{TAYAN2024100513,
title = {Considerations for adapting higher education technology courses for AI large language models: A critical review of the impact of ChatGPT},
journal = {Machine Learning with Applications},
volume = {15},
pages = {100513},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2023.100513},
url = {https://www.sciencedirect.com/science/article/pii/S266682702300066X},
author = {Omar Tayan and Ali Hassan and Khaled Khankan and Sanaa Askool},
keywords = {Artificial intelligence, ChatGPT, Higher education, Machine learning},
abstract = {Following the very recent launch of the ChatGPT chatbot, numerous comments and speculations were posted concerning the potential aspects of society that are expected to benefit from this AI revolution. In particular, the education sector is considered as one of the primary domains affected by this application, the impact of which remains yet to be fully understood. Furthermore, many Higher Education institutions are required to get to terms with its impact on teaching and learning, and to clarify their stances on the use of ChatGPT software. This study was developed to investigate some critical case studies considered as relevant to the inevitable re-evaluation of educational aspects needed, ranging from academic missions to student and course learning outcomes and its ethical uses. Following a review of some of the pros and cons of ChatGPT in the higher educational sector, this paper shall demonstrate several case studies of early trials in teaching and learning assessments related to various specializations. Next, the ability of some well-known AI detector software and analyzed in terms of their capacity to successfully detect AI-generated content. Analysis shall be made of the foreseen impact on important aspects including challenges and benefits related to its use in course assessments as well as academic integrity and ethical use. The study concludes with a set of recommendations made from our findings and benchmarks obtained from top universities in order to assist faculty members and decision makers at Higher Education institutions concerning their response strategy and use of ChatGPT.}
}
",https://www.sciencedirect.com/science/article/pii/S266682702300066X,https://doi.org/10.1016/j.mlwa.2023.100513,science_direct,2024
1392,ChatReview: A ChatGPT-enabled natural language processing framework to study domain-specific user reviews,"@article{HO2024100522,
title = {ChatReview: A ChatGPT-enabled natural language processing framework to study domain-specific user reviews},
journal = {Machine Learning with Applications},
volume = {15},
pages = {100522},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2023.100522},
url = {https://www.sciencedirect.com/science/article/pii/S2666827023000750},
author = {Brittany Ho and Ta’Rhonda Mayberry and Khanh Linh Nguyen and Manohar Dhulipala and Vivek Krishnamani Pallipuram},
keywords = {Natural Language Processing, ChatGPT, Sentiment analysis, Prompt engineering, Intelligent search engines, Recommender system},
abstract = {Intelligent search engines including pre-trained generative transformers (GPT) have revolutionized the user search experience. Several fields including e-commerce, education, and hospitality are increasingly exploring GPT tools to study user reviews and gain critical insights to improve their service quality. However, massive user-review data and imprecise prompt engineering lead to biased, irrelevant, and impersonal search results. In addition, exposing user data to these search engines may pose privacy issues. Motivated by these factors, we present ChatReview, a ChatGPT-enabled natural language processing (NLP) framework that effectively studies domain-specific user reviews to offer relevant and personalized search results at multiple levels of granularity. The framework accomplishes this task using four phases including data collection, tokenization, query construction, and response generation. The data collection phase involves gathering domain-specific user reviews from public and private repositories. In the tokenization phase, ChatReview applies sentiment analysis to extract keywords and categorize them into various sentiment classes. This process creates a token repository that best describes the user sentiments for a given user-review data. In the query construction phase, the framework uses the token repository and domain knowledge to construct three types of ChatGPT prompts including explicit, implicit, and creative. In the response generation phase, ChatReview pipelines these prompts into ChatGPT to generate search results at varying levels of granularity. We analyze our framework using three real-world domains including education, local restaurants, and hospitality. We assert that our framework simplifies prompt engineering for general users to produce effective results while minimizing the exposure of sensitive user data to search engines. We also present a one-of-a-kind Large Language Model (LLM) peer assessment of the ChatReview framework. Specifically, we employ Google’s Bard to objectively and qualitatively analyze the various ChatReview outputs. Our Bard-based analyses yield over 90% satisfaction, establishing ChatReview as a viable survey analysis tool.}
}
",https://www.sciencedirect.com/science/article/pii/S2666827023000750,https://doi.org/10.1016/j.mlwa.2023.100522,science_direct,2024
1393,Programming with ChatGPT: How far can we go?,"@article{BUCAIONI2024100526,
title = {Programming with ChatGPT: How far can we go?},
journal = {Machine Learning with Applications},
volume = {15},
pages = {100526},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2024.100526},
url = {https://www.sciencedirect.com/science/article/pii/S2666827024000021},
author = {Alessio Bucaioni and Hampus Ekedahl and Vilma Helander and Phuong T. Nguyen},
keywords = {ChatGPT, Large language models, Programming},
abstract = {Artificial intelligence (AI) has made remarkable strides, giving rise to the development of large language models such as ChatGPT. The chatbot has garnered significant attention from academia, industry, and the general public, marking the beginning of a new era in AI applications. This work explores how well ChatGPT can write source code. To this end, we performed a series of experiments to assess the extent to which ChatGPT is capable of solving general programming problems. Our objective is to assess ChatGPT’s capabilities in two different programming languages, namely C++ and Java, by providing it with a set of programming problem, encompassing various types and difficulty levels. We focus on evaluating ChatGPT’s performance in terms of code correctness, run-time efficiency, and memory usage. The experimental results show that, while ChatGPT is good at solving easy and medium programming problems written in C++ and Java, it encounters some difficulties with more complicated tasks in the two languages. Compared to code written by humans, the one generated by ChatGPT is of lower quality, with respect to runtime and memory usage.}
}
",https://www.sciencedirect.com/science/article/pii/S2666827024000021,https://doi.org/10.1016/j.mlwa.2024.100526,science_direct,2024
1394,ChatGPT: A meta-analysis after 2.5 months,"@article{LEITER2024100541,
title = {ChatGPT: A meta-analysis after 2.5 months},
journal = {Machine Learning with Applications},
volume = {16},
pages = {100541},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2024.100541},
url = {https://www.sciencedirect.com/science/article/pii/S2666827024000173},
author = {Christoph Leiter and Ran Zhang and Yanran Chen and Jonas Belouadi and Daniil Larionov and Vivian Fresen and Steffen Eger},
keywords = {ChatGPT, Sentiment analysis, Emotion analysis, Science, Large language models},
abstract = {ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and media attention since its release in November 2022. However, little hard evidence is available regarding its perception in various sources. In this paper, we analyze over 300,000 tweets and more than 150 scientific papers to investigate how ChatGPT is perceived and discussed. Our findings show that ChatGPT is generally viewed as of high quality, with positive sentiment and emotions of joy dominating social media. Its perception has slightly decreased since its debut, however, with joy decreasing and (negative) surprise on the rise, and it is perceived more negatively in languages other than English. In recent scientific papers, ChatGPT is characterized as a great opportunity across various fields including the medical domain, but also as a threat concerning ethics and receives mixed assessments for education. Our comprehensive meta-analysis of ChatGPT’s perception after 2.5 months since its release can contribute to shaping the public debate and informing its future development. We make our data available.11https://github.com/NL2G/ChatGPTReview.}
}
",https://www.sciencedirect.com/science/article/pii/S2666827024000173,https://doi.org/10.1016/j.mlwa.2024.100541,science_direct,2024
1395,The Dark Side of Language Models: Exploring the Potential of LLMs in Multimedia Disinformation Generation and Dissemination,"@article{BARMAN2024100545,
title = {The Dark Side of Language Models: Exploring the Potential of LLMs in Multimedia Disinformation Generation and Dissemination},
journal = {Machine Learning with Applications},
volume = {16},
pages = {100545},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2024.100545},
url = {https://www.sciencedirect.com/science/article/pii/S2666827024000215},
author = {Dipto Barman and Ziyi Guo and Owen Conlan},
keywords = {Llms, Disinformation, Information quality, ChatGPT, Mitigation},
abstract = {Disinformation - the deliberate spread of false or misleading information poses a significant threat to our society by undermining trust, exacerbating polarization, and manipulating public opinion. With the rapid advancement of artificial intelligence and the growing prominence of large language models (LLMs) such as ChatGPT, new avenues for the dissemination of disinformation are emerging. This review paper explores the potential of LLMs to initiate the generation of multi-media disinformation, encompassing text, images, audio, and video. We begin by examining the capabilities of LLMs, highlighting their potential to create compelling, context-aware content that can be weaponized for malicious purposes. Subsequently, we examine the nature of disinformation and the various mechanisms through which it spreads in the digital landscape. Utilizing these advanced models, malicious actors can automate and scale up disinformation effectively. We describe a theoretical pipeline for creating and disseminating disinformation on social media. Existing interventions to combat disinformation are also reviewed. While these efforts have shown success, we argue that they need to be strengthened to effectively counter the escalating threat posed by LLMs. Digital platforms have, unfortunately, enabled malicious actors to extend the reach of disinformation. The advent of LLMs poses an additional concern as they can be harnessed to significantly amplify the velocity, variety, and volume of disinformation. Thus, this review proposes augmenting current interventions with AI tools like LLMs, capable of assessing information more swiftly and comprehensively than human fact-checkers. This paper illuminates the dark side of LLMs and highlights their potential to be exploited as disinformation dissemination tools.}
}
",https://www.sciencedirect.com/science/article/pii/S2666827024000215,https://doi.org/10.1016/j.mlwa.2024.100545,science_direct,2024
1396,TeenyTinyLlama: Open-source tiny language models trained in Brazilian Portuguese,"@article{CORREA2024100558,
title = {TeenyTinyLlama: Open-source tiny language models trained in Brazilian Portuguese},
journal = {Machine Learning with Applications},
volume = {16},
pages = {100558},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2024.100558},
url = {https://www.sciencedirect.com/science/article/pii/S2666827024000343},
author = {Nicholas Kluge Corrêa and Sophia Falk and Shiza Fatimah and Aniket Sen and Nythamar {De Oliveira}},
keywords = {Large language models, Portuguese, Text generation, Low-resource settings, Low-resource languages},
abstract = {Large language models (LLMs) have significantly advanced natural language processing, but their progress has yet to be equal across languages. While most LLMs are trained in high-resource languages like English, multilingual models generally underperform monolingual ones. Additionally, aspects of their multilingual foundation sometimes restrict the byproducts they produce, like computational demands and licensing regimes. In this study, we document the development of open-foundation models tailored for use in low-resource settings, their limitations, and their benefits. This is the TeenyTinyLlama pair: two compact models for Brazilian Portuguese text generation. We release them under the permissive Apache 2.0 license on GitHub and Hugging Face for community use and further development.}
}
",https://www.sciencedirect.com/science/article/pii/S2666827024000343,https://doi.org/10.1016/j.mlwa.2024.100558,science_direct,2024
1398,Stock movement predictive network via incorporative attention mechanisms based on tweet and historical prices,"@article{XU2020326,
title = {Stock movement predictive network via incorporative attention mechanisms based on tweet and historical prices},
journal = {Neurocomputing},
volume = {418},
pages = {326-339},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.108},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220313060},
author = {Hongfeng Xu and Lei Chai and Zhiming Luo and Shaozi Li},
keywords = {Stock prediction, Incorporative attention, Local semantics, Contextual information},
abstract = {The recent advances usually attempt to mine the effective market information from the chaotic data and learn multilevel representations by using attention mechanisms to conduct a stock prediction task. However, such methods usually lack the full utilization of local semantic embedding which contains the abundant textual semantics information. Moreover, these models suffer from the severe noise diffusion in contextual embeddings from a sequence after passing through the RNN. The noises diffusion constrains the performance of the proposed methods. In this work, we propose a stock movement predictive network via incorporative attention mechanisms. The core innovation is that the incorporative attention combines local and contextual attention mechanisms to clean the contextual embeddings by using local semantics. As a result, the attention effectively reduce the noises in the constructed higher-level representations and enhance the performance. Moreover, the local semantics and context are merged into the constructed higher-level representations which provide more abundant local semantic and contextual information. The experimental results demonstrate the state-of-the-art performance of the proposed approach on tweet and historical price dataset.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231220313060,https://doi.org/10.1016/j.neucom.2020.07.108,science_direct,2020
1399,Static and adaptive subspace information fusion for indefinite heterogeneous proximity data,"@article{MUNCH2023126635,
title = {Static and adaptive subspace information fusion for indefinite heterogeneous proximity data},
journal = {Neurocomputing},
volume = {555},
pages = {126635},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126635},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223007580},
author = {Maximilian Münch and Manuel Röder and Simon Heilig and Christoph Raab and Frank-Michael Schleif},
keywords = {Indefinite learning, Multi-modal data, Heterogeneous data analysis, Multiple kernel learning, Kernel fusion, Proximity learning},
abstract = {Heterogeneous data is common in many real-world machine learning applications, such as healthcare, market analysis, environmental sciences, and social media analysis. In these domains, data is often represented in different modalities and, most of the time, in non-vectorial formats, like text, images, and video. Traditional machine learning algorithms are often limited in their ability to effectively analyze and learn from such diverse data types. In this paper, we propose two approaches for such heterogeneous data analysis: static and adaptive subspace kernel fusion. The first approach is a kernel-based method extracting the essential parts of the subspace of each input modality and creating one single fused representation of the data. The second approach utilizes an adaptation step by integrating the weighting of spectral properties into the fusion process in order to improve the data’s representation with respect to a given classification task. Our proposed methods are evaluated on several multi-modal, heterogeneous data sets and demonstrate significant performance improvement compared to other methods in the field. Our results highlight the importance of fusing the underlying subspace information of heterogeneous data for achieving superior performance in machine learning tasks.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231223007580,https://doi.org/10.1016/j.neucom.2023.126635,science_direct,2023
1400,ESA: Excitation-Switchable Attention for convolutional neural networks,"@article{ZHONG2023126706,
title = {ESA: Excitation-Switchable Attention for convolutional neural networks},
journal = {Neurocomputing},
volume = {557},
pages = {126706},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126706},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223008299},
author = {Shanshan Zhong and Zhongzhan Huang and Wushao Wen and Zhijing Yang and Jinghui Qin},
keywords = {Attention mechanism, Switchable excitation module, Neural network},
abstract = {Although various attention mechanisms can boost the representational power of convolutional neural networks (CNNs) and improve their performance, selecting an appropriate attention module becomes challenging when backbones or datasets change. Besides, as different CNN layers can learn distinct semantic features, applying the same attention module across all layers may not yield optimal results for enhancing the performance of a deep neural network. To address the above issues, we propose a novel excitation-switchable attention (ESA) to automatically select and integrate different excitation modules to compute attention maps, enabling a DNN to apply different attention modules in different layers for better feature learning and performance improvement. Extensive experiments on three widely-used image classification benchmarks demonstrate the superiority of our ESA over several well-known and widely-adopted attention modules.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231223008299,https://doi.org/10.1016/j.neucom.2023.126706,science_direct,2023
1401,FABSA: An aspect-based sentiment analysis dataset of user reviews,"@article{KONTONATSIOS2023126867,
title = {FABSA: An aspect-based sentiment analysis dataset of user reviews},
journal = {Neurocomputing},
volume = {562},
pages = {126867},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126867},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223009906},
author = {Georgios Kontonatsios and Jordan Clive and Georgia Harrison and Thomas Metcalfe and Patrycja Sliwiak and Hassan Tahir and Aji Ghose},
keywords = {ABSA, Multi-domain dataset, Deep learning},
abstract = {Aspect-based sentiment analysis (ABSA) aims at automatically extracting aspects of entities and classifying the polarity of each extracted aspect. The majority of available ABSA systems heavily rely on manually annotated datasets to train supervised machine learning models. However, the development of such manually curated datasets is a labour-intensive process and therefore existing ABSA datasets cover only a few domains and they are limited in size. In response, we present FABSA (Feedback ABSA), a new large-scale and multi-domain ABSA dataset of feedback reviews. FABSA consists of approximately 10,500 reviews which span across 10 domains. We conduct a number of experiments to evaluate the performance of state-of-the-art deep learning models when applied to the FABSA dataset. Our results demonstrate that ABSA models can generalise across different domains when trained on our FABSA dataset while the performance of the models is enhanced when using a larger training dataset. Our FABSA dataset is publicly available.11https://github.com/kontonag86/fabsa-dataset.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231223009906,https://doi.org/10.1016/j.neucom.2023.126867,science_direct,2023
1402,Pseudo dense counterfactual augmentation for aspect-based sentiment analysis,"@article{OUYANG2023126869,
title = {Pseudo dense counterfactual augmentation for aspect-based sentiment analysis},
journal = {Neurocomputing},
volume = {561},
pages = {126869},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126869},
url = {https://www.sciencedirect.com/science/article/pii/S092523122300992X},
author = {Jihong Ouyang and Shi Feng and Bing Wang and Zhiyao Yang},
keywords = {Aspect-based sentiment analysis, Encoder-decoder, Data augmentation},
abstract = {Aspect-based sentiment analysis (ABSA) is a fine-grained text classification task, and the cutting-edge ABSA models have achieved outstanding performance. Unfortunately, the robustness of these ABSA models is neglected. ABSA models must face numerous challenges to be robust, and we concentrate on one of these challenges caused by negation words, such as “not”, “un-”. In the actual context, these negation words intuitively result in two problems: negative sensitivity and spurious correlation. First, a negation word tends to reverse the sentiment polarity of a sentence. Meanwhile, in the ABSA datasets, most sentences containing negation words express Negative polarities, which will lead the predictive model to learn the spurious correlation between negation words and polarities. To resolve these ambiguous issues, we are inspired by causal inference and propose a novel data augmentation framework, namely Pseudo Dense Counterfactual Augmentation (PDCaug) for ABSA. Specifically, we initialize a pseudo sequence and employ a multi-head multi-layer attention network to achieve counterfactual augmentation for a vanilla sentence in the hidden space. This pseudo sequence will be adversarially trained. PDCaug is a plug-and-play method for various ABSA models, so we evaluate it on discriminative models and generative prompt-based models. Our extensive experiments show that our PDCaug can significantly and consistently outperform several data augmentation methods and ABSA models.}
}
",https://www.sciencedirect.com/science/article/pii/S092523122300992X,https://doi.org/10.1016/j.neucom.2023.126869,science_direct,2023
1403,An intelligent conversational agent for educating the general public about HIV,"@article{MORENO2024126902,
title = {An intelligent conversational agent for educating the general public about HIV},
journal = {Neurocomputing},
volume = {563},
pages = {126902},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126902},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223010251},
author = {Joan C. Moreno and Victor Sánchez-Anguix and Juan M. Alberola and Vicente Julián and Vicent Botti},
keywords = {Conversational agent, Natural language understanding, HIV, Health informatics, Human–computer interaction, Empirical study},
abstract = {The article presents a Spanish conversational agent that focuses on raising awareness about HIV. The agent aims to provide natural communication, personalized information based on user requests, and a centralized source of information about HIV. The core of the agent’s logic is formed by a natural language understanding conversational model, supported by a knowledge base of medical responses and real conversations with users. An empirical study was conducted with 71 users to evaluate the agent’s effectiveness as a sexual health educational tool. The results show that HIV knowledge raised by 18.44% after using the agent. That, and the positive user experience support the agent’s role as a tool for raising HIV prevention and awareness.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231223010251,https://doi.org/10.1016/j.neucom.2023.126902,science_direct,2024
1404,"Evidence, my Dear Watson: Abstractive dialogue summarization on learnable relevant utterances","@article{ITALIANI2024127132,
title = {Evidence, my Dear Watson: Abstractive dialogue summarization on learnable relevant utterances},
journal = {Neurocomputing},
volume = {572},
pages = {127132},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.127132},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223012559},
author = {Paolo Italiani and Giacomo Frisoni and Gianluca Moro and Antonella Carbonaro and Claudio Sartori},
keywords = {Abstractive dialogue summarization, Input augmentation, Text classification, Gumbel-softmax trick, Interpretable natural language processing},
abstract = {Abstractive dialogue summarization requires distilling and rephrasing key information from noisy multi-speaker documents. Combining pre-trained language models with input augmentation techniques has recently led to significant research progress. However, existing solutions still struggle to select relevant chat segments, primarily relying on open-domain and unsupervised annotators not tailored to the actual needs of the summarization task. In this paper, we propose DearWatson, a task-aware utterance-level annotation framework for improving the effectiveness and interpretability of pre-trained dialogue summarization models. Precisely, we learn relevant utterances in the source document and mark them with special tags, that then act as supporting evidence for the generated summary. Quantitative experiments are conducted on two datasets made up of real-life messenger conversations. The results show that DearWatson allows model attention to focus on salient tokens, achieving new state-of-the-art results in three evaluation metrics, including semantic and factuality measures. Human evaluation proves the superiority of our solution in semantic consistency and recall. Finally, extensive ablation studies confirm each module’s importance, also exploring different annotation strategies and parameter-efficient fine-tuning of large generative language models.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231223012559,https://doi.org/10.1016/j.neucom.2023.127132,science_direct,2024
1405,Multi-turn dialogue comprehension from a topic-aware perspective,"@article{MA2024127385,
title = {Multi-turn dialogue comprehension from a topic-aware perspective},
journal = {Neurocomputing},
volume = {578},
pages = {127385},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127385},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224001565},
author = {Xinbei Ma and Yi Xu and Hai Zhao and Zhuosheng Zhang},
keywords = {Multi-turn dialogue modeling, Topic-aware, Segmentation, Clustering, Response selection},
abstract = {Dialogue Machine Reading Comprehension requires language models to effectively decouple and model multi-turn dialogue passages. As a dialogue development goes after the intentions of participants, its topic may not remain constant throughout the whole passage. Hence, it is non-trivial to detect and leverage the topic shift in dialogue modeling. Topic modeling, although has been widely studied in plain text, deserves far more utilization in dialogue reading comprehension. This paper proposes to model multi-turn dialogues from a topic-aware perspective. This paper starts with a dialogue segmentation algorithm to split a dialogue passage into topic-concentrated fragments in an unsupervised way. Then these fragments are used as topic-aware language processing units in further dialogue comprehension. On one hand, the split segments indict specific topics rather than mixed intentions, thus showing convenience on in-domain topic detection and location. For this task, this paper designs a clustering system with a self-training auto-encoder, and two constructed datasets are built for evaluation. On the other hand, the split segments are an appropriate element of multi-turn dialogue response selection. For this purpose, this paper further presents a novel model, Topic-Aware Dual-Attention Matching (TADAM) Network, which takes topic segments as processing elements and matches response candidates with a dual cross-attention. Empirical studies on three public benchmarks show great improvements over baselines. Our work continues the previous studies on document topic, and brings the dialogue modeling to a novel topic-aware perspective with exhaustive experiments and analyses.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231224001565,https://doi.org/10.1016/j.neucom.2024.127385,science_direct,2024
1406,Guided evolutionary neural architecture search with efficient performance estimation,"@article{LOPES2024127509,
title = {Guided evolutionary neural architecture search with efficient performance estimation},
journal = {Neurocomputing},
volume = {584},
pages = {127509},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127509},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224002807},
author = {Vasco Lopes and Miguel Santos and Bruno Degardin and Luís A. Alexandre},
keywords = {Neural Architecture Search, Convolutional Neural Networks, Evolution, Guided search, AutoML, Zero-proxy estimator},
abstract = {Neural Architecture Search (NAS) methods have been successfully applied to image tasks with excellent results. However, NAS methods are often complex and tend to converge to local minima as soon as generated architectures yield good results. This paper proposes GEA, a novel approach for guided NAS. GEA guides the evolution by exploring the search space by generating and evaluating several architectures in each generation at initialization stage using a zero-proxy estimator, where only the highest-scoring architecture is trained and kept for the next generation. Subsequently, GEA continuously extracts knowledge about the search space without increased complexity by generating several off-springs from an existing architecture at each generation. Moreover, GEA forces exploitation of the most performant architectures by descendant generation while simultaneously driving exploration through parent mutation and favouring younger architectures to the detriment of older ones. Experimental results demonstrate the effectiveness of the proposed method, and extensive ablation studies evaluate the importance of different parameters. Results show that GEA achieves competitive results on all data sets of NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101 benchmarks, as well as in the DARTS search space.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231224002807,https://doi.org/10.1016/j.neucom.2024.127509,science_direct,2024
1407,The joint learning of multi-resolution feature for multi-class retinal vessel segmentation,"@article{TANG2024127570,
title = {The joint learning of multi-resolution feature for multi-class retinal vessel segmentation},
journal = {Neurocomputing},
volume = {584},
pages = {127570},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127570},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224003412},
author = {Xiaofan Tang and Hao Chen and Xiangru Li and Sihua Yang},
keywords = {Retinal vessel segmentation, Multi-resolution learning, Cross-scale fusion, Deep learning},
abstract = {The task of multi-class vessel segmentation on retinal images is the basis for the arteriovenous quantitative analysis, and plays an important role in the diagnosis and treatment of cerebrovascular diseases. Due to the intricate details and intertwining of the retinal vessels, traditional feature learning networks based on single-level resolution images are prone to the troubles from arteriovenous confusion and vascular edge discontinuity. To this end, we develop a paradigm of multi-level image resolution joint learning. This scheme overcomes the limitation of the methods depending on single-level image resolution on feature modeling. Specifically, we designed a cross-scale feature fusion network with a dual-branch structure that integrates global and local perspectives. This approach enables the extraction of retinal image features across multiple resolutions, effectively compensating for the vascular feature gaps inherent in single-resolution network models. This framework not only corrects the intra-segment misclassification, but also improves continuity by supplementing the details of vascular edge. Furthermore, the cross-scale fusion process of the network at multiple stages is conducive to its optimization and enhances the collaborative learning ability of dual-branch. Meanwhile, we use the generative adversarial structure as the backbone to supervise and constrain the aforementioned feature fusion results. Finally, extensive experiments are conducted on three publicly available datasets, DRIVE-AV, LES-AV, and HRF-AV. It is shown that the proposed scheme outperforms the current state-of-the-art methods significantly. The source code is available at https://github.com/Tang9867/Multi-Resolution-Learning.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231224003412,https://doi.org/10.1016/j.neucom.2024.127570,science_direct,2024
1408,ESIE-BERT: Enriching sub-words information explicitly with BERT for intent classification and slot filling,"@article{GUO2024127725,
title = {ESIE-BERT: Enriching sub-words information explicitly with BERT for intent classification and slot filling},
journal = {Neurocomputing},
volume = {591},
pages = {127725},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127725},
url = {https://www.sciencedirect.com/science/article/pii/S092523122400496X},
author = {Yu Guo and Zhilong Xie and Xingyan Chen and Huangen Chen and Leilei Wang and Huaming Du and Shaopeng Wei and Yu Zhao and Qing Li and Gang Wu},
keywords = {Wordpiece, Intent classification, Slot filling, BERT, Attention mechanisms},
abstract = {Natural language understanding (NLU) has two core tasks: intent classification and slot filling. The success of pre-training language models resulted in a significant breakthrough in the two tasks. The architecture based on autoencoding (BERT-based model) can optimize the two tasks jointly. However, we note that BERT-based models convert each complex token into multiple sub-tokens by the Wordpiece algorithm, which generates an out-of-alignment between the length of the tokens and the labels. This leads to BERT-based models not performing well in label prediction, limiting model performance improvement. Many existing models can address this issue, but some hidden semantic information is discarded during fine-tuning. We addressed the problem by introducing a novel joint method on top of BERT. This method explicitly models multiple sub-token features after the Wordpiece tokenization, contributing to both tasks. Our proposed method effectively extracts contextual features from complex tokens using the Sub-words Attention Adapter (SAA), preserving overall utterance information. Additionally, we propose an Intent Attention Adapter (IAA) to acquire comprehensive sentence features, assisting users in predicting intent. Experimental results confirm that our proposed model exhibits significant improvements on two public benchmark datasets. Specifically, the slot-filling F1 score improves from 96.5 to 98.2 (an absolute increase of 1.7%) on the Airline Travel Information Systems (ATIS) dataset.}
}
",https://www.sciencedirect.com/science/article/pii/S092523122400496X,https://doi.org/10.1016/j.neucom.2024.127725,science_direct,2024
1409,Sentence salience contrastive learning for abstractive text summarization,"@article{HUANG2024127808,
title = {Sentence salience contrastive learning for abstractive text summarization},
journal = {Neurocomputing},
volume = {593},
pages = {127808},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127808},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224005794},
author = {Ying Huang and Zhixin Li and Zhenbin Chen and Canlong Zhang and Huifang Ma},
keywords = {Contrastive learning, Abstractive text summarization, Semantic similarity, Sentence salience},
abstract = {Abstractive Text summarization aims to generate a short summary for a document while preserving salient information. Recently, contrastive learning has been extended from visual representation to summarization tasks. At present, the methods of contrastive learning summarization focus on modeling the global semantics of source documents, targets and candidate summaries to maximize their similarities. However, they ignore the influence of sentence semantics in the document. In this paper, we propose a sentence-level salience contrastive learning method to help the model capture salient information and denoise. The model expresses the sentence salience according to the semantic similarity between the summaries and sentences of the source document, and integrates the similarity distance into the contrastive loss in the form of soft weights. Therefore, our model maximize the similarity between summaries and salient information, while minimizing the similarity between summaries and potential noise. We have verified our method in three widely used datasets, CNN/Daily Mail, XSum and PubMed. The experimental results show that the proposed method can significantly improve the baseline performance and achieve competitive performance in the existing contrastive learning methods.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231224005794,https://doi.org/10.1016/j.neucom.2024.127808,science_direct,2024
1410,Fusing semantic information for syntax-guided paraphrase generation,"@article{ZHANG2024128009,
title = {Fusing semantic information for syntax-guided paraphrase generation},
journal = {Neurocomputing},
volume = {597},
pages = {128009},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128009},
url = {https://www.sciencedirect.com/science/article/pii/S092523122400780X},
author = {Haoran Zhang and Li Li},
keywords = {Paraphrase generation, Contrastive learning, Semantics and syntax, Transformer},
abstract = {Syntax-guided paraphrase generation (SGPG) refers to generating a paraphrase sentence that satisfies the given syntactic structure without changing the source sentences’ semantics. The commonly utilized syntactic structures are part-of-speech (POS) sequence, constituency parse tree, and masked template, with constituency parse tree achieving State-of-The-Art (SOTA) performance because of its rich syntactic information. As a result, further mining of syntactic information in parse trees has grown popular, yet fewer works pay attention to investigating semantic information in source sentences. A sentence is made up of two parts: syntax and semantics. Multiple studies have shown that improving the model’s ability to learn semantic information is critical for paraphrase construction as well as syntax learning. In this paper, we propose Fusing Semantic Information for Syntax-guided Paraphrase Generation (FS-SPG). Specifically, we propose a transformer-based semantic encoder to obtain detailed semantics from source sentences. This encoder contains a Semantics-Aware Attention mechanism for mining semantic information. In addition, we apply contrastive learning to improve the accuracy of parse tree nodes’ guidance to semantic sentences. Experiments on ParaNMT and QQP-Pos show that our model beats the SOTA model SI-SCP by 4.92% in syntactic metrics and 1.35% in semantic metrics.}
}
",https://www.sciencedirect.com/science/article/pii/S092523122400780X,https://doi.org/10.1016/j.neucom.2024.128009,science_direct,2024
1411,CoProLITE: Constrained Proxy Learning for lIver and hepaTic lesion sEgmentation,"@article{FU2024128014,
title = {CoProLITE: Constrained Proxy Learning for lIver and hepaTic lesion sEgmentation},
journal = {Neurocomputing},
volume = {598},
pages = {128014},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128014},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224007859},
author = {Yuchen Fu and Song Liu and Cong Wang and Zhiwei Jiang and Juan Du and Qing Gu},
keywords = {Liver tumor segmentation, Proxy learning, Deep convolutional neural network},
abstract = {Liver and hepatic lesion segmentation is an important task in medical image analysis, which plays a crucial role in diagnosis, treatment planning and monitoring of liver diseases. We observed an ordinal layout of the feature space that aligns with CT image characteristics will improve performance on liver and hepatic lesion segmentation task. In order to enforce the samples to conform to a specific layout of the feature space, we propose a novel liver and hepatic lesion segmentation method called CoProLITE, which learns a constrained proxy for each classes. Specifically, We replace the traditional FCN-based segmentation head by a proxy learning-based head to learn feature representations of the images, and introduces constraints during the training process to guide the learning of the proxies. We extensively evaluate CoProLITE on three public datasets and compare it to state-of-the-art methods. The experimental results demonstrate the effectiveness of the proposed method.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231224007859,https://doi.org/10.1016/j.neucom.2024.128014,science_direct,2024
1412,Offline prompt polishing for low quality instructions,"@article{YU2024128046,
title = {Offline prompt polishing for low quality instructions},
journal = {Neurocomputing},
volume = {598},
pages = {128046},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128046},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224008178},
author = {Jia Yu and Zhanchao Zhou and Long Li and Ling Li and Yuming Yan and Renjun Xu and Zhenzhong Lan},
keywords = {LLM, Dataset, User scenario, Offline prompt polishing},
abstract = {Instruction-tuning is an effective avenue for making large language models (LLMs) better at following real users’ instructions. However, it is challenging in aligning to human preference in user scenario since the instructions model received are usually not well-formatted. In this paper, we introduce offline prompt polishing and inserting specific delimiters before inputting them to the models to cope with these bad instructions. To better understand the user behavior in proposing instructions and how language models align to them, we introduce User-based Instructional Dataset (UID), a dataset comprises over 96,000 instruction–response pairs which contains over 3k human-revised free-form instructions collected from real-world scenarios. Within UID, we kept both original and revised instructions to improve model robustness. We obtained various IOPTs checkpoints, a range of OPT models (125M to 13B) trained with UID, through offline prompt polishing and delimiter insertion. The results demonstrate that IOPT-2.7B trained on 6,000 instances can achieve comparable performance to a 175B InstructGPT. Besides, we rigorously measure the impact of various factors including data volume, model size, and instruction format on aligning to real users’ instructions. We summarize several findings to shed a light on instruction-tuning under user scenario. Our dataset will be made public upon acceptance.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231224008178,https://doi.org/10.1016/j.neucom.2024.128046,science_direct,2024
1413,A review of green artificial intelligence: Towards a more sustainable future,"@article{BOLONCANEDO2024128096,
title = {A review of green artificial intelligence: Towards a more sustainable future},
journal = {Neurocomputing},
pages = {128096},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128096},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224008671},
author = {Verónica Bolón-Canedo and Laura Morán-Fernández and Brais Cancela and Amparo Alonso-Betanzos},
keywords = {Green machine learning, Sustainability, Green-by AI, Green-in AI},
abstract = {Green artificial intelligence (AI) is more environmentally friendly and inclusive than conventional AI, as it not only produces accurate results without increasing the computational cost but also ensures that any researcher with a laptop can perform high-quality research without the need for costly cloud servers. This paper discusses green AI as a pivotal approach to enhancing the environmental sustainability of AI systems. Described are AI solutions for eco-friendly practices in other fields (green-by AI), strategies for designing energy-efficient machine learning (ML) algorithms and models (green-in AI), and tools for accurately measuring and optimizing energy consumption. Also examined are the role of regulations in promoting green AI and future directions for sustainable ML. Underscored is the importance of aligning AI practices with environmental considerations, fostering a more eco-conscious and energy-efficient future for AI systems.}
}
",https://www.sciencedirect.com/science/article/pii/S0925231224008671,https://doi.org/10.1016/j.neucom.2024.128096,science_direct,2024
1414,A survey of GPT-3 family large language models including ChatGPT and GPT-4,"@article{KALYAN2024100048,
title = {A survey of GPT-3 family large language models including ChatGPT and GPT-4},
journal = {Natural Language Processing Journal},
volume = {6},
pages = {100048},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2023.100048},
url = {https://www.sciencedirect.com/science/article/pii/S2949719123000456},
author = {Katikapalli Subramanyam Kalyan},
keywords = {Large language models, LLMs, GPT-3, ChatGPT, GPT-4, Transformers, LLM survey},
abstract = {Large language models (LLMs) are a special class of pretrained language models (PLMs) obtained by scaling model size, pretraining corpus and computation. LLMs, because of their large size and pretraining on large volumes of text data, exhibit special abilities which allow them to achieve remarkable performances without any task-specific training in many of the natural language processing tasks. The era of LLMs started with OpenAI’s GPT-3 model, and the popularity of LLMs has increased exponentially after the introduction of models like ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models, including ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With the ever-rising popularity of GLLMs, especially in the research community, there is a strong need for a comprehensive survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. We then present a brief overview of GLLMs and discuss the performances of GLLMs in various downstream tasks, specific domains and multiple languages. We also discuss the data labelling and data augmentation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. To summarize, this comprehensive survey paper will serve as a good resource for both academic and industry people to stay updated with the latest research related to GLLMs.}
}
",https://www.sciencedirect.com/science/article/pii/S2949719123000456,https://doi.org/10.1016/j.nlp.2023.100048,science_direct,2024
1415,Deception detection using machine learning (ML) and deep learning (DL) techniques: A systematic review,"@article{PROME2024100057,
title = {Deception detection using machine learning (ML) and deep learning (DL) techniques: A systematic review},
journal = {Natural Language Processing Journal},
volume = {6},
pages = {100057},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100057},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000050},
author = {Shanjita Akter Prome and Neethiahnanthan Ari Ragavan and Md Rafiqul Islam and David Asirvatham and Anasuya Jegathevi Jegathesan},
keywords = {Deception detection, Lie detection, Artificial intelligence, Deep learning, Machine learning, Facial expression},
abstract = {Deception detection is a crucial concern in our daily lives, with its effect on social interactions. The human face is a rich source of data that offers trustworthy markers of deception. The deception detection systems are non-intrusive, cost-effective, and mobile by identifying face expressions. Over the last decade, numerous studies have been conducted on deception/lie detection using several advanced techniques. Researchers have given their attention to inventing more effective and efficient solutions for deception detection. However, there are still a lot of opportunities for innovative deception detection methods. Thus, in this literature review, we conduct the statistical analysis by following the PRISMA protocol and extract various articles from five e-databases. The main objectives of this paper are (i) to explain the overview of machine learning (ML) and deep learning (DL) techniques for deception detection, (ii) to outline the existing literature, and (iii) to address the current challenges and its research prospects for further study. While significant issues in deception detection methods are acknowledged, the review highlights key conclusions and offers a systematic analysis of state-of-the-art techniques, emphasizing contributions and opportunities. The findings illuminate current trends and future research prospects, fostering ongoing development in the field.}
}
",https://www.sciencedirect.com/science/article/pii/S2949719124000050,https://doi.org/10.1016/j.nlp.2024.100057,science_direct,2024
1416,Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review,"@article{JIM2024100059,
title = {Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review},
journal = {Natural Language Processing Journal},
volume = {6},
pages = {100059},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100059},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000074},
author = {Jamin Rahman Jim and Md Apon Riaz Talukder and Partha Malakar and Md Mohsin Kabir and Kamruddin Nur and M.F. Mridha},
keywords = {Sentiment classification, Text classification, Natural language processing, Emotion detection, Sentiment analysis},
abstract = {Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative, or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices, and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them within the context of existing research. We then delved into prevalent pre-processing techniques, datasets, and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles. Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed future research directions to mitigate these concerns. This extensive review provides a complete understanding of sentiment analysis, covering its models, application domains, results analysis, challenges, and research directions.}
}
",https://www.sciencedirect.com/science/article/pii/S2949719124000074,https://doi.org/10.1016/j.nlp.2024.100059,science_direct,2024
1417,Transformer-based text similarity and second language proficiency: A case of written production by learners of Korean,"@article{SHIN2024100060,
title = {Transformer-based text similarity and second language proficiency: A case of written production by learners of Korean},
journal = {Natural Language Processing Journal},
volume = {6},
pages = {100060},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100060},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000086},
author = {Gyu-Ho Shin and Boo Kyung Jung and Seongmin Mun},
keywords = {Second language writing, Transformer, Similarity score, Proficiency, Human rating},
abstract = {The present study applies two transformer models (BERT; GPT-2) to analyse argumentative essays produced by two first-language groups (Czech; English) of second-language learners of Korean and investigates how informative similarity scores of learner writing obtained by these models explain general language proficiency in Korean. Results show three major aspects on model performance. First, the relationships between the similarity scores and the proficiency scores differ from the tendencies between the human rating scores and the proficiency scores. Second, the degree to which the similarity scores obtained by each model explain the proficiency scores is asymmetric and idiosyncratic. Third, the performance of the two models is affected by learners’ native language and essay topic. These findings invite the need for researchers and educators to pay attention to how computational algorithms operate, together with learner language characteristics and language-specific properties of the target language, in utilising Natural Language Processing methods and techniques for their research or instructional purposes.}
}
",https://www.sciencedirect.com/science/article/pii/S2949719124000086,https://doi.org/10.1016/j.nlp.2024.100060,science_direct,2024
1418,Understanding latent affective bias in large pre-trained neural language models,"@article{KADAN2024100062,
title = {Understanding latent affective bias in large pre-trained neural language models},
journal = {Natural Language Processing Journal},
volume = {7},
pages = {100062},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100062},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000104},
author = {Anoop Kadan and Deepak P. and Sahely Bhadra and Manjary {P. Gangan} and Lajish V.L.},
keywords = {Affective bias in NLP, Fairness in NLP, Pre-trained language models, Textual emotion detection, Deep learning},
abstract = {Groundbreaking inventions and highly significant performance improvements in deep learning based Natural Language Processing are witnessed through the development of transformer based large Pre-trained Language Models (PLMs). The wide availability of unlabeled data within human generated data deluge along with self-supervised learning strategy helps to accelerate the success of large PLMs in language generation, language understanding, etc. But at the same time, latent historical bias/unfairness in human minds towards a particular gender, race, etc., encoded unintentionally/intentionally into the corpora harms and questions the utility and efficacy of large PLMs in many real-world applications, particularly for the protected groups. In this paper, we present an extensive investigation towards understanding the existence of “Affective Bias” in large PLMs to unveil any biased association of emotions such as anger, fear, joy, etc., towards a particular gender, race or religion with respect to the downstream task of textual emotion detection. We conduct our exploration of affective bias from the very initial stage of corpus level affective bias analysis by searching for imbalanced distribution of affective words within a domain, in large scale corpora that are used to pre-train and fine-tune PLMs. Later, to quantify affective bias in model predictions, we perform an extensive set of class-based and intensity-based evaluations using various bias evaluation corpora. Our results show the existence of statistically significant affective bias in the PLM based emotion detection systems, indicating biased association of certain emotions towards a particular gender, race, and religion.}
}
",https://www.sciencedirect.com/science/article/pii/S2949719124000104,https://doi.org/10.1016/j.nlp.2024.100062,science_direct,2024
1419,Utilization of generative AI for the characterization and identification of visual unknowns,"@article{COMBS2024100064,
title = {Utilization of generative AI for the characterization and identification of visual unknowns},
journal = {Natural Language Processing Journal},
volume = {7},
pages = {100064},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100064},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000128},
author = {Kara Combs and Trevor J. Bihl and Subhashini Ganapathy},
keywords = {Generative AI, Computer vision, Natural language processing, Analogical reasoning},
abstract = {Current state-of-the-art artificial intelligence (AI) struggles with accurate interpretation of out-of-library objects. One method proposed remedy is analogical reasoning (AR), which utilizes abductive reasoning to draw inferences on an unfamiliar scenario given knowledge about a similar familiar scenario. Currently, applications of visual AR gravitate toward analogy-formatted image problems rather than real-world computer vision data sets. This paper proposes the Image Recognition Through Analogical Reasoning Algorithm (IRTARA) and its “generative AI” version called “GIRTARA” which describes and predicts out-of-library visual objects. IRTARA characterizes the out-of-library object through a list of words called the “term frequency list”. GIRTARA uses the term frequency list to predict what the out-of-library object is. To evaluate the quality of the results of IRTARA, both quantitative and qualitative assessments are used, including a baseline to compare the automated methods with human-generated results. The accuracy of GIRTARA’s predictions is calculated through a cosine similarity analysis. This study observed that IRTARA had consistent results in the term frequency list based on the three evaluation methods for the high-quality results and GIRTARA was able to obtain up to 65% match in terms of cosine similarity when compared to the out-of-library object’s true labels.}
}
",https://www.sciencedirect.com/science/article/pii/S2949719124000128,https://doi.org/10.1016/j.nlp.2024.100064,science_direct,2024
1420,Cutting through the noise to motivate people: A comprehensive analysis of COVID-19 social media posts de/motivating vaccination,"@article{RAHMAN2024100085,
title = {Cutting through the noise to motivate people: A comprehensive analysis of COVID-19 social media posts de/motivating vaccination},
journal = {Natural Language Processing Journal},
pages = {100085},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100085},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000335},
author = {Ashiqur Rahman and Ehsan Mohammadi and Hamed Alhoori},
keywords = {Misinformation, Motivation, Vaccine hesitancy, Science communication, Social media, Social psychology},
abstract = {The COVID-19 pandemic exposed significant weaknesses in the healthcare information system. The overwhelming volume of misinformation on social media and other socioeconomic factors created extraordinary challenges to motivate people to take proper precautions and get vaccinated. In this context, our work explored a novel direction by analyzing an extensive dataset collected over two years, identifying the topics de/motivating the public about COVID-19 vaccination. We analyzed these topics based on time, geographic location, and political orientation. We noticed that while the motivating topics remain the same over time and geographic location, the demotivating topics rapidly. We also identified that intrinsic motivation, rather than external mandate, is more advantageous to inspire the public. This study addresses scientific communication and public motivation in social media. It can help public health officials, policymakers, and social media platforms develop more effective messaging strategies to cut through the noise of misinformation and educate the public about scientific findings.}
}
",https://www.sciencedirect.com/science/article/pii/S2949719124000335,https://doi.org/10.1016/j.nlp.2024.100085,science_direct,2024
1421,A social network of crime: A review of the use of social networks for crime and the detection of crime,"@article{DRURY2022100211,
title = {A social network of crime: A review of the use of social networks for crime and the detection of crime},
journal = {Online Social Networks and Media},
volume = {30},
pages = {100211},
year = {2022},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2022.100211},
url = {https://www.sciencedirect.com/science/article/pii/S2468696422000155},
author = {Brett Drury and Samuel Morais Drury and Md Arafatur Rahman and Ihsan Ullah},
keywords = {Social media, Cybercrime, Machine learning, Crime prediction, NLP},
abstract = {Social media is used to commit and detect crimes. With automated methods, it is possible to scale both crime and detection of crime to a large number of people. The ability of criminals to reach large numbers of people has made this area subject to frequent study, and consequently, there have been several surveys that have reviewed specific crimes committed on social platforms. Until now, there has not been a review article that considers all types of crimes on social media, their similarity as well as their detection. The demonstration of similarity between crimes and their detection methods allows for the transfer of techniques and data between domains. This survey, therefore, seeks to document the crimes that have been committed on social media, and demonstrate their similarity through a taxonomy of crimes. Also, this survey documents publicly available datasets. Finally, this survey provides suggestions for further research in this field.}
}
",https://www.sciencedirect.com/science/article/pii/S2468696422000155,https://doi.org/10.1016/j.osnem.2022.100211,science_direct,2022
1422,Evaluating password strength based on information spread on social networks: A combined approach relying on data reconstruction and generative models,"@article{ATZORI2024100278,
title = {Evaluating password strength based on information spread on social networks: A combined approach relying on data reconstruction and generative models},
journal = {Online Social Networks and Media},
volume = {42},
pages = {100278},
year = {2024},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2024.100278},
url = {https://www.sciencedirect.com/science/article/pii/S246869642400003X},
author = {Maurizio Atzori and Eleonora Calò and Loredana Caruccio and Stefano Cirillo and Giuseppe Polese and Giandomenico Solimando},
keywords = {Privacy-preserving, Password-disclosure, Data wrapping, Data reconstruction, Social network},
abstract = {Ensuring the security of personal accounts has become a key concern due to the widespread password attack techniques. Although passwords are the primary defense against unauthorized access, the practice of reusing easy-to-remember passwords increases security risks for people. Traditional methods for evaluating password strength are often insufficient since they overlook the public personal information that users frequently share on social networks. In addition, while users tend to limit access to their data on single profiles, personal data is often unintentionally shared across multiple profiles, exposing users to password threats. In this paper, we present an extension of a data reconstruction tool, namely soda advance, which incorporates a new module to evaluate password strength based on publicly available data across multiple social networks. It relies on a new metric to provide a comprehensive evaluation of password strength. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Specifically, by exploiting the proliferation of LLMs, it has been possible to interact with many LLMs through Automated Template Learning methodologies. Experimental evaluations, performed with 100 real users, demonstrate the effectiveness of LLMs in generating strong passwords with respect to data associated with users’ profiles. Furthermore, LLMs have proved to be effective also in evaluation tasks, but the combined usage of LLMs and soda advance guaranteed better classifications up to more than 10% in terms of F1-score.}
}
",https://www.sciencedirect.com/science/article/pii/S246869642400003X,https://doi.org/10.1016/j.osnem.2024.100278,science_direct,2024
1424,A survey on text generation using generative adversarial networks,"@article{DEROSA2021108098,
title = {A survey on text generation using generative adversarial networks},
journal = {Pattern Recognition},
volume = {119},
pages = {108098},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108098},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321002855},
author = {Gustavo H. {de Rosa} and João P. Papa},
keywords = {Text generation, Generative adversarial Networks, Machine learning, Language modeling, Natural language processing},
abstract = {This work presents a thorough review concerning recent studies and text generation advancements using Generative Adversarial Networks. The usage of adversarial learning for text generation is promising as it provides alternatives to generate the so-called “natural” language. Nevertheless, adversarial text generation is not a simple task as its foremost architecture, the Generative Adversarial Networks, were designed to cope with continuous information (image) instead of discrete data (text). Thus, most works are based on three possible options, i.e., Gumbel-Softmax differentiation, Reinforcement Learning, and modified training objectives. All alternatives are reviewed in this survey as they present the most recent approaches for generating text using adversarial-based techniques. The selected works were taken from renowned databases, such as Science Direct, IEEEXplore, Springer, Association for Computing Machinery, and arXiv, whereas each selected work has been critically analyzed and assessed to present its objective, methodology, and experimental results.}
}
",https://www.sciencedirect.com/science/article/pii/S0031320321002855,https://doi.org/10.1016/j.patcog.2021.108098,science_direct,2021
1425,Time pattern reconstruction for classification of irregularly sampled time series,"@article{SUN2024110075,
title = {Time pattern reconstruction for classification of irregularly sampled time series},
journal = {Pattern Recognition},
volume = {147},
pages = {110075},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2023.110075},
url = {https://www.sciencedirect.com/science/article/pii/S0031320323007720},
author = {Chenxi Sun and Hongyan Li and Moxian Song and Derun Cai and Baofeng Zhang and Shenda Hong},
keywords = {Classification of irregularly sampled time series, Time pattern, Deep learning, Healthcare and medical application},
abstract = {Irregularly Sampled Time Series (ISTS) include partially observed feature vectors caused by the lack of temporal alignment across dimensions and the presence of variable time intervals. Especially in medical applications, because patients’ examinations depend on their health status, observations in this event-based medical time series are nonuniformly distributed. When using deep learning models to classify ISTS, most work defines the problem that needs to be solved as alignment-caused data missing or nonuniformity-caused dependency change. However, they only modeled relationships between observed values, ignoring the fact that time is the independent variable for a time series. In this paper, we emphasize that irregularity is active, time-depended, and class-associated and is reflected in the Time Pattern (TP). To this end, this paper focused on the TP of ISTS for the first time, proposing a Time Pattern Reconstruction (TPR) method. It first encodes time information by the time encoding mechanism, then imputes values from time codes by the continuous-discrete Kalman network, selects key time points by the conditional masking mechanism, and finally classifies ISTS based on the reconstructed TP. Experiments on four real-world medical datasets and three other datasets show that TPR outperforms all baselines. We also show that TP can reveal biomarkers and key time points for diseases.}
}
",https://www.sciencedirect.com/science/article/pii/S0031320323007720,https://doi.org/10.1016/j.patcog.2023.110075,science_direct,2024
1426,Prompting large language model with context and pre-answer for knowledge-based VQA,"@article{HU2024110399,
title = {Prompting large language model with context and pre-answer for knowledge-based VQA},
journal = {Pattern Recognition},
volume = {151},
pages = {110399},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.110399},
url = {https://www.sciencedirect.com/science/article/pii/S003132032400150X},
author = {Zhongjian Hu and Peng Yang and Yuanshuang Jiang and Zijian Bai},
keywords = {Visual question answering, Large language model, Knowledge-based VQA, Fine-tuning, In-context learning},
abstract = {Existing studies apply Large Language Model (LLM) to knowledge-based Visual Question Answering (VQA) with encouraging results. Due to the insufficient input information, the previous methods still have shortcomings in constructing the prompt for LLM, and cannot fully activate the capacity of LLM. In addition, previous works adopt GPT-3 for inference, which has expensive costs. In this paper, we propose PCPA: a framework that Prompts LLM with Context and Pre-Answer for VQA. Specifically, we adopt a vanilla VQA model to generate in-context examples and candidate answers, and add a pre-answer selection layer to generate pre-answers. We integrate in-context examples and pre-answers into the prompt to inspire the LLM. In addition, we choose LLaMA instead of GPT-3, which is an open and free model. We build a small dataset to fine-tune the LLM. Compared to existing baselines, the PCPA improves accuracy by more than 2.1 and 1.5 on OK-VQA and A-OKVQA, respectively.}
}
",https://www.sciencedirect.com/science/article/pii/S003132032400150X,https://doi.org/10.1016/j.patcog.2024.110399,science_direct,2024
1427,Multimodal prediction of student performance: A fusion of signed graph neural networks and large language models,"@article{WANG20241,
title = {Multimodal prediction of student performance: A fusion of signed graph neural networks and large language models},
journal = {Pattern Recognition Letters},
volume = {181},
pages = {1-8},
year = {2024},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2024.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167865524000758},
author = {Sijie Wang and Lin Ni and Zeyu Zhang and Xiaoxuan Li and Xianda Zheng and Jiamou Liu},
keywords = {Signed network, Graph representations learning, Natural language processing, Multimodal},
abstract = {In online education platforms, accurately predicting student performance is essential for timely dropout prevention and interventions for at-risk students. This task is made difficult by the prevalent use of Multiple-Choice Questions (MCQs) in learnersourcing platforms, where noise in student-generated content and the limitations of existing unsigned graph-based models, specifically their inability to distinguish the semantic meaning between correct and incorrect responses, hinder accurate performance predictions. To address these issues, we introduce the Large Language Model enhanced Signed Bipartite graph Contrastive Learning (LLM-SBCL) model—a novel Multimodal Model utilizing Signed Graph Neural Networks (SGNNs) and a Large Language Model (LLM). Our model uses a signed bipartite graph to represent students’ answers, with positive and negative edges denoting correct and incorrect responses, respectively. To mitigate noise impact, we apply contrastive learning to the signed graphs, combined with knowledge point embeddings from the LLM to further enhance our model’s predictive performance. Upon evaluating our model on five real-world datasets, it demonstrates superior accuracy and stability, exhibiting an average F1 improvement of 3.7% over the best baseline models.}
}
",https://www.sciencedirect.com/science/article/pii/S0167865524000758,https://doi.org/10.1016/j.patrec.2024.03.007,science_direct,2024
1428,Atomist or holist? A diagnosis and vision for more productive interdisciplinary AI ethics dialogue,"@article{GREENE2023100652,
title = {Atomist or holist? A diagnosis and vision for more productive interdisciplinary AI ethics dialogue},
journal = {Patterns},
volume = {4},
number = {1},
pages = {100652},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2022.100652},
url = {https://www.sciencedirect.com/science/article/pii/S2666389922002926},
author = {Travis Greene and Amit Dhurandhar and Galit Shmueli},
abstract = {Summary
In response to growing recognition of the social impacts of new artificial intelligence (AI)-based technologies, major AI and machine learning (ML) conferences and journals now encourage or require papers to include ethics impact statements and undergo ethics reviews. This move has sparked heated debate concerning the role of ethics in AI research, at times devolving into name calling and threats of “cancellation.” We diagnose this conflict as one between “atomist” and “holist” ideologies. Among other things, atomists believe facts are and should be kept separate from values, while holists believe facts and values are and should be inextricable from one another. With the goal of reducing disciplinary polarization, we draw on numerous philosophical and historical sources to describe each ideology’s core beliefs and assumptions. Finally, we call on atomists and holists within the ever-expanding data science community to exhibit greater empathy during ethical disagreements and propose four targeted strategies to ensure AI research benefits society.}
}
",https://www.sciencedirect.com/science/article/pii/S2666389922002926,https://doi.org/10.1016/j.patter.2022.100652,science_direct,2023
1429,"This new conversational AI model can be your friend, philosopher, and guide ... and even your worst enemy","@article{CHATTERJEE2023100676,
title = {This new conversational AI model can be your friend, philosopher, and guide ... and even your worst enemy},
journal = {Patterns},
volume = {4},
number = {1},
pages = {100676},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2022.100676},
url = {https://www.sciencedirect.com/science/article/pii/S2666389922003233},
author = {Joyjit Chatterjee and Nina Dethlefs},
abstract = {We explore the recently released ChatGPT model, one of the most powerful conversational AI models that has ever been developed. This opinion provides a perspective on its strengths and weaknesses and a call to action for the AI community (including academic researchers and industry) to work together on preventing potential misuse of such powerful AI models in our everyday lives.}
}
",https://www.sciencedirect.com/science/article/pii/S2666389922003233,https://doi.org/10.1016/j.patter.2022.100676,science_direct,2023
1430,A historical perspective of biomedical explainable AI research,"@article{MALINVERNO2023100830,
title = {A historical perspective of biomedical explainable AI research},
journal = {Patterns},
volume = {4},
number = {9},
pages = {100830},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100830},
url = {https://www.sciencedirect.com/science/article/pii/S266638992300199X},
author = {Luca Malinverno and Vesna Barros and Francesco Ghisoni and Giovanni Visonà and Roman Kern and Philip J. Nickel and Barbara Elvira Ventura and Ilija Šimić and Sarah Stryeck and Francesca Manni and Cesar Ferri and Claire Jean-Quartier and Laura Genga and Gabriele Schweikert and Mario Lovrić and Michal Rosen-Zvi},
keywords = {explainability, COVID-19, coronavirus, artificial intelligence, machine learning, meta-review, PRISMA, decision-making, trustworthiness, foundation models},
abstract = {Summary
The black-box nature of most artificial intelligence (AI) models encourages the development of explainability methods to engender trust into the AI decision-making process. Such methods can be broadly categorized into two main types: post hoc explanations and inherently interpretable algorithms. We aimed at analyzing the possible associations between COVID-19 and the push of explainable AI (XAI) to the forefront of biomedical research. We automatically extracted from the PubMed database biomedical XAI studies related to concepts of causality or explainability and manually labeled 1,603 papers with respect to XAI categories. To compare the trends pre- and post-COVID-19, we fit a change point detection model and evaluated significant changes in publication rates. We show that the advent of COVID-19 in the beginning of 2020 could be the driving factor behind an increased focus concerning XAI, playing a crucial role in accelerating an already evolving trend. Finally, we present a discussion with future societal use and impact of XAI technologies and potential future directions for those who pursue fostering clinical trust with interpretable machine learning models.}
}
",https://www.sciencedirect.com/science/article/pii/S266638992300199X,https://doi.org/10.1016/j.patter.2023.100830,science_direct,2023
1431,The landscape of biomedical research,"@article{GONZALEZMARQUEZ2024100968,
title = {The landscape of biomedical research},
journal = {Patterns},
volume = {5},
number = {6},
pages = {100968},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100968},
url = {https://www.sciencedirect.com/science/article/pii/S266638992400076X},
author = {Rita González-Márquez and Luca Schmidt and Benjamin M. Schmidt and Philipp Berens and Dmitry Kobak},
keywords = {metascience, publications, PubMed, language models, embeddings, visualization, machine learning, gender bias, retractions},
abstract = {Summary
The number of publications in biomedicine and life sciences has grown so much that it is difficult to keep track of new scientific works and to have an overview of the evolution of the field as a whole. Here, we present a two-dimensional (2D) map of the entire corpus of biomedical literature, based on the abstract texts of 21 million English articles from the PubMed database. To embed the abstracts into 2D, we used the large language model PubMedBERT, combined with t-SNE tailored to handle samples of this size. We used our map to study the emergence of the COVID-19 literature, the evolution of the neuroscience discipline, the uptake of machine learning, the distribution of gender imbalance in academic authorship, and the distribution of retracted paper mill articles. Furthermore, we present an interactive website that allows easy exploration and will enable further insights and facilitate future research.}
}
",https://www.sciencedirect.com/science/article/pii/S266638992400076X,https://doi.org/10.1016/j.patter.2024.100968,science_direct,2024
1432,"Meet the authors: Rita González-Márquez, Philipp Berens, and Dmitry Kobak","@article{GONZALEZMARQUEZ2024100993,
title = {Meet the authors: Rita González-Márquez, Philipp Berens, and Dmitry Kobak},
journal = {Patterns},
volume = {5},
number = {6},
pages = {100993},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100993},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924001089},
author = {Rita González-Márquez and Philipp Berens and Dmitry Kobak},
abstract = {In their recent publication in Patterns,1 the authors present a 2D atlas of the entire English biomedical literature.}
}
",https://www.sciencedirect.com/science/article/pii/S2666389924001089,https://doi.org/10.1016/j.patter.2024.100993,science_direct,2024
1433,Churn Prediction in Telecommunication using Logistic Regression and Logit Boost,"@article{JAIN2020101,
title = {Churn Prediction in Telecommunication using Logistic Regression and Logit Boost},
journal = {Procedia Computer Science},
volume = {167},
pages = {101-112},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.187},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920306529},
author = {Hemlata Jain and Ajay Khunteta and Sumit Srivastava},
keywords = {Machine Learning, Logistic Regression, Logit Boost},
abstract = {Today in every industry weather, it is ISP, IT products, social network or mobile services there is the problem of customer churn (Customers changing their services from one service provider to another). However, in telecommunication the customers churning very frequently. As the market in telecom is fiercely competitive, in that case, companies proactively have to determine the customers churn by analyzing their behavior and try to put effort and money in retaining the customers. In this proposed model, two machine-learning techniques were used for predicting customer churn Logistic regression and Logit Boost. Experiment was carried out in the WEKA Machine-learning tool, along with a real database from an American company Orange. The result were shown in different evaluation measures.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050920306529,https://doi.org/10.1016/j.procs.2020.03.187,science_direct,2020
1434,Technology-Assisted Motivational Interviewing: Developing a Scalable Framework for Promoting Engagement with Tobacco Cessation Using NLP and Machine Learning,"@article{SAIYED2022121,
title = {Technology-Assisted Motivational Interviewing: Developing a Scalable Framework for Promoting Engagement with Tobacco Cessation Using NLP and Machine Learning},
journal = {Procedia Computer Science},
volume = {206},
pages = {121-131},
year = {2022},
note = {International Society for Research on Internet Interventions 11th Scientific Meeting},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.091},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922009644},
author = {Ahson Saiyed and John Layton and Brian Borsari and Jing Cheng and Tatyana Kanzaveli and Maksim Tsvetovat and Jason Satterfield},
keywords = {smoking cessation, motivational interviewing, digital health, chatbot, machine learning models},
abstract = {Motivational interviewing (MI) improves readiness for smoking cessation but can be time-intensive, require substantial expertise, and patients must still be linked with evidence-based cessation programs sensitive to local resources and patient preferences. Technology-assisted MI may provide a more efficient way to promote readiness and facilitate behavior change. This study developed the Technology Assisted Motivational Interviewing Coach (TAMI), a digital conversational agent that incorporates machine learning models to deliver MI for tobacco cessation and create tailored quit plans. This manuscript describes and evaluates the architecture and nested machine learning models within TAMI leveraged during the pilot clinical trial.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050922009644,https://doi.org/10.1016/j.procs.2022.09.091,science_direct,2022
1435,Collaborative Work Alternatives with ChatGPT Based on Evaluation Criteria for its Use in Higher Education: Application of the PROMETHEE-SAPEVO-M1 Method,"@article{PINOCHET2023177,
title = {Collaborative Work Alternatives with ChatGPT Based on Evaluation Criteria for its Use in Higher Education: Application of the PROMETHEE-SAPEVO-M1 Method},
journal = {Procedia Computer Science},
volume = {221},
pages = {177-184},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923007214},
author = {Luis Hernan Contreras Pinochet and Miguel Ângelo Lellis Moreira and Luiz Paulo Fávero and Marcos dos Santos and Vanessa Itacaramby Pardim},
keywords = {Artificial intelligence, ChatGPT, collaborative work, Higher Education, PROMETHEE-SAPEVO-M1 method},
abstract = {The objective of this article is to adopt the integration of two methods of Multicriteria Decision Support, based on the axiomatic models PROMETHEE and SAPEVO-M1, aggregating data of a qualitative nature through ordinal entries to analyze collaborative work alternatives with ChatGPT from evaluation criteria for its use in higher education. It is highlighted that the alternative with the best performance is ‘Support for Autonomous Learning,’ presenting the highest positive flow and the lowest negative flow, exposing a natural preference over the set. In this study, ‘Emotional Support’ was the worst alternative. It occurs because the tool is still under discussion when addressing issues such as the lack of human interaction, reduced critical thinking, and less empathy.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923007214,https://doi.org/10.1016/j.procs.2023.07.025,science_direct,2023
1436,The method of constructing basic-element base using large language model- Take the issue of rice waste,"@article{LONGHAO20231493,
title = {The method of constructing basic-element base using large language model- Take the issue of rice waste},
journal = {Procedia Computer Science},
volume = {221},
pages = {1493-1500},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923007706},
author = {WANG Long-hao and LI Ding-jie and LI Xing-sen},
keywords = {Large language model;Extenics;Basic-element base;Rice waste;ChatGPT},
abstract = {The rapid development of artificial intelligence technology has led to the emergence of large language models such as ChatGPT represented by natural language processing technology, but currently there is no effective way to input all the information to be exchanged. In this paper, a method of constructing local basic-element base of input information by combining the large language model with extenics is proposed. Taking rice waste problem as an example, the method is successfully applied to a practical project to verify the feasibility of the method.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923007706,https://doi.org/10.1016/j.procs.2023.08.012,science_direct,2023
1437,Generation of Radiology Findings in Chest X-Ray by Leveraging Collaborative Knowledge,"@article{DANU20231102,
title = {Generation of Radiology Findings in Chest X-Ray by Leveraging Collaborative Knowledge},
journal = {Procedia Computer Science},
volume = {221},
pages = {1102-1109},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.094},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923008529},
author = {Manuela Daniela Danu and George Marica and Sanjeev Kumar Karn and Bogdan Georgescu and Awais Mansoor and Florin Ghesu and Lucian Mihai Itu and Constantin Suciu and Sasa Grbic and Oladimeji Farri and Dorin Comaniciu},
keywords = {abnormalities detection, Findings generation, chest X-ray, radiology report, generative large language model, collaborative knowledge},
abstract = {Among all the sub-sections in a typical radiology report, the Clinical Indications, Findings, and Impression often reflect important details about the health status of a patient. The information included in Impression is also often covered in Findings. While Findings and Impression can be deduced by inspecting the image, Clinical Indications often require additional context. The cognitive task of interpreting medical images remains the most critical and often time-consuming step in the radiology workflow. Instead of generating an end-to-end radiology report, in this paper, we focus on generating the Findings from automated interpretation of medical images, specifically chest X-rays (CXRs). Thus, this work focuses on reducing the workload of radiologists who spend most of their time either writing or narrating the Findings. Unlike past research, which addresses radiology report generation as a single-step image captioning task, we have further taken into consideration the complexity of interpreting CXR images and propose a two-step approach: (a) detecting the regions with abnormalities in the image, and (b) generating relevant text for regions with abnormalities by employing a generative large language model (LLM). This two-step approach introduces a layer of interpretability and aligns the framework with the systematic reasoning that radiologists use when reviewing a CXR.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923008529,https://doi.org/10.1016/j.procs.2023.08.094,science_direct,2023
1438,Research on the impact of trends related to ChatGPT,"@article{YAN20231284,
title = {Research on the impact of trends related to ChatGPT},
journal = {Procedia Computer Science},
volume = {221},
pages = {1284-1291},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.117},
url = {https://www.sciencedirect.com/science/article/pii/S187705092300875X},
author = {Yunxi Yan and Biao Li and Jinyuan Feng and Yang Du and Zhichen Lu and Manling Huang and Youyuan Li},
keywords = {ChatGPT, Artificial Intelligence},
abstract = {Since ChatGPT was launched, it has attracted great attention across society. Especially in non-professional fields, ChatGPT can answer follow-up questions, reject inappropriate requests, challenge erroneous assumptions, and admit mistakes from a user's experience. It has many emergent capabilities such as high-quality dialogue, complex reasoning, chains of thought (CoT), zero/low-shot learning (contextual learning), cross-task generalization, code understanding/generation, etc. The emergence of ChatGPT has brought a profound impact on the development of all aspects, and brought huge changes to the social economy and living environment.}
}
",https://www.sciencedirect.com/science/article/pii/S187705092300875X,https://doi.org/10.1016/j.procs.2023.08.117,science_direct,2023
1439,Curriculum Compositional Continual Learning for Neural Machine Translation,"@article{OWOEYE2023167,
title = {Curriculum Compositional Continual Learning for Neural Machine Translation},
journal = {Procedia Computer Science},
volume = {222},
pages = {167-176},
year = {2023},
note = {International Neural Network Society Workshop on Deep Learning Innovations and Applications (INNS DLIA 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.154},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923009195},
author = {Kehinde Owoeye},
keywords = {Continual learning, Compositionality, Curriculum learning, Neural Machine Translation},
abstract = {Current trends in language modelling leverage large language models pre-trained on a huge corpus of data to achieve state of the art results on several NLP tasks. On the other hand, humans acquire language from small amount of data using cognitive principles. Recently, a continual learning approach using compositionality to disentangle the syntax and semantics of an input sentence for downstream sequence to sequence tasks was proposed. In this work, we show how curriculum learning can be incorporated with this framework to improve performance. More specifically, first, we show that using the model of interest with reduced hidden size as the auxiliary model to generate curriculum is not necessarily optimal and second, we propose a novel variant of the one best score approach for curriculum learning where, a sequence to sequence model is used as the auxiliary model to generate the conditional probabilities of word predictions (proxy for difficulty) and consequently used this to generate a curriculum. Results on a variety of translation tasks, demonstrate the superiority of the proposed approach compared to several baselines, enabling the improvement of sentence accuracy with respect to knowledge transfer and catastrophic-forgetting both by at least a significant margin of 35% with respect to the best performing baseline on the English-French translation task.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923009195,https://doi.org/10.1016/j.procs.2023.08.154,science_direct,2023
1440,A Large and Diverse Arabic Corpus for Language Modeling,"@article{ALI202312,
title = {A Large and Diverse Arabic Corpus for Language Modeling},
journal = {Procedia Computer Science},
volume = {225},
pages = {12-21},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.09.086},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923011419},
author = {Abbas Raza Ali and Muhammad Ajmal Siddiqui and Rema Algunaibet and Hasan Raza Ali},
keywords = {Arabic Corpus, GPT-3, Language Model, Transformers, NLP},
abstract = {Large Language Models (LLMs) have ushered in a major paradigm shift in Natural Language Processing (NLP), where large pre-trained Language models (LMs) have become a fundamental component of most NLP tasks. These models are intelligent enough to find relevant and meaningful representations of a language without any supervision. They are used to fine-tune typical NLP tasks with substantially higher precision than conventional shallow learning techniques. However, training these models requires a massively large corpus that adequately represents a language. Due to the availability of enormous corpora, English LLMs typically perform better than their counterparts. This effort focuses on the design and development of a large Arabic corpus. The corpus comprises over 500 GB of Arabic cleaned text, intended to improve cross-domain knowledge and downstream generalization capability of LLMs. The corpus was employed in the training of a large Arabic LLM. In order to assess the efficacy of the LLM, a variety of typical NLP tasks were fine-tuned. The fine-tuned tasks exhibited a significant boost in accuracy ranging between 4.5 and 8.5%, when compared to those downstreamed from multi-lingual BERT (mBERT). To the best of our knowledge, this is currently the largest clean and diverse Arabic corpus ever assembled.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923011419,https://doi.org/10.1016/j.procs.2023.09.086,science_direct,2023
1441,Socratic Video Understanding on Unmanned Aerial Vehicles,"@article{DEZARZA2023144,
title = {Socratic Video Understanding on Unmanned Aerial Vehicles},
journal = {Procedia Computer Science},
volume = {225},
pages = {144-154},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.09.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923011560},
author = {I. {de Zarzà} and J. {de Curtò} and Carlos T. Calafate},
keywords = {Socratic Models, UAV, Scene Understanding, Large Language Models, BLIP-2, GPT-3},
abstract = {In this work, we propose a system for video understanding through zero-shot reading comprehension using Socratic Models. Specifically, we create a language-based world-state history of events and objects present in a scene captured by an Unmanned Aerial Vehicle (UAV). To achieve this, video footage from RYZE Tello microdrones is transmitted to a ground computer for further processing. The semantically rich information offered by Large Language Models (LLMs) enables open-ended reasoning, such as event forecasting with minimal human intervention, in a cost-effective robotic system. BLIP-2 is employed to answer a given set of instructional prompts, creating a log-state of objects, humans, and hazards that can be searched. Simultaneously, it suggests probable actions in the scene and can assist the human controller with an estimated best command. The BLIP-2 instructional prompts are then combined with OpenAI's da-vinci-003/gpt-3.5-turbo to generate comprehensive video descriptions and summarize likely actions. The LLM-enhanced generated texts achieve a GUNNING Fog median grade level in the range of 7-12.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923011560,https://doi.org/10.1016/j.procs.2023.09.101,science_direct,2023
1442,AI in HRM: case study analysis. Preliminary research,"@article{GRYNCEWICZ20232351,
title = {AI in HRM: case study analysis. Preliminary research},
journal = {Procedia Computer Science},
volume = {225},
pages = {2351-2360},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.226},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923013844},
author = {Wiesława Gryncewicz and Ryszard Zygała and Agnieszka Pilch},
keywords = {Human Resource Management, Artificial Intelligence, Alghoritms, Artificial Intelligence Applications},
abstract = {The article attempts to identify Artificial Intelligence (AI) algorithms in Human Resources Management (HRM) systems focusing particular attention on candidate selection, career building, and predicting employee attrition. The review examines case studies that demonstrate the benefits of AI in HRM, including enhancing employee engagement and satisfaction, improving recruitment processes, supporting decision-making and predicting employee retention. The research indicates that interpretable algorithms, such as decision trees, are frequently used in HRM solutions. The study emphasizes that AI should be viewed as a tool rather than a replacement for human judgment in HRM. Both the review and article highlight the growing trend of AI in HRM systems and the need for further research in this area to fully understand its impact on HRM practices and outcomes.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923013844,https://doi.org/10.1016/j.procs.2023.10.226,science_direct,2023
1443,Students' Use of the Artificial Intelligence Language Model in their Learning Process,"@article{NIEDBAL20233059,
title = {Students' Use of the Artificial Intelligence Language Model in their Learning Process},
journal = {Procedia Computer Science},
volume = {225},
pages = {3059-3066},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.299},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014576},
author = {Rafał Niedbał and Adam Sokołowski and Artur Wrzalik},
keywords = {ChatGPT, Generative Artificial Intelligence, chatbot, Large Language Models, modern IT in education, innovative education},
abstract = {Generative Artificial Intelligence (GAI), of which ChatGPT is an exemplary tool, is beginning to revolutionize the way people search for information and use the information they acquire in their personal and professional lives. ChatGPT is showing a strong track record in a variety of tasks, such as generating text, summarizing text and answering questions during a conversation. It has the potential to revolutionize a wide range of fields - including education. The purpose of this article is to evaluate the extent to which the ChatGPT language model can be applied in the learning process for two types of students: full-time and part-time. Additionally, this article assesses the level of students' familiarity with intelligent chat functionality and their ability to construct queries directed to it. The study found that the use of an advanced language model based on artificial intelligence is more beneficial for full-time students in the learning process. However, there was no statistically significant difference in the knowledge of intelligent chat functionality and the ability to construct queries directed to it between full-time and part-time students.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923014576,https://doi.org/10.1016/j.procs.2023.10.299,science_direct,2023
1444,ChatGPT as an innovative tool for increasing sales in online stores,"@article{ORZOL20233450,
title = {ChatGPT as an innovative tool for increasing sales in online stores},
journal = {Procedia Computer Science},
volume = {225},
pages = {3450-3459},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.340},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014989},
author = {Michał Orzoł and Katarzyna Szopik-Depczyńska},
keywords = {ChatGPT, electronic commerce, e-commerce, online stores},
abstract = {The development of e-commerce is determined by several factors, including digital transformation, the COVID-19 pandemic, changing consumer behavior and product innovations that appear on the market, including ChatGPT which is one of the latest innovations in the field of artificial intelligence and which offers many opportunities for the e-commerce industry. Thus, the main aim of the paper is answering to the research question how ChatGPT can help e-commerce stores improve their customer communication, increase sales conversions, customer service, and build loyalty? In the article, a simple case study of a conversation between authors and an artificial intelligence-based chatbot ChatGPT was introduced. Several questions were asked related to e-commerce sphere.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923014989,https://doi.org/10.1016/j.procs.2023.10.340,science_direct,2023
1445,ChatGPT - opportunities or threats in the educational process,"@article{UBOWSKA20234551,
title = {ChatGPT - opportunities or threats in the educational process},
journal = {Procedia Computer Science},
volume = {225},
pages = {4551-4559},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.453},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923016113},
author = {Agnieszka Ubowska and Tomasz Królikowski},
keywords = {ChatGPT, Artificial Intelligence, survey research},
abstract = {The article is based on surveys carried out among students of selected technical universities in the West Pomeranian Voivodeship (Poland). It aims to determine students' knowledge of new tools such as ChatGPT, the use of which raises a discussion among the scientific community and beyond. According to some groups it can support learning, whereas others claim that it can limit problem-solving skills and creative thinking. Three hundred students of engineering and master's studies participated in the study. The results of the conducted research show the directions of the use of ChatGPT by students and their interest in this tool.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923016113,https://doi.org/10.1016/j.procs.2023.10.453,science_direct,2023
1446,Proposals and Methods for Foreign Language Learning Using Machine Translation and Large Language Model,"@article{SUGIYAMA20234750,
title = {Proposals and Methods for Foreign Language Learning Using Machine Translation and Large Language Model},
journal = {Procedia Computer Science},
volume = {225},
pages = {4750-4757},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.474},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923016320},
author = {Kohei Sugiyama and Tsukasa Yamanaka},
keywords = {English language learning, Foreign language teaching, Machine Translation, Large language model},
abstract = {In this paper, we propose a new learning model that utilizes machine translation and large language models. While English education has traditionally been conducted through the relationship between English teachers and learners, replacing English teachers with machine translation and large language models may offer the potential to provide an equally or even more efficient and high-quality learning environment. The authors have developed a browser-based service to experience this educational environment for Japanese. To experience a new learning model that is high quality and efficient, we have implemented DeepL, a machine translation service that can translate with high accuracy, and ChatGPT, which uses a large language model that can generate natural sentences and adapt to a variety of tasks interactively. By combining these advanced services, it is now possible to provide explanations of the English translations and to evaluate the essays. This newly developed service is currently being experimentally used in English classes at a Japanese university. Interviews with users who used it revealed that they were easily exposed to English above their level. In other words, the results suggest that this proposed model can provide a better environment for English utilization than teachers. The developed service is available to anyone at the following URL. Transable: https://transable.net}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923016320,https://doi.org/10.1016/j.procs.2023.10.474,science_direct,2023
1447,How To Teach Artificial Intelligence To Manage Our Organizations?,"@article{SLIWA20234795,
title = {How To Teach Artificial Intelligence To Manage Our Organizations?},
journal = {Procedia Computer Science},
volume = {225},
pages = {4795-4804},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.479},
url = {https://www.sciencedirect.com/science/article/pii/S187705092301637X},
author = {Piotr Śliwa and Grzegorz Krzos},
keywords = {artificial intelligence, machine learning, artificial general intelligence, intelligent agents, management, organizational model, sustainability},
abstract = {Undoubtedly, Artificial Intelligence (AI) is going mainstream. More and more AI agents come into existence to augment human agents in their work by synthesizing a gigantic body of knowledge in a conversational interface (e.g., ChatGPT), generating art from a provided description (e.g., Stable Diffusion), creating software code based on a provided description (e.g., Codex), just to name a few. It becomes evident that at some point an AI agent will similarly help human managers in their daily operations, and, when it reaches the level of artificial general intelligence (AGI), unlock completely new levels of performance and sustainability. The authors used the critical review method and identified a research gap concerning the development of a generalized, numerical model of an organization and its environment that could be applied in machine learning pipelines, and effectively support managers in the key management functions.}
}
",https://www.sciencedirect.com/science/article/pii/S187705092301637X,https://doi.org/10.1016/j.procs.2023.10.479,science_direct,2023
1448,Usability Analysis of Text Generation by ChatGPT OpenAI Using System Usability Scale Method,"@article{MULIA2023381,
title = {Usability Analysis of Text Generation by ChatGPT OpenAI Using System Usability Scale Method},
journal = {Procedia Computer Science},
volume = {227},
pages = {381-388},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.537},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923017040},
author = {Angelina Patience Mulia and Pirelli Rahelya Piri and Cuk Tho},
keywords = {Text Generation, Artificial Intelligence, ChatGPT, System Usability Scale, Questionnaire, SUS, Usability Analysis, OpenAI},
abstract = {The development of artificial intelligence systems has resulted in various AI products including ChatGPT, which is a new product classified as a chatbot. This research aims to ensure that text generation systems such as ChatGPT open AI have the best level of quality and usability and are able to provide a satisfying experience for users. To measure and evaluate the effectiveness, efficiency and user satisfaction of the ChatGPT platform, researchers used the System Usability Scale (SUS) method. This data collection was carried out using an online questionnaire. After the collected data has been tested for validity and reliability, the researchers then analyzed the data results. From the results of the research conducted, the SUS value of the ChatGPT platform is 67.44. This score is included in the marginal high category of class D, with a reasonable or sufficient interpretation. With the results of the analysis per question item, it shows that users tend to agree that the system runs quite effectively, efficiently, well and is easy to understand. Although ChatGPT is able to perform tasks or commands well. However, it should be noted that not all information loaded by ChatGPT is presented in a complete, current and correct manner. This is because the information presented by ChatGPT is only limited to 2021. Because ChatGPT is a new technology and is still under development, further researchers are expected to test other features or ChatGPT to ensure the stability and reliability of the entire ChatGPT system using other research methods.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923017040,https://doi.org/10.1016/j.procs.2023.10.537,science_direct,2023
1449,Strategic Trends in Artificial Intelligence Through Impact of Computational Science: What Young Scientists Should Expect,"@article{KLIMOVA20231,
title = {Strategic Trends in Artificial Intelligence Through Impact of Computational Science: What Young Scientists Should Expect},
journal = {Procedia Computer Science},
volume = {229},
pages = {1-7},
year = {2023},
note = {12th International Young Scientists Conference in Computational Science, YSC2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923019919},
author = {Alexandra Klimova and Denis Nasonov and Alexander Hvatov and Nikolay O. Nikitin and Sergey V. Ivanov and Anna V. Kalyuzhnaya and Alexander Boukhanovsky},
keywords = {Artificial Intelligence, Computational Science, Trends, Impact, Young Scientists},
abstract = {This volume presents selected papers of the 12th Young Scientists Conference in Computational Science (YSC'2023). ITMO University annually organises the event with various academic partners to disseminate current trends in Artificial Intelligence and Computational science among young researchers. In this paper, we present our view on major trends and challenges today in front of scientific and industrial society in this promising area.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050923019919,https://doi.org/10.1016/j.procs.2023.12.001,science_direct,2023
1450,Responsible AI (RAI) in Manufacturing: A Qualitative Framework,"@article{BESINGER2024813,
title = {Responsible AI (RAI) in Manufacturing: A Qualitative Framework},
journal = {Procedia Computer Science},
volume = {232},
pages = {813-822},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.01.081},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924000814},
author = {Philipp Besinger and Daniel Vejnoska and Fazel Ansari},
keywords = {Manufacturing, Responsible Artifical Intelligence, Responsible Research and Innovation},
abstract = {Artificial Intelligence (AI) has profound economic influence in manufacturing, but its unmindful integration can also pose societal and environmental risks. This paper provides a quantified overview of manufacturing areas that are highly advanced in AI capability research, such as maintenance. Integrating Responsible AI (RAI) in further studies of those areas is essential to mitigate risks and deliver business benefits. To enable this, manufacturing specific RAI dimensions are defined to represent accountability, explainability, fairness, human-centricity, sustainability (Green AI) and privacy & security. Further, a qualitative RAI framework consisting of responsibility areas (human involvement, decision making, business focus, system design) is proposed. Practical considerations to align the framework with manufacturing requirements are made by discussing it within an AI systems lifecycle.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924000814,https://doi.org/10.1016/j.procs.2024.01.081,science_direct,2024
1451,Potentials of the Metaverse for Robotized Applications in Industry 4.0 and Industry 5.0,"@article{KAIGOM20241829,
title = {Potentials of the Metaverse for Robotized Applications in Industry 4.0 and Industry 5.0},
journal = {Procedia Computer Science},
volume = {232},
pages = {1829-1838},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924001820},
author = {Eric Guiffo Kaigom},
keywords = {Robotics, Metaverse, Digital Twin, VR/AR, AI/ML, Foundation Model},
abstract = {As a digital environment of interconnected virtual ecosystems driven by measured and synthesized data, the Metaverse has so far been mostly considered from its gaming perspective that closely aligns with online edutainment. Although it is still in its infancy and more research as well as standardization efforts remain to be done, the Metaverse could provide considerable advantages for smart robotized applications in the industry. Workflow efficiency, collective decision enrichment even for executives, as well as a natural, resilient, and sustainable robotized assistance for the workforce are potential advantages. Hence, the Metaverse could consolidate the connection between Industry 4.0 and Industry 5.0. This paper identifies and puts forward potential advantages of the Metaverse for robotized applications and highlights how these advantages support goals pursued by the Industry 4.0 and Industry 5.0 visions.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924001820,https://doi.org/10.1016/j.procs.2024.02.005,science_direct,2024
1452,"Can ChatGPT Challenge the Scientific Impact of Published Research, Particularly in the Context of Industry 4.0 and Smart Manufacturing?","@article{TERZIYAN20242540,
title = {Can ChatGPT Challenge the Scientific Impact of Published Research, Particularly in the Context of Industry 4.0 and Smart Manufacturing?},
journal = {Procedia Computer Science},
volume = {232},
pages = {2540-2550},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.02.072},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924002497},
author = {Vagan Terziyan and Olena Kaikova and Mariia Golovianko and Oleksandra Vitko},
keywords = {Artificial Intelligence, ChatGPT, Industry 4.0, Smart Manufacturing, academic impact},
abstract = {The released ChatGPT as a powerful language model is capable of assisting with a wide range of tasks, including answering questions, summarizing, paraphrasing, proofreading, classifying, and integrating texts. In this study, we tested ChatGPT capability to assist researchers in evaluating the academic articles’ contribution. We suggest a dialogue schema in which ChatGPT is asked to answer research questions from the target article and then to compare its own answers with the answers from the article. Finally, ChatGPT is asked to integrate both solutions coherently. We experimented with Proceedings of ISM-2022 Conference on Industry 4.0 and Smart Manufacturing, utilizing explicit research questions. The chat context enabled assessing studied articles’ contributions to Industry 4.0, uncovering advancements beyond the state-of-the-art. However, ChatGPT demonstrates limitations in content understanding and contribution evaluation. We conclude that while it collaborates with humans on academic tasks, human guidance remains essential, while ChatGPT's assistance efficiently complements traditional academic processes.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924002497,https://doi.org/10.1016/j.procs.2024.02.072,science_direct,2024
1453,Hybrid Approach To Unsupervised Keyphrase Extraction,"@article{SINGH20241498,
title = {Hybrid Approach To Unsupervised Keyphrase Extraction},
journal = {Procedia Computer Science},
volume = {235},
pages = {1498-1511},
year = {2024},
note = {International Conference on Machine Learning and Data Engineering (ICMLDE 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.04.141},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924008172},
author = {Vijender Singh and Bharat Kumar Bolla},
keywords = {Keyphrase Extraction, Textual Approach, Graph Based Approach, Hybrid based Approach, F1 Score, Benchmarking, RAKE, FRAKE, BERT, Information Retrieval, TFIDF, Hybrid Ranking, Perfomance Score, Exploratory Data Analysis},
abstract = {The exponential growth of textual data poses a monumental challenge for extracting meaningful knowledge. Manually identifying descriptive keywords or keyphrases for each document is infeasible given the massive daily generated text. Automatic keyphrase extraction is, therefore, essential. However, current techniques struggle with learning the most salient semantic features from lengthy documents. This hybrid keyphrase extraction framework uniquely combines the complementary strengths of graph-based and textual feature methods. Our approach demonstrates improved performance over relying solely on statistical or graphical. Graph-based systems leverage word co- occurrence networks to score importance. Textual methods extract keyphrases using linguistic properties. Together, these complementary techniques overcome the limitations of relying on any strategy. The hybrid approach is evaluated on standard SemEval 2017 Task 10 and SemEval 2010 Task 5 benchmark datasets for scientific paper keyphrase extraction. Performance is quantified using the F1 score relative to human-annotated ground truth keyphrase. Results will quantify effectiveness on long documents with thousands of terms where only a few keywords represent salient concepts. Results show our technique effectively identifies the most salient semantic keywords, overcoming limitations of current techniques that struggle to mix features of graphical or statistical methods. Our experiments demonstrate that the proposed hybrid approach achieves superior F1 scores compared to current state-of-the-art methods on benchmark datasets. These results validate that synergistically combining graph and textual features enables more accurate keyphrase extraction, especially for long documents laden with extraneous terms.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924008172,https://doi.org/10.1016/j.procs.2024.04.141,science_direct,2024
1454,Modeling Speech Emotion Recognition via ImageBind representations,"@article{CHAKHTOUNA2024428,
title = {Modeling Speech Emotion Recognition via ImageBind representations},
journal = {Procedia Computer Science},
volume = {236},
pages = {428-435},
year = {2024},
note = {International Symposium on Green Technologies and Applications (ISGTA’2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924010664},
author = {Adil CHAKHTOUNA and Sara SEKKATE and Abdellah ADIB},
keywords = {ImageBind, Speech Emotion Recognition, Embedding representations, IEMOCAP, Nu-SVM},
abstract = {Speech Emotion Recognition (SER) refers to the ability of Machine Learning (ML) and Deep Learning (DL) techniques to accurately predict people's emotional states from speech signals. significant progress has been achieved in the SER domain involving the incorporation of DL models to introduce novel features extraction processes. This paper introduces the use of deep representations learned from the multi-modal Large Language Model (LLM) called ImageBind. These representations were subsequently provided as input to the Nu-Support Vector Machine (Nu-SVM) with RBF kernel for the classification task. The experiments were executed using the IEMOCAP database within the context of a Speaker-Dependent (SD) scenario. The method achieved a noteworthy overall accuracy rate of 80.58% for the four emotions of IEMOCAP, representing a substantial improvement over well-established methods in the existing body of literature. Thus, affirming that the proposed methodology, founded upon ImageBind representations, introduces a novel perspective to the field of SER.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924010664,https://doi.org/10.1016/j.procs.2024.05.050,science_direct,2024
1455,Artificial Intelligence as an Innovative Element of Support in Policing,"@article{DUBRAVOVA2024237,
title = {Artificial Intelligence as an Innovative Element of Support in Policing},
journal = {Procedia Computer Science},
volume = {237},
pages = {237-244},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011177},
author = {Hana Dubravova and Jan Cap and Kristyna Holubova and Lukas Hribnak},
keywords = {artificial intelligence, police, GPT, large language model, administrative burden, chat},
abstract = {Currently, the public security sector is faced with an increasing administrative burden that limits the ability of police officers to focus on core security tasks. This paper focuses on the possibility of using large-scale language models (LSMs) as an innovative tool to address this challenge. Based on a careful literature review and analysis of current trends in artificial intelligence, the author team develops a concept for integrating GPTs into police practice, with an emphasis on the potential for reducing administrative burden and supporting efficient processing of relevant information. As part of this research, we have identified key areas of policing where AI could bring significant value, including data analysis and document production assistance. However, it should be emphasized that this technology is still in its early stages of development and its implementation would require a carefully considered approach involving interdisciplinary collaboration and further research to test the theoretical assumptions presented in this study. Thus, this paper contributes to a deeper understanding of the potential benefits and challenges of integrating GPT into policing practice and outlines a path towards future innovative solutions in the field of public safety.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924011177,https://doi.org/10.1016/j.procs.2024.05.101,science_direct,2024
1456,Exploratory prompting of large language models to act as co-pilots for augmenting business process work in document classification,"@article{ILAGAN2024420,
title = {Exploratory prompting of large language models to act as co-pilots for augmenting business process work in document classification},
journal = {Procedia Computer Science},
volume = {237},
pages = {420-425},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.123},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011396},
author = {Jose Ramon Ilagan and Joseph Benjamin Ilagan and Claire Louisse Basallo and Zachary Matthew Alabastro},
keywords = {LLM, Document classification, GPT, RPA, Generative AI, AI, Natural language processing, NLP},
abstract = {Businesses deal with different types of documents containing unstructured documents. The data in these documents must be converted into digital forms other automated systems could only process. One generic use case is document classification, which usually involves manual transformation due to human understanding needed in the process. These documents go beyond those generated through regular business transactions and operations and also include web-based content such as online news, blogs, e-mails, and various digital libraries. Recent developments in robotic process automation (RPA) and artificial intelligence (AI) aim to automate the otherwise expensive, time-consuming, and repetitive manual steps. Through more powerful natural language processing (NLP) and natural language understanding (NLU) capabilities, large language models (LLMs) may come as a big boost in applying AI to RPA initiatives. This study proposes a general approach to using LLMs as document classifier co-pilots for knowledge workers in charge of classifying documents to be useful. The manner of prompt engineering and refinement involving labeled health insurance documents to achieve better results is discussed and evaluated through early, iterative classification attempts. However, early tests with a complex sample use case show unsatisfactory results. The study ends with recommendations for future work to improve precision and recall performance.}
}
",https://www.sciencedirect.com/science/article/pii/S1877050924011396,https://doi.org/10.1016/j.procs.2024.05.123,science_direct,2024
1457,A survey of Semantic Reasoning frameworks for robotic systems,"@article{LIU2023104294,
title = {A survey of Semantic Reasoning frameworks for robotic systems},
journal = {Robotics and Autonomous Systems},
volume = {159},
pages = {104294},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104294},
url = {https://www.sciencedirect.com/science/article/pii/S092188902200183X},
author = {Weiyu Liu and Angel Daruna and Maithili Patel and Kartik Ramachandruni and Sonia Chernova},
keywords = {Semantic reasoning, Robotics, Knowledge bases},
abstract = {Robots are increasingly transitioning from specialized, single-task machines to general-purpose systems that operate in diverse and dynamic environments. To address the challenges associated with operation in real-world domains, robots must effectively generalize knowledge, learn, and be transparent in their decision making. This survey examines Semantic Reasoning techniques for robotic systems, which enable robots to encode and use semantic knowledge, including concepts, facts, ideas, and beliefs about the world. Continually perceiving, understanding, and generalizing semantic knowledge allows a robot to identify the meaningful patterns shared between problems and environments, and therefore more effectively perform a wide range of real-world tasks. We identify the three common components that make up a computational Semantic Reasoning Framework: knowledge sources, computational frameworks, and world representations. We analyze the existing implementations and the key characteristics of these components, highlight the many interactions that occur between them, and examine their integration for solving robotic tasks related to five aspects of the world, including objects, spaces, agents, tasks, and actions. By analyzing the computational formulation and underlying mechanisms of existing methods, we provide a unified view of the wide range of semantic reasoning techniques and identify open areas for future research.}
}
",https://www.sciencedirect.com/science/article/pii/S092188902200183X,https://doi.org/10.1016/j.robot.2022.104294,science_direct,2023
1458,iCORPP: Interleaved commonsense reasoning and probabilistic planning on robots,"@article{ZHANG2024104613,
title = {iCORPP: Interleaved commonsense reasoning and probabilistic planning on robots},
journal = {Robotics and Autonomous Systems},
volume = {174},
pages = {104613},
year = {2024},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104613},
url = {https://www.sciencedirect.com/science/article/pii/S092188902300252X},
author = {Shiqi Zhang and Piyush Khandelwal and Peter Stone},
keywords = {Integrated Reasoning and Planning, Commonsense reasoning, Planning under uncertainty, Autonomous Robots, Markov Decision Processes, POMDPs},
abstract = {Robot sequential decision-making in the real world is a challenge because it requires the robots to simultaneously reason about the current world state and dynamics, while planning actions to accomplish complex tasks. On the one hand, declarative languages and reasoning algorithms support representing and reasoning with commonsense knowledge. But these algorithms are not good at planning actions toward maximizing cumulative reward over a long, unspecified horizon. On the other hand, probabilistic planning frameworks, such as Markov decision processes (MDPs) and partially observable MDPs (POMDPs), support planning to achieve long-term goals under uncertainty. But they are ill-equipped to represent or reason about knowledge that is not directly related to actions. In this article, we present an algorithm, called iCORPP, to simultaneously estimate the current world state, reason about world dynamics, and construct task-oriented controllers. In this process, robot decision-making problems are decomposed into two interdependent (smaller) subproblems that focus on reasoning to “understand the world” and planning to “achieve the goal” respectively. The developed algorithm has been implemented and evaluated both in simulation and on real robots using everyday service tasks, such as indoor navigation, and dialog management. Results show significant improvements in scalability, efficiency, and adaptiveness, compared to competitive baselines including handcrafted action policies.}
}
",https://www.sciencedirect.com/science/article/pii/S092188902300252X,https://doi.org/10.1016/j.robot.2023.104613,science_direct,2024
1459,Applying model-driven engineering to the domain of chatbots: The Xatkit experience,"@article{DANIEL2024103032,
title = {Applying model-driven engineering to the domain of chatbots: The Xatkit experience},
journal = {Science of Computer Programming},
volume = {232},
pages = {103032},
year = {2024},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2023.103032},
url = {https://www.sciencedirect.com/science/article/pii/S0167642323001144},
author = {Gwendal Daniel and Jordi Cabot},
keywords = {Chatbots, Commercial, Lessons learned, DSL},
abstract = {Chatbots are becoming a common component of many types of software systems. But they are typically developed as a side feature using ad-hoc tools and custom integrations. Moreover, current frameworks are efficient only when designing simple chatbot applications while they still require advanced technical knowledge to define complex interactions and are difficult to evolve along with the company needs. In addition, the deployment of a chatbot application usually requires a deep understanding of the targeted platforms, especially back-end connections, increasing the development and maintenance costs. In this paper, we discuss our experiences building, evolving and distributing the Xatkit framework. Xatkit is a model-based framework built around a Domain-Specific Language to define chatbots (and voicebots and bots in general) in a platform-independent way. Xatkit also comes with a runtime engine that automatically deploys the chatbot application and manages the defined conversation logic over the platforms of choice. Xatkit has significantly evolved since its initial release. This paper focuses on describing the evolution and the reasons (technical and non-technical) that triggered them. We believe our lessons learned can be useful to any other initiative trying to build a successful industrial-level chatbot platform, and in general, any type of model-based solution.}
}
",https://www.sciencedirect.com/science/article/pii/S0167642323001144,https://doi.org/10.1016/j.scico.2023.103032,science_direct,2024
1460,Lessons learned from applying model-driven engineering in 5 domains: The success story of the MontiGem generator framework,"@article{BUSCHHAUS2024103033,
title = {Lessons learned from applying model-driven engineering in 5 domains: The success story of the MontiGem generator framework},
journal = {Science of Computer Programming},
volume = {232},
pages = {103033},
year = {2024},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2023.103033},
url = {https://www.sciencedirect.com/science/article/pii/S0167642323001156},
author = {Constantin Buschhaus and Arkadii Gerasimov and Jörg Christian Kirchhof and Judith Michael and Lukas Netz and Bernhard Rumpe and Sebastian Stüber},
keywords = {Model-driven software engineering, Code synthesis, Domain-specific languages, Data management, Web applications},
abstract = {We report on our success stories in developing and using Model-Driven Engineering (MDE) tools for information systems on real-world projects within different application domains. It is necessary that we ensure the extensibility and adaptability of code generators if we want to reuse them for different domains. Up to now, research on reusing software has been mainly conducted in the software product line community but rarely discussed in the context of code generators. This paper introduces the generation framework MontiGem and shows how it has been used and evolved within five different research and industry projects in the domains of financial management, IoT, energy management, privacy policy, and wind turbine engineering. We have developed the code generator within the first project and further refined it with each of the following projects. This paper describes the projects, shows how MDE helped us in the software engineering process, and discusses the lessons we learned. These examples show how MDE techniques can be successfully applied to the development of information systems in practice, although further requirements have been met over time.}
}
",https://www.sciencedirect.com/science/article/pii/S0167642323001156,https://doi.org/10.1016/j.scico.2023.103033,science_direct,2024
1461,“Will I be replaced?” Assessing ChatGPT's effect on software development and programmer perceptions of AI tools,"@article{KUHAIL2024103111,
title = {“Will I be replaced?” Assessing ChatGPT's effect on software development and programmer perceptions of AI tools},
journal = {Science of Computer Programming},
volume = {235},
pages = {103111},
year = {2024},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2024.103111},
url = {https://www.sciencedirect.com/science/article/pii/S0167642324000340},
author = {Mohammad Amin Kuhail and Sujith Samuel Mathew and Ashraf Khalil and Jose Berengueres and Syed Jawad Hussain Shah},
keywords = {ChatGPT, Programmer assistant tools, AI tools, Chatbot},
abstract = {ChatGPT is a language model with artificial intelligence (AI) capabilities that has found utility across various sectors. Given its impact, we conducted two empirical studies to assess the potential and limitations of ChatGPT and other AI tools in software development. In the first study, we evaluated ChatGPT 3.5′s effectiveness in generating code for 180 coding problems from LeetCode, an online coding interview preparation platform. Our findings suggest that ChatGPT 3.5 is more effective in solving easy and medium coding problems but less reliable for harder problems. Further, ChatGPT 3.5 is somewhat more effective at coding problems with higher popularity scores. In the second study, we administered a questionnaire (N = 99) to programmers to gain insights into their views on ChatGPT and other AI tools. Our findings indicate that programmers use AI tools for various tasks, such as generating boilerplate code, explaining complex code, and conducting research. AI tools also help programmers to become more productive by creating better-performing, shorter, and more readable code, among other benefits. However, AI tools can sometimes misunderstand requirements and generate erroneous code. While most programmers are not currently concerned about AI tools replacing them, they are apprehensive about what the future may hold. Our research has also revealed associations between AI tool usage, trust, perceived productivity, and job security threats caused by the tools.}
}
",https://www.sciencedirect.com/science/article/pii/S0167642324000340,https://doi.org/10.1016/j.scico.2024.103111,science_direct,2024
1462,A comparative review on multi-modal sensors fusion based on deep learning,"@article{TANG2023109165,
title = {A comparative review on multi-modal sensors fusion based on deep learning},
journal = {Signal Processing},
volume = {213},
pages = {109165},
year = {2023},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2023.109165},
url = {https://www.sciencedirect.com/science/article/pii/S0165168423002396},
author = {Qin Tang and Jing Liang and Fangqi Zhu},
keywords = {Multi-model data fusion, Deep learning, Inference mechanisms},
abstract = {The wide deployment of multi-modal sensors in various areas generates vast amounts of data with characteristics of high volume, wide variety, and high integrity. However, traditional data fusion methods face immense challenges when dealing with multi-modal data containing abundant intermodality and cross-modality information. Deep learning has the ability to automatically extract and understand the potential association of multi-modal information. Despite this, there is a lack of a comprehensive review of the inherent inference mechanisms of deep learning for multi-modal sensor fusion. This work investigates up-to-date developments in multi-modal sensor fusion via deep learning to provide a broad picture of data fusion needs and technologies. It compares the characteristics of multi-modal data for various sensors, summarizes background concepts about data fusion and deep learning, and carefully reviews a large number of investigations in four inference mechanisms: adaptive learning, deep generative, deep discriminative, and algorithms unrolling. The pros and cons of the above methodologies are presented, and several popular application domains are discussed, including medical imaging, autonomous driving, remote sensing, and robotics. A large collection of multi-modal datasets published in recent years is presented, and several tables that quantitatively compare and summarize the performance of fusion algorithms are provided. Finally, by acknowledging the limitations of current research, we establish potential open challenges and future directions as guidance for deep learning-based multi-sensor fusion.}
}
",https://www.sciencedirect.com/science/article/pii/S0165168423002396,https://doi.org/10.1016/j.sigpro.2023.109165,science_direct,2023
1463,BeeFlow: Behavior tree-based Serverless workflow modeling and scheduling for resource-constrained edge clusters,"@article{LUO2023102968,
title = {BeeFlow: Behavior tree-based Serverless workflow modeling and scheduling for resource-constrained edge clusters},
journal = {Journal of Systems Architecture},
volume = {143},
pages = {102968},
year = {2023},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2023.102968},
url = {https://www.sciencedirect.com/science/article/pii/S1383762123001479},
author = {Ke Luo and Tao Ouyang and Zhi Zhou and Xu Chen},
keywords = {Edge computing, Serverless computing, Serverless workflow, Behavior tree, Workflow modeling, Workflow scheduling},
abstract = {Serverless computing has gained popularity in edge computing due to its flexible features, including the pay-per-use pricing model, auto-scaling capabilities, and multi-tenancy support. Complex Serverless-based applications typically rely on Serverless workflows (also known as Serverless function orchestration) to express task execution logic, and numerous application- and system-level optimization techniques have been developed for Serverless workflow scheduling. However, there has been limited exploration of optimizing Serverless workflow scheduling in edge computing systems, particularly in high-density, resource-constrained environments such as system-on-chip clusters and single-board-computer clusters. In this work, we discover that existing Serverless workflow scheduling techniques typically assume models with limited expressiveness and cause significant resource contention. To address these issues, we propose modeling Serverless workflows using behavior trees, a novel and fundamentally different approach from existing directed-acyclic-graph- and state machine-based models. Behavior tree-based modeling allows for easy analysis without compromising workflow expressiveness. We further present observations derived from the inherent tree structure of behavior trees for contention-free function collections and awareness of exact and empirical concurrent function invocations. Based on these observations, we introduce BeeFlow, a behavior tree-based Serverless workflow system tailored for resource-constrained edge clusters. Experimental results demonstrate that BeeFlow achieves up to 3.2× speedup in a high-density, resource-constrained edge testbed and 2.5× speedup in a high-profile cloud testbed, compared with the state-of-the-art. BeeFlow also demonstrates superior robustness in scenarios with heavy system workloads.}
}
",https://www.sciencedirect.com/science/article/pii/S1383762123001479,https://doi.org/10.1016/j.sysarc.2023.102968,science_direct,2023
1464,"An era of ChatGPT as a significant futuristic support tool: A study on features, abilities, and challenges","@article{HALEEM2022100089,
title = {An era of ChatGPT as a significant futuristic support tool: A study on features, abilities, and challenges},
journal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
volume = {2},
number = {4},
pages = {100089},
year = {2022},
issn = {2772-4859},
doi = {https://doi.org/10.1016/j.tbench.2023.100089},
url = {https://www.sciencedirect.com/science/article/pii/S2772485923000066},
author = {Abid Haleem and Mohd Javaid and Ravi Pratap Singh},
keywords = {Artificial Intelligence (AI), ChatGPT, Role, Features, Capabilities, Challenges},
abstract = {Open Artificial Intelligence (AI) published an AI chatbot tool called ChatGPT at the end of November 2022. Generative Pre-trained Transformer (GPT) architecture is the foundation of ChatGPT. On the internet, ChatGPT has been rapidly growing. This chatbot enables users to discuss with the AI by inputting prompts, and it is based on OpenAI’s language model. Although ChatGPT is fantastic and produces exciting results for writing tales, poetry, songs, essays, and other things, it has certain restrictions. Users may ask the bot questions, and it will reply with pertinent, convincing subjects and replies. ChatGPT has now risen to the top of several academic agendas. Administrators create task teams and hold institution-wide meetings to react to the tools, with most of the advice being to adopt this technology. This paper briefs about the ChatGPT and its need. Further, various Progressive Work Flow Processes of the ChatGPT Tool are stated diagrammatically. Specific features and capabilities of the ChatGPT Support System are studied in this paper. Finally, we identified and discussed the significant roles of ChatGPT in the current scenario. The neural language models that form the foundation of character AI have been developed from the bottom up with talks in mind. This technology implies that the programme uses deep learning methods to analyse and produce text. The model “understands” the subtleties of human-produced natural language using vast amounts of data from the internet.}
}
",https://www.sciencedirect.com/science/article/pii/S2772485923000066,https://doi.org/10.1016/j.tbench.2023.100089,science_direct,2022
1465,Unlocking the opportunities through ChatGPT Tool towards ameliorating the education system,"@article{JAVAID2023100115,
title = {Unlocking the opportunities through ChatGPT Tool towards ameliorating the education system},
journal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
volume = {3},
number = {2},
pages = {100115},
year = {2023},
issn = {2772-4859},
doi = {https://doi.org/10.1016/j.tbench.2023.100115},
url = {https://www.sciencedirect.com/science/article/pii/S2772485923000327},
author = {Mohd Javaid and Abid Haleem and Ravi Pratap Singh and Shahbaz Khan and Ibrahim Haleem Khan},
keywords = {Artificial Intelligence, ChatGPT, Education, Students, Teaching, Learning},
abstract = {Artificial Intelligence (AI)-based ChatGPT developed by OpenAI is now widely accepted in several fields, including education. Students can learn about ideas and theories by using this technology while generating content with it. ChatGPT is built on State of the Art (SOA), like Deep Learning (DL), Natural Language Processing (NLP), and Machine Learning (ML), an extrapolation of a class of ML-NLP models known as Large Language Model (LLMs). It may be used to automate test and assignment grading, giving instructors more time to concentrate on instruction. This technology can be utilised to customise learning for kids, enabling them to focus more intently on the subject matter and critical thinking ChatGPT is an excellent tool for language lessons since it can translate text from one language to another. It may provide lists of vocabulary terms and meanings, assisting students in developing their language proficiency with resources. Personalised learning opportunities are one of ChatGPT’s significant applications in the classroom. This might include creating educational resources and content tailored to a student’s unique interests, skills, and learning goals. This paper discusses the need for ChatGPT and the significant features of ChatGPT in the education system. Further, it identifies and discusses the significant applications of ChatGPT in education. Using ChatGPT, educators may design lessons and instructional materials specific to each student’s requirements and skills based on current trends. Students may work at their speed and concentrate on the areas where they need the most support, resulting in a more effective and efficient learning environment. Both instructors and students may profit significantly from using ChatGPT in the classroom. Instructors may save time on numerous duties by using this technology. In future, ChatGPT will become a powerful tool for enhancing students’ and teachers’ experience.}
}
",https://www.sciencedirect.com/science/article/pii/S2772485923000327,https://doi.org/10.1016/j.tbench.2023.100115,science_direct,2023
1466,"The Third BenchCouncil International Symposium on Intelligent Computers, Algorithms, and Applications (IC 2023) Call for Papers","@article{2023100123,
title = {The Third BenchCouncil International Symposium on Intelligent Computers, Algorithms, and Applications (IC 2023) Call for Papers},
journal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
volume = {3},
number = {2},
pages = {100123},
year = {2023},
issn = {2772-4859},
doi = {https://doi.org/10.1016/j.tbench.2023.100123},
url = {https://www.sciencedirect.com/science/article/pii/S2772485923000406},
keywords = {IC 2023, IC23, Call for papers},
abstract = {Sponsored and organized by the International Open Benchmark Council (BenchCouncil), the IC conference is to provide a pioneering technology map through searching and advancing state-of-the-art and state-of-the-practice in processors, systems, algorithms, and applications for machine learning, deep learning, spiking neural network and other AI techniques across multidisciplinary and interdisciplinary areas. IC 2023 invites manuscripts describing original work in the above areas and topics. All accepted papers will be presented at the IC 2023 conference and published by Springer CCIS (Indexed by EI). The IC conferences have been successfully held for two series from 2019 to 2022 and attracted plenty of paper submissions and participants. IC 2023 will be held on December 4-6, 2023 in Sanya and invites manuscripts describing original work in processors, systems, algorithms, and applications for AI techniques across multidisciplinary and interdisciplinary areas. The conference website is https://www.benchcouncil.org/ic2023/. Important Dates: Paper Submission: July 31, 2023, at 11:59 PM AoE Notification: September 30, 2023, at 11:59 PM AoE Final Papers Due: October 31, 2023, at 11:59 PM AoE Conference Date: December 4-6, 2023 Submission Site: https://ic2023.hotcrp.com/}
}
",https://www.sciencedirect.com/science/article/pii/S2772485923000406,https://doi.org/10.1016/j.tbench.2023.100123,science_direct,2023
1467,Analyzing the potential benefits and use cases of ChatGPT as a tool for improving the efficiency and effectiveness of business operations,"@article{RAJ2023100140,
title = {Analyzing the potential benefits and use cases of ChatGPT as a tool for improving the efficiency and effectiveness of business operations},
journal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
volume = {3},
number = {3},
pages = {100140},
year = {2023},
issn = {2772-4859},
doi = {https://doi.org/10.1016/j.tbench.2023.100140},
url = {https://www.sciencedirect.com/science/article/pii/S2772485923000571},
author = {Rohit Raj and Arpit Singh and Vimal Kumar and Pratima Verma},
keywords = {ChatGPT, benefits, business, efficiency, automation},
abstract = {The study addresses the potential benefits for companies of adopting ChatGPT, a popular chatbot built on a large-scale transformer-based language model known as a generative pre-trained transformer (GPT). Chatbots like ChatGPT may improve customer service, handle several client inquiries at once, and save operational costs. Moreover, ChatGPT may automate regular processes like order tracking and billing, allowing human employees to focus on more complex and strategic responsibilities. Nevertheless, before deploying ChatGPT, enterprises must carefully analyze its use cases and restrictions, as well as its strengths and disadvantages. ChatGPT, for example, requires training data that is particular to the business domain and might produce erroneous and ambiguous findings. The study identifies areas of deployment of ChatGPT's possible benefits in enterprises by drawing on the literature that is currently accessible on ChatGPT, massive language models, and artificial intelligence. Then, using the PSI (Preference Selection Index) and COPRAS (Complex Proportional Assessment) approaches, potential advantages are taken into account and prioritized. By highlighting current trends and possible advantages in the industry, this editorial seeks to provide insight into the present state of employing ChatGPT in enterprises and research. ChatGPT may also learn biases from training data and create replies that reinforce those biases. As a result, enterprises must train and fine-tune ChatGPT to specific operations, set explicit boundaries and limitations for its use, and implement appropriate security measures to avoid malicious input. The study highlights the research gap in the dearth of literature by outlining ChatGPT's potential benefits for businesses, analyzing its strengths and limits, and offering insights into how organizations might use ChatGPT's capabilities to enhance their operations.}
}
",https://www.sciencedirect.com/science/article/pii/S2772485923000571,https://doi.org/10.1016/j.tbench.2023.100140,science_direct,2023
1468,Benchmarking ChatGPT for prototyping theories: Experimental studies using the technology acceptance model,"@article{GOH2023100153,
title = {Benchmarking ChatGPT for prototyping theories: Experimental studies using the technology acceptance model},
journal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
volume = {3},
number = {4},
pages = {100153},
year = {2023},
issn = {2772-4859},
doi = {https://doi.org/10.1016/j.tbench.2024.100153},
url = {https://www.sciencedirect.com/science/article/pii/S277248592400005X},
author = {Tiong-Thye Goh and Xin Dai and Yanwu Yang},
keywords = {ChatGPT, Large language model, Technology acceptance model, Prototyping Theory},
abstract = {This paper explores the paradigm of leveraging ChatGPT as a benchmark tool for theory prototyping in conceptual research. Specifically, we conducted two experimental studies using the classical technology acceptance model (TAM) to demonstrate and evaluate ChatGPT's capability of comprehending theoretical concepts, discriminating between constructs, and generating meaningful responses. Results of the two studies indicate that ChatGPT can generate responses aligned with the TAM theory and constructs. Key metrics including the factors loading, internal consistency reliability, and convergence reliability of the measurement model surpass the minimum threshold, thus confirming the validity of TAM constructs. Moreover, supported hypotheses provide an evidence for the nomological validity of TAM constructs. However, both of the two studies show a high Heterotrait–Monotrait ratio of correlations (HTMT) among TAM constructs, suggesting a concern about discriminant validity. Furthermore, high duplicated response rates were identified and potential biases regarding gender, usage experiences, perceived usefulness, and behavioural intention were revealed in ChatGPT-generated samples. Therefore, it calls for additional efforts in LLM to address performance metrics related to duplicated responses, the strength of discriminant validity, the impact of prompt design, and the generalizability of findings across contexts.}
}
",https://www.sciencedirect.com/science/article/pii/S277248592400005X,https://doi.org/10.1016/j.tbench.2024.100153,science_direct,2023
1469,D-HRSP: Dataset of helpful reviews for service providers,"@article{LEE2023102001,
title = {D-HRSP: Dataset of helpful reviews for service providers},
journal = {Telematics and Informatics},
volume = {82},
pages = {102001},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102001},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323000655},
author = {Jinmo Lee and Eunil Park},
keywords = {Mobile application review, Service quality, Service provider, Review helpfulness},
abstract = {Most common services are now provided through mobile applications; thus, the importance of mobile application reviews has increased. Service providers and developers seek helpful reviews to find useful information to improve their services. However, with currently existing indicators, e.g., star rating systems, it is difficult to identify reviews that are directly related to the quality of the service. Thus, in this study, we defined helpful mobile application reviews for service providers and developers based on the components of an existing service quality evaluation model. We also provide the D-HRSP (dataset of helpful reviews for service providers), which is a labeled dataset that can be used to examine helpful reviews. We also report the experimental results obtained with simple natural language processing techniques and machine learning and deep learning classification models. The experimental results demonstrate that the proposed definition can help address real-life problems and create opportunities for additional research into the identification of helpful mobile application reviews.}
}
",https://www.sciencedirect.com/science/article/pii/S0736585323000655,https://doi.org/10.1016/j.tele.2023.102001,science_direct,2023
1470,"Exploring the Determinants of Artificial Intelligence (AI) Literacy: Digital Divide, Computational Thinking, Cognitive Absorption","@article{CELIK2023102026,
title = {Exploring the Determinants of Artificial Intelligence (AI) Literacy: Digital Divide, Computational Thinking, Cognitive Absorption},
journal = {Telematics and Informatics},
volume = {83},
pages = {102026},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102026},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323000904},
author = {Ismail Celik},
keywords = {AI Literacy, Digital Divide, Computational Thinking, Cognitive Absorption, ChatGPT},
abstract = {To effectively utilize artificial intelligence (AI)-based technologies such as ChatGPT and realize their novel ethical issues, individuals must have a variety of knowledge and skills about AI. Such knowledge and skills have led to the emergence of AI literacy. Despite the importance of AI literacy in everyday life, little is known about its determinants. To better understand the determinants of AI literacy, we attempted to build a research model relying on previous research and different theoretical frameworks. The model incorporated digital divide, cognitive absorption, and computational thinking. As a major finding from the current study, computational thinking was found to be a significant determinant of AI literacy, which facilitate using, recognizing, and evaluating AI-based technologies. Moreover, we found out that individuals with physical access to information and communication technologies (ICTs) are more expected to use and recognize AI. Also, motivation and skills in using ICTs enable individuals to better evaluate the outcomes of AI-based technologies. The findings also showed that convenient access to ICTs contributes to a deep involvement with AI-based technologies in the use. Further, individuals with higher motivation and skills to use AI technologies are likely to have a pleasant experience after using these technologies.}
}
",https://www.sciencedirect.com/science/article/pii/S0736585323000904,https://doi.org/10.1016/j.tele.2023.102026,science_direct,2023
1471,"Exploring the limitations in how ChatGPT introduces environmental justice issues in the United States: A case study of 3,108 counties","@article{KIM2024102085,
title = {Exploring the limitations in how ChatGPT introduces environmental justice issues in the United States: A case study of 3,108 counties},
journal = {Telematics and Informatics},
volume = {86},
pages = {102085},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102085},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323001491},
author = {Junghwan Kim and Jinhyung Lee and Kee Moon Jang and Ismini Lourentzou},
keywords = {ChatGPT, Disparities, Environmental justice, Generative AI, Geographic bias},
abstract = {The potential of Generative AI, such as ChatGPT, has sparked discussions among researchers and the public. This study empirically explores the capabilities and limitations of ChatGPT, specifically its portrayal of environmental justice issues. Using OpenAI’s ChatGPT API, we asked ChatGPT (GPT-4) to answer questions about environmental justice issues in 3,108 counties in the contiguous United States. Our findings suggest that ChatGPT provides a general overview of environmental justice issues. Consistent with research, ChatGPT appears to acknowledge the disproportionate distribution of environmental pollutants and toxic materials in low-income communities and those inhabited by people of color. However, our results also highlighted ChatGPT’s shortcomings in detailing specific local environmental justice issues, particularly in disadvantaged (e.g., rural and low-income) counties. For instance, ChatGPT could not provide information on local-specific environmental justice issues for 2,593 of 3,108 counties (83%). The results of the binary logistic regression model revealed that counties with lower population densities, higher percentages of white population, and lower incomes are less likely to receive local-specific responses from the ChatGPT. This could indicate a potential regional disparity in the volume and quality of training data, hinting at geographical biases. Our findings offer insights and implications for educators, researchers, and AI developers.}
}
",https://www.sciencedirect.com/science/article/pii/S0736585323001491,https://doi.org/10.1016/j.tele.2023.102085,science_direct,2024
1472,Excitements and concerns in the post-ChatGPT era: Deciphering public perception of AI through social media analysis,"@article{QI2024102158,
title = {Excitements and concerns in the post-ChatGPT era: Deciphering public perception of AI through social media analysis},
journal = {Telematics and Informatics},
volume = {92},
pages = {102158},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102158},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000625},
author = {Weihong Qi and Jinsheng Pan and Hanjia Lyu and Jiebo Luo},
keywords = {Generative AI, Public opinion, Social media},
abstract = {As AI systems become increasingly prevalent in various aspects of daily life, gaining a comprehensive understanding of public perception towards these AI systems has become increasingly essential for several reasons such as ethical considerations, user experience, fear, disinformation, regulation, collaboration, and co-creation. In this study, we investigate how mass social media users perceive the recent rise of AI frameworks such as ChatGPT. We collect a total of 33,912 comments in 388 unique subreddits spanning from November 30, 2022 to June 8, 2023 using a list of AI-related keywords. We employ a combination of thematic and sentiment analysis, using advanced natural language processing techniques. Specifically, we use BERTopic to uncover the major themes regarding AI on Reddit. Our findings indicate that technology-focused subreddits primarily discuss the technical dimensions of AI, while non-technical subreddits more often address societal impacts, such as job displacement concerns. The disparity in focus between subreddits suggests a gap in the public understanding of AI. We leverage GPT-3.5 with zero-shot prompting and LIWC to analyze the sentiment and perception of AI among individual users. Through a comprehensive sentiment and emotion analysis, we discover that tech-centric communities exhibit greater polarization compared to non-tech communities when discussing AI topics. This suggests that individuals with a deeper understanding or familiarity with AI technologies might have more divided opinions, possibly reflecting a mix of optimism about technological advancements and skepticism about potential impacts. This research contributes to our broader understanding of public opinion surrounding artificial intelligence.}
}
",https://www.sciencedirect.com/science/article/pii/S0736585324000625,https://doi.org/10.1016/j.tele.2024.102158,science_direct,2024
1473,Informatics on a social view and need of ethical interventions for wellbeing via interference of artificial intelligence,"@article{DAS2023100065,
title = {Informatics on a social view and need of ethical interventions for wellbeing via interference of artificial intelligence},
journal = {Telematics and Informatics Reports},
volume = {11},
pages = {100065},
year = {2023},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2023.100065},
url = {https://www.sciencedirect.com/science/article/pii/S2772503023000257},
author = {Kabita Das and Manaswini Pattanaik and Smitimayee Basantia and Radhashyam Mishra and Debashreemayee Das and Kanhucharan Sahoo and Biswaranjan Paital},
keywords = {Artificial intelligence, Ethical enquiry, Ethics in technology, Human conduct, Moral value, Social cognition, Human intelligence},
abstract = {The main focus of this paper was to discuss and appraise the attribution of intelligence and value judgement on Artificial Intelligence (AI) and its regulated use in society. Humans are tool-making creatures and AI is used for civilization via tools. During the time of pre-civilization, tools were simple in the form of crude construction, using hand skills but at present, the achievements are the substitution of machinery to relieve/replace human intellect. AI is the scientific technique of bringing learning, adaptation, and self-organization of machines. It encompasses various concepts and methods, deployed by researchers in many diverse fields of computation and cognition. This is the computational mode of a brain, based on artificial neural networks. The usefulness of AI ethically, initiates a big question i.e. if the human mind is not self-sufficient for any work without harming the moral sentiment of others then, how can people believe in a computational model of the mind, is a machine, morally responsible for any good or bad action. We highlight issues on the use of AI in the replacement of the human mind asking what is the value of humans in this age of AI? Can AI reciprocate and respect human values better than human beings? Can AI replace human intelligence? In the case of ethical enquiry, it is rather a herculean task to consider a machine's action to be moral or immoral, after all, it is just a machinery action devoid of any moral quality.}
}
",https://www.sciencedirect.com/science/article/pii/S2772503023000257,https://doi.org/10.1016/j.teler.2023.100065,science_direct,2023
1474,"Artificial intelligence research: A review on dominant themes, methods, frameworks and future research directions","@article{OFOSUAMPONG2024100127,
title = {Artificial intelligence research: A review on dominant themes, methods, frameworks and future research directions},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100127},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100127},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000136},
author = {Kingsley Ofosu-Ampong},
keywords = {Artificial intelligence, Classification, Literature review, Technological issues, Research agenda},
abstract = {This article presents an analysis of artificial intelligence (AI) in information systems and innovation-related journals to determine the current issues and stock of knowledge in AI literature, research methodology, frameworks, level of analysis and conceptual approaches. By doing this, the article aims to identify research gaps that can guide future investigations. A total of 85 peer-reviewed articles from 2020 to 2023 were used in the analysis. The findings show that extant literature is skewed towards the prevalence of technological issues and highlights the relatively lower focus on other themes, such as contextual knowledge co-creation issues, conceptualisation, and application domains. While there have been increasing technological issues with artificial intelligence, the three identified areas of security concern are data security, model security and network security. Furthermore, the review found that contemporary AI, which continually drives the boundaries of computational capabilities to tackle increasingly intricate decision-making challenges, distinguishes itself from earlier iterations in two primary aspects that significantly affect organisational learning in dealing with AI's potential: autonomy and learnability. This study contributes to AI research by providing insights into current issues, research methodology, level of analysis and conceptual approaches, and AI framework to help identify research gaps for future investigations.}
}
",https://www.sciencedirect.com/science/article/pii/S2772503024000136,https://doi.org/10.1016/j.teler.2024.100127,science_direct,2024
1475,"Exploring the impact of ChatGPT on art creation and collaboration: Benefits, challenges and ethical implications","@article{ZHU2024100138,
title = {Exploring the impact of ChatGPT on art creation and collaboration: Benefits, challenges and ethical implications},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100138},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100138},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000240},
author = {Sijin Zhu and Zheng Wang and Yuan Zhuang and Yuyang Jiang and Mengyao Guo and Xiaolin Zhang and Ze Gao},
keywords = {Creative AI, HumanAI collaboration, Language models, Interactive AI literacy},
abstract = {This paper examines the chaos caused by introducing advanced language models, specifically ChatGPT, to art. Our focus is on the potential impact of ChatGPT on art creation and collaboration. We explore how it has been utilized to generate art and assist in creative writing and how it facilitates collaboration between artists. This exploration includes an investigation into the use of AI in creating art, music, and literature, emphasizing ChatGPT’s role in generating poetry and prose and its ability to provide valuable suggestions for sentence structure and word choice in creative writing. We conduct case studies and interviews with diverse artists and AI experts to understand the benefits and challenges of using ChatGPT in the creative process. Our findings reveal that artists find ChatGPT helpful in generating new ideas, overcoming creative blocks, and improving the quality of their work. It enables remote collaboration between artists by providing a real-time communication and idea-sharing platform. However, ethical concerns relating to authorship ownership and authenticity have emerged. Artists fear using ChatGPT may lead to losing their artistic identity and ownership of their work. While our data suggests that ChatGPT holds the potential to transform the art world, careful consideration must be given to the ethical implications of AI in art. We recommend future research to focus on developing guidelines for the responsible use of AI in art, safeguarding artists’ rights, and preserving artistic authenticity.}
}
",https://www.sciencedirect.com/science/article/pii/S2772503024000240,https://doi.org/10.1016/j.teler.2024.100138,science_direct,2024
1477,The academic industry’s response to generative artificial intelligence: An institutional analysis of large language models,"@article{KSHETRI2024102760,
title = {The academic industry’s response to generative artificial intelligence: An institutional analysis of large language models},
journal = {Telecommunications Policy},
volume = {48},
number = {5},
pages = {102760},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102760},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124000570},
author = {Nir Kshetri},
keywords = {Academic industry, ChatGPT, Generative artificial intelligence, Institutional theory, Large language models, Theorization},
abstract = {This paper examines academic institutions' heterogeneous initial responses to generative AI (GAI) tools like ChatGPT and factors influencing increased acceptance over time. GAI's disruptive nature coupled with uncertainty about impacts poses adoption challenges. However, external pressures from stakeholders seeking GAI integration contribute to changing attitudes. Actions of institutional change agents also drive growing acceptance by increasing awareness of GAI advantages. They challenge prevailing logics emphasizing assessments, proposing new values around employability and job performance. Additionally, academic institutions reevaluating GAI's value creation potential through applications and evolving business models contributes to favorable responses. The paper proposes an institutional theory framework explaining dynamics underpinning academic institutions' assimilation of GAI. It highlights how various mechanisms like external pressures, institutional entrepreneurs' theorization efforts justifying technology use, and internal sensemaking shape institutional norms and values, enabling academic systems' adaptation. The study informs policy and practice while directing future research toward validating propositions empirically and examining contextual dimensions including industry characteristics affecting GAI adoption.}
}
",https://www.sciencedirect.com/science/article/pii/S0308596124000570,https://doi.org/10.1016/j.telpol.2024.102760,science_direct,2024
1478,Generative AI for visualization: State of the art and future directions,"@article{YE202443,
title = {Generative AI for visualization: State of the art and future directions},
journal = {Visual Informatics},
volume = {8},
number = {2},
pages = {43-66},
year = {2024},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2024.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X24000160},
author = {Yilin Ye and Jianing Hao and Yihan Hou and Zhan Wang and Shishi Xiao and Yuyu Luo and Wei Zeng},
keywords = {Visualization, Generative AI},
abstract = {Generative AI (GenAI) has witnessed remarkable progress in recent years and demonstrated impressive performance in various generation tasks in different domains such as computer vision and computational design. Many researchers have attempted to integrate GenAI into visualization framework, leveraging the superior generative capacity for different operations. Concurrently, recent major breakthroughs in GenAI like diffusion models and large language models have also drastically increased the potential of GenAI4VIS. From a technical perspective, this paper looks back on previous visualization studies leveraging GenAI and discusses the challenges and opportunities for future research. Specifically, we cover the applications of different types of GenAI methods including sequence, tabular, spatial and graph generation techniques for different tasks of visualization which we summarize into four major stages: data enhancement, visual mapping generation, stylization and interaction. For each specific visualization sub-task, we illustrate the typical data and concrete GenAI algorithms, aiming to provide in-depth understanding of the state-of-the-art GenAI4VIS techniques and their limitations. Furthermore, based on the survey, we discuss three major aspects of challenges and research opportunities including evaluation, dataset, and the gap between end-to-end GenAI methods and visualizations. By summarizing different generation algorithms, their current applications and limitations, this paper endeavors to provide useful insights for future GenAI4VIS research.}
}
",https://www.sciencedirect.com/science/article/pii/S2468502X24000160,https://doi.org/10.1016/j.visinf.2024.04.003,science_direct,2024
1479,A popular topic detection method based on microblog images and short text information,"@article{LIU2024100820,
title = {A popular topic detection method based on microblog images and short text information},
journal = {Journal of Web Semantics},
volume = {81},
pages = {100820},
year = {2024},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100820},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000064},
author = {Wenjun Liu and Hai Wang and Jieyang Wang and Huan Guo and Yuyan Sun and Mengshu Hou and Bao Yu and Hailan Wang and Qingcheng Peng and Chao Zhang and Cheng Liu},
keywords = {Topic detection, Image description, Semantic similarity, Internet New Word Detection, Short Text},
abstract = {Popular topic detection is a topic identification by the information of documents posted by users in social networking platforms. In a large body of research literature, most popular topic detection methods identify the distribution of unknown topics by integrating information from documents based on social networking platforms. However, among these popular topic detection methods, most of them have a low accuracy in topic detection due to the short text content and the abundance of useless punctuation marks and emoticons. Image information in short texts has also been overlooked, while this information may contain the real topic matter of the user's posted content. In order to solve the above problems and improve the quality of topic detection, this paper proposes a popular topic detection method based on microblog images and short text information. The method uses an image description model to obtain more information about short texts, identifies hot words by a new word discovery algorithm in the preprocessing stage, and uses a PTM model to improve the quality and effectiveness of topic detection during topic detection and aggregation. The experimental results show that the topic detection method in this paper improves the values of evaluation indicators compared with the other three topic detection methods. In conclusion, the popular topic detection method proposed in this paper can improve the performance of topic detection by integrating microblog images and short text information, and outperforms other topic detection methods selected in this paper.}
}
",https://www.sciencedirect.com/science/article/pii/S1570826824000064,https://doi.org/10.1016/j.websem.2024.100820,science_direct,2024
1480,RevOnt: Reverse engineering of competency questions from knowledge graphs via language models,"@article{CIROKU2024100822,
title = {RevOnt: Reverse engineering of competency questions from knowledge graphs via language models},
journal = {Journal of Web Semantics},
volume = {82},
pages = {100822},
year = {2024},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100822},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000088},
author = {Fiorela Ciroku and Jacopo {de Berardinis} and Jongmo Kim and Albert Meroño-Peñuela and Valentina Presutti and Elena Simperl},
keywords = {Knowledge engineering, Knowledge graph, Ontology development, Competency question extraction},
abstract = {The process of developing ontologies – a formal, explicit specification of a shared conceptualisation – is addressed by well-known methodologies. As for any engineering development, its fundamental basis is the collection of requirements, which includes the elicitation of competency questions. Competency questions are defined through interacting with domain and application experts or by investigating existing datasets that may be used to populate the ontology i.e. its knowledge graph. The rise in popularity and accessibility of knowledge graphs provides an opportunity to support this phase with automatic tools. In this work, we explore the possibility of extracting competency questions from a knowledge graph. This reverses the traditional workflow in which knowledge graphs are built from ontologies, which in turn are engineered from competency questions. We describe in detail RevOnt, an approach that extracts and abstracts triples from a knowledge graph, generates questions based on triple verbalisations, and filters the resulting questions to yield a meaningful set of competency questions; the WDV dataset. This approach is implemented utilising the Wikidata knowledge graph as a use case, and contributes a set of core competency questions from 20 domains present in the WDV dataset. To evaluate RevOnt, we contribute a new dataset of manually-annotated high-quality competency questions, and compare the extracted competency questions by calculating their BLEU score against the human references. The results for the abstraction and question generation components of the approach show good to high quality. Meanwhile, the accuracy of the filtering component is above 86%, which is comparable to the state-of-the-art classifications.}
}
",https://www.sciencedirect.com/science/article/pii/S1570826824000088,https://doi.org/10.1016/j.websem.2024.100822,science_direct,2024
1481,Natural language processing models that automate programming will transform chemistry research and teaching††Electronic supplementary information (ESI) available. See DOI: 10.1039/d1dd00009h,"@article{HOCKY202279,
title = {Natural language processing models that automate programming will transform chemistry research and teaching††Electronic supplementary information (ESI) available. See DOI: 10.1039/d1dd00009h},
journal = {Digital Discovery},
volume = {1},
number = {2},
pages = {79-83},
year = {2022},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d1dd00009h},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X23000694},
author = {Glen M. Hocky and Andrew D. White},
abstract = {ABSTRACT
Natural language processing models have emerged that can generate useable software and automate a number of programming tasks with high fidelity. These tools have yet to have an impact on the chemistry community. Yet, our initial testing demonstrates that this form of artificial intelligence is poised to transform chemistry and chemical engineering research. Here, we review developments that brought us to this point, examine applications in chemistry, and give our perspective on how this may fundamentally alter research and teaching.}
}
",https://www.sciencedirect.com/science/article/pii/S2635098X23000694,https://doi.org/10.1039/d1dd00009h,science_direct,2022
1482,"Assessment of chemistry knowledge in large language models that generate code††Electronic supplementary information (ESI) available: Supporting figures, tables, and text. Accuracy data are available as comma separated value files. Contexts are available as a markup file. The responses from the model (completions) which were the basis for expert evaluators are available in HTML format at https://doi.org/10.5281/zenodo.6800475. See DOI: https://doi.org/10.1039/d2dd00087c","@article{WHITE2023368,
title = {Assessment of chemistry knowledge in large language models that generate code††Electronic supplementary information (ESI) available: Supporting figures, tables, and text. Accuracy data are available as comma separated value files. Contexts are available as a markup file. The responses from the model (completions) which were the basis for expert evaluators are available in HTML format at https://doi.org/10.5281/zenodo.6800475. See DOI: https://doi.org/10.1039/d2dd00087c},
journal = {Digital Discovery},
volume = {2},
number = {2},
pages = {368-376},
year = {2023},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d2dd00087c},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X23000359},
author = {Andrew D. White and Glen M. Hocky and Heta A. Gandhi and Mehrad Ansari and Sam Cox and Geemi P. Wellawatte and Subarna Sasmal and Ziyue Yang and Kangxin Liu and Yuvraj Singh and Willmor J. {Peña Ccoa}},
abstract = {ABSTRACT
In this work, we investigate the question: do code-generating large language models know chemistry? Our results indicate, mostly yes. To evaluate this, we introduce an expandable framework for evaluating chemistry knowledge in these models, through prompting models to solve chemistry problems posed as coding tasks. To do so, we produce a benchmark set of problems, and evaluate these models based on correctness of code by automated testing and evaluation by experts. We find that recent LLMs are able to write correct code across a variety of topics in chemistry and their accuracy can be increased by 30 percentage points via prompt engineering strategies, like putting copyright notices at the top of files. Our dataset and evaluation tools are open source which can be contributed to or built upon by future researchers, and will serve as a community resource for evaluating the performance of new models as they emerge. We also describe some good practices for employing LLMs in chemistry. The general success of these models demonstrates that their impact on chemistry teaching and research is poised to be enormous.}
}
",https://www.sciencedirect.com/science/article/pii/S2635098X23000359,https://doi.org/10.1039/d2dd00087c,science_direct,2023
1483,Towards a modular architecture for science factories††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d3dd00142c,"@article{VESCOVI20231980,
title = {Towards a modular architecture for science factories††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d3dd00142c},
journal = {Digital Discovery},
volume = {2},
number = {6},
pages = {1980-1998},
year = {2023},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00142c},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X2300133X},
author = {Rafael Vescovi and Tobias Ginsburg and Kyle Hippe and Doga Ozgulbas and Casey Stone and Abraham Stroka and Rory Butler and Ben Blaiszik and Tom Brettin and Kyle Chard and Mark Hereld and Arvind Ramanathan and Rick Stevens and Aikaterini Vriza and Jie Xu and Qingteng Zhang and Ian Foster},
abstract = {ABSTRACT
Advances in robotic automation, high-performance computing (HPC), and artificial intelligence (AI) encourage us to conceive of science factories: large, general-purpose computation- and AI-enabled self-driving laboratories (SDLs) with the generality and scale needed both to tackle large discovery problems and to support thousands of scientists. Science factories require modular hardware and software that can be replicated for scale and (re)configured to support many applications. To this end, we propose a prototype modular science factory architecture in which reconfigurable modules encapsulating scientific instruments are linked with manipulators to form workcells, that can themselves be combined to form larger assemblages, and linked with distributed computing for simulation, AI model training and inference, and related tasks. Workflows that perform sets of actions on modules can be specified, and various applications, comprising workflows plus associated computational and data manipulation steps, can be run concurrently. We report on our experiences prototyping this architecture and applying it in experiments involving 15 different robotic apparatus, five applications (one in education, two in biology, two in materials), and a variety of workflows, across four laboratories. We describe the reuse of modules, workcells, and workflows in different applications, the migration of applications between workcells, and the use of digital twins, and suggest directions for future work aimed at yet more generality and scalability. Code and data are available at https://ad-sdl.github.io/wei2023 and in the ESI.}
}
",https://www.sciencedirect.com/science/article/pii/S2635098X2300133X,https://doi.org/10.1039/d3dd00142c,science_direct,2023
1484,What is missing in autonomous discovery: open challenges for the community,"@article{MAFFETTONE20231644,
title = {What is missing in autonomous discovery: open challenges for the community},
journal = {Digital Discovery},
volume = {2},
number = {6},
pages = {1644-1659},
year = {2023},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00143a},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X23001171},
author = {Phillip M. Maffettone and Pascal Friederich and Sterling G. Baird and Ben Blaiszik and Keith A. Brown and Stuart I. Campbell and Orion A. Cohen and Rebecca L. Davis and Ian T. Foster and Navid Haghmoradi and Mark Hereld and Howie Joress and Nicole Jung and Ha-Kyung Kwon and Gabriella Pizzuto and Jacob Rintamaki and Casper Steinmann and Luca Torresi and Shijing Sun},
abstract = {ABSTRACT
Self-driving labs (SDLs) leverage combinations of artificial intelligence, automation, and advanced computing to accelerate scientific discovery. The promise of this field has given rise to a rich community of passionate scientists, engineers, and social scientists, as evidenced by the development of the Acceleration Consortium and recent Accelerate Conference. Despite its strengths, this rapidly developing field presents numerous opportunities for growth, challenges to overcome, and potential risks of which to remain aware. This community perspective builds on a discourse instantiated during the first Accelerate Conference, and looks to the future of self-driving labs with a tempered optimism. Incorporating input from academia, government, and industry, we briefly describe the current status of self-driving labs, then turn our attention to barriers, opportunities, and a vision for what is possible. Our field is delivering solutions in technology and infrastructure, artificial intelligence and knowledge generation, and education and workforce development. In the spirit of community, we intend for this work to foster discussion and drive best practices as our field grows.}
}
",https://www.sciencedirect.com/science/article/pii/S2635098X23001171,https://doi.org/10.1039/d3dd00143a,science_direct,2023
1485,MaScQA: investigating materials science knowledge of large language models††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d3dd00188a,"@article{ZAKI2024313,
title = {MaScQA: investigating materials science knowledge of large language models††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d3dd00188a},
journal = {Digital Discovery},
volume = {3},
number = {2},
pages = {313-327},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00188a},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000159},
author = {Mohd Zaki and  Jayadeva and  Mausam and N. M. Anoop Krishnan},
abstract = {Information extraction and textual comprehension from materials literature are vital for developing an exhaustive knowledge base that enables accelerated materials discovery. Language models have demonstrated their capability to answer domain-specific questions and retrieve information from knowledge bases. However, there are no benchmark datasets in the materials science domain that can be used to evaluate the understanding of the key concepts by these language models. In this work, we curate a dataset of 650 challenging questions from the materials domain that require the knowledge and skills of a materials science student who has cleared their undergraduate degree. We classify these questions based on their structure and the materials science domain-based subcategories. Further, we evaluate the performance of LLaMA-2-70B, GPT-3.5, and GPT-4 models on solving these questions via zero-shot and chain of thought prompting. It is observed that GPT-4 gives the best performance (∼62% accuracy) as compared to other models. Interestingly, in contrast to the general observation, no significant improvement in accuracy is observed with the chain of thought prompting. To evaluate the limitations, we performed an error analysis, which revealed conceptual errors (∼72%) as the major contributor compared to computational errors (∼28%) towards the reduced performance of the LLMs. We also compared GPT-4 with human performance and observed that GPT-4 is better than an average student and comes close to passing the exam. We also show applications of the best performing model (GPT-4) on composition–extraction from tables of materials science research papers and code writing tasks. While GPT-4 performs poorly on composition extraction, it outperforms all other models on the code writing task. We hope that the dataset, analysis, and applications discussed in this work will promote further research in developing better materials science domain-specific LLMs and strategies for information extraction.}
}
",https://www.sciencedirect.com/science/article/pii/S2635098X24000159,https://doi.org/10.1039/d3dd00188a,science_direct,2024
1486,Review of low-cost self-driving laboratories in chemistry and materials science: the “frugal twin” concept,"@article{LO2024842,
title = {Review of low-cost self-driving laboratories in chemistry and materials science: the “frugal twin” concept},
journal = {Digital Discovery},
volume = {3},
number = {5},
pages = {842-868},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00223c},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000846},
author = {Stanley Lo and Sterling G. Baird and Joshua Schrier and Ben Blaiszik and Nessa Carson and Ian Foster and Andrés Aguilar-Granda and Sergei V. Kalinin and Benji Maruyama and Maria Politi and Helen Tran and Taylor D. Sparks and Alán Aspuru-Guzik},
abstract = {This review proposes the concept of a “frugal twin,” similar to a digital twin, but for physical experiments. Frugal twins range from simple toy examples to low-cost surrogates of high-cost research systems. For example, a color-mixing self-driving laboratory (SDL) can serve as a low-cost version of a costly multi-step chemical discovery SDL. Frugal twins already provide hands-on experience for SDLs with low costs and low risks. They can also offer as test beds for software prototyping (e.g., optimization, data infrastructure), and a low barrier to entry for democratizing SDLs. However, there is room for improvement. The true value of frugal twins can be realized in three core areas. Firstly, hardware and software modularity; secondly, purpose-built design (human-inspired vs. hardware-centric vs. human-in-the-loop); and thirdly state-of-the-art (SOTA) software (e.g., multi-fidelity optimization). We also describe the ethical benefits and risks that come with the democratization of science through frugal twins. For future work, we suggest ideas for new frugal twins, SDL educational course outcomes, and a classification scheme for autonomy levels.}
}
",https://www.sciencedirect.com/science/article/pii/S2635098X24000846,https://doi.org/10.1039/d3dd00223c,science_direct,2024
1488,Let's ask AI About Their Programs: Exploring ChatGPT's Answers to Program Comprehension Questions,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10/nan</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10/nan"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554757,,ieee,2024
1489,Compositional API Recommendation for Library-Oriented Code Generation,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10/nan</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10/nan"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556452,,ieee,2024
1490,Seven Failure Points When Engineering a Retrieval Augmented Generation System,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10/nan</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10/nan"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556182,,ieee,2024
1491,Chances and Challenges of Chatgpt and Similar Models for Education in M&amp;S,"@inproceedings{10.5555/3643142.3643420,
author = {Tolk, Andreas and Barry, Philip and Loper, Margaret L. and Rabadi, Ghaith and Scherer, William T. and Yilmaz, Levent},
title = {Chances and Challenges of Chatgpt and Similar Models for Education in M&amp;S},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {This position paper summarizes the inputs of a group of experts from academia and industry presenting their view on chances and challenges of using ChatGPT within Modeling and Simulation education. The experts also address the need to evaluate continuous education as well as education of faculty members to address scholastic challenges and opportunities while meeting the expectation of industry. Generally, the use of ChatGPT is encouraged, but it needs to be embedded into an updated curriculum with more emphasis on validity constraints, systems thinking, and ethics.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3332–3346},
numpages = {15},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

",,,acm,2024
1492,GPT-Based Models Meet Simulation: How to Efficiently use Large-Scale Pre-Trained Language Models Across Simulation Tasks,"@inproceedings{10.5555/3643142.3643385,
author = {Giabbanelli, Philippe J.},
title = {GPT-Based Models Meet Simulation: How to Efficiently use Large-Scale Pre-Trained Language Models Across Simulation Tasks},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {The disruptive technology provided by large-scale pre-trained language models (LLMs) such as ChatGPT or GPT-4 has received significant attention in several application domains, often with an emphasis on high-level opportunities and concerns. This paper is the first examination regarding the use of LLMs for scientific simulations. We focus on four modeling and simulation tasks, each time assessing the expected benefits and limitations of LLMs while providing practical guidance for modelers regarding the steps involved. The first task is devoted to explaining the structure of a conceptual model to promote the engagement of participants in the modeling process. The second task focuses on summarizing simulation outputs, so that model users can identify a preferred scenario. The third task seeks to broaden accessibility to simulation platforms by conveying the insights of simulation visualizations via text. Finally, the last task evokes the possibility of explaining simulation errors and providing guidance to resolve them.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2920–2931},
numpages = {12},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

",,,acm,2024
1493,Getting Started with Large Language Models for the CS Curriculum,"@article{10.5555/3665464.3665480,
author = {Manley, Eric D.},
title = {Getting Started with Large Language Models for the CS Curriculum},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {With the introduction of ChatGPT in late 2022, popular interest in language-based Artificial Intelligence has exploded. Employers are looking to hire computer scientists who can leverage large language models (LLMs) [2], and student demand for learning about them at many higher education institutions has followed. This one-hour workshop will help computer science educators respond to this demand by introducing the Python transformers library and its associated LLM ecosystem [1]. We will discuss how LLMs can be integrated into college computer science curricula from CS 1 through advanced courses in Artificial Intelligence, Machine Learning, or Natural Language Processing. Specific topics include• Using the transformers library with pre-trained models for inference tasks like sentiment analysis, text classification, summarization, translation, and question answering in only a few lines of code• Searching for and using hundreds of thousands of different pre-trained language models hosted by Hugging Face along with datasets that they can be tested on• Utilizing conversational models to build chat bots},
journal = {J. Comput. Sci. Coll.},
month = {may},
pages = {116–117},
numpages = {2}
}

",,,acm,2024
1494,Examining Student Use of AI in CS1 and CS2,"@article{10.5555/3665464.3665469,
author = {Manley, Eric D. and Urness, Timothy and Migunov, Andrei and Reza, Md. Alimoor},
title = {Examining Student Use of AI in CS1 and CS2},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {The launch of ChatGPT in November 2022 marked a seismic disruption to many disciplines and industries, including higher education. For the first time, students everywhere have widely available access to a Large Language Model (LLM) capable of generating content - including solutions to programming assignments in CS1 and CS2 - that can pass as the work of a high-achieving student while making traditional plagiarism-detection obsolete. This has spurred various responses in higher education, including a shift to more in-class and unplugged assessments. At the same time, LLMs are transforming the way that many people work, including professional software developers, and students similarly might be able to use them to enhance their learning. In this paper, we report on our experiences with a permissive policy towards the use of ChatGPT and other artificial intelligence (AI) tools for assisting students with their programming assignments in CS1 and CS2 courses in the Spring 2023 semester. Students were allowed to use these tools however they wished as long as they submitted a form which included a transcript of their chat and a reflection on what they learned, if anything, through the interaction. We found that students largely approached the AI in positive ways and that they seemed to genuinely learn from the experience. We also document some things that did not go well and that remain challenges to using AI in programming courses, along with our recommendations on how these might be dealt with in the future.},
journal = {J. Comput. Sci. Coll.},
month = {may},
pages = {41–51},
numpages = {11}
}

",,,acm,2024
1495,Coding Integrity Unveiled: Exploring the Pros and Cons of Detecting Plagiarism in Programming Assignments Using Copyleaks,"@article{10.5555/3665464.3665471,
author = {Mouli, Chandra and Kotteti, Madhav and Lal, Ratan and Chetti, Prasad},
title = {Coding Integrity Unveiled: Exploring the Pros and Cons of Detecting Plagiarism in Programming Assignments Using Copyleaks},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Before the advent of generative Artificial Intelligence (AI) tools, for example, ChatGPT, students traditionally approached assignment development authentically by employing libraries and by referring to textbooks. However, with the widespread reliance on powerful AI tools for assignment completion, the process has become more convenient. Unfortunately, this ease of use has led to a potential detriment in students' genuine understanding of subjects, as well as a decline in their problem-solving and innovative thinking skills. Moreover, AI tools like ChatGPT will evolve as technology advances such that the need to detect AI-generated content is even more crucial in educational setting to reinforce the value of original work [5]. This paper aims to address this issue by focusing on the detection of plagiarism in student assignments through the utilization of the Copyleaks1 tool, specifically designed to identify AI-generated code. The accuracy of the tool is systematically evaluated by submitting various pairs of codes, each with similar functionality, wherein one is generated by AI and the other by humans.},
journal = {J. Comput. Sci. Coll.},
month = {may},
pages = {61–69},
numpages = {9}
}

",,,acm,2024
1496,"ChatGPT: To Use or Not to Use, That is the Question: Panel Discussion","@article{10.5555/3637068.3637089,
author = {Cerkez, Paul S. and Hummel, Joseph Edward and Mejias, Marlon and Pruitt, William},
title = {ChatGPT: To Use or Not to Use, That is the Question: Panel Discussion},
year = {2023},
issue_date = {November 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {5},
issn = {1937-4771},
abstract = {ChatGPT, from OpenAI (AI - artificial intelligence), and the many similar Large Language Models (LLM) appear to have taken the world by storm with some for it, some against it. In simple terms, these products are a great tool for the experienced domain user, however, precisely because of their capability, there is a lot of controversy surrounding student's use.},
journal = {J. Comput. Sci. Coll.},
month = {nov},
pages = {175–176},
numpages = {2}
}

",,,acm,2023
1497,Can ChatGPT Pass a CS1 Python Course?,"@article{10.5555/3665609.3665618,
author = {Sharpe, James S. and Dougherty, Ryan E. and Smith, Sarah J.},
title = {Can ChatGPT Pass a CS1 Python Course?},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {In this paper we determine whether an LLM-ChatGPT in this case-can successfully complete the assignments in our CS1 course as if it were a ""real"" student. Our study contains a two-stage approach, involving reprompts to the LLM in the cases of either not successfully completing the assignment, or using concepts that are more advanced than are taught in our course. We find that LLMs can in fact can either perfectly solve, or almost perfectly solve, every assignment in our CS1 course.},
journal = {J. Comput. Sci. Coll.},
month = {may},
pages = {128–142},
numpages = {15}
}

",,,acm,2024
1498,MAUVE scores for generative models: theory and practice,"@article{10.5555/3648699.3649055,
author = {Pillutla, Krishna and Liu, Lang and Thickstun, John and Welleck, Sean and Swayamdipta, Swabha and Zellers, Rowan and Oh, Sewoong and Choi, Yejin and Harchaoui, Zaid},
title = {MAUVE scores for generative models: theory and practice},
year = {2024},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Generative artificial intelligence has made significant strides, producing text indistinguishable from human prose and remarkably photorealistic images. Automatically measuring how close the generated data distribution is to the target distribution is central to diagnosing existing models and developing better ones. We present MAUVE, a family of comparison measures between pairs of distributions such as those encountered in the generative modeling of text or images. These scores are statistical summaries of divergence frontiers capturing two types of errors in generative modeling. We explore three approaches to statistically estimate these scores: vector quantization, non-parametric estimation, and classifier-based estimation. We provide statistical bounds for the vector quantization approach.Empirically, we find that the proposed scores paired with a range of f-divergences and statistical estimation methods can quantify the gaps between the distributions of humanwritten text and those of modern neural language models by correlating with human judgments and identifying known properties of the generated texts. We demonstrate in the vision domain that MAUVE can identify known properties of generated images on par with or better than existing metrics. In conclusion, we present practical recommendations for using MAUVE effectively with language and image modalities.},
journal = {J. Mach. Learn. Res.},
month = {mar},
articleno = {356},
numpages = {92},
keywords = {generative models, evaluation, divergence frontiers, neural text generation, large language models, f-divergences, statistical estimation}
}

",,,acm,2024
1500,Exploring ChatGPT's Ability to Solve Programming Problems with Complex Context,"@article{10.5555/3636988.3637017,
author = {Tran, Nghia D. and May, James J. and Ho, Nguyen and Ngo, Linh B.},
title = {Exploring ChatGPT's Ability to Solve Programming Problems with Complex Context},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {This paper presents a preliminary study on ChatGPT's ability to generate a working solution from a complex programming problem's textual description. Utilizing an online competitive programming platform's problem statements and its respective difficulty measures, we were able to examine ChatGPT's capabilities using the platform's solution status as a performance indicator. The experimental results show a strong relationship between the problem's perceived difficulty level, as provided by the platform, and the final solution status. Various techniques were used to measure the readability level of the problems' text, and we also found statistical relationship among several of them regarding the final status. The results also hint at a potential limitation of ChatGPT to understand complex programming problem context.},
journal = {J. Comput. Sci. Coll.},
month = {oct},
pages = {195–209},
numpages = {15}
}

",,,acm,2023
1501,The Cognitive Hourglass: Agent Abstractions in the Large Models Era,"@inproceedings{10.5555/3635637.3663262,
author = {Ricci, Alessandro and Mariani, Stefano and Zambonelli, Franco and Burattini, Samuele and Castelfranchi, Cristiano},
title = {The Cognitive Hourglass: Agent Abstractions in the Large Models Era},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Recent advances in AI are driving an unprecedented and fast-paced development of myriads of powerful agent tools and applications, mostly based on generative AI technologies such as Large Language/Multi-modal/Agent Models. However, despite many proposals in that direction, the lack of a sound set of usable engineering abstractions hinders the possibility of methodically engineering complex agent-based applications, also due to the gap between cognitive agent-based concepts and LLMs' behavioural patterns. We argue that such a set of abstractions should constitute the ""narrow neck"" of an indispensable ""cognitive hourglass"": a level of abstraction that is meant to be useful for humans to understand/design/control agents and MAS, regardless of the specific AI technologies adopted at the implementation level and of the specific application context. Here, we elaborate on the idea of the cognitive hourglass, motivate its need, sketch its envisioned architecture, and identify the research challenges for its realisation.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {2706–2711},
numpages = {6},
keywords = {agent systems engineering, cognition, hourglass model, llms},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

",,,acm,2024
1502,PaLM: scaling language modeling with pathways,"@article{10.5555/3648699.3648939,
author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sashank and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
title = {PaLM: scaling language modeling with pathways},
year = {2024},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540- billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
journal = {J. Mach. Learn. Res.},
month = {mar},
articleno = {240},
numpages = {113},
keywords = {large language models, few-shot learning, natural language processing, scalable deep learning}
}

",,,acm,2024
1503,Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning,"@inproceedings{10.5555/3635637.3663007,
author = {Niu, Tong and Zhang, Weihao and Zhao, Rong},
title = {Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Agent-based models (ABMs) stand as an essential paradigm for proposing and validating hypothetical solutions or policies aimed at addressing challenges posed by complex systems and achieving various objectives. This process demands labor-intensive endeavors and multidisciplinary expertise. Large language models (LLMs) encapsulating cross-domain knowledge and programming proficiency could potentially alleviate the difficulty of this process. However, LLMs excel in handling sequential information, making it challenging for analyzing the intricate interactions and nonlinear dynamics inherent in ABMs. Additionally, due to the lack of self-evaluation capability of LLMs, relying solely on LLMs is insufficient to effectively accomplish this process. In this paper, we present SAGE, a general solution-oriented ABM generation framework designed for automatic modeling and generating solutions for targeted problems. Unlike approaches reliant on expert handcrafting or resource-intensive neural network training, SAGE establishes a verifier-assisted iterative in-context learning process employing large language models (LLMs) to leverages their inherent cross-domain knowledge for tackling intricate demands from diverse domain scenarios. In SAGE, we introduce an semi-structured conceptual representation expliciting the intricate structures of ABMs and an objective representation to guide LLMs in modeling scenarios and proposing hypothetical solutions through in-context learning. To ensure the model executability and solution feasibility, SAGE devises a two-level verifier with chain-of-thought prompting tailored to the complex interactions and non-linear dynamics of ABMs, driving the iterative generation optimization. Moreover, we construct an evaluation dataset of solution-oriented ABMs from open sources. It contains practical models across various domains, completed with scenario descriptions and executable agent-based solutions. Evaluations by various LLMs demonstrate that SAGE leads to an average improvement of 18.7% in modeling quality and 38.1% in solution generation effectiveness. This work advances our understanding and ability in tackling complex real-world challenges across diverse domains through the application of ABM methodologies.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {1473–1481},
numpages = {9},
keywords = {automatic verification and generation, chain-of-thought prompting, iterative in-context learning, large language models, solution-oriented agent-based modeling},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

",,,acm,2024
1504,Compute-efficient deep learning: algorithmic trends and opportunities,"@article{10.5555/3648699.3648821,
author = {Bartoldson, Brian R. and Kailkhura, Bhavya and Blalock, Davis},
title = {Compute-efficient deep learning: algorithmic trends and opportunities},
year = {2024},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Although deep learning has made great progress in recent years, the exploding economic and environmental costs of training neural networks are becoming unsustainable. To address this problem, there has been a great deal of research on algorithmically-efficient deep learning, which seeks to reduce training costs not at the hardware or implementation level, but through changes in the semantics of the training program. In this paper, we present a structured and comprehensive overview of the research in this field. First, we formalize the algorithmic speedup problem, then we use fundamental building blocks of algorithmically efficient training to develop a taxonomy. Our taxonomy highlights commonalities of seemingly disparate methods and reveals current research gaps. Next, we present evaluation best practices to enable comprehensive, fair, and reliable comparisons of speedup techniques. To further aid research and applications, we discuss common bottlenecks in the training pipeline (illustrated via experiments) and offer taxonomic mitigation strategies for them. Finally, we highlight some unsolved research challenges and present promising future directions.},
journal = {J. Mach. Learn. Res.},
month = {mar},
articleno = {122},
numpages = {77},
keywords = {deep learning, training speedup, computational efficiency, carbon emission}
}

",,,acm,2024
1505,Residual energy-based models for text,"@article{10.5555/3546258.3546298,
author = {Bakhtin, Anton and Deng, Yuntian and Gross, Sam and Ott, Myle and Ranzato, Marc'Aurelio and Szlam, Arthur},
title = {Residual energy-based models for text},
year = {2021},
issue_date = {January 2021},
publisher = {JMLR.org},
volume = {22},
number = {1},
issn = {1532-4435},
abstract = {Current large-scale auto-regressive language models (Radford et al., 2019; Liu et al., 2018; Graves, 2013) display impressive fluency and can generate convincing text. In this work we start by asking the question: Can the generations of these models be reliably distinguished from real text by statistical discriminators? We find experimentally that the answer is affirmative when we have access to the training data for the model, and guardedly affirmative even if we do not.This suggests that the auto-regressive models can be improved by incorporating the (globally normalized) discriminators into the generative process. We give a formalism for this using the Energy-Based Model framework, and show that it indeed improves the results of the generative models, measured both in terms of perplexity and in terms of human evaluation.},
journal = {J. Mach. Learn. Res.},
month = {jan},
articleno = {40},
numpages = {41},
keywords = {energy-based models, text generation, negative sampling, importance sampling, generalization, real/fake discrimination}
}

",,,acm,2021
1506,Large Language Models (GPT) for automating feedback on programming assignments,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10/nan</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10/nan"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",,,web_of_science,2023
1507,ExGen: Ready-To-Use Exercise Generation in Introductory Programming Courses,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10/nan</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10/nan"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",,,web_of_science,2023
1508,Catalyzing Python Learning: Assessing an LLM-based Conversational Agent,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10/nan</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10/nan"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",,,web_of_science,2023
1509,Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10/nan</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10/nan"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",,,web_of_science,2023
1510,Automated Analysis of Job Market Demands using Large Language Model,"<!DOCTYPE html>
<html lang=""en-us"">
<head>

    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1"">
    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
    <title>Error: DOI Not Found</title>



    <link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css""
          rel=""stylesheet""
          integrity=""sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC""
          crossorigin=""anonymous"">
    <script
            src=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js""
            integrity=""sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM""
            crossorigin=""anonymous"">
    </script>

    <script src=""https://kit.fontawesome.com/731b8140c4.js"" crossorigin=""anonymous""></script>

    <link rel=""stylesheet"" href=""/static/css/style.css"" integrity="""">

    <style>
        @import url(""https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Roboto:wght@100&display=swap"");
    </style>

    <link rel=""icon"" sizes=""48x48"" href=""/static/images/favicons/favicon.ico"">
    <link rel=""icon"" sizes=""32x32"" href=""/static/images/favicons/favicon-32x32.png"">
    <link rel=""icon"" sizes=""16x16"" href=""/static/images/favicons/favicon-16x16.png"">
    <link rel=""apple-touch-icon-precomposed"" href=""/static/images/favicons/apple-touch-icon.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""192x192"" href=""/static/images/favicons/android-chrome-192x192.png"">
    <link rel=""apple-touch-icon-precomposed"" sizes=""512x512"" href=""/static/images/favicons/android-chrome-512x512.png"">

</head>
<body class=""generic-page"">
<header>
    <div class=""row"">
        <div class=""col logo"">
            <a href=""https://www.doi.org""><img class=""header-logo"" src=""/static/images/logos/header_logo_cropped.svg"" /></a>
        </div>
        <div class=""col home-link"">
            <div class=""link-alt"">
                <a href=""https://www.doi.org"">
                    <span>VISIT DOI.ORG</span>
                    <i class=""fa-solid fa-arrow-right-long hover-move-right""></i>
                </a>
            </div>
        </div>
    </div>

</header>


<main aria-role=""main"">
    <header class=""homepage-header"">
    </header>
    <div class=""homepage-content"">

        <section class=""single-top"">
            <div class=""row short""></div>
        </section>

        <div class=""page-content"">
            <article>
                <div>
                    <h2>DOI Not Found</h2>

                    

                    <h3>10/nan</h3>

                    
                    
                    
                    <p>This DOI cannot be found in the DOI System.  Possible reasons are:</p>
                    

                    <ul>
                        <li style=""padding-bottom: .5em;"">The DOI is incorrect in your source. Search for the item by name, title, or other metadata using a search engine.</li>
                        <li style=""padding-bottom: .5em;"">The DOI was copied incorrectly. Check to see that the string includes all the characters before and after the slash and no sentence punctuation marks.</li>
                        <li style=""padding-bottom: .5em;"">The DOI has not been activated yet. Please try again later, and report the problem if the error continues.</li>
                    </ul>
                    
                    
                </div>
            </article>
        </div>

        <section class=""home-infos"">
            <div class=""row"">
                <div class=""col "">
                    <h2 class=""title"">WHAT CAN I DO NEXT?</h2>
                    <ul>
                        <li>If you believe this DOI is valid, you may <strong>report this error</strong> to the responsible DOI Registration Agency using the form here.</li>
                        <li>If your organization is the steward of this DOI prefix, please make sure you have completed registration of this DOI with your Registration Agency.</li>
                        <li>You can try to search again from <a href=""https://www.doi.org"">DOI.ORG homepage</a></li>
                    </ul>
                </div>
                <div class=""col form"">
                    <h2 class=""title""><img src=""/static/images/exclamation.svg"">REPORT AN ERROR</h2>
                    <form action=""/notfound"" method=""post"" enctype=""application/x-www-form-urlencoded"" name=""notFoundForm"" onsubmit=""return submitDoiNotFound(event);"">
                        <div class=""row"">
                            <div class=""col""><label for=""missingHandle"">DOI:</label></div>
                            <div class=""col""><input id=""missingHandle"" name=""missingHandle"" value=""10/nan"" type=""text"" readonly=""readonly""></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""referringPage"">URL of Web Page Listing the DOI:</label></div>
                            <div class=""col""><input id=""referringPage"" name=""referringPage"" type=""text"" ></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""userEmailAddress"">Your Email Address:</label></div>
                            <div class=""col""><input id=""userEmailAddress"" name=""userEmailAddress"" type=""text"" /></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""><label for=""comments"">Additional Information About the Error:</label></div>
                            <div class=""col""><textarea id=""comments"" name=""comments""></textarea></div>
                        </div>
                        <div class=""row"">
                            <div class=""col""></div>
                            <div class=""col""><input class=""submit"" type=""submit"" value=""Submit Error Report""></div>
                        </div>
                        <div class=""row"">
                            <p id=""invalidDoi"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The DOI entered is not a valid DOI: it should start with 10 followed by a dot, and contain a slash with no preceding whitespace.</p>
                            <p id=""invalidEmail"" style=""display: none; background:#F5B7B1; border-radius: 5px;"">The email address entered is invalid.</p>
                            <p id=""fallback"" style=""display: none;"">Please <a href=""mailto:doi-help@doi.org?subject=DOI%20Not%20Found"">contact us</a> if you wish to report this anyway.</p>
                        </div>
                    </form>
                </div>
            </div>

        </section>
    </div>
    
    
</main>

<footer>
    <div class=""row"">
        <div class=""col footer-left"">
            <a href=""https://www.doi.org""><img class=""footer-logo"" src=""/static/images/logos/footer_logo_cropped.svg"" /></a>
        </div>
        <div class=""col footer-right"">
            <div class=""row more-info-heading"">
                <div class=""col"">
                    <h2>More information on DOI resolution:</h2>
                </div>
            </div>
            <div class=""row"">
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/factsheets/doi-resolution-documentation"">DOI Resolution Factsheet</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/the-identifier/resources/handbook"">The DOI Handbook</a></li>
                    </ul>
                </div>
                <div class=""col"">
                    <ul>
                        <li><a href=""https://www.doi.org/privacy-policy/"">Privacy Policy</a></li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <div class=""row"">
        <div class=""col copyright"">
            <p>Copyright © 2023 DOI Foundation. <i class=""fa-brands fa-fw fa-creative-commons""></i><i class=""fa-brands fa-fw fa-creative-commons-by""></i> The content of this site is licensed under a <a href=""https://creativecommons.org/licenses/by/4.0/"" title=""Creative Commons"" target=""_blank"">Creative Commons Attribution 4.0 International License</a>.</p><p>DOI&reg;, DOI.ORG&reg;, and shortDOI&reg; are trademarks of the DOI Foundation.</p>
        </div>
        <div class=""col socials"">
            <ul class=""socials-footer"">

                <li><a href=""https://twitter.com/DOI_Foundation""><i class=""fa-brands fa-fw fa-twitter""></i></a></li>

                <li><a href=""https://www.linkedin.com/company/doi-foundation-inc/""><i class=""fa-brands fa-fw fa-linkedin""></i></a></li>

                <li><a href=""mailto:info@doi.org""><i class=""fa-solid fa-fw fa-envelope""></i></a></li>

            </ul>
        </div>
    </div>
</footer>

<script type=""text/javascript"">
    function submitDoiNotFound(event) {
        try {
            document.getElementById(""invalidEmail"").style.display = ""none"";
            document.getElementById(""invalidDoi"").style.display = ""none"";
            document.getElementById(""fallback"").style.display = ""none"";

            const missingHandle = document.getElementById('missingHandle').value.trim();
            const userEmailAddress = document.getElementById('userEmailAddress').value.trim();

            if (!validateDoi(missingHandle)) {
                event.preventDefault();
                document.getElementById(""invalidDoi"").style.display = ""block"";
                document.getElementById(""fallback"").style.display = ""block"";
                return false;
            }
            if (!validateEmail(userEmailAddress)) {
                event.preventDefault();
                document.getElementById(""invalidEmail"").style.display = ""block"";
                return false;
            }
        } catch (error) {
            // ignore
        }
    }

    function validateEmail(email) {
        const regEx = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return regEx.test(email);
    }

    function validateDoi(doi) {
        const regEx = /^10(?:\.[^\s\/]+)?\//;
        return regEx.test(doi);
    }
</script>

</body>
</html>
",,,web_of_science,2023
1511,Calibration-Tuning: Teaching Large Language Models to Know What They Don{'}t Know,"@inproceedings{kapoor-etal-2024-calibration,
    title = {""Calibration-Tuning: Teaching Large Language Models to Know What They Don{'}t Know""},
    editor = {V{\'a}zquez, Ra{\'u}l  and},
    month = {mar},
    year = {""2024""},
    address = {""St Julians, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.uncertainlp-1.1""},
    author = {""Kapoor, Sanyam  and},
    booktitle = {""Proceedings of the 1st Workshop on Uncertainty-Aware NLP (UncertaiNLP 2024)""},
    pages = {""1--14""},
    abstract = {""Large language models are increasingly deployed for high-stakes decision making, for example in financial and medical applications. In such applications, it is imperative that we be able to estimate our confidence in the answers output by a language model in order to assess risks. Although we can easily compute the probability assigned by a language model to the sequence of tokens that make up an answer, we cannot easily compute the probability of the answer itself, which could be phrased in numerous ways.While other works have engineered ways of assigning such probabilities to LLM outputs, a key problem remains: existing language models are poorly calibrated, often confident when they are wrong or unsure when they are correct. In this work, we devise a protocol called *calibration tuning* for finetuning LLMs to output calibrated probabilities. Calibration-tuned models demonstrate superior calibration performance compared to existing language models on a variety of question-answering tasks, including open-ended generation, without affecting accuracy. We further show that this ability transfers to new domains outside of the calibration-tuning train set.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.uncertainlp-1.1,,acl,2024
1512,Cross-Task Defense: Instruction-Tuning {LLM}s for Content Safety,"@inproceedings{fu-etal-2024-cross,
    title = {""Cross-Task Defense: Instruction-Tuning {LLM}s for Content Safety""},
    editor = {""Chang, Kai-Wei  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.trustnlp-1.9""},
    author = {""Fu, Yu  and},
    booktitle = {""Proceedings of the 4th Workshop on Trustworthy Natural Language Processing (TrustNLP 2024)""},
    pages = {""85--93""},
    abstract = {""Recent studies reveal that Large Language Models (LLMs) face challenges in balancing safety with utility, particularly when processing long texts for NLP tasks like summarization and translation. Despite defenses against malicious short questions, the ability of LLMs to safely handle dangerous long content, such as manuals teaching illicit activities, remains unclear. Our work aims to develop robust defenses for LLMs in processing malicious documents alongside benign NLP task queries. We introduce a defense dataset comprised of safety-related examples and propose single-task and mixed-task losses for instruction tuning. Our empirical results demonstrate that LLMs can significantly enhance their capacity to safely manage dangerous content with appropriate instruction tuning. Additionally, strengthening the defenses of tasks most susceptible to misuse is effective in protecting LLMs against processing harmful information. We also observe that trade-offs between utility and safety exist in defense strategies, where Llama2, utilizing our proposed approach, displays a significantly better balance compared to Llama1.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.trustnlp-1.9,,acl,2024
1513,"{B}ad{R}ock at {S}em{E}val-2024 Task 8: {D}istil{BERT} to Detect Multigenerator, Multidomain and Multilingual Black-Box Machine-Generated Text","@inproceedings{siino-2024-badrock,
    title = {""{B}ad{R}ock at {S}em{E}val-2024 Task 8: {D}istil{BERT} to Detect Multigenerator, Multidomain and Multilingual Black-Box Machine-Generated Text""},
    editor = {Ojha, Atul Kr.  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.semeval-1.37""},
    author = {""Siino, Marco""},
    booktitle = {""Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)""},
    pages = {""239--245""},
    abstract = {""The rise of Large Language Models (LLMs) has brought about a notable shift, rendering them increasingly ubiquitous and readily accessible. This accessibility has precipitated a surge in machine-generated content across diverse platforms encompassing news outlets, social media platforms, question-answering forums, educational platforms, and even academic domains. Recent iterations of LLMs, exemplified by entities like ChatGPT and GPT-4, exhibit a remarkable ability to produce coherent and contextually relevant responses across a broad spectrum of user inquiries. The fluidity and sophistication of these generated texts position LLMs as compelling candidates for substituting human labor in numerous applications. Nevertheless, this proliferation of machine-generated content has raised apprehensions regarding potential misuse, including the dissemination of misinformation and disruption of educational ecosystems. Given that humans marginally outperform random chance in discerning between machine-generated and human-authored text, there arises a pressing imperative to develop automated systems capable of accurately distinguishing machine-generated text. This pursuit is driven by the overarching objective of curbing the potential misuse of machine-generated content. Our manuscript delineates the approach we adopted for participation in this competition. Specifically, we detail the use of a DistilBERT model for classifying each sample in the test set provided. Our submission is able to reach an accuracy equal to 0.754 in place of the worst result obtained at the competition that is equal to 0.231.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.semeval-1.37,,acl,2024
1514,"Team Innovative at {S}em{E}val-2024 Task 8: Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text Detection","@inproceedings{sharma-mansuri-2024-team,
    title = {""Team Innovative at {S}em{E}val-2024 Task 8: Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text Detection""},
    editor = {Ojha, Atul Kr.  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.semeval-1.171""},
    author = {""Sharma, Surbhi  and},
    booktitle = {""Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)""},
    pages = {""1172--1176""},
    abstract = {""With the widespread adoption of large language models (LLMs), such as ChatGPT and GPT-4, in various domains, concerns regarding their potential misuse, including spreading misinformation and disrupting education, have escalated. The need to discern between human-generated and machine-generated text has become increasingly crucial. This paper addresses the challenge of automatic text classification with a focus on distinguishing between human-written and machine-generated text. Leveraging the robust capabilities of the RoBERTa model, we propose an approach for text classification, termed as RoBERTa hybrid, which involves fine-tuning the pre-trained Roberta model coupled with additional dense layers and softmax activation for authorship attribution. In this paper, we present an approach that leverages Stylometric features, hybrid features, and the output probabilities of a fine-tuned RoBERTa model. Our method achieves a test accuracy of 73{\%} and a validation accuracy of 89{\%}, demonstrating promising advancements in the field of machine-generated text detection. These results mark significant progress in the domain of machine-generated text detection, as evidenced by our 74th position on the leaderboard for Subtask-A of SemEval-2024 Task 8.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.semeval-1.171,,acl,2024
1515,Mast Kalandar at {S}em{E}val-2024 Task 8: On the Trail of Textual Origins: {R}o{BERT}a-{B}i{LSTM} Approach to Detect {AI}-Generated Text,"@inproceedings{bafna-etal-2024-mast,
    title = {""Mast Kalandar at {S}em{E}val-2024 Task 8: On the Trail of Textual Origins: {R}o{BERT}a-{B}i{LSTM} Approach to Detect {AI}-Generated Text""},
    editor = {Ojha, Atul Kr.  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.semeval-1.231""},
    author = {""Bafna, Jainit  and},
    booktitle = {""Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)""},
    pages = {""1627--1633""},
    abstract = {""Large Language Models (LLMs) have showcased impressive abilities in generating fluent responses to diverse user queries. However, concerns regarding the potential misuse ofsuch texts in journalism, educational, and academic contexts have surfaced. SemEval 2024introduces the task of Multigenerator, Multidomain, and Multilingual Black-Box MachineGenerated Text Detection, aiming to developautomated systems for identifying machinegenerated text and detecting potential misuse. In this paper, we i) propose a RoBERTaBiLSTM based classifier designed to classifytext into two categories: AI-generated or human ii) conduct a comparative study of ourmodel with baseline approaches to evaluate itseffectiveness. This paper contributes to the advancement of automatic text detection systemsin addressing the challenges posed by machinegenerated text misuse. Our architecture ranked46th on the official leaderboard with an accuracy of 80.83 among 125.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.semeval-1.231,,acl,2024
1516,{G}roningen Team {F} at {S}em{E}val-2024 Task 8: Detecting Machine-Generated Text using Feature-Based Machine Learning Models,"@inproceedings{donker-etal-2024-groningen,
    title = {""{G}roningen Team {F} at {S}em{E}val-2024 Task 8: Detecting Machine-Generated Text using Feature-Based Machine Learning Models""},
    editor = {Ojha, Atul Kr.  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.semeval-1.268""},
    author = {Donker, Rina  and},
    booktitle = {""Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)""},
    pages = {""1919--1925""},
    abstract = {""Large language models (LLMs) have shown remarkable capability of creating fluent responses to a wide variety of user queries. However, this also comes with concerns regarding the spread of misinformation and potential misuse within educational context. In this paper we describe our contribution to SemEval-2024 Task 8 (Wang et al., 2024), a shared task created around detecting machine-generated text. We aim to create several feature-based models that can detect whether a text is machine-generated or human-written. In the end, we obtained an accuracy of 0.74 on the binary human-written vs. machine-generated text classification task (Subtask A monolingual) and an accuracy of 0.61 on the multi-way machine-generated text-classification task (Subtask B). For future work, more features and models could be implemented.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.semeval-1.268,,acl,2024
1517,Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes,"@inproceedings{wang-etal-2024-bridging,
    title = {""Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.120""},
    author = {""Wang, Rose  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""2174--2199""},
    abstract = {""Scaling high-quality tutoring remains a major challenge in education. Due to growing demand, many platforms employ novice tutors who, unlike experienced educators, struggle to address student mistakes and thus fail to seize prime learning opportunities. Our work explores the potential of large language models (LLMs) to close the novice-expert knowledge gap in remediating math mistakes. We contribute Bridge, a method that uses cognitive task analysis to translate an expert{'}s latent thought process into a decision-making model for remediation. This involves an expert identifying (A) the student{'}s error, (B) a remediation strategy, and (C) their intention before generating a response. We construct a dataset of 700 real tutoring conversations, annotated by experts with their decisions. We evaluate state-of-the-art LLMs on our dataset and find that the expert{'}s decision-making model is critical for LLMs to close the gap: responses from GPT4 with expert decisions (e.g., {``}simplify the problem{''}) are +76{\%} more preferred than without. Additionally, context-sensitive decisions are critical to closing pedagogical gaps: random decisions decrease GPT4{'}s response quality by -97{\%} than expert decisions. Our work shows the potential of embedding expert thought processes in LLM generations to enhance their capability to bridge novice-expert knowledge gaps. Our dataset and code can be found at: https://github.com/rosewang2008/bridge.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.naacl-long.120,,acl,2024
1518,Towards Improved Multi-Source Attribution for Long-Form Answer Generation,"@inproceedings{patel-etal-2024-towards,
    title = {""Towards Improved Multi-Source Attribution for Long-Form Answer Generation""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.216""},
    author = {""Patel, Nilay  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""3906--3919""},
    abstract = {""Teaching large language models (LLMs) to generate text with attribution to evidence sources can reduce hallucinations, improve verifiability in question answering systems (QA), and increase reliability of retrieval augmented LLMs. Despite gaining increasing popularity for usage in QA systems and search engines, current LLMs struggle with attribution for long-form responses which require reasoning over multiple evidence sources. To address this, in this paper we aim to improve the attribution capability of LLMs for long-form answer generation to multiple sources, with multiple citations per sentence. However, data for training multi-source attributable QA systems is difficult and expensive to annotate, and therefore scarce. To overcome this challenge, we transform existing QA datasets for this task (MultiAttr), and empirically demonstrate, on a wide range of attribution benchmark datasets, that fine-tuning on MultiAttr provides significant improvements over training only on the target QA domain. Lastly, to fill a gap in existing benchmarks, we present a multi-source attribution dataset containing multi-paragraph answers, PolitiICite, based on PolitiFact articles that discuss events closely related to implementation statuses of election promises.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.naacl-long.216,,acl,2024
1519,"In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax","@inproceedings{mueller-etal-2024-context,
    title = {""In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.267""},
    author = {""Mueller, Aaron  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""4761--4779""},
    abstract = {""In-context learning (ICL) is now a common method for teaching large language models (LLMs) new tasks: given labeled examples in the input context, the LLM learns to perform the task without weight updates. Do models guided via ICL infer the underlying structure of the task defined by the context, or do they rely on superficial heuristics that only generalize to identically distributed examples? We address this question using transformations tasks and an NLI task that assess sensitivity to syntax{---}a requirement for robust language understanding. We further investigate whether out-of-distribution generalization can be improved via chain-of-thought prompting, where the model is provided with a sequence of intermediate computation steps that illustrate how the task ought to be performed. In experiments with models from the GPT, PaLM, and Llama 2 families, we find large variance across LMs. The variance is explained more by the composition of the pre-training corpus and supervision methods than by model size; in particular, models pre-trained on code generalize better, and benefit more from chain-of-thought prompting.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.naacl-long.267,,acl,2024
1520,Teaching Language Models to Self-Improve through Interactive Demonstrations,"@inproceedings{yu-etal-2024-teaching,
    title = {""Teaching Language Models to Self-Improve through Interactive Demonstrations""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.287""},
    author = {""Yu, Xiao  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""5127--5149""},
    abstract = {""The self-improving ability of large language models (LLMs), enabled by prompting them to analyze and revise their own outputs, has garnered significant interest in recent research. However, this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones. To reduce this gap, we introduce TriPosT, a training algorithm that endows smaller models with such self-improvement ability, and show that our approach can improve LLaMA-7B{'}s performance on math and reasoning tasks by up to 7.13{\%}. In contrast to prior work, we achieve this by using the smaller model to interact with LLMs to collect feedback and improvements on *its own generations*. We then replay this experience to train the small model. Our experiments on four math and reasoning datasets show that the interactive experience of learning from and correcting its *own* mistakes is crucial for small models to improve their performance.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.naacl-long.287,,acl,2024
1521,{MT}-{PATCHER}: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation,"@inproceedings{li-etal-2024-mt,
    title = {""{MT}-{PATCHER}: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.358""},
    author = {""Li, Jiahuan  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""6445--6459""},
    abstract = {""Large Language Models (LLM) have demonstrated their strong ability in the field of machine translation, yet they suffer from high computational cost and latency. Therefore, transferring translation knowledge from giant LLMs to medium-sized machine translation models is a promising research direction. However, traditional knowledge distillation methods ignore the capability of student and teacher models, therefore repeatedly teaching student models on the knowledge they have learned, and failing to extend to novel contexts and knowledge. In this paper, we propose a framework called MT-Patcher, which transfers knowledge from LLMs to existing MT models in a selective, comprehensive and proactive manner. Considering the current translation ability of student MT models, we only identify and correct their translation errors, instead of distilling the whole translation from the teacher. Leveraging the strong language abilities of LLMs, we instruct LLM teachers to synthesize diverse contexts and anticipate more potential errors for the student. Experiment results on translating both specific language phenomena and general MT benchmarks demonstrate that finetuning the MT model on about 10{\%} examples can achieve comparable results to the traditional knowledge distillation method, and synthesized potential errors and diverse contexts further improve MT performances on unseen contexts and words.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.naacl-long.358,,acl,2024
1522,Analysis of State-Level Legislative Process in Enhanced Linguistic and Nationwide Network Contexts,"@inproceedings{davoodi-goldwasser-2024-analysis,
    title = {""Analysis of State-Level Legislative Process in Enhanced Linguistic and Nationwide Network Contexts""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.411""},
    author = {""Davoodi, Maryam  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""7404--7422""},
    abstract = {""State bills have a significant impact on various aspects of society, including health, education, and the economy. Consequently, it is crucial to conduct systematic research on state bills before and after they are enacted to evaluate their benefits and drawbacks, thereby guiding future decision-making. In this work, we developed the first state-level deep learning framework that (1) handles the complex and inconsistent language of policies across US states using generative large language models and (2) decodes legislators{'} behavior and implications of state policies by establishing a shared nationwide network, enriched with diverse contexts, such as information on interest groups influencing public policy and legislators{'} courage test results, which reflect their political positions.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.naacl-long.411,,acl,2024
1523,Uncertainty Estimation in Large Language Models to Support Biodiversity Conservation,"@inproceedings{mora-cross-calderon-ramirez-2024-uncertainty,
    title = {""Uncertainty Estimation in Large Language Models to Support Biodiversity Conservation""},
    editor = {""Yang, Yi  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-industry.31""},
    author = {""Mora-Cross, Maria  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)""},
    pages = {""368--378""},
    abstract = {""Large Language Models (LLM) provide significant value in question answering (QA) scenarios and have practical application in complex decision-making contexts, such as biodiversity conservation. However, despite substantial performance improvements, they may still produce inaccurate outcomes. Consequently, incorporating uncertainty quantification alongside predictions is essential for mitigating the potential risks associated with their use. This study introduces an exploratory analysis of the application of Monte Carlo Dropout (MCD) and Expected Calibration Error (ECE) to assess the uncertainty of generative language models. To that end, we analyzed two publicly available language models (Falcon-7B and DistilGPT-2). Our findings suggest the viability of employing ECE as a metric to estimate uncertainty in generative LLM. The findings from this research contribute to a broader project aiming at facilitating free and open access to standardized and integrated data and services about Costa Rica{'}s biodiversity to support the development of science, education, and biodiversity conservation.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.naacl-industry.31,,acl,2024
1524,Agenda-Driven Question Generation: A Case Study in the Courtroom Domain,"@inproceedings{fung-etal-2024-agenda-driven,
    title = {""Agenda-Driven Question Generation: A Case Study in the Courtroom Domain""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.49""},
    author = {""Fung, Yi  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""572--583""},
    abstract = {""This paper introduces a novel problem of automated question generation for courtroom examinations, CourtQG. While question generation has been studied in domains such as educational testing and product description, CourtQG poses several unique challenges owing to its non-cooperative and agenda-driven nature. Specifically, not only the generated questions need to be relevant to the case and underlying context, they also have to achieve certain objectives such as challenging the opponent{'}s arguments and/or revealing potential inconsistencies in their answers. We propose to leverage large language models (LLM) for CourtQG by fine-tuning them on two auxiliary tasks, agenda explanation (i.e., uncovering the underlying intents) and question type prediction. We additionally propose cold-start generation of questions from background documents without relying on examination history. We construct a dataset to evaluate our proposed method and show that it generates better questions according to standard metrics when compared to several baselines.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.49,,acl,2024
1525,Argument Quality Assessment in the Age of Instruction-Following Large Language Models,"@inproceedings{wachsmuth-etal-2024-argument-quality,
    title = {""Argument Quality Assessment in the Age of Instruction-Following Large Language Models""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.135""},
    author = {""Wachsmuth, Henning  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""1519--1538""},
    abstract = {""The computational treatment of arguments on controversial issues has been subject to extensive NLP research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. A critical task in any such application is the assessment of an argument{'}s quality - but it is also particularly challenging. In this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. We argue that the capabilities of instruction-following large language models (LLMs) to leverage knowledge across contexts enable a much more reliable assessment. Rather than just fine-tuning LLMs towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to solve argument-related problems. We discuss the real-world opportunities and ethical issues emerging thereby.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.135,,acl,2024
1526,Assessing Online Writing Feedback Resources: Generative {AI} vs. Good Samaritans,"@inproceedings{behzad-etal-2024-assessing-online,
    title = {""Assessing Online Writing Feedback Resources: Generative {AI} vs. Good Samaritans""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.144""},
    author = {""Behzad, Shabnam  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""1638--1644""},
    abstract = {""Providing constructive feedback on student essays is a critical factor in improving educational results; however, it presents notable difficulties and may demand substantial time investments, especially when aiming to deliver individualized and informative guidance. This study undertakes a comparative analysis of two readily available online resources for students seeking to hone their skills in essay writing for English proficiency tests: 1) essayforum.com, a widely used platform where students can submit their essays and receive feedback from volunteer educators at no cost, and 2) Large Language Models (LLMs) such as ChatGPT. By contrasting the feedback obtained from these two resources, we posit that they can mutually reinforce each other and are more helpful if employed in conjunction when seeking no-cost online assistance. The findings of this research shed light on the challenges of providing personalized feedback and highlight the potential of AI in advancing the field of automated essay evaluation.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.144,,acl,2024
1527,Clue-Instruct: Text-Based Clue Generation for Educational Crossword Puzzles,"@inproceedings{zugarini-etal-2024-clue-instruct,
    title = {""Clue-Instruct: Text-Based Clue Generation for Educational Crossword Puzzles""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.297""},
    author = {""Zugarini, Andrea  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""3347--3356""},
    abstract = {""Crossword puzzles are popular linguistic games often used as tools to engage students in learning. Educational crosswords are characterized by less cryptic and more factual clues that distinguish them from traditional crossword puzzles. Despite there exist several publicly available clue-answer pair databases for traditional crosswords, educational clue-answer pairs datasets are missing. In this article, we propose a methodology to build educational clue generation datasets that can be used to instruct Large Language Models (LLMs). By gathering from Wikipedia pages informative content associated with relevant keywords, we use Large Language Models to automatically generate pedagogical clues related to the given input keyword and its context. With such an approach, we created clue-instruct, a dataset containing 44,075 unique examples with text-keyword pairs associated with three distinct crossword clues. We used clue-instruct to instruct different LLMs to generate educational clues from a given input content and keyword. Both human and automatic evaluations confirmed the quality of the generated clues, thus validating the effectiveness of our approach.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.297,,acl,2024
1528,Educational Dialogue Systems for Visually Impaired Students: Introducing a Task-Oriented User-Agent Corpus,"@inproceedings{di-nuovo-etal-2024-educational-dialogue,
    title = {""Educational Dialogue Systems for Visually Impaired Students: Introducing a Task-Oriented User-Agent Corpus""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.489""},
    author = {""Di Nuovo, Elisa  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""5507--5519""},
    abstract = {""This paper describes a corpus consisting of real-world dialogues in English between users and a task-oriented conversational agent, with interactions revolving around the description of finite state automata. The creation of this corpus is part of a larger research project aimed at developing tools for an easier access to educational content, especially in STEM fields, for users with visual impairments. The development of this corpus was precisely motivated by the aim of providing a useful resource to support the design of such tools. The core feature of this corpus is that its creation involved both sighted and visually impaired participants, thus allowing for a greater diversity of perspectives and giving the opportunity to identify possible differences in the way the two groups of participants interacted with the agent. The paper introduces this corpus, giving an account of the process that led to its creation, i.e. the methodology followed to obtain the data, the annotation scheme adopted, and the analysis of the results. Finally, the paper reports the results of a classification experiment on the annotated corpus, and an additional experiment to assess the annotation capabilities of three large language models, in view of a further expansion of the corpus.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.489,,acl,2024
1529,Extracting Social Determinants of Health from Pediatric Patient Notes Using Large Language Models: Novel Corpus and Methods,"@inproceedings{fu-etal-2024-extracting-social,
    title = {""Extracting Social Determinants of Health from Pediatric Patient Notes Using Large Language Models: Novel Corpus and Methods""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.618""},
    author = {Fu, Yujuan  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""7045--7056""},
    abstract = {""Social determinants of health (SDoH) play a critical role in shaping health outcomes, particularly in pediatric populations where interventions can have long-term implications. SDoH are frequently studied in the Electronic Health Record (EHR), which provides a rich repository for diverse patient data. In this work, we present a novel annotated corpus, the Pediatric Social History Annotation Corpus (PedSHAC), and evaluate the automatic extraction of detailed SDoH representations using fine-tuned and in-context learning methods with Large Language Models (LLMs). PedSHAC comprises annotated social history sections from 1,260 clinical notes obtained from pediatric patients within the University of Washington (UW) hospital system. Employing an event-based annotation scheme, PedSHAC captures ten distinct health determinants to encompass living and economic stability, prior trauma, education access, substance use history, and mental health with an overall annotator agreement of 81.9 F1. Our proposed fine-tuning LLM-based extractors achieve high performance at 78.4 F1 for event arguments. In-context learning approaches with GPT-4 demonstrate promise for reliable SDoH extraction with limited annotated examples, with extraction performance at 82.3 F1 for event triggers.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.618,,acl,2024
1530,Finding Educationally Supportive Contexts for Vocabulary Learning with Attention-Based Models,"@inproceedings{nam-etal-2024-finding-educationally,
    title = {""Finding Educationally Supportive Contexts for Vocabulary Learning with Attention-Based Models""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.640""},
    author = {""Nam, Sungjin  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""7286--7295""},
    abstract = {""When learning new vocabulary, both humans and machines acquire critical information about the meaning of an unfamiliar word through contextual information in a sentence or passage. However, not all contexts are equally helpful for learning an unfamiliar {`}target{'} word. Some contexts provide a rich set of semantic clues to the target word{'}s meaning, while others are less supportive. We explore the task of finding educationally supportive contexts with respect to a given target word for vocabulary learning scenarios, particularly for improving student literacy skills. Because of their inherent context-based nature, attention-based deep learning methods provide an ideal starting point. We evaluate attention-based approaches for predicting the amount of educational support from contexts, ranging from a simple custom model using pre-trained embeddings with an additional attention layer, to a commercial Large Language Model (LLM). Using an existing major benchmark dataset for educational context support prediction, we found that a sophisticated but generic LLM had poor performance, while a simpler model using a custom attention-based approach achieved the best-known performance to date on this dataset.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.640,,acl,2024
1531,Incorporating Word-level Phonemic Decoding into Readability Assessment,"@inproceedings{pinney-etal-2024-incorporating-word,
    title = {""Incorporating Word-level Phonemic Decoding into Readability Assessment""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.788""},
    author = {""Pinney, Christine  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""8998--9009""},
    abstract = {""Current approaches in automatic readability assessment have found success with the use of large language models and transformer architectures. These techniques lead to accuracy improvement, but they do not offer the interpretability that is uniquely required by the audience most often employing readability assessment tools: teachers and educators. Recent work that employs more traditional machine learning methods has highlighted the linguistic importance of considering semantic and syntactic characteristics of text in readability assessment by utilizing handcrafted feature sets. Research in Education suggests that, in addition to semantics and syntax, phonetic and orthographic instruction are necessary for children to progress through the stages of reading and spelling development; children must first learn to decode the letters and symbols on a page to recognize words and phonemes and their connection to speech sounds. Here, we incorporate this word-level phonemic decoding process into readability assessment by crafting a phonetically-based feature set for grade-level classification for English. Our resulting feature set shows comparable performance to much larger, semantically- and syntactically-based feature sets, supporting the linguistic value of orthographic and phonetic considerations in readability assessment.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.788,,acl,2024
1532,{LHMKE}: A Large-scale Holistic Multi-subject Knowledge Evaluation Benchmark for {C}hinese Large Language Models,"@inproceedings{liu-etal-2024-lhmke-large,
    title = {""{LHMKE}: A Large-scale Holistic Multi-subject Knowledge Evaluation Benchmark for {C}hinese Large Language Models""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.916""},
    author = {""Liu, Chuang  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""10476--10487""},
    abstract = {""Chinese Large Language Models (LLMs) have recently demonstrated impressive capabilities across various NLP benchmarks and real-world applications. However, the existing benchmarks for comprehensively evaluating these LLMs are still insufficient, particularly in terms of measuring knowledge that LLMs capture. Current datasets collect questions from Chinese examinations across different subjects and educational levels to address this issue. Yet, these benchmarks primarily focus on objective questions such as multiple-choice questions, leading to a lack of diversity in question types. To tackle this problem, we propose LHMKE, a Large-scale, Holistic, and Multi-subject Knowledge Evaluation benchmark in this paper. LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of Chinese LLMs. It encompasses 10,465 questions across 75 tasks covering 30 subjects, ranging from primary school to professional certification exams. Notably, LHMKE includes both objective and subjective questions, offering a more holistic evaluation of the knowledge level of LLMs. We have assessed 11 Chinese LLMs under the zero-shot setting, which aligns with real examinations, and compared their performance across different subjects. We also conduct an in-depth analysis to check whether GPT-4 can automatically score subjective predictions. Our findings suggest that LHMKE is a challenging and advanced testbed for Chinese LLMs.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.916,,acl,2024
1533,Teaching Large Language Models to Translate on Low-resource Languages with Textbook Prompting,"@inproceedings{guo-etal-2024-teaching-large,
    title = {""Teaching Large Language Models to Translate on Low-resource Languages with Textbook Prompting""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.1362""},
    author = {""Guo, Ping  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""15685--15697""},
    abstract = {""Large Language Models (LLMs) have achieved impressive results in Machine Translation by simply following instructions, even without training on parallel data. However, LLMs still face challenges on low-resource languages due to the lack of pre-training data. In real-world situations, humans can become proficient in their native languages through abundant and meaningful social interactions and can also learn foreign languages effectively using well-organized textbooks. Drawing inspiration from human learning patterns, we introduce the Translate After LEarNing Textbook (TALENT) approach, which aims to enhance LLMs{'} ability to translate low-resource languages by learning from a textbook. TALENT follows a step-by-step process: (1) Creating a Textbook for low-resource languages. (2) Guiding LLMs to absorb the Textbook{'}s content for Syntax Patterns. (3) Enhancing translation by utilizing the Textbook and Syntax Patterns. We thoroughly assess TALENT{'}s performance using 112 low-resource languages from FLORES-200 with two LLMs: ChatGPT and BLOOMZ. Evaluation across three different metrics reveals that TALENT consistently enhances translation performance by 14.8{\%} compared to zero-shot baselines. Further analysis demonstrates that TALENT not only improves LLMs{'} comprehension of low-resource languages but also equips them with the knowledge needed to generate accurate and fluent sentences in these languages.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.1362,,acl,2024
1534,Would You Like to Make a Donation? A Dialogue System to Persuade You to Donate,"@inproceedings{song-wang-2024-like-make,
    title = {""Would You Like to Make a Donation? A Dialogue System to Persuade You to Donate""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.1540""},
    author = {""Song, Yuhan  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""17707--17717""},
    abstract = {""Persuasive dialogue is a type of dialogue commonly used in human daily life in scenarios such as promotion and sales. Its purpose is to influence the decision, attitude or behavior of another person through the dialogue process. Persuasive automated dialogue systems can be applied in a variety of fields such as charity, business, education, and healthcare. Regardless of their amazing abilities, Large Language Models (LLMs) such as ChatGPT still have limitations in persuasion. There is few research dedicated to persuasive dialogue in the current research of automated dialogue systems. In this paper, we introduce a persuasive automated dialogue system. In the system, a context-aware persuasion strategy selection module makes dialogue system flexibly use different persuasion strategies to persuade users; Then a natural language generation module is used to output a response. We also propose a persuasiveness prediction model to automatically evaluate the persuasiveness of generated text. Experimental results show that our dialogue system can achieve better performance on several automated evaluation metrics than baseline models.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.lrec-main.1540,,acl,2024
1535,{LLM}-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?,"@inproceedings{zhang-etal-2024-llm,
    title = {""{LLM}-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.29""},
    author = {""Zhang, Qihui  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""409--436""},
    abstract = {""With the rapid development and widespread application of Large Language Models (LLMs), the use of Machine-Generated Text (MGT) has become increasingly common, bringing with it potential risks, especially in terms of quality and integrity in fields like news, education, and science. Current research mainly focuses on purely MGT detection, without adequately addressing mixed scenarios including AI-revised Human-Written Text (HWT) or human-revised MGT. To tackle this challenge, we define mixtext, a form of mixed text involving both AI and human-generated content. Then we introduce MixSet, the first dataset dedicated to studying these mixtext scenarios. Leveraging MixSet, we executed comprehensive experiments to assess the efficacy of prevalent MGT detectors in handling mixtext situations, evaluating their performance in terms of effectiveness, robustness, and generalization. Our findings reveal that existing detectors struggle to identify mixtext, particularly in dealing with subtle modifications and style adaptability. This research underscores the urgent need for more fine-grain detectors tailored for mixtext, offering valuable insights for future research. Code and Models are available at https://github.com/Dongping-Chen/MixSet.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.findings-naacl.29,,acl,2024
1536,Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training,"@inproceedings{denisov-vu-2024-teaching,
    title = {""Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.52""},
    author = {""Denisov, Pavel  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""814--834""},
    abstract = {""Recent advancements in language modeling have led to the emergenceof Large Language Models (LLMs) capable ofvarious natural language processing tasks.Despite their success in text-based tasks, applying LLMs to the speech domainremains limited and challenging. This paper presents BLOOMZMMS, a novel modelthat integrates a multilingual LLM with a multilingual speech encoder,aiming to harness the capabilities of LLMs for speech recognition and beyond.Utilizing a multi-instructional training approach, we demonstrate the transferabilityof linguistic knowledge from the text to the speech modality.Our experiments, conducted on 1900 hours of transcribed data from 139 languages,establish that a multilingual speech representation can be effectivelylearned and aligned with a multilingual LLM. While this learned representationinitially shows limitations in task generalization, we address this issue bygenerating synthetic targets in a multi-instructional style.Our zero-shot evaluation results confirm the robustness of our approach acrossmultiple tasks, including speech translation and multilingual spoken languageunderstanding, thereby opening new avenues for applying LLMs in the speech domain.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.findings-naacl.52,,acl,2024
1537,{MIC}o: Preventative Detoxification of Large Language Models through Inhibition Control,"@inproceedings{siegelmann-etal-2024-mico,
    title = {""{MIC}o: Preventative Detoxification of Large Language Models through Inhibition Control""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.110""},
    author = {""Siegelmann, Roy  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""1696--1703""},
    abstract = {""Large Language Models (LLMs) are powerful tools which have been both dominant and commonplace in the field of Artificial Intelligence. Yet, LLMs have a tendency to devolve into toxic degeneration, wherein otherwise safe and unproblematic models begin generating toxic content. For the sake of social responsibility and inspired by the biological mechanisms of inhibition control, we introduce the paradigm of Education for Societal Norms (ESN). By collecting and labeling examples as acceptable and unacceptable (in this case toxic and non-toxic), and including a corresponding acceptable rewrite with every unacceptable example, we introduce a new mechanism for LLM detoxification. We annotate a dataset of 2,850 entries and use it to fine-tune a model, which we call a Model with Inhibition Control (MICo). Evaluating this model on toxicity detection capability, rewrite detoxification, meaning preservation, and overall toxicity reduction, we discover significant improvements over the baseline model. In our experiments we show that overall toxicity of this model is more than 60{\%} reduced, with over 75{\%} reduction in severe toxicity.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.findings-naacl.110,,acl,2024
1538,Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models,"@inproceedings{feng-etal-2024-exploring,
    title = {""Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.193""},
    author = {""Feng, Wanyong  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""3067--3082""},
    abstract = {""Multiple-choice questions (MCQs) are ubiquitous in almost all levels of education since they are easy to administer, grade, and are a reliable format in assessments and practices. One of the most important aspects of MCQs is the distractors, i.e., incorrect options that are designed to target common errors or misconceptions among real students. To date, the task of crafting high-quality distractors largely remains a labor and time-intensive process for teachers and learning content designers, which has limited scalability. In this work, we study the task of automated distractor generation in the domain of math MCQs and explore a wide variety of large language model (LLM)-based approaches, from in-context learning to fine-tuning. We conduct extensive experiments using a real-world math MCQ dataset and find that although LLMs can generate some mathematically valid distractors, they are less adept at anticipating common errors or misconceptions among real students.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.findings-naacl.193,,acl,2024
1539,Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer,"@inproceedings{kuulmets-etal-2024-teaching,
    title = {""Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.210""},
    author = {""Kuulmets, Hele-Andra  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""3309--3325""},
    abstract = {""This paper explores cost-efficient methods to adapt pretrained Large Language Models (LLMs) to new lower-resource languages, with a specific focus on Estonian. Leveraging the Llama 2 model, we investigate the impact of combining cross-lingual instruction-tuning with additional monolingual pretraining. Our results demonstrate that even a relatively small amount of additional monolingual pretraining followed by cross-lingual instruction-tuning significantly enhances results on Estonian. Furthermore, we showcase cross-lingual knowledge transfer from high-quality English instructions to Estonian, resulting in improvements in commonsense reasoning and multi-turn conversation capabilities. Our best model, named Llammas, represents the first open-source instruction-following LLM for Estonian. Additionally, we publish Alpaca-est, the first general task instruction dataset for Estonia. These contributions mark the initial progress in the direction of developing open-source LLMs for Estonian.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.findings-naacl.210,,acl,2024
1540,Teaching Probabilistic Logical Reasoning to Transformers,"@inproceedings{nafar-etal-2024-teaching,
    title = {""Teaching Probabilistic Logical Reasoning to Transformers""},
    editor = {""Graham, Yvette  and},
    month = {mar},
    year = {""2024""},
    address = {""St. Julian{'}s, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-eacl.112""},
    author = {""Nafar, Aliakbar  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EACL 2024""},
    pages = {""1615--1632""},
    abstract = {""In this paper, we evaluate the capability of transformer-based language models in making inferences over uncertain text that includes uncertain rules of reasoning. We cover both Pre-trained Language Models (PLMs) and generative Large Language Models (LLMs). Our evaluation results show that both generations of language models struggle with reasoning over uncertain text. We propose a novel end-to-end fine-tuning approach, Probabilistic Constraint Training (PCT), that utilizes probabilistic logical rules as constraints in the fine-tuning phase without relying on these rules in the inference stage. To assess the effectiveness of PCT, we utilize the related corpora and, additionally, create a new and more challenging benchmark that, unlike the previous ones, uses instance-specific rules. Our study demonstrates that PCT improves the transformer-based language model{'}s intrinsic reasoning and makes their probabilistic logical reasoning process more explicit and explainable. Furthermore, PCT equips these models to effectively handle novel situations, including higher reasoning depth, new domains, and complex probabilistic structures.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.findings-eacl.112,,acl,2024
1541,{LLM}-{GE}m: Large Language Model-Guided Prediction of People{'}s Empathy Levels towards Newspaper Article,"@inproceedings{hasan-etal-2024-llm,
    title = {""{LLM}-{GE}m: Large Language Model-Guided Prediction of People{'}s Empathy Levels towards Newspaper Article""},
    editor = {""Graham, Yvette  and},
    month = {mar},
    year = {""2024""},
    address = {""St. Julian{'}s, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-eacl.147""},
    author = {""Hasan, Md Rakibul  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EACL 2024""},
    pages = {""2215--2231""},
    abstract = {""Empathy {--} encompassing the understanding and supporting others{'} emotions and perspectives {--} strengthens various social interactions, including written communication in healthcare, education and journalism. Detecting empathy using AI models by relying on self-assessed ground truth through crowdsourcing is challenging due to the inherent noise in such annotations. To this end, we propose a novel system, named Large Language Model-Guided Empathy {\_}(LLM-GEm){\_} prediction system. It rectifies annotation errors based on our defined annotation selection threshold and makes the annotations reliable for conventional empathy prediction models, e.g., BERT-based pre-trained language models (PLMs). Previously, demographic information was often integrated numerically into empathy detection models. In contrast, our {\_}LLM-GEm{\_} leverages GPT-3.5 LLM to convert numerical data into semantically meaningful textual sequences, enabling seamless integration into PLMs. We experiment with three {\_}NewsEmpathy{\_} datasets involving people{'}s empathy levels towards newspaper articles and achieve state-of-the-art test performance using a RoBERTa-based PLM. Code and evaluations are publicly available at [https://github.com/hasan-rakibul/LLM-GEm](https://github.com/hasan-rakibul/LLM-GEm).""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.findings-eacl.147,,acl,2024
1542,"{LLM}s for Low Resource Languages in Multilingual, Multimodal and Dialectal Settings","@inproceedings{alam-etal-2024-llms,
    title = {""{LLM}s for Low Resource Languages in Multilingual, Multimodal and Dialectal Settings""},
    editor = {""Mesgar, Mohsen  and},
    month = {mar},
    year = {""2024""},
    address = {""St. Julian{'}s, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.eacl-tutorials.5""},
    author = {""Alam, Firoj  and},
    booktitle = {""Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts""},
    pages = {""27--33""},
    abstract = {""The recent breakthroughs in Artificial Intelligence (AI) can be attributed to the remarkable performance of Large Language Models (LLMs) across a spectrum of research areas (e.g., machine translation, question-answering, automatic speech recognition, text-to-speech generation) and application domains (e.g., business, law, healthcare, education, and psychology). The success of these LLMs largely de- pends on specific training techniques, most notably instruction tuning, RLHF, and subsequent prompting to achieve the desired output. As the development of such LLMs continues to increase in both closed and open settings, evaluation has become crucial for understanding their generalization capabilities across different tasks, modalities, languages, and dialects. This evaluation process is tightly coupled with prompting, which plays a key role in obtain- ing better outputs. There has been attempts to evaluate such models focusing on diverse tasks, languages, and dialects, which suggests that the capabilities of LLMs are still limited to medium-to-low-resource languages due to the lack of representative datasets. The tutorial offers an overview of this emerging research area. We explore the capabilities of LLMs in terms of their performance, zero- and few-shot settings, fine-tuning, instructions tuning, and close vs. open models with a special emphasis on low-resource settings. In addition to LLMs for standard NLP tasks, we will focus on speech and multimodality.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.eacl-tutorials.5,,acl,2024
1543,"M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection","@inproceedings{wang-etal-2024-m4,
    title = {""M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection""},
    editor = {""Graham, Yvette  and},
    month = {mar},
    year = {""2024""},
    address = {""St. Julian{'}s, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.eacl-long.83""},
    author = {""Wang, Yuxia  and},
    booktitle = {""Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)""},
    pages = {""1369--1407""},
    abstract = {""Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark M4, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research towards more robust approaches to this pressing societal problem. The dataset is available at https://github.com/mbzuai-nlp/M4""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.eacl-long.83,,acl,2024
1544,How Good are {M}odern {LLM}s in Generating Relevant and High-Quality Questions at Different Bloom{'}s Skill Levels for {I}ndian High School Social Science Curriculum?,"@inproceedings{scaria-etal-2024-good,
    title = {""How Good are {M}odern {LLM}s in Generating Relevant and High-Quality Questions at Different Bloom{'}s Skill Levels for {I}ndian High School Social Science Curriculum?""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.1""},
    author = {""Scaria, Nicy  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""1--10""},
    abstract = {""The creation of pedagogically effective questions is a challenge for teachers and requires significant time and meticulous planning, especially in resource-constrained economies. For example, in India, assessments for social science in high schools are characterized by rote memorization without regard to higher-order skill levels. Automated educational question generation (AEQG) using large language models (LLMs) has the potential to help teachers develop assessments at scale. However, it is important to evaluate the quality and relevance of these questions. In this study, we examine the ability of different LLMs (Falcon 40B, Llama2 70B, Palm 2, GPT 3.5, and GPT 4) to generate relevant and high-quality questions of different cognitive levels, as defined by Bloom{'}s taxonomy. We prompt each model with the same instructions and different contexts to generate 510 questions in the social science curriculum of a state educational board in India. Two human experts used a nine-item rubric to assess linguistic correctness, pedagogical relevance and quality, and adherence to Bloom{'}s skill levels. Our results showed that 91.56{\%} of the LLM-generated questions were relevant and of high quality. This suggests that LLMs can generate relevant and high-quality questions at different cognitive levels, making them useful for creating assessments for scaling education in resource-constrained economies.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.1,,acl,2024
1545,Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts,"@inproceedings{rooein-etal-2024-beyond,
    title = {""Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.5""},
    author = {Rooein, Donya  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""54--67""},
    abstract = {""Using large language models (LLMs) for educational applications like dialogue-based teaching is a hot topic. Effective teaching, however, requires teachers to adapt the difficulty of content and explanations to the education level of their students. Even the best LLMs today struggle to do this well. If we want to improve LLMs on this adaptation task, we need to be able to measure adaptation success reliably. However, current Static metrics for text difficulty, like the Flesch-Kincaid Reading Ease score, are known to be crude and brittle. We, therefore, introduce and evaluate a new set of Prompt-based metrics for text difficulty. Based on a user study, we create Prompt-based metrics as inputs for LLMs. They leverage LLM{'}s general language understanding capabilities to capture more abstract and complex features than Static metrics. Regression experiments show that adding our Prompt-based metrics significantly improves text difficulty classification over Static metrics alone. Our results demonstrate the promise of using LLMs to evaluate text adaptation to different education levels.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.5,,acl,2024
1546,Can Language Models Guess Your Identity? Analyzing Demographic Biases in {AI} Essay Scoring,"@inproceedings{kwako-ormerod-2024-language,
    title = {""Can Language Models Guess Your Identity? Analyzing Demographic Biases in {AI} Essay Scoring""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.7""},
    author = {""Kwako, Alexander  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""78--86""},
    abstract = {""Large language models (LLMs) are increasingly used for automated scoring of student essays. However, these models may perpetuate societal biases if not carefully monitored. This study analyzes potential biases in an LLM (XLNet) trained to score persuasive student essays, based on data from the PERSUADE corpus. XLNet achieved strong performance based on quadratic weighted kappa, standardized mean difference, and exact agreement with human scores. Using available metadata, we performed analyses of scoring differences across gender, race/ethnicity, English language learning status, socioeconomic status, and disability status. Automated scores exhibited small magnifications of marginal differences in human scoring, favoring female students over males and White students over Black students. To further probe potential biases, we found that separate XLNet classifiers and XLNet hidden states weakly predicted demographic membership. Overall, results reinforce the need for continued fairness analyses as use of LLMs expands in education.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.7,,acl,2024
1547,Can {GPT}-4 do {L}2 analytic assessment?,"@inproceedings{banno-etal-2024-gpt,
    title = {""Can {GPT}-4 do {L}2 analytic assessment?""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.14""},
    author = {""Banno, Stefano  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""149--164""},
    abstract = {""Automated essay scoring (AES) to evaluate second language (L2) proficiency has been a firmly established technology used in educational contexts for decades. Although holistic scoring has seen advancements in AES that match or even exceed human performance, analytic scoring still encounters issues as it inherits flaws and shortcomings from the human scoring process. The recent introduction of large language models presents new opportunities for automating the evaluation of specific aspects of L2 writing proficiency. In this paper, we perform a series of experiments using GPT-4 in a zero-shot fashion on a publicly available dataset annotated with holistic scores based on the Common European Framework of Reference and aim to extract detailed information about their underlying analytic components. We observe significant correlations between the automatically predicted analytic scores and multiple features associated with the individual proficiency components.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.14,,acl,2024
1548,Using Program Repair as a Proxy for Language Models{'} Feedback Ability in Programming Education,"@inproceedings{koutcheme-etal-2024-using,
    title = {""Using Program Repair as a Proxy for Language Models{'} Feedback Ability in Programming Education""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.15""},
    author = {""Koutcheme, Charles  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""165--181""},
    abstract = {""One of the key challenges in programming education is being able to provide high-quality feedback to learners. Such feedback often includes explanations of the issues in students{'} programs coupled with suggestions on how to fix these issues. Large language models (LLMs) have recently emerged as valuable tools that can help in this effort. In this article, we explore the relationship between the program repair ability of LLMs and their proficiency in providing natural language explanations of coding mistakes. We outline a benchmarking study that evaluates leading LLMs (including open-source ones) on program repair and explanation tasks. Our experiments study the capabilities of LLMs both on a course level and on a programming concept level, allowing us to assess whether the programming concepts practised in exercises with faulty student programs relate to the performance of the models. Our results highlight that LLMs proficient in repairing student programs tend to provide more complete and accurate natural language explanations of code issues. Overall, these results enhance our understanding of the role and capabilities of LLMs in programming education. Using program repair as a proxy for explanation evaluation opens the door for cost-effective assessment methods.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.15,,acl,2024
1549,Fairness in Automated Essay Scoring: A Comparative Analysis of Algorithms on {G}erman Learner Essays from Secondary Education,"@inproceedings{schaller-etal-2024-fairness,
    title = {""Fairness in Automated Essay Scoring: A Comparative Analysis of Algorithms on {G}erman Learner Essays from Secondary Education""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.18""},
    author = {""Schaller, Nils-Jonathan  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""210--221""},
    abstract = {""Pursuing educational equity, particularly in writing instruction, requires that all students receive fair (i.e., accurate and unbiased) assessment and feedback on their texts. Automated Essay Scoring (AES) algorithms have so far focused on optimizing the mean accuracy of their scores and paid less attention to fair scores for all subgroups, although research shows that students receive unfair scores on their essays in relation to demographic variables, which in turn are related to their writing competence. We add to the literature arguing that AES should also optimize for fairness by presenting insights on the fairness of scoring algorithms on a corpus of learner texts in the German language and introduce the novelty of examining fairness on psychological and demographic differences in addition to demographic differences. We compare shallow learning, deep learning, and large language models with full and skewed subsets of training data to investigate what is needed for fair scoring. The results show that training on a skewed subset of higher and lower cognitive ability students shows no bias but very low accuracy for students outside the training set. Our results highlight the need for specific training data on all relevant user groups, not only for demographic background variables but also for cognitive abilities as psychological student characteristics.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.18,,acl,2024
1550,Improving Automated Distractor Generation for Math Multiple-choice Questions with Overgenerate-and-rank,"@inproceedings{scarlatos-etal-2024-improving,
    title = {""Improving Automated Distractor Generation for Math Multiple-choice Questions with Overgenerate-and-rank""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.19""},
    author = {""Scarlatos, Alexander  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""222--231""},
    abstract = {""Multiple-choice questions (MCQs) are commonly used across all levels of math education since they can be deployed and graded at a large scale. A critical component of MCQs is the distractors, i.e., incorrect answers crafted to reflect student errors or misconceptions. Automatically generating them in math MCQs, e.g., with large language models, has been challenging. In this work, we propose a novel method to enhance the quality of generated distractors through overgenerate-and-rank, training a ranking model to predict how likely distractors are to be selected by real students. Experimental results on a real-world dataset and human evaluation with math teachers show that our ranking model increases alignment with human-authored distractors, although human-authored ones are still preferred over generated ones.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.19,,acl,2024
1551,Towards Fine-Grained Pedagogical Control over {E}nglish Grammar Complexity in Educational Text Generation,"@inproceedings{glandorf-meurers-2024-towards,
    title = {""Towards Fine-Grained Pedagogical Control over {E}nglish Grammar Complexity in Educational Text Generation""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.24""},
    author = {""Glandorf, Dominik  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""299--308""},
    abstract = {""Teaching foreign languages and fostering language awareness in subject matter teaching requires a profound knowledge of grammar structures. Yet, while Large Language Models can act as tutors, it is unclear how effectively they can control grammar in generated text and adapt to learner needs. In this study, we investigate the ability of these models to exemplify pedagogically relevant grammar patterns, detect instances of grammar in a given text, and constrain text generation to grammar characteristic of a proficiency level. Concretely, we (1) evaluate the ability of GPT3.5 and GPT4 to generate example sentences for the standard English Grammar Profile CEFR taxonomy using few-shot in-context learning, (2) train BERT-based detectors with these generated examples of grammatical patterns, and (3) control the grammatical complexity of text generated by the open Mistral model by ranking sentence candidates with these detectors. We show that the grammar pattern instantiation quality is accurate but too homogeneous, and our classifiers successfully detect these patterns. A GPT-generated dataset of almost 1 million positive and negative examples for the English Grammar Profile is released with this work. With our method, Mistral{'}s output significantly increases the number of characteristic grammar constructions on the desired level, outperforming GPT4. This showcases how language domain knowledge can enhance Large Language Models for specific education needs, facilitating their effective use for intelligent tutor development and AI-generated materials. Code, models, and data are available at https://github.com/dominikglandorf/LLM-grammar.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.24,,acl,2024
1552,Large Language Model-based Pipeline for Item Difficulty and Response Time Estimation for Educational Assessments,"@inproceedings{veeramani-etal-2024-large,
    title = {""Large Language Model-based Pipeline for Item Difficulty and Response Time Estimation for Educational Assessments""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.49""},
    author = {""Veeramani, Hariram  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""561--566""},
    abstract = {""This work presents a novel framework for the automated prediction of item difficulty and response time within educational assessments. Utilizing data from the BEA 2024 Shared Task, we integrate Named Entity Recognition, Semantic Role Labeling, and linguistic features to prompt a Large Language Model (LLM). Our best approach achieves an RMSE of 0.308 for item difficulty and 27.474 for response time prediction, improving on the provided baseline. The framework{'}s adaptability is demonstrated on audio recordings of 3rd-8th graders from the Atlanta, Georgia area responding to the Test of Narrative Language. These results highlight the framework{'}s potential to enhance test development efficiency.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.bea-1.49,,acl,2024
1553,The unreasonable effectiveness of large language models for low-resource clause-level morphology: In-context generalization or prior exposure?,"@inproceedings{haley-2024-unreasonable,
    title = {""The unreasonable effectiveness of large language models for low-resource clause-level morphology: In-context generalization or prior exposure?""},
    editor = {""Mager, Manuel  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.americasnlp-1.20""},
    author = {""Haley, Coleman""},
    booktitle = {""Proceedings of the 4th Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP 2024)""},
    pages = {""174--178""},
    abstract = {""This paper describes the submission of Team {``}Giving it a Shot{''} to the AmericasNLP 2024 Shared Task on Creation of Educational Materials for Indigenous Languages. We use a simple few-shot prompting approach with several state of the art large language models, achieving competitive performance on the shared task, with our best system placing third overall. We perform a preliminary analysis to determine to what degree the performance of our model is due to prior exposure to the task languages, finding that generally our performance is better explained as being derived from in-context learning capabilities.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.americasnlp-1.20,,acl,2024
1554,A Comparison of Fine-Tuning and In-Context Learning for Clause-Level Morphosyntactic Alternation,"@inproceedings{su-etal-2024-comparison,
    title = {""A Comparison of Fine-Tuning and In-Context Learning for Clause-Level Morphosyntactic Alternation""},
    editor = {""Mager, Manuel  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.americasnlp-1.21""},
    author = {""Su, Jim  and},
    booktitle = {""Proceedings of the 4th Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP 2024)""},
    pages = {""179--187""},
    abstract = {""This paper presents our submission to the AmericasNLP 2024 Shared Task on the Creation of Educational Materials for Indigenous Languages. We frame this task as one of morphological inflection generation, treating each sentence as a single word. We investigate and compare two distinct approaches: fine-tuning neural encoder-decoder models such as NLLB- 200, and in-context learning with proprietary large language models (LLMs). Our findings demonstrate that for this task, no one approach is perfect. Anthropic{'}s Claude 3 Opus, when supplied with grammatical description entries, achieves the highest performance on Bribri among the evaluated models. This outcome corroborates and extends previous research exploring the efficacy of in-context learning in low- resource settings. For Maya, fine-tuning NLLB- 200-3.3B using StemCorrupt augmented data yielded the best performance.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.americasnlp-1.21,,acl,2024
1555,Applying Linguistic Expertise to {LLM}s for Educational Material Development in Indigenous Languages,"@inproceedings{vasselli-etal-2024-applying,
    title = {""Applying Linguistic Expertise to {LLM}s for Educational Material Development in Indigenous Languages""},
    editor = {""Mager, Manuel  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.americasnlp-1.24""},
    author = {""Vasselli, Justin  and},
    booktitle = {""Proceedings of the 4th Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP 2024)""},
    pages = {""201--208""},
    abstract = {""This paper presents our approach to the AmericasNLP 2024 Shared Task 2 as the JAJ (/dʒ{\ae}z/) team. The task aimed at creating educational materials for indigenous languages, and we focused on Maya and Bribri. Given the unique linguistic features and challenges of these languages, and the limited size of the training datasets, we developed a hybrid methodology combining rule-based NLP methods with prompt-based techniques. This approach leverages the meta-linguistic capabilities of large language models, enabling us to blend broad, language-agnostic processing with customized solutions. Our approach lays a foundational framework that can be expanded to other indigenous languages languages in future work.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2024.americasnlp-1.24,,acl,2024
1556,Detecting {C}hat{GPT}: A Survey of the State of Detecting {C}hat{GPT}-Generated Text,"@inproceedings{dhaini-etal-2023-detecting,
    title = {""Detecting {C}hat{GPT}: A Survey of the State of Detecting {C}hat{GPT}-Generated Text""},
    editor = {""Hardalov, Momchil  and},
    month = {sep},
    year = {""2023""},
    address = {""Varna, Bulgaria""},
    publisher = {""INCOMA Ltd., Shoumen, Bulgaria""},
    url = {""https://aclanthology.org/2023.ranlp-stud.1""},
    author = {""Dhaini, Mahdi  and},
    booktitle = {""Proceedings of the 8th Student Research Workshop associated with the International Conference Recent Advances in Natural Language Processing""},
    pages = {""1--12""},
    abstract = {""While recent advancements in the capabilities and widespread accessibility of generative language models, such as ChatGPT (OpenAI, 2022), have brought about various benefits by generating fluent human-like text, the task of distinguishing between human- and large language model (LLM) generated text has emerged as a crucial problem. These models can potentially deceive by generating artificial text that appears to be human-generated. This issue is particularly significant in domains such as law, education, and science, where ensuring the integrity of text is of the utmost importance. This survey provides an overview of the current approaches employed to differentiate between texts generated by humans and ChatGPT. We present an account of the different datasets constructed for detecting ChatGPT-generated text, the various methods utilized, what qualitative analyses into the characteristics of human versus ChatGPT-generated text have been performed, and finally, summarize our findings into general insights.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.ranlp-stud.1,,acl,2023
1557,Automated Generation of Multiple-Choice Cloze Questions for Assessing {E}nglish Vocabulary Using {GPT}-turbo 3.5,"@inproceedings{wang-etal-2023-automated-generation,
    title = {""Automated Generation of Multiple-Choice Cloze Questions for Assessing {E}nglish Vocabulary Using {GPT}-turbo 3.5""},
    editor = {H{\""a}m{\""a}l{\""a}inen, Mika  and},
    month = {dec},
    year = {""2023""},
    address = {""Tokyo, Japan""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.nlp4dh-1.7""},
    author = {""Wang, Qiao  and},
    booktitle = {""Proceedings of the Joint 3rd International Conference on Natural Language Processing for Digital Humanities and 8th International Workshop on Computational Linguistics for Uralic Languages""},
    pages = {""52--61""},
    abstract = {""A common way of assessing language learners{'} mastery of vocabulary is via multiple-choice cloze (i.e., fill-in-the-blank) questions. But the creation of test items can be laborious for individual teachers or in large-scale language programs. In this paper, we evaluate a new method for automatically generating these types of questions using large language models (LLM). The VocaTT (vocabulary teaching and training) engine is written in Python and comprises three basic steps: pre-processing target word lists, generating sentences and candidate word options using GPT, and finally selecting suitable word options. To test the efficiency of this system, 60 questions were generated targeting academic words. The generated items were reviewed by expert reviewers who judged the well-formedness of the sentences and word options, adding comments to items judged not well-formed. Results showed a 75{\%} rate of well-formedness for sentences and 66.85{\%} rate for suitable word options. This is a marked improvement over the generator used earlier in our research which did not take advantage of GPT{'}s capabilities. Post-hoc qualitative analysis reveals several points for improvement in future work including cross-referencing part-of-speech tagging, better sentence validation, and improving GPT prompts.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}",https://aclanthology.org/2023.nlp4dh-1.7,,acl,2023
