title,published,link,DOI,authors,content_type,abstract
"Large Language Model Assisted Software Engineering: Prospects, Challenges, and a Case Study",2024,https://link.springer.com/chapter/10.1007/978-3-031-46002-9_23,10.1007/978-3-031-46002-9_23,"Lenz Belzner, Thomas Gabor, Martin Wirsing",Conference paper,No abstract available for this DOI.
Docimological Quality Analysis of LLM-Generated Multiple Choice Questions in Computer Science and Medicine,10 June 2024,/article/10.1007/s42979-024-02963-6,10.1007/s42979-024-02963-6,"Christian Grévisse, Maria Angeliki S. Pavlou, Jochen G. Schneider",Article,"<jats:title>Abstract</jats:title><jats:p>Assessment is an essential part of education, both for teachers who assess their students as well as learners who may evaluate themselves. Multiple-choice questions (MCQ) are one of the most popular types of knowledge assessment, e.g., in medical education, as they can be automatically graded and can cover a wide range of learning items. However, the creation of high-quality MCQ items is a time-consuming task. The recent advent of Large Language Models (LLM), such as Generative Pre-trained Transformer (GPT), caused a new momentum for automatic question generation solutions. Still, evaluating generated questions according to the best practices for MCQ item writing is needed to ensure docimological quality. In this article, we propose an analysis of the quality of LLM-generated MCQs. We employ zero-shot approaches in two domains, namely computer science and medicine. In the former, we make use of 3 GPT-based services to generate MCQs. In the latter, we developed a plugin for the Moodle learning management system that generates MCQs based on learning material. We compare the generated MCQs against common multiple-choice item writing guidelines. Among the major challenges, we determined that while LLMs are certainly useful in generating MCQs more efficiently, they sometimes create broad items with ambiguous keys or implausible distractors. Human oversight is also necessary to ensure instructional alignment between generated items and course contents. Finally, we propose solutions for AQG developers.</jats:p>"
Assistant Teaching System for Computer Hardware Courses Based on Large Language Model,2024,https://link.springer.com/chapter/10.1007/978-981-97-0730-0_27,10.1007/978-981-97-0730-0_27,"Dongdong Zhang, Qian Cao, ... Lisheng Wang",Conference paper,No abstract available for this DOI.
Automated quantum software engineering,12 April 2024,/article/10.1007/s10515-024-00436-x,10.1007/s10515-024-00436-x,Aritra Sarkar,Article,"<jats:title>Abstract</jats:title><jats:p>As bigger quantum processors with hundreds of qubits become increasingly available, the potential for quantum computing to solve problems intractable for classical computers is becoming more tangible. Designing efficient quantum algorithms and software in tandem is key to achieving quantum advantage. Quantum software engineering is challenging due to the unique counterintuitive nature of quantum logic. Moreover, with larger quantum systems, traditional programming using quantum assembly language and qubit-level reasoning is becoming infeasible. Automated Quantum Software Engineering (AQSE) can help to reduce the barrier to entry, speed up development, reduce errors, and improve the efficiency of quantum software. This article elucidates the motivation to research AQSE (why), a precise description of such a framework (what), and reflections on components that are required for implementing it (how).</jats:p>"
Large language model and domain-specific model collaboration for smart education,23 March 2024,/article/10.1631/FITEE.2300747,10.1631/FITEE.2300747,"Yawei Luo, Yi Yang",Article,No abstract available for this DOI.
A survey on large language model based autonomous agents,22 March 2024,/article/10.1007/s11704-024-40231-1,10.1007/s11704-024-40231-1,"Lei Wang, Chen Ma, ... Jirong Wen",Article,"<jats:title>Abstract</jats:title><jats:p>Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in research on LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of LLM-based autonomous agents from a holistic perspective. We first discuss the construction of LLM-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of LLM-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.</jats:p>"
Large Language Model for Geometric Algebra: A Preliminary Attempt,2024,https://link.springer.com/chapter/10.1007/978-3-031-50078-7_19,10.1007/978-3-031-50078-7_19,"Jian Wang, Ziqiang Wang, ... Zhaoyuan Yu",Conference paper,No abstract available for this DOI.
Evaluation of LLM Tools for Feedback Generation in a Course on Concurrent Programming,15 May 2024,/article/10.1007/s40593-024-00406-0,10.1007/s40593-024-00406-0,"Iria Estévez-Ayres, Patricia Callejo, ... Carlos Delgado Kloos",Article,"<jats:title>Abstract</jats:title><jats:p>The emergence of Large Language Models (LLMs) has marked a significant change in education. The appearance of these LLMs and their associated chatbots has yielded several advantages for both students and educators, including their use as teaching assistants for content creation or summarisation. This paper aims to evaluate the capacity of LLMs chatbots to provide feedback on student exercises in a university programming course. The complexity of the programming topic in this study (concurrency) makes the need for feedback to students even more important. The authors conducted an assessment of exercises submitted by students. Then, ChatGPT (from OpenAI) and Bard (from Google) were employed to evaluate each exercise, looking for typical concurrency errors, such as starvation, deadlocks, or race conditions. Compared to the ground-truth evaluations performed by expert teachers, it is possible to conclude that none of these two tools can accurately assess the exercises despite the generally positive reception of LLMs within the educational sector. All attempts result in an accuracy rate of 50%, meaning that both tools have limitations in their ability to evaluate these particular exercises effectively, specifically finding typical concurrency errors.</jats:p>"
Automated Comment Generation Based on the Large Language Model,2024,https://link.springer.com/chapter/10.1007/978-981-97-0730-0_25,10.1007/978-981-97-0730-0_25,"Kaiwei Cai, Junsheng Zhou, ... Xianzhuo Li",Conference paper,No abstract available for this DOI.
Can AI serve as a substitute for human subjects in software engineering research?,11 January 2024,/article/10.1007/s10515-023-00409-6,10.1007/s10515-023-00409-6,"Marco Gerosa, Bianca Trinkenreich, ... Anita Sarma",Article,No abstract available for this DOI.
Performance of Large Language Models in a Computer Science Degree Program,2024,https://link.springer.com/chapter/10.1007/978-3-031-50485-3_40,10.1007/978-3-031-50485-3_40,"Tim Krüger, Michael Gref",Conference paper,No abstract available for this DOI.
Transforming Driver Education: A Comparative Analysis of LLM-Augmented Training and Conventional Instruction for Autonomous Vehicle Technologies,14 May 2024,/article/10.1007/s40593-024-00407-z,10.1007/s40593-024-00407-z,"Mohsin Murtaza, Chi-Tsun Cheng, ... John Zeleznikow",Article,"<jats:title>Abstract</jats:title><jats:p>As modern vehicles continue to integrate increasingly sophisticated Advanced Driver Assistance Systems (ADAS) and Autonomous Vehicles (AV) functions, conventional user manuals may no longer be the most effective medium for conveying knowledge to drivers. This research analysed conventional, paper and video-based instructional methods versus a Large Language Model (LLM)-based instructional tool to educate 86 participants about the operation of specific ADAS and AV functionalities. The study sampled participants aged between 20 and over 40, with driving experience ranging from one to over six years. The first group was educated using the conventional methods. In contrast, the second group received instructions via an LLM, i.e., users learn via ChatGPT interaction. Our goal was to assess the efficiency and effectiveness of these teaching methodologies based on the reaction times participants required to activate ADAS functions and the corresponding accuracies. Our findings revealed that the group trained via ChatGPT demonstrated significantly improved learning outcomes compared to conventional training. This included shorter activation times, higher consistency, and higher accuracy across examined functions. This study further proposed a framework to effectively use ChatGPT for different training scenarios and education purposes, offering a valuable resource for leveraging Artificial Intelligence (AI) in training users to handle complex systems. The framework empowers educators to tailor ChatGPT’s interactions, ensuring efficient, guided learning experiences for learners. For researchers, this study lays the foundation for exploring the role of LLM-based instructional tools in a broader range of applications.</jats:p>"
LLM examiner: automating assessment in informal self-directed e-learning using ChatGPT,10 June 2024,/article/10.1007/s10115-024-02156-w,10.1007/s10115-024-02156-w,"Nursultan Askarbekuly, Nenad Aničić",Article,No abstract available for this DOI.
Exploring Gender Bias In Remote Pair Programming Among Software Engineering Students: The twincode Original Study And First External Replication,01 February 2024,/article/10.1007/s10664-023-10416-6,10.1007/s10664-023-10416-6,"Amador Durán Toro, Pablo Fernández, ... Armando Fox",Article,"<jats:title>Abstract</jats:title><jats:sec>
                <jats:title>Context</jats:title>
                <jats:p>Women have historically been underrepresented in Software Engineering, due in part to the stereotyped assumption that women are less technically competent than men. Pair programming is both widely used in industry and has been shown to increase student interest in Software Engineering, particularly among women; but if those same gender biases are also present in pair programming, its potential for attracting women to the field could be thwarted.</jats:p>
              </jats:sec><jats:sec>
                <jats:title>Objective</jats:title>
                <jats:p>We aim to explore the effects of gender bias in pair programming. Specifically, in a remote setting in which students cannot directly observe the gender of their peers, we study whether the perception of the partner, the behavior during programming, or the style of communication of Software Engineering students differ depending on the perceived gender of their remote partner. To our knowledge, this is the first study specifically focusing on the impact of gender stereotypes and bias <jats:italic>within</jats:italic> pairs in pair programming.</jats:p>
              </jats:sec><jats:sec>
                <jats:title>Method</jats:title>
                <jats:p>We have developed an online pair-programming platform () that provides a collaborative editing window and a chat pane, both of which are heavily instrumented. Students in the control group had no information about their partner’s gender, whereas students in the treatment group could see a gendered avatar representing the other participant as a man or as a woman. The gender of the avatar was swapped between programming tasks to analyze 45 variables related to the collaborative coding behavior, chat utterances, and questionnaire responses of 46 pairs in the original study at the University of Seville, and 23 pairs in the external replication at the University of California, Berkeley.</jats:p>
              </jats:sec><jats:sec>
                <jats:title>Results</jats:title>
                <jats:p>We did not observe any statistically significant effect of the gender bias treatment, nor any interaction between the perceived partner’s gender and subject’s gender, in any of the 45 response variables measured in the original study. In the external replication, we observed statistically significant effects with moderate to large sizes in four dependent variables within the experimental group, comparing how subjects acted when their partners were represented as a man or a woman.</jats:p>
              </jats:sec><jats:sec>
                <jats:title>Conclusions</jats:title>
                <jats:p>The results in the original study do not show any clear effect of the treatment in remote pair programming among current Software Engineering students. In the external replication, it seems that students delete more source code characters when they have a woman partner, and communicate using more informal utterances, reflections and yes/no questions when they have a man partner, although these results must be considered inconclusive because of the small number of subjects in the replication, and because when multiple test corrections are applied, only the result about informal utterances remains significant. In any case, more mixed methods replications are needed in order to confirm or refute the results in the same and other Software Engineering students populations.</jats:p>
              </jats:sec>"
A Large Language Model Approach to Educational Survey Feedback Analysis,25 June 2024,/article/10.1007/s40593-024-00414-0,10.1007/s40593-024-00414-0,"Michael J. Parker, Caitlin Anderson, ... YeaRim Oh",Article,"<jats:title>Abstract</jats:title><jats:p>This paper assesses the potential for the large language models (LLMs) GPT-4 and GPT-3.5 to aid in deriving insight from education feedback surveys. Exploration of LLM use cases in education has focused on teaching and learning, with less exploration of capabilities in education feedback analysis. Survey analysis in education involves goals such as finding gaps in curricula or evaluating teachers, often requiring time-consuming manual processing of textual responses. LLMs have the potential to provide a flexible means of achieving these goals without specialized machine learning models or fine-tuning. We demonstrate a versatile approach to such goals by treating them as sequences of natural language processing (NLP) tasks including classification (multi-label, multi-class, and binary), extraction, thematic analysis, and sentiment analysis, each performed by LLM. We apply these workflows to a real-world dataset of 2500 end-of-course survey comments from biomedical science courses, and evaluate a zero-shot approach (i.e., requiring no examples or labeled training data) across all tasks, reflecting education settings, where labeled data is often scarce. By applying effective prompting practices, we achieve human-level performance on multiple tasks with GPT-4, enabling workflows necessary to achieve typical goals. We also show the potential of inspecting LLMs’ chain-of-thought (CoT) reasoning for providing insight that may foster confidence in practice. Moreover, this study features development of a versatile set of classification categories, suitable for various course types (online, hybrid, or in-person) and amenable to customization. Our results suggest that LLMs can be used to derive a range of insights from survey text.</jats:p>"
Large language models for qualitative research in software engineering: exploring opportunities and challenges,21 December 2023,/article/10.1007/s10515-023-00407-8,10.1007/s10515-023-00407-8,"Muneera Bano, Rashina Hoda, ... Christoph Treude",Article,No abstract available for this DOI.
Future of software development with generative AI,11 March 2024,/article/10.1007/s10515-024-00426-z,10.1007/s10515-024-00426-z,"Jaakko Sauvola, Sasu Tarkoma, ... David Doermann",Article,"<jats:title>Abstract</jats:title><jats:p>Generative AI is regarded as a major disruption to software development. Platforms, repositories, clouds, and the automation of tools and processes have been proven to improve productivity, cost, and quality. Generative AI, with its rapidly expanding capabilities, is a major step forward in this field. As a new key enabling technology, it can be used for many purposes, from creative dimensions to replacing repetitive and manual tasks. The number of opportunities increases with the capabilities of large-language models (LLMs). This has raised concerns about ethics, education, regulation, intellectual property, and even criminal activities. We analyzed the potential of generative AI and LLM technologies for future software development paths. We propose four primary scenarios, model trajectories for transitions between them, and reflect against relevant software development operations. The motivation for this research is clear: the software development industry needs new tools to understand the potential, limitations, and risks of generative AI, as well as guidelines for using it.</jats:p>"
Enhancing Image Comprehension for Computer Science Visual Question Answering,2024,https://link.springer.com/chapter/10.1007/978-981-99-8429-9_39,10.1007/978-981-99-8429-9_39,"Hongyu Wang, Pengpeng Qiang, ... Jingchang Hu",Conference paper,No abstract available for this DOI.
RA-CFGPT: Chinese financial assistant with retrieval-augmented large language model,06 June 2024,/article/10.1007/s11704-024-31018-5,10.1007/s11704-024-31018-5,"Jiangtong Li, Yang Lei, ... Changjun Jiang",Article,No abstract available for this DOI.
Analyzing Scrum Team Impediments Using NLP,2023,https://link.springer.com/chapter/10.1007/978-3-031-48639-5_4,10.1007/978-3-031-48639-5_4,"Kaleemunnisa, Christelle Scharff, ... Kaiyin Chen",Conference paper,No abstract available for this DOI.
Incorporating AI in foreign language education: An investigation into ChatGPT’s effect on foreign language learners,19 March 2024,/article/10.1007/s10639-024-12574-6,10.1007/s10639-024-12574-6,"Fatih Karataş, Faramarz Yaşar Abedi, ... Yasemin Kuzgun",Article,"<jats:title>Abstract</jats:title><jats:p>ChatGPT, an artificial intelligence application, has emerged as a promising educational tool with a wide range of applications, attracting the attention of researchers and educators. This qualitative case study, chosen for its ability to provide an in-depth exploration of the nuanced effects of AI on the foreign language learning process within its real-world educational context, aimed to utilize ChatGPT in foreign language education, addressing a gap in existing research by offering insights into the potential, benefits, and drawbacks of this innovative approach. The study involved 13 preparatory class students studying at the School of Foreign Languages at a university in Turkey. The students were introduced to ChatGPT through learning experiences over a span of four weeks by the researcher as a language teacher. The qualitative data collected from the interviews were analysed using thematic analysis. The findings suggest that ChatGPT positively affects students’ learning experiences, especially in writing, grammar, and vocabulary acquisition, and enhances motivation and engagement through its versatile and accessible nature in various learning activities. These insights contribute to understanding the utility and constraints of employing ChatGPT technology in foreign language instruction and can inform educators and researchers in developing effective teaching strategies and in designing curricula.</jats:p>"
Role of AI chatbots in education: systematic literature review,31 October 2023,/article/10.1186/s41239-023-00426-1,10.1186/s41239-023-00426-1,"Lasha Labadze, Maya Grigolia, Lela Machaidze",Article,"<jats:title>Abstract</jats:title><jats:p>AI chatbots shook the world not long ago with their potential to revolutionize education systems in a myriad of ways. AI chatbots can provide immediate support by answering questions, offering explanations, and providing additional resources. Chatbots can also act as virtual teaching assistants, supporting educators through various means. In this paper, we try to understand the full benefits of AI chatbots in education, their opportunities, challenges, potential limitations, concerns, and prospects of using AI chatbots in educational settings. We conducted an extensive search across various academic databases, and after applying specific predefined criteria, we selected a final set of 67 relevant studies for review. The research findings emphasize the numerous benefits of integrating AI chatbots in education, as seen from both students' and educators' perspectives. We found that students primarily gain from AI-powered chatbots in three key areas: homework and study assistance, a personalized learning experience, and the development of various skills. For educators, the main advantages are the time-saving assistance and improved pedagogy. However, our research also emphasizes significant challenges and critical factors that educators need to handle diligently. These include concerns related to AI applications such as reliability, accuracy, and ethical considerations.</jats:p>"
Parallel intelligent education with ChatGPT,08 June 2023,/article/10.1631/FITEE.2300166,10.1631/FITEE.2300166,"Jiacun Wang, Ying Tang, ... Fei-Yue Wang",Article,No abstract available for this DOI.
"Large-Language-Models (LLM)-Based AI Chatbots: Architecture, In-Depth Analysis and Their Performance Evaluation",2024,https://link.springer.com/chapter/10.1007/978-3-031-53085-2_20,10.1007/978-3-031-53085-2_20,"Vimal Kumar, Priyam Srivastava, ... Ruchika Arora",Conference paper,No abstract available for this DOI.
Assessing ChatGPT’s Proficiency in CS1-Level Problem Solving,2024,https://link.springer.com/chapter/10.1007/978-3-031-47372-2_7,10.1007/978-3-031-47372-2_7,"Mario Sánchez, Andrea Herrera",Conference paper,No abstract available for this DOI.
Bridging the Programming Skill Gap with ChatGPT: A Machine Learning Project with Business Students,2024,https://link.springer.com/chapter/10.1007/978-3-031-50485-3_42,10.1007/978-3-031-50485-3_42,"Michael Reiche, Jochen L. Leidner",Conference paper,No abstract available for this DOI.
Towards Higher Abstraction Levels in Quantum Computing,2024,https://link.springer.com/chapter/10.1007/978-981-97-0989-2_13,10.1007/978-981-97-0989-2_13,"Hermann Fürntratt, Paul Schnabl, ... Herwig Zeiner",Conference paper,No abstract available for this DOI.
Applications and Implication of Generative AI in Non-STEM Disciplines in Higher Education,2024,https://link.springer.com/chapter/10.1007/978-981-99-7587-7_29,10.1007/978-981-99-7587-7_29,"Tao Wu, Shu hua Zhang",Conference paper,No abstract available for this DOI.
The Recent Trends of Research on GitHub Copilot: A Systematic Review,2024,https://link.springer.com/chapter/10.1007/978-981-99-9589-9_27,10.1007/978-981-99-9589-9_27,"Zhamri Che Ani, Zauridah Abdul Hamid, Nur Nazifa Zhamri",Conference paper,No abstract available for this DOI.
Anticipating User Needs: Insights from Design Fiction on Conversational Agents for Computational Thinking,2024,https://link.springer.com/chapter/10.1007/978-3-031-54975-5_12,10.1007/978-3-031-54975-5_12,"Jacob Penney, João Felipe Pimentel, ... Marco A. Gerosa",Conference paper,No abstract available for this DOI.
Empowering Education with LLMs - The Next-Gen Interface and Content Generation,2023,https://link.springer.com/chapter/10.1007/978-3-031-36336-8_4,10.1007/978-3-031-36336-8_4,"Steven Moore, Richard Tong, ... John Stamper",Conference paper,No abstract available for this DOI.
Investigating large language models capabilities for automatic code repair in Python,09 May 2024,/article/10.1007/s10586-024-04490-8,10.1007/s10586-024-04490-8,"Safwan Omari, Kshitiz Basnet, Mohammad Wardat",Article,No abstract available for this DOI.
Beyond Mastery: Toward a Broader Understanding of AI in Education,20 June 2023,/article/10.1007/s40593-023-00343-4,10.1007/s40593-023-00343-4,Ilkka Tuomi,Article,No abstract available for this DOI.
Prospectives and drawbacks of ChatGPT in healthcare and clinical medicine,20 February 2024,/article/10.1007/s43681-024-00434-5,10.1007/s43681-024-00434-5,"Khadija Alam, Akhil Kumar, F. N. U. Samiullah",Article,No abstract available for this DOI.
Training Language Models for Programming Feedback Using Automated Repair Tools,2023,https://link.springer.com/chapter/10.1007/978-3-031-36272-9_79,10.1007/978-3-031-36272-9_79,Charles Koutcheme,Conference paper,No abstract available for this DOI.
"Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education",26 February 2024,/article/10.1186/s41239-024-00448-3,10.1186/s41239-024-00448-3,Yoshija Walter,Article,"<jats:title>Abstract</jats:title><jats:p>The present discussion examines the transformative impact of Artificial Intelligence (AI) in educational settings, focusing on the necessity for AI literacy, prompt engineering proficiency, and enhanced critical thinking skills. The introduction of AI into education marks a significant departure from conventional teaching methods, offering personalized learning and support for diverse educational requirements, including students with special needs. However, this integration presents challenges, including the need for comprehensive educator training and curriculum adaptation to align with societal structures. AI literacy is identified as crucial, encompassing an understanding of AI technologies and their broader societal impacts. Prompt engineering is highlighted as a key skill for eliciting specific responses from AI systems, thereby enriching educational experiences and promoting critical thinking. There is detailed analysis of strategies for embedding these skills within educational curricula and pedagogical practices. This is discussed through a case-study based on a Swiss university and a narrative literature review, followed by practical suggestions of how to implement AI in the classroom.</jats:p>"
Exploring GPT-4 as MR Sequence and Reconstruction Programming Assistant,2024,https://link.springer.com/chapter/10.1007/978-3-658-44037-4_28,10.1007/978-3-658-44037-4_28,"Moritz Zaiss, Junaid R. Rajput, ... Andreas Maier",Conference paper,No abstract available for this DOI.
Value-Based Adoption of ChatGPT in Agile Software Development: A Survey Study of Nordic Software Experts,2024,https://link.springer.com/chapter/10.1007/978-3-031-55642-5_12,10.1007/978-3-031-55642-5_12,"Anh Nguyen-Duc, Dron Khanna",Chapter,No abstract available for this DOI.
"A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour",19 January 2024,/article/10.1186/s41239-023-00436-z,10.1186/s41239-023-00436-z,"Melissa Bond, Hassan Khosravi, ... George Siemens",Article,"<jats:title>Abstract</jats:title><jats:p>Although the field of Artificial Intelligence in Education (AIEd) has a substantial history as a research domain, never before has the rapid evolution of AI applications in education sparked such prominent public discourse. Given the already rapidly growing AIEd literature base in higher education, now is the time to ensure that the field has a solid research and conceptual grounding. This review of reviews is the first comprehensive meta review to explore the scope and nature of AIEd in higher education (AIHEd) research, by synthesising secondary research (e.g., systematic reviews), indexed in the Web of Science, Scopus, ERIC, EBSCOHost, IEEE Xplore, ScienceDirect and ACM Digital Library, or captured through snowballing in OpenAlex, ResearchGate and Google Scholar. Reviews were included if they synthesised applications of AI solely in formal higher or continuing education, were published in English between 2018 and July 2023, were journal articles or full conference papers, and if they had a method section 66 publications were included for data extraction and synthesis in EPPI Reviewer, which were predominantly systematic reviews (66.7%), published by authors from North America (27.3%), conducted in teams (89.4%) in mostly domestic-only collaborations (71.2%). Findings show that these reviews mostly focused on AIHEd generally (47.0%) or Profiling and Prediction (28.8%) as thematic foci, however key findings indicated a predominance of the use of Adaptive Systems and Personalisation in higher education. Research gaps identified suggest a need for greater ethical, methodological, and contextual considerations within future research, alongside interdisciplinary approaches to AIHEd application. Suggestions are provided to guide future primary and secondary research.</jats:p>"
Prompting Large Language Models to Power Educational Chatbots,2023,https://link.springer.com/chapter/10.1007/978-981-99-8385-8_14,10.1007/978-981-99-8385-8_14,"Juan Carlos Farah, Sandy Ingram, ... Denis Gillet",Conference paper,No abstract available for this DOI.
On the assessment of generative AI in modeling tasks: an experience report with ChatGPT and UML,22 May 2023,/article/10.1007/s10270-023-01105-5,10.1007/s10270-023-01105-5,"Javier Cámara, Javier Troya, ... Antonio Vallecillo",Article,"<jats:title>Abstract</jats:title><jats:p>Most experts agree that large language models (LLMs), such as those used by Copilot and ChatGPT, are expected to revolutionize the way in which software is developed. Many papers are currently devoted to analyzing the potential advantages and limitations of these generative AI models for writing code. However, the analysis of the current state of LLMs with respect to software modeling has received little attention. In this paper, we investigate the current capabilities of ChatGPT to perform modeling tasks and to assist modelers, while also trying to identify its main shortcomings. Our findings show that, in contrast to code generation, the performance of the current version of ChatGPT for software modeling is limited, with various syntactic and semantic deficiencies, lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role that LLMs can play in the software modeling discipline in the short term, and how the modeling community can help to improve the current capabilities of ChatGPT and the coming LLMs for software modeling.</jats:p>"
"GPT-4 in Education: Evaluating Aptness, Reliability, and Loss of Coherence in Solving Calculus Problems and Grading Submissions",05 May 2024,/article/10.1007/s40593-024-00403-3,10.1007/s40593-024-00403-3,Alberto Gandolfi,Article,"<jats:title>Abstract</jats:title><jats:p>In this paper, we initially investigate the capabilities of GPT-3 5 and GPT-4 in solving college-level calculus problems, an essential segment of mathematics that remains under-explored so far. Although improving upon earlier versions, GPT-4 attains approximately 65% accuracy for standard problems and decreases to 20% for competition-like scenarios. Overall, the models prove to be unreliable due to common arithmetic errors.</jats:p><jats:p>Our primary contribution lies then in examining the use of ChatGPT for grading solutions to calculus exercises. Our objectives are to probe an in-context learning task with less emphasis over direct calculations; recognize positive applications of ChatGPT in educational contexts; highlight a potentially emerging facet of AI that could necessitate oversight; and introduce unconventional AI benchmarks, for which models like GPT are untrained. Pertaining to the latter, we uncover a tendency for loss of coherence in extended contexts. Our findings suggest that while the current ChatGPT exhibits comprehension of the grading task and often provides relevant outputs, the consistency of grading is marred by occasional loss of coherence and hallucinations. Intriguingly, GPT-4's overall scores, delivered in mere moments, align closely with human graders, although its detailed accuracy remains suboptimal.</jats:p><jats:p>This work suggests that, when appropriately orchestrated, collaboration between human graders and LLMs like GPT-4 might combine their unique strengths while mitigating their respective shortcomings In this direction, it is imperative to consider implementing transparency, fairness, and appropriate regulations in the near future.</jats:p>"
Automatic Generation of Multiple-Choice Questions for CS0 and CS1 Curricula Using Large Language Models,2024,https://link.springer.com/chapter/10.1007/978-981-97-0730-0_28,10.1007/978-981-97-0730-0_28,"Tian Song, Qinqin Tian, ... Shuting Liu",Conference paper,No abstract available for this DOI.
An analysis of large language models: their impact and potential applications,11 May 2024,/article/10.1007/s10115-024-02120-8,10.1007/s10115-024-02120-8,"G. Bharathi Mohan, R. Prasanna Kumar, ... Srinath Doss",Article,No abstract available for this DOI.
Feasibility Study on Parameter Adjustment for a Humanoid Using LLM Tailoring Physical Care,2024,https://link.springer.com/chapter/10.1007/978-981-99-8715-3_20,10.1007/978-981-99-8715-3_20,"Tamon Miyake, Yushi Wang, ... Shigeki Sugano",Conference paper,No abstract available for this DOI.
Four Interactions Between AI and Education: Broadening Our Perspective on What AI Can Offer Education,2023,https://link.springer.com/chapter/10.1007/978-3-031-36336-8_1,10.1007/978-3-031-36336-8_1,"Sina Rismanchian, Shayan Doroudi",Conference paper,No abstract available for this DOI.
Generating domain models from natural language text using NLP: a benchmark dataset and experimental comparison of tools,08 May 2024,/article/10.1007/s10270-024-01176-y,10.1007/s10270-024-01176-y,"Fatma Bozyigit, Tolgahan Bardakci, ... Michel R. V. Chaudron",Article,No abstract available for this DOI.
From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer Multiple-Choice Questions for Programming Classes in Higher Education,2024,https://link.springer.com/chapter/10.1007/978-3-031-53656-4_8,10.1007/978-3-031-53656-4_8,"Jaromir Savelka, Arav Agarwal, ... Majd Sakr",Conference paper,No abstract available for this DOI.
Empowering education development through AIGC: A systematic literature review,29 February 2024,/article/10.1007/s10639-024-12549-7,10.1007/s10639-024-12549-7,"Xiaojiao Chen, Zhebing Hu, Chengliang Wang",Article,No abstract available for this DOI.
Business and Ethical Concerns in Domestic Conversational Generative AI-Empowered Multi-robot Systems,2024,https://link.springer.com/chapter/10.1007/978-3-031-53227-6_13,10.1007/978-3-031-53227-6_13,"Rebekah Rousi, Hooman Samani, ... Pekka Abrahamsson",Conference paper,"<jats:title>Abstract</jats:title><jats:p>Business and technology are intricately connected through logic and design. They are equally sensitive to societal changes and may be devastated by scandal. Cooperative multi-robot systems (MRSs) are on the rise, allowing robots of different types and brands to work together in diverse contexts. Generative artificial intelligence has been a dominant topic in recent artificial intelligence (AI) discussions due to its capacity to mimic humans through the use of natural language and the production of media, including deep fakes. In this article, we focus specifically on the conversational aspects of generative AI, and hence use the term Conversational Generative artificial intelligence (CGI). Like MRSs, CGIs have enormous potential for revolutionizing processes across sectors and transforming the way humans conduct business. From a business perspective, cooperative MRSs alone, with potential conflicts of interest, privacy practices, and safety concerns, require ethical examination. MRSs empowered by CGIs demand multi-dimensional and sophisticated methods to uncover imminent ethical pitfalls. This study focuses on ethics in CGI-empowered MRSs while reporting the stages of developing the MORUL model.</jats:p>"
Exploring ChatGPT and its impact on society,21 February 2024,/article/10.1007/s43681-024-00435-4,10.1007/s43681-024-00435-4,"Md. Asraful Haque, Shuai Li",Article,No abstract available for this DOI.
"Public attitudes toward chatgpt on twitter: sentiments, topics, and occupations",20 May 2024,/article/10.1007/s13278-024-01260-7,10.1007/s13278-024-01260-7,"Ratanond Koonchanok, Yanling Pan, Hyeju Jang",Article,No abstract available for this DOI.
Data,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9367-6_2,10.1007/978-1-4842-9367-6_2,Tom Taulli,Chapter,No abstract available for this DOI.
To resist it or to embrace it? Examining ChatGPT’s potential to support teacher feedback in EFL writing,29 August 2023,/article/10.1007/s10639-023-12146-0,10.1007/s10639-023-12146-0,"Kai Guo, Deliang Wang",Article,No abstract available for this DOI.
Adaptation of Enterprise Modeling Methods for Large Language Models,2024,https://link.springer.com/chapter/10.1007/978-3-031-48583-1_1,10.1007/978-3-031-48583-1_1,"Balbir S. Barn, Souvik Barat, Kurt Sandkuhl",Conference paper,No abstract available for this DOI.
"Students’ voices on generative AI: perceptions, benefits, and challenges in higher education",17 July 2023,/article/10.1186/s41239-023-00411-8,10.1186/s41239-023-00411-8,"Cecilia Ka Yuk Chan, Wenjie Hu",Article,"<jats:title>Abstract</jats:title><jats:p>This study explores university students’ perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Students recognized the potential for personalized learning support, writing and brainstorming assistance, and research and analysis capabilities. However, concerns about accuracy, privacy, ethical issues, and the impact on personal development, career prospects, and societal values were also expressed. According to John Biggs’ 3P model, student perceptions significantly influence learning approaches and outcomes. By understanding students’ perceptions, educators and policymakers can tailor GenAI technologies to address needs and concerns while promoting effective learning outcomes. Insights from this study can inform policy development around the integration of GenAI technologies into higher education. By understanding students’ perceptions and addressing their concerns, policymakers can create well-informed guidelines and strategies for the responsible and effective implementation of GenAI tools, ultimately enhancing teaching and learning experiences in higher education.</jats:p>"
Design and Application of Formative Evaluation in the Artificial Intelligence Course,2024,https://link.springer.com/chapter/10.1007/978-981-97-0791-1_22,10.1007/978-981-97-0791-1_22,"Ping Zhong, Chengyang Zhu, ... Wanchun Jiang",Conference paper,No abstract available for this DOI.
"Reflections on Automation, Learnability and Expressiveness in Logic-Based Programming Languages",2023,https://link.springer.com/chapter/10.1007/978-3-031-35254-6_29,10.1007/978-3-031-35254-6_29,Paul Tarau,Chapter,No abstract available for this DOI.
"ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review",05 May 2024,/article/10.1007/s12559-024-10285-1,10.1007/s12559-024-10285-1,"Sunder Ali Khowaja, Parus Khuwaja, ... Lewis Nkenyereye",Article,"<jats:title>Abstract</jats:title><jats:p>ChatGPT is another large language model (LLM) vastly available for the consumers on their devices but due to its performance and ability to converse effectively, it has gained a huge popularity amongst research as well as industrial community. Recently, many studies have been published to show the effectiveness, efficiency, integration, and sentiments of chatGPT and other LLMs. In contrast, this study focuses on the important aspects that are mostly overlooked, i.e. sustainability, privacy, digital divide, and ethics and suggests that not only chatGPT but every subsequent entry in the category of conversational bots should undergo Sustainability, PrivAcy, Digital divide, and Ethics (SPADE) evaluation. This paper discusses in detail the issues and concerns raised over chatGPT in line with aforementioned characteristics. We also discuss the recent EU AI Act briefly in accordance with the SPADE evaluation. We support our hypothesis by some preliminary data collection and visualizations along with hypothesized facts. We also suggest mitigations and recommendations for each of the concerns. Furthermore, we also suggest some policies and recommendations for EU AI policy act concerning ethics, digital divide, and sustainability.</jats:p>"
Natural language processing in educational research: The evolution of research topics,23 May 2024,/article/10.1007/s10639-024-12764-2,10.1007/s10639-024-12764-2,"Hao Wu, Shan Li, ... Guozhu Ding",Article,No abstract available for this DOI.
"Editorial for EAIT issue 12, 2023",20 November 2023,/article/10.1007/s10639-023-12367-3,10.1007/s10639-023-12367-3,Arthur Tatnall,Article,No abstract available for this DOI.
Few-shot is enough: exploring ChatGPT prompt engineering method for automatic question generation in english education,31 October 2023,/article/10.1007/s10639-023-12249-8,10.1007/s10639-023-12249-8,"Unggi Lee, Haewon Jung, ... Hyeoncheol Kim",Article,No abstract available for this DOI.
Demystifying the Impact of ChatGPT on Teaching and Learning,2024,https://link.springer.com/chapter/10.1007/978-3-031-48536-7_7,10.1007/978-3-031-48536-7_7,"Tapiwa Gundu, Colin Chibaya",Conference paper,No abstract available for this DOI.
Students’ perceptions of using ChatGPT in a physics class as a virtual tutor,22 December 2023,/article/10.1186/s41239-023-00434-1,10.1186/s41239-023-00434-1,"Lu Ding, Tong Li, ... Albert Gapud",Article,"<jats:title>Abstract</jats:title><jats:p>The latest development of Generative Artificial Intelligence (GenAI), particularly ChatGPT, has drawn the attention of educational researchers and practitioners. We have witnessed many innovative uses of ChatGPT in STEM classrooms. However, studies regarding students’ perceptions of ChatGPT as a virtual tutoring tool in STEM education are rare. The current study investigated undergraduate students’ perceptions of using ChatGPT in a physics class as an assistant tool for addressing physics questions. Specifically, the study examined the accuracy of ChatGPT in answering physics questions, the relationship between students’ ChatGPT trust levels and answer accuracy, and the influence of trust on students’ perceptions of ChatGPT. Our finding indicates that despite the inaccuracy of GenAI in question answering, most students trust its ability to provide correct answers. Trust in GenAI is also associated with students’ perceptions of GenAI. In addition, this study sheds light on students’ misconceptions toward GenAI and provides suggestions for future considerations in AI literacy teaching and research.</jats:p>"
Distilled GPT for source code summarization,01 March 2024,/article/10.1007/s10515-024-00421-4,10.1007/s10515-024-00421-4,"Chia-Yi Su, Collin McMillan",Article,No abstract available for this DOI.
Formative Feedback on Student-Authored Summaries in Intelligent Textbooks Using Large Language Models,28 March 2024,/article/10.1007/s40593-024-00395-0,10.1007/s40593-024-00395-0,"Wesley Morris, Scott Crossley, ... Danielle McNamara",Article,"<jats:title>Abstract</jats:title><jats:p>As intelligent textbooks become more ubiquitous in classrooms and educational settings, the need to make them more interactive arises. An alternative is to ask students to generate knowledge in response to textbook content and provide feedback about the produced knowledge. This study develops Natural Language Processing models to automatically provide feedback to students about the quality of summaries written at the end of intelligent textbook sections. The study builds on the work of Botarleanu et al. (2022), who used a Longformer Large Language Model (LLM) to develop a summary grading model. Their model explained around 55% of holistic summary score variance as assigned by human raters. This study uses a principal component analysis to distill summary scores from an analytic rubric into two principal components – content and wording. This study uses two encoder-only classification large language models finetuned from Longformer on the summaries and the source texts using these principal components explained 82% and 70% of the score variance for content and wording, respectively. On a dataset of summaries collected on the crowd-sourcing site Prolific, the content model was shown to be robust although the accuracy of the wording model was reduced compared to the training set. The developed models are freely available on HuggingFace and will allow formative feedback to users of intelligent textbooks to assess reading comprehension through summarization in real time. The models can also be used for other summarization applications in learning systems.</jats:p>"
Prospects for Hybrid AI,2024,https://link.springer.com/chapter/10.1007/978-3-662-68290-6_5,10.1007/978-3-662-68290-6_5,"Klaus Mainzer, Reinhard Kahle",Chapter,No abstract available for this DOI.
Acceptance and use of ChatGPT in the academic community,18 May 2024,/article/10.1007/s10639-024-12765-1,10.1007/s10639-024-12765-1,"Artur Strzelecki, Karina Cicha, ... Paulina Rutecka",Article,"<jats:title>Abstract</jats:title><jats:p>Since OpenAI released ChatGPT, the discussion on its usage in education has been conducted by students and teachers of every education level. Also, many studies have been performed on the tool’s possibilities and the threats related to its usage, such as incomplete or inaccurate information obtained or even plagiarism. Many universities worldwide have introduced specific regulations on ChatGPT usage in academic work. Furthermore, research on using ChatGPT by students and their attitudes towards it has appeared. However, a research gap exists in higher education teachers’ acceptance of AI solutions. The goal of this research was to explore the level of acceptance of the usage of ChatGPT by academics in Poland, as well as point out factors influencing their intention to use this tool. The study motivation was related to an ongoing academic discussion mainly focusing on the disadvantages of AI solutions used in scientific work and the willingness to fill the gap by showing teachers’ attitudes toward AI. The data was collected online by inviting academic teachers from Polish public universities to complete the prepared survey. The survey was prepared using the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model extended with Personal Innovativeness. It revealed the acceptance level of ChatGPT usage in Polish universities by teachers and researchers and the antecedents influencing willingness to use this technology in academic work. The paper contributes to the theory of AI usage by structuring the studies regarding ChatGPT application for teaching and research, and provides practical recommendations on ChatGPT adoption in the work of academics.</jats:p>"
"Integrating LLMs in Higher Education, Through Interactive Problem Solving and Tutoring: Algorithmic Approach and Use Cases",2024,https://link.springer.com/chapter/10.1007/978-3-031-56478-9_21,10.1007/978-3-031-56478-9_21,"Nikolaos P. Bakas, Maria Papadaki, ... Savvas A. Chatzichristofis",Conference paper,No abstract available for this DOI.
Academic Integrity in the Face of Generative Language Models,2024,https://link.springer.com/chapter/10.1007/978-3-031-50215-6_5,10.1007/978-3-031-50215-6_5,"Alba Meça, Nirvana Shkëlzeni",Conference paper,No abstract available for this DOI.
The work of art in the age of artificial intelligibility,28 March 2024,/article/10.1007/s00146-023-01845-4,10.1007/s00146-023-01845-4,John McLoughlin,Article,"<jats:title>Abstract</jats:title><jats:p>The emergence of complex deep-learning models capable of producing novel images on a practically innumerable number of subjects and in an equally wide variety of artistic styles is beginning to highlight serious inadequacies in the ethical, aesthetic, epistemological and legal frameworks we have so far used to categorise art. To begin tackling these issues and identifying a role for AI in the production and protection of human artwork, it is necessary to take a multidisciplinary approach which considers current legal precedents, the practice of software engineering, historical attitudes towards technological innovation and a sustained technical analysis of the models themselves. This paper queries the location and nature of substantive artistic work in the developmental stages of an AI-generated image, offering critiques of existing assumptions and posing questions for future research. The emergence of convincing AI creative output, artistic or literary, has significant long-term implications for the humanities, including the need for re-appraisal of foundational ideas about authorship and creativity in general. The effects of artificial intelligence, whether generalised or task-specific, cannot be ignored or displaced now that easy-access, scalable image and text production is a reality.</jats:p>"
The Current Era of Chatbots,2024,https://link.springer.com/chapter/10.1007/978-3-031-51004-5_4,10.1007/978-3-031-51004-5_4,Robert Ciesla,Chapter,No abstract available for this DOI.
A comprehensive bibliometric and content analysis of artificial intelligence in language learning: tracing between the years 2017 and 2023,01 April 2024,/article/10.1007/s10462-023-10643-9,10.1007/s10462-023-10643-9,"Abdur Rahman, Antony Raj, ... Mohamed Sahul Hameed",Article,"<jats:title>Abstract</jats:title><jats:p>The rising pervasiveness of Artificial Intelligence (AI) has led applied linguists to combine it with language teaching and learning processes. In many cases, such implementation has significantly contributed to the field. The retrospective amount of literature dedicated on the use of AI in language learning (LL) is overwhelming. Thus, the objective of this paper is to map the existing literature on Artificial Intelligence in language learning through bibliometric and content analysis. From the Scopus database, we systematically explored, after keyword refinement, the prevailing literature of AI in LL. After excluding irrelevant articles, we conducted our study with 606 documents published between 2017 and 2023 for further investigation. This review reinforces our understanding by identifying and distilling the relationships between the content, the contributions, and the contributors. The findings of the study show a rising pattern of AI in LL. Along with the metrics of performance analysis, through VOSviewer and R studio (Biblioshiny), our findings uncovered the influential authors, institutions, countries, and the most influential documents in the field. Moreover, we identified 7 clusters and potential areas of related research through keyword analysis. In addition to the bibliographic details, this review aims to elucidate the content of the field. NVivo 14 and Atlas AI were used to perform content analysis to categorize and present the type of AI used in language learning, Language learning factors, and its participants.</jats:p>"
Examining Potential Harms of Large Language Models (LLMs) in Africa,2024,https://link.springer.com/chapter/10.1007/978-3-031-56396-6_1,10.1007/978-3-031-56396-6_1,"Rehema Baguma, Hajarah Namuwaya, ... Qazi Mamunur Rashid",Conference paper,No abstract available for this DOI.
Friend or foe? Exploring the implications of large language models on the science system,26 October 2023,/article/10.1007/s00146-023-01791-1,10.1007/s00146-023-01791-1,"Benedikt Fecher, Marcel Hebing, ... Fabian Sofsky",Article,"<jats:title>Abstract</jats:title><jats:p>The advent of ChatGPT by OpenAI has prompted extensive discourse on its potential implications for science and higher education. While the impact on education has been a primary focus, there is limited empirical research on the effects of large language models (LLMs) and LLM-based chatbots on science and scientific practice. To investigate this further, we conducted a Delphi study involving 72 researchers specializing in AI and digitization. The study focused on applications and limitations of LLMs, their effects on the science system, ethical and legal considerations, and the required competencies for their effective use. Our findings highlight the transformative potential of LLMs in science, particularly in administrative, creative, and analytical tasks. However, risks related to bias, misinformation, and quality assurance need to be addressed through proactive regulation and science education. This research contributes to informed discussions on the impact of generative AI in science and helps identify areas for future action.</jats:p>"
"Sora for foundation robots with parallel intelligence: three world models, three robotic systems",22 April 2024,/article/10.1631/FITEE.2400144,10.1631/FITEE.2400144,"Lili Fan, Chao Guo, ... Fei-Yue Wang",Article,No abstract available for this DOI.
Building open-source AI,26 October 2023,/article/10.1038/s43588-023-00540-0,10.1038/s43588-023-00540-0,"Yash Raj Shrestha, Georg von Krogh, Stefan Feuerriegel",Article,No abstract available for this DOI.
Can ChatGPT Pass High School Exams on English Language Comprehension?,13 September 2023,/article/10.1007/s40593-023-00372-z,10.1007/s40593-023-00372-z,Joost C. F. de Winter,Article,"<jats:title>Abstract</jats:title><jats:p>Launched in late November 2022, ChatGPT, a large language model chatbot, has garnered considerable attention. However, ongoing questions remain regarding its capabilities. In this study, ChatGPT was used to complete national high school exams in the Netherlands on the topic of English reading comprehension. In late December 2022, we submitted the exam questions through the ChatGPT web interface (GPT-3.5). According to official norms, ChatGPT achieved a mean grade of 7.3 on the Dutch scale of 1 to 10—comparable to the mean grade of all students who took the exam in the Netherlands, 6.99. However, ChatGPT occasionally required re-prompting to arrive at an explicit answer; without these nudges, the overall grade was 6.5. In March 2023, API access was made available, and a new version of ChatGPT, GPT-4, was released. We submitted the same exams to the API, and GPT-4 achieved a score of 8.3 without a need for re-prompting. Additionally, employing a bootstrapping method that incorporated randomness through ChatGPT’s ‘temperature’ parameter proved effective in self-identifying potentially incorrect answers. Finally, a re-assessment conducted with the GPT-4 model updated as of June 2023 showed no substantial change in the overall score. The present findings highlight significant opportunities but also raise concerns about the impact of ChatGPT and similar large language models on educational assessment.</jats:p>"
The Practical Concepts of Machine Learning,2024,https://link.springer.com/chapter/10.1007/978-1-4842-9801-5_2,10.1007/978-1-4842-9801-5_2,Patanjali Kashyap,Chapter,No abstract available for this DOI.
Artificial Intelligence and Information Literacy: Hazards and Opportunities,2024,https://link.springer.com/chapter/10.1007/978-3-031-53001-2_5,10.1007/978-3-031-53001-2_5,Michael Flierl,Conference paper,No abstract available for this DOI.
Use Cases,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9579-3_12,10.1007/978-1-4842-9579-3_12,Patrick Parra Pennefather,Chapter,No abstract available for this DOI.
Artificial Intelligence and Information Literacy: Hazards and Opportunities,2024,https://link.springer.com/chapter/10.1007/978-3-031-53001-2_5,10.1007/978-3-031-53001-2_5,Michael Flierl,Conference paper,No abstract available for this DOI.
Fairness-aware machine learning engineering: how far are we?,24 November 2023,/article/10.1007/s10664-023-10402-y,10.1007/s10664-023-10402-y,"Carmine Ferrara, Giulia Sellitto, ... Andrea De Lucia",Article,"<jats:title>Abstract</jats:title><jats:p>Machine learning is part of the daily life of people and companies worldwide. Unfortunately, bias in machine learning algorithms risks unfairly influencing the decision-making process and reiterating possible discrimination. While the interest of the software engineering community in software fairness is rapidly increasing, there is still a lack of understanding of various aspects connected to fair machine learning engineering, i.e., the software engineering process involved in developing fairness-critical machine learning systems. Questions connected to the practitioners’ awareness and maturity about fairness, the skills required to deal with the matter, and the best development phase(s) where fairness should be faced more are just some examples of the knowledge gaps currently open. In this paper, we provide insights into how fairness is perceived and managed in practice, to shed light on the instruments and approaches that practitioners might employ to properly handle fairness. We conducted a survey with 117 professionals who shared their knowledge and experience highlighting the relevance of fairness in practice, and the skills and tools required to handle it. The key results of our study show that fairness is still considered a second-class quality aspect in the development of artificial intelligence systems. The building of specific methods and development environments, other than automated validation tools, might help developers to treat fairness throughout the software lifecycle and revert this trend.</jats:p>"
1 \(^{st}\) Workshop on Information Retrieval for Understudied Users (IR4U2),2024,https://link.springer.com/chapter/10.1007/978-3-031-56069-9_55,10.1007/978-3-031-56069-9_55,"Maria Soledad Pera, Federica Cena, ... Emiliana Murgia",Conference paper,No abstract available for this DOI.
Learning Hierarchical Robot Skills Represented by Behavior Trees from Natural Language,2024,https://link.springer.com/chapter/10.1007/978-3-031-46846-9_20,10.1007/978-3-031-46846-9_20,"Kaiyi Wang, Yongjia Zhao, ... Ning Zhang",Conference paper,No abstract available for this DOI.
Using rhetorical strategies to design prompts: a human-in-the-loop approach to make AI useful,01 April 2024,/article/10.1007/s00146-024-01905-3,10.1007/s00146-024-01905-3,"Nupoor Ranade, Marly Saravia, Aditya Johri",Article,"<jats:title>Abstract</jats:title><jats:p>The growing capabilities of artificial intelligence (AI) word processing models have demonstrated exceptional potential to impact language related tasks and functions. Their fast pace of adoption and probable effect has also given rise to controversy within certain fields. Models, such as GPT-3, are a particular concern for professionals engaged in writing, particularly as their engagement with these technologies is limited due to lack of ability to control their output. Most efforts to maximize and control output rely on a process known as prompt engineering, the construction and modification of the inputted prompt with expectation for certain outputted or desired text. Consequently, prompt engineering has emerged as an important consideration for research and practice. Previous conceptions of prompt engineering have largely focused on technical and logistic modifications to the back-end processing, remaining inaccessible and, still, limited for most users. In this paper, we look to the technical communication field and its methods of text generation—the rhetorical situation—to conceptualize prompt engineering in a more comprehensible way for its users by considering the context and rhetoric. We introduce a framework, consisting of a formula, to prompt engineering, which demands all components of the rhetorical situation be present in the inputted prompt. We present discussions on the future of AI writing models and their use in both professional and educational settings. Ultimately, this discussion and its findings aim to provide a means of integrating agency and writer-centric methods to AI writing tools to advance a more human-in-the-loop approach. As the use of generative AI and especially NLP-based technologies become common across societal functions, the use of prompt engineering will play a crucial role not just in adoption of the technology, but also its productive and responsible use.</jats:p>"
"The role of ChatGPT in disrupting concepts, changing values, and challenging ethical norms: a qualitative study",04 September 2023,/article/10.1007/s43681-023-00338-w,10.1007/s43681-023-00338-w,Pouyan Esmaeilzadeh,Article,No abstract available for this DOI.
Text Analysis on Early Reactions to ChatGPT as a Tool for Academic Progress or Exploitation,29 March 2024,/article/10.1007/s42979-024-02714-7,10.1007/s42979-024-02714-7,"Umar Ali Bukar, Md Shohel Sayeed, ... Raja Azlina Raja Mahmood",Article,No abstract available for this DOI.
AI hype as a cyber security risk: the moral responsibility of implementing generative AI in business,23 February 2024,/article/10.1007/s43681-024-00443-4,10.1007/s43681-024-00443-4,"Declan Humphreys, Abigail Koay, ... Erica Mealy",Article,"<jats:title>Abstract</jats:title><jats:p>This paper examines the ethical obligations companies have when implementing generative Artificial Intelligence (AI). We point to the potential cyber security risks companies are exposed to when rushing to adopt generative AI solutions or buying into “AI hype”. While the benefits of implementing generative AI solutions for business have been widely touted, the inherent risks associated have been less well publicised. There are growing concerns that the race to integrate generative AI is not being accompanied by adequate safety measures. The rush to buy into the hype of generative AI and not fall behind the competition is potentially exposing companies to broad and possibly catastrophic cyber-attacks or breaches. In this paper, we outline significant cyber security threats generative AI models pose, including potential ‘backdoors’ in AI models that could compromise user data or the risk of ‘poisoned’ AI models producing false results. In light of these the cyber security concerns, we discuss the moral obligations of implementing generative AI into business by considering the ethical principles of beneficence, non-maleficence, autonomy, justice, and explicability. We identify two examples of ethical concern, <jats:italic>overreliance</jats:italic> and <jats:italic>over-trust</jats:italic> in generative AI, both of which can negatively influence business decisions, leaving companies vulnerable to cyber security threats. This paper concludes by recommending a set of checklists for ethical implementation of generative AI in business environment to minimise cyber security risk based on the discussed moral responsibilities and ethical concern.</jats:p>"
A survey of safety and trustworthiness of large language models through the lens of verification and validation,17 June 2024,/article/10.1007/s10462-024-10824-0,10.1007/s10462-024-10824-0,"Xiaowei Huang, Wenjie Ruan, ... Mustafa A. Mustafa",Article,"<jats:title>Abstract</jats:title><jats:p>Large language models (LLMs) have exploded a new heatwave of AI for their ability to engage end-users in human-level conversations with detailed and articulate answers across many knowledge domains. In response to their fast adoption in many industrial applications, this survey concerns their safety and trustworthiness. First, we review known vulnerabilities and limitations of the LLMs, categorising them into inherent issues, attacks, and unintended bugs. Then, we consider if and how the Verification and Validation (V&amp;V) techniques, which have been widely developed for traditional software and deep learning models such as convolutional neural networks as independent processes to check the alignment of their implementations against the specifications, can be integrated and further extended throughout the lifecycle of the LLMs to provide rigorous analysis to the safety and trustworthiness of LLMs and their applications. Specifically, we consider four complementary techniques: falsification and evaluation, verification, runtime monitoring, and regulations and ethical use. In total, 370+ references are considered to support the quick understanding of the safety and trustworthiness issues from the perspective of V&amp;V. While intensive research has been conducted to identify the safety and trustworthiness issues, rigorous yet practical methods are called for to ensure the alignment of LLMs with safety and trustworthiness requirements.</jats:p>"
Breaking language barriers with ChatGPT: enhancing low-resource machine translation between algerian arabic and MSA,23 May 2024,/article/10.1007/s41870-024-01926-7,10.1007/s41870-024-01926-7,"Baligh Babaali, Mohammed Salem, Nawaf R. Alharbe",Article,No abstract available for this DOI.
AI-generated feedback on writing: insights into efficacy and ENL student preference,27 October 2023,/article/10.1186/s41239-023-00425-2,10.1186/s41239-023-00425-2,"Juan Escalante, Austin Pack, Alex Barrett",Article,"<jats:title>Abstract</jats:title><jats:p>The question of how generative AI tools, such as large language models and chatbots, can be leveraged ethically and effectively in education is ongoing. Given the critical role that writing plays in learning and assessment within educational institutions, it is of growing importance for educators to make thoughtful and informed decisions as to how and in what capacity generative AI tools should be leveraged to assist in the development of students’ writing skills. This paper reports on two longitudinal studies. Study 1 examined learning outcomes of 48 university English as a new language (ENL) learners in a six-week long repeated measures quasi experimental design where the experimental group received writing feedback generated from ChatGPT (GPT-4) and the control group received feedback from their human tutor. Study 2 analyzed the perceptions of a different group of 43 ENLs who received feedback from both ChatGPT and their tutor. Results of study 1 showed no difference in learning outcomes between the two groups. Study 2 results revealed a near even split in preference for AI-generated or human-generated feedback, with clear advantages to both forms of feedback apparent from the data. The main implication of these studies is that the use of AI-generated feedback can likely be incorporated into ENL essay evaluation without affecting learning outcomes, although we recommend a blended approach that utilizes the strengths of both forms of feedback. The main contribution of this paper is in addressing generative AI as an automatic essay evaluator while incorporating learner perspectives.</jats:p>"
Large Language Models,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9367-6_5,10.1007/978-1-4842-9367-6_5,Tom Taulli,Chapter,No abstract available for this DOI.
Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs,2023,https://link.springer.com/chapter/10.1007/978-3-031-52038-9_13,10.1007/978-3-031-52038-9_13,"Yankai Zeng, Abhiramon Rajasekharan, ... Gopal Gupta",Conference paper,No abstract available for this DOI.
My Perspective,2024,https://link.springer.com/chapter/10.1007/978-3-031-53747-9_2,10.1007/978-3-031-53747-9_2,Carlo Lipizzi,Chapter,No abstract available for this DOI.
Large language models as an “operating” system for software and systems modeling,16 September 2023,/article/10.1007/s10270-023-01126-0,10.1007/s10270-023-01126-0,"Benoit Combemale, Jeff Gray, Bernhard Rumpe",Article,No abstract available for this DOI.
Developments in Artificial Intelligence and Linguistics,2024,https://link.springer.com/chapter/10.1007/978-3-031-51004-5_2,10.1007/978-3-031-51004-5_2,Robert Ciesla,Chapter,No abstract available for this DOI.
Generating Creativity from Negativity,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9579-3_1,10.1007/978-1-4842-9579-3_1,Patrick Parra Pennefather,Chapter,No abstract available for this DOI.
Prof Pi: Using Whatsapp Bots and GPT-4 for Tutoring Mathematics in Underserved Areas,2024,https://link.springer.com/chapter/10.1007/978-3-031-51849-2_19,10.1007/978-3-031-51849-2_19,"Laurie Butgereit, Herman Martinus",Conference paper,No abstract available for this DOI.
Exploratory study on the potential of ChatGPT as a rater of second language writing,13 June 2024,/article/10.1007/s10639-024-12817-6,10.1007/s10639-024-12817-6,"Dongkwang Shin, Jang Ho Lee",Article,No abstract available for this DOI.
Prof Pi: Using Whatsapp Bots and GPT-4 for Tutoring Mathematics in Underserved Areas,2024,https://link.springer.com/chapter/10.1007/978-3-031-51849-2_19,10.1007/978-3-031-51849-2_19,"Laurie Butgereit, Herman Martinus",Conference paper,No abstract available for this DOI.
KG-CTG: Citation Generation Through Knowledge Graph-Guided Large Language Models,2023,https://link.springer.com/chapter/10.1007/978-3-031-49601-1_3,10.1007/978-3-031-49601-1_3,"Avinash Anand, Mohit Gupta, ... Rajiv Ratn Shah",Conference paper,No abstract available for this DOI.
"Influence of Artificial Intelligence in Higher Education; Impact, Risk and Counter Measure",2023,https://link.springer.com/chapter/10.1007/978-3-031-33627-0_7,10.1007/978-3-031-33627-0_7,"Musarrat Saberin Nipun, Md.Simul Hasan Talukder, ... Rejwan Bin Sulaiman",Chapter,No abstract available for this DOI.
PapagAI: Automated Feedback for Reflective Essays,2023,https://link.springer.com/chapter/10.1007/978-3-031-42608-7_16,10.1007/978-3-031-42608-7_16,"Veronika Solopova, Eiad Rostom, ... Tim Landgraf",Conference paper,No abstract available for this DOI.
The ethics of using artificial intelligence in scientific research: new guidance needed for a new tool,27 May 2024,/article/10.1007/s43681-024-00493-8,10.1007/s43681-024-00493-8,"David B. Resnik, Mohammad Hosseini",Article,"<jats:title>Abstract</jats:title><jats:p>Using artificial intelligence (AI) in research offers many important benefits for science and society but also creates novel and complex ethical issues. While these ethical issues do not necessitate changing established ethical norms of science, they require the scientific community to develop new guidance for the appropriate use of AI. In this article, we briefly introduce AI and explain how it can be used in research, examine some of the ethical issues raised when using it, and offer nine recommendations for responsible use, including: (1) Researchers are responsible for identifying, describing, reducing, and controlling AI-related biases and random errors; (2) Researchers should disclose, describe, and explain their use of AI in research, including its limitations, in language that can be understood by non-experts; (3) Researchers should engage with impacted communities, populations, and other stakeholders concerning the use of AI in research to obtain their advice and assistance and address their interests and concerns, such as issues related to bias; (4) Researchers who use synthetic data should (a) indicate which parts of the data are synthetic; (b) clearly label the synthetic data; (c) describe how the data were generated; and (d) explain how and why the data were used; (5) AI systems should not be named as authors, inventors, or copyright holders but their contributions to research should be disclosed and described; (6) Education and mentoring in responsible conduct of research should include discussion of ethical use of AI.</jats:p>"
The Impact on Major Industries,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9367-6_8,10.1007/978-1-4842-9367-6_8,Tom Taulli,Chapter,No abstract available for this DOI.
"“The ChatGPT bot is causing panic now – but it’ll soon be as mundane a tool as Excel”: analysing topics, sentiment and emotions relating to ChatGPT on Twitter",21 May 2024,/article/10.1007/s00779-024-01811-x,10.1007/s00779-024-01811-x,"Dan Heaton, Jeremie Clos, ... Joel E. Fischer",Article,"<jats:title>Abstract</jats:title><jats:p>ChatGPT, a sophisticated chatbot system by OpenAI, gained significant attention and adoption in 2022 and 2023. By generating human-like conversations, it attracted over 100 million monthly users; however, there are concerns about the social impact of ChatGPT, including panic, misinformation and ethics. Twitter has become a platform for expressing views on ChatGPT and popular NLP approaches like topic modelling, sentiment analysis and emotion detection are commonly used to study public discourses on Twitter. While these approaches have limitations, an analytical process of existing best practices captures the evolving nature of these views. Previous studies have examined early reactions and topics associated with ChatGPT on Twitter but have not fully explored the combination of topics, sentiment and emotions, nor have they explicitly followed existing best practices. This study provides an overview of the views expressed on Twitter about ChatGPT by analysing 88,058 tweets from November 2022 to March 2023 to see if panic and concern were replicated in Twitter discourses. The topics covered human-like text generation, chatbot development, writing assistance, data training, efficiency, impact on business and cryptocurrency. Overall, the sentiment was predominantly positive, indicating that concerns surrounding ChatGPT were not widely replicated. However, sentiment fluctuated, with a decline observed around the launch of ChatGPT Plus. The discourse saw consistent patterns of trust and fear, with trust maintaining a steady presence until a decline potentially influenced by concerns about biases and misinformation. We discuss how our findings build upon existing research regarding ChatGPT by providing trajectories of topics, sentiment and emotions.</jats:p>"
Comparative Quality Analysis of GPT-Based Multiple Choice Question Generation,2024,https://link.springer.com/chapter/10.1007/978-3-031-46813-1_29,10.1007/978-3-031-46813-1_29,Christian Grévisse,Conference paper,No abstract available for this DOI.
The Use of ChatGPT in Source-Based Writing Tasks,19 June 2024,/article/10.1007/s40593-024-00413-1,10.1007/s40593-024-00413-1,"Christian Tarchi, Alessandra Zappoli, ... Eva Wennås Brante",Article,"<jats:title>Abstract</jats:title><jats:p>ChatGPT, a chatbot based on a Generative Pre-trained Transformer model, can be used as a teaching tool in the educational setting, providing text in an interactive way. However, concerns point out risks and disadvantages, as possible incorrect or irrelevant answers, privacy concerns, and copyright issues. This study aims to categorize the strategies used by undergraduate students completing a source-based writing task (SBW, i.e., written production based on texts previously read) with the help of ChatGPT and their relation to the quality and content of students’ written products. ChatGPT can be educationally useful in SBW tasks, which require the synthesis of information from a text in response to a prompt. SBW requires mastering writing conventions and an accurate understanding of source material. We collected 27 non-expert users of ChatGPT and writers (M<jats:sub>age</jats:sub> = 20.37; SD = 2.17). We administered a sociodemographic questionnaire, an academic writing motivation scale, and a measure of perceived prior knowledge. Participants were given a source-based writing task with access to ChatGPT as external aid. They performed a retrospective think-aloud interview on ChatGPT use. Data showed limited use of ChatGPT due to limited expertise and ethical concerns. The level of integration of conflicting information showed to not be associated with the interaction with ChatGPT. However, the use of ChatGPT showed a negative association with the amount of literal source-text information that students include in their written product.</jats:p>"
Self-agreement: A Framework for Fine-Tuning Language Models to Find Agreement Among Diverse Opinions,2024,https://link.springer.com/chapter/10.1007/978-981-99-7022-3_26,10.1007/978-981-99-7022-3_26,"Shiyao Ding, Takayuki Ito",Conference paper,No abstract available for this DOI.
Unraveling the mysteries of AI chatbots,13 March 2024,/article/10.1007/s10462-024-10720-7,10.1007/s10462-024-10720-7,Raj Bridgelall,Article,"<jats:title>Abstract</jats:title><jats:p>This primer provides an overview of the rapidly evolving field of generative artificial intelligence, specifically focusing on large language models like ChatGPT (OpenAI) and Bard (Google). Large language models have demonstrated unprecedented capabilities in responding to natural language prompts. The aim of this primer is to demystify the underlying theory and architecture of large language models, providing intuitive explanations for a broader audience. Learners seeking to gain insight into the technical underpinnings of large language models must sift through rapidly growing and fragmented literature on the topic. This primer brings all the main concepts into a single digestible document. Topics covered include text tokenization, vocabulary construction, token embedding, context embedding with attention mechanisms, artificial neural networks, and objective functions in model training. The primer also explores state-of-the-art methods in training large language models to generalize on specific applications and to align with human intentions. Finally, an introduction to the concept of prompt engineering highlights the importance of effective human-machine interaction through natural language in harnessing the full potential of artificial intelligence chatbots. This comprehensive yet accessible primer will benefit students and researchers seeking foundational knowledge and a deeper understanding of the inner workings of existing and emerging artificial intelligence models. The author hopes that the primer will encourage further responsible innovation and informed discussions about these increasingly powerful tools.</jats:p>"
FIFAWC: a dataset with detailed annotation and rich semantics for group activity recognition,06 June 2024,/article/10.1007/s11704-024-40027-3,10.1007/s11704-024-40027-3,"Duoxuan Pei, Di Huang, Yunhong Wang",Article,No abstract available for this DOI.
"Artificial thinking and doomsday projections: a discourse on trust, ethics and safety",20 November 2023,/article/10.1007/s00146-023-01810-1,10.1007/s00146-023-01810-1,"Jeffrey White, Dietrich Brandt, ... Larry Stapleton",Article,No abstract available for this DOI.
"On inscription and bias: data, actor network theory, and the social problems of text-to-image AI models",21 February 2024,/article/10.1007/s43681-024-00431-8,10.1007/s43681-024-00431-8,Jorge Luis Morton,Article,No abstract available for this DOI.
Chatbots as Villains: The Antisocial Uses of AI,2024,https://link.springer.com/chapter/10.1007/978-3-031-51004-5_7,10.1007/978-3-031-51004-5_7,Robert Ciesla,Chapter,No abstract available for this DOI.
Evolution Through Large Models,2024,https://link.springer.com/chapter/10.1007/978-981-99-3814-8_11,10.1007/978-981-99-3814-8_11,"Joel Lehman, Jonathan Gordon, ... Kenneth O. Stanley",Chapter,No abstract available for this DOI.
Philosophical and Social Realm,2023,https://link.springer.com/chapter/10.1007/978-3-031-35331-4_2,10.1007/978-3-031-35331-4_2,"Boris Aberšek, Andrej Flogie, Igor Pesek",Chapter,No abstract available for this DOI.
Requirements Engineering for Cyber-Physical Products,2023,https://link.springer.com/chapter/10.1007/978-3-031-42307-9_23,10.1007/978-3-031-42307-9_23,"Thomas Fehlmann, Eberhard Kranich",Conference paper,No abstract available for this DOI.
What do academics have to say about ChatGPT? A text mining analytics on the discussions regarding ChatGPT on research writing,23 October 2023,/article/10.1007/s43681-023-00354-w,10.1007/s43681-023-00354-w,Rex Bringula,Article,No abstract available for this DOI.
How Can Natural Language Processing and Generative AI Address Grand Challenges of Quantitative User Personas?,2023,https://link.springer.com/chapter/10.1007/978-3-031-48057-7_14,10.1007/978-3-031-48057-7_14,"Joni Salminen, Soon-gyo Jung, ... Bernard Jansen",Conference paper,No abstract available for this DOI.
"A phenomenology and epistemology of large language models: transparency, trust, and trustworthiness",18 June 2024,/article/10.1007/s10676-024-09777-3,10.1007/s10676-024-09777-3,"Richard Heersmink, Barend de Rooij, ... Matteo Colombo",Article,"<jats:title>Abstract</jats:title><jats:p>This paper analyses the phenomenology and epistemology of chatbots such as ChatGPT and Bard. The computational architecture underpinning these chatbots are large language models (LLMs), which are generative artificial intelligence (AI) systems trained on a massive dataset of text extracted from the Web. We conceptualise these LLMs as multifunctional computational cognitive artifacts, used for various cognitive tasks such as translating, summarizing, answering questions, information-seeking, and much more. Phenomenologically, LLMs can be experienced as a “quasi-other”; when that happens, users anthropomorphise them. For most users, current LLMs are black boxes, i.e., for the most part, they lack data transparency and algorithmic transparency. They can, however, be phenomenologically and informationally transparent, in which case there is an interactional flow. Anthropomorphising and interactional flow can, in some users, create an attitude of (unwarranted) trust towards the output LLMs generate. We conclude this paper by drawing on the epistemology of trust and testimony to examine the epistemic implications of these dimensions. Whilst LLMs generally generate accurate responses, we observe two epistemic pitfalls. Ideally, users should be able to match the level of trust that they place in LLMs to the degree that LLMs are trustworthy. However, both their data and algorithmic opacity and their phenomenological and informational transparency can make it difficult for users to calibrate their trust correctly. The effects of these limitations are twofold: users may adopt unwarranted attitudes of trust towards the outputs of LLMs (which is particularly problematic when LLMs hallucinate), and the trustworthiness of LLMs may be undermined.</jats:p>"
Optimized BERT Model for Question Answering System on Mobile Platform,2024,https://link.springer.com/chapter/10.1007/978-3-031-58495-4_9,10.1007/978-3-031-58495-4_9,"Priyadarshini Patil, Chandan Rao, S. M. Meena",Conference paper,No abstract available for this DOI.
Getting it right: the limits of fine-tuning large language models,31 May 2024,/article/10.1007/s10676-024-09779-1,10.1007/s10676-024-09779-1,Jacob Browning,Article,No abstract available for this DOI.
"ChatGPT: potential, prospects, and limitations",28 February 2023,/article/10.1631/FITEE.2300089,10.1631/FITEE.2300089,"Jie Zhou, Pei Ke, ... Junping Zhang",Article,No abstract available for this DOI.
Generative AI as a Supportive Tool for Scientific Research,2024,https://link.springer.com/chapter/10.1007/978-3-031-46238-2_1,10.1007/978-3-031-46238-2_1,Abraham Itzhak Weinberg,Chapter,No abstract available for this DOI.
Application of Large Language Models to DDoS Attack Detection,2024,https://link.springer.com/chapter/10.1007/978-3-031-51630-6_6,10.1007/978-3-031-51630-6_6,"Michael Guastalla, Yiyi Li, ... Bhaskar Krishnamachari",Conference paper,No abstract available for this DOI.
Assessing and Enhancing LLMs: A Physics and History Dataset and One-More-Check Pipeline Method,2024,https://link.springer.com/chapter/10.1007/978-981-99-8178-6_38,10.1007/978-981-99-8178-6_38,"Chaofan He, Chunhui Li, ... Liping Shen",Conference paper,No abstract available for this DOI.
@llegra: a chatbot for Vallader,19 February 2024,/article/10.1007/s41870-024-01779-0,10.1007/s41870-024-01779-0,"Oliver Bendel, Dalil Jabou",Article,"<jats:title>Abstract</jats:title><jats:p>Extinct and endangered languages have been preserved primarily through audio conservation and the collection and digitization of scripts and have been promoted through targeted language acquisition efforts. Another possibility would be to build conversational agents like chatbots or voice assistants that can master these languages. This would provide an artificial, active conversational partner which has knowledge of the vocabulary and grammar and allows one to learn with it in a different way. The chatbot, @llegra, with which one can communicate in the Rhaeto-Romanic idiom Vallader was developed in 2023 based on GPT-4. It can process and output text and has voice output. It was additionally equipped with a manually created knowledge base. After laying the conceptual groundwork, this paper presents the preparation and implementation of the project. In addition, it summarizes the tests that native speakers conducted with the chatbot. A critical discussion elaborates advantages and disadvantages. @llegra could be a new tool for teaching and learning Vallader in a memorable and entertaining way through dialog. It not only masters the idiom, but also has extensive knowledge about the Lower Engadine, that is, the area where Vallader is spoken. In conclusion, it is argued that conversational agents are an innovative approach to promoting and preserving languages.</jats:p>"
Knowledge Sources,2024,https://link.springer.com/chapter/10.1007/978-981-97-0747-8_2,10.1007/978-981-97-0747-8_2,"Meng Jiang, Bill Yuchen Lin, ... Chenguang Zhu",Chapter,No abstract available for this DOI.
Computational Approaches for Traditional Chinese Painting: From the “Six Principles of Painting” Perspective,01 March 2024,/article/10.1007/s11390-024-3408-x,10.1007/s11390-024-3408-x,"Wei Zhang, Jian-Wei Zhang, ... Wei Chen",Article,No abstract available for this DOI.
"Conversational Process Modelling: State of the Art, Applications, and Implications in Practice",2023,https://link.springer.com/chapter/10.1007/978-3-031-41623-1_19,10.1007/978-3-031-41623-1_19,"Nataliia Klievtsova, Janik-Vasily Benzin, ... Stefanie Rinderle-Ma",Conference paper,No abstract available for this DOI.
Constructing a teacher portrait for the artificial intelligence age based on the micro ecological system theory: A systematic review,14 February 2024,/article/10.1007/s10639-024-12513-5,10.1007/s10639-024-12513-5,"Xiaoyong Hu, Hui Sui, ... Li Zhao",Article,No abstract available for this DOI.
Beware of sustainable AI! Uses and abuses of a worthy goal,02 February 2023,/article/10.1007/s43681-023-00259-8,10.1007/s43681-023-00259-8,"Jan-Christoph Heilinger, Hendrik Kempt, Saskia Nagel",Article,"<jats:title>Abstract</jats:title><jats:p>The ethical debate about technologies called artificial intelligence (AI) has recently turned towards the question whether and in which sense using AI can be sustainable, distinguishing possible contributions of AI to achieve the end of sustainability on the one hand from the sustainability of AI and its underlying technologies as means on the other hand. This important distinction is both applied in the context of environmental as well as social sustainability. However, further elaboration is necessary to capture the complexities of sustainability assessments in the context of AI. To this end, our analysis of the ends and means of “sustainable AI” in social and environmental contexts leads to a matrix of four dimensions reflecting its social and its environmental impact and costs. This matrix avoids overly narrow, one-dimensional assessments that too quickly label some AI-based technology as sustainable. While a selective assessment can, at best, warrant the narrower verdict of “thin” sustainability, only such a comprehensive assessment can warrant the verdict of what we call “thick” sustainability. In consequence, we recommend to broaden the normative scope in considering the ethics and justice of AI and to use the notion “sustainability” more carefully and sparingly, and to pursue the more ambitious goal of “thick” sustainability of AI-based technologies to meaningfully contribute to actual improvements of human lives and living together. Current conditions of an economy oriented towards permanent growth, however, may make it difficult or even impossible to realise sustainable AI.</jats:p>"
Automated Program Repair Using Generative Models for Code Infilling,2023,https://link.springer.com/chapter/10.1007/978-3-031-36272-9_74,10.1007/978-3-031-36272-9_74,"Charles Koutcheme, Sami Sarsa, ... Paul Denny",Conference paper,No abstract available for this DOI.
"Threats, Opportunities, and Misconceptions",2023,https://link.springer.com/chapter/10.1007/979-8-8688-0017-7_6,10.1007/979-8-8688-0017-7_6,Thimira Amaratunga,Chapter,No abstract available for this DOI.
Safeguarding human values: rethinking US law for generative AI’s societal impacts,07 May 2024,/article/10.1007/s43681-024-00451-4,10.1007/s43681-024-00451-4,"Inyoung Cheong, Aylin Caliskan, Tadayoshi Kohno",Article,"<jats:title>Abstract</jats:title><jats:p>Our interdisciplinary study examines the effectiveness of US law in addressing the complex challenges posed by generative AI systems to fundamental human values, including physical and mental well-being, privacy, autonomy, diversity, and equity. Through the analysis of diverse hypothetical scenarios developed in collaboration with experts, we identified significant shortcomings and ambiguities within the existing legal protections. Constitutional and civil rights law currently struggles to hold AI companies responsible for AI-assisted discriminatory outputs. Moreover, even without considering the liability shield provided by Section 230, existing liability laws may not effectively remedy unintentional and intangible harms caused by AI systems. Demonstrating causal links for liability claims such as defamation or product liability proves exceptionally difficult due to the intricate and opaque nature of these systems. To effectively address these unique and evolving risks posed by generative AI, we propose a “Responsible AI Legal Framework”  that adapts to recognize new threats and utilizes a multi-pronged approach. This framework would enshrine fundamental values in legal frameworks, establish comprehensive safety guidelines, and implement liability models tailored to the complexities of human-AI interactions. By proactively mitigating unforeseen harms like mental health impacts and privacy breaches, this framework aims to create a legal landscape capable of navigating the exciting yet precarious future brought forth by generative AI technologies.</jats:p>"
Support to Interaction Between Medical Practitioners and Patients: A Systematic Review,2024,https://link.springer.com/chapter/10.1007/978-3-031-56396-6_24,10.1007/978-3-031-56396-6_24,"Ezekiel Olayide Tolulope, Franklin Tchakounte",Conference paper,No abstract available for this DOI.
The impact of ChatGPT on L2 writing and expected responses: Voice from doctoral students,12 December 2023,/article/10.1007/s10639-023-12397-x,10.1007/s10639-023-12397-x,"Min Zou, Liang Huang",Article,No abstract available for this DOI.
Analyzing the Innovative Potential of Texts Generated by Large Language Models: An Empirical Evaluation,2023,https://link.springer.com/chapter/10.1007/978-3-031-39689-2_2,10.1007/978-3-031-39689-2_2,"Oliver Krauss, Michaela Jungwirth, ... Andreas Stoeckl",Conference paper,No abstract available for this DOI.
The Transformation of Business,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9367-6_7,10.1007/978-1-4842-9367-6_7,Tom Taulli,Chapter,No abstract available for this DOI.
Creating Automatic Connections for Personal Knowledge Management,08 May 2024,/article/10.1007/s42979-024-02876-4,10.1007/s42979-024-02876-4,"Felipe Poggi A. Fraga, Marcus Poggi, ... Luiz André P. Paes Leme",Article,No abstract available for this DOI.
Exploring differences in ethical decision-making processes between humans and ChatGPT-3 model: a study of trade-offs,04 September 2023,/article/10.1007/s43681-023-00335-z,10.1007/s43681-023-00335-z,"Umair Rehman, Farkhund Iqbal, Muhammad Umair Shah",Article,No abstract available for this DOI.
Interpretable Dropout Prediction: Towards XAI-Based Personalized Intervention,14 March 2023,/article/10.1007/s40593-023-00331-8,10.1007/s40593-023-00331-8,"Marcell Nagy, Roland Molontay",Article,"<jats:title>Abstract</jats:title><jats:p>Student drop-out is one of the most burning issues in STEM higher education, which induces considerable social and economic costs. Using machine learning tools for the early identification of students at risk of dropping out has gained a lot of interest recently. However, there has been little discussion on dropout prediction using interpretable machine learning (IML) and explainable artificial intelligence (XAI) tools.In this work, using the data of a large public Hungarian university, we demonstrate how IML and XAI tools can support educational stakeholders in dropout prediction. We show that complex machine learning models – such as the CatBoost classifier – can efficiently identify at-risk students relying solely on pre-enrollment achievement measures, however, they lack interpretability. Applying IML tools, such as permutation importance (PI), partial dependence plot (PDP), LIME, and SHAP values, we demonstrate how the predictions can be explained both globally and locally. Explaining individual predictions opens up great opportunities for personalized intervention, for example by offering the right remedial courses or tutoring sessions. Finally, we present the results of a user study that evaluates whether higher education stakeholders find these tools interpretable and useful.</jats:p>"
Machine learning in human creativity: status and perspectives,12 January 2024,/article/10.1007/s00146-023-01836-5,10.1007/s00146-023-01836-5,"Mirko Farina, Andrea Lavazza, ... Witold Pedrycz",Article,No abstract available for this DOI.
Student Opinion Mining About Instructor Using Optimized Ensemble Machine Learning Model and Feature Fusion,25 June 2024,/article/10.1007/s42979-024-03032-8,10.1007/s42979-024-03032-8,"Ravinder Ahuja, S. C. Sharma",Article,No abstract available for this DOI.
The Economics of Generative AI,2024,https://link.springer.com/chapter/10.1007/978-3-031-46238-2_25,10.1007/978-3-031-46238-2_25,Stanislav Ivanov,Chapter,No abstract available for this DOI.
The Future of Humans and Language Models,2023,https://link.springer.com/chapter/10.1007/978-3-031-37690-0_7,10.1007/978-3-031-37690-0_7,Mascha Kurpicz-Briki,Chapter,No abstract available for this DOI.
Conversational Systems for AI-Augmented Business Process Management,2024,https://link.springer.com/chapter/10.1007/978-3-031-59465-6_12,10.1007/978-3-031-59465-6_12,"Angelo Casciani, Mario L. Bernardi, ... Andrea Marrella",Conference paper,No abstract available for this DOI.
"Generative AI for pentesting: the good, the bad, the ugly",15 March 2024,/article/10.1007/s10207-024-00835-x,10.1007/s10207-024-00835-x,"Eric Hilario, Sami Azam, ... Bharanidharan Shanmugam",Article,"<jats:title>Abstract</jats:title><jats:p>This paper examines the role of Generative AI (GenAI) and Large Language Models (LLMs) in penetration testing exploring the benefits, challenges, and risks associated with cyber security applications. Through the use of generative artificial intelligence, penetration testing becomes more creative, test environments are customised, and continuous learning and adaptation is achieved. We examined how GenAI (ChatGPT 3.5) helps penetration testers with options and suggestions during the five stages of penetration testing. The effectiveness of the GenAI tool was tested using a publicly available vulnerable machine from VulnHub. It was amazing how quickly they responded at each stage and provided better pentesting report. In this article, we discuss potential risks, unintended consequences, and uncontrolled AI development associated with pentesting.</jats:p>"
A Software Platform for Evaluating Student Essays in Interdisciplinary Learning with Topic Classification Techniques,2023,https://link.springer.com/chapter/10.1007/978-3-031-36336-8_100,10.1007/978-3-031-36336-8_100,"Bryan Lim Cheng Yee, Chenyu Hou, ... Xiuyi Fan",Conference paper,No abstract available for this DOI.
"The imitation game, the “child machine,” and the fathers of AI",25 June 2022,/article/10.1007/s00146-022-01512-0,10.1007/s00146-022-01512-0,Teresa Heffernan,Article,No abstract available for this DOI.
Acceptance of Generative AI in the Creative Industry: Examining the Role of AI Anxiety in the UTAUT2 Model,2023,https://link.springer.com/chapter/10.1007/978-3-031-48057-7_18,10.1007/978-3-031-48057-7_18,"Ming Yin, Bingxu Han, ... Min Hua",Conference paper,No abstract available for this DOI.
Data cleaning and machine learning: a systematic literature review,11 June 2024,/article/10.1007/s10515-024-00453-w,10.1007/s10515-024-00453-w,"Pierre-Olivier Côté, Amin Nikanjam, ... Foutse Khomh",Article,No abstract available for this DOI.
Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification,2023,https://link.springer.com/chapter/10.1007/978-3-031-35320-8_1,10.1007/978-3-031-35320-8_1,"Benjamin Clavié, Alexandru Ciceu, ... Thomas Brightwell",Conference paper,No abstract available for this DOI.
"Prolog: Past, Present, and Future",2023,https://link.springer.com/chapter/10.1007/978-3-031-35254-6_4,10.1007/978-3-031-35254-6_4,"Gopal Gupta, Elmer Salazar, ... Manuel Carro",Chapter,No abstract available for this DOI.
Fundamentals of Natural Language Processing,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9221-1_5,10.1007/978-1-4842-9221-1_5,Krunal S. Trivedi,Chapter,No abstract available for this DOI.
From nCoder to ChatGPT: From Automated Coding to Refining Human Coding,2023,https://link.springer.com/chapter/10.1007/978-3-031-47014-1_32,10.1007/978-3-031-47014-1_32,"Andres Felipe Zambrano, Xiner Liu, ... Nidhi Nasiar",Conference paper,No abstract available for this DOI.
State of the Art of Machine Learning,2024,https://link.springer.com/chapter/10.1007/978-3-031-46990-9_7,10.1007/978-3-031-46990-9_7,Eklas Hossain,Chapter,No abstract available for this DOI.
At the intersection of humanity and technology: a technofeminist intersectional critical discourse analysis of gender and race biases in the natural language processing model GPT-3,25 November 2023,/article/10.1007/s00146-023-01804-z,10.1007/s00146-023-01804-z,"M. A. Palacios Barea, D. Boeren, J. F. Ferreira Goncalves",Article,"<jats:title>Abstract</jats:title><jats:p>Algorithmic biases, or algorithmic unfairness, have been a topic of public and scientific scrutiny for the past years, as increasing evidence suggests the pervasive assimilation of human cognitive biases and stereotypes in such systems. This research is specifically concerned with analyzing the presence of discursive biases in the text generated by GPT-3, an NLPM which has been praised in recent years for resembling human language so closely that it is becoming difficult to differentiate between the human and the algorithm. The pertinence of this research object is substantiated by the identification of race, gender and religious biases in the model’s completions in recent research, suggesting that the model is indeed heavily influenced by human cognitive biases. To this end, this research inquires: <jats:italic>How does the Natural Language Processing Model GPT-3 replicate existing social biases?.</jats:italic> This question is addressed through the scrutiny of GPT-3’s completions using Critical Discourse Analysis (CDA), a method which has been deemed as amply valuable for this research as it is aimed at uncovering power asymmetries in language. As such, the analysis is specifically centered around the analysis of gender and race biases in the model’s generated text. Research findings suggest that GPT-3’s language generation model significantly exacerbates existing social biases while replicating dangerous ideologies akin to white supremacy and hegemonic masculinity as factual knowledge.</jats:p>"
Prompting meaning: a hermeneutic approach to optimising prompt engineering with ChatGPT,04 September 2023,/article/10.1007/s00146-023-01752-8,10.1007/s00146-023-01752-8,"Leah Henrickson, Albert Meroño-Peñuela",Article,"<jats:title>Abstract</jats:title><jats:p>Recent advances in natural language generation (NLG), such as public accessibility to ChatGPT, have sparked polarised debates about the societal impact of this technology. Popular discourse tends towards either overoptimistic hype that touts the radically transformative potentials of these systems or pessimistic critique of their technical limitations and general ‘stupidity’. Surprisingly, these debates have largely overlooked the exegetical capacities of these systems, which for many users seem to be producing meaningful texts. In this paper, we take an interdisciplinary approach that combines hermeneutics—the study of meaning and interpretation—with prompt engineering—task descriptions embedded in input to NLG systems—to study the extent to which a specific NLG system, ChatGPT, produces texts of hermeneutic value. We design prompts with the goal of optimising hermeneuticity rather than mere factual accuracy, and apply them in four different use cases combining humans and ChatGPT as readers and writers. In most cases, ChatGPT produces readable texts that respond clearly to our requests. However, increasing the specificity of prompts’ task descriptions leads to texts with intensified neutrality, indicating that ChatGPT’s optimisation for factual accuracy may actually be detrimental to the hermeneuticity of its output.</jats:p>"
Prompting meaning: a hermeneutic approach to optimising prompt engineering with ChatGPT,04 September 2023,/article/10.1007/s00146-023-01752-8,10.1007/s00146-023-01752-8,"Leah Henrickson, Albert Meroño-Peñuela",Article,"<jats:title>Abstract</jats:title><jats:p>Recent advances in natural language generation (NLG), such as public accessibility to ChatGPT, have sparked polarised debates about the societal impact of this technology. Popular discourse tends towards either overoptimistic hype that touts the radically transformative potentials of these systems or pessimistic critique of their technical limitations and general ‘stupidity’. Surprisingly, these debates have largely overlooked the exegetical capacities of these systems, which for many users seem to be producing meaningful texts. In this paper, we take an interdisciplinary approach that combines hermeneutics—the study of meaning and interpretation—with prompt engineering—task descriptions embedded in input to NLG systems—to study the extent to which a specific NLG system, ChatGPT, produces texts of hermeneutic value. We design prompts with the goal of optimising hermeneuticity rather than mere factual accuracy, and apply them in four different use cases combining humans and ChatGPT as readers and writers. In most cases, ChatGPT produces readable texts that respond clearly to our requests. However, increasing the specificity of prompts’ task descriptions leads to texts with intensified neutrality, indicating that ChatGPT’s optimisation for factual accuracy may actually be detrimental to the hermeneuticity of its output.</jats:p>"
Opposing agents evolve the research: a decade of digital forensics,11 June 2024,/article/10.1007/s11042-024-19519-8,10.1007/s11042-024-19519-8,"Raghu Raman, Aditya Kumar Sahu, ... Prema Nedungadi",Article,No abstract available for this DOI.
Enhancing academic performance prediction with temporal graph networks for massive open online courses,13 April 2024,/article/10.1186/s40537-024-00918-5,10.1186/s40537-024-00918-5,"Qionghao Huang, Jili Chen",Article,"<jats:title>Abstract</jats:title><jats:p>Educational big data significantly impacts education, and Massive Open Online Courses (MOOCs), a crucial learning approach, have evolved to be more intelligent with these technologies. Deep neural networks have significantly advanced the crucial task within MOOCs, predicting student academic performance. However, most deep learning-based methods usually ignore the temporal information and interaction behaviors during the learning activities, which can effectively enhance the model’s predictive accuracy. To tackle this, we formulate the learning processes of e-learning students as dynamic temporal graphs to encode the temporal information and interaction behaviors during their studying. We propose a novel academic performance prediction model (APP-TGN) based on temporal graph neural networks. Specifically, in APP-TGN, a dynamic graph is constructed from online learning activity logs. A temporal graph network with low-high filters learns potential academic performance variations encoded in dynamic graphs. Furthermore, a global sampling module is developed to mitigate the problem of false correlations in deep learning-based models. Finally, multi-head attention is utilized for predicting academic outcomes. Extensive experiments are conducted on a well-known public dataset. The experimental results indicate that APP-TGN significantly surpasses existing methods and demonstrates excellent potential in automated feedback and personalized learning.</jats:p>"
"Chatgpt for cybersecurity: practical applications, challenges, and future directions",24 August 2023,/article/10.1007/s10586-023-04124-5,10.1007/s10586-023-04124-5,"Muna Al-Hawawreh, Ahamed Aljuhani, Yaser Jararweh",Article,No abstract available for this DOI.
Panda3D,2023,https://link.springer.com/chapter/10.1007/978-3-319-08234-9_535-1,10.1007/978-3-319-08234-9_535-1,Elif Surer,Living reference work entry,No abstract available for this DOI.
Predictive analysis visualization component in simulated data streams,14 June 2024,/article/10.1007/s10791-024-09447-4,10.1007/s10791-024-09447-4,"Adam Dudáš, Daniel Demian",Article,"<jats:title>Abstract</jats:title><jats:p>One of the most significant problems related to Big Data is their analysis with the use of various methods from the area of descriptive statistics or machine and deep learning. This process is interesting in both—static datasets containing various data sources which do not change over time, and dynamic datasets collected with the use of ambient data sources, which measure a number of attribute values over long periods. Since access to actual dynamic data systems is demanding, the focus of this work is put on the design and implementation of a framework usable in a simulation of data streams, their processing and subsequent dynamic predictive and visual analysis. The proposed system is experimentally verified in the context of a case study conducted on an environmental variable dataset, which was measured with the use of a real-life sensor network.</jats:p>"
Challenges as catalysts: how Waymo’s Open Dataset Challenges shape AI development,17 April 2024,/article/10.1007/s00146-024-01927-x,10.1007/s00146-024-01927-x,"Sam Hind, Fernando N. van der Vlist, Max Kanderske",Article,"<jats:title>Abstract</jats:title><jats:p>Artificial intelligence (AI) and machine learning (ML) are becoming increasingly significant areas of research for scholars in science and technology studies (STS) and media studies. In March 2020, Waymo, Google/Alphabet’s autonomous vehicle project, introduced the ‘Open Dataset Virtual Challenge’, an annual competition leveraging their Waymo Open Dataset. This freely accessible dataset comprises annotated autonomous vehicle data from their own Waymo vehicles. Yearly, Waymo has continued to host iterations of this challenge, inviting teams of computer scientists to tackle evolving machine learning and vision problems using Google's data and tools. This article analyses these challenges, situating them within the context of the ‘Grand Challenges’ of artificial intelligence (AI), which aimed to foster accountable and commercially viable advancements in the late 1980s. Through two exploratory workshops, we adopted a ‘technographic’ approach to examine the pivotal role of challenges in the development and political economy of AI. Serving as an organising principle for the AI innovation ecosystem, the challenge connects companies and external collaborators, driving advancements in specific machine vision domains. By exploring six key themes—interface methods, incrementalism, metrics, AI vernacular, applied domains, and competitive advantages—the article illustrates the role of these challenges in shaping AI research and development. By unpacking the dynamic interaction between data, computation, and labour, these challenges serve as catalysts propelling advancements towards self-driving technologies. The study reveals how challenges have historically and presently shaped the evolving landscape of self-driving and AI technologies.</jats:p>"
Learner Models for MOOC in a Lifelong Learning Context: A Systematic Literature Review,2021,https://link.springer.com/chapter/10.1007/978-3-030-86439-2_20,10.1007/978-3-030-86439-2_20,"Sergio Iván Ramírez Luelmo, Nour El Mawas, Jean Heutte",Conference paper,No abstract available for this DOI.
BiMuF: a bi-directional recommender system with multi-semantic filter for online recruitment,17 October 2023,/article/10.1007/s10115-023-01997-1,10.1007/s10115-023-01997-1,"Pei-Yuan Lai, Zhe-Rui Yang, ... Chang-Dong Wang",Article,No abstract available for this DOI.
The mechanisms of AI hype and its planetary and social costs,02 April 2024,/article/10.1007/s43681-024-00461-2,10.1007/s43681-024-00461-2,"Alva Markelius, Connor Wright, ... Yu-Ting Kuo",Article,"<jats:title>Abstract</jats:title><jats:p>Our global landscape of emerging technologies is increasingly affected by artificial intelligence (AI) hype, a phenomenon with significant large-scale consequences for the global AI narratives being created today. This paper aims to dissect the phenomenon of AI hype in light of its core mechanisms, drawing comparisons between the current wave and historical episodes of AI hype, concluding that the current hype is historically unmatched in terms of magnitude, scale and planetary and social costs. We identify and discuss socio-technical mechanisms fueling AI hype, including anthropomorphism, the proliferation of self-proclaimed AI “experts”, the geopolitical and private sector “fear of missing out” trends and the overuse and misappropriation of the term “AI” in emerging technologies. The second part of the paper seeks to highlight the often-overlooked costs of the current AI hype. We examine its planetary costs as the AI hype exerts tremendous pressure on finite resources and energy consumption. Additionally, we focus on the connection between AI hype and socio-economic injustices, including perpetuation of social inequalities by the huge associated redistribution of wealth and costs to human intelligence. In the conclusion, we offer insights into the implications for how to mitigate AI hype moving forward. We give recommendations of how developers, regulators, deployers and the public can navigate the relationship between AI hype, innovation, investment and scientific exploration, while addressing critical societal and environmental challenges.</jats:p>"
Engaging the many-hands problem of generative-AI outputs: a framework for attributing credit,11 March 2024,/article/10.1007/s43681-024-00440-7,10.1007/s43681-024-00440-7,"Donal Khosrowi, Finola Finn, Elinor Clark",Article,"<jats:title>Abstract</jats:title><jats:p>The recent wave of generative AI (GenAI) systems like Stable Diffusion or ChatGPT that can produce images, text and code from human prompts raises controversial issues about creatorship, originality, creativity and copyright. This paper focuses on creatorship: who creates and should be credited with the outputs made with the help of GenAI? There is currently significant moral, legal and regulatory uncertainty around these questions. We develop a novel framework, called CCC (collective-centered creation), that helps resolve this uncertainty. According to CCC, GenAI outputs are created by collectives in the first instance. Claims to creatorship come in degrees and depend on the nature and significance of individual contributions made by the various agents and entities involved, including users, GenAI systems, developers, producers of training data and others. We demonstrate how CCC can help navigate a range of ongoing controversies around the responsible development and deployment of GenAI technologies and help more accurately attribute credit where it is due.</jats:p>"
Analyzing the impact of companies on AI research based on publications,24 November 2023,/article/10.1007/s11192-023-04867-3,10.1007/s11192-023-04867-3,"Michael Färber, Lazaros Tampakis",Article,"<jats:title>Abstract</jats:title><jats:p>Artificial Intelligence (AI) is one of the most momentous technologies of our time. Thus, it is of major importance to know which stakeholders influence AI research. Besides researchers at universities and colleges, researchers in companies have hardly been considered in this context. In this article, we consider how the influence of companies on AI research can be made measurable on the basis of scientific publishing activities. We compare academic- and company-authored AI publications published in the last decade and use scientometric data from multiple scholarly databases to look for differences across these groups and to disclose the top contributing organizations. While the vast majority of publications is still produced by academia, we find that the citation count an individual publication receives is significantly higher when it is (co–)authored by a company. Furthermore, using a variety of altmetric indicators, we notice that publications with company participation receive considerably more attention online. Finally, we place our analysis results in a broader context and present targeted recommendations to safeguard a harmonious balance between academia and industry in the realm of AI research.</jats:p>"
Identifying missing data handling methods with text mining,17 June 2024,/article/10.1007/s41060-024-00582-1,10.1007/s41060-024-00582-1,"Krisztián Boros, Zoltán Kmetty",Article,"<jats:title>Abstract</jats:title><jats:p>Missing data is an inevitable aspect of every empirical research. Researchers developed several techniques to handle missing data to avoid information loss and biases. Over the past 50 years, these methods have become more and more efficient and also more complex. Building on previous review studies, this paper aims to analyze what kind of missing data handling methods are used among various scientific disciplines. For the analysis, we used nearly 50.000 scientific articles published between 1999 and 2016. JSTOR provided the data in text format. We utilized a text-mining approach to extract the necessary information from our corpus. Our results show that the usage of advanced missing data handling methods, such as Multiple Imputation or Full Information Maximum Likelihood estimation, is steadily growing in the examination period. Additionally, simpler methods, like listwise and pairwise deletion, are still in widespread use.</jats:p>"
ChatGPT: towards AI subjectivity,09 April 2024,/article/10.1007/s00146-024-01898-z,10.1007/s00146-024-01898-z,Kristian D’Amato,Article,"<jats:title>Abstract</jats:title><jats:p>Motivated by the question of responsible AI and value alignment, I seek to offer a uniquely Foucauldian reconstruction of the problem as the emergence of an ethical subject in a disciplinary setting. This reconstruction contrasts with the strictly human-oriented programme typical to current scholarship that often views technology in instrumental terms. With this in mind, I problematise the concept of a technological subjectivity through an exploration of various aspects of ChatGPT in light of Foucault’s work, arguing that current systems lack the reflexivity and self-formative characteristics inherent in the notion of the subject. By drawing upon a recent dialogue between Foucault and phenomenology, I suggest four techno-philosophical desiderata that would address the gaps in this search for a technological subjectivity: <jats:italic>embodied self-care, embodied intentionality, imagination and reflexivity</jats:italic>. Thus I propose that advanced AI be reconceptualised as a subject capable of “technical” self-crafting and reflexive self-conduct, opening new pathways to grasp the intertwinement of the human and the artificial. This reconceptualisation holds the potential to render future AI technology more transparent and responsible in the circulation of knowledge, care and power.</jats:p>"
Understanding AI,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9852-7_7,10.1007/978-1-4842-9852-7_7,Tom Taulli,Chapter,No abstract available for this DOI.
Similarity-driven and task-driven models for diversity of opinion in crowdsourcing markets,17 May 2024,/article/10.1007/s00778-024-00853-0,10.1007/s00778-024-00853-0,"Chen Jason Zhang, Yunrui Liu, ... Fei Hao",Article,No abstract available for this DOI.
Summary,2024,https://link.springer.com/chapter/10.1007/978-3-031-55225-0_9,10.1007/978-3-031-55225-0_9,Grzegorz Chodak,Chapter,No abstract available for this DOI.
Enhancing BERT-Based Language Model for Multi-label Vulnerability Detection of Smart Contract in Blockchain,24 June 2024,/article/10.1007/s10922-024-09832-w,10.1007/s10922-024-09832-w,"Van Tong, Cuong Dao, ... Sami Souihi",Article,No abstract available for this DOI.
Future Trends in AI and Its Considerations for Business,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9669-1_23,10.1007/978-1-4842-9669-1_23,Francisco Javier Campos Zabala,Chapter,No abstract available for this DOI.
Understanding ChatGPT’s Underlying Technology,2023,https://link.springer.com/chapter/10.1007/979-8-8688-0032-0_2,10.1007/979-8-8688-0032-0_2,Charles Waghmare,Chapter,No abstract available for this DOI.
"Exploring contactless techniques in multimodal emotion recognition: insights into diverse applications, challenges, solutions, and prospects",06 April 2024,/article/10.1007/s00530-024-01302-2,10.1007/s00530-024-01302-2,"Umair Ali Khan, Qianru Xu, ... Janne Kauttonen",Article,"<jats:title>Abstract</jats:title><jats:p>In recent years, emotion recognition has received significant attention, presenting a plethora of opportunities for application in diverse fields such as human–computer interaction, psychology, and neuroscience, to name a few. Although unimodal emotion recognition methods offer certain benefits, they have limited ability to encompass the full spectrum of human emotional expression. In contrast, Multimodal Emotion Recognition (MER) delivers a more holistic and detailed insight into an individual's emotional state. However, existing multimodal data collection approaches utilizing contact-based devices hinder the effective deployment of this technology. We address this issue by examining the potential of contactless data collection techniques for MER. In our tertiary review study, we highlight the unaddressed gaps in the existing body of literature on MER. Through our rigorous analysis of MER studies, we identify the modalities, specific cues, open datasets with contactless cues, and unique modality combinations. This further leads us to the formulation of a comparative schema for mapping the MER requirements of a given scenario to a specific modality combination. Subsequently, we discuss the implementation of Contactless Multimodal Emotion Recognition (CMER) systems in diverse use cases with the help of the comparative schema which serves as an evaluation blueprint. Furthermore, this paper also explores ethical and privacy considerations concerning the employment of contactless MER and proposes the key principles for addressing ethical and privacy concerns. The paper further investigates the current challenges and future prospects in the field, offering recommendations for future research and development in CMER. Our study serves as a resource for researchers and practitioners in the field of emotion recognition, as well as those intrigued by the broader outcomes of this rapidly progressing technology.</jats:p>"
Public perception of generative AI on Twitter: an empirical study based on occupation and usage,08 January 2024,/article/10.1140/epjds/s13688-023-00445-y,10.1140/epjds/s13688-023-00445-y,"Kunihiro Miyazaki, Taichi Murayama, ... Haewoon Kwak",Article,"<jats:title>Abstract</jats:title><jats:p>The emergence of generative AI has sparked substantial discussions, with the potential to have profound impacts on society in all aspects. As emerging technologies continue to advance, it is imperative to facilitate their proper integration into society, managing expectations and fear. This paper investigates users’ perceptions of generative AI using 3M posts on Twitter from January 2019 to March 2023, especially focusing on their occupation and usage. We find that people across various occupations, not just IT-related ones, show a strong interest in generative AI. The sentiment toward generative AI is generally positive, and remarkably, their sentiments are positively correlated with their exposure to AI. Among occupations, illustrators show exceptionally negative sentiment mainly due to concerns about the unethical usage of artworks in constructing AI. People use ChatGPT in diverse ways, and notably the casual usage in which they “play with” ChatGPT tends to be associated with positive sentiments. These findings would offer valuable lessons for policymaking on the emergence of new technology and also empirical insights for the considerations of future human-AI symbiosis.</jats:p>"
Examining Ethical and Social Implications of Digital Mental Health Technologies Through Expert Interviews and Sociotechnical Systems Theory,31 May 2024,/article/10.1007/s44206-024-00110-5,10.1007/s44206-024-00110-5,Jonathan Adams,Article,"<jats:title>Abstract</jats:title><jats:p>This paper aims to understand how science and technology experts working in the digital mental health field interpret the ethical and social implications of its technologies, combining an ‘expert interview’ methodology with insights from sociotechnical systems theory. Following recruitment of experts in science and technology fields who had experience of supporting the development of DMH interventions, 11 semi-structured interviews were conducted and analyzed in accordance with the Framework Method. A single theme of ‘complexity of implications’ is presented here and divided into the categories of ‘implications for users’, ‘implications for healthcare professionals and systems’, and ‘implications for society’. Participants identified a range of ethical and social implications of digital mental health technologies at the three different levels, which this discussion relates to three key aspects of complex sociotechnical systems identified in existing theoretical work. These are ‘heterogeneity’, ‘interdependence’ and ‘distribution’, each of which raises important questions for future research about how complex values, relationships and responsibilities should be negotiated in digital mental health. The paper concludes that this study’s approach provides a model for understanding the implications of digital health more broadly, with participants’ combined experience and knowledge shedding light on key interventions at the forefront of digitalization in healthcare.</jats:p>"
AI ethics as subordinated innovation network,20 April 2023,/article/10.1007/s00146-023-01658-5,10.1007/s00146-023-01658-5,James Steinhoff,Article,"<jats:title>Abstract</jats:title><jats:p>AI ethics is proposed, by the Big Tech companies which lead AI research and development, as the cure for diverse social problems posed by the commercialization of data-intensive technologies. It aims to reconcile capitalist AI production with ethics. However, AI ethics is itself now the subject of wide criticism; most notably, it is accused of being no more than “ethics washing” a cynical means of dissimulation for Big Tech, while it continues its business operations unchanged. This paper aims to critically assess, and go beyond the ethics washing thesis. I argue that AI ethics is indeed ethics washing, but not only that. It has a more significant economic function for Big Tech. To make this argument I draw on the theory of intellectual monopoly capital. I argue that ethics washing is better understood as a subordinated innovation network: a dispersed network of contributors beyond Big Tech’s formal employment whose research is indirectly planned by Big Tech, which also appropriates its results. These results are not intended to render AI more ethical, but rather to advance the business processes of data-intensive capital. Because the parameters of AI ethics are indirectly set in advance by Big tech, the ostensible goal that AI ethics sets for itself—to resolve the contradiction between business and ethics—is in fact insoluble. I demonstrate this via an analysis of the latest trend in AI ethics: the operationalization of ethical principles.</jats:p>"
Needs and artificial intelligence,06 October 2022,/article/10.1007/s43681-022-00206-z,10.1007/s43681-022-00206-z,"Soheil Human, Ryan Watkins",Article,"<jats:title>Abstract</jats:title><jats:p>Throughout our history, we, Homo sapiens, have used technologies to better satisfy our<jats:italic>needs</jats:italic>. The relation between<jats:italic>needs</jats:italic>and<jats:italic>technology</jats:italic>is so fundamental that the US National Research Council defines the distinguishing characteristic of technology as its goal “to make modifications in the world [in order] to meet human needs” [1]. Artificial intelligence (AI) is one of the most promising emerging technologies of our time. Similar to other technologies, AI is expected by many “to meet [human] needs”. In this article, we reflect on the relationship between<jats:italic>needs</jats:italic>and AI, and call for the realization of<jats:italic>needs-aware</jats:italic>AI systems. We argue that re-thinking<jats:italic>needs</jats:italic><jats:italic>for</jats:italic>,<jats:italic>through</jats:italic>,<jats:italic>by</jats:italic>, and<jats:italic>with</jats:italic>AI can be a very useful means towards the development of realistic approaches for sustainable<jats:italic>H</jats:italic>uman-aware,<jats:italic>A</jats:italic>ccountable,<jats:italic>L</jats:italic>awful, and<jats:italic>E</jats:italic>thical (HALE) AI systems. We discuss some of the most critical gaps, barriers, enablers, and drivers of co-creating future AI-based sociotechnical systems in which [human]<jats:italic>needs</jats:italic>are well considered and met. Finally, we provide an overview of potential challenges and considerations that should be carefully taken into account; and call for joint, immediate, and interdisciplinary efforts and collaborations to start on the path to<jats:italic>needs-aware</jats:italic>AI.</jats:p>"
A method for the ethical analysis of brain-inspired AI,03 May 2024,/article/10.1007/s10462-024-10769-4,10.1007/s10462-024-10769-4,"Michele Farisco, G. Baldassarre, ... S. J. van Albada",Article,"<jats:title>Abstract</jats:title><jats:p>Despite its successes, to date Artificial Intelligence (AI) is still characterized by a number of shortcomings with regards to different application domains and goals. These limitations are arguably both conceptual (e.g., related to the underlying theoretical models, such as symbolic vs.connectionist), and operational (e.g., related to robustness and ability to generalize). Biologically inspired AI, and more specifically brain-inspired AI, promises to provide further biological aspects beyond those that are already traditionally included in AI, making it possible to assess and possibly overcome some of its present shortcomings. This article examines some conceptual, technical, and ethical issues raised by the development and use of brain-inspired AI. Against this background, the paper asks whether there is anything ethically unique about brain-inspired AI. The aim of the paper is to introduce a method that has a heuristic nature and that can be applied to identify and address the ethical issues arising from brain-inspired AI (and from AI more generally). The conclusion resulting from the application of this method is that, compared to traditional AI, brain-inspired AI raises new foundational ethical issues and some new practical ethical issues, and exacerbates some of the issues raised by traditional AI.</jats:p>"
Use case cards: a use case reporting framework inspired by the European AI Act,20 March 2024,/article/10.1007/s10676-024-09757-7,10.1007/s10676-024-09757-7,"Isabelle Hupont, David Fernández-Llorca, ... Emilia Gómez",Article,"<jats:title>Abstract</jats:title><jats:p>Despite recent efforts by the Artificial Intelligence (AI) community to move towards standardised procedures for documenting models, methods, systems or datasets, there is currently no methodology focused on use cases aligned with the risk-based approach of the European AI Act (AI Act). In this paper, we propose a new framework for the documentation of use cases that we call <jats:italic>use case cards</jats:italic>, based on the use case modelling included in the Unified Markup Language (UML) standard. Unlike other documentation methodologies, we focus on the intended purpose and operational use of an AI system. It consists of two main parts: firstly, a UML-based template, tailored to allow implicitly assessing the risk level of the AI system and defining relevant requirements, and secondly, a supporting UML diagram designed to provide information about the system-user interactions and relationships. The proposed framework is the result of a co-design process involving a relevant team of EU policy experts and scientists. We have validated our proposal with 11 experts with different backgrounds and a reasonable knowledge of the AI Act as a prerequisite. We provide the 5 <jats:italic>use case cards</jats:italic> used in the co-design and validation process. <jats:italic>Use case cards</jats:italic> allows framing and contextualising use cases in an effective way, and we hope this methodology can be a useful tool for policy makers and providers for documenting use cases, assessing the risk level, adapting the different requirements and building a catalogue of existing usages of AI.</jats:p>"
Re-evaluating GPT-4’s bar exam performance,30 March 2024,/article/10.1007/s10506-024-09396-9,10.1007/s10506-024-09396-9,Eric Martínez,Article,"<jats:title>Abstract</jats:title><jats:p>Perhaps the most widely touted of GPT-4’s at-launch, zero-shot capabilities has been its reported 90th-percentile performance on the Uniform Bar Exam. This paper begins by investigating the methodological challenges in documenting and verifying the 90th-percentile claim, presenting four sets of findings that indicate that OpenAI’s estimates of GPT-4’s UBE percentile are overinflated. First, although GPT-4’s UBE score nears the 90th percentile when examining approximate conversions from February administrations of the Illinois Bar Exam, these estimates are heavily skewed towards repeat test-takers who failed the July administration and score significantly lower than the general test-taking population. Second, data from a recent July administration of the same exam suggests GPT-4’s overall UBE percentile was below the 69th percentile, and <jats:inline-formula><jats:alternatives><jats:tex-math>$$\sim$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"">
                <mml:mo>∼</mml:mo>
              </mml:math></jats:alternatives></jats:inline-formula>48th percentile on essays. Third, examining official NCBE data and using several conservative statistical assumptions, GPT-4’s performance against first-time test takers is estimated to be <jats:inline-formula><jats:alternatives><jats:tex-math>$$\sim$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"">
                <mml:mo>∼</mml:mo>
              </mml:math></jats:alternatives></jats:inline-formula>62nd percentile, including <jats:inline-formula><jats:alternatives><jats:tex-math>$$\sim$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"">
                <mml:mo>∼</mml:mo>
              </mml:math></jats:alternatives></jats:inline-formula>42nd percentile on essays. Fourth, when examining only those who passed the exam (i.e. licensed or license-pending attorneys), GPT-4’s performance is estimated to drop to <jats:inline-formula><jats:alternatives><jats:tex-math>$$\sim$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"">
                <mml:mo>∼</mml:mo>
              </mml:math></jats:alternatives></jats:inline-formula>48th percentile overall, and <jats:inline-formula><jats:alternatives><jats:tex-math>$$\sim$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"">
                <mml:mo>∼</mml:mo>
              </mml:math></jats:alternatives></jats:inline-formula>15th percentile on essays. In addition to investigating the validity of the percentile claim, the paper also investigates the validity of GPT-4’s reported scaled UBE score of 298. The paper successfully replicates the MBE score, but highlights several methodological issues in the grading of the MPT + MEE components of the exam, which call into question the validity of the reported essay score. Finally, the paper investigates the effect of different hyperparameter combinations on GPT-4’s MBE performance, finding no significant effect of adjusting temperature settings, and a significant effect of few-shot chain-of-thought prompting over basic zero-shot prompting. Taken together, these findings carry timely insights for the desirability and feasibility of outsourcing legally relevant tasks to AI models, as well as for the importance for AI developers to implement rigorous and transparent capabilities evaluations to help secure safe and trustworthy AI.</jats:p>"
On the computational complexity of ethics: moral tractability for minds and machines,31 March 2024,/article/10.1007/s10462-024-10732-3,10.1007/s10462-024-10732-3,Jakob Stenseke,Article,"<jats:title>Abstract</jats:title><jats:p>Why should moral philosophers, moral psychologists, and machine ethicists care about computational complexity? Debates on whether artificial intelligence (AI) can or should be used to solve problems in ethical domains have mainly been driven by what AI can or cannot do in terms of human capacities. In this paper, we tackle the problem from the other end by exploring what kind of moral machines are possible based on what computational systems can or cannot do. To do so, we analyze normative ethics through the lens of computational complexity. First, we introduce computational complexity for the uninitiated reader and discuss how the complexity of ethical problems can be framed within Marr’s three levels of analysis. We then study a range of ethical problems based on consequentialism, deontology, and virtue ethics, with the aim of elucidating the complexity associated with the problems themselves (e.g., due to combinatorics, uncertainty, strategic dynamics), the computational methods employed (e.g., probability, logic, learning), and the available resources (e.g., time, knowledge, learning). The results indicate that most problems the normative frameworks pose lead to tractability issues in every category analyzed. Our investigation also provides several insights about the computational nature of normative ethics, including the differences between rule- and outcome-based moral strategies, and the implementation-variance with regard to moral resources. We then discuss the consequences complexity results have for the prospect of moral machines in virtue of the trade-off between optimality and efficiency. Finally, we elucidate how computational complexity can be used to inform both philosophical and cognitive-psychological research on human morality by advancing the moral tractability thesis.</jats:p>"
Anticipating impacts: using large-scale scenario-writing to explore diverse implications of generative AI in the news environment,27 May 2024,/article/10.1007/s43681-024-00497-4,10.1007/s43681-024-00497-4,"Kimon Kieslich, Nicholas Diakopoulos, Natali Helberger",Article,"<jats:title>Abstract</jats:title><jats:p>The tremendous rise of generative AI has reached every part of society—including the news environment. There are many concerns about the individual and societal impact of the increasing use of generative AI, including issues such as disinformation and misinformation, discrimination, and the promotion of social tensions. However, research on anticipating the impact of generative AI is still in its infancy and mostly limited to the views of technology developers and/or researchers. In this paper, we aim to broaden the perspective and capture the expectations of three stakeholder groups (news consumers; technology developers; content creators) about the potential negative impacts of generative AI, as well as mitigation strategies to address these. Methodologically, we apply scenario-writing and use participatory foresight in the context of a survey (n = 119) to delve into cognitively diverse imaginations of the future. We qualitatively analyze the scenarios using thematic analysis to systematically map potential impacts of generative AI on the news environment, potential mitigation strategies, and the role of stakeholders in causing and mitigating these impacts. In addition, we measure respondents' opinions on a specific mitigation strategy, namely transparency obligations as suggested in Article 52 of the draft EU AI Act. We compare the results across different stakeholder groups and elaborate on different expected impacts across these groups. We conclude by discussing the usefulness of scenario-writing and participatory foresight as a toolbox for generative AI impact assessment.</jats:p>"
Legal Tech and Lawtech: Towards a Framework for Technological Trends in the Legal Services Industry,2021,https://link.springer.com/chapter/10.1007/978-3-030-66661-3_11,10.1007/978-3-030-66661-3_11,"Ciaran M. Harper, S. Sarah Zhang",Chapter,"<jats:title>Abstract</jats:title><jats:p>The use of legal technology (legal tech) and the lawtech ecosystem of legal start-ups has experienced tremendous growth in recent years. To provide a structured approach of analysing IT innovations in the legal sector, we propose a framework for lawtech applications, classifying them into three groups: internal, B2C and B2B applications. In the context of this framework, we examine technological trends in lawtech and their potential to support and transform processes in specific areas of business or personal law. We acknowledge that within lawtech there is a gap between the areas of interest of legal practitioners, IT professionals and academic researchers, and that some areas have received considerable attention by these groups, while other areas have been left relatively unexplored by one or more of these groups. However, the growing interest by legal practitioners in advanced technology such as artificial intelligence (AI) and natural language processing (NLP) is further closing the gap between academic research, IT professionals and legal practice.</jats:p>"
Growth and Branching of Natural Language Processing,2024,https://link.springer.com/chapter/10.1007/978-981-97-0771-3_6,10.1007/978-981-97-0771-3_6,Masayuki Ida,Chapter,No abstract available for this DOI.
Personalized Persuasive Technologies in Health and Wellness: From Theory to Practice,2024,https://link.springer.com/chapter/10.1007/978-3-031-55109-3_10,10.1007/978-3-031-55109-3_10,"Alaa Alslaity, Oladapo Oyebode, ... Rita Orji",Chapter,No abstract available for this DOI.
"Machine learning towards intelligent systems: applications, challenges, and opportunities",08 January 2021,/article/10.1007/s10462-020-09948-w,10.1007/s10462-020-09948-w,"MohammadNoor Injadat, Abdallah Moubayed, ... Abdallah Shami",Article,No abstract available for this DOI.
Beyond Predictive Learning Analytics Modelling and onto Explainable Artificial Intelligence with Prescriptive Analytics and ChatGPT,22 June 2023,/article/10.1007/s40593-023-00336-3,10.1007/s40593-023-00336-3,Teo Susnjak,Article,"<jats:title>Abstract</jats:title><jats:p>A significant body of recent research in the field of Learning Analytics has focused on leveraging machine learning approaches for predicting at-risk students in order to initiate timely interventions and thereby elevate retention and completion rates. The overarching feature of the majority of these research studies has been on the science of prediction only. The component of predictive analytics concerned with interpreting the internals of the models and explaining their predictions for individual cases to stakeholders has largely been neglected. Additionally, works that attempt to employ data-driven prescriptive analytics to automatically generate evidence-based remedial advice for at-risk learners are in their infancy. eXplainable AI is a field that has recently emerged providing cutting-edge tools which support transparent predictive analytics and techniques for generating tailored advice for at-risk students. This study proposes a novel framework that unifies both transparent machine learning as well as techniques for enabling prescriptive analytics, while integrating the latest advances in large language models for communicating the insights to learners. This work demonstrates a predictive modelling framework for identifying learners at risk of qualification non-completion based on a real-world dataset comprising <jats:inline-formula><jats:alternatives><jats:tex-math>$$\sim $$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"">
                  <mml:mo>∼</mml:mo>
                </mml:math></jats:alternatives></jats:inline-formula>7000 learners with their outcomes, covering 2018 - 2022. The study further demonstrates how predictive modelling can be augmented with prescriptive analytics on two case studies to generate human-readable prescriptive feedback for those who are at risk using ChatGPT.</jats:p>"
Situational Data Integration in Question Answering systems: a survey over two decades,18 June 2024,/article/10.1007/s10115-024-02136-0,10.1007/s10115-024-02136-0,"Maria Helena Franciscatto, Luis Carlos Erpen de Bona, ... João Carlos Damasceno Lima",Article,No abstract available for this DOI.
A systematic review and research challenges on phishing cyberattacks from an electroencephalography and gaze-based perspective,19 March 2024,/article/10.1007/s00779-024-01794-9,10.1007/s00779-024-01794-9,"George A. Thomopoulos, Dimitrios P. Lyras, Christos A. Fidas",Article,"<jats:title>Abstract</jats:title><jats:p>Phishing is one of the most important security threats in modern information systems causing different levels of damages to end-users and service providers such as financial and reputational losses. State-of-the-art anti-phishing research is highly fragmented and monolithic and does not address the problem from a pervasive computing perspective. In this survey, we aim to contribute to the existing literature by providing a systematic review of existing experimental phishing research that employs EEG and eye-tracking methods within multi-modal and multi-sensory interaction environments. The main research objective of this review is to examine articles that contain results of at least one EEG-based and/or eye-tracking-based experimental setup within a phishing context. The database search with specific search criteria yielded 651 articles from which, after the identification and the screening process, 42 articles were examined as per the execution of experiments using EEG or eye-tracking technologies in the context of phishing, resulting to a total of 18 distinct papers that were included in the analysis. This survey is approaching the subject across the following pillars: a) the experimental design practices with an emphasis on the applied EEG and eye-tracking acquisition protocols, b) the artificial intelligence and signal preprocessing techniques that were applied in those experiments, and finally, c) the phishing attack types examined. We also provide a roadmap for future research in the field by suggesting ideas on how to combine state-of-the-art gaze-based mechanisms with EEG technologies for advancing phishing research. This leads to a discussion on the best practices for designing EEG and gaze-based frameworks.</jats:p>"
Text Data Augmentation for Deep Learning,19 July 2021,/article/10.1186/s40537-021-00492-0,10.1186/s40537-021-00492-0,"Connor Shorten, Taghi M. Khoshgoftaar, Borko Furht",Article,"<jats:title>Abstract</jats:title><jats:p>Natural Language Processing (NLP) is one of the most captivating applications of Deep Learning. In this survey, we consider how the Data Augmentation training strategy can aid in its development. We begin with the major motifs of Data Augmentation summarized into strengthening local decision boundaries, brute force training, causality and counterfactual examples, and the distinction between meaning and form. We follow these motifs with a concrete list of augmentation frameworks that have been developed for text data. Deep Learning generally struggles with the measurement of generalization and characterization of overfitting. We highlight studies that cover how augmentations can construct test sets for generalization. NLP is at an early stage in applying Data Augmentation compared to Computer Vision. We highlight the key differences and promising ideas that have yet to be tested in NLP. For the sake of practical implementation, we describe tools that facilitate Data Augmentation such as the use of consistency regularization, controllers, and offline and online augmentation pipelines, to preview a few. Finally, we discuss interesting topics around Data Augmentation in NLP such as task-specific augmentations, the use of prior knowledge in self-supervised learning versus Data Augmentation, intersections with transfer and multi-task learning, and ideas for AI-GAs (AI-Generating Algorithms). We hope this paper inspires further research interest in Text Data Augmentation.</jats:p>"
Resources and Conclusions,2022,https://link.springer.com/chapter/10.1007/978-3-031-16719-5_13,10.1007/978-3-031-16719-5_13,"Matthew Guzdial, Sam Snodgrass, Adam J. Summerville",Chapter,No abstract available for this DOI.
Exploring Unique App Signature of the Depressed and Non-depressed Through Their Fingerprints on Apps,2022,https://link.springer.com/chapter/10.1007/978-3-030-99194-4_15,10.1007/978-3-030-99194-4_15,"Md. Sabbir Ahmed, Nova Ahmed",Conference paper,No abstract available for this DOI.
A survey on sentiment analysis and its applications,17 August 2023,/article/10.1007/s00521-023-08941-y,10.1007/s00521-023-08941-y,"Tamara Amjad Al-Qablan, Mohd Halim Mohd Noor, ... Ahamad Tajudin Khader",Article,No abstract available for this DOI.
Clinical Information Retrieval: A Literature Review,23 January 2024,/article/10.1007/s41666-024-00159-4,10.1007/s41666-024-00159-4,"Sonish Sivarajkumar, Haneef Ahamed Mohammad, ... Yanshan Wang",Article,No abstract available for this DOI.
Six-Writings multimodal processing with pictophonetic coding to enhance Chinese language models,01 January 2024,/article/10.1631/FITEE.2300384,10.1631/FITEE.2300384,"Li Weigang, Mayara Chew Marinho, ... Vitor Vasconcelos De Oliveira",Article,No abstract available for this DOI.
Advanced SXO Techniques,2023,https://link.springer.com/chapter/10.1007/978-1-4842-9212-9_4,10.1007/978-1-4842-9212-9_4,Zuzanna Krüger,Chapter,No abstract available for this DOI.
The Ethics of Computational Social Science,2023,https://link.springer.com/chapter/10.1007/978-3-031-16624-2_4,10.1007/978-3-031-16624-2_4,David Leslie,Chapter,"<jats:title>Abstract</jats:title><jats:p>This chapter is concerned with setting up practical guardrails within the research activities and environments of Computational Social Science (CSS). It aims to provide CSS scholars, as well as policymakers and other stakeholders who apply CSS methods, with the critical and constructive means needed to ensure that their practices are ethical, trustworthy, and responsible. It begins by providing a taxonomy of the ethical challenges faced by researchers in the field of CSS. These are challenges related to (1) the treatment of research subjects, (2) the impacts of CSS research on affected individuals and communities, (3) the quality of CSS research and to its epistemological status, (4) research integrity, and (5) research equity. Taking these challenges as motivation for cultural transformation, it then argues for the incorporation of end-to-end habits of Responsible Research and Innovation (RRI) into CSS practices, focusing on the role that contextual considerations, anticipatory reflection, impact assessment, public engagement, and justifiable and well-documented action should play across the research lifecycle. In proposing the inclusion of habits of RRI in CSS practices, the chapter lays out several practical steps needed for ethical, trustworthy, and responsible CSS research activities. These include stakeholder engagement processes, research impact assessments, data lifecycle documentation, bias self-assessments, and transparent research reporting protocols.</jats:p>"
So What’s the Plan? Mining Strategic Planning Documents,2020,https://link.springer.com/chapter/10.1007/978-3-030-65218-0_16,10.1007/978-3-030-65218-0_16,"Ekaterina Artemova, Tatiana Batura, ... Elena Tutubalina",Conference paper,No abstract available for this DOI.
Tabular and latent space synthetic data generation: a literature review,10 July 2023,/article/10.1186/s40537-023-00792-7,10.1186/s40537-023-00792-7,"Joao Fonseca, Fernando Bacao",Article,"<jats:title>Abstract</jats:title><jats:p>The generation of synthetic data can be used for anonymization, regularization, oversampling, semi-supervised learning, self-supervised learning, and several other tasks. Such broad potential motivated the development of new algorithms, specialized in data generation for specific data formats and Machine Learning (ML) tasks. However, one of the most common data formats used in industrial applications, tabular data, is generally overlooked; Literature analyses are scarce, state-of-the-art methods are spread across domains or ML tasks and there is little to no distinction among the main types of mechanism underlying synthetic data generation algorithms. In this paper, we analyze tabular and latent space synthetic data generation algorithms. Specifically, we propose a unified taxonomy as an extension and generalization of previous taxonomies, review 70 generation algorithms across six ML problems, distinguish the main generation mechanisms identified into six categories, describe each type of generation mechanism, discuss metrics to evaluate the quality of synthetic data and provide recommendations for future research. We expect this study to assist researchers and practitioners identify relevant gaps in the literature and design better and more informed practices with synthetic data.</jats:p>"
An association between fingerprint patterns with blood group and lifestyle based diseases: a review,18 August 2020,/article/10.1007/s10462-020-09891-w,10.1007/s10462-020-09891-w,"Vijaykumar Patil, D. R. Ingle",Article,No abstract available for this DOI.
Special issue in memory of Carole Hafner: editor’s introduction,10 November 2016,/article/10.1007/s10506-016-9191-4,10.1007/s10506-016-9191-4,T. J. M. Bench-Capon,Article,No abstract available for this DOI.
Digital Innovation and Social Dilemmas,2014,https://link.springer.com/chapter/10.1007/978-3-662-43459-8_4,10.1007/978-3-662-43459-8_4,"Maria Åkesson, Michel Thomsen",Conference paper,No abstract available for this DOI.
Topological Operators on Cell Complexes in Arbitrary Dimensions,2012,https://link.springer.com/chapter/10.1007/978-3-642-30238-1_11,10.1007/978-3-642-30238-1_11,"Lidija Čomić, Leila De Floriani",Conference paper,No abstract available for this DOI.
"Bureaucracy, Safety and Software: a Potentially Lethal Cocktail",2010,https://link.springer.com/chapter/10.1007/978-1-84996-086-1_2,10.1007/978-1-84996-086-1_2,Les Hatton,Conference paper,No abstract available for this DOI.
E-Government Interoperability Framework: A Case Study in a Developing Country,2010,https://link.springer.com/chapter/10.1007/978-1-4419-6536-3_32,10.1007/978-1-4419-6536-3_32,"Pavel Shvaiko, Adolfo Villafiorita, ... Teotonio Fumo",Chapter,No abstract available for this DOI.
Distillation,2011,https://link.springer.com/chapter/10.1007/978-1-4419-7713-7_4,10.1007/978-1-4419-7713-7_4,"Radu Hans Florian, Joseph Olive, ... John McCary",Chapter,No abstract available for this DOI.
eGIF4M: eGovernment Interoperability Framework for Mozambique,2009,https://link.springer.com/chapter/10.1007/978-3-642-03516-6_28,10.1007/978-3-642-03516-6_28,"Pavel Shvaiko, Adolfo Villafiorita, ... Jussi Hinkkanen",Conference paper,No abstract available for this DOI.
A Methodology of Traffic Engineering to IP Backbone,2009,https://link.springer.com/chapter/10.1007/978-3-642-04968-2_16,10.1007/978-3-642-04968-2_16,"José E. Bessa Maia, Arnoldo N. da Silva, ... Paulo R. F. Cunha",Conference paper,No abstract available for this DOI.
"The Transmission of Pythagorean Arithmetic in the Context of the Ancient Musical Tradition from the Greek to the Latin Orbits During the Renaissance: A Computational Approach of Identifying and Analyzing the Formation of Scales in the De Harmonia Musicorum Instrumentorum Opus (Milan, 1518) of Franchino Gaffurio (1451–1522)",2009,https://link.springer.com/chapter/10.1007/978-3-642-04579-0_39,10.1007/978-3-642-04579-0_39,"Herbert Kreyszig, Walter Kreyszig",Conference paper,No abstract available for this DOI.
On Alternating Phrase-Structure Grammars,2008,https://link.springer.com/chapter/10.1007/978-3-540-88282-4_36,10.1007/978-3-540-88282-4_36,"Etsuro Moriya, Friedrich Otto",Conference paper,No abstract available for this DOI.
Implementing Flexible Parallelism for Modular Self-reconfigurable Robots,2008,https://link.springer.com/chapter/10.1007/978-3-540-89076-8_15,10.1007/978-3-540-89076-8_15,"Mirko Bordignon, Lars Lindegaard Mikkelsen, Ulrik Pagh Schultz",Conference paper,No abstract available for this DOI.
Measuring Core Inflation by Multivariate Structural Time Series Models,2007,https://link.springer.com/chapter/10.1007/3-540-36626-1_10,10.1007/3-540-36626-1_10,Tommaso Proietti,Conference paper,No abstract available for this DOI.
Towards a Digital Library for Language Learning,2006,https://link.springer.com/chapter/10.1007/11863878_29,10.1007/11863878_29,"Shaoqun Wu, Ian H. Witten",Conference paper,No abstract available for this DOI.
Determination of Storage Locations for Incoming Containers of Uncertain Weight,2006,https://link.springer.com/chapter/10.1007/11779568_123,10.1007/11779568_123,"Jaeho Kang, Kwang Ryel Ryu, Kap Hwan Kim",Conference paper,No abstract available for this DOI.
Safety Case Practice - Meet the Challenge,2006,https://link.springer.com/chapter/10.1007/1-84628-447-3_5,10.1007/1-84628-447-3_5,"Werner Winkelbauer, Gabriele Schedl, Andreas Gerstinger",Conference paper,No abstract available for this DOI.
The Offshoring Obstacle Course,2004,https://link.springer.com/chapter/10.1007/978-1-4302-0740-5_3,10.1007/978-1-4302-0740-5_3,Bill Blunden,Chapter,No abstract available for this DOI.
Intelligent Agents for Document Categorization and Adaptive Filtering Using a Neural Network Approach and Fuzzy Logic,2003,https://link.springer.com/chapter/10.1007/978-1-4757-3739-4_12,10.1007/978-1-4757-3739-4_12,Frank Teuteberg,Chapter,No abstract available for this DOI.
Machine vision for industrial applications,2001,https://link.springer.com/chapter/10.1007/978-1-4471-0239-7_1,10.1007/978-1-4471-0239-7_1,"Bruce Batchelor, Frederick Waltz",Chapter,No abstract available for this DOI.
Chip-To-Package Interconnections,1997,https://link.springer.com/chapter/10.1007/978-1-4615-6037-1_2,10.1007/978-1-4615-6037-1_2,"Paul A. Totta, Subash Khadpe, ... Michael J. Sheaffer",Chapter,No abstract available for this DOI.
Legal Case Analysis in IS Research: Failures in Employing and Outsourcing for IT Professionals,1997,https://link.springer.com/chapter/10.1007/978-0-387-35309-8_25,10.1007/978-0-387-35309-8_25,"S. Ang, A. Endeshaw",Chapter,No abstract available for this DOI.
High-speed tools for Global Information Management I. Information processing and retrieval,01 August 1996,/article/10.1007/BF02265087,10.1007/BF02265087,"Paul A. D. De Maine, Kenneth D. Bradley",Article,No abstract available for this DOI.
Inductive logic programming beyond logical implication,1996,https://link.springer.com/chapter/10.1007/3-540-61863-5_46,10.1007/3-540-61863-5_46,"Jianguo Lu, Jun Arima",Conference paper,No abstract available for this DOI.
Learning controllers for industrial robots,01 May 1996,/article/10.1007/BF00117445,10.1007/BF00117445,"C. Baroglio, A. Giordana, ... R. Piola",Article,No abstract available for this DOI.
Estimating test effectiveness with dynamic complexity measurement,01 January 1996,/article/10.1007/BF00127448,10.1007/BF00127448,"John C. Munson, Gregory A. Hall",Article,No abstract available for this DOI.
A skills-driven process for training computer professionals,1995,https://link.springer.com/chapter/10.1007/3-540-58951-1_119,10.1007/3-540-58951-1_119,"Sherrie Bayman, Maurice H. Blumberg, ... Cheryl Diallo",Conference paper,No abstract available for this DOI.
Fast parallel Lyndon factorization with applications,01 March 1995,/article/10.1007/BF01191471,10.1007/BF01191471,"A. Apostolico, M. Crochemore",Article,No abstract available for this DOI.
The effect of management structure on the performance of interconnected packet-switched networks,01 March 1993,/article/10.1007/BF01026826,10.1007/BF01026826,"Izhak Rubin, Teresa Cheng",Article,No abstract available for this DOI.
On the Computational Complexity of Approximating Distributions by Probabilistic Automata,01 July 1992,/article/10.1023/A:1022693116573,10.1023/A:1022693116573,"Naoki Abe, Manfred K. Warmuth",Article,No abstract available for this DOI.
Random Mapping Statistics,1990,https://link.springer.com/chapter/10.1007/3-540-46885-4_34,10.1007/3-540-46885-4_34,"Philippe Flajolet, Andrew M. Odlyzko",Conference paper,No abstract available for this DOI.
Scientometric datafiles. A comprehensive set of indicators on 2649 journals and 96 countries in all major science fields and subfields 1981–1985,01 June 1989,/article/10.1007/BF02093234,10.1007/BF02093234,"A. Schubert, W. Glänzel, T. Braun",Article,No abstract available for this DOI.
Performance Evaluation of a Database System in Multiple Backend Configurations,1985,https://link.springer.com/chapter/10.1007/978-1-4612-5144-6_5,10.1007/978-1-4612-5144-6_5,"Steven A. Demurjian, David K. Hsiao, ... Joel Trimble",Chapter,No abstract available for this DOI.
Transcript of panel discussion,1982,https://link.springer.com/chapter/10.1007/BFb0025794,10.1007/BFb0025794,,Conference paper,No abstract available for this DOI.
Lateralization of Emotional or Behavioral Responses in Intact and Hemisphere-Damaged Humans and Rats,1982,https://link.springer.com/chapter/10.1007/978-1-4684-7890-7_10,10.1007/978-1-4684-7890-7_10,"Godfrey D. Pearlson, Robert G. Robinson",Chapter,No abstract available for this DOI.
