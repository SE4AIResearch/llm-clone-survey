title,url,doi,abstract,# pages,paper_type,year,bibtex
Calibration-Tuning: Teaching Large Language Models to Know What They Don{'}t Know,https://aclanthology.org/2024.uncertainlp-1.1,,"""Large language models are increasingly deployed for high-stakes decision making, for example in financial and medical applications. In such applications, it is imperative that we be able to estimate our confidence in the answers output by a language model in order to assess risks. Although we can easily compute the probability assigned by a language model to the sequence of tokens that make up an answer, we cannot easily compute the probability of the answer itself, which could be phrased in numerous ways.While other works have engineered ways of assigning such probabilities to LLM outputs, a key problem remains: existing language models are poorly calibrated, often confident when they are wrong or unsure when they are correct. In this work, we devise a protocol called *calibration tuning* for finetuning LLMs to output calibrated probabilities. Calibration-tuned models demonstrate superior calibration performance compared to existing language models on a variety of question-answering tasks, including open-ended generation, without affecting accuracy. We further show that this ability transfers to new domains outside of the calibration-tuning train set.""",14,inproceedings,2024,"@inproceedings{kapoor-etal-2024-calibration,
    title = {""Calibration-Tuning: Teaching Large Language Models to Know What They Don{'}t Know""},
    editor = {V{\'a}zquez, Ra{\'u}l  and},
    month = {mar},
    year = {""2024""},
    address = {""St Julians, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.uncertainlp-1.1""},
    author = {""Kapoor, Sanyam  and},
    booktitle = {""Proceedings of the 1st Workshop on Uncertainty-Aware NLP (UncertaiNLP 2024)""},
    pages = {""1--14""},
    abstract = {""Large language models are increasingly deployed for high-stakes decision making, for example in financial and medical applications. In such applications, it is imperative that we be able to estimate our confidence in the answers output by a language model in order to assess risks. Although we can easily compute the probability assigned by a language model to the sequence of tokens that make up an answer, we cannot easily compute the probability of the answer itself, which could be phrased in numerous ways.While other works have engineered ways of assigning such probabilities to LLM outputs, a key problem remains: existing language models are poorly calibrated, often confident when they are wrong or unsure when they are correct. In this work, we devise a protocol called *calibration tuning* for finetuning LLMs to output calibrated probabilities. Calibration-tuned models demonstrate superior calibration performance compared to existing language models on a variety of question-answering tasks, including open-ended generation, without affecting accuracy. We further show that this ability transfers to new domains outside of the calibration-tuning train set.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Cross-Task Defense: Instruction-Tuning {LLM}s for Content Safety,https://aclanthology.org/2024.trustnlp-1.9,,"""Recent studies reveal that Large Language Models (LLMs) face challenges in balancing safety with utility, particularly when processing long texts for NLP tasks like summarization and translation. Despite defenses against malicious short questions, the ability of LLMs to safely handle dangerous long content, such as manuals teaching illicit activities, remains unclear. Our work aims to develop robust defenses for LLMs in processing malicious documents alongside benign NLP task queries. We introduce a defense dataset comprised of safety-related examples and propose single-task and mixed-task losses for instruction tuning. Our empirical results demonstrate that LLMs can significantly enhance their capacity to safely manage dangerous content with appropriate instruction tuning. Additionally, strengthening the defenses of tasks most susceptible to misuse is effective in protecting LLMs against processing harmful information. We also observe that trade-offs between utility and safety exist in defense strategies, where Llama2, utilizing our proposed approach, displays a significantly better balance compared to Llama1.""",9,inproceedings,2024,"@inproceedings{fu-etal-2024-cross,
    title = {""Cross-Task Defense: Instruction-Tuning {LLM}s for Content Safety""},
    editor = {""Chang, Kai-Wei  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.trustnlp-1.9""},
    author = {""Fu, Yu  and},
    booktitle = {""Proceedings of the 4th Workshop on Trustworthy Natural Language Processing (TrustNLP 2024)""},
    pages = {""85--93""},
    abstract = {""Recent studies reveal that Large Language Models (LLMs) face challenges in balancing safety with utility, particularly when processing long texts for NLP tasks like summarization and translation. Despite defenses against malicious short questions, the ability of LLMs to safely handle dangerous long content, such as manuals teaching illicit activities, remains unclear. Our work aims to develop robust defenses for LLMs in processing malicious documents alongside benign NLP task queries. We introduce a defense dataset comprised of safety-related examples and propose single-task and mixed-task losses for instruction tuning. Our empirical results demonstrate that LLMs can significantly enhance their capacity to safely manage dangerous content with appropriate instruction tuning. Additionally, strengthening the defenses of tasks most susceptible to misuse is effective in protecting LLMs against processing harmful information. We also observe that trade-offs between utility and safety exist in defense strategies, where Llama2, utilizing our proposed approach, displays a significantly better balance compared to Llama1.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
"{B}ad{R}ock at {S}em{E}val-2024 Task 8: {D}istil{BERT} to Detect Multigenerator, Multidomain and Multilingual Black-Box Machine-Generated Text",https://aclanthology.org/2024.semeval-1.37,,"""The rise of Large Language Models (LLMs) has brought about a notable shift, rendering them increasingly ubiquitous and readily accessible. This accessibility has precipitated a surge in machine-generated content across diverse platforms encompassing news outlets, social media platforms, question-answering forums, educational platforms, and even academic domains. Recent iterations of LLMs, exemplified by entities like ChatGPT and GPT-4, exhibit a remarkable ability to produce coherent and contextually relevant responses across a broad spectrum of user inquiries. The fluidity and sophistication of these generated texts position LLMs as compelling candidates for substituting human labor in numerous applications. Nevertheless, this proliferation of machine-generated content has raised apprehensions regarding potential misuse, including the dissemination of misinformation and disruption of educational ecosystems. Given that humans marginally outperform random chance in discerning between machine-generated and human-authored text, there arises a pressing imperative to develop automated systems capable of accurately distinguishing machine-generated text. This pursuit is driven by the overarching objective of curbing the potential misuse of machine-generated content. Our manuscript delineates the approach we adopted for participation in this competition. Specifically, we detail the use of a DistilBERT model for classifying each sample in the test set provided. Our submission is able to reach an accuracy equal to 0.754 in place of the worst result obtained at the competition that is equal to 0.231.""",7,inproceedings,2024,"@inproceedings{siino-2024-badrock,
    title = {""{B}ad{R}ock at {S}em{E}val-2024 Task 8: {D}istil{BERT} to Detect Multigenerator, Multidomain and Multilingual Black-Box Machine-Generated Text""},
    editor = {Ojha, Atul Kr.  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.semeval-1.37""},
    author = {""Siino, Marco""},
    booktitle = {""Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)""},
    pages = {""239--245""},
    abstract = {""The rise of Large Language Models (LLMs) has brought about a notable shift, rendering them increasingly ubiquitous and readily accessible. This accessibility has precipitated a surge in machine-generated content across diverse platforms encompassing news outlets, social media platforms, question-answering forums, educational platforms, and even academic domains. Recent iterations of LLMs, exemplified by entities like ChatGPT and GPT-4, exhibit a remarkable ability to produce coherent and contextually relevant responses across a broad spectrum of user inquiries. The fluidity and sophistication of these generated texts position LLMs as compelling candidates for substituting human labor in numerous applications. Nevertheless, this proliferation of machine-generated content has raised apprehensions regarding potential misuse, including the dissemination of misinformation and disruption of educational ecosystems. Given that humans marginally outperform random chance in discerning between machine-generated and human-authored text, there arises a pressing imperative to develop automated systems capable of accurately distinguishing machine-generated text. This pursuit is driven by the overarching objective of curbing the potential misuse of machine-generated content. Our manuscript delineates the approach we adopted for participation in this competition. Specifically, we detail the use of a DistilBERT model for classifying each sample in the test set provided. Our submission is able to reach an accuracy equal to 0.754 in place of the worst result obtained at the competition that is equal to 0.231.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
"Team Innovative at {S}em{E}val-2024 Task 8: Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text Detection",https://aclanthology.org/2024.semeval-1.171,,"""With the widespread adoption of large language models (LLMs), such as ChatGPT and GPT-4, in various domains, concerns regarding their potential misuse, including spreading misinformation and disrupting education, have escalated. The need to discern between human-generated and machine-generated text has become increasingly crucial. This paper addresses the challenge of automatic text classification with a focus on distinguishing between human-written and machine-generated text. Leveraging the robust capabilities of the RoBERTa model, we propose an approach for text classification, termed as RoBERTa hybrid, which involves fine-tuning the pre-trained Roberta model coupled with additional dense layers and softmax activation for authorship attribution. In this paper, we present an approach that leverages Stylometric features, hybrid features, and the output probabilities of a fine-tuned RoBERTa model. Our method achieves a test accuracy of 73{\%} and a validation accuracy of 89{\%}, demonstrating promising advancements in the field of machine-generated text detection. These results mark significant progress in the domain of machine-generated text detection, as evidenced by our 74th position on the leaderboard for Subtask-A of SemEval-2024 Task 8.""",5,inproceedings,2024,"@inproceedings{sharma-mansuri-2024-team,
    title = {""Team Innovative at {S}em{E}val-2024 Task 8: Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text Detection""},
    editor = {Ojha, Atul Kr.  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.semeval-1.171""},
    author = {""Sharma, Surbhi  and},
    booktitle = {""Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)""},
    pages = {""1172--1176""},
    abstract = {""With the widespread adoption of large language models (LLMs), such as ChatGPT and GPT-4, in various domains, concerns regarding their potential misuse, including spreading misinformation and disrupting education, have escalated. The need to discern between human-generated and machine-generated text has become increasingly crucial. This paper addresses the challenge of automatic text classification with a focus on distinguishing between human-written and machine-generated text. Leveraging the robust capabilities of the RoBERTa model, we propose an approach for text classification, termed as RoBERTa hybrid, which involves fine-tuning the pre-trained Roberta model coupled with additional dense layers and softmax activation for authorship attribution. In this paper, we present an approach that leverages Stylometric features, hybrid features, and the output probabilities of a fine-tuned RoBERTa model. Our method achieves a test accuracy of 73{\%} and a validation accuracy of 89{\%}, demonstrating promising advancements in the field of machine-generated text detection. These results mark significant progress in the domain of machine-generated text detection, as evidenced by our 74th position on the leaderboard for Subtask-A of SemEval-2024 Task 8.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Mast Kalandar at {S}em{E}val-2024 Task 8: On the Trail of Textual Origins: {R}o{BERT}a-{B}i{LSTM} Approach to Detect {AI}-Generated Text,https://aclanthology.org/2024.semeval-1.231,,"""Large Language Models (LLMs) have showcased impressive abilities in generating fluent responses to diverse user queries. However, concerns regarding the potential misuse ofsuch texts in journalism, educational, and academic contexts have surfaced. SemEval 2024introduces the task of Multigenerator, Multidomain, and Multilingual Black-Box MachineGenerated Text Detection, aiming to developautomated systems for identifying machinegenerated text and detecting potential misuse. In this paper, we i) propose a RoBERTaBiLSTM based classifier designed to classifytext into two categories: AI-generated or human ii) conduct a comparative study of ourmodel with baseline approaches to evaluate itseffectiveness. This paper contributes to the advancement of automatic text detection systemsin addressing the challenges posed by machinegenerated text misuse. Our architecture ranked46th on the official leaderboard with an accuracy of 80.83 among 125.""",7,inproceedings,2024,"@inproceedings{bafna-etal-2024-mast,
    title = {""Mast Kalandar at {S}em{E}val-2024 Task 8: On the Trail of Textual Origins: {R}o{BERT}a-{B}i{LSTM} Approach to Detect {AI}-Generated Text""},
    editor = {Ojha, Atul Kr.  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.semeval-1.231""},
    author = {""Bafna, Jainit  and},
    booktitle = {""Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)""},
    pages = {""1627--1633""},
    abstract = {""Large Language Models (LLMs) have showcased impressive abilities in generating fluent responses to diverse user queries. However, concerns regarding the potential misuse ofsuch texts in journalism, educational, and academic contexts have surfaced. SemEval 2024introduces the task of Multigenerator, Multidomain, and Multilingual Black-Box MachineGenerated Text Detection, aiming to developautomated systems for identifying machinegenerated text and detecting potential misuse. In this paper, we i) propose a RoBERTaBiLSTM based classifier designed to classifytext into two categories: AI-generated or human ii) conduct a comparative study of ourmodel with baseline approaches to evaluate itseffectiveness. This paper contributes to the advancement of automatic text detection systemsin addressing the challenges posed by machinegenerated text misuse. Our architecture ranked46th on the official leaderboard with an accuracy of 80.83 among 125.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{G}roningen Team {F} at {S}em{E}val-2024 Task 8: Detecting Machine-Generated Text using Feature-Based Machine Learning Models,https://aclanthology.org/2024.semeval-1.268,,"""Large language models (LLMs) have shown remarkable capability of creating fluent responses to a wide variety of user queries. However, this also comes with concerns regarding the spread of misinformation and potential misuse within educational context. In this paper we describe our contribution to SemEval-2024 Task 8 (Wang et al., 2024), a shared task created around detecting machine-generated text. We aim to create several feature-based models that can detect whether a text is machine-generated or human-written. In the end, we obtained an accuracy of 0.74 on the binary human-written vs. machine-generated text classification task (Subtask A monolingual) and an accuracy of 0.61 on the multi-way machine-generated text-classification task (Subtask B). For future work, more features and models could be implemented.""",7,inproceedings,2024,"@inproceedings{donker-etal-2024-groningen,
    title = {""{G}roningen Team {F} at {S}em{E}val-2024 Task 8: Detecting Machine-Generated Text using Feature-Based Machine Learning Models""},
    editor = {Ojha, Atul Kr.  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.semeval-1.268""},
    author = {Donker, Rina  and},
    booktitle = {""Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)""},
    pages = {""1919--1925""},
    abstract = {""Large language models (LLMs) have shown remarkable capability of creating fluent responses to a wide variety of user queries. However, this also comes with concerns regarding the spread of misinformation and potential misuse within educational context. In this paper we describe our contribution to SemEval-2024 Task 8 (Wang et al., 2024), a shared task created around detecting machine-generated text. We aim to create several feature-based models that can detect whether a text is machine-generated or human-written. In the end, we obtained an accuracy of 0.74 on the binary human-written vs. machine-generated text classification task (Subtask A monolingual) and an accuracy of 0.61 on the multi-way machine-generated text-classification task (Subtask B). For future work, more features and models could be implemented.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes,https://aclanthology.org/2024.naacl-long.120,,"""Scaling high-quality tutoring remains a major challenge in education. Due to growing demand, many platforms employ novice tutors who, unlike experienced educators, struggle to address student mistakes and thus fail to seize prime learning opportunities. Our work explores the potential of large language models (LLMs) to close the novice-expert knowledge gap in remediating math mistakes. We contribute Bridge, a method that uses cognitive task analysis to translate an expert{'}s latent thought process into a decision-making model for remediation. This involves an expert identifying (A) the student{'}s error, (B) a remediation strategy, and (C) their intention before generating a response. We construct a dataset of 700 real tutoring conversations, annotated by experts with their decisions. We evaluate state-of-the-art LLMs on our dataset and find that the expert{'}s decision-making model is critical for LLMs to close the gap: responses from GPT4 with expert decisions (e.g., {``}simplify the problem{''}) are +76{\%} more preferred than without. Additionally, context-sensitive decisions are critical to closing pedagogical gaps: random decisions decrease GPT4{'}s response quality by -97{\%} than expert decisions. Our work shows the potential of embedding expert thought processes in LLM generations to enhance their capability to bridge novice-expert knowledge gaps. Our dataset and code can be found at: https://github.com/rosewang2008/bridge.""",26,inproceedings,2024,"@inproceedings{wang-etal-2024-bridging,
    title = {""Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.120""},
    author = {""Wang, Rose  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""2174--2199""},
    abstract = {""Scaling high-quality tutoring remains a major challenge in education. Due to growing demand, many platforms employ novice tutors who, unlike experienced educators, struggle to address student mistakes and thus fail to seize prime learning opportunities. Our work explores the potential of large language models (LLMs) to close the novice-expert knowledge gap in remediating math mistakes. We contribute Bridge, a method that uses cognitive task analysis to translate an expert{'}s latent thought process into a decision-making model for remediation. This involves an expert identifying (A) the student{'}s error, (B) a remediation strategy, and (C) their intention before generating a response. We construct a dataset of 700 real tutoring conversations, annotated by experts with their decisions. We evaluate state-of-the-art LLMs on our dataset and find that the expert{'}s decision-making model is critical for LLMs to close the gap: responses from GPT4 with expert decisions (e.g., {``}simplify the problem{''}) are +76{\%} more preferred than without. Additionally, context-sensitive decisions are critical to closing pedagogical gaps: random decisions decrease GPT4{'}s response quality by -97{\%} than expert decisions. Our work shows the potential of embedding expert thought processes in LLM generations to enhance their capability to bridge novice-expert knowledge gaps. Our dataset and code can be found at: https://github.com/rosewang2008/bridge.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Towards Improved Multi-Source Attribution for Long-Form Answer Generation,https://aclanthology.org/2024.naacl-long.216,,"""Teaching large language models (LLMs) to generate text with attribution to evidence sources can reduce hallucinations, improve verifiability in question answering systems (QA), and increase reliability of retrieval augmented LLMs. Despite gaining increasing popularity for usage in QA systems and search engines, current LLMs struggle with attribution for long-form responses which require reasoning over multiple evidence sources. To address this, in this paper we aim to improve the attribution capability of LLMs for long-form answer generation to multiple sources, with multiple citations per sentence. However, data for training multi-source attributable QA systems is difficult and expensive to annotate, and therefore scarce. To overcome this challenge, we transform existing QA datasets for this task (MultiAttr), and empirically demonstrate, on a wide range of attribution benchmark datasets, that fine-tuning on MultiAttr provides significant improvements over training only on the target QA domain. Lastly, to fill a gap in existing benchmarks, we present a multi-source attribution dataset containing multi-paragraph answers, PolitiICite, based on PolitiFact articles that discuss events closely related to implementation statuses of election promises.""",14,inproceedings,2024,"@inproceedings{patel-etal-2024-towards,
    title = {""Towards Improved Multi-Source Attribution for Long-Form Answer Generation""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.216""},
    author = {""Patel, Nilay  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""3906--3919""},
    abstract = {""Teaching large language models (LLMs) to generate text with attribution to evidence sources can reduce hallucinations, improve verifiability in question answering systems (QA), and increase reliability of retrieval augmented LLMs. Despite gaining increasing popularity for usage in QA systems and search engines, current LLMs struggle with attribution for long-form responses which require reasoning over multiple evidence sources. To address this, in this paper we aim to improve the attribution capability of LLMs for long-form answer generation to multiple sources, with multiple citations per sentence. However, data for training multi-source attributable QA systems is difficult and expensive to annotate, and therefore scarce. To overcome this challenge, we transform existing QA datasets for this task (MultiAttr), and empirically demonstrate, on a wide range of attribution benchmark datasets, that fine-tuning on MultiAttr provides significant improvements over training only on the target QA domain. Lastly, to fill a gap in existing benchmarks, we present a multi-source attribution dataset containing multi-paragraph answers, PolitiICite, based on PolitiFact articles that discuss events closely related to implementation statuses of election promises.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
"In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax",https://aclanthology.org/2024.naacl-long.267,,"""In-context learning (ICL) is now a common method for teaching large language models (LLMs) new tasks: given labeled examples in the input context, the LLM learns to perform the task without weight updates. Do models guided via ICL infer the underlying structure of the task defined by the context, or do they rely on superficial heuristics that only generalize to identically distributed examples? We address this question using transformations tasks and an NLI task that assess sensitivity to syntax{---}a requirement for robust language understanding. We further investigate whether out-of-distribution generalization can be improved via chain-of-thought prompting, where the model is provided with a sequence of intermediate computation steps that illustrate how the task ought to be performed. In experiments with models from the GPT, PaLM, and Llama 2 families, we find large variance across LMs. The variance is explained more by the composition of the pre-training corpus and supervision methods than by model size; in particular, models pre-trained on code generalize better, and benefit more from chain-of-thought prompting.""",19,inproceedings,2024,"@inproceedings{mueller-etal-2024-context,
    title = {""In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.267""},
    author = {""Mueller, Aaron  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""4761--4779""},
    abstract = {""In-context learning (ICL) is now a common method for teaching large language models (LLMs) new tasks: given labeled examples in the input context, the LLM learns to perform the task without weight updates. Do models guided via ICL infer the underlying structure of the task defined by the context, or do they rely on superficial heuristics that only generalize to identically distributed examples? We address this question using transformations tasks and an NLI task that assess sensitivity to syntax{---}a requirement for robust language understanding. We further investigate whether out-of-distribution generalization can be improved via chain-of-thought prompting, where the model is provided with a sequence of intermediate computation steps that illustrate how the task ought to be performed. In experiments with models from the GPT, PaLM, and Llama 2 families, we find large variance across LMs. The variance is explained more by the composition of the pre-training corpus and supervision methods than by model size; in particular, models pre-trained on code generalize better, and benefit more from chain-of-thought prompting.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Teaching Language Models to Self-Improve through Interactive Demonstrations,https://aclanthology.org/2024.naacl-long.287,,"""The self-improving ability of large language models (LLMs), enabled by prompting them to analyze and revise their own outputs, has garnered significant interest in recent research. However, this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones. To reduce this gap, we introduce TriPosT, a training algorithm that endows smaller models with such self-improvement ability, and show that our approach can improve LLaMA-7B{'}s performance on math and reasoning tasks by up to 7.13{\%}. In contrast to prior work, we achieve this by using the smaller model to interact with LLMs to collect feedback and improvements on *its own generations*. We then replay this experience to train the small model. Our experiments on four math and reasoning datasets show that the interactive experience of learning from and correcting its *own* mistakes is crucial for small models to improve their performance.""",23,inproceedings,2024,"@inproceedings{yu-etal-2024-teaching,
    title = {""Teaching Language Models to Self-Improve through Interactive Demonstrations""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.287""},
    author = {""Yu, Xiao  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""5127--5149""},
    abstract = {""The self-improving ability of large language models (LLMs), enabled by prompting them to analyze and revise their own outputs, has garnered significant interest in recent research. However, this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones. To reduce this gap, we introduce TriPosT, a training algorithm that endows smaller models with such self-improvement ability, and show that our approach can improve LLaMA-7B{'}s performance on math and reasoning tasks by up to 7.13{\%}. In contrast to prior work, we achieve this by using the smaller model to interact with LLMs to collect feedback and improvements on *its own generations*. We then replay this experience to train the small model. Our experiments on four math and reasoning datasets show that the interactive experience of learning from and correcting its *own* mistakes is crucial for small models to improve their performance.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{MT}-{PATCHER}: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation,https://aclanthology.org/2024.naacl-long.358,,"""Large Language Models (LLM) have demonstrated their strong ability in the field of machine translation, yet they suffer from high computational cost and latency. Therefore, transferring translation knowledge from giant LLMs to medium-sized machine translation models is a promising research direction. However, traditional knowledge distillation methods ignore the capability of student and teacher models, therefore repeatedly teaching student models on the knowledge they have learned, and failing to extend to novel contexts and knowledge. In this paper, we propose a framework called MT-Patcher, which transfers knowledge from LLMs to existing MT models in a selective, comprehensive and proactive manner. Considering the current translation ability of student MT models, we only identify and correct their translation errors, instead of distilling the whole translation from the teacher. Leveraging the strong language abilities of LLMs, we instruct LLM teachers to synthesize diverse contexts and anticipate more potential errors for the student. Experiment results on translating both specific language phenomena and general MT benchmarks demonstrate that finetuning the MT model on about 10{\%} examples can achieve comparable results to the traditional knowledge distillation method, and synthesized potential errors and diverse contexts further improve MT performances on unseen contexts and words.""",15,inproceedings,2024,"@inproceedings{li-etal-2024-mt,
    title = {""{MT}-{PATCHER}: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.358""},
    author = {""Li, Jiahuan  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""6445--6459""},
    abstract = {""Large Language Models (LLM) have demonstrated their strong ability in the field of machine translation, yet they suffer from high computational cost and latency. Therefore, transferring translation knowledge from giant LLMs to medium-sized machine translation models is a promising research direction. However, traditional knowledge distillation methods ignore the capability of student and teacher models, therefore repeatedly teaching student models on the knowledge they have learned, and failing to extend to novel contexts and knowledge. In this paper, we propose a framework called MT-Patcher, which transfers knowledge from LLMs to existing MT models in a selective, comprehensive and proactive manner. Considering the current translation ability of student MT models, we only identify and correct their translation errors, instead of distilling the whole translation from the teacher. Leveraging the strong language abilities of LLMs, we instruct LLM teachers to synthesize diverse contexts and anticipate more potential errors for the student. Experiment results on translating both specific language phenomena and general MT benchmarks demonstrate that finetuning the MT model on about 10{\%} examples can achieve comparable results to the traditional knowledge distillation method, and synthesized potential errors and diverse contexts further improve MT performances on unseen contexts and words.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Analysis of State-Level Legislative Process in Enhanced Linguistic and Nationwide Network Contexts,https://aclanthology.org/2024.naacl-long.411,,"""State bills have a significant impact on various aspects of society, including health, education, and the economy. Consequently, it is crucial to conduct systematic research on state bills before and after they are enacted to evaluate their benefits and drawbacks, thereby guiding future decision-making. In this work, we developed the first state-level deep learning framework that (1) handles the complex and inconsistent language of policies across US states using generative large language models and (2) decodes legislators{'} behavior and implications of state policies by establishing a shared nationwide network, enriched with diverse contexts, such as information on interest groups influencing public policy and legislators{'} courage test results, which reflect their political positions.""",19,inproceedings,2024,"@inproceedings{davoodi-goldwasser-2024-analysis,
    title = {""Analysis of State-Level Legislative Process in Enhanced Linguistic and Nationwide Network Contexts""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-long.411""},
    author = {""Davoodi, Maryam  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)""},
    pages = {""7404--7422""},
    abstract = {""State bills have a significant impact on various aspects of society, including health, education, and the economy. Consequently, it is crucial to conduct systematic research on state bills before and after they are enacted to evaluate their benefits and drawbacks, thereby guiding future decision-making. In this work, we developed the first state-level deep learning framework that (1) handles the complex and inconsistent language of policies across US states using generative large language models and (2) decodes legislators{'} behavior and implications of state policies by establishing a shared nationwide network, enriched with diverse contexts, such as information on interest groups influencing public policy and legislators{'} courage test results, which reflect their political positions.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Uncertainty Estimation in Large Language Models to Support Biodiversity Conservation,https://aclanthology.org/2024.naacl-industry.31,,"""Large Language Models (LLM) provide significant value in question answering (QA) scenarios and have practical application in complex decision-making contexts, such as biodiversity conservation. However, despite substantial performance improvements, they may still produce inaccurate outcomes. Consequently, incorporating uncertainty quantification alongside predictions is essential for mitigating the potential risks associated with their use. This study introduces an exploratory analysis of the application of Monte Carlo Dropout (MCD) and Expected Calibration Error (ECE) to assess the uncertainty of generative language models. To that end, we analyzed two publicly available language models (Falcon-7B and DistilGPT-2). Our findings suggest the viability of employing ECE as a metric to estimate uncertainty in generative LLM. The findings from this research contribute to a broader project aiming at facilitating free and open access to standardized and integrated data and services about Costa Rica{'}s biodiversity to support the development of science, education, and biodiversity conservation.""",11,inproceedings,2024,"@inproceedings{mora-cross-calderon-ramirez-2024-uncertainty,
    title = {""Uncertainty Estimation in Large Language Models to Support Biodiversity Conservation""},
    editor = {""Yang, Yi  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.naacl-industry.31""},
    author = {""Mora-Cross, Maria  and},
    booktitle = {""Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)""},
    pages = {""368--378""},
    abstract = {""Large Language Models (LLM) provide significant value in question answering (QA) scenarios and have practical application in complex decision-making contexts, such as biodiversity conservation. However, despite substantial performance improvements, they may still produce inaccurate outcomes. Consequently, incorporating uncertainty quantification alongside predictions is essential for mitigating the potential risks associated with their use. This study introduces an exploratory analysis of the application of Monte Carlo Dropout (MCD) and Expected Calibration Error (ECE) to assess the uncertainty of generative language models. To that end, we analyzed two publicly available language models (Falcon-7B and DistilGPT-2). Our findings suggest the viability of employing ECE as a metric to estimate uncertainty in generative LLM. The findings from this research contribute to a broader project aiming at facilitating free and open access to standardized and integrated data and services about Costa Rica{'}s biodiversity to support the development of science, education, and biodiversity conservation.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Agenda-Driven Question Generation: A Case Study in the Courtroom Domain,https://aclanthology.org/2024.lrec-main.49,,"""This paper introduces a novel problem of automated question generation for courtroom examinations, CourtQG. While question generation has been studied in domains such as educational testing and product description, CourtQG poses several unique challenges owing to its non-cooperative and agenda-driven nature. Specifically, not only the generated questions need to be relevant to the case and underlying context, they also have to achieve certain objectives such as challenging the opponent{'}s arguments and/or revealing potential inconsistencies in their answers. We propose to leverage large language models (LLM) for CourtQG by fine-tuning them on two auxiliary tasks, agenda explanation (i.e., uncovering the underlying intents) and question type prediction. We additionally propose cold-start generation of questions from background documents without relying on examination history. We construct a dataset to evaluate our proposed method and show that it generates better questions according to standard metrics when compared to several baselines.""",12,inproceedings,2024,"@inproceedings{fung-etal-2024-agenda-driven,
    title = {""Agenda-Driven Question Generation: A Case Study in the Courtroom Domain""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.49""},
    author = {""Fung, Yi  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""572--583""},
    abstract = {""This paper introduces a novel problem of automated question generation for courtroom examinations, CourtQG. While question generation has been studied in domains such as educational testing and product description, CourtQG poses several unique challenges owing to its non-cooperative and agenda-driven nature. Specifically, not only the generated questions need to be relevant to the case and underlying context, they also have to achieve certain objectives such as challenging the opponent{'}s arguments and/or revealing potential inconsistencies in their answers. We propose to leverage large language models (LLM) for CourtQG by fine-tuning them on two auxiliary tasks, agenda explanation (i.e., uncovering the underlying intents) and question type prediction. We additionally propose cold-start generation of questions from background documents without relying on examination history. We construct a dataset to evaluate our proposed method and show that it generates better questions according to standard metrics when compared to several baselines.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Argument Quality Assessment in the Age of Instruction-Following Large Language Models,https://aclanthology.org/2024.lrec-main.135,,"""The computational treatment of arguments on controversial issues has been subject to extensive NLP research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. A critical task in any such application is the assessment of an argument{'}s quality - but it is also particularly challenging. In this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. We argue that the capabilities of instruction-following large language models (LLMs) to leverage knowledge across contexts enable a much more reliable assessment. Rather than just fine-tuning LLMs towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to solve argument-related problems. We discuss the real-world opportunities and ethical issues emerging thereby.""",20,inproceedings,2024,"@inproceedings{wachsmuth-etal-2024-argument-quality,
    title = {""Argument Quality Assessment in the Age of Instruction-Following Large Language Models""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.135""},
    author = {""Wachsmuth, Henning  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""1519--1538""},
    abstract = {""The computational treatment of arguments on controversial issues has been subject to extensive NLP research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. A critical task in any such application is the assessment of an argument{'}s quality - but it is also particularly challenging. In this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. We argue that the capabilities of instruction-following large language models (LLMs) to leverage knowledge across contexts enable a much more reliable assessment. Rather than just fine-tuning LLMs towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to solve argument-related problems. We discuss the real-world opportunities and ethical issues emerging thereby.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Assessing Online Writing Feedback Resources: Generative {AI} vs. Good Samaritans,https://aclanthology.org/2024.lrec-main.144,,"""Providing constructive feedback on student essays is a critical factor in improving educational results; however, it presents notable difficulties and may demand substantial time investments, especially when aiming to deliver individualized and informative guidance. This study undertakes a comparative analysis of two readily available online resources for students seeking to hone their skills in essay writing for English proficiency tests: 1) essayforum.com, a widely used platform where students can submit their essays and receive feedback from volunteer educators at no cost, and 2) Large Language Models (LLMs) such as ChatGPT. By contrasting the feedback obtained from these two resources, we posit that they can mutually reinforce each other and are more helpful if employed in conjunction when seeking no-cost online assistance. The findings of this research shed light on the challenges of providing personalized feedback and highlight the potential of AI in advancing the field of automated essay evaluation.""",7,inproceedings,2024,"@inproceedings{behzad-etal-2024-assessing-online,
    title = {""Assessing Online Writing Feedback Resources: Generative {AI} vs. Good Samaritans""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.144""},
    author = {""Behzad, Shabnam  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""1638--1644""},
    abstract = {""Providing constructive feedback on student essays is a critical factor in improving educational results; however, it presents notable difficulties and may demand substantial time investments, especially when aiming to deliver individualized and informative guidance. This study undertakes a comparative analysis of two readily available online resources for students seeking to hone their skills in essay writing for English proficiency tests: 1) essayforum.com, a widely used platform where students can submit their essays and receive feedback from volunteer educators at no cost, and 2) Large Language Models (LLMs) such as ChatGPT. By contrasting the feedback obtained from these two resources, we posit that they can mutually reinforce each other and are more helpful if employed in conjunction when seeking no-cost online assistance. The findings of this research shed light on the challenges of providing personalized feedback and highlight the potential of AI in advancing the field of automated essay evaluation.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Clue-Instruct: Text-Based Clue Generation for Educational Crossword Puzzles,https://aclanthology.org/2024.lrec-main.297,,"""Crossword puzzles are popular linguistic games often used as tools to engage students in learning. Educational crosswords are characterized by less cryptic and more factual clues that distinguish them from traditional crossword puzzles. Despite there exist several publicly available clue-answer pair databases for traditional crosswords, educational clue-answer pairs datasets are missing. In this article, we propose a methodology to build educational clue generation datasets that can be used to instruct Large Language Models (LLMs). By gathering from Wikipedia pages informative content associated with relevant keywords, we use Large Language Models to automatically generate pedagogical clues related to the given input keyword and its context. With such an approach, we created clue-instruct, a dataset containing 44,075 unique examples with text-keyword pairs associated with three distinct crossword clues. We used clue-instruct to instruct different LLMs to generate educational clues from a given input content and keyword. Both human and automatic evaluations confirmed the quality of the generated clues, thus validating the effectiveness of our approach.""",10,inproceedings,2024,"@inproceedings{zugarini-etal-2024-clue-instruct,
    title = {""Clue-Instruct: Text-Based Clue Generation for Educational Crossword Puzzles""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.297""},
    author = {""Zugarini, Andrea  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""3347--3356""},
    abstract = {""Crossword puzzles are popular linguistic games often used as tools to engage students in learning. Educational crosswords are characterized by less cryptic and more factual clues that distinguish them from traditional crossword puzzles. Despite there exist several publicly available clue-answer pair databases for traditional crosswords, educational clue-answer pairs datasets are missing. In this article, we propose a methodology to build educational clue generation datasets that can be used to instruct Large Language Models (LLMs). By gathering from Wikipedia pages informative content associated with relevant keywords, we use Large Language Models to automatically generate pedagogical clues related to the given input keyword and its context. With such an approach, we created clue-instruct, a dataset containing 44,075 unique examples with text-keyword pairs associated with three distinct crossword clues. We used clue-instruct to instruct different LLMs to generate educational clues from a given input content and keyword. Both human and automatic evaluations confirmed the quality of the generated clues, thus validating the effectiveness of our approach.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Educational Dialogue Systems for Visually Impaired Students: Introducing a Task-Oriented User-Agent Corpus,https://aclanthology.org/2024.lrec-main.489,,"""This paper describes a corpus consisting of real-world dialogues in English between users and a task-oriented conversational agent, with interactions revolving around the description of finite state automata. The creation of this corpus is part of a larger research project aimed at developing tools for an easier access to educational content, especially in STEM fields, for users with visual impairments. The development of this corpus was precisely motivated by the aim of providing a useful resource to support the design of such tools. The core feature of this corpus is that its creation involved both sighted and visually impaired participants, thus allowing for a greater diversity of perspectives and giving the opportunity to identify possible differences in the way the two groups of participants interacted with the agent. The paper introduces this corpus, giving an account of the process that led to its creation, i.e. the methodology followed to obtain the data, the annotation scheme adopted, and the analysis of the results. Finally, the paper reports the results of a classification experiment on the annotated corpus, and an additional experiment to assess the annotation capabilities of three large language models, in view of a further expansion of the corpus.""",13,inproceedings,2024,"@inproceedings{di-nuovo-etal-2024-educational-dialogue,
    title = {""Educational Dialogue Systems for Visually Impaired Students: Introducing a Task-Oriented User-Agent Corpus""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.489""},
    author = {""Di Nuovo, Elisa  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""5507--5519""},
    abstract = {""This paper describes a corpus consisting of real-world dialogues in English between users and a task-oriented conversational agent, with interactions revolving around the description of finite state automata. The creation of this corpus is part of a larger research project aimed at developing tools for an easier access to educational content, especially in STEM fields, for users with visual impairments. The development of this corpus was precisely motivated by the aim of providing a useful resource to support the design of such tools. The core feature of this corpus is that its creation involved both sighted and visually impaired participants, thus allowing for a greater diversity of perspectives and giving the opportunity to identify possible differences in the way the two groups of participants interacted with the agent. The paper introduces this corpus, giving an account of the process that led to its creation, i.e. the methodology followed to obtain the data, the annotation scheme adopted, and the analysis of the results. Finally, the paper reports the results of a classification experiment on the annotated corpus, and an additional experiment to assess the annotation capabilities of three large language models, in view of a further expansion of the corpus.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Extracting Social Determinants of Health from Pediatric Patient Notes Using Large Language Models: Novel Corpus and Methods,https://aclanthology.org/2024.lrec-main.618,,"""Social determinants of health (SDoH) play a critical role in shaping health outcomes, particularly in pediatric populations where interventions can have long-term implications. SDoH are frequently studied in the Electronic Health Record (EHR), which provides a rich repository for diverse patient data. In this work, we present a novel annotated corpus, the Pediatric Social History Annotation Corpus (PedSHAC), and evaluate the automatic extraction of detailed SDoH representations using fine-tuned and in-context learning methods with Large Language Models (LLMs). PedSHAC comprises annotated social history sections from 1,260 clinical notes obtained from pediatric patients within the University of Washington (UW) hospital system. Employing an event-based annotation scheme, PedSHAC captures ten distinct health determinants to encompass living and economic stability, prior trauma, education access, substance use history, and mental health with an overall annotator agreement of 81.9 F1. Our proposed fine-tuning LLM-based extractors achieve high performance at 78.4 F1 for event arguments. In-context learning approaches with GPT-4 demonstrate promise for reliable SDoH extraction with limited annotated examples, with extraction performance at 82.3 F1 for event triggers.""",12,inproceedings,2024,"@inproceedings{fu-etal-2024-extracting-social,
    title = {""Extracting Social Determinants of Health from Pediatric Patient Notes Using Large Language Models: Novel Corpus and Methods""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.618""},
    author = {Fu, Yujuan  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""7045--7056""},
    abstract = {""Social determinants of health (SDoH) play a critical role in shaping health outcomes, particularly in pediatric populations where interventions can have long-term implications. SDoH are frequently studied in the Electronic Health Record (EHR), which provides a rich repository for diverse patient data. In this work, we present a novel annotated corpus, the Pediatric Social History Annotation Corpus (PedSHAC), and evaluate the automatic extraction of detailed SDoH representations using fine-tuned and in-context learning methods with Large Language Models (LLMs). PedSHAC comprises annotated social history sections from 1,260 clinical notes obtained from pediatric patients within the University of Washington (UW) hospital system. Employing an event-based annotation scheme, PedSHAC captures ten distinct health determinants to encompass living and economic stability, prior trauma, education access, substance use history, and mental health with an overall annotator agreement of 81.9 F1. Our proposed fine-tuning LLM-based extractors achieve high performance at 78.4 F1 for event arguments. In-context learning approaches with GPT-4 demonstrate promise for reliable SDoH extraction with limited annotated examples, with extraction performance at 82.3 F1 for event triggers.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Finding Educationally Supportive Contexts for Vocabulary Learning with Attention-Based Models,https://aclanthology.org/2024.lrec-main.640,,"""When learning new vocabulary, both humans and machines acquire critical information about the meaning of an unfamiliar word through contextual information in a sentence or passage. However, not all contexts are equally helpful for learning an unfamiliar {`}target{'} word. Some contexts provide a rich set of semantic clues to the target word{'}s meaning, while others are less supportive. We explore the task of finding educationally supportive contexts with respect to a given target word for vocabulary learning scenarios, particularly for improving student literacy skills. Because of their inherent context-based nature, attention-based deep learning methods provide an ideal starting point. We evaluate attention-based approaches for predicting the amount of educational support from contexts, ranging from a simple custom model using pre-trained embeddings with an additional attention layer, to a commercial Large Language Model (LLM). Using an existing major benchmark dataset for educational context support prediction, we found that a sophisticated but generic LLM had poor performance, while a simpler model using a custom attention-based approach achieved the best-known performance to date on this dataset.""",10,inproceedings,2024,"@inproceedings{nam-etal-2024-finding-educationally,
    title = {""Finding Educationally Supportive Contexts for Vocabulary Learning with Attention-Based Models""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.640""},
    author = {""Nam, Sungjin  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""7286--7295""},
    abstract = {""When learning new vocabulary, both humans and machines acquire critical information about the meaning of an unfamiliar word through contextual information in a sentence or passage. However, not all contexts are equally helpful for learning an unfamiliar {`}target{'} word. Some contexts provide a rich set of semantic clues to the target word{'}s meaning, while others are less supportive. We explore the task of finding educationally supportive contexts with respect to a given target word for vocabulary learning scenarios, particularly for improving student literacy skills. Because of their inherent context-based nature, attention-based deep learning methods provide an ideal starting point. We evaluate attention-based approaches for predicting the amount of educational support from contexts, ranging from a simple custom model using pre-trained embeddings with an additional attention layer, to a commercial Large Language Model (LLM). Using an existing major benchmark dataset for educational context support prediction, we found that a sophisticated but generic LLM had poor performance, while a simpler model using a custom attention-based approach achieved the best-known performance to date on this dataset.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Incorporating Word-level Phonemic Decoding into Readability Assessment,https://aclanthology.org/2024.lrec-main.788,,"""Current approaches in automatic readability assessment have found success with the use of large language models and transformer architectures. These techniques lead to accuracy improvement, but they do not offer the interpretability that is uniquely required by the audience most often employing readability assessment tools: teachers and educators. Recent work that employs more traditional machine learning methods has highlighted the linguistic importance of considering semantic and syntactic characteristics of text in readability assessment by utilizing handcrafted feature sets. Research in Education suggests that, in addition to semantics and syntax, phonetic and orthographic instruction are necessary for children to progress through the stages of reading and spelling development; children must first learn to decode the letters and symbols on a page to recognize words and phonemes and their connection to speech sounds. Here, we incorporate this word-level phonemic decoding process into readability assessment by crafting a phonetically-based feature set for grade-level classification for English. Our resulting feature set shows comparable performance to much larger, semantically- and syntactically-based feature sets, supporting the linguistic value of orthographic and phonetic considerations in readability assessment.""",12,inproceedings,2024,"@inproceedings{pinney-etal-2024-incorporating-word,
    title = {""Incorporating Word-level Phonemic Decoding into Readability Assessment""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.788""},
    author = {""Pinney, Christine  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""8998--9009""},
    abstract = {""Current approaches in automatic readability assessment have found success with the use of large language models and transformer architectures. These techniques lead to accuracy improvement, but they do not offer the interpretability that is uniquely required by the audience most often employing readability assessment tools: teachers and educators. Recent work that employs more traditional machine learning methods has highlighted the linguistic importance of considering semantic and syntactic characteristics of text in readability assessment by utilizing handcrafted feature sets. Research in Education suggests that, in addition to semantics and syntax, phonetic and orthographic instruction are necessary for children to progress through the stages of reading and spelling development; children must first learn to decode the letters and symbols on a page to recognize words and phonemes and their connection to speech sounds. Here, we incorporate this word-level phonemic decoding process into readability assessment by crafting a phonetically-based feature set for grade-level classification for English. Our resulting feature set shows comparable performance to much larger, semantically- and syntactically-based feature sets, supporting the linguistic value of orthographic and phonetic considerations in readability assessment.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{LHMKE}: A Large-scale Holistic Multi-subject Knowledge Evaluation Benchmark for {C}hinese Large Language Models,https://aclanthology.org/2024.lrec-main.916,,"""Chinese Large Language Models (LLMs) have recently demonstrated impressive capabilities across various NLP benchmarks and real-world applications. However, the existing benchmarks for comprehensively evaluating these LLMs are still insufficient, particularly in terms of measuring knowledge that LLMs capture. Current datasets collect questions from Chinese examinations across different subjects and educational levels to address this issue. Yet, these benchmarks primarily focus on objective questions such as multiple-choice questions, leading to a lack of diversity in question types. To tackle this problem, we propose LHMKE, a Large-scale, Holistic, and Multi-subject Knowledge Evaluation benchmark in this paper. LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of Chinese LLMs. It encompasses 10,465 questions across 75 tasks covering 30 subjects, ranging from primary school to professional certification exams. Notably, LHMKE includes both objective and subjective questions, offering a more holistic evaluation of the knowledge level of LLMs. We have assessed 11 Chinese LLMs under the zero-shot setting, which aligns with real examinations, and compared their performance across different subjects. We also conduct an in-depth analysis to check whether GPT-4 can automatically score subjective predictions. Our findings suggest that LHMKE is a challenging and advanced testbed for Chinese LLMs.""",12,inproceedings,2024,"@inproceedings{liu-etal-2024-lhmke-large,
    title = {""{LHMKE}: A Large-scale Holistic Multi-subject Knowledge Evaluation Benchmark for {C}hinese Large Language Models""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.916""},
    author = {""Liu, Chuang  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""10476--10487""},
    abstract = {""Chinese Large Language Models (LLMs) have recently demonstrated impressive capabilities across various NLP benchmarks and real-world applications. However, the existing benchmarks for comprehensively evaluating these LLMs are still insufficient, particularly in terms of measuring knowledge that LLMs capture. Current datasets collect questions from Chinese examinations across different subjects and educational levels to address this issue. Yet, these benchmarks primarily focus on objective questions such as multiple-choice questions, leading to a lack of diversity in question types. To tackle this problem, we propose LHMKE, a Large-scale, Holistic, and Multi-subject Knowledge Evaluation benchmark in this paper. LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of Chinese LLMs. It encompasses 10,465 questions across 75 tasks covering 30 subjects, ranging from primary school to professional certification exams. Notably, LHMKE includes both objective and subjective questions, offering a more holistic evaluation of the knowledge level of LLMs. We have assessed 11 Chinese LLMs under the zero-shot setting, which aligns with real examinations, and compared their performance across different subjects. We also conduct an in-depth analysis to check whether GPT-4 can automatically score subjective predictions. Our findings suggest that LHMKE is a challenging and advanced testbed for Chinese LLMs.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Teaching Large Language Models to Translate on Low-resource Languages with Textbook Prompting,https://aclanthology.org/2024.lrec-main.1362,,"""Large Language Models (LLMs) have achieved impressive results in Machine Translation by simply following instructions, even without training on parallel data. However, LLMs still face challenges on low-resource languages due to the lack of pre-training data. In real-world situations, humans can become proficient in their native languages through abundant and meaningful social interactions and can also learn foreign languages effectively using well-organized textbooks. Drawing inspiration from human learning patterns, we introduce the Translate After LEarNing Textbook (TALENT) approach, which aims to enhance LLMs{'} ability to translate low-resource languages by learning from a textbook. TALENT follows a step-by-step process: (1) Creating a Textbook for low-resource languages. (2) Guiding LLMs to absorb the Textbook{'}s content for Syntax Patterns. (3) Enhancing translation by utilizing the Textbook and Syntax Patterns. We thoroughly assess TALENT{'}s performance using 112 low-resource languages from FLORES-200 with two LLMs: ChatGPT and BLOOMZ. Evaluation across three different metrics reveals that TALENT consistently enhances translation performance by 14.8{\%} compared to zero-shot baselines. Further analysis demonstrates that TALENT not only improves LLMs{'} comprehension of low-resource languages but also equips them with the knowledge needed to generate accurate and fluent sentences in these languages.""",13,inproceedings,2024,"@inproceedings{guo-etal-2024-teaching-large,
    title = {""Teaching Large Language Models to Translate on Low-resource Languages with Textbook Prompting""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.1362""},
    author = {""Guo, Ping  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""15685--15697""},
    abstract = {""Large Language Models (LLMs) have achieved impressive results in Machine Translation by simply following instructions, even without training on parallel data. However, LLMs still face challenges on low-resource languages due to the lack of pre-training data. In real-world situations, humans can become proficient in their native languages through abundant and meaningful social interactions and can also learn foreign languages effectively using well-organized textbooks. Drawing inspiration from human learning patterns, we introduce the Translate After LEarNing Textbook (TALENT) approach, which aims to enhance LLMs{'} ability to translate low-resource languages by learning from a textbook. TALENT follows a step-by-step process: (1) Creating a Textbook for low-resource languages. (2) Guiding LLMs to absorb the Textbook{'}s content for Syntax Patterns. (3) Enhancing translation by utilizing the Textbook and Syntax Patterns. We thoroughly assess TALENT{'}s performance using 112 low-resource languages from FLORES-200 with two LLMs: ChatGPT and BLOOMZ. Evaluation across three different metrics reveals that TALENT consistently enhances translation performance by 14.8{\%} compared to zero-shot baselines. Further analysis demonstrates that TALENT not only improves LLMs{'} comprehension of low-resource languages but also equips them with the knowledge needed to generate accurate and fluent sentences in these languages.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Would You Like to Make a Donation? A Dialogue System to Persuade You to Donate,https://aclanthology.org/2024.lrec-main.1540,,"""Persuasive dialogue is a type of dialogue commonly used in human daily life in scenarios such as promotion and sales. Its purpose is to influence the decision, attitude or behavior of another person through the dialogue process. Persuasive automated dialogue systems can be applied in a variety of fields such as charity, business, education, and healthcare. Regardless of their amazing abilities, Large Language Models (LLMs) such as ChatGPT still have limitations in persuasion. There is few research dedicated to persuasive dialogue in the current research of automated dialogue systems. In this paper, we introduce a persuasive automated dialogue system. In the system, a context-aware persuasion strategy selection module makes dialogue system flexibly use different persuasion strategies to persuade users; Then a natural language generation module is used to output a response. We also propose a persuasiveness prediction model to automatically evaluate the persuasiveness of generated text. Experimental results show that our dialogue system can achieve better performance on several automated evaluation metrics than baseline models.""",11,inproceedings,2024,"@inproceedings{song-wang-2024-like-make,
    title = {""Would You Like to Make a Donation? A Dialogue System to Persuade You to Donate""},
    editor = {""Calzolari, Nicoletta  and},
    month = {may},
    year = {""2024""},
    address = {""Torino, Italia""},
    publisher = {""ELRA and ICCL""},
    url = {""https://aclanthology.org/2024.lrec-main.1540""},
    author = {""Song, Yuhan  and},
    booktitle = {""Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)""},
    pages = {""17707--17717""},
    abstract = {""Persuasive dialogue is a type of dialogue commonly used in human daily life in scenarios such as promotion and sales. Its purpose is to influence the decision, attitude or behavior of another person through the dialogue process. Persuasive automated dialogue systems can be applied in a variety of fields such as charity, business, education, and healthcare. Regardless of their amazing abilities, Large Language Models (LLMs) such as ChatGPT still have limitations in persuasion. There is few research dedicated to persuasive dialogue in the current research of automated dialogue systems. In this paper, we introduce a persuasive automated dialogue system. In the system, a context-aware persuasion strategy selection module makes dialogue system flexibly use different persuasion strategies to persuade users; Then a natural language generation module is used to output a response. We also propose a persuasiveness prediction model to automatically evaluate the persuasiveness of generated text. Experimental results show that our dialogue system can achieve better performance on several automated evaluation metrics than baseline models.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{LLM}-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?,https://aclanthology.org/2024.findings-naacl.29,,"""With the rapid development and widespread application of Large Language Models (LLMs), the use of Machine-Generated Text (MGT) has become increasingly common, bringing with it potential risks, especially in terms of quality and integrity in fields like news, education, and science. Current research mainly focuses on purely MGT detection, without adequately addressing mixed scenarios including AI-revised Human-Written Text (HWT) or human-revised MGT. To tackle this challenge, we define mixtext, a form of mixed text involving both AI and human-generated content. Then we introduce MixSet, the first dataset dedicated to studying these mixtext scenarios. Leveraging MixSet, we executed comprehensive experiments to assess the efficacy of prevalent MGT detectors in handling mixtext situations, evaluating their performance in terms of effectiveness, robustness, and generalization. Our findings reveal that existing detectors struggle to identify mixtext, particularly in dealing with subtle modifications and style adaptability. This research underscores the urgent need for more fine-grain detectors tailored for mixtext, offering valuable insights for future research. Code and Models are available at https://github.com/Dongping-Chen/MixSet.""",28,inproceedings,2024,"@inproceedings{zhang-etal-2024-llm,
    title = {""{LLM}-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.29""},
    author = {""Zhang, Qihui  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""409--436""},
    abstract = {""With the rapid development and widespread application of Large Language Models (LLMs), the use of Machine-Generated Text (MGT) has become increasingly common, bringing with it potential risks, especially in terms of quality and integrity in fields like news, education, and science. Current research mainly focuses on purely MGT detection, without adequately addressing mixed scenarios including AI-revised Human-Written Text (HWT) or human-revised MGT. To tackle this challenge, we define mixtext, a form of mixed text involving both AI and human-generated content. Then we introduce MixSet, the first dataset dedicated to studying these mixtext scenarios. Leveraging MixSet, we executed comprehensive experiments to assess the efficacy of prevalent MGT detectors in handling mixtext situations, evaluating their performance in terms of effectiveness, robustness, and generalization. Our findings reveal that existing detectors struggle to identify mixtext, particularly in dealing with subtle modifications and style adaptability. This research underscores the urgent need for more fine-grain detectors tailored for mixtext, offering valuable insights for future research. Code and Models are available at https://github.com/Dongping-Chen/MixSet.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training,https://aclanthology.org/2024.findings-naacl.52,,"""Recent advancements in language modeling have led to the emergenceof Large Language Models (LLMs) capable ofvarious natural language processing tasks.Despite their success in text-based tasks, applying LLMs to the speech domainremains limited and challenging. This paper presents BLOOMZMMS, a novel modelthat integrates a multilingual LLM with a multilingual speech encoder,aiming to harness the capabilities of LLMs for speech recognition and beyond.Utilizing a multi-instructional training approach, we demonstrate the transferabilityof linguistic knowledge from the text to the speech modality.Our experiments, conducted on 1900 hours of transcribed data from 139 languages,establish that a multilingual speech representation can be effectivelylearned and aligned with a multilingual LLM. While this learned representationinitially shows limitations in task generalization, we address this issue bygenerating synthetic targets in a multi-instructional style.Our zero-shot evaluation results confirm the robustness of our approach acrossmultiple tasks, including speech translation and multilingual spoken languageunderstanding, thereby opening new avenues for applying LLMs in the speech domain.""",21,inproceedings,2024,"@inproceedings{denisov-vu-2024-teaching,
    title = {""Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.52""},
    author = {""Denisov, Pavel  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""814--834""},
    abstract = {""Recent advancements in language modeling have led to the emergenceof Large Language Models (LLMs) capable ofvarious natural language processing tasks.Despite their success in text-based tasks, applying LLMs to the speech domainremains limited and challenging. This paper presents BLOOMZMMS, a novel modelthat integrates a multilingual LLM with a multilingual speech encoder,aiming to harness the capabilities of LLMs for speech recognition and beyond.Utilizing a multi-instructional training approach, we demonstrate the transferabilityof linguistic knowledge from the text to the speech modality.Our experiments, conducted on 1900 hours of transcribed data from 139 languages,establish that a multilingual speech representation can be effectivelylearned and aligned with a multilingual LLM. While this learned representationinitially shows limitations in task generalization, we address this issue bygenerating synthetic targets in a multi-instructional style.Our zero-shot evaluation results confirm the robustness of our approach acrossmultiple tasks, including speech translation and multilingual spoken languageunderstanding, thereby opening new avenues for applying LLMs in the speech domain.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{MIC}o: Preventative Detoxification of Large Language Models through Inhibition Control,https://aclanthology.org/2024.findings-naacl.110,,"""Large Language Models (LLMs) are powerful tools which have been both dominant and commonplace in the field of Artificial Intelligence. Yet, LLMs have a tendency to devolve into toxic degeneration, wherein otherwise safe and unproblematic models begin generating toxic content. For the sake of social responsibility and inspired by the biological mechanisms of inhibition control, we introduce the paradigm of Education for Societal Norms (ESN). By collecting and labeling examples as acceptable and unacceptable (in this case toxic and non-toxic), and including a corresponding acceptable rewrite with every unacceptable example, we introduce a new mechanism for LLM detoxification. We annotate a dataset of 2,850 entries and use it to fine-tune a model, which we call a Model with Inhibition Control (MICo). Evaluating this model on toxicity detection capability, rewrite detoxification, meaning preservation, and overall toxicity reduction, we discover significant improvements over the baseline model. In our experiments we show that overall toxicity of this model is more than 60{\%} reduced, with over 75{\%} reduction in severe toxicity.""",8,inproceedings,2024,"@inproceedings{siegelmann-etal-2024-mico,
    title = {""{MIC}o: Preventative Detoxification of Large Language Models through Inhibition Control""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.110""},
    author = {""Siegelmann, Roy  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""1696--1703""},
    abstract = {""Large Language Models (LLMs) are powerful tools which have been both dominant and commonplace in the field of Artificial Intelligence. Yet, LLMs have a tendency to devolve into toxic degeneration, wherein otherwise safe and unproblematic models begin generating toxic content. For the sake of social responsibility and inspired by the biological mechanisms of inhibition control, we introduce the paradigm of Education for Societal Norms (ESN). By collecting and labeling examples as acceptable and unacceptable (in this case toxic and non-toxic), and including a corresponding acceptable rewrite with every unacceptable example, we introduce a new mechanism for LLM detoxification. We annotate a dataset of 2,850 entries and use it to fine-tune a model, which we call a Model with Inhibition Control (MICo). Evaluating this model on toxicity detection capability, rewrite detoxification, meaning preservation, and overall toxicity reduction, we discover significant improvements over the baseline model. In our experiments we show that overall toxicity of this model is more than 60{\%} reduced, with over 75{\%} reduction in severe toxicity.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models,https://aclanthology.org/2024.findings-naacl.193,,"""Multiple-choice questions (MCQs) are ubiquitous in almost all levels of education since they are easy to administer, grade, and are a reliable format in assessments and practices. One of the most important aspects of MCQs is the distractors, i.e., incorrect options that are designed to target common errors or misconceptions among real students. To date, the task of crafting high-quality distractors largely remains a labor and time-intensive process for teachers and learning content designers, which has limited scalability. In this work, we study the task of automated distractor generation in the domain of math MCQs and explore a wide variety of large language model (LLM)-based approaches, from in-context learning to fine-tuning. We conduct extensive experiments using a real-world math MCQ dataset and find that although LLMs can generate some mathematically valid distractors, they are less adept at anticipating common errors or misconceptions among real students.""",16,inproceedings,2024,"@inproceedings{feng-etal-2024-exploring,
    title = {""Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.193""},
    author = {""Feng, Wanyong  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""3067--3082""},
    abstract = {""Multiple-choice questions (MCQs) are ubiquitous in almost all levels of education since they are easy to administer, grade, and are a reliable format in assessments and practices. One of the most important aspects of MCQs is the distractors, i.e., incorrect options that are designed to target common errors or misconceptions among real students. To date, the task of crafting high-quality distractors largely remains a labor and time-intensive process for teachers and learning content designers, which has limited scalability. In this work, we study the task of automated distractor generation in the domain of math MCQs and explore a wide variety of large language model (LLM)-based approaches, from in-context learning to fine-tuning. We conduct extensive experiments using a real-world math MCQ dataset and find that although LLMs can generate some mathematically valid distractors, they are less adept at anticipating common errors or misconceptions among real students.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer,https://aclanthology.org/2024.findings-naacl.210,,"""This paper explores cost-efficient methods to adapt pretrained Large Language Models (LLMs) to new lower-resource languages, with a specific focus on Estonian. Leveraging the Llama 2 model, we investigate the impact of combining cross-lingual instruction-tuning with additional monolingual pretraining. Our results demonstrate that even a relatively small amount of additional monolingual pretraining followed by cross-lingual instruction-tuning significantly enhances results on Estonian. Furthermore, we showcase cross-lingual knowledge transfer from high-quality English instructions to Estonian, resulting in improvements in commonsense reasoning and multi-turn conversation capabilities. Our best model, named Llammas, represents the first open-source instruction-following LLM for Estonian. Additionally, we publish Alpaca-est, the first general task instruction dataset for Estonia. These contributions mark the initial progress in the direction of developing open-source LLMs for Estonian.""",17,inproceedings,2024,"@inproceedings{kuulmets-etal-2024-teaching,
    title = {""Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer""},
    editor = {""Duh, Kevin  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-naacl.210""},
    author = {""Kuulmets, Hele-Andra  and},
    booktitle = {""Findings of the Association for Computational Linguistics: NAACL 2024""},
    pages = {""3309--3325""},
    abstract = {""This paper explores cost-efficient methods to adapt pretrained Large Language Models (LLMs) to new lower-resource languages, with a specific focus on Estonian. Leveraging the Llama 2 model, we investigate the impact of combining cross-lingual instruction-tuning with additional monolingual pretraining. Our results demonstrate that even a relatively small amount of additional monolingual pretraining followed by cross-lingual instruction-tuning significantly enhances results on Estonian. Furthermore, we showcase cross-lingual knowledge transfer from high-quality English instructions to Estonian, resulting in improvements in commonsense reasoning and multi-turn conversation capabilities. Our best model, named Llammas, represents the first open-source instruction-following LLM for Estonian. Additionally, we publish Alpaca-est, the first general task instruction dataset for Estonia. These contributions mark the initial progress in the direction of developing open-source LLMs for Estonian.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Teaching Probabilistic Logical Reasoning to Transformers,https://aclanthology.org/2024.findings-eacl.112,,"""In this paper, we evaluate the capability of transformer-based language models in making inferences over uncertain text that includes uncertain rules of reasoning. We cover both Pre-trained Language Models (PLMs) and generative Large Language Models (LLMs). Our evaluation results show that both generations of language models struggle with reasoning over uncertain text. We propose a novel end-to-end fine-tuning approach, Probabilistic Constraint Training (PCT), that utilizes probabilistic logical rules as constraints in the fine-tuning phase without relying on these rules in the inference stage. To assess the effectiveness of PCT, we utilize the related corpora and, additionally, create a new and more challenging benchmark that, unlike the previous ones, uses instance-specific rules. Our study demonstrates that PCT improves the transformer-based language model{'}s intrinsic reasoning and makes their probabilistic logical reasoning process more explicit and explainable. Furthermore, PCT equips these models to effectively handle novel situations, including higher reasoning depth, new domains, and complex probabilistic structures.""",18,inproceedings,2024,"@inproceedings{nafar-etal-2024-teaching,
    title = {""Teaching Probabilistic Logical Reasoning to Transformers""},
    editor = {""Graham, Yvette  and},
    month = {mar},
    year = {""2024""},
    address = {""St. Julian{'}s, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-eacl.112""},
    author = {""Nafar, Aliakbar  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EACL 2024""},
    pages = {""1615--1632""},
    abstract = {""In this paper, we evaluate the capability of transformer-based language models in making inferences over uncertain text that includes uncertain rules of reasoning. We cover both Pre-trained Language Models (PLMs) and generative Large Language Models (LLMs). Our evaluation results show that both generations of language models struggle with reasoning over uncertain text. We propose a novel end-to-end fine-tuning approach, Probabilistic Constraint Training (PCT), that utilizes probabilistic logical rules as constraints in the fine-tuning phase without relying on these rules in the inference stage. To assess the effectiveness of PCT, we utilize the related corpora and, additionally, create a new and more challenging benchmark that, unlike the previous ones, uses instance-specific rules. Our study demonstrates that PCT improves the transformer-based language model{'}s intrinsic reasoning and makes their probabilistic logical reasoning process more explicit and explainable. Furthermore, PCT equips these models to effectively handle novel situations, including higher reasoning depth, new domains, and complex probabilistic structures.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{LLM}-{GE}m: Large Language Model-Guided Prediction of People{'}s Empathy Levels towards Newspaper Article,https://aclanthology.org/2024.findings-eacl.147,,"""Empathy {--} encompassing the understanding and supporting others{'} emotions and perspectives {--} strengthens various social interactions, including written communication in healthcare, education and journalism. Detecting empathy using AI models by relying on self-assessed ground truth through crowdsourcing is challenging due to the inherent noise in such annotations. To this end, we propose a novel system, named Large Language Model-Guided Empathy {\_}(LLM-GEm){\_} prediction system. It rectifies annotation errors based on our defined annotation selection threshold and makes the annotations reliable for conventional empathy prediction models, e.g., BERT-based pre-trained language models (PLMs). Previously, demographic information was often integrated numerically into empathy detection models. In contrast, our {\_}LLM-GEm{\_} leverages GPT-3.5 LLM to convert numerical data into semantically meaningful textual sequences, enabling seamless integration into PLMs. We experiment with three {\_}NewsEmpathy{\_} datasets involving people{'}s empathy levels towards newspaper articles and achieve state-of-the-art test performance using a RoBERTa-based PLM. Code and evaluations are publicly available at [https://github.com/hasan-rakibul/LLM-GEm](https://github.com/hasan-rakibul/LLM-GEm).""",17,inproceedings,2024,"@inproceedings{hasan-etal-2024-llm,
    title = {""{LLM}-{GE}m: Large Language Model-Guided Prediction of People{'}s Empathy Levels towards Newspaper Article""},
    editor = {""Graham, Yvette  and},
    month = {mar},
    year = {""2024""},
    address = {""St. Julian{'}s, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.findings-eacl.147""},
    author = {""Hasan, Md Rakibul  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EACL 2024""},
    pages = {""2215--2231""},
    abstract = {""Empathy {--} encompassing the understanding and supporting others{'} emotions and perspectives {--} strengthens various social interactions, including written communication in healthcare, education and journalism. Detecting empathy using AI models by relying on self-assessed ground truth through crowdsourcing is challenging due to the inherent noise in such annotations. To this end, we propose a novel system, named Large Language Model-Guided Empathy {\_}(LLM-GEm){\_} prediction system. It rectifies annotation errors based on our defined annotation selection threshold and makes the annotations reliable for conventional empathy prediction models, e.g., BERT-based pre-trained language models (PLMs). Previously, demographic information was often integrated numerically into empathy detection models. In contrast, our {\_}LLM-GEm{\_} leverages GPT-3.5 LLM to convert numerical data into semantically meaningful textual sequences, enabling seamless integration into PLMs. We experiment with three {\_}NewsEmpathy{\_} datasets involving people{'}s empathy levels towards newspaper articles and achieve state-of-the-art test performance using a RoBERTa-based PLM. Code and evaluations are publicly available at [https://github.com/hasan-rakibul/LLM-GEm](https://github.com/hasan-rakibul/LLM-GEm).""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
"{LLM}s for Low Resource Languages in Multilingual, Multimodal and Dialectal Settings",https://aclanthology.org/2024.eacl-tutorials.5,,"""The recent breakthroughs in Artificial Intelligence (AI) can be attributed to the remarkable performance of Large Language Models (LLMs) across a spectrum of research areas (e.g., machine translation, question-answering, automatic speech recognition, text-to-speech generation) and application domains (e.g., business, law, healthcare, education, and psychology). The success of these LLMs largely de- pends on specific training techniques, most notably instruction tuning, RLHF, and subsequent prompting to achieve the desired output. As the development of such LLMs continues to increase in both closed and open settings, evaluation has become crucial for understanding their generalization capabilities across different tasks, modalities, languages, and dialects. This evaluation process is tightly coupled with prompting, which plays a key role in obtain- ing better outputs. There has been attempts to evaluate such models focusing on diverse tasks, languages, and dialects, which suggests that the capabilities of LLMs are still limited to medium-to-low-resource languages due to the lack of representative datasets. The tutorial offers an overview of this emerging research area. We explore the capabilities of LLMs in terms of their performance, zero- and few-shot settings, fine-tuning, instructions tuning, and close vs. open models with a special emphasis on low-resource settings. In addition to LLMs for standard NLP tasks, we will focus on speech and multimodality.""",7,inproceedings,2024,"@inproceedings{alam-etal-2024-llms,
    title = {""{LLM}s for Low Resource Languages in Multilingual, Multimodal and Dialectal Settings""},
    editor = {""Mesgar, Mohsen  and},
    month = {mar},
    year = {""2024""},
    address = {""St. Julian{'}s, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.eacl-tutorials.5""},
    author = {""Alam, Firoj  and},
    booktitle = {""Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts""},
    pages = {""27--33""},
    abstract = {""The recent breakthroughs in Artificial Intelligence (AI) can be attributed to the remarkable performance of Large Language Models (LLMs) across a spectrum of research areas (e.g., machine translation, question-answering, automatic speech recognition, text-to-speech generation) and application domains (e.g., business, law, healthcare, education, and psychology). The success of these LLMs largely de- pends on specific training techniques, most notably instruction tuning, RLHF, and subsequent prompting to achieve the desired output. As the development of such LLMs continues to increase in both closed and open settings, evaluation has become crucial for understanding their generalization capabilities across different tasks, modalities, languages, and dialects. This evaluation process is tightly coupled with prompting, which plays a key role in obtain- ing better outputs. There has been attempts to evaluate such models focusing on diverse tasks, languages, and dialects, which suggests that the capabilities of LLMs are still limited to medium-to-low-resource languages due to the lack of representative datasets. The tutorial offers an overview of this emerging research area. We explore the capabilities of LLMs in terms of their performance, zero- and few-shot settings, fine-tuning, instructions tuning, and close vs. open models with a special emphasis on low-resource settings. In addition to LLMs for standard NLP tasks, we will focus on speech and multimodality.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
"M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection",https://aclanthology.org/2024.eacl-long.83,,"""Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark M4, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research towards more robust approaches to this pressing societal problem. The dataset is available at https://github.com/mbzuai-nlp/M4""",39,inproceedings,2024,"@inproceedings{wang-etal-2024-m4,
    title = {""M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection""},
    editor = {""Graham, Yvette  and},
    month = {mar},
    year = {""2024""},
    address = {""St. Julian{'}s, Malta""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.eacl-long.83""},
    author = {""Wang, Yuxia  and},
    booktitle = {""Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)""},
    pages = {""1369--1407""},
    abstract = {""Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark M4, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research towards more robust approaches to this pressing societal problem. The dataset is available at https://github.com/mbzuai-nlp/M4""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
How Good are {M}odern {LLM}s in Generating Relevant and High-Quality Questions at Different Bloom{'}s Skill Levels for {I}ndian High School Social Science Curriculum?,https://aclanthology.org/2024.bea-1.1,,"""The creation of pedagogically effective questions is a challenge for teachers and requires significant time and meticulous planning, especially in resource-constrained economies. For example, in India, assessments for social science in high schools are characterized by rote memorization without regard to higher-order skill levels. Automated educational question generation (AEQG) using large language models (LLMs) has the potential to help teachers develop assessments at scale. However, it is important to evaluate the quality and relevance of these questions. In this study, we examine the ability of different LLMs (Falcon 40B, Llama2 70B, Palm 2, GPT 3.5, and GPT 4) to generate relevant and high-quality questions of different cognitive levels, as defined by Bloom{'}s taxonomy. We prompt each model with the same instructions and different contexts to generate 510 questions in the social science curriculum of a state educational board in India. Two human experts used a nine-item rubric to assess linguistic correctness, pedagogical relevance and quality, and adherence to Bloom{'}s skill levels. Our results showed that 91.56{\%} of the LLM-generated questions were relevant and of high quality. This suggests that LLMs can generate relevant and high-quality questions at different cognitive levels, making them useful for creating assessments for scaling education in resource-constrained economies.""",10,inproceedings,2024,"@inproceedings{scaria-etal-2024-good,
    title = {""How Good are {M}odern {LLM}s in Generating Relevant and High-Quality Questions at Different Bloom{'}s Skill Levels for {I}ndian High School Social Science Curriculum?""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.1""},
    author = {""Scaria, Nicy  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""1--10""},
    abstract = {""The creation of pedagogically effective questions is a challenge for teachers and requires significant time and meticulous planning, especially in resource-constrained economies. For example, in India, assessments for social science in high schools are characterized by rote memorization without regard to higher-order skill levels. Automated educational question generation (AEQG) using large language models (LLMs) has the potential to help teachers develop assessments at scale. However, it is important to evaluate the quality and relevance of these questions. In this study, we examine the ability of different LLMs (Falcon 40B, Llama2 70B, Palm 2, GPT 3.5, and GPT 4) to generate relevant and high-quality questions of different cognitive levels, as defined by Bloom{'}s taxonomy. We prompt each model with the same instructions and different contexts to generate 510 questions in the social science curriculum of a state educational board in India. Two human experts used a nine-item rubric to assess linguistic correctness, pedagogical relevance and quality, and adherence to Bloom{'}s skill levels. Our results showed that 91.56{\%} of the LLM-generated questions were relevant and of high quality. This suggests that LLMs can generate relevant and high-quality questions at different cognitive levels, making them useful for creating assessments for scaling education in resource-constrained economies.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts,https://aclanthology.org/2024.bea-1.5,,"""Using large language models (LLMs) for educational applications like dialogue-based teaching is a hot topic. Effective teaching, however, requires teachers to adapt the difficulty of content and explanations to the education level of their students. Even the best LLMs today struggle to do this well. If we want to improve LLMs on this adaptation task, we need to be able to measure adaptation success reliably. However, current Static metrics for text difficulty, like the Flesch-Kincaid Reading Ease score, are known to be crude and brittle. We, therefore, introduce and evaluate a new set of Prompt-based metrics for text difficulty. Based on a user study, we create Prompt-based metrics as inputs for LLMs. They leverage LLM{'}s general language understanding capabilities to capture more abstract and complex features than Static metrics. Regression experiments show that adding our Prompt-based metrics significantly improves text difficulty classification over Static metrics alone. Our results demonstrate the promise of using LLMs to evaluate text adaptation to different education levels.""",14,inproceedings,2024,"@inproceedings{rooein-etal-2024-beyond,
    title = {""Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.5""},
    author = {Rooein, Donya  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""54--67""},
    abstract = {""Using large language models (LLMs) for educational applications like dialogue-based teaching is a hot topic. Effective teaching, however, requires teachers to adapt the difficulty of content and explanations to the education level of their students. Even the best LLMs today struggle to do this well. If we want to improve LLMs on this adaptation task, we need to be able to measure adaptation success reliably. However, current Static metrics for text difficulty, like the Flesch-Kincaid Reading Ease score, are known to be crude and brittle. We, therefore, introduce and evaluate a new set of Prompt-based metrics for text difficulty. Based on a user study, we create Prompt-based metrics as inputs for LLMs. They leverage LLM{'}s general language understanding capabilities to capture more abstract and complex features than Static metrics. Regression experiments show that adding our Prompt-based metrics significantly improves text difficulty classification over Static metrics alone. Our results demonstrate the promise of using LLMs to evaluate text adaptation to different education levels.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Can Language Models Guess Your Identity? Analyzing Demographic Biases in {AI} Essay Scoring,https://aclanthology.org/2024.bea-1.7,,"""Large language models (LLMs) are increasingly used for automated scoring of student essays. However, these models may perpetuate societal biases if not carefully monitored. This study analyzes potential biases in an LLM (XLNet) trained to score persuasive student essays, based on data from the PERSUADE corpus. XLNet achieved strong performance based on quadratic weighted kappa, standardized mean difference, and exact agreement with human scores. Using available metadata, we performed analyses of scoring differences across gender, race/ethnicity, English language learning status, socioeconomic status, and disability status. Automated scores exhibited small magnifications of marginal differences in human scoring, favoring female students over males and White students over Black students. To further probe potential biases, we found that separate XLNet classifiers and XLNet hidden states weakly predicted demographic membership. Overall, results reinforce the need for continued fairness analyses as use of LLMs expands in education.""",9,inproceedings,2024,"@inproceedings{kwako-ormerod-2024-language,
    title = {""Can Language Models Guess Your Identity? Analyzing Demographic Biases in {AI} Essay Scoring""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.7""},
    author = {""Kwako, Alexander  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""78--86""},
    abstract = {""Large language models (LLMs) are increasingly used for automated scoring of student essays. However, these models may perpetuate societal biases if not carefully monitored. This study analyzes potential biases in an LLM (XLNet) trained to score persuasive student essays, based on data from the PERSUADE corpus. XLNet achieved strong performance based on quadratic weighted kappa, standardized mean difference, and exact agreement with human scores. Using available metadata, we performed analyses of scoring differences across gender, race/ethnicity, English language learning status, socioeconomic status, and disability status. Automated scores exhibited small magnifications of marginal differences in human scoring, favoring female students over males and White students over Black students. To further probe potential biases, we found that separate XLNet classifiers and XLNet hidden states weakly predicted demographic membership. Overall, results reinforce the need for continued fairness analyses as use of LLMs expands in education.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Can {GPT}-4 do {L}2 analytic assessment?,https://aclanthology.org/2024.bea-1.14,,"""Automated essay scoring (AES) to evaluate second language (L2) proficiency has been a firmly established technology used in educational contexts for decades. Although holistic scoring has seen advancements in AES that match or even exceed human performance, analytic scoring still encounters issues as it inherits flaws and shortcomings from the human scoring process. The recent introduction of large language models presents new opportunities for automating the evaluation of specific aspects of L2 writing proficiency. In this paper, we perform a series of experiments using GPT-4 in a zero-shot fashion on a publicly available dataset annotated with holistic scores based on the Common European Framework of Reference and aim to extract detailed information about their underlying analytic components. We observe significant correlations between the automatically predicted analytic scores and multiple features associated with the individual proficiency components.""",16,inproceedings,2024,"@inproceedings{banno-etal-2024-gpt,
    title = {""Can {GPT}-4 do {L}2 analytic assessment?""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.14""},
    author = {""Banno, Stefano  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""149--164""},
    abstract = {""Automated essay scoring (AES) to evaluate second language (L2) proficiency has been a firmly established technology used in educational contexts for decades. Although holistic scoring has seen advancements in AES that match or even exceed human performance, analytic scoring still encounters issues as it inherits flaws and shortcomings from the human scoring process. The recent introduction of large language models presents new opportunities for automating the evaluation of specific aspects of L2 writing proficiency. In this paper, we perform a series of experiments using GPT-4 in a zero-shot fashion on a publicly available dataset annotated with holistic scores based on the Common European Framework of Reference and aim to extract detailed information about their underlying analytic components. We observe significant correlations between the automatically predicted analytic scores and multiple features associated with the individual proficiency components.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Using Program Repair as a Proxy for Language Models{'} Feedback Ability in Programming Education,https://aclanthology.org/2024.bea-1.15,,"""One of the key challenges in programming education is being able to provide high-quality feedback to learners. Such feedback often includes explanations of the issues in students{'} programs coupled with suggestions on how to fix these issues. Large language models (LLMs) have recently emerged as valuable tools that can help in this effort. In this article, we explore the relationship between the program repair ability of LLMs and their proficiency in providing natural language explanations of coding mistakes. We outline a benchmarking study that evaluates leading LLMs (including open-source ones) on program repair and explanation tasks. Our experiments study the capabilities of LLMs both on a course level and on a programming concept level, allowing us to assess whether the programming concepts practised in exercises with faulty student programs relate to the performance of the models. Our results highlight that LLMs proficient in repairing student programs tend to provide more complete and accurate natural language explanations of code issues. Overall, these results enhance our understanding of the role and capabilities of LLMs in programming education. Using program repair as a proxy for explanation evaluation opens the door for cost-effective assessment methods.""",17,inproceedings,2024,"@inproceedings{koutcheme-etal-2024-using,
    title = {""Using Program Repair as a Proxy for Language Models{'} Feedback Ability in Programming Education""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.15""},
    author = {""Koutcheme, Charles  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""165--181""},
    abstract = {""One of the key challenges in programming education is being able to provide high-quality feedback to learners. Such feedback often includes explanations of the issues in students{'} programs coupled with suggestions on how to fix these issues. Large language models (LLMs) have recently emerged as valuable tools that can help in this effort. In this article, we explore the relationship between the program repair ability of LLMs and their proficiency in providing natural language explanations of coding mistakes. We outline a benchmarking study that evaluates leading LLMs (including open-source ones) on program repair and explanation tasks. Our experiments study the capabilities of LLMs both on a course level and on a programming concept level, allowing us to assess whether the programming concepts practised in exercises with faulty student programs relate to the performance of the models. Our results highlight that LLMs proficient in repairing student programs tend to provide more complete and accurate natural language explanations of code issues. Overall, these results enhance our understanding of the role and capabilities of LLMs in programming education. Using program repair as a proxy for explanation evaluation opens the door for cost-effective assessment methods.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Fairness in Automated Essay Scoring: A Comparative Analysis of Algorithms on {G}erman Learner Essays from Secondary Education,https://aclanthology.org/2024.bea-1.18,,"""Pursuing educational equity, particularly in writing instruction, requires that all students receive fair (i.e., accurate and unbiased) assessment and feedback on their texts. Automated Essay Scoring (AES) algorithms have so far focused on optimizing the mean accuracy of their scores and paid less attention to fair scores for all subgroups, although research shows that students receive unfair scores on their essays in relation to demographic variables, which in turn are related to their writing competence. We add to the literature arguing that AES should also optimize for fairness by presenting insights on the fairness of scoring algorithms on a corpus of learner texts in the German language and introduce the novelty of examining fairness on psychological and demographic differences in addition to demographic differences. We compare shallow learning, deep learning, and large language models with full and skewed subsets of training data to investigate what is needed for fair scoring. The results show that training on a skewed subset of higher and lower cognitive ability students shows no bias but very low accuracy for students outside the training set. Our results highlight the need for specific training data on all relevant user groups, not only for demographic background variables but also for cognitive abilities as psychological student characteristics.""",12,inproceedings,2024,"@inproceedings{schaller-etal-2024-fairness,
    title = {""Fairness in Automated Essay Scoring: A Comparative Analysis of Algorithms on {G}erman Learner Essays from Secondary Education""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.18""},
    author = {""Schaller, Nils-Jonathan  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""210--221""},
    abstract = {""Pursuing educational equity, particularly in writing instruction, requires that all students receive fair (i.e., accurate and unbiased) assessment and feedback on their texts. Automated Essay Scoring (AES) algorithms have so far focused on optimizing the mean accuracy of their scores and paid less attention to fair scores for all subgroups, although research shows that students receive unfair scores on their essays in relation to demographic variables, which in turn are related to their writing competence. We add to the literature arguing that AES should also optimize for fairness by presenting insights on the fairness of scoring algorithms on a corpus of learner texts in the German language and introduce the novelty of examining fairness on psychological and demographic differences in addition to demographic differences. We compare shallow learning, deep learning, and large language models with full and skewed subsets of training data to investigate what is needed for fair scoring. The results show that training on a skewed subset of higher and lower cognitive ability students shows no bias but very low accuracy for students outside the training set. Our results highlight the need for specific training data on all relevant user groups, not only for demographic background variables but also for cognitive abilities as psychological student characteristics.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Improving Automated Distractor Generation for Math Multiple-choice Questions with Overgenerate-and-rank,https://aclanthology.org/2024.bea-1.19,,"""Multiple-choice questions (MCQs) are commonly used across all levels of math education since they can be deployed and graded at a large scale. A critical component of MCQs is the distractors, i.e., incorrect answers crafted to reflect student errors or misconceptions. Automatically generating them in math MCQs, e.g., with large language models, has been challenging. In this work, we propose a novel method to enhance the quality of generated distractors through overgenerate-and-rank, training a ranking model to predict how likely distractors are to be selected by real students. Experimental results on a real-world dataset and human evaluation with math teachers show that our ranking model increases alignment with human-authored distractors, although human-authored ones are still preferred over generated ones.""",10,inproceedings,2024,"@inproceedings{scarlatos-etal-2024-improving,
    title = {""Improving Automated Distractor Generation for Math Multiple-choice Questions with Overgenerate-and-rank""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.19""},
    author = {""Scarlatos, Alexander  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""222--231""},
    abstract = {""Multiple-choice questions (MCQs) are commonly used across all levels of math education since they can be deployed and graded at a large scale. A critical component of MCQs is the distractors, i.e., incorrect answers crafted to reflect student errors or misconceptions. Automatically generating them in math MCQs, e.g., with large language models, has been challenging. In this work, we propose a novel method to enhance the quality of generated distractors through overgenerate-and-rank, training a ranking model to predict how likely distractors are to be selected by real students. Experimental results on a real-world dataset and human evaluation with math teachers show that our ranking model increases alignment with human-authored distractors, although human-authored ones are still preferred over generated ones.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Towards Fine-Grained Pedagogical Control over {E}nglish Grammar Complexity in Educational Text Generation,https://aclanthology.org/2024.bea-1.24,,"""Teaching foreign languages and fostering language awareness in subject matter teaching requires a profound knowledge of grammar structures. Yet, while Large Language Models can act as tutors, it is unclear how effectively they can control grammar in generated text and adapt to learner needs. In this study, we investigate the ability of these models to exemplify pedagogically relevant grammar patterns, detect instances of grammar in a given text, and constrain text generation to grammar characteristic of a proficiency level. Concretely, we (1) evaluate the ability of GPT3.5 and GPT4 to generate example sentences for the standard English Grammar Profile CEFR taxonomy using few-shot in-context learning, (2) train BERT-based detectors with these generated examples of grammatical patterns, and (3) control the grammatical complexity of text generated by the open Mistral model by ranking sentence candidates with these detectors. We show that the grammar pattern instantiation quality is accurate but too homogeneous, and our classifiers successfully detect these patterns. A GPT-generated dataset of almost 1 million positive and negative examples for the English Grammar Profile is released with this work. With our method, Mistral{'}s output significantly increases the number of characteristic grammar constructions on the desired level, outperforming GPT4. This showcases how language domain knowledge can enhance Large Language Models for specific education needs, facilitating their effective use for intelligent tutor development and AI-generated materials. Code, models, and data are available at https://github.com/dominikglandorf/LLM-grammar.""",10,inproceedings,2024,"@inproceedings{glandorf-meurers-2024-towards,
    title = {""Towards Fine-Grained Pedagogical Control over {E}nglish Grammar Complexity in Educational Text Generation""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.24""},
    author = {""Glandorf, Dominik  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""299--308""},
    abstract = {""Teaching foreign languages and fostering language awareness in subject matter teaching requires a profound knowledge of grammar structures. Yet, while Large Language Models can act as tutors, it is unclear how effectively they can control grammar in generated text and adapt to learner needs. In this study, we investigate the ability of these models to exemplify pedagogically relevant grammar patterns, detect instances of grammar in a given text, and constrain text generation to grammar characteristic of a proficiency level. Concretely, we (1) evaluate the ability of GPT3.5 and GPT4 to generate example sentences for the standard English Grammar Profile CEFR taxonomy using few-shot in-context learning, (2) train BERT-based detectors with these generated examples of grammatical patterns, and (3) control the grammatical complexity of text generated by the open Mistral model by ranking sentence candidates with these detectors. We show that the grammar pattern instantiation quality is accurate but too homogeneous, and our classifiers successfully detect these patterns. A GPT-generated dataset of almost 1 million positive and negative examples for the English Grammar Profile is released with this work. With our method, Mistral{'}s output significantly increases the number of characteristic grammar constructions on the desired level, outperforming GPT4. This showcases how language domain knowledge can enhance Large Language Models for specific education needs, facilitating their effective use for intelligent tutor development and AI-generated materials. Code, models, and data are available at https://github.com/dominikglandorf/LLM-grammar.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Large Language Model-based Pipeline for Item Difficulty and Response Time Estimation for Educational Assessments,https://aclanthology.org/2024.bea-1.49,,"""This work presents a novel framework for the automated prediction of item difficulty and response time within educational assessments. Utilizing data from the BEA 2024 Shared Task, we integrate Named Entity Recognition, Semantic Role Labeling, and linguistic features to prompt a Large Language Model (LLM). Our best approach achieves an RMSE of 0.308 for item difficulty and 27.474 for response time prediction, improving on the provided baseline. The framework{'}s adaptability is demonstrated on audio recordings of 3rd-8th graders from the Atlanta, Georgia area responding to the Test of Narrative Language. These results highlight the framework{'}s potential to enhance test development efficiency.""",6,inproceedings,2024,"@inproceedings{veeramani-etal-2024-large,
    title = {""Large Language Model-based Pipeline for Item Difficulty and Response Time Estimation for Educational Assessments""},
    editor = {Kochmar, Ekaterina  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.bea-1.49""},
    author = {""Veeramani, Hariram  and},
    booktitle = {""Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)""},
    pages = {""561--566""},
    abstract = {""This work presents a novel framework for the automated prediction of item difficulty and response time within educational assessments. Utilizing data from the BEA 2024 Shared Task, we integrate Named Entity Recognition, Semantic Role Labeling, and linguistic features to prompt a Large Language Model (LLM). Our best approach achieves an RMSE of 0.308 for item difficulty and 27.474 for response time prediction, improving on the provided baseline. The framework{'}s adaptability is demonstrated on audio recordings of 3rd-8th graders from the Atlanta, Georgia area responding to the Test of Narrative Language. These results highlight the framework{'}s potential to enhance test development efficiency.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
The unreasonable effectiveness of large language models for low-resource clause-level morphology: In-context generalization or prior exposure?,https://aclanthology.org/2024.americasnlp-1.20,,"""This paper describes the submission of Team {``}Giving it a Shot{''} to the AmericasNLP 2024 Shared Task on Creation of Educational Materials for Indigenous Languages. We use a simple few-shot prompting approach with several state of the art large language models, achieving competitive performance on the shared task, with our best system placing third overall. We perform a preliminary analysis to determine to what degree the performance of our model is due to prior exposure to the task languages, finding that generally our performance is better explained as being derived from in-context learning capabilities.""",5,inproceedings,2024,"@inproceedings{haley-2024-unreasonable,
    title = {""The unreasonable effectiveness of large language models for low-resource clause-level morphology: In-context generalization or prior exposure?""},
    editor = {""Mager, Manuel  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.americasnlp-1.20""},
    author = {""Haley, Coleman""},
    booktitle = {""Proceedings of the 4th Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP 2024)""},
    pages = {""174--178""},
    abstract = {""This paper describes the submission of Team {``}Giving it a Shot{''} to the AmericasNLP 2024 Shared Task on Creation of Educational Materials for Indigenous Languages. We use a simple few-shot prompting approach with several state of the art large language models, achieving competitive performance on the shared task, with our best system placing third overall. We perform a preliminary analysis to determine to what degree the performance of our model is due to prior exposure to the task languages, finding that generally our performance is better explained as being derived from in-context learning capabilities.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
A Comparison of Fine-Tuning and In-Context Learning for Clause-Level Morphosyntactic Alternation,https://aclanthology.org/2024.americasnlp-1.21,,"""This paper presents our submission to the AmericasNLP 2024 Shared Task on the Creation of Educational Materials for Indigenous Languages. We frame this task as one of morphological inflection generation, treating each sentence as a single word. We investigate and compare two distinct approaches: fine-tuning neural encoder-decoder models such as NLLB- 200, and in-context learning with proprietary large language models (LLMs). Our findings demonstrate that for this task, no one approach is perfect. Anthropic{'}s Claude 3 Opus, when supplied with grammatical description entries, achieves the highest performance on Bribri among the evaluated models. This outcome corroborates and extends previous research exploring the efficacy of in-context learning in low- resource settings. For Maya, fine-tuning NLLB- 200-3.3B using StemCorrupt augmented data yielded the best performance.""",9,inproceedings,2024,"@inproceedings{su-etal-2024-comparison,
    title = {""A Comparison of Fine-Tuning and In-Context Learning for Clause-Level Morphosyntactic Alternation""},
    editor = {""Mager, Manuel  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.americasnlp-1.21""},
    author = {""Su, Jim  and},
    booktitle = {""Proceedings of the 4th Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP 2024)""},
    pages = {""179--187""},
    abstract = {""This paper presents our submission to the AmericasNLP 2024 Shared Task on the Creation of Educational Materials for Indigenous Languages. We frame this task as one of morphological inflection generation, treating each sentence as a single word. We investigate and compare two distinct approaches: fine-tuning neural encoder-decoder models such as NLLB- 200, and in-context learning with proprietary large language models (LLMs). Our findings demonstrate that for this task, no one approach is perfect. Anthropic{'}s Claude 3 Opus, when supplied with grammatical description entries, achieves the highest performance on Bribri among the evaluated models. This outcome corroborates and extends previous research exploring the efficacy of in-context learning in low- resource settings. For Maya, fine-tuning NLLB- 200-3.3B using StemCorrupt augmented data yielded the best performance.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Applying Linguistic Expertise to {LLM}s for Educational Material Development in Indigenous Languages,https://aclanthology.org/2024.americasnlp-1.24,,"""This paper presents our approach to the AmericasNLP 2024 Shared Task 2 as the JAJ (/dʒ{\ae}z/) team. The task aimed at creating educational materials for indigenous languages, and we focused on Maya and Bribri. Given the unique linguistic features and challenges of these languages, and the limited size of the training datasets, we developed a hybrid methodology combining rule-based NLP methods with prompt-based techniques. This approach leverages the meta-linguistic capabilities of large language models, enabling us to blend broad, language-agnostic processing with customized solutions. Our approach lays a foundational framework that can be expanded to other indigenous languages languages in future work.""",8,inproceedings,2024,"@inproceedings{vasselli-etal-2024-applying,
    title = {""Applying Linguistic Expertise to {LLM}s for Educational Material Development in Indigenous Languages""},
    editor = {""Mager, Manuel  and},
    month = {jun},
    year = {""2024""},
    address = {""Mexico City, Mexico""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2024.americasnlp-1.24""},
    author = {""Vasselli, Justin  and},
    booktitle = {""Proceedings of the 4th Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP 2024)""},
    pages = {""201--208""},
    abstract = {""This paper presents our approach to the AmericasNLP 2024 Shared Task 2 as the JAJ (/dʒ{\ae}z/) team. The task aimed at creating educational materials for indigenous languages, and we focused on Maya and Bribri. Given the unique linguistic features and challenges of these languages, and the limited size of the training datasets, we developed a hybrid methodology combining rule-based NLP methods with prompt-based techniques. This approach leverages the meta-linguistic capabilities of large language models, enabling us to blend broad, language-agnostic processing with customized solutions. Our approach lays a foundational framework that can be expanded to other indigenous languages languages in future work.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Detecting {C}hat{GPT}: A Survey of the State of Detecting {C}hat{GPT}-Generated Text,https://aclanthology.org/2023.ranlp-stud.1,,"""While recent advancements in the capabilities and widespread accessibility of generative language models, such as ChatGPT (OpenAI, 2022), have brought about various benefits by generating fluent human-like text, the task of distinguishing between human- and large language model (LLM) generated text has emerged as a crucial problem. These models can potentially deceive by generating artificial text that appears to be human-generated. This issue is particularly significant in domains such as law, education, and science, where ensuring the integrity of text is of the utmost importance. This survey provides an overview of the current approaches employed to differentiate between texts generated by humans and ChatGPT. We present an account of the different datasets constructed for detecting ChatGPT-generated text, the various methods utilized, what qualitative analyses into the characteristics of human versus ChatGPT-generated text have been performed, and finally, summarize our findings into general insights.""",12,inproceedings,2023,"@inproceedings{dhaini-etal-2023-detecting,
    title = {""Detecting {C}hat{GPT}: A Survey of the State of Detecting {C}hat{GPT}-Generated Text""},
    editor = {""Hardalov, Momchil  and},
    month = {sep},
    year = {""2023""},
    address = {""Varna, Bulgaria""},
    publisher = {""INCOMA Ltd., Shoumen, Bulgaria""},
    url = {""https://aclanthology.org/2023.ranlp-stud.1""},
    author = {""Dhaini, Mahdi  and},
    booktitle = {""Proceedings of the 8th Student Research Workshop associated with the International Conference Recent Advances in Natural Language Processing""},
    pages = {""1--12""},
    abstract = {""While recent advancements in the capabilities and widespread accessibility of generative language models, such as ChatGPT (OpenAI, 2022), have brought about various benefits by generating fluent human-like text, the task of distinguishing between human- and large language model (LLM) generated text has emerged as a crucial problem. These models can potentially deceive by generating artificial text that appears to be human-generated. This issue is particularly significant in domains such as law, education, and science, where ensuring the integrity of text is of the utmost importance. This survey provides an overview of the current approaches employed to differentiate between texts generated by humans and ChatGPT. We present an account of the different datasets constructed for detecting ChatGPT-generated text, the various methods utilized, what qualitative analyses into the characteristics of human versus ChatGPT-generated text have been performed, and finally, summarize our findings into general insights.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Automated Generation of Multiple-Choice Cloze Questions for Assessing {E}nglish Vocabulary Using {GPT}-turbo 3.5,https://aclanthology.org/2023.nlp4dh-1.7,,"""A common way of assessing language learners{'} mastery of vocabulary is via multiple-choice cloze (i.e., fill-in-the-blank) questions. But the creation of test items can be laborious for individual teachers or in large-scale language programs. In this paper, we evaluate a new method for automatically generating these types of questions using large language models (LLM). The VocaTT (vocabulary teaching and training) engine is written in Python and comprises three basic steps: pre-processing target word lists, generating sentences and candidate word options using GPT, and finally selecting suitable word options. To test the efficiency of this system, 60 questions were generated targeting academic words. The generated items were reviewed by expert reviewers who judged the well-formedness of the sentences and word options, adding comments to items judged not well-formed. Results showed a 75{\%} rate of well-formedness for sentences and 66.85{\%} rate for suitable word options. This is a marked improvement over the generator used earlier in our research which did not take advantage of GPT{'}s capabilities. Post-hoc qualitative analysis reveals several points for improvement in future work including cross-referencing part-of-speech tagging, better sentence validation, and improving GPT prompts.""",10,inproceedings,2023,"@inproceedings{wang-etal-2023-automated-generation,
    title = {""Automated Generation of Multiple-Choice Cloze Questions for Assessing {E}nglish Vocabulary Using {GPT}-turbo 3.5""},
    editor = {H{\""a}m{\""a}l{\""a}inen, Mika  and},
    month = {dec},
    year = {""2023""},
    address = {""Tokyo, Japan""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.nlp4dh-1.7""},
    author = {""Wang, Qiao  and},
    booktitle = {""Proceedings of the Joint 3rd International Conference on Natural Language Processing for Digital Humanities and 8th International Workshop on Computational Linguistics for Uralic Languages""},
    pages = {""52--61""},
    abstract = {""A common way of assessing language learners{'} mastery of vocabulary is via multiple-choice cloze (i.e., fill-in-the-blank) questions. But the creation of test items can be laborious for individual teachers or in large-scale language programs. In this paper, we evaluate a new method for automatically generating these types of questions using large language models (LLM). The VocaTT (vocabulary teaching and training) engine is written in Python and comprises three basic steps: pre-processing target word lists, generating sentences and candidate word options using GPT, and finally selecting suitable word options. To test the efficiency of this system, 60 questions were generated targeting academic words. The generated items were reviewed by expert reviewers who judged the well-formedness of the sentences and word options, adding comments to items judged not well-formed. Results showed a 75{\%} rate of well-formedness for sentences and 66.85{\%} rate for suitable word options. This is a marked improvement over the generator used earlier in our research which did not take advantage of GPT{'}s capabilities. Post-hoc qualitative analysis reveals several points for improvement in future work including cross-referencing part-of-speech tagging, better sentence validation, and improving GPT prompts.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Toxicity in chatgpt: Analyzing persona-assigned language models,https://aclanthology.org/2023.findings-emnlp.88,10.18653/v1/2023.findings-emnlp.88,"""Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Legislation has recognized its significance and recently drafted a {``}Blueprint For An AI Bill Of Rights{''} which calls for domain experts to identify risks and potential impact of AI systems. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to $6\times$, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others ($3\times$ more) irrespective of the assigned persona, reflecting discriminatory biases in the model. Our findings show that multiple provisions in the legislative blueprint are being violated, and we hope that the broader AI community rethinks the efficacy of current safety guardrails and develops better techniques that lead to robust, safe, and trustworthy AI.""",35,inproceedings,2023,"@inproceedings{deshpande-etal-2023-toxicity,
    title = {""Toxicity in chatgpt: Analyzing persona-assigned language models""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.88""},
    author = {""Deshpande, Ameet  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""1236--1270""},
    abstract = {""Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Legislation has recognized its significance and recently drafted a {``}Blueprint For An AI Bill Of Rights{''} which calls for domain experts to identify risks and potential impact of AI systems. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to $6\times$, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others ($3\times$ more) irrespective of the assigned persona, reflecting discriminatory biases in the model. Our findings show that multiple provisions in the legislative blueprint are being violated, and we hope that the broader AI community rethinks the efficacy of current safety guardrails and develops better techniques that lead to robust, safe, and trustworthy AI.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.88""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach,https://aclanthology.org/2023.findings-emnlp.111,10.18653/v1/2023.findings-emnlp.111,"""Large Language Models (LLMs) have not only exhibited exceptional performance across various tasks, but also demonstrated sparks of intelligence. Recent studies have focused on assessing their capabilities on human exams and revealed their impressive competence in different domains. However, cognitive research on the overall knowledge structure of LLMs is still lacking. In this paper, based on educational diagnostic assessment method, we conduct an evaluation using MoocRadar, a meticulously annotated human test dataset based on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain insights of their cognitive capabilities. This research emphasizes the significance of investigating LLMs{'} knowledge and understanding the disparate cognitive patterns of LLMs. By shedding light on models{'} knowledge, researchers can advance development and utilization of LLMs in a more informed and effective manner.""",8,inproceedings,2023,"@inproceedings{zhang-etal-2023-exploring-cognitive,
    title = {""Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.111""},
    author = {""Zhang, Zheyuan  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""1643--1650""},
    abstract = {""Large Language Models (LLMs) have not only exhibited exceptional performance across various tasks, but also demonstrated sparks of intelligence. Recent studies have focused on assessing their capabilities on human exams and revealed their impressive competence in different domains. However, cognitive research on the overall knowledge structure of LLMs is still lacking. In this paper, based on educational diagnostic assessment method, we conduct an evaluation using MoocRadar, a meticulously annotated human test dataset based on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain insights of their cognitive capabilities. This research emphasizes the significance of investigating LLMs{'} knowledge and understanding the disparate cognitive patterns of LLMs. By shedding light on models{'} knowledge, researchers can advance development and utilization of LLMs in a more informed and effective manner.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.111""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning,https://aclanthology.org/2023.findings-emnlp.201,10.18653/v1/2023.findings-emnlp.201,"""Due to the remarkable language understanding and generation abilities of large language models (LLMs), their use in educational applications has been explored. However, little work has been done on investigating the pedagogical ability of LLMs in helping students to learn mathematics. In this position paper, we discuss the challenges associated with employing LLMs to enhance students{'} mathematical problem-solving skills by providing adaptive feedback. Apart from generating the wrong reasoning processes, LLMs can misinterpret the meaning of the question, and also exhibit difficulty in understanding the given questions{'} rationales when attempting to correct students{'} answers. Three research questions are formulated.""",15,inproceedings,2023,"@inproceedings{yen-hsu-2023-three,
    title = {""Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.201""},
    author = {""Yen, An-Zi  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""3055--3069""},
    abstract = {""Due to the remarkable language understanding and generation abilities of large language models (LLMs), their use in educational applications has been explored. However, little work has been done on investigating the pedagogical ability of LLMs in helping students to learn mathematics. In this position paper, we discuss the challenges associated with employing LLMs to enhance students{'} mathematical problem-solving skills by providing adaptive feedback. Apart from generating the wrong reasoning processes, LLMs can misinterpret the meaning of the question, and also exhibit difficulty in understanding the given questions{'} rationales when attempting to correct students{'} answers. Three research questions are formulated.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.201""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{M}ath{D}ial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems,https://aclanthology.org/2023.findings-emnlp.372,10.18653/v1/2023.findings-emnlp.372,"""While automatic dialogue tutors hold great potential in making education personalized and more accessible, research on such systems has been hampered by a lack of sufficiently large and high-quality datasets. Collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this, we propose a framework to generate such dialogues by pairing human teachers with a Large Language Model (LLM) prompted to represent common student errors. We describe how we use this framework to collect MathDial, a dataset of 3k one-to-one teacher-student tutoring dialogues grounded in multi-step math reasoning problems. While models like GPT-3 are good problem solvers, they fail at tutoring because they generate factually incorrect feedback or are prone to revealing solutions to students too early. To overcome this, we let teachers provide learning opportunities to students by guiding them using various scaffolding questions according to a taxonomy of teacher moves. We demonstrate MathDial and its extensive annotations can be used to finetune models to be more effective tutors (and not just solvers). We confirm this by automatic and human evaluation, notably in an interactive setting that measures the trade-off between student solving success and telling solutions. The dataset is released publicly.""",20,inproceedings,2023,"@inproceedings{macina-etal-2023-mathdial,
    title = {""{M}ath{D}ial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.372""},
    author = {""Macina, Jakub  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""5602--5621""},
    abstract = {""While automatic dialogue tutors hold great potential in making education personalized and more accessible, research on such systems has been hampered by a lack of sufficiently large and high-quality datasets. Collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this, we propose a framework to generate such dialogues by pairing human teachers with a Large Language Model (LLM) prompted to represent common student errors. We describe how we use this framework to collect MathDial, a dataset of 3k one-to-one teacher-student tutoring dialogues grounded in multi-step math reasoning problems. While models like GPT-3 are good problem solvers, they fail at tutoring because they generate factually incorrect feedback or are prone to revealing solutions to students too early. To overcome this, we let teachers provide learning opportunities to students by guiding them using various scaffolding questions according to a taxonomy of teacher moves. We demonstrate MathDial and its extensive annotations can be used to finetune models to be more effective tutors (and not just solvers). We confirm this by automatic and human evaluation, notably in an interactive setting that measures the trade-off between student solving success and telling solutions. The dataset is released publicly.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.372""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Distilling {C}hat{GPT} for Explainable Automated Student Answer Assessment,https://aclanthology.org/2023.findings-emnlp.399,10.18653/v1/2023.findings-emnlp.399,"""Providing explainable and faithful feedback is crucial for automated student answer assessment. In this paper, we introduce a novel framework that explores using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation. We identify the appropriate instructions by prompting ChatGPT with different templates to collect the rationales, where inconsistent rationales are refined to align with marking standards. The refined ChatGPT outputs enable us to fine-tune a smaller language model that simultaneously assesses student answers and provides rationales. Extensive experiments on the benchmark dataset show that the proposed method improves the overall QWK score by 11{\%} compared to ChatGPT. Furthermore, our thorough analysis and human evaluation demonstrate that the rationales generated by our proposed method are comparable to those of ChatGPT. Our approach provides a viable solution to achieve explainable automated assessment in education""",20,inproceedings,2023,"@inproceedings{li-etal-2023-distilling,
    title = {""Distilling {C}hat{GPT} for Explainable Automated Student Answer Assessment""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.399""},
    author = {""Li, Jiazheng  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""6007--6026""},
    abstract = {""Providing explainable and faithful feedback is crucial for automated student answer assessment. In this paper, we introduce a novel framework that explores using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation. We identify the appropriate instructions by prompting ChatGPT with different templates to collect the rationales, where inconsistent rationales are refined to align with marking standards. The refined ChatGPT outputs enable us to fine-tune a smaller language model that simultaneously assesses student answers and provides rationales. Extensive experiments on the benchmark dataset show that the proposed method improves the overall QWK score by 11{\%} compared to ChatGPT. Furthermore, our thorough analysis and human evaluation demonstrate that the rationales generated by our proposed method are comparable to those of ChatGPT. Our approach provides a viable solution to achieve explainable automated assessment in education""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.399""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{C}onic10{K}: A Challenging Math Problem Understanding and Reasoning Dataset,https://aclanthology.org/2023.findings-emnlp.427,10.18653/v1/2023.findings-emnlp.427,"""Mathematical understanding and reasoning are crucial tasks for assessing the capabilities of artificial intelligence (AI). However, existing benchmarks either require just a few steps of reasoning, or only contain a small amount of data in one specific topic, making it hard to analyse AI{'}s behaviour with reference to different problems within a specific topic in detail. In this work, we propose Conic10K, a challenging math problem dataset on conic sections in Chinese senior high school education. Our dataset contains various problems with different reasoning depths, while only the knowledge from conic sections is required. Since the dataset only involves a narrow range of knowledge, it is easy to separately analyse the knowledge a model possesses and the reasoning ability it has. For each problem, we provide a high-quality formal representation, the reasoning steps, and the final solution. Experiments show that existing large language models, including GPT-4, exhibit weak performance on complex reasoning. We hope that our findings could inspire more advanced techniques for precise natural language understanding and reasoning. Our dataset and codes are available at https://github.com/whyNLP/Conic10K.""",15,inproceedings,2023,"@inproceedings{wu-etal-2023-conic10k,
    title = {""{C}onic10{K}: A Challenging Math Problem Understanding and Reasoning Dataset""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.427""},
    author = {""Wu, Haoyi  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""6444--6458""},
    abstract = {""Mathematical understanding and reasoning are crucial tasks for assessing the capabilities of artificial intelligence (AI). However, existing benchmarks either require just a few steps of reasoning, or only contain a small amount of data in one specific topic, making it hard to analyse AI{'}s behaviour with reference to different problems within a specific topic in detail. In this work, we propose Conic10K, a challenging math problem dataset on conic sections in Chinese senior high school education. Our dataset contains various problems with different reasoning depths, while only the knowledge from conic sections is required. Since the dataset only involves a narrow range of knowledge, it is easy to separately analyse the knowledge a model possesses and the reasoning ability it has. For each problem, we provide a high-quality formal representation, the reasoning steps, and the final solution. Experiments show that existing large language models, including GPT-4, exhibit weak performance on complex reasoning. We hope that our findings could inspire more advanced techniques for precise natural language understanding and reasoning. Our dataset and codes are available at https://github.com/whyNLP/Conic10K.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.427""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses,https://aclanthology.org/2023.findings-emnlp.496,10.18653/v1/2023.findings-emnlp.496,"""In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses. We designed targeted prompts for GPT4, guiding it to generate code-tracing questions based on code snippets and descriptions. We established a set of human evaluation metrics to assess the quality of questions produced by the model compared to those created by human experts. Our analysis provides insights into the capabilities and potential of LLMs in generating diverse code-tracing questions. Additionally, we present a unique dataset of human and LLM-generated tracing questions, serving as a valuable resource for both the education and NLP research communities. This work contributes to the ongoing dialogue on the potential uses of LLMs in educational settings.""",16,inproceedings,2023,"@inproceedings{fan-etal-2023-exploring,
    title = {""Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.496""},
    author = {""Fan, Aysa  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""7406--7421""},
    abstract = {""In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses. We designed targeted prompts for GPT4, guiding it to generate code-tracing questions based on code snippets and descriptions. We established a set of human evaluation metrics to assess the quality of questions produced by the model compared to those created by human experts. Our analysis provides insights into the capabilities and potential of LLMs in generating diverse code-tracing questions. Additionally, we present a unique dataset of human and LLM-generated tracing questions, serving as a valuable resource for both the education and NLP research communities. This work contributes to the ongoing dialogue on the potential uses of LLMs in educational settings.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.496""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Salespeople vs {S}ales{B}ot: Exploring the Role of Educational Value in Conversational Recommender Systems,https://aclanthology.org/2023.findings-emnlp.657,10.18653/v1/2023.findings-emnlp.657,"""Making big purchases requires consumers to research or consult a salesperson to gain domain expertise. However, existing conversational recommender systems (CRS) often overlook users{'} lack of background knowledge, focusing solely on gathering preferences. In this work, we define a new problem space for conversational agents that aim to provide both product recommendations and educational value through mixed-type mixed-initiative dialog. We introduce SalesOps, a framework that facilitates the simulation and evaluation of such systems by leveraging recent advancements in large language models (LLMs). We build SalesBot and ShopperBot, a pair of LLM-powered agents that can simulate either side of the framework. A comprehensive human study compares SalesBot against professional salespeople, revealing that although SalesBot approaches professional performance in terms of fluency and informativeness, it lags behind in recommendation quality. We emphasize the distinct limitations both face in providing truthful information, highlighting the challenges of ensuring faithfulness in the CRS context. We release our code and make all data available.""",16,inproceedings,2023,"@inproceedings{murakhovska-etal-2023-salespeople,
    title = {""Salespeople vs {S}ales{B}ot: Exploring the Role of Educational Value in Conversational Recommender Systems""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.657""},
    author = {""Murakhovs{'}ka, Lidiya  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""9823--9838""},
    abstract = {""Making big purchases requires consumers to research or consult a salesperson to gain domain expertise. However, existing conversational recommender systems (CRS) often overlook users{'} lack of background knowledge, focusing solely on gathering preferences. In this work, we define a new problem space for conversational agents that aim to provide both product recommendations and educational value through mixed-type mixed-initiative dialog. We introduce SalesOps, a framework that facilitates the simulation and evaluation of such systems by leveraging recent advancements in large language models (LLMs). We build SalesBot and ShopperBot, a pair of LLM-powered agents that can simulate either side of the framework. A comprehensive human study compares SalesBot against professional salespeople, revealing that although SalesBot approaches professional performance in terms of fluency and informativeness, it lags behind in recommendation quality. We emphasize the distinct limitations both face in providing truthful information, highlighting the challenges of ensuring faithfulness in the CRS context. We release our code and make all data available.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.657""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Unraveling Downstream Gender Bias from Large Language Models: A Study on {AI} Educational Writing Assistance,https://aclanthology.org/2023.findings-emnlp.689,10.18653/v1/2023.findings-emnlp.689,"""Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one in-classroom group with recommender system feature-based suggestions and four groups recruited from Prolific {--} a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis and Word Embedding Association Tests (WEAT), we evaluate the gender bias at various stages of the pipeline: in reviews written by students, in suggestions generated by the models, and in model embeddings directly. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students{'} responses.""",14,inproceedings,2023,"@inproceedings{wambsganss-etal-2023-unraveling,
    title = {""Unraveling Downstream Gender Bias from Large Language Models: A Study on {AI} Educational Writing Assistance""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.689""},
    author = {Wambsganss, Thiemo  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""10275--10288""},
    abstract = {""Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one in-classroom group with recommender system feature-based suggestions and four groups recruited from Prolific {--} a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis and Word Embedding Association Tests (WEAT), we evaluate the gender bias at various stages of the pipeline: in reviews written by students, in suggestions generated by the models, and in model embeddings directly. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students{'} responses.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.689""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{D}etect{LLM}: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text,https://aclanthology.org/2023.findings-emnlp.827,10.18653/v1/2023.findings-emnlp.827,"""With the rapid progress of Large language models (LLMs) and the huge amount of text they generate, it becomes impractical to manually distinguish whether a text is machine-generated. The growing use of LLMs in social media and education, prompts us to develop methods to detect machine-generated text, preventing malicious use such as plagiarism, misinformation, and propaganda. In this paper, we introduce two novel zero-shot methods for detecting machine-generated text by leveraging the Log-Rank information. One is called DetectLLM-LRR, which is fast and efficient, and the other is called DetectLLM-NPR, which is more accurate, but slower due to the need for perturbations. Our experiments on three datasets and seven language models show that our proposed methods improve over the state of the art by 3.9 and 1.75 AUROC points absolute. Moreover, DetectLLM-NPR needs fewer perturbations than previous work to achieve the same level of performance, which makes it more practical for real-world use. We also investigate the efficiency-performance trade-off based on users{'} preference for these two measures and provide intuition for using them in practice effectively. We release the data and the code of both methods in https://github.com/mbzuai-nlp/DetectLLM.""",18,inproceedings,2023,"@inproceedings{su-etal-2023-detectllm,
    title = {""{D}etect{LLM}: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-emnlp.827""},
    author = {""Su, Jinyan  and},
    booktitle = {""Findings of the Association for Computational Linguistics: EMNLP 2023""},
    pages = {""12395--12412""},
    abstract = {""With the rapid progress of Large language models (LLMs) and the huge amount of text they generate, it becomes impractical to manually distinguish whether a text is machine-generated. The growing use of LLMs in social media and education, prompts us to develop methods to detect machine-generated text, preventing malicious use such as plagiarism, misinformation, and propaganda. In this paper, we introduce two novel zero-shot methods for detecting machine-generated text by leveraging the Log-Rank information. One is called DetectLLM-LRR, which is fast and efficient, and the other is called DetectLLM-NPR, which is more accurate, but slower due to the need for perturbations. Our experiments on three datasets and seven language models show that our proposed methods improve over the state of the art by 3.9 and 1.75 AUROC points absolute. Moreover, DetectLLM-NPR needs fewer perturbations than previous work to achieve the same level of performance, which makes it more practical for real-world use. We also investigate the efficiency-performance trade-off based on users{'} preference for these two measures and provide intuition for using them in practice effectively. We release the data and the code of both methods in https://github.com/mbzuai-nlp/DetectLLM.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-emnlp.827""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Teaching the Pre-trained Model to Generate Simple Texts for Text Simplification,https://aclanthology.org/2023.findings-acl.595,10.18653/v1/2023.findings-acl.595,"""Randomly masking text spans in ordinary texts in the pre-training stage hardly allows models to acquire the ability to generate simple texts. It can hurt the performance of pre-trained models on text simplification tasks. In this paper, we propose a new continued pre-training strategy to teach the pre-trained model to generate simple texts. We continue pre-training BART, a representative model, to obtain SimpleBART. It consistently and significantly improves the results on lexical simplification, sentence simplification, and document-level simplification tasks over BART. At the end, we compare SimpleBART with several representative large language models (LLMs).""",11,inproceedings,2023,"@inproceedings{sun-etal-2023-teaching,
    title = {""Teaching the Pre-trained Model to Generate Simple Texts for Text Simplification""},
    editor = {""Rogers, Anna  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.findings-acl.595""},
    author = {""Sun, Renliang  and},
    booktitle = {""Findings of the Association for Computational Linguistics: ACL 2023""},
    pages = {""9345--9355""},
    abstract = {""Randomly masking text spans in ordinary texts in the pre-training stage hardly allows models to acquire the ability to generate simple texts. It can hurt the performance of pre-trained models on text simplification tasks. In this paper, we propose a new continued pre-training strategy to teach the pre-trained model to generate simple texts. We continue pre-training BART, a representative model, to obtain SimpleBART. It consistently and significantly improves the results on lexical simplification, sentence simplification, and document-level simplification tasks over BART. At the end, we compare SimpleBART with several representative large language models (LLMs).""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.findings-acl.595""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{E}du{Q}uick: A Dataset Toward Evaluating Summarization of Informal Educational Content for Social Media,https://aclanthology.org/2023.eval4nlp-1.4,10.18653/v1/2023.eval4nlp-1.4,"""This study explores the capacity of large language models (LLMs) to efficiently generate summaries of informal educational content tailored for platforms like TikTok. It also investigates how both humans and LLMs assess the quality of these summaries, based on a series of experiments, exploring the potential replacement of human evaluation with LLMs. Furthermore, the study delves into how experienced content creators perceive the utility of automatic summaries for TikTok videos. We employ strategic prompt selection techniques to guide LLMs in producing engaging summaries based on the characteristics of viral TikTok content, including hashtags, captivating hooks, storytelling, and user engagement. The study leverages OpenAI{'}s GPT-4 model to generate TikTok content summaries, aiming to align them with the essential features identified. By employing this model and incorporating human evaluation and expert assessment, this research endeavors to shed light on the intricate dynamics of modern content creation, where AI and human ingenuity converge. Ultimately, it seeks to enhance strategies for disseminating and evaluating educational information effectively in the realm of social media.""",17,inproceedings,2023,"@inproceedings{kolagar-etal-2023-eduquick,
    title = {""{E}du{Q}uick: A Dataset Toward Evaluating Summarization of Informal Educational Content for Social Media""},
    editor = {Deutsch, Daniel  and},
    month = {nov},
    year = {""2023""},
    address = {""Bali, Indonesia""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.eval4nlp-1.4""},
    author = {""Kolagar, Zahra  and},
    booktitle = {""Proceedings of the 4th Workshop on Evaluation and Comparison of NLP Systems""},
    pages = {""32--48""},
    abstract = {""This study explores the capacity of large language models (LLMs) to efficiently generate summaries of informal educational content tailored for platforms like TikTok. It also investigates how both humans and LLMs assess the quality of these summaries, based on a series of experiments, exploring the potential replacement of human evaluation with LLMs. Furthermore, the study delves into how experienced content creators perceive the utility of automatic summaries for TikTok videos. We employ strategic prompt selection techniques to guide LLMs in producing engaging summaries based on the characteristics of viral TikTok content, including hashtags, captivating hooks, storytelling, and user engagement. The study leverages OpenAI{'}s GPT-4 model to generate TikTok content summaries, aiming to align them with the essential features identified. By employing this model and incorporating human evaluation and expert assessment, this research endeavors to shed light on the intricate dynamics of modern content creation, where AI and human ingenuity converge. Ultimately, it seeks to enhance strategies for disseminating and evaluating educational information effectively in the realm of social media.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.eval4nlp-1.4""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency,https://aclanthology.org/2023.emnlp-main.135,10.18653/v1/2023.emnlp-main.135,"""Developing an educational test can be expensive and time-consuming, as each item must be written by experts and then evaluated by collecting hundreds of student responses. Moreover, many tests require multiple distinct sets of questions administered throughout the school year to closely monitor students{'} progress, known as parallel tests. In this study, we focus on tests of silent sentence reading efficiency, used to assess students{'} reading ability over time. To generate high-quality parallel tests, we propose to fine-tune large language models (LLMs) to simulate how previous students would have responded to unseen items. With these simulated responses, we can estimate each item{'}s difficulty and ambiguity. We first use GPT-4 to generate new test items following a list of expert-developed rules and then apply a fine-tuned LLM to filter the items based on criteria from psychological measurements. We also propose an optimal-transport-inspired technique for generating parallel tests and show the generated tests closely correspond to the original test{'}s difficulty and reliability based on crowdworker responses. Our evaluation of a generated test with 234 students from grades 2 to 8 produces test scores highly correlated (r=0.93) to those of a standard test form written by human experts and evaluated across thousands of K-12 students.""",16,inproceedings,2023,"@inproceedings{zelikman-etal-2023-generating,
    title = {""Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.135""},
    author = {""Zelikman, Eric  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""2190--2205""},
    abstract = {""Developing an educational test can be expensive and time-consuming, as each item must be written by experts and then evaluated by collecting hundreds of student responses. Moreover, many tests require multiple distinct sets of questions administered throughout the school year to closely monitor students{'} progress, known as parallel tests. In this study, we focus on tests of silent sentence reading efficiency, used to assess students{'} reading ability over time. To generate high-quality parallel tests, we propose to fine-tune large language models (LLMs) to simulate how previous students would have responded to unseen items. With these simulated responses, we can estimate each item{'}s difficulty and ambiguity. We first use GPT-4 to generate new test items following a list of expert-developed rules and then apply a fine-tuned LLM to filter the items based on criteria from psychological measurements. We also propose an optimal-transport-inspired technique for generating parallel tests and show the generated tests closely correspond to the original test{'}s difficulty and reliability based on crowdworker responses. Our evaluation of a generated test with 234 students from grades 2 to 8 produces test scores highly correlated (r=0.93) to those of a standard test form written by human experts and evaluated across thousands of K-12 students.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.135""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
On the Automatic Generation and Simplification of Children{'}s Stories,https://aclanthology.org/2023.emnlp-main.218,10.18653/v1/2023.emnlp-main.218,"""With recent advances in large language models (LLMs), the concept of automatically generating children{'}s educational materials has become increasingly realistic. Working toward the goal of age-appropriate simplicity in generated educational texts, we first examine the ability of several popular LLMs to generate stories with properly adjusted lexical and readability levels. We find that, in spite of the growing capabilities of LLMs, they do not yet possess the ability to limit their vocabulary to levels appropriate for younger age groups. As a second experiment, we explore the ability of state-of-the-art lexical simplification models to generalize to the domain of children{'}s stories and, thus, create an efficient pipeline for their automatic generation. In order to test these models, we develop a dataset of child-directed lexical simplification instances, with examples taken from the LLM-generated stories in our first experiment. We find that, while the strongest-performing current lexical simplification models do not perform as well on material designed for children due to their reliance on large language models behind the scenes, some models that still achieve fairly strong results on general data can mimic or even improve their performance on children-directed data with proper fine-tuning, which we conduct using our newly created child-directed simplification dataset.""",11,inproceedings,2023,"@inproceedings{valentini-etal-2023-automatic,
    title = {""On the Automatic Generation and Simplification of Children{'}s Stories""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.218""},
    author = {""Valentini, Maria  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""3588--3598""},
    abstract = {""With recent advances in large language models (LLMs), the concept of automatically generating children{'}s educational materials has become increasingly realistic. Working toward the goal of age-appropriate simplicity in generated educational texts, we first examine the ability of several popular LLMs to generate stories with properly adjusted lexical and readability levels. We find that, in spite of the growing capabilities of LLMs, they do not yet possess the ability to limit their vocabulary to levels appropriate for younger age groups. As a second experiment, we explore the ability of state-of-the-art lexical simplification models to generalize to the domain of children{'}s stories and, thus, create an efficient pipeline for their automatic generation. In order to test these models, we develop a dataset of child-directed lexical simplification instances, with examples taken from the LLM-generated stories in our first experiment. We find that, while the strongest-performing current lexical simplification models do not perform as well on material designed for children due to their reliance on large language models behind the scenes, some models that still achieve fairly strong results on general data can mimic or even improve their performance on children-directed data with proper fine-tuning, which we conduct using our newly created child-directed simplification dataset.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.218""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{``}Mistakes Help Us Grow{''}: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms,https://aclanthology.org/2023.emnlp-main.549,10.18653/v1/2023.emnlp-main.549,"""Teachers{'} growth mindset supportive language (GMSL){---}rhetoric emphasizing that one{'}s skills can be improved over time{---}has been shown to significantly reduce disparities in academic achievement and enhance students{'} learning outcomes. Although teachers espouse growth mindset principles, most find it difficult to adopt GMSL in their practice due the lack of effective coaching in this area. We explore whether large language models (LLMs) can provide automated, personalized coaching to support teachers{'} use of GMSL. We establish an effective coaching tool to reframe unsupportive utterances to GMSL by developing (i) a parallel dataset containing GMSL-trained teacher reframings of unsupportive statements with an accompanying annotation guide, (ii) a GMSL prompt framework to revise teachers{'} unsupportive language, and (iii) an evaluation framework grounded in psychological theory for evaluating GMSL with the help of students and teachers. We conduct a large-scale evaluation involving 174 teachers and 1,006 students, finding that both teachers and students perceive GMSL-trained teacher and model reframings as more effective in fostering a growth mindset and promoting challenge-seeking behavior, among other benefits. We also find that model-generated reframings outperform those from the GMSL-trained teachers. These results show promise for harnessing LLMs to provide automated GMSL feedback for teachers and, more broadly, LLMs{'} potentiality for supporting students{'} learning in the classroom. Our findings also demonstrate the benefit of large-scale human evaluations when applying LLMs in educational domains.""",21,inproceedings,2023,"@inproceedings{handa-etal-2023-mistakes,
    title = {""{``}Mistakes Help Us Grow{''}: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.549""},
    author = {""Handa, Kunal  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""8877--8897""},
    abstract = {""Teachers{'} growth mindset supportive language (GMSL){---}rhetoric emphasizing that one{'}s skills can be improved over time{---}has been shown to significantly reduce disparities in academic achievement and enhance students{'} learning outcomes. Although teachers espouse growth mindset principles, most find it difficult to adopt GMSL in their practice due the lack of effective coaching in this area. We explore whether large language models (LLMs) can provide automated, personalized coaching to support teachers{'} use of GMSL. We establish an effective coaching tool to reframe unsupportive utterances to GMSL by developing (i) a parallel dataset containing GMSL-trained teacher reframings of unsupportive statements with an accompanying annotation guide, (ii) a GMSL prompt framework to revise teachers{'} unsupportive language, and (iii) an evaluation framework grounded in psychological theory for evaluating GMSL with the help of students and teachers. We conduct a large-scale evaluation involving 174 teachers and 1,006 students, finding that both teachers and students perceive GMSL-trained teacher and model reframings as more effective in fostering a growth mindset and promoting challenge-seeking behavior, among other benefits. We also find that model-generated reframings outperform those from the GMSL-trained teachers. These results show promise for harnessing LLMs to provide automated GMSL feedback for teachers and, more broadly, LLMs{'} potentiality for supporting students{'} learning in the classroom. Our findings also demonstrate the benefit of large-scale human evaluations when applying LLMs in educational domains.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.549""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Hidding the Ghostwriters: An Adversarial Evaluation of {AI}-Generated Student Essay Detection,https://aclanthology.org/2023.emnlp-main.644,10.18653/v1/2023.emnlp-main.644,"""Large language models (LLMs) have exhibited remarkable capabilities in text generation tasks. However, the utilization of these models carries inherent risks, including but not limited to plagiarism, the dissemination of fake news, and issues in educational exercises. Although several detectors have been proposed to address these concerns, their effectiveness against adversarial perturbations, specifically in the context of student essay writing, remains largely unexplored. This paper aims to bridge this gap by constructing AIG-ASAP, an AI-generated student essay dataset, employing a range of text perturbation methods that are expected to generate high-quality essays while evading detection. Through empirical experiments, we assess the performance of current AIGC detectors on the AIG-ASAP dataset. The results reveal that the existing detectors can be easily circumvented using straightforward automatic adversarial attacks. Specifically, we explore word substitution and sentence substitution perturbation methods that effectively evade detection while maintaining the quality of the generated essays. This highlights the urgent need for more accurate and robust methods to detect AI-generated student essays in the education domain. Code and data are released for public use.""",14,inproceedings,2023,"@inproceedings{peng-etal-2023-hidding,
    title = {""Hidding the Ghostwriters: An Adversarial Evaluation of {AI}-Generated Student Essay Detection""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.644""},
    author = {""Peng, Xinlin  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""10406--10419""},
    abstract = {""Large language models (LLMs) have exhibited remarkable capabilities in text generation tasks. However, the utilization of these models carries inherent risks, including but not limited to plagiarism, the dissemination of fake news, and issues in educational exercises. Although several detectors have been proposed to address these concerns, their effectiveness against adversarial perturbations, specifically in the context of student essay writing, remains largely unexplored. This paper aims to bridge this gap by constructing AIG-ASAP, an AI-generated student essay dataset, employing a range of text perturbation methods that are expected to generate high-quality essays while evading detection. Through empirical experiments, we assess the performance of current AIGC detectors on the AIG-ASAP dataset. The results reveal that the existing detectors can be easily circumvented using straightforward automatic adversarial attacks. Specifically, we explore word substitution and sentence substitution perturbation methods that effectively evade detection while maintaining the quality of the generated essays. This highlights the urgent need for more accurate and robust methods to detect AI-generated student essays in the education domain. Code and data are released for public use.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.644""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Large Language Models Only Pass Primary School Exams in {I}ndonesia: A Comprehensive Test on {I}ndo{MMLU},https://aclanthology.org/2023.emnlp-main.760,10.18653/v1/2023.emnlp-main.760,"""Although large language models (LLMs) are often pre-trained on large-scale multilingual texts, their reasoning abilities and real-world knowledge are mainly evaluated based on English datasets. Assessing LLM capabilities beyond English is increasingly vital but hindered due to the lack of suitable datasets. In this work, we introduce IndoMMLU, the first multi-task language understanding benchmark for Indonesian culture and languages, which consists of questions from primary school to university entrance exams in Indonesia. By employing professional teachers, we obtain 14,981 questions across 64 tasks and education levels, with 46{\%} of the questions focusing on assessing proficiency in the Indonesian language and knowledge of nine local languages and cultures in Indonesia. Our empirical evaluations show that GPT-3.5 only manages to pass the Indonesian primary school level, with limited knowledge of local Indonesian languages and culture. Other smaller models such as BLOOMZ and Falcon perform at even lower levels.""",16,inproceedings,2023,"@inproceedings{koto-etal-2023-large,
    title = {""Large Language Models Only Pass Primary School Exams in {I}ndonesia: A Comprehensive Test on {I}ndo{MMLU}""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.760""},
    author = {""Koto, Fajri  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""12359--12374""},
    abstract = {""Although large language models (LLMs) are often pre-trained on large-scale multilingual texts, their reasoning abilities and real-world knowledge are mainly evaluated based on English datasets. Assessing LLM capabilities beyond English is increasingly vital but hindered due to the lack of suitable datasets. In this work, we introduce IndoMMLU, the first multi-task language understanding benchmark for Indonesian culture and languages, which consists of questions from primary school to university entrance exams in Indonesia. By employing professional teachers, we obtain 14,981 questions across 64 tasks and education levels, with 46{\%} of the questions focusing on assessing proficiency in the Indonesian language and knowledge of nine local languages and cultures in Indonesia. Our empirical evaluations show that GPT-3.5 only manages to pass the Indonesian primary school level, with limited knowledge of local Indonesian languages and culture. Other smaller models such as BLOOMZ and Falcon perform at even lower levels.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.760""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Let {GPT} be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation,https://aclanthology.org/2023.emnlp-main.889,10.18653/v1/2023.emnlp-main.889,"""In this paper, we present a novel approach for distilling math word problem solving capabilities from large language models (LLMs) into smaller, more efficient student models. Our approach is designed to consider the student model{'}s weaknesses and foster a tailored learning experience by generating targeted exercises aligned with educational science principles, such as knowledge tracing and personalized learning. Concretely, we let GPT-3 be a math tutor and run two steps iteratively: 1) assessing the student model{'}s current learning status on a GPT-generated exercise book, and 2) improving the student model by training it with tailored exercise samples generated by GPT-3. Experimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and PaLM) in accuracy across three distinct benchmarks while employing significantly fewer parameters. Furthermore, we provide a comprehensive analysis of the various components within our methodology to substantiate their efficacy.""",13,inproceedings,2023,"@inproceedings{liang-etal-2023-gpt,
    title = {""Let {GPT} be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation""},
    editor = {""Bouamor, Houda  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.emnlp-main.889""},
    author = {""Liang, Zhenwen  and},
    booktitle = {""Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""14384--14396""},
    abstract = {""In this paper, we present a novel approach for distilling math word problem solving capabilities from large language models (LLMs) into smaller, more efficient student models. Our approach is designed to consider the student model{'}s weaknesses and foster a tailored learning experience by generating targeted exercises aligned with educational science principles, such as knowledge tracing and personalized learning. Concretely, we let GPT-3 be a math tutor and run two steps iteratively: 1) assessing the student model{'}s current learning status on a GPT-generated exercise book, and 2) improving the student model by training it with tailored exercise samples generated by GPT-3. Experimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and PaLM) in accuracy across three distinct benchmarks while employing significantly fewer parameters. Furthermore, we provide a comprehensive analysis of the various components within our methodology to substantiate their efficacy.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.emnlp-main.889""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Opportunities and Challenges in Neural Dialog Tutoring,https://aclanthology.org/2023.eacl-main.173,10.18653/v1/2023.eacl-main.173,"""Designing dialog tutors has been challenging as it involves modeling the diverse and complex pedagogical strategies employed by human tutors. Although there have been significant recent advances in neural conversational systems using large language models and growth in available dialog corpora, dialog tutoring has largely remained unaffected by these advances. In this paper, we rigorously analyze various generative language models on two dialog tutoring datasets for language learning using automatic and human evaluations to understand the new opportunities brought by these advances as well as the challenges we must overcome to build models that would be usable in real educational settings. We find that although current approaches can model tutoring in constrained learning scenarios when the number of concepts to be taught and possible teacher strategies are small, they perform poorly in less constrained scenarios. Our human quality evaluation shows that both models and ground-truth annotations exhibit low performance in terms of equitable tutoring, which measures learning opportunities for students and how engaging the dialog is. To understand the behavior of our models in a real tutoring setting, we conduct a user study using expert annotators and find a significantly large number of model reasoning errors in 45{\%} of conversations. Finally, we connect our findings to outline future work.""",16,inproceedings,2023,"@inproceedings{macina-etal-2023-opportunities,
    title = {""Opportunities and Challenges in Neural Dialog Tutoring""},
    editor = {""Vlachos, Andreas  and},
    month = {may},
    year = {""2023""},
    address = {""Dubrovnik, Croatia""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.eacl-main.173""},
    author = {""Macina, Jakub  and},
    booktitle = {""Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics""},
    pages = {""2357--2372""},
    abstract = {""Designing dialog tutors has been challenging as it involves modeling the diverse and complex pedagogical strategies employed by human tutors. Although there have been significant recent advances in neural conversational systems using large language models and growth in available dialog corpora, dialog tutoring has largely remained unaffected by these advances. In this paper, we rigorously analyze various generative language models on two dialog tutoring datasets for language learning using automatic and human evaluations to understand the new opportunities brought by these advances as well as the challenges we must overcome to build models that would be usable in real educational settings. We find that although current approaches can model tutoring in constrained learning scenarios when the number of concepts to be taught and possible teacher strategies are small, they perform poorly in less constrained scenarios. Our human quality evaluation shows that both models and ground-truth annotations exhibit low performance in terms of equitable tutoring, which measures learning opportunities for students and how engaging the dialog is. To understand the behavior of our models in a real tutoring setting, we conduct a user study using expert annotators and find a significantly large number of model reasoning errors in 45{\%} of conversations. Finally, we connect our findings to outline future work.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.eacl-main.173""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Reviewriter: {AI}-Generated Instructions For Peer Review Writing,https://aclanthology.org/2023.bea-1.5,10.18653/v1/2023.bea-1.5,"""Large Language Models (LLMs) offer novel opportunities for educational applications that have the potential to transform traditional learning for students. Despite AI-enhanced applications having the potential to provide personalized learning experiences, more studies are needed on the design of generative AI systems and evidence for using them in real educational settings. In this paper, we design, implement and evaluate {\textbackslash}texttt{Reviewriter}, a novel tool to provide students with AI-generated instructions for writing peer reviews in German. Our study identifies three key aspects: a) we provide insights into student needs when writing peer reviews with generative models which we then use to develop a novel system to provide adaptive instructions b) we fine-tune three German language models on a selected corpus of 11,925 student-written peer review texts in German and choose German-GPT2 based on quantitative measures and human evaluation, and c) we evaluate our tool with fourteen students, revealing positive technology acceptance based on quantitative measures. Additionally, the qualitative feedback presents the benefits and limitations of generative AI in peer review writing.""",15,inproceedings,2023,"@inproceedings{su-etal-2023-reviewriter,
    title = {""Reviewriter: {AI}-Generated Instructions For Peer Review Writing""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.5""},
    author = {Su, Xiaotian  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""57--71""},
    abstract = {""Large Language Models (LLMs) offer novel opportunities for educational applications that have the potential to transform traditional learning for students. Despite AI-enhanced applications having the potential to provide personalized learning experiences, more studies are needed on the design of generative AI systems and evidence for using them in real educational settings. In this paper, we design, implement and evaluate {\textbackslash}texttt{Reviewriter}, a novel tool to provide students with AI-generated instructions for writing peer reviews in German. Our study identifies three key aspects: a) we provide insights into student needs when writing peer reviews with generative models which we then use to develop a novel system to provide adaptive instructions b) we fine-tune three German language models on a selected corpus of 11,925 student-written peer review texts in German and choose German-GPT2 based on quantitative measures and human evaluation, and c) we evaluate our tool with fourteen students, revealing positive technology acceptance based on quantitative measures. Additionally, the qualitative feedback presents the benefits and limitations of generative AI in peer review writing.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.5""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Enhancing Human Summaries for Question-Answer Generation in Education,https://aclanthology.org/2023.bea-1.9,10.18653/v1/2023.bea-1.9,"""We address the problem of generating high-quality question-answer pairs for educational materials. Previous work on this problem showed that using summaries as input improves the quality of question generation (QG) over original textbook text and that human-written summaries result in higher quality QG than automatic summaries. In this paper, a) we show that advances in Large Language Models (LLMs) are not yet sufficient to generate quality summaries for QG and b) we introduce a new methodology for enhancing bullet point student notes into fully fledged summaries and find that our methodology yields higher quality QG. We conducted a large-scale human annotation study of generated question-answer pairs for the evaluation of our methodology. In order to aid in future research, we release a new dataset of 9.2K human annotations of generated questions.""",11,inproceedings,2023,"@inproceedings{gonzalez-etal-2023-enhancing,
    title = {""Enhancing Human Summaries for Question-Answer Generation in Education""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.9""},
    author = {""Gonzalez, Hannah  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""108--118""},
    abstract = {""We address the problem of generating high-quality question-answer pairs for educational materials. Previous work on this problem showed that using summaries as input improves the quality of question generation (QG) over original textbook text and that human-written summaries result in higher quality QG than automatic summaries. In this paper, a) we show that advances in Large Language Models (LLMs) are not yet sufficient to generate quality summaries for QG and b) we introduce a new methodology for enhancing bullet point student notes into fully fledged summaries and find that our methodology yields higher quality QG. We conducted a large-scale human annotation study of generated question-answer pairs for the evaluation of our methodology. In order to aid in future research, we release a new dataset of 9.2K human annotations of generated questions.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.9""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series,https://aclanthology.org/2023.bea-1.21,10.18653/v1/2023.bea-1.21,"""This paper analyzes winning solutions from the Feedback Prize competition series hosted from 2021-2022. The competition sought to improve Assisted Writing Feedback Tools (AWFTs) by crowdsourcing Large Language Model (LLM) solutions for evaluating student writing. The winning models are freely available for incorporation into educational applications, but the models need to be assessed for performance and other factors. This study reports the performance accuracy of Feedback Prize-winning models based on demographic factors such as student race/ethnicity, economic disadvantage, and English Language Learner status. Two competitions are analyzed. The first, which focused on identifying discourse elements, demonstrated minimal bias based on students{'} demographic factors. However, the second competition, which aimed to predict discourse effectiveness, exhibited moderate bias.""",5,inproceedings,2023,"@inproceedings{baffour-etal-2023-analyzing,
    title = {""Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.21""},
    author = {""Baffour, Perpetual  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""242--246""},
    abstract = {""This paper analyzes winning solutions from the Feedback Prize competition series hosted from 2021-2022. The competition sought to improve Assisted Writing Feedback Tools (AWFTs) by crowdsourcing Large Language Model (LLM) solutions for evaluating student writing. The winning models are freely available for incorporation into educational applications, but the models need to be assessed for performance and other factors. This study reports the performance accuracy of Feedback Prize-winning models based on demographic factors such as student race/ethnicity, economic disadvantage, and English Language Learner status. Two competitions are analyzed. The first, which focused on identifying discourse elements, demonstrated minimal bias based on students{'} demographic factors. However, the second competition, which aimed to predict discourse effectiveness, exhibited moderate bias.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.21""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{SIGHT}: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts,https://aclanthology.org/2023.bea-1.27,10.18653/v1/2023.bea-1.27,"""Lectures are a learning experience for both students and teachers. Students learn from teachers about the subject material, while teachers learn from students about how to refine their instruction. Unfortunately, online student feedback is unstructured and abundant, making it challenging for teachers to learn and improve. We take a step towards tackling this challenge. First, we contribute a dataset for studying this problem: SIGHT is a large dataset of 288 math lecture transcripts and 15,784 comments collected from the Massachusetts Institute of Technology OpenCourseWare (MIT OCW) YouTube channel. Second, we develop a rubric for categorizing feedback types using qualitative analysis. Qualitative analysis methods are powerful in uncovering domain-specific insights, however they are costly to apply to large data sources. To overcome this challenge, we propose a set of best practices for using large language models (LLMs) to cheaply classify the comments at scale. We observe a striking correlation between the model{'}s and humans{'} annotation: Categories with consistent human annotations (0.9 inter-rater reliability, IRR) also display higher human-model agreement (0.7), while categories with less consistent human annotations (0.7-0.8 IRR) correspondingly demonstrate lower human-model agreement (0.3-0.5). These techniques uncover useful student feedback from thousands of comments, costing around {\$}0.002 per comment. We conclude by discussing exciting future directions on using online student feedback and improving automated annotation techniques for qualitative research.""",37,inproceedings,2023,"@inproceedings{wang-etal-2023-sight,
    title = {""{SIGHT}: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.27""},
    author = {""Wang, Rose  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""315--351""},
    abstract = {""Lectures are a learning experience for both students and teachers. Students learn from teachers about the subject material, while teachers learn from students about how to refine their instruction. Unfortunately, online student feedback is unstructured and abundant, making it challenging for teachers to learn and improve. We take a step towards tackling this challenge. First, we contribute a dataset for studying this problem: SIGHT is a large dataset of 288 math lecture transcripts and 15,784 comments collected from the Massachusetts Institute of Technology OpenCourseWare (MIT OCW) YouTube channel. Second, we develop a rubric for categorizing feedback types using qualitative analysis. Qualitative analysis methods are powerful in uncovering domain-specific insights, however they are costly to apply to large data sources. To overcome this challenge, we propose a set of best practices for using large language models (LLMs) to cheaply classify the comments at scale. We observe a striking correlation between the model{'}s and humans{'} annotation: Categories with consistent human annotations (0.9 inter-rater reliability, IRR) also display higher human-model agreement (0.7), while categories with less consistent human annotations (0.7-0.8 IRR) correspondingly demonstrate lower human-model agreement (0.3-0.5). These techniques uncover useful student feedback from thousands of comments, costing around {\$}0.002 per comment. We conclude by discussing exciting future directions on using online student feedback and improving automated annotation techniques for qualitative research.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.27""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Automated evaluation of written discourse coherence using {GPT}-4,https://aclanthology.org/2023.bea-1.32,10.18653/v1/2023.bea-1.32,"""The popularization of large language models (LLMs) such as OpenAI{'}s GPT-3 and GPT-4 have led to numerous innovations in the field of AI in education. With respect to automated writing evaluation (AWE), LLMs have reduced challenges associated with assessing writing quality characteristics that are difficult to identify automatically, such as discourse coherence. In addition, LLMs can provide rationales for their evaluations (ratings) which increases score interpretability and transparency. This paper investigates one approach to producing ratings by training GPT-4 to assess discourse coherence in a manner consistent with expert human raters. The findings of the study suggest that GPT-4 has strong potential to produce discourse coherence ratings that are comparable to human ratings, accompanied by clear rationales. Furthermore, the GPT-4 ratings outperform traditional NLP coherence metrics with respect to agreement with human ratings. These results have implications for advancing AWE technology for learning and assessment.""",10,inproceedings,2023,"@inproceedings{naismith-etal-2023-automated,
    title = {""Automated evaluation of written discourse coherence using {GPT}-4""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.32""},
    author = {""Naismith, Ben  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""394--403""},
    abstract = {""The popularization of large language models (LLMs) such as OpenAI{'}s GPT-3 and GPT-4 have led to numerous innovations in the field of AI in education. With respect to automated writing evaluation (AWE), LLMs have reduced challenges associated with assessing writing quality characteristics that are difficult to identify automatically, such as discourse coherence. In addition, LLMs can provide rationales for their evaluations (ratings) which increases score interpretability and transparency. This paper investigates one approach to producing ratings by training GPT-4 to assess discourse coherence in a manner consistent with expert human raters. The findings of the study suggest that GPT-4 has strong potential to produce discourse coherence ratings that are comparable to human ratings, accompanied by clear rationales. Furthermore, the GPT-4 ratings outperform traditional NLP coherence metrics with respect to agreement with human ratings. These results have implications for advancing AWE technology for learning and assessment.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.32""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Generating Better Items for Cognitive Assessments Using Large Language Models,https://aclanthology.org/2023.bea-1.34,10.18653/v1/2023.bea-1.34,"""Writing high-quality test questions (items) is critical to building educational measures but has traditionally also been a time-consuming process. One promising avenue for alleviating this is automated item generation, whereby methods from artificial intelligence (AI) are used to generate new items with minimal human intervention. Researchers have explored using large language models (LLMs) to generate new items with equivalent psychometric properties to human-written ones. But can LLMs generate items with improved psychometric properties, even when existing items have poor validity evidence? We investigate this using items from a natural language inference (NLI) dataset. We develop a novel prompting strategy based on selecting items with both the best and worst properties to use in the prompt and use GPT-3 to generate new NLI items. We find that the GPT-3 items show improved psychometric properties in many cases, whilst also possessing good content, convergent and discriminant validity evidence. Collectively, our results demonstrate the potential of employing LLMs to ease the item development process and suggest that the careful use of prompting may allow for iterative improvement of item quality.""",15,inproceedings,2023,"@inproceedings{laverghetta-jr-licato-2023-generating,
    title = {""Generating Better Items for Cognitive Assessments Using Large Language Models""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.34""},
    author = {""Laverghetta Jr., Antonio  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""414--428""},
    abstract = {""Writing high-quality test questions (items) is critical to building educational measures but has traditionally also been a time-consuming process. One promising avenue for alleviating this is automated item generation, whereby methods from artificial intelligence (AI) are used to generate new items with minimal human intervention. Researchers have explored using large language models (LLMs) to generate new items with equivalent psychometric properties to human-written ones. But can LLMs generate items with improved psychometric properties, even when existing items have poor validity evidence? We investigate this using items from a natural language inference (NLI) dataset. We develop a novel prompting strategy based on selecting items with both the best and worst properties to use in the prompt and use GPT-3 to generate new NLI items. We find that the GPT-3 items show improved psychometric properties in many cases, whilst also possessing good content, convergent and discriminant validity evidence. Collectively, our results demonstrate the potential of employing LLMs to ease the item development process and suggest that the careful use of prompting may allow for iterative improvement of item quality.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.34""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Evaluating Reading Comprehension Exercises Generated by {LLM}s: A Showcase of {C}hat{GPT} in Education Applications,https://aclanthology.org/2023.bea-1.52,10.18653/v1/2023.bea-1.52,"""The recent advancement of pre-trained Large Language Models (LLMs), such as OpenAI{'}s ChatGPT, has led to transformative changes across fields. For example, developing intelligent systems in the educational sector that leverage the linguistic capabilities of LLMs demonstrates a visible potential. Though researchers have recently explored how ChatGPT could possibly assist in student learning, few studies have applied these techniques to real-world classroom settings involving teachers and students. In this study, we implement a reading comprehension exercise generation system that provides high-quality and personalized reading materials for middle school English learners in China. Extensive evaluations of the generated reading passages and corresponding exercise questions, conducted both automatically and manually, demonstrate that the system-generated materials are suitable for students and even surpass the quality of existing human-written ones. By incorporating first-hand feedback and suggestions from experienced educators, this study serves as a meaningful pioneering application of ChatGPT, shedding light on the future design and implementation of LLM-based systems in the educational context.""",16,inproceedings,2023,"@inproceedings{xiao-etal-2023-evaluating,
    title = {""Evaluating Reading Comprehension Exercises Generated by {LLM}s: A Showcase of {C}hat{GPT} in Education Applications""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.52""},
    author = {""Xiao, Changrong  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""610--625""},
    abstract = {""The recent advancement of pre-trained Large Language Models (LLMs), such as OpenAI{'}s ChatGPT, has led to transformative changes across fields. For example, developing intelligent systems in the educational sector that leverage the linguistic capabilities of LLMs demonstrates a visible potential. Though researchers have recently explored how ChatGPT could possibly assist in student learning, few studies have applied these techniques to real-world classroom settings involving teachers and students. In this study, we implement a reading comprehension exercise generation system that provides high-quality and personalized reading materials for middle school English learners in China. Extensive evaluations of the generated reading passages and corresponding exercise questions, conducted both automatically and manually, demonstrate that the system-generated materials are suitable for students and even surpass the quality of existing human-written ones. By incorporating first-hand feedback and suggestions from experienced educators, this study serves as a meaningful pioneering application of ChatGPT, shedding light on the future design and implementation of LLM-based systems in the educational context.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.52""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Assessing the efficacy of large language models in generating accurate teacher responses,https://aclanthology.org/2023.bea-1.60,10.18653/v1/2023.bea-1.60,"""(Tack et al., 2023) organized the shared task hosted by the 18th Workshop on Innovative Use of NLP for Building Educational Applications on generation of teacher language in educational dialogues. Following the structure of the shared task, in this study, we attempt to assess the generative abilities of large language models in providing informative and helpful insights to students, thereby simulating the role of a knowledgeable teacher. To this end, we present an extensive evaluation of several benchmarking generative models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT. Additionally, to optimize for pedagogical quality, we fine-tuned the Flan-T5 model using reinforcement learning. Our experimental findings on the Teacher-Student Chatroom Corpus subset indicate the efficacy of GPT-4 over other fine-tuned models, measured using BERTScore and DialogRPT. We hypothesize that several dataset characteristics, including sampling, representativeness, and dialog completeness, pose significant challenges to fine-tuning, thus contributing to the poor generalizability of the fine-tuned models. Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on the model{'}s ability to showcase pedagogical skills.""",11,inproceedings,2023,"@inproceedings{hicke-etal-2023-assessing,
    title = {""Assessing the efficacy of large language models in generating accurate teacher responses""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.60""},
    author = {""Hicke, Yann  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""745--755""},
    abstract = {""(Tack et al., 2023) organized the shared task hosted by the 18th Workshop on Innovative Use of NLP for Building Educational Applications on generation of teacher language in educational dialogues. Following the structure of the shared task, in this study, we attempt to assess the generative abilities of large language models in providing informative and helpful insights to students, thereby simulating the role of a knowledgeable teacher. To this end, we present an extensive evaluation of several benchmarking generative models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT. Additionally, to optimize for pedagogical quality, we fine-tuned the Flan-T5 model using reinforcement learning. Our experimental findings on the Teacher-Student Chatroom Corpus subset indicate the efficacy of GPT-4 over other fine-tuned models, measured using BERTScore and DialogRPT. We hypothesize that several dataset characteristics, including sampling, representativeness, and dialog completeness, pose significant challenges to fine-tuning, thus contributing to the poor generalizability of the fine-tuned models. Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on the model{'}s ability to showcase pedagogical skills.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.60""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{RETUYT}-{I}n{C}o at {BEA} 2023 Shared Task: Tuning Open-Source {LLM}s for Generating Teacher Responses,https://aclanthology.org/2023.bea-1.61,10.18653/v1/2023.bea-1.61,"""This paper presents the results of our participation in the BEA 2023 shared task, which focuses on generating AI teacher responses in educational dialogues. We conducted experiments using several Open-Source Large Language Models (LLMs) and explored fine-tuning techniques along with prompting strategies, including Few-Shot and Chain-of-Thought approaches. Our best model was ranked 4.5 in the competition with a BertScore F1 of 0.71 and a DialogRPT final (avg) of 0.35. Nevertheless, our internal results did not exactly correlate with those obtained in the competition, which showed the difficulty in evaluating this task. Other challenges we faced were data leakage on the train set and the irregular format of the conversations.""",10,inproceedings,2023,"@inproceedings{baladon-etal-2023-retuyt,
    title = {""{RETUYT}-{I}n{C}o at {BEA} 2023 Shared Task: Tuning Open-Source {LLM}s for Generating Teacher Responses""},
    editor = {Kochmar, Ekaterina  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.bea-1.61""},
    author = {""Balad{\'o}n, Alexis  and},
    booktitle = {""Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)""},
    pages = {""756--765""},
    abstract = {""This paper presents the results of our participation in the BEA 2023 shared task, which focuses on generating AI teacher responses in educational dialogues. We conducted experiments using several Open-Source Large Language Models (LLMs) and explored fine-tuning techniques along with prompting strategies, including Few-Shot and Chain-of-Thought approaches. Our best model was ranked 4.5 in the competition with a BertScore F1 of 0.71 and a DialogRPT final (avg) of 0.35. Nevertheless, our internal results did not exactly correlate with those obtained in the competition, which showed the difficulty in evaluating this task. Other challenges we faced were data leakage on the train set and the irregular format of the conversations.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.bea-1.61""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{A}rab{I}cros: {AI}-Powered {A}rabic Crossword Puzzle Generation for Educational Applications,https://aclanthology.org/2023.arabicnlp-1.23,10.18653/v1/2023.arabicnlp-1.23,"""This paper presents the first Arabic crossword puzzle generator driven by advanced AI technology. Leveraging cutting-edge large language models including GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system generates distinctive and challenging clues. Based on a dataset comprising over 50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot learning strategies, and rigorous quality-checking protocols to enforce the generation of high-quality clue-answer pairs. Importantly, educational crosswords contribute to enhancing memory, expanding vocabulary, and promoting problem-solving skills, thereby augmenting the learning experience through a fun and engaging approach, reshaping the landscape of traditional learning methods. The overall system can be exploited as a powerful educational tool that amalgamates AI and innovative learning techniques, heralding a transformative era for Arabic crossword puzzles and the intersection of technology and education.""",14,inproceedings,2023,"@inproceedings{zeinalipour-etal-2023-arabicros,
    title = {""{A}rab{I}cros: {AI}-Powered {A}rabic Crossword Puzzle Generation for Educational Applications""},
    editor = {""Sawaf, Hassan  and},
    month = {dec},
    year = {""2023""},
    address = {""Singapore (Hybrid)""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.arabicnlp-1.23""},
    author = {""Zeinalipour, Kamyar  and},
    booktitle = {""Proceedings of ArabicNLP 2023""},
    pages = {""288--301""},
    abstract = {""This paper presents the first Arabic crossword puzzle generator driven by advanced AI technology. Leveraging cutting-edge large language models including GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system generates distinctive and challenging clues. Based on a dataset comprising over 50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot learning strategies, and rigorous quality-checking protocols to enforce the generation of high-quality clue-answer pairs. Importantly, educational crosswords contribute to enhancing memory, expanding vocabulary, and promoting problem-solving skills, thereby augmenting the learning experience through a fun and engaging approach, reshaping the landscape of traditional learning methods. The overall system can be exploited as a powerful educational tool that amalgamates AI and innovative learning techniques, heralding a transformative era for Arabic crossword puzzles and the intersection of technology and education.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.arabicnlp-1.23""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Teaching Small Language Models to Reason,https://aclanthology.org/2023.acl-short.151,10.18653/v1/2023.acl-short.151,"""Chain of thought prompting successfully improves the reasoning capabilities of large language models, achieving state of the art results on a range of datasets. However, these reasoning capabilities only appear to emerge in models with at least tens of billions of parameters. In this paper, we explore the transfer of such reasoning capabilities to smaller models via knowledge distillation, also investigating model and dataset size trade-off. Specifically, we finetune a student model on the chain of thought outputs generated by a larger teacher model. Our experiments show that the proposed method improves task performance across arithmetic, commonsense and symbolic reasoning datasets. For example, the accuracy of T5 XXL on GSM8K improves from 8.11{\%} to 21.99{\%} and 18.42{\%} when finetuned on PaLM 540B and GPT-3 175B generated chains of thought, respectively.""",9,inproceedings,2023,"@inproceedings{magister-etal-2023-teaching,
    title = {""Teaching Small Language Models to Reason""},
    editor = {""Rogers, Anna  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.acl-short.151""},
    author = {""Magister, Lucie Charlotte  and},
    booktitle = {""Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)""},
    pages = {""1773--1781""},
    abstract = {""Chain of thought prompting successfully improves the reasoning capabilities of large language models, achieving state of the art results on a range of datasets. However, these reasoning capabilities only appear to emerge in models with at least tens of billions of parameters. In this paper, we explore the transfer of such reasoning capabilities to smaller models via knowledge distillation, also investigating model and dataset size trade-off. Specifically, we finetune a student model on the chain of thought outputs generated by a larger teacher model. Our experiments show that the proposed method improves task performance across arithmetic, commonsense and symbolic reasoning datasets. For example, the accuracy of T5 XXL on GSM8K improves from 8.11{\%} to 21.99{\%} and 18.42{\%} when finetuned on PaLM 540B and GPT-3 175B generated chains of thought, respectively.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.acl-short.151""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
{ELQA}: A Corpus of Metalinguistic Questions and Answers about {E}nglish,https://aclanthology.org/2023.acl-long.113,10.18653/v1/2023.acl-long.113,"""We present ELQA, a corpus of questions and answers in and about the English language. Collected from two online forums, the {\textgreater}70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology. The answers include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect) usage examples. Unlike most NLP datasets, this corpus is metalinguistic{---}it consists of language about language. As such, it can facilitate investigations of the metalinguistic capabilities of NLU models, as well as educational applications in the language learning domain. To study this, we define a free-form question answering task on our dataset and conduct evaluations on multiple LLMs (Large Language Models) to analyze their capacity to generate metalinguistic answers.""",17,inproceedings,2023,"@inproceedings{behzad-etal-2023-elqa,
    title = {""{ELQA}: A Corpus of Metalinguistic Questions and Answers about {E}nglish""},
    editor = {""Rogers, Anna  and},
    month = {jul},
    year = {""2023""},
    address = {""Toronto, Canada""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2023.acl-long.113""},
    author = {""Behzad, Shabnam  and},
    booktitle = {""Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)""},
    pages = {""2031--2047""},
    abstract = {""We present ELQA, a corpus of questions and answers in and about the English language. Collected from two online forums, the {\textgreater}70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology. The answers include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect) usage examples. Unlike most NLP datasets, this corpus is metalinguistic{---}it consists of language about language. As such, it can facilitate investigations of the metalinguistic capabilities of NLU models, as well as educational applications in the language learning domain. To study this, we define a free-form question answering task on our dataset and conduct evaluations on multiple LLMs (Large Language Models) to analyze their capacity to generate metalinguistic answers.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2023.acl-long.113""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
Automatic Generation of Socratic Subquestions for Teaching Math Word Problems,https://aclanthology.org/2022.emnlp-main.277,10.18653/v1/2022.emnlp-main.277,"""Socratic questioning is an educational method that allows students to discover answers to complex problems by asking them a series of thoughtful questions. Generation of didactically sound questions is challenging, requiring understanding of the reasoning process involved in the problem. We hypothesize that such questioning strategy can not only enhance the human performance, but also assist the math word problem (MWP) solvers.In this work, we explore the ability of large language models (LMs) in generating sequential questions for guiding math word problem-solving. We propose various guided question generation schemes based on input conditioning and reinforcement learning.On both automatic and human quality evaluations, we find that LMs constrained with desirable question properties generate superior questions and improve the overall performance of a math word problem solver. We conduct a preliminary user study to examine the potential value of such question generation models in the education domain. Results suggest that the difficulty level of problems plays an important role in determining whether questioning improves or hinders human performance. We discuss the future of using such questioning strategies in education.""",14,inproceedings,2022,"@inproceedings{shridhar-etal-2022-automatic,
    title = {""Automatic Generation of Socratic Subquestions for Teaching Math Word Problems""},
    editor = {""Goldberg, Yoav  and},
    month = {dec},
    year = {""2022""},
    address = {""Abu Dhabi, United Arab Emirates""},
    publisher = {""Association for Computational Linguistics""},
    url = {""https://aclanthology.org/2022.emnlp-main.277""},
    author = {""Shridhar, Kumar  and},
    booktitle = {""Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing""},
    pages = {""4136--4149""},
    abstract = {""Socratic questioning is an educational method that allows students to discover answers to complex problems by asking them a series of thoughtful questions. Generation of didactically sound questions is challenging, requiring understanding of the reasoning process involved in the problem. We hypothesize that such questioning strategy can not only enhance the human performance, but also assist the math word problem (MWP) solvers.In this work, we explore the ability of large language models (LMs) in generating sequential questions for guiding math word problem-solving. We propose various guided question generation schemes based on input conditioning and reinforcement learning.On both automatic and human quality evaluations, we find that LMs constrained with desirable question properties generate superior questions and improve the overall performance of a math word problem solver. We conduct a preliminary user study to examine the potential value of such question generation models in the education domain. Results suggest that the difficulty level of problems plays an important role in determining whether questioning improves or hinders human performance. We discuss the future of using such questioning strategies in education.""},
    Stali{\ = {},
    journal = {},
    volume = {},
    doi = {""10.18653/v1/2022.emnlp-main.277""},
    Keith, T{\ = {},
    V{\ = {},
    Pinnis, M{\ = {},
    B{\ = {},
    number = {},
    Val{\ = {},
    language = {},
    K{\ = {},
    Ole{\v{s}}kevi{\v{c}}ien{\.e}, Giedr{\.e} Val{\ = {},
    St{\ = {},
    Vasi{\c{l}}evskis, Art{\ = {},
    Ziedi{\c{n}}{\v{s}}, J{\ = {},
    Lev{\ = {},
    Pokratniece, Krist{\ = {},
    Poik{\ = {},
    Bakl{\ = {},
    Saulespur{\ = {},
    Girdzijauskas, {\v{S}}ar{\ = {},
    {\v{S}}lapi{\c{n}}{\v{s}}, J{\ = {},
    Bern{\ = {},
    Stafanovi{\v{c}}, Art{\ = {},
    Ne{\v{s}}pore-B{\ = {},
    ISBN = {},
    Auksori{\ = {},
    Me{\c{l}}{\c{n}}ika, J{\ = {},
    Ajausks, {\ = {},
    Rikters, Mat{\ = {},
    Metuz{\ = {},
    S{\ = {},
    Liepins, Ren{\ = {},
    Znoti{\c{n}}{\v{s}}, Art{\ = {},
    {\c{N}}ikiforovs, P{\ = {},
    Goba, K{\ = {},
    Paikens, P{\ = {},
    Gr{\ = {},
    Saul{\ = {},
    Manuirirangi, H{\ = {},
    Br{\ = {},
    Matsumoto, Y{\ = {},
    note = {},
}"
