author,title,year,isbn,publisher,address,url,doi,abstract,booktitle,pages,numpages,keywords,location,series,type,articleno,issue_date,volume,number,journal,month,issn,note,edition,editor
"Xiang, Lili",SQL Query Evaluation with Large Language Model and Abstract Syntax Trees,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635408,10.1145/3626253.3635408,"SQL stands as the foundational language for data analysis and manipulation, playing a pivotal role in the database learning process. Proficiency in SQL is essential for students seeking to excel in data-related fields. However, the conventional approaches to assessing SQL queries rely heavily on manual grading, and the automated assessment tools are usually producing only binary decisions for the submitted queries. Our primary research objective is to develop effective methods for evaluating the quality of the SQL queries. To meet this objective, we introduce two approaches: structure-based analysis and evaluation by an instruction tuned large language model (LLM). The first approach deconstructs queries into Abstract Syntax Trees (AST) and employs cosine similarity to assess student submissions. The second approach utilizes a pre-trained LLM: FLAN-T5, fine-tuned for predicting the quality of student submissions. These methodologies are tested on a SQL dataset, and our experimental findings evaluate against a grading rubric with categories ranging from ",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1890,1,"abstract syntax trees, auto-grader, cs education, large language model, sql","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Fulcini, Tommaso and Torchiano, Marco",Is ChatGPT Capable of Crafting Gamification Strategies for Software Engineering Tasks?,2023,9798400703737,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3617553.3617887,10.1145/3617553.3617887,"Gamification has gained significant attention in the last decade for its potential to enhance engagement and motivation in various domains. During the last year ChatGPT, a state-of-the-art large language model has received even more attention both in the field of scientific research and in common use by individuals or companies.  
In this study, we investigate the possibility of adopting ChatGPT as a tool for designing gamification platforms in the Software Engineering domain. Leveraging the capabilities of ChatGPT, we assess how good is it at generating effective suggestions and ideas for designers or developers.  
To evaluate ChatGPT's potential as a gamification platform creator we narrowed the context to one particular Software Engineering activity, asking for possible aspects of the activity to be gamified. Each proposed aspect was subsequently unraveled by ChatGPT both asking in a shared and separate context, first following the conversational nature of the model, then applying a validated design framework. The study assesses ChatGPT's ability to select and integrate game elements to build a thriving gamification environment by framing the design of the platform to a state-of-the-art conceptual framework. To evaluate the goodness of the design choices made we relied both on the Octalysis framework and on personal experience.  
The findings of the papers show that ChatGPT can only create simple playful experiences not very effective. Although, by instructing the model with more specific desired mechanics and dynamics, it is possible to guide it toward the application of the ideas suggested. We argue that ChatGPT is not capable of building a gamified environment on its own, but it could still be used to build the foundation of a gamification platform as long as the designers refine and rough out the advice gained from a user-centered solution.","Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation",22–28,7,"Artificial Intelligence, Gamification, Large Language Model, Software Engineering, Software Lifecycle","San Francisco, CA, USA",Gamify 2023,inproceedings,,,,,,,,,,
"Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.",Software Engineering Education Must Adapt and Evolve for an LLM Environment,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630927,10.1145/3626252.3630927,"In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,666–672,7,"chatgpt, generative ai, large language models (llms), responsible ai, software engineering, software engineering education, software engineering ethics, software ethics","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Jiang, Peiling and Rayan, Jude and Dow, Steven P. and Xia, Haijun",Graphologue: Exploring Large Language Model Responses with Interactive Diagrams,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606737,10.1145/3586183.3606737,"Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented ability to synthesize text responses to diverse user questions. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can interact with the diagrams to flexibly adjust the graphical presentation and to submit context-specific prompts to obtain more information. Utilizing diagrams, Graphologue enables graphical, non-linear dialogues between humans and LLMs, facilitating information exploration, organization, and comprehension.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,20,"Large Language Model, Natural Language Interface, Visualization","San Francisco, CA, USA",UIST '23,inproceedings,3,,,,,,,,,
"Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca",Incorporating Generative AI into Software Development Education,2024,9798400709326,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3633053.3633057,10.1145/3633053.3633057,"This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.",Proceedings of the 8th Conference on Computing Education Practice,37–40,4,"apprenticeship, assessment, education, generative AI, software engineering","Durham, United Kingdom",CEP '24,inproceedings,,,,,,,,,,
"Brie, Paul and Burny, Nicolas and Slu\",Evaluating a Large Language Model on Searching for GUI Layouts,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3593230,10.1145/3593230,"The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.",,,37,"generative pre-training, gui design, gui layout, large language model, web pages",,,article,178,June 2023,7,EICS,Proc. ACM Hum.-Comput. Interact.,jun,,,,
"Wang, Jiabo and Chu, Guojun and Wang, Jingyu and Sun, Haifeng and Qi, Qi and Wang, Yuanyi and Qi, Ji and Liao, Jianxin",LogExpert: Log-based Recommended Resolutions Generation using Large Language Model,2024,9798400705007,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639476.3639773,10.1145/3639476.3639773,"Software logs play a vital role in ensuring the reliability and availability of large-scale software systems. In recent years, researchers have made significant efforts to build log analysis approaches to manage software systems. However, these approaches focus on log compression, log parsing and log anomaly detection. In the current context, engineers continue to spend substantial time and effort on resolving errors once anomalous logs have been detected. To achieve truly automated software system management and high-level Artificial Intelligence for IT Operations (AIOps), it's necessary to bridge the gap between anomalous logs and their resolutions.In this paper, we propose a novel framework LogExpert to automatically generate recommended resolutions for anomalous logs. Specifically, we build a log recognizer to utilize the wealth of software knowledge in technical forums such as Stack Overflow (SO). In addition, LogExpert combines the great power of a Large Language Model (LLM) with domain-specific knowledge to generate the resolution. We conducted a preliminary evaluation of our framework on datasets from SO. Our log recognizer achieves the F1 score of 0.936. Our lexical metrics and human evaluation show the overall LogExpert framework achieves excellent performance in log-based resolution generation.",Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results,42–46,5,"log-based resolution generation, log anomaly detection, large language models, Stack Overflow","Lisbon, Portugal",ICSE-NIER'24,inproceedings,,,,,,,,,,
"McGuire, Sean and Schultz, Erin and Ayoola, Bimpe and Ralph, Paul",Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering,2023,9781665457019,IEEE Press,,https://doi.org/10.1109/ICSE48619.2023.00169,10.1109/ICSE48619.2023.00169,Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or ,Proceedings of the 45th International Conference on Software Engineering,1996–2008,13,"sustainable development, software engineering, sustainable software engineering, scoping review, meta-synthesis","Melbourne, Victoria, Australia",ICSE '23,inproceedings,,,,,,,,,,
"Zhang, Mengmei and Sun, Mingwei and Wang, Peng and Fan, Shen and Mo, Yanhu and Xu, Xiaoxiao and Liu, Hong and Yang, Cheng and Shi, Chuan",GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks,2024,9798400701719,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589334.3645682,10.1145/3589334.3645682,"Large language models (LLMs) like ChatGPT, exhibit powerful zero-shot and instruction-following capabilities, have catalyzed a revolutionary transformation across diverse fields, especially for open-ended tasks. While the idea is less explored in the graph domain, despite the availability of numerous powerful graph models (GMs), they are restricted to tasks in a pre-defined form. Although several methods applying LLMs to graphs have been proposed, they fail to simultaneously handle the pre-defined and open-ended tasks, with LLM as a node feature enhancer or as a standalone predictor. To break this dilemma, we propose to bridge the pretrained GM and LLM by a Translator, named GraphTranslator, aiming to leverage GM to handle the pre-defined tasks effectively and utilize the extended interface of LLMs to offer various open-ended tasks for GM. To train such Translator, we propose a Producer capable of constructing the graph-text alignment data along node information, neighbor information and model information. By translating node representation into tokens, GraphTranslator empowers an LLM to make predictions based on language instructions, providing a unified perspective for both pre-defined and open-ended tasks. Extensive results demonstrate the effectiveness of our proposed GraphTranslator on zero-shot node classification. The graph question answering experiments reveal our GraphTranslator potential across a broad spectrum of open-ended tasks through language instructions. Our code is available at: https://github.com/alibaba/GraphTranslator",Proceedings of the ACM on Web Conference 2024,1003–1014,12,"graph neural network, large language model","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Goetze, Trystan S.","Integrating Ethics into Computer Science Education: Multi-, Inter-, and Transdisciplinary Approaches",2023,9781450394314,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3545945.3569792,10.1145/3545945.3569792,"While calls to integrate ethics into computer science education go back decades, recent high-profile ethical failures related to computing technology by large technology companies, governments, and academic institutions have accelerated the adoption of computer ethics education at all levels of instruction. Discussions of how to integrate ethics into existing computer science programmes often focus on the structure of the intervention---embedded modules or dedicated courses, humanists or computer scientists as ethics instructors---or on the specific content to be included---lists of case studies and essential topics to cover. While proponents of computer ethics education often emphasize the importance of closely connecting ethical and technical content in these initiatives, most do not reflect in depth on the variety of ways in which the disciplines can be combined. In this paper, I deploy a framework from cross-disciplinary studies that categorizes academic projects that work across disciplines as multidisciplinary, interdisciplinary, or transdisciplinary, depending on the degree of integration. When applied to computer ethics education, this framework is orthogonal to the structure and content of the initiative, as I illustrate using examples of dedicated ethics courses and embedded modules. It therefore highlights additional features of cross-disciplinary teaching that need to be considered when planning a computer ethics programme. I argue that computer ethics education should aim to be at least interdisciplinary-multidisciplinary initiatives are less aligned with the pedagogical aims of computer ethics-and that computer ethics educators should experiment with fully transdisciplinary education that could transform computer science as a whole for the better.",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,645–651,7,"cross-disciplinary studies, data justice, embedded ethics, ethics course, ethics education, higher education, interdisciplinary studies, interdisciplinary teaching and learning, responsible computing, transdisciplinary studies","Toronto ON, Canada",SIGCSE 2023,inproceedings,,,,,,,,,,
"Liu, Mengqi and M'Hiri, Faten",Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630789,10.1145/3626252.3630789,"As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,743–749,7,"adaptive teaching, chatgpt, cs education, gpt, llm, machine learning, novice programmers, openai, programming","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"MacNeil, Stephen and Tran, Andrew and Mogil, Dan and Bernstein, Seth and Ross, Erin and Huang, Ziheng",Generating Diverse Code Explanations using the GPT-3 Large Language Model,2022,9781450391955,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3501709.3544280,10.1145/3501709.3544280,"Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these approaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github's Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs' potential to support learning by explaining numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.",Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 2,37–39,3,"code explanations, computer science education, large language models, natural language processing","Lugano and Virtual Event, Switzerland",ICER '22,inproceedings,,,,,,,,,,
"Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth",AI-Tutoring in Software Engineering Education,2024,9798400704987,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639474.3640061,10.1145/3639474.3640061,"With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences.In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students' concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI's role in education.",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,309–319,11,"programming education, automated programming assessment systems, artificial intelligence, ChatGPT, OpenAI, ChatBots","Lisbon, Portugal",ICSE-SEET '24,inproceedings,,,,,,,,,,
,ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,9798400704987,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
,ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice,2024,9798400705014,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"Russo, Daniel",Navigating the Complexity of Generative AI Adoption in Software Engineering,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652154,10.1145/3652154,"This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.",,,50,"Generative AI, large language models, technology adaption, empirical software engineering",,,article,135,June 2024,33,5,ACM Trans. Softw. Eng. Methodol.,jun,1049-331X,,,
"Kumar, Amruth N. and Raj, Rajendra K. and Aly, Sherif G. and Anderson, Monica D. and Becker, Brett A. and Blumenthal, Richard L. and Eaton, Eric and Epstein, Susan L. and Goldweber, Michael and Jalote, Pankaj and Lea, Douglas and Oudshoorn, Michael and Pias, Marcelo and Reiser, Susan and Servin, Christian and Simha, Rahul and Winters, Titus and Xiang, Qiao",Computer Science Curricula 2023,2024,9798400710339,Association for Computing Machinery,"New York, NY, USA",,,,,,,,,,book,,,,,,,,,,
,ICSE-SEIS'24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Society,2024,9798400704994,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"Gao, Chen and Xu, Fengli and Chen, Xu and Wang, Xiang and He, Xiangnan and Li, Yong","Simulating Human Society with Large Language Model Agents: City, Social Media, and Economic System",2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3641253,10.1145/3589335.3641253,"This tutorial will delve into the fascinating realm of simulating human society using Large Language Model (LLM)-driven agents, exploring their applications in cities, social media, and economic systems. Through this tutorial, participants will gain insights into the integration of LLMs into human society simulation, providing a comprehensive understanding of how these models can accurately represent human interactions, decision-making processes, and societal dynamics from cities to social media and to economic systems. The tutorial will introduce the essential background, discuss the motivation and challenges, and elaborate on the recent advances.",Companion Proceedings of the ACM on Web Conference 2024,1290–1293,4,"agent-based modeling and simulation, large language model agents","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Coppola, Riccardo and Ardito, Luca and Leotta, Maurizio","Gamify: Gamification in Software Development, Verification,and Validation",2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3650142.3650151,10.1145/3650142.3650151,"In this paper we report the outcomes of the 1st and 2nd edition of the International Workshop on Gamification in Software Development, Verification, and Validation (Gamify 2022 and Gamify 2023) which were held as part of the 30th and 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2022, in Singapore, November 17, 2022 and ESEC/FSE 2023, online workshop, December 4, 2023).",,27–30,4,,,,article,,April 2024,49,2,SIGSOFT Softw. Eng. Notes,apr,0163-5948,,,
"Joshi, Ishika and Budhiraja, Ritvik and Dev, Harshal and Kadia, Jahnvi and Ataullah, Mohammad Osama and Mitra, Sayan and Akolekar, Harshal D. and Kumar, Dhruv",ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630803,10.1145/3626252.3630803,"This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,625–631,7,"chatgpt, computer science, education","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Gehringer, Edward F.",Electronic peer review and peer grading in computer-science courses,2001,1581133294,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/364447.364564,10.1145/364447.364564,"We have implemented a peer-grading system for review of student assignments over the World-Wide Web and used it in approximately eight computer-science courses. Students prepare their assignments and submit them to our Peer Grader (PG) system. Other students are then assigned to review and grade the assignments. The system allows authors and reviewers to communicate with authors being able to update their submissions. Unique features of our approach include the ability to submit arbitrary sets of Web pages for review, and mechanisms for encouraging careful review of submissions. We have used the system to produce high-quality compilations of student work. Our assignment cycle consists of six phases, from signing up for an assignment to Web publishing of the final result. Based upon our experience with PG, we offer suggestions for improving the system to make it more easily usable by students at all levels.",Proceedings of the Thirty-Second SIGCSE Technical Symposium on Computer Science Education,139–143,5,,"Charlotte, North Carolina, USA",SIGCSE '01,inproceedings,,,,,,,,,,
"Smith, David H. and Zilles, Craig",Evaluating Large Language Model Code Generation as an Autograding Mechanism for ,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635542,10.1145/3626253.3635542,"The ability of students to ''Explain in Plain English'' (EiPE) the purpose of code is a critical skill for students in introductory programming courses to develop. EiPE questions serve as both a mechanism for students to develop and demonstrate code comprehension skills. However, evaluating this skill has been challenging as manual grading is time consuming and not easily automated. The process of constructing a prompt for the purposes of code generation for a Large Language Model, such OpenAI's GPT-4, bears a striking resemblance to constructing EiPE responses. In this paper, we explore the potential of using test cases run on code generated by GPT-4 from students' EiPE responses as a grading mechanism for EiPE questions. We applied this proposed grading method to a corpus of EiPE responses collected from past exams, then measured agreement between the results of this grading method and human graders. Overall, we find moderate agreement between the human raters and the results of the unit tests run on the generated code. This appears to be attributable to GPT-4's code generation being more lenient than human graders on low-level descriptions of code.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1824–1825,2,"autograding, eipe, gpt-4, large language models","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
,ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2023,9798400703270,Association for Computing Machinery,"New York, NY, USA",,,"We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.",,,,,"San Francisco, CA, USA",,proceedings,,,,,,,,,,
"Cheng, Alan Y. and Tanimura, Ellie and Tey, Joseph and Wu, Andrew C. and Brunskill, Emma","Brief, Just-in-Time Teaching Tips to Support Computer Science Tutors",2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630794,10.1145/3626252.3630794,"As enrollments in computing-related programs continue to rise, computer science departments are increasingly relying on teaching assistants (TAs) to provide additional educational support to students, such as one-on-one tutoring or office hours. Tutoring is more effective with highly trained tutors, but most TAs receive little to no training in pedagogical skills. How might we provide support to TAs working with students one-on-one, especially in online settings? We propose a just-in-time intervention that shows a tutor actionable teaching tips and relevant information right before they begin an online tutoring session with a student. We conducted a crossover experiment (n = 46) where participants engaged in two tutoring roleplays for an introductory computer science programming task and found that participants demonstrated effective instructional strategies for much longer periods of time after receiving the intervention. We discuss the implications of these findings for both educators looking to support tutors and researchers seeking to build technology for tutors.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,200–206,7,"online tutoring teacher training, remote tutoring, ta training, tutoring","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
,ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2022,9781450394130,Association for Computing Machinery,"New York, NY, USA",,,"On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.",,,,,"Singapore, Singapore",,proceedings,,,,,,,,,,
"Maninger, Daniel and Narasimhan, Krishna and Mezini, Mira",Towards Trustworthy AI Software Development Assistance,2024,9798400705007,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639476.3639770,10.1145/3639476.3639770,"It is expected that in the near future, AI software development assistants will play an important role in the software industry. However, current software development assistants tend to be unreliable, often producing incorrect, unsafe, or low-quality code. We seek to resolve these issues by introducing a holistic architecture for constructing, training, and using trustworthy AI software development assistants. In the center of the architecture, there is a foundational LLM trained on datasets representative of real-world coding scenarios and complex software architectures, and fine-tuned on code quality criteria beyond correctness. The LLM will make use of graph-based code representations for advanced semantic comprehension. We envision a knowledge graph integrated into the system to provide up-to-date background knowledge and to enable the assistant to provide appropriate explanations. Finally, a modular framework for constrained decoding will ensure that certain guarantees (e.g., for correctness and security) hold for the generated code.",Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results,112–116,5,,"Lisbon, Portugal",ICSE-NIER'24,inproceedings,,,,,,,,,,
"Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul",Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636249,10.1145/3636243.3636249,"Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.",Proceedings of the 26th Australasian Computing Education Conference,49–57,9,"Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
"Wang, Ben and Liu, Jiqun and Karimnazarov, Jamshed and Thompson, Nicolas",Task Supportive and Personalized Human-Large Language Model Interaction: A User Study,2024,9798400704345,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627508.3638344,10.1145/3627508.3638344,"Large language model (LLM) applications, such as ChatGPT, are a powerful tool for online information-seeking (IS) and problem-solving tasks. However, users still face challenges initializing and refining prompts, and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions, including perception articulation, prompt suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine prompts, and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users.",Proceedings of the 2024 Conference on Human Information Interaction and Retrieval,370–375,6,"ChatGPT, Human-LLM Interaction, Information Seeking, Proactive System, Prompt Engineering","Sheffield, United Kingdom",CHIIR '24,inproceedings,,,,,,,,,,
,ACSW '24: Proceedings of the 2024 Australasian Computer Science Week,2024,9798400717307,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
"Cao, Chen",Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System,2023,9798400701078,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3581754.3584111,10.1145/3581754.3584111,"Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students’ sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students’ learning needs and provides scaffolding to support their success in introductory computer programming courses. My research includes three studies: a formative study, a user study of an initial prototype, and a computer simulation study with a user study in progress. Both qualitative and quantitative data were collected through surveys, observations, focus group discussions and computer simulation. The preliminary findings suggest that GPT-3-enhanced gamification has great potential in scaffolding introductory programming learning by providing adaptive and personalised feedback, increasing students’ sense of belonging, and reducing their anxiety about learning programming.",Companion Proceedings of the 28th International Conference on Intelligent User Interfaces,229–232,4,,"Sydney, NSW, Australia",IUI '23 Companion,inproceedings,,,,,,,,,,
,ICSE '23: Proceedings of the 45th International Conference on Software Engineering,2023,9781665457019,IEEE Press,,,,"ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.",,,,,"Melbourne, Victoria, Australia",,proceedings,,,,,,,,,,
"Cutts, Quintin and Kallia, Maria and Anderson, Ruth and Crick, Tom and Devlin, Marie and Farghally, Mohammed and Mirolo, Claudio and Runde, Ragnhild Kobro and Sepp\",Arguments for and Approaches to Computing Education in Undergraduate Computer Science Programmes,2023,9798400704055,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3623762.3633494,10.1145/3623762.3633494,"Computing education (CE), the scientific foundation of the teaching and learning of subject matter specific to computing, has matured into a field with its own research journals and conferences as well as graduate programmes. Yet, and unlike other mature subfields of computer science (CS), it is rarely taught as part of undergraduate CS programmes. In this report, we present a gap analysis resulting from semi-structured interviews with various types of stakeholders and derive a set of arguments for teaching CE courses in undergraduate CS programmes. This analysis and the arguments highlight a number of opportunities for the discipline of CS at large, in academia, in industry, and in school education, that would be opened up with undergraduate CE courses, as well as potential barriers to implementation that will need to be overcome. We also report on the results of a Delphi process performed to elicit topics for such a course with various audiences in mind. The Delphi process yielded 19 high-level categories that encompass the subject matter CE courses should incorporate, tailored to the specific needs of their intended student audiences. This outcome underscores the extensive range of content that can be integrated into a comprehensive CE programme. Based on these two stakeholder interactions as well as a systematic literature review aiming to explore the current practices in teaching CE to undergraduate students, we develop two prototypical outlines of such a course, keeping in mind that departments may have different preferences and affordances resulting in different kinds of CE offerings. Overall, input from external stakeholders underscores the clear significance of undergraduate CE courses. We anticipate leveraging this valuable feedback to actively promote these courses on a broader scale.",Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education,160–195,36,"argument, computing education, curriculum outline, undergraduate","Turku, Finland",ITiCSE-WGR '23,inproceedings,,,,,,,,,,
"Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.",Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630938,10.1145/3626252.3630938,"In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had ",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,750–756,7,"ai, artificial intelligence, generative ai, large language models, llms","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Huang, Ziheng and Quan, Kexin and Chan, Joel and MacNeil, Stephen",CausalMapper: Challenging designers to think in systems with Causal Maps and Large Language Model,2023,9798400701801,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3591196.3596818,10.1145/3591196.3596818,"Professional designers often construct and explore conceptual representations (e.g.: design spaces) to help them reason about complex design situations and consider potential design pitfalls. However, it is often challenging, even for professional designers, to exhaustively consider the many pitfalls that might result from design activity. We present CausalMapper, a mixed-initiative system, that leverages a large language model (LLM) and a causal map representation to teach design students how to reason about the relationships between problems and solutions. Where creativity support tools often focus on ideating creative solutions, our mixed-initiative approach focuses on ideating ecosystems of solutions that holistically address a set of related problems. By leveraging the generative creativity of LLMs, designers are inspired to consider solutions and potential consequences that emerge when solutions are adopted. At the same time, leveraging the designers’ domain knowledge to account for and correct the biases inherent in LLMs. Through a case study, we demonstrate the functionality of this mixed-initiative system. The goal of this demo is to present a creativity support tool that is intended to teach design students to think more systematically by generating ideas that challenge their thinking rather just augmenting their creative potential.",Proceedings of the 15th Conference on Creativity and Cognition,325–329,5,"creativity support tools, design space, large language models","Virtual Event, USA",C&amp;C '23,inproceedings,,,,,,,,,,
,SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is ",,,,,"Portland, OR, USA",,proceedings,,,,,,,,,,
,SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is ",,,,,"Portland, OR, USA",,proceedings,,,,,,,,,,
"Bhalerao, Rasika",My Learnings from Allowing Large Language Models in Introductory Computer Science Classes,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635511,10.1145/3626253.3635511,"Many instructors want to allow their students to use large language models (LLMs) in their introductory computer science courses, but they first want to see other instructors' results from doing so before taking on the risk in their own courses. Presented here are the results from allowing students to use LLMs in the second course in a sequence of intensive introductory courses designed to prepare students with a non-computational background for entry into a masters' degree program. We allowed students to use the internet and LLMs (such as ChatGPT or Github Copilot) to help with assignments, with guidelines to avoid plagiarism and encourage learning. We then surveyed students to ask about how they used LLMs, whether they saw others cheating, how they generally used internet-based resources on assignments and exams, and their feedback on the policies. We found that students are overwhelmingly using LLMs (and the internet generally) to learn and code ",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1574–1575,2,"AI, assignments, plagiarism, students","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Khanshan, Alireza and Van Gorp, Pieter and Markopoulos, Panos",Evaluation of Code Generation for Simulating Participant Behavior in Experience Sampling Method by Iterative In-Context Learning of a Large Language Model,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3661143,10.1145/3661143,"The Experience Sampling Method (ESM) is commonly used to understand behaviors, thoughts, and feelings in the wild by collecting self-reports. Sustaining sufficient response rates, especially in long-running studies remains challenging. To avoid low response rates and dropouts, experimenters rely on their experience, proposed methodologies from earlier studies, trial and error, or the scarcely available participant behavior data from previous ESM protocols. This approach often fails in finding the acceptable study parameters, resulting in redesigning the protocol and repeating the experiment. Research has shown the potential of machine learning to personalize ESM protocols such that ESM prompts are delivered at opportune moments, leading to higher response rates. The corresponding training process is hindered due to the scarcity of open data in the ESM domain, causing a cold start, which could be mitigated by simulating participant behavior. Such simulations provide training data and insights for the experimenters to update their study design choices. Creating this simulation requires behavioral science, psychology, and programming expertise. Large language models (LLMs) have emerged as facilitators for information inquiry and programming, albeit random and occasionally unreliable. We aspire to assess the readiness of LLMs in an ESM use case. We conducted research using GPT-3.5 turbo-16k to tackle an ESM simulation problem. We explored several prompt design alternatives to generate ESM simulation programs, evaluated the output code in terms of semantics and syntax, and interviewed ESM practitioners. We found that engineering LLM-enabled ESM simulations have the potential to facilitate data generation, but they perpetuate trust and reliability challenges.",,,19,"Behavior Simulation, Experience Sampling Method, Large Language Model, Prompt Engineering",,,article,255,June 2024,8,EICS,Proc. ACM Hum.-Comput. Interact.,jun,,,,
,ECSEE '23: Proceedings of the 5th European Conference on Software Engineering Education,2023,9781450399562,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Seeon/Bavaria, Germany",,proceedings,,,,,,,,,,
,ITiCSE-WGR '23: Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education,2023,9798400704055,Association for Computing Machinery,"New York, NY, USA",,,"In these proceedings, we present papers from the Working Groups that worked in the context of the 28th Annual Conference on Innovation &amp; Technology in Computer Science Education (ITiCSE), held in Turku Finland, and hosted by University of Turku from the 10th to the 12th of July 2023.The concept of Working Groups has been a unique feature of the ITiCSE conference series since its inception, with CompEd adopting the Working Group practice in 2019. A Working Group typically comprises 5 to 10 researchers who work together on a project related to computing education. Working Groups provide a wonderful opportunity to work intensively on a topic of interest with an international group of computing education researchers. This unique experience is one that, in our opinion, each Computer Science Educator should strive to participate in at least once.In 2023, 13 proposals for Working Groups were received and six Working Groups were selected by the Working Group chairs to recruit members and proceed for ITiCSE 2023. There were over 100 member applications to Working Groups, with 67 being accepted across the six Working Groups.",,,,,"Turku, Finland",,proceedings,,,,,,,,,,
,CSLAW '24: Proceedings of the Symposium on Computer Science and Law,2024,9798400703331,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Boston, MA, USA",,proceedings,,,,,,,,,,
"Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun",AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts,2022,9781450391573,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3491102.3517582,10.1145/3491102.3517582,"Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by “unit-testing” sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.",Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems,,22,"Human-AI Interaction, Large Language Models, Natural Language Processing","New Orleans, LA, USA",CHI '22,inproceedings,385,,,,,,,,,
"Pias, Marcelo and Cuadros-Vargas, Ernesto and Duran, Rodrigo",Computer Science Education in Latin America and the Caribbean,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3643646,10.1145/3643646,,,38–47,10,,,,article,,March 2024,15,1,ACM Inroads,feb,2153-2184,,,
,ICSE '23: Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings,2023,9798350322637,IEEE Press,,,,"ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.",,,,,"Melbourne, Victoria, Australia",,proceedings,,,,,,,,,,
"Sun, Yuqian and Li, Xingyu and Peng, Jun and Gao, Ze",Inspire creativity with ORIBA: Transform Artists' Original Characters into Chatbots through Large Language Model,2023,9798400702006,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3594739.3610695,10.1145/3594739.3610695,"This research delves into the intersection of illustration art and artificial intelligence (AI), focusing on how illustrators engage with AI agents that embody their original characters (OCs). We introduce ’ORIBA’, a customizable AI chatbot that enables illustrators to converse with their OCs. This approach allows artists to not only receive responses from their OCs but also to observe their inner monologues and behavior. Despite the existing tension between artists and AI, our study explores innovative collaboration methods that are inspiring to illustrators. By examining the impact of AI on the creative process and the boundaries of authorship, we aim to enhance human-AI interactions in creative fields, with potential applications extending beyond illustration to interactive storytelling and more.",Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing &amp; the 2023 ACM International Symposium on Wearable Computing,78–82,5,"creative support, drawing assistants, humanAI collaboration, interactive AI literacy, interactive language models","Cancun, Quintana Roo, Mexico",UbiComp/ISWC '23 Adjunct,inproceedings,,,,,,,,,,
,ISEC '24: Proceedings of the 17th Innovations in Software Engineering Conference,2024,9798400717673,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bangalore, India",,proceedings,,,,,,,,,,
"Jabbarvand, Reyhaneh and Tizpaz-Niari, Saeid and Barr, Earl T. and Chandra, Satish",Summary of the 1st Interpretability and Robustness in Neural Software Engineering (InteNSE 2023),2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3635439.3635446,10.1145/3635439.3635446,"InteNSE is an interdisciplinary workshop for research at the intersection of Machine Learning (ML) and Software Engineering (SE) and would be a pioneer in emphasizing the implicit properties of neural software engineering and analysis. Due to recent computational advancements, ML has become an inseparable part of the SE research community. ML can indeed improve and revolutionize many SE tasks. However, most research in the AI and SE communities consider ML as a closed box, i.e., only considering the final performance of the developed models as an evaluation metric. Ignoring the implicit properties of neural models, such as interpretability and robustness, one cannot validate the model's actual performance, generalizability, and whether it is learning what it is supposed to do. Specifically, in the domain of SE, where the result of ML4SE tools is code synthesis, bug finding, or repair, interpretability and robustness are crucial to ensure the reliability of the products.",,30–33,4,,,,article,,January 2024,49,1,SIGSOFT Softw. Eng. Notes,dec,0163-5948,,,
,SBES '23: Proceedings of the XXXVII Brazilian Symposium on Software Engineering,2023,9798400707872,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Campo Grande, Brazil",,proceedings,,,,,,,,,,
,ISEC '23: Proceedings of the 16th Innovations in Software Engineering Conference,2023,9798400700644,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Allahabad, India",,proceedings,,,,,,,,,,
"Li, Ruizhe and Guo, Jiahao and Li, Mingxi and Wu, Zhengqian and Liang, Chao",A Hierarchical Deep Video Understanding Method with Shot-Based Instance Search and Large Language Model,2023,9798400701085,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3581783.3612838,10.1145/3581783.3612838,"Deep video understanding (DVU) is often considered a challenge due to the aim of interpreting a video with storyline, which is designed to solve two levels of problems: predicting the human interaction in scene-level and identifying the relationship between two entities in movie-level. Based on our understanding of the movie characteristics and analysis of DVU tasks, in this paper, we propose a four-stage method to solve the task, which includes video structuring, shot based instance search, interaction &amp; relation prediction and shot-scene summary &amp; Question Answering (QA) with ChatGPT. In these four stages, shot based instance search allows accurate identification and tracking of characters at an appropriate video granularity. Using ChatGPT in QA, on the one hand, can narrow the answer space, on the other hand, with the help of the powerful text understanding ability, ChatGPT can help us answer the questions by giving background knowledge. We rank first in movie-level group 2 and scene-level group 1, second in movie-level group 1 and scene-level group 2 in ACM MM 2023 Grand Challenge.",Proceedings of the 31st ACM International Conference on Multimedia,9425–9429,5,"instance search, multi-modal feature, vedio understanding","Ottawa ON, Canada",MM '23,inproceedings,,,,,,,,,,
"Cai, Zhenyao and Park, Seehee and Nixon, Nia and Doroudi, Shayan",Advancing Knowledge Together: Integrating Large Language Model-based Conversational AI in Small Group Collaborative Learning,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650868,10.1145/3613905.3650868,"In today’s educational landscape, students learn collaboratively, where students benefit from both peer interactions and facilitator guidance. Prior research in Human-Computer Interaction (HCI) and Computer-Supported Collaborative Learning (CSCL) has explored chatbots and AI techniques to aid such collaboration. However, these methods often depend on predefined dialogues (which limits adaptability), are not based on collaborative learning theories, and do not fully recognize the learning context. In this paper, we introduce an Large Language Model (LLM)-powered conversational AI, designed to enhance small group learning through its advanced language understanding and generation capabilities. We detail the iterative design process, final design, and implementation. Our preliminary evaluation indicates that the bot performs as designed but points to considerations in the timing of interventions and bot’s role in discussions. The evaluation also reveals that learners perceive the bot’s tone and behavior as important for engagement. We discuss design implications for chatbot integration in collaborative learning and future research directions.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,9,"AI facilitator, Collaborative Learning, Human-AI Collaboration","
",CHI EA '24,inproceedings,37,,,,,,,,,
,Evaluating ChatGPT-4 Vision on Brazil’s National Undergraduate Computer Science Exam,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3674149,10.1145/3674149,"The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI’s most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil’s 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam’s open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model’s reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. A positive correlation between the model’s performance in multiple-choice questions and the performance distribution of the human participants suggests multimodal LLMs can provide a useful tool for question testing and refinement. However, the involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model’s accuracy and ensuring the fairness of high-stakes educational exams. The paper’s research materials are publicly available at .",,,,"Multimodal Generative AI, ChatGPT-4 Vision, Educational Assessment, Computer Science Education",,,article,,,,,ACM Trans. Comput. Educ.,jun,,Just Accepted,,
"Shein, Esther",The Impact of AI on Computer Science Education,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3673428,10.1145/3673428,Understanding why “working hard and struggling is … an important way of learning.”,,,4,,,,article,,,,,Commun. ACM,jun,0001-0782,Online First,,
"Tucker, Allen",A Model Curriculum for K--12 Computer Science: Final Report of the ACM K--12 Task Force Curriculum Committee,2003,1581138377,Association for Computing Machinery,"New York, NY, USA",,,,,,,,,,techreport,,,,,,,,,,
"Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos",Impacts of the Usage of Generative Artificial Intelligence on Software Development Process,2024,9798400709968,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3658271.3658337,10.1145/3658271.3658337,"Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.",Proceedings of the 20th Brazilian Symposium on Information Systems,,9,"ChatGPT, Copilot, Generative AI, Software Engineering, Software Process","Juiz de Fora, Brazil",SBSI '24,inproceedings,65,,,,,,,,,
,"Gamify 2023: Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation",2023,9798400703737,Association for Computing Machinery,"New York, NY, USA",,,"On behalf of the Program Committee, we are pleased to present the proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation (Gamify 2023). The workshop is virtually co-located with the 2023 edition of the ESEC/FSE conference, held in San Francisco (CA, USA). The workshop will be held online only the 4th of December 2023.",,,,,"San Francisco, CA, USA",,proceedings,,,,,,,,,,
"Goddard, Quinn and Moton, Nathan and Hudson, Jonathan and He, Helen Ai",A Chatbot Won't Judge Me: An Exploratory Study of Self-disclosing Chatbots in Introductory Computer Science Classes,2024,9798400709975,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3660650.3660662,10.1145/3660650.3660662,"Students in introductory Computer Science (CS) courses sometimes struggle with learning course content, but feel these struggles are uniquely theirs. To foster a more inclusive CS culture and normalize challenges in the learning process, we designed a conversational agent (“chatbot”) that self-discloses information about the chatbot’s own imaginary struggles with learning course material. Inspired by previous work in the mental health domain where humans reciprocated disclosure when a chatbot disclosed sensitive information, our goal was to promote student self-disclosure of learning challenges and to help students feel less alone. To inform design, we first conducted three focus groups with CS students on themes of identity and belonging. Based on these findings, we designed a self-disclosing chatbot (“Mibi”) and deployed it in a pilot summer course (40 students) and a larger course (460 students) in the fall semester of 2023. Our work is the first real-world deployment of a chatbot in higher education for promoting student wellbeing, rather than assisting with practical course content. We highlight findings from this exploratory study, sharing how students engaged with Mibi, where it succeeded, where it has room to grow, and how that can inform future iterations of this promising new classroom companion for student mental health.",Proceedings of the 26th Western Canadian Conference on Computing Education,,7,"CS1/CS2, Chatbot, Computer Science, Mental well-being, Qualitative, Self-Disclosure","Kelowna, BC, Canada",WCCCE '24,inproceedings,9,,,,,,,,,
,ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings,2024,9798400705021,Association for Computing Machinery,"New York, NY, USA",,,"ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.",,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
,WSSE '23: Proceedings of the 2023 5th World Symposium on Software Engineering,2023,9798400708053,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Tokyo, Japan",,proceedings,,,,,,,,,,
,ICSE-NIER '23: Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results,2023,9798350300390,IEEE Press,,,,"ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.",,,,,"Melbourne, Australia",,proceedings,,,,,,,,,,
,ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,2024,9798400702174,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"Cuadra, Andrea and Breuch, Justine and Estrada, Samantha and Ihim, David and Hung, Isabelle and Askaryar, Derek and Hassanien, Marwan and Fessele, Kristen L. and Landay, James A.",Digital Forms for All: A Holistic Multimodal Large Language Model Agent for Health Data Entry,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3659624,10.1145/3659624,"Digital forms help us access services and opportunities, but they are not equally accessible to everyone, such as older adults or those with sensory impairments. Large language models (LLMs) and multimodal interfaces offer a unique opportunity to increase form accessibility. Informed by prior literature and needfinding, we built a holistic multimodal LLM agent for health data entry. We describe the process of designing and building our system, and the results of a study with older adults (N =10). All participants, regardless of age or disability status, were able to complete a standard 47-question form independently using our system---one blind participant said it was ",,,39,"Accessibility, Artifact or System, Field Study, Health - Clinical, Input Techniques, Interaction Design, Mobile Devices: Phones/Tablets, Older Adults, Prototyping/Implementation, Qualitative Methods, Text/Speech/Language, User Experience Design",,,article,72,May 2024,8,2,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,may,,,,
"Kumar, Harsh and Yu, Kunzhi and Chung, Andrew and Shi, Jiakai and Williams, Joseph Jay",Exploring The Potential of Chatbots to Provide Mental Well-being Support for Computer Science Students,2023,9781450394338,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3545947.3576285,10.1145/3545947.3576285,"Computer Science students are affected by a number of stressors, such as competition, which make it difficult for them to manage their mental well-being and mood. Students are often reluctant to use existing resources for support because they are difficult to access or perceived as ineffective. Conversational agents have shown potential to provide accessible and effective support to improve well-being. In this work, we explore the problem space to identify contexts in which chatbots could be beneficial for students and investigate how different types of chatbot could supplement existing resources provided by universities.",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2,1339,1,"chatbots, field study, gpt-3, large language models, mental well-being, stress","Toronto ON, Canada",SIGCSE 2023,inproceedings,,,,,,,,,,
,ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering,2022,9781450394758,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rochester, MI, USA",,proceedings,,,,,,,,,,
"Qureshi, Basit",ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings,2023,9798400700415,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613944.3613946,10.1145/3613944.3613946,"The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility, and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore-level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to textbooks and notes of programming courses, however, no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using Programming Contest Control (PC2) environment which is widely used in ACM International Collegiate Programming Contest (ICPC). Each team of students addresses the problem by writing executable code that satisfies a certain number of test cases. Student teams were scored based on their performance in terms of the number of successfully passed test cases. Results show that students using ChatGPT had an advantage in terms of earned scores, however, there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper’s findings indicate that incorporating AI in higher education brings about various opportunities and challenges. Nonetheless, universities can efficiently manage these apprehensions by adopting a proactive and ethical stance toward the implementation of such tools.","Proceedings of the 2023 9th International Conference on E-Society, e-Learning and e-Technologies",7–13,7,"Academic assessment, ChatGPT, Data Structures and Algorithms, programming concepts","Portsmouth, United Kingdom",ICSLT '23,inproceedings,,,,,,,,,,
,CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI,2024,9798400705915,Association for Computing Machinery,"New York, NY, USA",,,"The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.",,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
,EASE '24: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,2024,9798400717017,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Salerno, Italy",,proceedings,,,,,,,,,,
"Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv","“It's not like Jarvis, but it's pretty close!” - Examining ChatGPT's Usage among Undergraduate Students in Computer Science",2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636257,10.1145/3636243.3636257,"Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education.",Proceedings of the 26th Australasian Computing Education Conference,124–133,10,"ChatGPT, Computer Science Education, User Study","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
,FORGE '24: Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering,2024,9798400706097,Association for Computing Machinery,"New York, NY, USA",,,"FORGE aims to bring researchers, practitioners, and educators from the AI and Software Engineering community to solve the new challenges we meet in the era of foundation models.",,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
,CSAI '23: Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence,2023,9798400708688,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Beijing, China",,proceedings,,,,,,,,,,
,ASSE '23: Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference,2023,9798400708534,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Aizu-Wakamatsu City, Japan",,proceedings,,,,,,,,,,
,ICSIM '24: Proceedings of the 2024 7th International Conference on Software Engineering and Information Management,2024,9798400709197,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Suva, Fiji",,proceedings,,,,,,,,,,
,ICAICE '23: Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering,2023,9798400708831,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Dalian, China",,proceedings,,,,,,,,,,
,EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering,2023,9798400700446,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Oulu, Finland",,proceedings,,,,,,,,,,
"Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel",Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3633287,10.1145/3633287,"Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.",,,32,"ChatGPT, generative AI, cheating, quality assurance, university assessment’",,,article,5,March 2024,24,1,ACM Trans. Comput. Educ.,jan,,,,
,KUI '23: Proceedings of the 20th International Conference on Culture and Computer Science: Code and Materiality,2023,9798400708367,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
,CHASE '24: Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering,2024,9798400705335,Association for Computing Machinery,"New York, NY, USA",,,"CHASE 2024 continues the tradition of a high-quality venue for research related to the cooperative and human aspects of software engineering. Researchers and practitioners have long recognized the need to investigate the cooperative and human aspects. However, their articles have been scattered across many conferences and communities. The CHASE conference provides academics and practitioners with a unified forum for discussing high-quality research studies, models, methods, and tools for human and cooperative aspects of software engineering.",,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"MacNeil, Stephen and Tran, Andrew and Hellas, Arto and Kim, Joanne and Sarsa, Sami and Denny, Paul and Bernstein, Seth and Leinonen, Juho",Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book,2023,9781450394314,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3545945.3569785,10.1145/3545945.3569785,"Advances in natural language processing have resulted in large language models (LLMs) that can generate code and code explanations. In this paper, we report on our experiences generating multiple code explanation types using LLMs and integrating them into an interactive e-book on web software development. Three different types of explanations -- a line-by-line explanation, a list of important concepts, and a high-level summary of the code -- were created. Students could view explanations by clicking a button next to code snippets, which showed the explanation and asked about its utility. Our results show that all explanation types were viewed by students and that the majority of students perceived the code explanations as helpful to them. However, student engagement varied by code snippet complexity, explanation type, and code snippet length. Drawing on our experiences, we discuss future directions for integrating explanations generated by LLMs into CS classrooms.",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,931–937,7,,"Toronto ON, Canada",SIGCSE 2023,inproceedings,,,,,,,,,,
"Tran, Minh",Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects,2023,9781450399753,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3568812.3603453,10.1145/3568812.3603453,"The power of large language models has opened up opportunities for educational use. In computing education, recent studies have demonstrated the potential of these models to improve learning and teaching experiences in university-level programming courses. However, research into leveraging them to aid computer science instructors in curriculum development and course material design is relatively sparse, especially at the K-12 level. This work aims to fill this gap by exploring the capability of large language models in ideating and designing culturally responsive projects for elementary and middle school programming classes. Our ultimate goal is to support K-8 teachers in effectively extracting suggestions from large language models by only using natural language modifications. Furthermore, we aim to develop a comprehensive assessment framework for culturally responsive AI-generated project ideas. We also hope to provide valuable insight into teachers’ perspectives on large language models and their integration into teaching practices.",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,110–112,3,"culturally responsive pedagogy, large language models","Chicago, IL, USA",ICER '23,inproceedings,,,,,,,,,,
,MOBILESoft '24: Proceedings of the IEEE/ACM 11th International Conference on Mobile Software Engineering and Systems,2024,9798400705946,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\",,2023,9798400708749,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3616961.3616974,10.1145/3616961.3616974,"Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.",Proceedings of the 26th International Academic Mindtrek Conference,83–94,12,"ChatGPT, artificial intelligence, chatbots, discussion forum, education, generative AI, student perceptions, tutoring","Tampere, Finland",Mindtrek '23,inproceedings,,,,,,,,,,
,EITCE '23: Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering,2023,9798400708305,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Xiamen, China",,proceedings,,,,,,,,,,
"Leiser, Florian and Eckhardt, Sven and Knaeble, Merlin and Maedche, Alexander and Schwabe, Gerhard and Sunyaev, Ali",From ChatGPT to FactGPT: A Participatory Design Study to Mitigate the Effects of Large Language Model Hallucinations on Users,2023,9798400707711,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3603555.3603565,10.1145/3603555.3603565,"Large language models (LLMs) like ChatGPT recently gained interest across all walks of life with their human-like quality in textual responses. Despite their success in research, healthcare, or education, LLMs frequently include incorrect information, called hallucinations, in their responses. These hallucinations could influence users to trust fake news or change their general beliefs. Therefore, we investigate mitigation strategies desired by users to enable identification of LLM hallucinations. To achieve this goal, we conduct a participatory design study where everyday users design interface features which are then assessed for their feasibility by machine learning (ML) experts. We find that many of the desired features are well-perceived by ML experts but are also considered as difficult to implement. Finally, we provide a list of desired features that should serve as a basis for mitigating the effect of LLM hallucinations on users.",Proceedings of Mensch Und Computer 2023,81–90,10,"Artificial Hallucinations, ChatGPT, Disney Method, Large Language Models, Participatory Design","Rapperswil, Switzerland",MuC '23,inproceedings,,,,,,,,,,
,SEAMS '24: Proceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems,2024,9798400705854,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, AA, Portugal",,proceedings,,,,,,,,,,
,ICSE-NIER'24: Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results,2024,9798400705007,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"Jo, Eunkyung and Jeong, Yuin and Park, Sohyun and Epstein, Daniel A. and Kim, Young-Ho",Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642420,10.1145/3613904.3642420,"Recent large language models (LLMs) offer the potential to support public health monitoring by facilitating health disclosure through open-ended conversations but rarely preserve the knowledge gained about individuals across repeated interactions. Augmenting LLMs with long-term memory (LTM) presents an opportunity to improve engagement and self-disclosure, but we lack an understanding of how LTM impacts people’s interaction with LLM-driven chatbots in public health interventions. We examine the case of CareCall—an LLM-driven voice chatbot with LTM—through the analysis of 1,252 call logs and interviews with nine users. We found that LTM enhanced health disclosure and fostered positive perceptions of the chatbot by offering familiarity. However, we also observed challenges in promoting self-disclosure through LTM, particularly around addressing chronic health conditions and privacy concerns. We discuss considerations for LTM integration in LLM-driven chatbots for public health monitoring, including carefully deciding what topics need to be remembered in light of public health goals.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,21,"Chatbot, Check-up calls, Large language models, Long-term memory, Open-domain dialog systems, Public health, Social isolation","Honolulu, HI, USA",CHI '24,inproceedings,440,,,,,,,,,
"Thool, Arpit and Brown, Chris",Securing Agile: Assessing the Impact of Security Activities on Agile Development,2024,9798400717017,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3661167.3661280,10.1145/3661167.3661280,"Software systems are expected to be secure and robust. To verify and ensure software security, it is vital to include security activities, or development practices to detect and prevent security vulnerabilities, into the software development process. Agile software development is a popular software engineering (SE) process used by many organizations and development teams. However, while Agile aims to be a lightweight and responsive process, security activities are typically more cumbersome and involve more documentation and tools–violating the core principles of Agile. This work investigates the impact of security activities on various aspects of Agile development. To understand how software engineers perceive incorporating security practices into Agile methodologies, we distributed an online survey to collect data from software practitioners with experience working in Agile teams. Our results from 34 survey participants show most software practitioners believe security activities are beneficial to development overall but lack confidence in their impact on the security of software systems. Our findings provide insight into how security activities affect Agile development and provide implications to help SE teams better incorporate security activities into implementing Agile development processes.",Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,668–678,11,"Agile, Security Activities, Software Engineering","Salerno, Italy",EASE '24,inproceedings,,,,,,,,,,
"Fernandez, Amanda S. and Cornell, Kimberly A.",CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630817,10.1145/3626252.3630817,"As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create ",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,345–351,7,"ai, artificial intelligence, code generation, copilot, cs1, gpt-4, introductory programming, large language model, llm, machine learning, novice programmers, programming, prompt engineering, secure code, software verification","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Dobslaw, Felix and Bergh, Peter",Experiences with Remote Examination Formats in Light of GPT-4,2023,9781450399562,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3593663.3593695,10.1145/3593663.3593695,"Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.",Proceedings of the 5th European Conference on Software Engineering Education,220–225,6,"ChatGPT, Examination Formats, Oral Examinations, Software Engineering Education","Seeon/Bavaria, Germany",ECSEE '23,inproceedings,,,,,,,,,,
"Fan, Aysa X. and Hendrawan, Rully A. and Shi, Yang and Ma, Qianou",Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635624,10.1145/3626253.3635624,"This study refines Large Language Models (LLMs) prompts to enhance the generation of code tracing questions, where the new expert-guided prompts consider features identified from prior research. Expert evaluations compared new LLM-generated questions against previously preferred ones, revealing improved quality in aspects like complexity and concept coverage. While providing insights into effective question generation and affirming LLMs' potential in educational content creation, the study also contributes an expert-evaluated question dataset to the computing education community. However, generating high-quality reverse tracing questions remains a nuanced challenge, indicating a need for further LLM prompting refinement.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1640–1641,2,"computer science education, large language model, programming education, tracing question","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Luo, Weilin and Fang, Weiyuan and Qiu, Junming and Wan, Hai and Liu, Yanan and Ye, Rongzhen",ITG: Trace Generation via Iterative Interaction between LLM Query and Trace Checking,2024,9798400705007,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639476.3639779,10.1145/3639476.3639779,"Due to the complexity of linear temporal logic (LTL) trace generation (PSPACE-Complete), existing neural network-based approaches will fail as the formula sizes increase. Recently, large language models (LLMs) have demonstrated remarkable reasoning capabilities, benefiting from efficient training on hyper-scale data. Inspired by this, we propose an iterative interaction framework for applying LLMs, exemplified by ChatGPT, to generate a trace satisfying a given LTL formula. The key insight behind it is to transfer the powerful reasoning capabilities of LLM to LTL trace generation via iterative interaction between LLM reasoning and logical reasoning. Preliminary results show that compared with the state-of-the-art approach, the accuracy is relatively improved by 9.7%-23.4%. Besides, we show that our framework is able to produce heuristics for new tasks, which provides a reference for other reasoning-heavy tasks requiring heuristics.",Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results,11–15,5,"large language model, linear temporal logic, satisfiability checking, trace generation, trace checking","Lisbon, Portugal",ICSE-NIER'24,inproceedings,,,,,,,,,,
"Han, Jiyeon and Park, Jimin and Huh, Jinyoung and Oh, Uran and Do, Jaeyoung and Kim, Daehee",AscleAI: A LLM-based Clinical Note Management System for Enhancing Clinician Productivity,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650784,10.1145/3613905.3650784,"While clinical notes are essential to the field of healthcare, they pose several challenges for clinicians since it is difficult to write down medical information, review prior notes, and extract the desired information at the same time while examining a patient. Thus, we designed a system that can automatically generate clinical notes from dialogues between patients and clinicians and provide specific information upon clinicians’ query using a Large Language Model (LLM) both in real-time. To explore how this system can be used to support clinicians in practice, we conducted an interview with six clinicians followed by a design probe study with the current version of our system for feedback. Findings suggest that our system has the potential to enable clinicians to write and access clinical notes and examine the patients simultaneously with reduced cognitive loads and increased efficiency and accuracy.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"Large language model, clinical note, design probe, interview","
",CHI EA '24,inproceedings,50,,,,,,,,,
"Becker, Brett A. and Denny, Paul and Finnie-Ansley, James and Luxton-Reilly, Andrew and Prather, James and Santos, Eddie Antonio",Programming Is Hard - Or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation,2023,9781450394314,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3545945.3569759,10.1145/3545945.3569759,"The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,500–506,7,"ai, alphacode, amazon, artificial intelligence, code generation, codewhisperer, codex, copilot, cs1, cs2, github, google, gpt-3, introductory programming, large language model, llm, machine learning, midjourney, novice programmers, openai, programming, tabnine","Toronto ON, Canada",SIGCSE 2023,inproceedings,,,,,,,,,,
"Liu, Zhe and Chen, Chunyang and Wang, Junjie and Chen, Mengzhuo and Wu, Boyu and Che, Xing and Wang, Dandan and Wang, Qing",Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions,2024,9798400702174,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3597503.3639180,10.1145/3597503.3639180,"Automated Graphical User Interface (GUI) testing plays a crucial role in ensuring app quality, especially as mobile applications have become an integral part of our daily lives. Despite the growing popularity of learning-based techniques in automated GUI testing due to their ability to generate human-like interactions, they still suffer from several limitations, such as low testing coverage, inadequate generalization capabilities, and heavy reliance on training data. Inspired by the success of Large Language Models (LLMs) like ChatGPT in natural language understanding and question answering, we formulate the mobile GUI testing problem as a Q&amp;A task. We propose GPTDroid, asking LLM to chat with the mobile apps by passing the GUI page information to LLM to elicit testing scripts, and executing them to keep passing the app feedback to LLM, iterating the whole process. Within this framework, we have also introduced a functionality-aware memory prompting mechanism that equips the LLM with the ability to retain testing knowledge of the whole process and conduct long-term, functionality-based reasoning to guide exploration. We evaluate it on 93 apps from Google Play and demonstrate that it outperforms the best baseline by 32% in activity coverage, and detects 31% more bugs at a faster rate. Moreover, GPTDroid identifies 53 new bugs on Google Play, of which 35 have been confirmed and fixed.",Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,,13,"automated GUI testing, large language model","Lisbon, Portugal",ICSE '24,inproceedings,100,,,,,,,,,
,Exploring the Role of ChatGPT in Education: Applications and Challenges,2023,9798400701306,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3585059.3611445,10.1145/3585059.3611445,"The development of ChatGPT as a sophisticated artificial intelligence technology has impacted numerous sectors, including education and research. The ChatGPT is a powerful large language model that allows students and educators to take advantage of many opportunities, such as personalized learning, lesson planning, and task reduction. While ChatGPT has the potential to streamline pedagogy and research, it poses a variety of challenges, such as allowing cheating on exams and homework, which puts students’ problem-solving skills at risk. Also, ChatGPT creates text that looks like human text, so cheating can be difficult to detect. In this paper, we explore the potential opportunities of ChatGPT in the education sector, as well as its limitations and challenges.",Proceedings of the 24th Annual Conference on Information Technology Education,84–89,6,"Artificial Intelligence, ChatGPT, Education, Large Language Model, OpenAI","Marietta, GA, USA",SIGITE '23,inproceedings,,,,,,,,,,
"Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita",Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630826,10.1145/3626252.3630826,"The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,526–532,7,"artificial intelligence, chatgpt, cheat detection, cs1, introductory programming course, large language model, plagiarism detection","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon",An Empirical Study on How Large Language Models Impact Software Testing Learning,2024,9798400717017,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3661167.3661273,10.1145/3661167.3661273,"Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.",Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,555–564,10,"ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant","Salerno, Italy",EASE '24,inproceedings,,,,,,,,,,
"Dugan, Robert F.",Performance lies my professor told me: the case for teaching Software Performance Engineering to undergraduates,2004,1581136730,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/974044.974050,10.1145/974044.974050,"In this paper we report a survey examining the approach to performance and software engineering in courses at highly ranked computer science schools in the United States. An analysis of the survey shows serious shortcomings including inadequate or missing definitions of performance, reactive ",Proceedings of the 4th International Workshop on Software and Performance,37–48,12,"education, performance, software engineering","Redwood Shores, California",WOSP '04,inproceedings,,,,,,,,,,
"Zhang, Chenyuan and Liu, Hao and Zeng, Jiutian and Yang, Kejing and Li, Yuhong and Li, Hui",Prompt-Enhanced Software Vulnerability Detection Using ChatGPT,2024,9798400705021,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639478.3643065,10.1145/3639478.3643065,"With the increase in software vulnerabilities that cause significant economic and social losses, automatic vulnerability detection has become essential in software development and maintenance. Recently, large language models (LLMs) have received considerable attention due to their stunning intelligence, and some studies consider using ChatGPT for vulnerability detection. However, they do not fully consider the characteristics of LLMs, since their designed questions to ChatGPT are simple without a prompt design tailored for vulnerability detection. This paper launches a study on the performance of software vulnerability detection using ChatGPT with different prompt designs. Firstly, we complement previous work by applying various improvements to the basic prompt. Moreover, we incorporate structural and sequential auxiliary information to improve the prompt design. Moreover, we leverage ChatGPT's ability of memorizing multi-round dialogue to design suitable prompts for vulnerability detection. We conduct extensive experiments on two vulnerability datasets to demonstrate the effectiveness of prompt-enhanced vulnerability detection using ChatGPT.",Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings,276–277,2,"software vulnerability detection, prompt engineering, large language model, chatgpt","Lisbon, Portugal",ICSE-Companion '24,inproceedings,,,,,,,,,,
"Esposito, Matteo and Palagiano, Francesco",Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study,2024,9798400717017,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3661167.3661226,10.1145/3661167.3661226,"Preliminary security risk analysis (PSRA) provides a quick approach to identify, evaluate, and propose remediation to potential risks in specific scenarios. The extensive expertise required for an effective PSRA and the substantial textual-related tasks hinders quick assessments in mission-critical contexts, where timely and prompt actions are essential. The speed and accuracy of human experts in PSRA significantly impact response time. A large language model can quickly summarise information in less time than a human. To our knowledge, no prior study has explored the capabilities of fine-tuned models (FTM) in PSRA. Our case study investigates the proficiency of FTM in assisting practitioners in PSRA. We manually curated 141 representative samples from over 50 mission-critical analyses archived by the industrial context team in the last five years. We compared the proficiency of the FTM versus seven human experts. Within the industrial context, our approach has proven successful in reducing errors in PSRA, hastening security risk detection, and minimizing false positives and negatives. This translates to cost savings for the company by averting unnecessary expenses associated with implementing unwarranted countermeasures. Therefore, experts can focus on more comprehensive risk analysis, leveraging LLMs for an effective preliminary assessment within a condensed timeframe.",Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,442–445,4,"Analysis, Fine-Tuning, Generative AI, Human Experts, LLM, Large Language Model, Management, Preliminary, Risk, Security, Standards","Salerno, Italy",EASE '24,inproceedings,,,,,,,,,,
"Denny, Paul and Becker, Brett A. and Leinonen, Juho and Prather, James",Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?,2023,9798400701382,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587102.3588773,10.1145/3587102.3588773,"Recent breakthroughs in deep learning have led to the emergence of generative AI models that exhibit extraordinary performance at producing human-like outputs. Using only simple input prompts, it is possible to generate novel text, images, video, music, and source code, as well as tackle tasks such as answering questions and translating and summarising text.However, the potential for these models to impact computing education practice is only just beginning to be explored. For example, novices learning to code can now use free tools that automatically suggest solutions to programming exercises and assignments; yet these tools were not designed with novices in mind and little to nothing is known about how they will impact learning. Furthermore, much attention has focused on the immediate challenges these models present, such as academic integrity concerns. It seems that even in the AI-era a pending apocalypse sells better than a promising renaissance.Generative AI will likely play an increasing role in people's lives in the reasonably foreseeable future. Model performance seems set to continue accelerating while novel uses and new possibilities multiply. Given this, we should devote just as much effort to identifying and exploiting new opportunities as we do to identifying and mitigating challenges.In this talk, we begin by discussing several concrete and research-backed opportunities for computing educators. Many of these have already shown great promise in positively impacting current practice. We then discuss more short- to medium-term possibilities in areas such as student recruitment, and curricular changes. Finally - against our better judgement - we speculate over the longer-term, including rethinking the very fundamentals of the practice of teaching introductory and advanced computing courses. In these discussions we suggest potential research questions and directions. Although making remotely accurate predictions in such a fast-changing landscape is foolhardy, we believe that now is the time to explore and embrace opportunities to help make positive change in as many computing classrooms as possible.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,3–4,2,"ai, artificial intelligence, chatgpt, computer programming, computer science education, computing education, copilot, deep learning, generative ai, large language models, llm, machine learning","Turku, Finland",ITiCSE 2023,inproceedings,,,,,,,,,,
"Bopp, Chris and Foerst, Anne and Kellogg, Brian",The Case for LLM Workshops,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630941,10.1145/3626252.3630941,"Large Language Models (LLMs) are radically changing the academic landscape. Many professors are unaware of how LLMs work and are therefore unsure how to incorporate them in their teaching. This is problematic as students will use them anyway. In this paper, we outline our institution as a case study for a curricular initiative. We develop an intellectual framework for creating workshops for faculty at small liberal arts universities. We base their development on the literature we have analyzed and discussed as a group. Our approach is to address our colleagues across a variety of different disciplines and teach them the responsible use of LLMs in the classroom. We also teach our colleagues how to modify assignments to make them, to some extent, LLM proof. This includes adding personalized elements, and including LLM designed parts explicitly, such as article summaries. We also design a syllabus policy about the responsible use of LLMs. We present philosophical and ethical challenges and teach a list of other actionable items. We ultimately support the use of LLMs in academia but seek to teach our colleagues how they can guide students to use them mindfully and responsibly.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,130–136,7,"ethics, large language models, liberal arts universities, pedagogy, philosophy, workshops","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Dong, Yihong and Jiang, Xue and Jin, Zhi and Li, Ge",Self-collaboration Code Generation via ChatGPT,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3672459,10.1145/3672459,"Although Large Language Models (LLMs) have demonstrated remarkable code-generation ability, they still struggle with complex tasks. In real-world software development, humans usually tackle complex tasks through collaborative teamwork, a strategy that significantly controls development complexity and enhances software quality. Inspired by this, we present a self-collaboration framework for code generation employing LLMs, exemplified by ChatGPT. Specifically, through role instructions, 1) Multiple LLM agents act as distinct ‘experts’, each responsible for a specific subtask within a complex task; 2) Specify the way to collaborate and interact, so that different roles form a virtual team to facilitate each other’s work, ultimately the virtual team addresses code generation tasks collaboratively without the need for human intervention. To effectively organize and manage this virtual team, we incorporate software-development methodology into the framework. Thus, we assemble an elementary team consisting of three LLM roles (i.e., analyst, coder, and tester) responsible for software development’s analysis, coding, and testing stages. We conduct comprehensive experiments on various code-generation benchmarks. Experimental results indicate that self-collaboration code generation relatively improves 29.9%-47.1% Pass@1 compared to the base LLM agent. Moreover, we showcase that self-collaboration could potentially enable LLMs to efficiently handle complex repository-level tasks that are not readily solved by the single LLM agent.",,,,"Code Generation, Large Language Models, Multi-Agent Collaboration, Software Development",,,article,,,,,ACM Trans. Softw. Eng. Methodol.,jun,1049-331X,Just Accepted,,
"Nguyen, Ha and Allan, Vicki","Using GPT-4 to Provide Tiered, Formative Code Feedback",2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630960,10.1145/3626252.3630960,"Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,958–964,7,"computer science education, feedback, large language models","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan",Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education,2024,9798400704987,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639474.3640068,10.1145/3639474.3640068,"Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct.In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,1–11,11,"software engineering education, AI-generated code, AI-generated code detection","Lisbon, Portugal",ICSE-SEET '24,inproceedings,,,,,,,,,,
"Huang, Qing and Luo, Zhiwen and Xing, Zhenchang and Zeng, Jinshan and Chen, Jieshan and Xu, Xiwei and Chen, Yong",Revealing the Unseen: AI Chain on LLMs for Predicting Implicit Data Flows to Generate Data Flow Graphs in Dynamically-Typed Code,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3672458,10.1145/3672458,"Data flow graphs (DFGs) capture definitions (defs) and uses across program blocks, which is a fundamental program representation for program analysis, testing and maintenance. However, dynamically-typed programming languages like Python present implicit data flow issues that make it challenging to determine def-use flow information at compile time. Static analysis methods like Soot and WALA are inadequate for handling these issues, and manually enumerating comprehensive heuristic rules is impractical. Large pre-trained language models (LLMs) offer a potential solution, as they have powerful language understanding and pattern matching abilities, allowing them to predict implicit data flow by analyzing code context and relationships between variables, functions, and statements in code. We propose leveraging LLMs’ in-context learning ability to learn implicit rules and patterns from code representation and contextual information to solve implicit data flow problems. To further enhance the accuracy of LLMs, we design a five-step Chain of Thought (CoT) and break it down into an AI chain, with each step corresponding to a separate AI unit to generate accurate DFGs for Python code. Our approach’s performance is thoroughly assessed, demonstrating the effectiveness of each AI unit in the AI Chain. Compared to static analysis, our method achieves 82% higher def coverage and 58% higher use coverage in DFG generation on implicit data flow. We also prove the indispensability of each unit in the AI Chain. Overall, our approach offers a promising direction for building software engineering tools by utilizing foundation models, eliminating significant engineering and maintenance effort, but focusing on identifying problems for AI to solve.",,,,"Data Flow Graph, AI Chain, Large Language Model",,,article,,,,,ACM Trans. Softw. Eng. Methodol.,jun,1049-331X,Just Accepted,,
"Garaccione, Giacomo and Coppola, Riccardo and Ardito, Luca",Gamifying Business Process Modeling Education: A Longitudinal Study,2024,9798400717017,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3661167.3661272,10.1145/3661167.3661272,"Gamification, the practice consisting of adapting game elements and features in non-recreational contexts to increase user motivation and interest, has become increasingly common in recent years in the different fields of Software Engineering such as development, requirements definition, testing, and education. Among the different educational fields to which gamification has been applied, process modeling is currently not much explored: there are few examples of game-like approaches used for teaching process modeling, and such examples have yet to be applied for the duration of an entire course to assess possible benefits. We thus describe the use of BIPMIN, a platform that implements elements regularly used in gamified tools such as levels, avatars, and leaderboards, in an Information Systems course, where students used the tool to perform practical BPMN modeling exercises over the whole duration of the course to get feedback on their modeling strategies. The students’ opinions have been gathered in the form of an end-of-course questionnaire and have been analyzed following the Straussian grounded theory approach to assess the general sentiment regarding usability, appreciation, and possible issues and improvement areas of the tool. The gathered results are encouraging, as they show that the tool has been well received and that its features that help student understanding the reasons behind their errors have been perceived as helpful for learning and improving BPMN modeling.",Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,580–589,10,"BPMN, Gamification, Process Modeling, Software Engineering Education, Software Modeling","Salerno, Italy",EASE '24,inproceedings,,,,,,,,,,
"Dou, Yutao and Huang, Yuwei and Zhao, Xiongjun and Zou, Haitao and Shang, Jiandong and Lu, Ying and Yang, Xiaolin and Xiao, Jian and Peng, Shaoliang",ShennongMGS: An LLM-based Chinese Medication Guidance System,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3658451,10.1145/3658451,"The rapidly evolving field of Large Language Models (LLMs) holds immense promise for healthcare, particularly in medication guidance and adverse drug reaction prediction. Despite their potential, existing LLMs face challenges in dealing with complex polypharmacy scenarios and often grapple with data lag issues. To address these limitations, we introduce an LLM-based Chinese medication guidance system, called ShennongMGS, specifically tailored for robust medication guidance and adverse drug reaction predictions. Our system transforms multi-source heterogeneous medication information into a knowledge graph and employs a two-stage training strategy to construct a specialised LLM (ShennongGPT). This method enables the simulation of professional pharmacists’ decision-making processes and incorporates the capability for knowledge self-updating, thereby significantly enhancing drug safety and the overall quality of medical services. Rigorously evaluated by medical professionals and artificial intelligence experts, our method demonstrates superiority, outperforming existing general and specialised LLMs in performance.",,,,"Large Language Model, Model Fine-tuning, Medication Guidance, Chinese Medical System, Natural Language Processing, Software System",,,article,,,,,ACM Trans. Manage. Inf. Syst.,apr,2158-656X,Just Accepted,,
"Tao, Yida and Chen, Wenyan and Ye, Qingyang and Zhao, Yao",Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments,2024,9798400704987,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639474.3640065,10.1145/3639474.3640065,"Practical programming assignments are critical parts of programming courses in Computer Science education. Students are expected to translate programming concepts learned from lectures into executable implementations that solve the tasks outlined in the assignments. These implementations are primarily assessed based on their functional correctness, ensuring that students' code produces the expected output when provided with specific inputs.However, functional correctness is not the only metric that evaluates the quality of programs. Runtime efficiency is a metric that is less frequently evaluated in programming courses, yet it holds significant importance in the context of professional software development. To investigate this gap and its potential ramifications, we conducted a large-scale empirical study on the time efficiency of 250 programming assignments that are evaluated solely on functional correctness. The results demonstrate that students' programming assignments exhibit significant variance in terms of execution time. We further identified 27 recurring inefficient code patterns from these assignments, and observed that most of the inefficient patterns can be optimized by automated tools such as PMD, IntelliJ IDEA and ChatGPT. Our findings provide actionable guidelines for educators to enhance the organization and integration of code performance topics throughout the programming course curriculum.",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,320–330,11,"programming assignment, code performance, tool support","Lisbon, Portugal",ICSE-SEET '24,inproceedings,,,,,,,,,,
"Nouri, Ali and Cabrero-Daniel, Beatriz and Torner, Fredrik and Sivencrona, Hakan and Berger, Christian",Welcome Your New AI Teammate: On Safety Analysis by Leashing Large Language Models,2024,9798400705915,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3644815.3644953,10.1145/3644815.3644953,"DevOps is a necessity in many industries, including the development of Autonomous Vehicles. In those settings, there are iterative activities that reduce the speed of SafetyOps cycles. One of these activities is ",Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI,172–177,6,"hazard analysis risk assessment, autonomous vehicles, DevOps, safety, large language model, prompt engineering, LLM, ChatGPT","Lisbon, Portugal",CAIN '24,inproceedings,,,,,,,,,,
"Zhu, Lixi and Huang, Xiaowen and Sang, Jitao",How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation,2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3651955,10.1145/3589335.3651955,"Conversational Recommender System (CRS) interacts with users through natural language to understand their preferences and provide personalized recommendations in real-time. CRS has demonstrated significant potential, prompting researchers to address the development of more realistic and reliable user simulators as a key focus. Recently, the capabilities of Large Language Models (LLMs) have attracted a lot of attention in various fields. Simultaneously, efforts are underway to construct user simulators based on LLMs. While these works showcase innovation, they also come with certain limitations that require attention. In this work, we aim to analyze the limitations of using LLMs in constructing user simulators for CRS, to guide future research. To achieve this goal, we conduct analytical validation on the notable work, iEvaLM. Through multiple experiments on two widely-used datasets in the field of conversational recommendation, we highlight several issues with the current evaluation methods for user simulators based on LLMs: (1) Data leakage, which occurs in conversational history and the user simulator's replies, results in inflated evaluation results. (2) The success of CRS recommendations depends more on the availability and quality of conversational history than on the responses from user simulators. (3) Controlling the output of the user simulator through a single prompt template proves challenging. To overcome these limitations, we propose SimpleUserSim, employing a straightforward strategy to guide the topic toward the target items. Our study validates the ability of CRS models to utilize the interaction information, significantly improving the recommendation results.",Companion Proceedings of the ACM on Web Conference 2024,1726–1732,7,"conversational recommendation system, large language model, user simulator","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir",The Robots Are Here: Navigating the Generative AI Revolution in Computing Education,2023,9798400704055,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3623762.3633499,10.1145/3623762.3633499,"Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.",Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education,108–159,52,"ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming","Turku, Finland",ITiCSE-WGR '23,inproceedings,,,,,,,,,,
"Zheng, Yong",ChatGPT for Teaching and Learning: An Experience from Data Science Education,2023,9798400701306,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3585059.3611431,10.1145/3585059.3611431,"ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum.",Proceedings of the 24th Annual Conference on Information Technology Education,66–72,7,"ChatGPT, data analytics, data science, large language model","Marietta, GA, USA",SIGITE '23,inproceedings,,,,,,,,,,
"Dehbozorgi, Nasrin and Kunuku, Mourya T.",An LLM-based Reflection Analysis Tool for Identifying and Addressing Challenging Topics,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635601,10.1145/3626253.3635601,"Traditional evaluation of students' learning primarily relies on assessing learning outcomes through either summative or formative assessment methods. In these approaches, the primary emphasis is on the students' learning outcome, rather than the learning process. However, assessing the learning process is as important since it allows providing timely feedback which can directly impact students' learning outcomes. One of the known approaches to getting information about the learning process is the use of formative reflection tools, which also help students in developing their meta-cognitive skills. One effective method for formative reflection is the Minute Paper technique which asks students two concise questions after each class session: what they have learned and what challenges they have encountered. While Minute Papers encourage brief responses, the analysis process can become time-consuming as the number of students and class sessions grows. To address this challenge, in this study, we propose a Large Language Model (LLM)-based reflection analysis tool designed to assess the challenging topics students encounter during each class session. This tool suggests additional learning modules for students to study based on the frequency of the challenging topics. To achieve this, the model utilizes a local repository of lecture materials to create query contexts, which are then input into the LLM as prompts. Students are given access to these recommended resources for further learning, and they are encouraged to provide feedback after completing these modules. These data-driven recommended learning resources serve as continuous content delivery channels to foster a deeper understanding of the subjects at hand.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1618–1619,2,"automated reflection analysis, chatgpt, cs education, large language models (llm), learning outcome, natural language processing (nlp)","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Ahmad, Aakash and Waseem, Muhammad and Liang, Peng and Fahmideh, Mahdi and Aktar, Mst Shamima and Mikkonen, Tommi",Towards Human-Bot Collaborative Software Architecting with ChatGPT,2023,9798400700446,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3593434.3593468,10.1145/3593434.3593468,"Architecting software-intensive systems can be a complex process. It deals with the daunting tasks of unifying stakeholders’ perspectives, designers’ intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation. Despite its benefits, architecture-centric software engineering (ACSE) suffers from a multitude of challenges. ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software. Software Development Bots (DevBots) trained on large language models can help synergise architects’ knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE. An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing. We detail a case study that involves collaboration between a novice software architect and ChatGPT to architect a service-based software. Future research focuses on harnessing empirical evidence about architects’ productivity and explores socio-technical aspects of architecting with ChatGPT to tackle challenges of ACSE.",Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering,279–285,7,"ChatGPT, DevBots, Large Language Models, Software Architecture","Oulu, Finland",EASE '23,inproceedings,,,,,,,,,,
"Fwa, Hua Leong",Experience Report: Identifying common misconceptions and errors of novice programmers with ChatGPT,2024,9798400704987,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639474.3640059,10.1145/3639474.3640059,"Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,233–241,9,"LLM, ChatGPT, misconception, programming, errors, cluster, prompts","Lisbon, Portugal",ICSE-SEET '24,inproceedings,,,,,,,,,,
"Cipriano, Bruno Pereira and Alves, Pedro",GPT-3 vs Object Oriented Programming Assignments: An Experience Report,2023,9798400701382,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587102.3588814,10.1145/3587102.3588814,"Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages.In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,61–67,7,"GPT-3, large language models, object oriented programming, programming assignments, teaching","Turku, Finland",ITiCSE 2023,inproceedings,,,,,,,,,,
,Mining Students' Mastery Levels from CS Placement Tests via LLMs,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635403,10.1145/3626253.3635403,"In higher education, introductory Computer Science (CS) programs offer a range of foundational courses. These encompass not only the standard CS1 and CS2 courses but may also include more specialized options like CS0 and CS1.5. In order to appropriately assign students to the suitable introductory courses, many institutions utilize placement tests, which assess students' pre-existing knowledge and skills. While most institutions rely on accuracy alone to make these determinations, there is often additional information concealed within the completed tests. This paper delves into the potential of Large Language Models (LLMs) to uncover this hidden information, particularly in gaining insights into how students perform in different concepts. Moreover, our framework has the flexibility to accommodate variations in curricula across different institutions, providing additional analytical perspectives. Initially, we built a concept inventory (CI) using the concepts covered in an institution's CS0, CS1, and CS2 curricula. Next, an LLM, specifically GPT 3.5, was applied to associate each question in the placement test with one or more concepts in the CI. Finally, the results of the placement tests were scrutinized, allowing the calculation of mastery levels in each concept for individual students. These mastery levels enable institutions to gauge a student's prior knowledge across various concepts simply by using a CS placement test. Additionally, we presented a case study demonstrating the application of this framework to 267 existing placement test results at Boston College.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1883,1,"concept inventory, introductory computer science courses, large language models, placement test","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Li, Haonan and Hao, Yu and Zhai, Yizhuo and Qian, Zhiyun",Enhancing Static Analysis for Practical Bug Detection: An LLM-Integrated Approach,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3649828,10.1145/3649828,"While static analysis is instrumental in uncovering software bugs, its precision in analyzing large and intricate codebases remains challenging. The emerging prowess of Large Language Models (LLMs) offers a promising avenue to address these complexities. In this paper, we present LLift, a pioneering framework that synergizes static analysis and LLMs, with a spotlight on identifying use-before-initialization (UBI) bugs within the Linux kernel. Drawing from our insights into variable usage conventions in Linux, we enhance path analysis using post-constraint guidance. This approach, combined with our methodically crafted procedures, empowers LLift to adeptly handle the challenges of bug-specific modeling, extensive codebases, and the unpredictable nature of LLMs. Our real-world evaluations identified four previously undiscovered UBI bugs in the mainstream Linux kernel, which the Linux community has acknowledged. This study reaffirms the potential of marrying static analysis with LLMs, setting a compelling direction for future research in this area.",,,26,"Static analysis, bug detection, large language model",,,article,111,April 2024,8,OOPSLA1,Proc. ACM Program. Lang.,apr,,,,
"Chen, Xi and Liang, Jingsai",Pair Programming with ChatGPT,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635600,10.1145/3626253.3635600,"This poster explores the potential of ChatGPT to replace the traditional approach of pair programming in introductory computer science courses. Traditionally, two students collaborate as a driver and a navigator, periodically switching roles. Now, a student can pair up with ChatGPT, which offers an innovative approach to pair programming. This exploratory activity, which emphasizes collaboration and communication, provides step-by-step instructions for effectively interacting with ChatGPT during pair programming.This poster reflects on the advantages and limitations of using ChatGPT in pair programming. The main advantages of using ChatGPT include rapid responses, syntax error-free code generation, and flexibility in handling incomplete pseudocode. The primary limitations include the coding generation style, redundancy in responses, and challenges in understanding the code. Despite the advantages, it may still be valuable to have students work with human partners in certain situations, particularly for learning purposes.This poster proposes that ChatGPT is an invaluable tool for enhancing productivity and emphasizes the importance of becoming proficient in its use during students' college years. It also provides insights into the effective utilization of ChatGPT in pair programming and its preparation for future careers in programming and related fields.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1600–1601,2,"chatgpt, pair programming","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Asare, Owura and Nagappan, Meiyappan and Asokan, N.",A User-centered Security Evaluation of Copilot,2024,9798400702174,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3597503.3639154,10.1145/3597503.3639154,"Code generation tools driven by artificial intelligence have recently become more popular due to advancements in deep learning and natural language processing that have increased their capabilities. The proliferation of these tools may be a double-edged sword because while they can increase developer productivity by making it easier to write code, research has shown that they can also generate insecure code. In this paper, we perform a user-centered evaluation GitHub's Copilot to better understand its strengths and weaknesses with respect to code security. We conduct a user study where participants solve programming problems (with and without Copilot assistance) that have potentially vulnerable solutions. The main goal of the user study is to determine how the use of Copilot affects participants' security performance. In our set of participants (n=25), we find that access to Copilot accompanies a more secure solution when tackling harder problems. For the easier problem, we observe no effect of Copilot access on the security of solutions. We also observe no disproportionate impact of Copilot use on particular kinds of vulnerabilities. Our results indicate that there are potential security benefits to using Copilot, but more research is warranted on the effects of the use of code generation tools on technically complex problems with security requirements.",Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,,11,"user study, code generation, copilot, security, software engineering","Lisbon, Portugal",ICSE '24,inproceedings,158,,,,,,,,,
"Cambaz, Doga and Zhang, Xiaoling",Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630958,10.1145/3626252.3630958,"The recent emergence of LLM-based code generation models can potentially transform programming education. To pinpoint the current state of research on using LLM-based code generators to support the teaching and learning of programming, we conducted a systematic literature review of 21 papers published since 2018. The review focuses on (1) the teaching and learning practices in programming education that utilized LLM-based code generation models, (2) characteristics and (3) performance indicators of the models, and (4) aspects to consider when utilizing the models in programming education, including the risks and challenges. We found that the most commonly reported uses of LLM-based code generation models for teachers are generating assignments and evaluating student work, while for students, the models function as virtual tutors. We identified that the models exhibit accuracy limitations; generated content often contains minor errors that are manageable by instructors but pose risks for novice learners. Moreover, risks such as academic misconduct and over-reliance on the models are critical when considering integrating these models into education. Overall, LLM-based code generation models can be an assistive tool for both learners and instructors if the risks are mitigated.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,172–178,7,"artificial intelligence in education, code generation models, large language models, programming education, systematic review","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Lee, Eun-young and il, Ngagaba Gogo Dae and An, Gi-hong and Lee, Sungchul and Lim, Kiho",ChatGPT-Based Debate Game Application Utilizing Prompt Engineering,2023,9798400702280,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3599957.3606244,10.1145/3599957.3606244,"This paper1 focuses on the implementation of a debate game using ChatGPT, aiming to investigate the feasibility of incorporating large language models into the educational domain through prompt engineering. The study explores strategies to elicit desired outputs from the GPT model by employing the prompt engineering methodology, as provided by Microsoft.Specifically, the game implementation involves the customization of ChatGPT's responses to facilitate a natural progression of debates, varying levels of difficulty, and an evaluation system for assessing the quality of discourse. By leveraging the prompt engineering methodology, we demonstrate that providing specific instructions or case-based prompts improves the accuracy and relevance of ChatGPT's answers. The developed application targets teenagers, enabling them to engage in real-time debates with ChatGPT and enhance their literacy skills. Furthermore, the game fosters the development of logical reasoning, persuasive abilities, effective expression, active participation, and attentive listening while expressing personal opinions, ultimately fostering a sense of accomplishment. Moreover, through debate evaluation and personalized advice, ChatGPT is expected to recognize and address its shortcomings, thereby continuously improving its conversational capabilities.Overall, this research contributes to the understanding of how large language models can be harnessed in educational settings and underscores the potential benefits of prompt engineering techniques in optimizing the outputs of such models.",Proceedings of the 2023 International Conference on Research in Adaptive and Convergent Systems,,6,"ChatGPT, Large Language Model, Prompt Engineering","Gdansk, Poland",RACS '23,inproceedings,29,,,,,,,,,
"Jin, Matthew and Shahriar, Syed and Tufano, Michele and Shi, Xin and Lu, Shuai and Sundaresan, Neel and Svyatkovskiy, Alexey",InferFix: End-to-End Program Repair with LLMs,2023,9798400703270,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3611643.3613892,10.1145/3611643.3613892,"Software development life cycle is profoundly influenced by bugs; their introduction, identification, and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose : a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs.  combines a Retriever – transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator – an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated , a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that  outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of  alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration (CI) pipeline to automate the software development workflow.",Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,1646–1656,11,"Program repair, finetuning, prompt augmentation, static analyses","San Francisco, CA, USA",ESEC/FSE 2023,inproceedings,,,,,,,,,,
"Fu, Ying and Wang, Teng and Li, Shanshan and Ding, Jinyan and Zhou, Shulin and Jia, Zhouyang and Li, Wang and Jiang, Yu and Liao, Xiangke",MissConf: LLM-Enhanced Reproduction of Configuration-Triggered Bugs,2024,9798400705021,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639478.3647635,10.1145/3639478.3647635,"Bug reproduction stands as a pivotal phase in software development, but the absence of configuration information emerges as the main obstacle to effective bug reproduction. Since configuration options generally control critical branches of the software, many bugs can only be triggered under specific configuration settings. We refer to these bugs as configuration-triggered bugs or CTBugs for short. The reproduction of CTBugs consumes considerable time and manual efforts due to the challenges in deducing the missing configuration options within the vast search space of configurations. This complexity contributes to a form of technical debt in software development.To address these challenges, we first conducted an empirical study on 120 CTBugs from 4 widely used systems to understand the root causes and factors influencing the reproduction of CTBugs. Based on our study, we designed and implemented MissConf, the first LLM-enhanced automated tool for CTBug reproduction. Miss-Conf first leverages the LLM to infer whether crucial configuration options are missing in the bug report. Once a suspect CTBug is found, MissConf employs configuration taint analysis and dynamic monitoring methods to filter suspicious configuration options set. Furthermore, it adopts a heuristic strategy for identifying crucial configuration options and their corresponding values. We evaluated MissConf on 5 real-world software systems. The experimental results demonstrate that MissConf successfully infers the 84% (41/49) of the CTBugs and reproduces the 65% (32/49) CTBugs. In the reproduction phase, MissConf eliminates up to 76% of irrelevant configurations, offering significant time savings for developers.",Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings,484–495,12,"bug reproduction, software configuration, software maintenance","Lisbon, Portugal",ICSE-Companion '24,inproceedings,,,,,,,,,,
"Huotala, Aleksi and Kuutila, Miikka and Ralph, Paul and M\",The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews,2024,9798400717017,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3661167.3661172,10.1145/3661167.3661172,"Context: Systematic review (SR) is a popular research method in software engineering (SE). However, conducting an SR takes an average of 67 weeks. Thus, automating any step of the SR process could reduce the effort associated with SRs. Objective: Our objective is to investigate the extent to which Large Language Models (LLMs) can accelerate title-abstract screening by (1) simplifying abstracts for human screeners, and (2) automating title-abstract screening entirely. Method: We performed an experiment where human screeners performed title-abstract screening for 20 papers with both original and simplified abstracts from a prior SR. The experiment with human screeners was reproduced by instructing GPT-3.5 and GPT-4 LLMs to perform the same screening tasks. We also studied whether different prompting techniques (Zero-shot (ZS), One-shot (OS), Few-shot (FS), and Few-shot with Chain-of-Thought (FS-CoT) prompting) improve the screening performance of LLMs. Lastly, we studied if redesigning the prompt used in the LLM reproduction of title-abstract screening leads to improved screening performance. Results: Text simplification did not increase the screeners’ screening performance, but reduced the time used in screening. Screeners’ scientific literacy skills and researcher status predict screening performance. Some LLM and prompt combinations perform as well as human screeners in the screening tasks. Our results indicate that a more recent LLM (GPT-4) is better than its predecessor LLM (GPT-3.5). Additionally, Few-shot and One-shot prompting outperforms Zero-shot prompting. Conclusion: Using LLMs for text simplification in the screening process does not significantly improve human performance. Using LLMs to automate title-abstract screening seems promising, but current LLMs are not significantly more accurate than human screeners. To recommend the use of LLMs in the screening process of SRs, more research is needed. We recommend future SR studies to publish replication packages with screening data to enable more conclusive experimenting with LLM screening.",Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,262–271,10,"ChatGPT, GPT-3.5, GPT-4, LLMs, Screening Process of Systematic Reviews, Text Simplification","Salerno, Italy",EASE '24,inproceedings,,,,,,,,,,
"Shen, Yiyin and Ai, Xinyi and Soosai Raj, Adalbert Gerald and Leo John, Rogers Jeffrey and Syamkumar, Meenakshi",Implications of ChatGPT for Data Science Education,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630874,10.1145/3626252.3630874,"ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,1230–1236,7,"data science education, large language models, prompt engineering","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Cipriano, Bruno Pereira and Alves, Pedro","LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments",2024,9798400704987,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639474.3640052,10.1145/3639474.3640052,"Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision.",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,162–169,8,"programming assignments, teaching, object-oriented programming, object-oriented design, OOP best practices, large language models, GPT-3, GPT-4, bard","Lisbon, Portugal",ICSE-SEET '24,inproceedings,,,,,,,,,,
"Kim, Jeongyeon and Suh, Sangho and Chilton, Lydia B and Xia, Haijun",Metaphorian: Leveraging Large Language Models to Support Extended Metaphor Creation for Science Writing,2023,9781450398930,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3563657.3595996,10.1145/3563657.3595996,"Science writers commonly use extended metaphors to communicate unfamiliar concepts in a more accessible way to a wider audience. However, creating metaphors for science writing is challenging even for professional writers; according to our formative study (n=6), finding inspiration and extending metaphors with coherent structures were critical yet significantly challenging tasks for them. We contribute Metaphorian, a system that supports science writers with the creation of scientific metaphors by facilitating the search, extension, and iterative revision of metaphors. Metaphorian uses a large language model-based workflow inspired by the heuristic rules revealed from a study with six professional writers. A user study (n=16) revealed that Metaphorian significantly enhances satisfaction, confidence, and inspiration in metaphor writing without decreasing writers’ sense of agency. We discuss design implications for creativity support for figurative writing in science.",Proceedings of the 2023 ACM Designing Interactive Systems Conference,115–135,21,"Creativity Support Tools, GPT-3, Large Language Model, Metaphors, Science Writing, Writing Support","Pittsburgh, PA, USA",DIS '23,inproceedings,,,,,,,,,,
"Saldanha, Mateus Santos and Digiampietri, Luciano Antonio",ChatGPT and Bard Performance on the POSCOMP Exam,2024,9798400709968,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3658271.3658320,10.1145/3658271.3658320,"Context: Modern chatbots, built upon advanced language models, have achieved remarkable proficiency in answering questions across diverse fields. Problem: Understanding the capabilities and limitations of these chatbots is a significant challenge, particularly as they are integrated into different information systems, including those in education. Solution: In this study, we conducted a quantitative assessment of the ability of two prominent chatbots, ChatGPT and Bard, to solve POSCOMP questions. IS Theory: The IS theory used in this work is Information processing theory. Method: We used a total of 271 questions from the last five POSCOMP exams that did not rely on graphic content as our materials. We presented these questions to the two chatbots in two formats: directly as they appeared in the exam and with additional context. In the latter case, the chatbots were informed that they were answering a multiple-choice question from a computing exam. Summary of Results: On average, chatbots outperformed human exam-takers by more than 20%. Interestingly, both chatbots performed better, in average, without additional context added to the prompt. They exhibited similar performance levels, with a slight advantage observed for ChatGPT. Contributions and Impact in the IS area: The primary contribution to the field involves the exploration of the capabilities and limitations of chatbots in addressing computing-related questions. This information is valuable for individuals developing Information Systems with the assistance of such chatbots or those relying on technologies built upon these capabilities.",Proceedings of the 20th Brazilian Symposium on Information Systems,,10,"Bard, ChatBot, ChatGPT, Computer Science Examination, Large Language Model","Juiz de Fora, Brazil",SBSI '24,inproceedings,49,,,,,,,,,
"Ni, Qin and Yu, Yangze and Ma, Yiming and Lin, Xin and Deng, Ciping and Wei, Tingjiang and Xuan, Mo",The Social Cognition Ability Evaluation of LLMs: A Dynamic Gamified Assessment and Hierarchical Social Learning Measurement Approach,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3673238,10.1145/3673238,"Large Language Model(LLM) has shown amazing abilities in reasoning tasks, theory of mind(ToM) has been tested in many studies as part of reasoning tasks, and social learning, which is closely related to theory of mind, are still lack of investigation. However, the test methods and materials make the test results unconvincing. We propose a dynamic gamified assessment(DGA) and hierarchical social learning measurement to test ToM and social learning capacities in LLMs. The test for ToM consists of five parts. First, we extract ToM tasks from ToM experiments and then design game rules to satisfy the ToM task requirement. After that, we design ToM questions to match the game’s rules and use these to generate test materials. Finally, we go through the above steps to test the model. To assess the social learning ability, we introduce a novel set of social rules (three in total). Experiment results demonstrate that, except GPT-4, LLMs performed poorly on the ToM test but showed a certain level of social learning ability in social learning measurement.",,,,"Large Language Model, theory of mind, social learning, DGA, and hierarchical social learning measurement",,,article,,,,,ACM Trans. Intell. Syst. Technol.,jun,2157-6904,Just Accepted,,
"Niousha, Rose and Hoq, Muntasir and Akram, Bita and Norouzi, Narges",Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635592,10.1145/3626253.3635592,"This study utilizes large language models to extract foundational programming concepts in programming assignments in a CS1 course. We seek to answer the following research questions: RQ1. How effectively can large language models identify knowledge components in a CS1 course from programming assignments? RQ2. Can large language models be used to extract program-level knowledge components, and how can the information be used to identify students' misconceptions? Preliminary results demonstrated a high similarity between course-level knowledge components retrieved from a large language model and that of an expert-generated list.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1762–1763,2,"cs1, curriculum design, knowledge component","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Lee Solano, Lorenzo and Renzella, Jake and Vassar, Alexandra",DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635483,10.1145/3626253.3635483,"Students in introductory computing courses often lack the experience required to effectively identify and resolve errors in their code. For such students, Programming Error Messages (PEMs) are often the first indication of an error, and could provide valuable debugging guidance. However, in many cases, such as with standard C compiler implementations, PEMs are largely unsuitable for novices. Confusing, misleading, and filled with terse language and jargon, these messages instead act as an additional source of difficulty.In this paper, we present DCC Sidekick, which integrates the Debugging C Compiler (DCC) with a Large Language Model (LLM) in a web-based dashboard to produce contextual, accurate guidance conducive to student learning. This dashboard is directly accessible from the output of the compiler, and provides a bird's-eye-view of the program source, compiler output, and a conversational AI interface to help unravel cryptic error messages. We aim to deploy DCC Sidekick to a C-based CS1 cohort at a large higher education institution to investigate how novice students utilise the conversational explanation interface during debugging activities. In this work, we present our experience designing and building DCC Sidekick.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1714–1715,2,"ai in education, compiler error messages, cs1, error message enhancement, generative ai","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Rogers, Michael P. and Hillberg, Hannah Miller and Groves, Christopher L.",Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630784,10.1145/3626252.3630784,"ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,1147–1153,7,"academic misconduct, artificial intelligence, chatgpt, large language models, student survey","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Nam, Daye and Macvean, Andrew and Hellendoorn, Vincent and Vasilescu, Bogdan and Myers, Brad",Using an LLM to Help With Code Understanding,2024,9798400702174,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3597503.3639187,10.1145/3597503.3639187,"Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domain-specific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.",Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,,13,,"Lisbon, Portugal",ICSE '24,inproceedings,97,,,,,,,,,
"Wang, Sierra and Mitchell, John and Piech, Chris",A Large Scale RCT on Effective Error Messages in CS1,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630764,10.1145/3626252.3630764,"In this paper, we evaluate the most effective error message types through a large-scale randomized controlled trial conducted in an open-access, online introductory computer science course with 8,762 students from 146 countries. We assess existing error message enhancement strategies, as well as two novel approaches of our own: (1) generating error messages using OpenAI's GPT in real time and (2) constructing error messages that incorporate the course discussion forum. By examining students' direct responses to error messages, and their behavior throughout the course, we quantitatively evaluate the immediate and longer term efficacy of different error message types. We find that students using GPT generated error messages repeat an error 23.1% less often in the subsequent attempt, and resolve an error in 34.8% fewer additional attempts, compared to students using standard error messages. We also perform an analysis across various demographics to understand any disparities in the impact of different error message types. Our results find no significant difference in the effectiveness of GPT generated error messages for students from varying socioeconomic and demographic backgrounds. Our findings underscore GPT generated error messages as the most helpful error message type, especially as a universally effective intervention across demographics.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,1395–1401,7,"cs1, error messages, gpt, llm, randomized control trial","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Kabir, Samia and Udo-Imeh, David N. and Kou, Bonan and Zhang, Tianyi",Is Stack Overflow Obsolete? An Empirical Study of the Characteristics of ChatGPT Answers to Stack Overflow Questions,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642596,10.1145/3613904.3642596,"Q&amp;A platforms have been crucial for the online help-seeking behavior of programmers. However, the recent popularity of ChatGPT is altering this trend. Despite this popularity, no comprehensive study has been conducted to evaluate the characteristics of ChatGPT’s answers to programming questions. To bridge the gap, we conducted the first in-depth analysis of ChatGPT answers to 517 programming questions on Stack Overflow and examined the correctness, consistency, comprehensiveness, and conciseness of ChatGPT answers. Furthermore, we conducted a large-scale linguistic analysis, as well as a user study, to understand the characteristics of ChatGPT answers from linguistic and human aspects. Our analysis shows that 52% of ChatGPT answers contain incorrect information and 77% are verbose. Nonetheless, our user study participants still preferred ChatGPT answers 35% of the time due to their comprehensiveness and well-articulated language style. However, they also overlooked the misinformation in the ChatGPT answers 39% of the time. This implies the need to counter misinformation in ChatGPT answers to programming questions and raise awareness of the risks associated with seemingly correct answers.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"chatgpt, large language model, misinformation, q&amp;a, stack overflow","Honolulu, HI, USA",CHI '24,inproceedings,935,,,,,,,,,
"Ma, Zexiong and An, Shengnan and Xie, Bing and Lin, Zeqi",Compositional API Recommendation for Library-Oriented Code Generation,2024,9798400705861,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3643916.3644403,10.1145/3643916.3644403,"Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task.To address this, we propose CAPIR (Compositional API Recommendation), which adopts a ",Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension,87–98,12,"API recommendation, code generation, requirements decomposition, large language model","Lisbon, Portugal",ICPC '24,inproceedings,,,,,,,,,,
"Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Caspersen, Michael E. and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir",Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans,2023,9798400701399,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587103.3594206,10.1145/3587103.3594206,"The recent advent of highly accurate and scalable large language models (LLMs) has taken the world by storm. From art to essays to computer code, LLMs are producing novel content that until recently was thought only humans could produce. Recent work in computing education has sought to understand the capabilities of LLMs for solving tasks such as writing code, explaining code, creating novel coding assignments, interpreting programming error messages, and more. However, these technologies continue to evolve at an astonishing rate leaving educators little time to adapt. This working group seeks to document the state-of-the-art for code generation LLMs, detail current opportunities and challenges related to their use, and present actionable approaches to integrating them into computing curricula.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2,561–562,2,"AI, CS1, GPT, GitHub, LLM, artificial intelligence, code generation, codex, computer programming, copilot, large language models, novice programming, openAI, pedagogical practices","Turku, Finland",ITiCSE 2023,inproceedings,,,,,,,,,,
"Xu, Xiaotong (Tone) and Yin, Jiayu and Gu, Catherine and Mar, Jenny and Zhang, Sydney and E, Jane L. and Dow, Steven P.",Jamplate: Exploring LLM-Enhanced Templates for Idea Reflection,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645196,10.1145/3640543.3645196,"Advances in AI, particularly large language models (LLMs), can transform creative work. When developing a new idea, LLMs can help designers gather information, find competitors, and generate alternatives. However, LLM responses tend to be long-winded or contain inaccuracies, placing a burden on users to carefully synthesize information. In our formative studies with 52 students and five instructors, we find that novice designers typically lack guidance on how to compose prompts, reflect critically on LLM responses, and extract key information to help shape an idea. Building on these insights, we explore an alternative approach for interacting with LLMs, not via chat, but rather through structured templates. Collaborative design templates are a well-established strategy for helping novices think, organize information, and reflect on creative work. Developed as a digital whiteboard plugin, Jamplate integrates LLM capabilities into design templates, streamlining the collection and organization of user-generated content and LLM responses within the template structure. In a preliminary study with 8 novice designers, participants expressed that Jamplate’s reflective questions and in-situ guidance improved their ability to think critically and improve ideas more effectively. We discuss the potential of designing LLM-enhanced templates to instigate critical reflection.",Proceedings of the 29th International Conference on Intelligent User Interfaces,907–921,15,"LLM interaction, design process, design template, large language model interaction","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
"Liu, Zhe and Chen, Chunyang and Wang, Junjie and Chen, Mengzhuo and Wu, Boyu and Huang, Yuekai and Hu, Jun and Wang, Qing",Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642939,10.1145/3613904.3642939,"Mobile apps have become indispensable for accessing and participating in various environments, especially for low-vision users. Users with visual impairments can use screen readers to read the content of each screen and understand the content that needs to be operated. Screen readers need to read the hint-text attribute in the text input component to remind visually impaired users what to fill in. Unfortunately, based on our analysis of 4,501 Android apps with text inputs, over 76% of them are missing hint-text. These issues are mostly caused by developers’ lack of awareness when considering visually impaired individuals. To overcome these challenges, we developed an LLM-based hint-text generation model called HintDroid, which analyzes the GUI information of input components and uses in-context learning to generate the hint-text. To ensure the quality of hint-text generation, we further designed a feedback-based inspection mechanism to further adjust hint-text. The automated experiments demonstrate the high BLEU and a user study further confirms its usefulness. HintDroid can not only help visually impaired individuals, but also help ordinary people understand the requirements of input components. HintDroid demo video: https://youtu.be/FWgfcctRbfI.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"App Accessibility, Large Language Model, Mobile App Design, User Interface","Honolulu, HI, USA",CHI '24,inproceedings,51,,,,,,,,,
"Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew",Evaluating LLM-generated Worked Examples in an Introductory Programming Course,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636252,10.1145/3636243.3636252,"Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.",Proceedings of the 26th Australasian Computing Education Conference,77–86,10,"CS1, GPT-3.5, LLM, chat-GPT, computing education, large language models, worked examples","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
,How to Support ML End-User Programmers through a Conversational Agent,2024,9798400702174,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3597503.3608130,10.1145/3597503.3608130,"Machine Learning (ML) is increasingly gaining significance for enduser programmer (EUP) applications. However, machine learning end-user programmers (ML-EUPs) without the right background face a daunting learning curve and a heightened risk of mistakes and flaws in their models. In this work, we designed a conversational agent named ",Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,,12,"end-user programming, conversational agent, wizard of Oz","Lisbon, Portugal",ICSE '24,inproceedings,53,,,,,,,,,
"Wu, Ruolan and Yu, Chun and Pan, Xiaole and Liu, Yujia and Zhang, Ningning and Fu, Yue and Wang, Yuhan and Zheng, Zhi and Chen, Li and Jiang, Qiaolei and Xu, Xuhai and Shi, Yuanchun",MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642790,10.1145/3613904.3642790,"Problematic smartphone use negatively affects physical and mental health. Despite the wide range of prior research, existing persuasive techniques are not flexible enough to provide dynamic persuasion content based on users’ physical contexts and mental states. We first conducted a Wizard-of-Oz study (N=12) and an interview study (N=10) to summarize the mental states behind problematic smartphone use: boredom, stress, and inertia. This informs our design of four persuasion strategies: understanding, comforting, evoking, and scaffolding habits. We leveraged large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content. We developed MindShift, a novel LLM-powered problematic smartphone use intervention technique. MindShift takes users’ in-the-moment app usage behaviors, physical contexts, mental states, goals &amp; habits as input, and generates personalized and dynamic persuasive content with appropriate persuasion strategies. We conducted a 5-week field experiment (N=25) to compare MindShift with its simplified version (remove mental states) and baseline techniques (fixed reminder). The results show that MindShift improves intervention acceptance rates by 4.7-22.5% and reduces smartphone usage duration by 7.4-9.8%. Moreover, users have a significant drop in smartphone addiction scale scores and a rise in self-efficacy scale scores. Our study sheds light on the potential of leveraging LLMs for context-aware persuasion in other behavior change domains.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,24,"Problematic smartphone use, large language model, mental model, persuasion","Honolulu, HI, USA",CHI '24,inproceedings,248,,,,,,,,,
"Liu, Yi-Cheng and Chu, Wei-Ta",Chart Question Answering based on Modality Conversion and Large Language Models,2024,9798400705472,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3643479.3662057,10.1145/3643479.3662057,"A two-stage chart question answering system is proposed in this paper. Chart/plot images are first converted into structured text-based data by a transformer-based conversion model. Based on the structured text data, a large language model (LLM) is employed to answer the given questions to achieve chart-related question answering. Techniques like chain-of-thoughts, self-consistency, and program of thoughts are utilized to prompt the LLM based on the one-shot learning scheme. We also found that, by rephrasing questions several times and asking the LLM, different answers may be obtained. Aggregating these answers gives rise to performance gain. Overall, we show the proposed method is competitive or even better than the state of the arts, with smaller model size and requiring less training data.",Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia,19–24,6,"ChartQA, Large language model, PlotQA, Visual question answering","Phuket, Thailand",AIQAM '24,inproceedings,,,,,,,,,,
"Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto",Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions,2024,9798400704987,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639474.3640058,10.1145/3639474.3640058,"Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,221–232,12,"QLCs, large language models, artificial intelligence, introductory programming, program comprehension","Lisbon, Portugal",ICSE-SEET '24,inproceedings,,,,,,,,,,
"Weber, Thomas and Brandmaier, Maximilian and Schmidt, Albrecht and Mayer, Sven",Significant Productivity Gains through Programming with Large Language Models,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3661145,10.1145/3661145,"Large language models like GPT and Codex drastically alter many daily tasks, including programming, where they can rapidly generate code from natural language or informal specifications. Thus, they will change what it means to be a programmer and how programmers act during software development. This work explores how AI assistance for code generation impacts productivity. In our user study (N=24), we asked programmers to complete Python programming tasks supported by a) an auto-complete interface using GitHub Copilot, b) a conversational system using GPT-3, and c) traditionally with just the web browser. Aside from significantly increasing productivity metrics, participants displayed distinctive usage patterns and strategies, highlighting that the form of presentation and interaction affects how users engage with these systems. Our findings emphasize the benefits of AI-assisted coding and highlight the different design challenges for these systems.",,,29,"github copilot, gpt, language models, programming, software development, user study",,,article,256,June 2024,8,EICS,Proc. ACM Hum.-Comput. Interact.,jun,,,,
"Messer, Marcus and Brown, Neil C. C. and K\",Automated Grading and Feedback Tools for Programming Education: A Systematic Review,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636515,10.1145/3636515,"We conducted a systematic literature review on automated grading and feedback tools for programming education. We analysed 121 research papers from 2017 to 2021 inclusive and categorised them based on skills assessed, approach, language paradigm, degree of automation, and evaluation techniques. Most papers assess the correctness of assignments in object-oriented languages. Typically, these tools use a dynamic technique, primarily unit testing, to provide grades and feedback to the students or static analysis techniques to compare a submission with a reference solution or with a set of correct student submissions. However, these techniques’ feedback is often limited to whether the unit tests have passed or failed, the expected and actual output, or how they differ from the reference solution. Furthermore, few tools assess the maintainability, readability, or documentation of the source code, with most using static analysis techniques, such as code quality metrics, in conjunction with grading correctness. Additionally, we found that most tools offered fully automated assessment to allow for near-instantaneous feedback and multiple resubmissions, which can increase student satisfaction and provide them with more opportunities to succeed. In terms of techniques used to evaluate the tools’ performance, most papers primarily use student surveys or compare the automatic assessment tools to grades or feedback provided by human graders. However, because the evaluation dataset is frequently unavailable, it is more difficult to reproduce results and compare tools to a collection of common assignments.",,,43,"Automated grading, feedback, assessment, computer science education, systematic literature review, automatic assessment tools",,,article,10,March 2024,24,1,ACM Trans. Comput. Educ.,feb,,,,
"Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond",dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630822,10.1145/3626252.3630822,"In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,1314–1320,7,"ai in cs1, ai in education, compiler error messages, cs1, debugging, error message enhancement, generative ai, large language models, programming error messages","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Liu, Ziyi and Zhu, Zhengzhe and Zhu, Lijun and Jiang, Enze and Hu, Xiyun and Peppler, Kylie A and Ramani, Karthik",ClassMeta: Designing Interactive Virtual Classmate to Promote VR Classroom Participation,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642947,10.1145/3613904.3642947,"Peer influence plays a crucial role in promoting classroom participation, where behaviors from active students can contribute to a collective classroom learning experience. However, the presence of these active students depends on several conditions and is not consistently available across all circumstances. Recently, Large Language Models (LLMs) such as GPT have demonstrated the ability to simulate diverse human behaviors convincingly due to their capacity to generate contextually coherent responses based on their role settings. Inspired by this advancement in technology, we designed ClassMeta, a GPT-4 powered agent to help promote classroom participation by playing the role of an active student. These agents, which are embodied as 3D avatars in virtual reality, interact with actual instructors and students with both spoken language and body gestures. We conducted a comparative study to investigate the potential of ClassMeta for improving the overall learning experience of the class.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"VR classroom, collaborative learning, large language Model, pedagogical agent","Honolulu, HI, USA",CHI '24,inproceedings,659,,,,,,,,,
"Balse, Rishabh and Valaboju, Bharath and Singhal, Shreya and Warriem, Jayakrishnan Madathil and Prasad, Prajish",Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments,2023,9798400701382,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587102.3588852,10.1145/3587102.3588852,"Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course.We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,292–298,7,"GPT-3, evaluation, feedback, large language models (LLM), python programming","Turku, Finland",ITiCSE 2023,inproceedings,,,,,,,,,,
"AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem",How can We Leverage Static Analysis and Large Language Models to Engage Students in Software Quality Improvement,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635356,10.1145/3626253.3635356,"Static analysis tools are frequently used to scan the source code and detect deviations from the project coding guidelines. Yet, their adoption is challenged by their high false positive rate, which makes them not suitable for students and novice developers. However, Large Language Models (LLMs), such as ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including testing, code review, and program comprehension. Such models represent an opportunity to reduce the ambiguity of static analysis tools and support their adoption. Yet, the effectiveness of using static analysis (i.e., PMD) to detect coding issues, and relying on LLMs (i.e., ChatGPT) to explain and recommend fix, has not yet been explored. In this talk, we aim to shed light on our experience in teaching the use of ChatGPT to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. We share our findings to support educators in teaching students better code review strategies, and to increase students' awareness about LLM and promote software quality in education.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1930,1,"computing, education, large language models, quality","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Zheng, Zhi and Chao, WenShuo and Qiu, Zhaopeng and Zhu, Hengshu and Xiong, Hui",Harnessing Large Language Models for Text-Rich Sequential Recommendation,2024,9798400701719,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589334.3645358,10.1145/3589334.3645358,"Recent advances in Large Language Models (LLMs) have been changing the paradigm of Recommender Systems (RS). However, when items in the recommendation scenarios contain rich textual information, such as product descriptions in online shopping or news headlines on social media, LLMs require longer texts to comprehensively depict the historical user behavior sequence. This poses significant challenges to LLM-based recommenders, such as over-length limitations, extensive time and space overheads, and suboptimal model performance. To this end, in this paper, we design a novel framework for harnessing Large Language Models for Text-Rich Sequential Recommendation (LLM-TRSR). Specifically, we first propose to segment the user historical behaviors and subsequently employ an LLM-based summarizer for summarizing these user behavior blocks. Particularly, drawing inspiration from the successful application of Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) models in user modeling, we introduce two unique summarization techniques in this paper, respectively hierarchical summarization and recurrent summarization. Then, we construct a prompt text encompassing the user preference summary, recent user interactions, and candidate item information into an LLM-based recommender, which is subsequently fine-tuned using Supervised Fine-Tuning (SFT) techniques to yield our final recommendation model. We also use Low-Rank Adaptation (LoRA) for Parameter-Efficient Fine-Tuning (PEFT). We conduct experiments on two public datasets, and the results clearly demonstrate the effectiveness of our approach.",Proceedings of the ACM on Web Conference 2024,3207–3216,10,"large language model, recommender system, sequential recommendation","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew",Evaluating Automatically Generated Contextualised Programming Exercises,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630863,10.1145/3626252.3630863,"Introductory programming courses often require students to solve many small programming exercises as part of their learning. Researchers have previously suggested that the context used in the problem description for these exercises is likely to impact student engagement and motivation. Furthermore, supplying programming exercises that use a broad range of contexts or even allowing students to select contexts to personalize their own exercises, may support the interests of a diverse student population. Unfortunately, it is time-consuming for instructors to create large numbers of programming exercises that provide a wide range of contextualized problems. However, recent work has shown that large language models may be able to automate the mass production of programming exercises, reducing the burden on instructors. In this research, we explore the potential of OpenAI's GPT-4 to create high-quality and novel programming exercises that implement various contexts. Finally, through prompt engineering, we compare different prompting strategies used to generate many programming exercises with various contextualized problem descriptions and then evaluate the quality of the exercises generated.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,289–295,7,"chatgpt, cs1, gpt-4, large language models, novice programmers, openai, programming exercises, prompt engineering","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Agarwal, Nimisha",Finding and Investigating Buggy Codes to Make CS1 Learning Efficient,2024,9798400717673,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3641399.3641442,10.1145/3641399.3641442,"In an introductory programming course, students make several logical errors and struggle to fix those errors. This PhD research focuses on creating tools and methods that can aid students in the learning process and help them to find such errors more efficiently.",Proceedings of the 17th Innovations in Software Engineering Conference,,3,"CS1, Refute questions, automated feedback, error localization, targeted test cases, test case generation","Bangalore, India",ISEC '24,inproceedings,24,,,,,,,,,
"Malik, Ali and Woodrow, Juliette and Piech, Chris",Learners Teaching Novices: An Uplifting Alternative Assessment,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630887,10.1145/3626252.3630887,"We propose and carry-out a novel method of formative assessment called Assessment via Teaching (AVT), in which learners demonstrate their understanding of CS1 topics by tutoring more novice students. AVT has powerful benefits over traditional forms of assessment: it is centered around service to others and is highly rewarding for the learners who teach. Moreover, teaching greatly improves the learners' own understanding of the material and has a huge positive impact on novices, who receive free 1:1 tutoring. Lastly, this form of assessment is naturally difficult to cheat---a critical property for assessments in the era of large-language models. We use AVT in a randomised control trial with learners in a CS1 course at an R1 university. The learners provide tutoring sessions to more novice students taking a lagged online version of the same course. We show that learners who do an AVT session before the course exam performed 20 to 30 percentage points better than the class average on several questions. Moreover, compared to students who did a practice exam, the AVT learners enjoyed their experience more and were twice as likely to study for their teaching session. We believe AVT is a scalable and uplifting method for formative assessment that could one day replace traditional exams.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,785–791,7,"formative assessment, learning at scale, online courses, peer teaching, student-led teaching, studying strategies","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed",Seven Failure Points When Engineering a Retrieval Augmented Generation System,2024,9798400705915,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3644815.3644945,10.1145/3644815.3644945,"Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.",Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI,194–199,6,"retrieval augmented generation, RAG, SE4AI, case study","Lisbon, Portugal",CAIN '24,inproceedings,,,,,,,,,,
"De La Torre, Fernanda and Fang, Cathy Mengying and Huang, Han and Banburski-Fahey, Andrzej and Amores Fernandez, Judith and Lanier, Jaron",LLMR: Real-time Prompting of Interactive Worlds using Large Language Models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642579,10.1145/3613904.3642579,"We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR’s cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,22,"artificial intelligence, large language model, mixed reality, spatial reasoning","Honolulu, HI, USA",CHI '24,inproceedings,600,,,,,,,,,
"Abolnejadian, Mohammad and Alipour, Sharareh and Taeb, Kamyar",Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3637148,10.1145/3613905.3637148,"In this research paper, we discuss our attempt to teach high school students introductory programming with Python using a custom learning platform that leverages ChatGPT to generate personalized learning materials based on each student’s educational background. The platform features topics and subtopics, each supported by prompts for Explanation, Example, Exercise, and Exercise Solution, with a context-setting prompt tailored to individual students’ backgrounds while respecting their privacy.The case study brought up compelling insights. Students exhibited heightened engagement, and the lecturers transitioned from being traditional instructors teaching content to becoming mentors who guide students on what to do next, clarifying misunderstandings and addressing potential questions. Furthermore, students gained hands-on programming experience during the learning process, eliminating the traditional post-class experimentation phase.This innovative approach not only enhances traditional CS1 education but also suggests a broader application of Large Language Models (LLMs) for personalized learning across diverse fields, providing tailored instruction and fostering engagement.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,8,"CS1, ChatGPT, Course Design, Introductory Programming, LLM, Learning Platform, Prompt Engineering","
",CHI EA '24,inproceedings,521,,,,,,,,,
"Prasad, Prajish and Sane, Aamod",A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630828,10.1145/3626252.3630828,"Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,1070–1076,7,"chatgpt, generative ai, llm, metacognition, pair programming, pair thinking, self-regulated learning, self-regulation, srl","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Grover, Shuchi","Teaching AI to K-12 Learners: Lessons, Issues, and Guidance",2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630937,10.1145/3626252.3630937,"There is growing recognition of the need to teach artificial intelli- gence (AI) and machine learning (ML) at the school level. This push acknowledges the meteoric growth in the range and diversity of ap- plications of ML in all industries and everyday consumer products, with Large Language Models (LLMs) being only the latest and most compelling example yet. Efforts to bring AI, especially ML educa- tion to school learners are being propelled by substantial industry interest, research efforts, as well as technological developments that make sophisticated ML tools readily available to learners of all ages. These early efforts span a variety of learning goals captured by the AI4K12 ",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,422–428,7,"artificial intelligence, k-12 ai education, k-12 cs education, machine learning","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.",Prompt Problems: A New Programming Exercise for the Generative AI Era,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630909,10.1145/3626252.3630909,"Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,296–302,7,"ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Chen, Liuqing and Xiao, Shuhong and Chen, Yunnong and Song, Yaxuan and Wu, Ruoyu and Sun, Lingyun",ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642229,10.1145/3613904.3642229,"As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children’s autonomous Scratch learning: artist’s block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist’s block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,19,"Children Aged 6-12, Computational Thinking, Large Language Model, Scratch","Honolulu, HI, USA",CHI '24,inproceedings,649,,,,,,,,,
"Yang, Ziqi and Xu, Xuhai and Yao, Bingsheng and Rogers, Ethan and Zhang, Shao and Intille, Stephen and Shara, Nawar and Gao, Guodong Gordon and Wang, Dakuo",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3659625,10.1145/3659625,"Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",,,35,"Large-language-model, Older adults, Patient-provider communication",,,article,73,May 2024,8,2,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,may,,,,
"Zhang, Yu and Sun, Jingwei and Feng, Li and Yao, Cen and Fan, Mingming and Zhang, Liuxin and Wang, Qianying and Geng, Xin and Rui, Yong","See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642545,10.1145/3613904.3642545,"The proliferation of AI-powered search and recommendation systems has accelerated the formation of “filter bubbles” that reinforce people’s biases and narrow their perspectives. Previous research has attempted to address this issue by increasing the diversity of information exposure, which is often hindered by a lack of user motivation to engage with. In this study, we took a human-centered approach to explore how Large Language Models (LLMs) could assist users in embracing more diverse perspectives. We developed a prototype featuring LLM-powered multi-agent characters that users could interact with while reading social media content. We conducted a participatory design study with 18 participants and found that multi-agent dialogues with gamification incentives could motivate users to engage with opposing viewpoints. Additionally, progressive interactions with assessment tasks could promote thoughtful consideration. Based on these findings, we provided design implications with future work outlooks for leveraging LLMs to help users burst their filter bubbles.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,24,"diverse information, filter bubble, interaction design, large language model, multi-agent system","Honolulu, HI, USA",CHI '24,inproceedings,484,,,,,,,,,
"Akram, Bita and Leinonen, Juho and Norouzi, Narges and Prather, James and Zhang, Lisa",AI in Computing Education from Research to Practice,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3631657,10.1145/3626253.3631657,"The panel comprises a diverse set of Computing educators working on AI in education. The panelists will address four areas of AI in Computing education: 1) AI for introductory CS classrooms, 2) Investigating opportunities presented by LLMs, 3) LLM-based tool development, and 4) Ethics and inclusion in AI curriculum. The panel will share experiences and discuss opportunities and challenges in AI education with the community.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1521–1522,2,"artificial intelligence, computing education, large language models","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Leinonen, Juho and Hellas, Arto and Sarsa, Sami and Reeves, Brent and Denny, Paul and Prather, James and Becker, Brett A.",Using Large Language Models to Enhance Programming Error Messages,2023,9781450394314,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3545945.3569770,10.1145/3545945.3569770,"A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix them. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,563–569,7,"ai, codex, compiler error messages, large language models, programming error messages, syntax error messages","Toronto ON, Canada",SIGCSE 2023,inproceedings,,,,,,,,,,
"Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul",CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes,2024,9798400716539,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3631802.3631830,10.1145/3631802.3631830,"Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,,11,"Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance","Koli, Finland",Koli Calling '23,inproceedings,8,,,,,,,,,
"Jeuring, Johan and Groot, Roel and Keuning, Hieke",What Skills Do You Need When Developing Software Using ChatGPT? (Discussion Paper),2024,9798400716539,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3631802.3631807,10.1145/3631802.3631807,"Since the release of LLM-based tools such as GitHub Copilot and ChatGPT the media and popular scientific literature, but also journals such as the Communications of the ACM, have been flooded with opinions how these tools will change programming. The opinions range from “machines will program themselves”, to “AI does not help programmers”. Of course, these statements are meant to to stir up a discussion, and should be taken with a grain of salt, but we argue that such unfounded statements are potentially harmful. Instead, we propose to investigate which skills are required to develop software using LLM-based tools. In this paper we report on an experiment in which we explore if Computational Thinking (CT) skills predict the ability to develop software using LLM-based tools. Our results show that the ability to develop software using LLM-based tools can indeed be predicted by the score on a CT assessment. There are many limitations to our experiment, and this paper is also a call to discuss how to approach, preferably experimentally, the question of which skills are required to develop software using LLM-based tools. We propose to rephrase this question to include by what kind of people/programmers, to develop what kind of software using what kind of LLM-based tools.",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,,6,"ChatGPT, Computational thinking skills, LLM-based tools, Software development skills","Koli, Finland",Koli Calling '23,inproceedings,38,,,,,,,,,
"Xiao, Ruiwei and Hou, Xinying and Stamper, John",Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650937,10.1145/3613905.3650937,"Recent studies have integrated large language models (LLMs) into diverse educational contexts, including providing adaptive programming hints, a type of feedback focuses on helping students move forward during problem-solving. However, most existing LLM-based hint systems are limited to one single hint type. To investigate whether and how different levels of hints can support students’ problem-solving and learning, we conducted a think-aloud study with 12 novices using the LLM Hint Factory, a system providing four levels of hints from general natural language guidance to concrete code assistance, varying in format and granularity. We discovered that high-level natural language hints alone can be helpless or even misleading, especially when addressing next-step or syntax-related help requests. Adding lower-level hints, like code examples with in-line comments, can better support students. The findings open up future work on customizing help responses from content, format, and granularity levels to accurately identify and meet students’ learning needs.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,10,"GPT, Help-seeking, Introductory Programming, Large Language Model, Programming Hint","
",CHI EA '24,inproceedings,142,,,,,,,,,
"Choi, Dasom and Lee, Sunok and Kim, Sung-In and Lee, Kyungah and Yoo, Hee Jeong and Lee, Sangsu and Hong, Hwajung",Unlock Life with a Chat(GPT): Integrating Conversational AI with Large Language Models into Everyday Lives of Autistic Individuals,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641989,10.1145/3613904.3641989,"Autistic individuals often draw on insights from their supportive networks to develop self-help life strategies ranging from everyday chores to social activities. However, human resources may not always be immediately available. Recently emerging conversational agents (CAs) that leverage large language models (LLMs) have the potential to serve as powerful information-seeking tools, facilitating autistic individuals to tackle daily concerns independently. This study explored the opportunities and challenges of LLM-driven CAs in empowering autistic individuals through focus group interviews and workshops (N=14). We found that autistic individuals expected LLM-driven CAs to offer a non-judgmental space, encouraging them to approach day-to-day issues proactively. However, they raised issues regarding critically digesting the CA responses and disclosing their autistic characteristics. Based on these findings, we propose approaches that place autistic individuals at the center of shaping the meaning and role of LLM-driven CAs in their lives, while preserving their unique needs and characteristics.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"autism, conversational agent, large language model, participatory design workshop","Honolulu, HI, USA",CHI '24,inproceedings,72,,,,,,,,,
"Sun, Xin and Liu, Yunjie and De Wit, Jan and Bosch, Jos A. and Li, Zhuying",Trust by Interface: How Different User Interfaces Shape Human Trust in Health Information from Large Language Models,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650837,10.1145/3613905.3650837,"The integration of Large Language Models (LLMs) with Conversational User Interfaces (CUIs) has significantly transformed health information seeking, offering interactive access to health resources. Despite the importance of trust in adopting health advice, the impact of user interfaces on trust perception in LLM-provided information remains unclear. Our mixed-methods study investigated how different CUIs (text-based, speech-based, and embodied) influence trust when using an identical LLM source. Key findings include (a) higher trust levels in information delivered via text-based interface compared to others; (b) a significant correlation between trust in the interface and the information provided; (c) participant’s prior experience, processing approach for information with different modalities and presentation styles, and usability level were key determinants of trust in health-related information. Our study sheds light on trust perceptions in health information from LLMs and its dissemination, underscoring the importance of user interface in trustworthy and effective health information seeking with LLM-powered CUIs.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"Conversational user interface, Healthcare, Human trust perception, Large language model","
",CHI EA '24,inproceedings,344,,,,,,,,,
"Oakes, Bentley James and Famelis, Michalis and Sahraoui, Houari",Building Domain-Specific Machine Learning Workflows: A Conceptual Framework for the State of the Practice,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3638243,10.1145/3638243,"Domain experts are increasingly employing machine learning to solve their domain-specific problems. This article presents to software engineering researchers the six key challenges that a domain expert faces in addressing their problem with a computational workflow, and the underlying executable implementation. These challenges arise out of our conceptual framework which presents the “route” of transformations that a domain expert may choose to take while developing their solution.To ground our conceptual framework in the state of the practice, this article discusses a selection of available textual and graphical workflow systems and their support for the transformations described in our framework. Example studies from the literature in various domains are also examined to highlight the tools used by the domain experts as well as a classification of the domain specificity and machine learning usage of their problem, workflow, and implementation.The state of the practice informs our discussion of the six key challenges, where we identify which challenges and transformations are not sufficiently addressed by available tools. We also suggest possible research directions for software engineering researchers to increase the automation of these tools and disseminate best-practice techniques between software engineering and various scientific domains.",,,50,"Computational workflow, workflow composition, domain experts, machine learning, machine learning pipelines, software engineering framework",,,article,91,May 2024,33,4,ACM Trans. Softw. Eng. Methodol.,apr,1049-331X,,,
"Yang, Jackie (Junrui) and Shi, Yingtian and Zhang, Yuhan and Li, Karina and Rosli, Daniel Wan and Jain, Anisha and Zhang, Shuning and Li, Tianshi and Landay, James A. and Lam, Monica S.",ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642517,10.1145/3613904.3642517,"By combining voice and touch interactions, multimodal interfaces can surpass the efficiency of either modality alone. Traditional multimodal frameworks require laborious developer work to support rich multimodal commands where the user’s multimodal command involves possibly exponential combinations of actions/function invocations. This paper presents ReactGenie, a programming framework that better separates multimodal input from the computational model to enable developers to create efficient and capable multimodal interfaces with ease. ReactGenie translates multimodal user commands into NLPL (Natural Language Programming Language), a programming language we created, using a neural semantic parser based on large-language models. The ReactGenie runtime interprets the parsed NLPL and composes primitives in the computational model to implement complex user commands. As a result, ReactGenie allows easy implementation and unprecedented richness in commands for end-users of multimodal apps. Our evaluation showed that 12 developers can learn and build a non-trivial ReactGenie application in under 2.5 hours on average. In addition, compared with a traditional GUI, end-users can complete tasks faster and with less task load using ReactGenie apps.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,23,"development frameworks, large-language model, multimodal interactions, natural language processing, programming framework","Honolulu, HI, USA",CHI '24,inproceedings,483,,,,,,,,,
"Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald",Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630897,10.1145/3626252.3630897,"Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,618–624,7,"introductory programming, large language models, non-native english speakers, problem generation","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.",Solving Proof Block Problems Using Large Language Models,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630928,10.1145/3626252.3630928,"Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,1063–1069,7,"ai, algorithms, artificial intelligence, chatgpt, code generation, generative ai, gpt-3, gpt-4, large language models, openai, proof blocks, proofs","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Guo, Jiajing and Mohanty, Vikram and Hao, Hongtao and Gou, Liang and Ren, Liu",Can LLMs Infer Domain Knowledge from Code Exemplars? A Preliminary Study,2024,9798400705090,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640544.3645228,10.1145/3640544.3645228,"As organizations recognize the potential of Large Language Models (LLMs), bespoke domain-specific solutions are emerging, which inherently face challenges of knowledge gaps and contextual accuracy. Prompt engineering techniques such as chain-of-thoughts and few-shot prompting have been proposed to enhance LLMs’ capabilities by dynamically presenting relevant exemplars. Are LLMs able to infer domain knowledge from code exemplars involving similar domain concepts and analyze the data correctly? To investigate this, we curated a synthetic dataset containing 45 tabular databases, each has domain concepts and definitions, natural language data analysis queries, and responses in the form of Python code, visualizations, and insights. Using this dataset, we conducted a within-subjects experiment to evaluate the effectiveness of domain-specific exemplars versus randomly selected, generic exemplars. Our study underscores the significance of tailored exemplars in enhancing LLMs’ accuracy and contextual understanding in domain-specific tasks, paving the way for more intuitive and effective data analysis solutions.",Companion Proceedings of the 29th International Conference on Intelligent User Interfaces,95–100,6,"LLM, LLM evaluation, domain-specific data analysis, large language model, prompt engineering","Greenville, SC, USA",IUI '24 Companion,inproceedings,,,,,,,,,,
"Cowan, Brendan and Watanobe, Yutaka and Shirafuji, Atsushi",Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction,2024,9798400708534,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3634814.3634816,10.1145/3634814.3634816,"Due to their robustness, large language models (LLMs) are being utilized in many fields of study, including programming and education. Notably, they can be used by programmers by interfacing with their IDEs to assist with development, and in education by giving students meaningful and immediate feedback. In this paper, we propose and explore the groundwork of a framework designed to combine these two applications of LLMs. The framework acts as a facilitator between the LLM and the student by reading the student’s prompts before filtering and modifying them and sending them to the LLM. The intent is that this will improve the responses from the LLM, thereby improving the student’s learning experience. We discuss the framework in detail and analyze the value of individual responses returned from the LLM as a result of our framework. We conclude that the framework causes the LLM to give helpful responses in comparison to how it would respond without the framework.",Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference,10–16,7,"ChatGPT, educational technology, large language models, programming education, prompt engineering","Aizu-Wakamatsu City, Japan",ASSE '23,inproceedings,,,,,,,,,,
"Lee, Jungeun and Yoon, Suwon and Lee, Kyoosik and Jeong, Eunae and Cho, Jae-Eun and Park, Wonjeong and Yim, Dongsun and Hwang, Inseok",Open Sesame? Open Salami! Personalizing Vocabulary Assessment-Intervention for Children via Pervasive Profiling and Bespoke Storybook Generation,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642580,10.1145/3613904.3642580,"Children acquire language by interacting with their surroundings. Due to the different language environments each child is exposed to, the words they encounter and need in their life vary. Despite the standard tools for assessment and intervention as per predefined vocabulary sets, speech-language pathologists and parents struggle with the absence of systematic tools for child-specific custom vocabulary, i.e., out-of-standard but personally more important. We propose “Open Sesame? Open Salami! (OSOS)”, a personalized vocabulary assessment and intervention system with pervasive language profiling and targeted storybook generation, collaboratively developed with speech-language pathologists. Melded into a child’s daily life and powered by large language models (LLM), OSOS profiles the child’s language environment, extracts priority words therein, and generates bespoke storybooks naturally incorporating those words. We evaluated OSOS through 4-week-long deployments to 9 families. We report their experiences with OSOS, and its implications in supporting personalization outside standards.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,32,"generative AI, language assessment and intervention, large language model, storybook generation, vocabulary learning","Honolulu, HI, USA",CHI '24,inproceedings,120,,,,,,,,,
"Kawamura, Kazuki and Rekimoto, Jun",QA-FastPerson: Extending Video Platform Search Capabilities by Creating Summary Videos in Response to User Queries,2024,9798400709807,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652920.3653052,10.1145/3652920.3653052,"In the rapidly evolving field of digital education, the need for efficient and targeted access to information within video content has become critical. This study presents a system designed to enhance the search capabilities of video platforms by generating summary videos that answer user queries. The system uses machine learning and natural language processing techniques to understand complex user queries, pinpoint the exact video segment that provides the answer, and answer user queries more efficiently by providing the user with a summary video around that segment. Preliminary evaluations have demonstrated the system’s potential to accurately identify relevant content and generate effective summaries.",Proceedings of the Augmented Humans International Conference 2024,290–293,4,"Video summarization, e-learning, human–computer interaction, large language model, learning efficiency, user-centered design","Melbourne, VIC, Australia",AHs '24,inproceedings,,,,,,,,,,
"Shrestha, Shristi and Mahmoud, Anas",Generating Rate Features for Mobile Applications,2024,9798400705946,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3647632.3647986,10.1145/3647632.3647986,"Mobile application (app) stores employ standardized mechanisms for rating hosted apps, typically in the form of free text reviews and numerical rating scales. App users use these mechanisms to express their opinions about their apps and discover apps that fit their specific needs. However, existing app rating systems do not take into account the operational characteristics of application domains. Thus, generated user reviews are often short, subjective, and one-dimensional. To overcome these limitations, in this paper, we propose a multi-dimensional rating system for mobile apps. Our assumption is that an adaptive goal-based app rating system can prompt users to generate higher-quality reviews. To achieve our research objectives, we initially apply extractive summarization to generate short and concise summaries of salient themes in app reviews. Extracted summaries are then fed to a language model to generate Rate Features for apps. Our results show that the language model GPT-3.5 can be prompted to generate abstract, neutral, and domain-specific Rate Features that are aligned to a large extent with user goals in different application domains.",Proceedings of the IEEE/ACM 11th International Conference on Mobile Software Engineering and Systems,54–64,11,,"Lisbon, Portugal",MOBILESoft '24,inproceedings,,,,,,,,,,
"Serafini, Raphael and Otto, Clemens and Horstmann, Stefan Albert and Naiakshina, Alena",ChatGPT-Resistant Screening Instrument for Identifying Non-Programmers,2024,9798400702174,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3597503.3639075,10.1145/3597503.3639075,"To ensure the validity of software engineering and IT security studies with professional programmers, it is essential to identify participants without programming skills. Existing screening questions are efficient, cheating robust, and effectively differentiate programmers from non-programmers. However, the release of ChatGPT raises concerns about their continued effectiveness in identifying non-programmers. In a simulated attack, we showed that Chat-GPT can easily solve existing screening questions. Therefore, we designed new ChatGPT-resistant screening questions using visual concepts and code comprehension tasks. We evaluated 28 screening questions in an online study with 121 participants involving programmers and non-programmers. Our results showed that questions using visualizations of well-known programming concepts performed best in differentiating between programmers and non-programmers. Participants prompted to use ChatGPT struggled to solve the tasks. They considered ChatGPT ineffective and changed their strategy after a few screening questions. In total, we present six ChatGPT-resistant screening questions that effectively identify non-programmers. We provide recommendations on setting up a ChatGPT-resistant screening instrument that takes less than three minutes to complete by excluding 99.47% of non-programmers while including 94.83% of programmers.",Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,,13,"chatgpt, programmer screening, developer study, study protection","Lisbon, Portugal",ICSE '24,inproceedings,181,,,,,,,,,
"Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi",CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642773,10.1145/3613904.3642773,"Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student’s incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI’s unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"AI assistants, AI tutoring, class deployment, design guidelines, educational technology, generative AI, intelligent tutoring systems, large language models, programming education","Honolulu, HI, USA",CHI '24,inproceedings,650,,,,,,,,,
"Kim, Seongwoon and Ahn, Yong-Yeol and Park, Jaehyuk",Labor Space: A Unifying Representation of the Labor Market via Large Language Models,2024,9798400701719,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589334.3645464,10.1145/3589334.3645464,"The labor market is a complex ecosystem comprising diverse, interconnected entities, such as industries, occupations, skills, and firms. Due to the lack of a systematic method to map these heterogeneous entities together, each entity has been analyzed in isolation or only through pairwise relationships, inhibiting comprehensive understanding of the whole ecosystem. Here, we introduce Labor Space, a vector-space embedding of heterogeneous labor market entities, derived through applying a large language model with fine-tuning. Labor Space exposes the complex relational fabric of various labor market constituents, facilitating coherent integrative analysis of industries, occupations, skills, and firms, while retaining type-specific clustering. We demonstrate its unprecedented analytical capacities, including positioning heterogeneous entities on an economic axes, such as 'Manufacturing-Healthcare and Social Assistance'. Furthermore, by allowing vector arithmetic of these entities, Labor Space enables the exploration of complex inter-unit relations, and subsequently the estimation of the ramifications of economic shocks on individual units and their ripple effect across the labor market. We posit that Labor Space provides policymakers and business leaders with a comprehensive unifying framework for labor market analysis and simulation, fostering more nuanced and effective strategic decision-making.",Proceedings of the ACM on Web Conference 2024,2441–2451,11,"firm, industry, job, labor market, large language model, skill, word embedding","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Kuramitsu, Kimio and Obara, Yui and Sato, Miyu and Obara, Momoka",KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education,2023,9798400703904,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3622780.3623648,10.1145/3622780.3623648,"The impact of ChatGPT has brought both anxiety and anticipation to schools and universities. Exploring a positive method to improve programming skills with ChatGPT is a new and pressing challenge.  
In pursuit of this goal, we have developed KOGI, a learning support system that integrates ChatGPT into the Jupyter environment. This paper demonstrates how KOGI enables students to receive timely advice from ChatGPT in response to errors and other questions they encounter.  

We immediately introduced KOGI in our two introductory courses: Algorithms and Data Science. The introduction of KOGI resulted in a significant decrease in the number of unresolved student errors. In addition, we report on student trends observed in the classroom regarding the type and frequency of help requested. Although our findings are preliminary, they are informative for programming instructors interested in using ChatGPT.",Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E,50–59,10,"ChatGPT, LLM, classroom experience, programming education","Cascais, Portugal",SPLASH-E 2023,inproceedings,,,,,,,,,,
"Tran, Andrew and Li, Linxuan and Rama, Egi and Angelikas, Kenneth and Macneil, Stephen",Using Large Language Models to Automatically Identify Programming Concepts in Code Snippets,2023,9781450399753,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3568812.3603482,10.1145/3568812.3603482,"Curating course material that aligns with students’ learning goals is a challenging and time-consuming task that instructors undergo when preparing their curricula. For instance, it is a challenge to find multiple-choice questions or example codes that demonstrate recursion in an unlabeled question bank or repository. Recently, Large Language Models (LLMs) have demonstrated the capability to generate high-quality learning materials at scale. In this poster, we use LLMs to identify programming concepts found within code snippets, allowing instructors to quickly curate their course materials. We compare programming concepts generated by LLMs with concepts generated by experts to see the extent to which they agree. The agreement was calculated using Cohen’s Kappa.",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,22–23,2,"computer science education, explanations, large language models","Chicago, IL, USA",ICER '23,inproceedings,,,,,,,,,,
"Baimetov, Ilya",Improving Effectiveness of Programming Assignments with Real-time Formative Feedback,2023,9798400701399,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587103.3594145,10.1145/3587103.3594145,"This PhD research explores the problem of building an effective ITS-like system for providing real-time formative feedback for programming assignments given to college/university students. Such system would maximize learning outcomes while minimizing the effort from the tutor to construct such system.It proposes an approach to building such a system and assessing its effectiveness, as well as outlines topics for future research.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2,627–628,2,"ITS, automated feedback, formative feedback, programming assignments","Turku, Finland",ITiCSE 2023,inproceedings,,,,,,,,,,
"Tolk, Andreas and Barry, Philip and Loper, Margaret L. and Rabadi, Ghaith and Scherer, William T. and Yilmaz, Levent",Chances and Challenges of Chatgpt and Similar Models for Education in M&amp;S,2024,9798350369663,IEEE Press,,,,"This position paper summarizes the inputs of a group of experts from academia and industry presenting their view on chances and challenges of using ChatGPT within Modeling and Simulation education. The experts also address the need to evaluate continuous education as well as education of faculty members to address scholastic challenges and opportunities while meeting the expectation of industry. Generally, the use of ChatGPT is encouraged, but it needs to be embedded into an updated curriculum with more emphasis on validity constraints, systems thinking, and ethics.",Proceedings of the Winter Simulation Conference,3332–3346,15,,"San Antonio, Texas, USA",WSC '23,inproceedings,,,,,,,,,,
"Gao, Haoyu and Treude, Christoph and Zahedi, Mansooreh",Evaluating Transfer Learning for Simplifying GitHub READMEs,2023,9798400703270,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3611643.3616291,10.1145/3611643.3616291,"Software documentation captures detailed knowledge about a software product, e.g., code, technologies, and design. It plays an important role in the coordination of development teams and in conveying ideas to various stakeholders. However, software documentation can be hard to comprehend if it is written with jargon and complicated sentence structure. In this study, we explored the potential of text simplification techniques in the domain of software engineering to automatically simplify GitHub README files. We collected software-related pairs of GitHub README files consisting of 14,588 entries, aligned difficult sentences with their simplified counterparts, and trained a Transformer-based model to automatically simplify difficult versions. To mitigate the sparse and noisy nature of the software-related simplification dataset, we applied general text simplification knowledge to this field. Since many general-domain difficult-to-simple Wikipedia document pairs are already publicly available, we explored the potential of transfer learning by first training the model on the Wikipedia data and then fine-tuning it on the README data. Using automated BLEU scores and human evaluation, we compared the performance of different transfer learning schemes and the baseline models without transfer learning. The transfer learning model using the best checkpoint trained on a general topic corpus achieved the best performance of 34.68 BLEU score and statistically significantly higher human annotation scores compared to the rest of the schemes and baselines. We conclude that using transfer learning is a promising direction to circumvent the lack of data and drift style problem in software README files simplification and achieved a better trade-off between simplification and preservation of meaning.",Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,1548–1560,13,"GitHub, Software Documentation, Text Simplification, Transfer Learning","San Francisco, CA, USA",ESEC/FSE 2023,inproceedings,,,,,,,,,,
"Kawamura, Kazuki and Rekimoto, Jun",FastPerson: Enhancing Video-Based Learning through Video Summarization that Preserves Linguistic and Visual Contexts,2024,9798400709807,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652920.3652922,10.1145/3652920.3652922,"Quickly understanding lengthy lecture videos is essential for learners with limited time and interest in various topics to improve their learning efficiency. To this end, video summarization has been actively researched to enable users to view only important scenes from a video. However, these studies focus on either the visual or audio information of a video and extract important segments in the video. Therefore, there is a risk of missing important information when both the teacher’s speech and visual information on the blackboard or slides are important, such as in a lecture video. To tackle this issue, we propose FastPerson, a video summarization approach that considers both the visual and auditory information in lecture videos. FastPerson creates summary videos by utilizing audio transcriptions along with on-screen images and text, minimizing the risk of overlooking crucial information for learners. Further, it provides a feature that allows learners to switch between the summary and original videos for each chapter of the video, enabling them to adjust the pace of learning based on their interests and level of understanding. We conducted an evaluation with 40 participants to assess the effectiveness of our method and confirmed that it reduced viewing time by 53% at the same level of comprehension as that when using traditional video playback methods.",Proceedings of the Augmented Humans International Conference 2024,205–216,12,"Video summarization, e-learning, human–computer interaction, large language model, learning efficiency, multimodal information processing, speech synthesis, user-centered design","Melbourne, VIC, Australia",AHs '24,inproceedings,,,,,,,,,,
,"Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641965,10.1145/3613904.3641965,"Creating intervention messages for smoking cessation is a labor-intensive process. Advances in Large Language Models (LLMs) offer a promising alternative for automated message generation. Two critical questions remain: 1) How to optimize LLMs to mimic human expert writing, and 2) Do LLM-generated messages meet clinical standards? We systematically examined the message generation and evaluation processes through three studies investigating prompt engineering (Study 1), decoding optimization (Study 2), and expert review (Study 3). We employed computational linguistic analysis in LLM assessment and established a comprehensive evaluation framework, incorporating automated metrics, linguistic attributes, and expert evaluations. Certified tobacco treatment specialists assessed the quality, accuracy, credibility, and persuasiveness of LLM-generated messages, using expert-written messages as the benchmark. Results indicate that larger LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate expert writing to generate well-written, accurate, and persuasive messages, thereby demonstrating the capability of LLMs in augmenting clinical practices of smoking cessation interventions.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Computational Linguistic Analysis, Expert Review, Large Language Model, Message Generation, Smoking Cessation Intervention","Honolulu, HI, USA",CHI '24,inproceedings,436,,,,,,,,,
"Hu, Zhizhang and Zhang, Yue and Rossi, Ryan and Yu, Tong and Kim, Sungchul and Pan, Shijia",Are Large Language Models Capable of Causal Reasoning for Sensing Data Analysis?,2024,9798400706639,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3662006.3662064,10.1145/3662006.3662064,"The correlation analysis between socioeconomic factors and environmental impact is essential for policy making to ensure sustainability and economic development simultaneously. With the development of Internet of Things (IoT), citizen science IoT monitoring provides valuable environmental measurements, such as PM 2.5 for air quality monitoring. However, socioeconomic factors are usually interconnected and confound each other, making accurate correlation analysis challenging. To isolate this information on an individual socioeconomic factor, we need to mitigate the confounding effect (e.g., propensity score matching) of other factors on the environmental sensing data. Large language models (LLMs) have shown remarkable capabilities in data reasoning, making us wonder if they can conduct causal reasoning and answer questions like ",Proceedings of the Workshop on Edge and Mobile Foundation Models,24–29,6,"Causal Data Reasoning, Large Language Model","Minato-ku, Tokyo, Japan",EdgeFM '24,inproceedings,,,,,,,,,,
"Jamil, Hasan",Equity and Fairness Challenges in Online Learning in the Age of ChatGPT,2024,9798400702433,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3605098.3636108,10.1145/3605098.3636108,"Recent research suggest that equity remained a neglected consideration in most learning analytics and continues to be an esoteric concept. Online learning poses many additional equity challenges that largely concerns gender, access to resources, socio-economic conditions, fairness, or feeling of isolation. In this article, we discuss a novel equity concern in the emerging online learning environment often aided by large language models such as ChatGPT. It has been observed that ChatGPT-like models can be a significantly powerful learning and tutoring aid for learners. However, in online learning and in the absence of a human instructor, ChatGPT could introduce inequity in form of ",Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,91–92,2,"large language model, equity, database, authentic assessment","Avila, Spain",SAC '24,inproceedings,,,,,,,,,,
"Happe, Andreas and Cito, J\",Getting pwn’d by AI: Penetration Testing with Large Language Models,2023,9798400703270,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3611643.3613083,10.1145/3611643.3613083,"The field of software security testing, more specifically penetration testing, requires high levels of expertise and involves many manual testing and analysis steps. This paper explores the potential use of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners. We explore two distinct use cases: high-level task planning for security testing assignments and low-level vulnerability hunting within a vulnerable virtual machine. For the latter, we implemented a closed-feedback loop between LLM-generated low-level actions with a vulnerable virtual machine (connected through SSH) and allowed the LLM to analyze the machine state for vulnerabilities and suggest concrete attack vectors which were automatically executed within the virtual machine. We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of AI sparring partners.",Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2082–2086,5,"large language models, penetration testing, security testing","San Francisco, CA, USA",ESEC/FSE 2023,inproceedings,,,,,,,,,,
"Giabbanelli, Philippe J.",GPT-Based Models Meet Simulation: How to Efficiently use Large-Scale Pre-Trained Language Models Across Simulation Tasks,2024,9798350369663,IEEE Press,,,,"The disruptive technology provided by large-scale pre-trained language models (LLMs) such as ChatGPT or GPT-4 has received significant attention in several application domains, often with an emphasis on high-level opportunities and concerns. This paper is the first examination regarding the use of LLMs for scientific simulations. We focus on four modeling and simulation tasks, each time assessing the expected benefits and limitations of LLMs while providing practical guidance for modelers regarding the steps involved. The first task is devoted to explaining the structure of a conceptual model to promote the engagement of participants in the modeling process. The second task focuses on summarizing simulation outputs, so that model users can identify a preferred scenario. The third task seeks to broaden accessibility to simulation platforms by conveying the insights of simulation visualizations via text. Finally, the last task evokes the possibility of explaining simulation errors and providing guidance to resolve them.",Proceedings of the Winter Simulation Conference,2920–2931,12,,"San Antonio, Texas, USA",WSC '23,inproceedings,,,,,,,,,,
"Wang, Zixuan and Denny, Paul and Leinonen, Juho and Luxton-Reilly, Andrew",Leveraging Large Language Models for Analysis of Student Course Feedback,2023,9798400708404,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627217.3627221,10.1145/3627217.3627221,"This study investigates the use of large language models, specifically ChatGPT, to analyse the feedback from a Summative Evaluation Tool (SET) used to collect student feedback on the quality of teaching. We find that these models enhance comprehension of SET scores and the impact of context on student evaluations. This work aims to reveal hidden patterns in student evaluation data, demonstrating a positive first step towards automated, detailed analysis of student feedback.",Proceedings of the 16th Annual ACM India Compute Conference,76–79,4,"Large Language Model, Natural Language Processing, Student Evaluation of Teaching, Student Feedback","Hyderabad, India",COMPUTE '23,inproceedings,,,,,,,,,,
"Agarwal, Arav and Mittal, Karthik and Doyle, Aidan and Sridhar, Pragnya and Wan, Zipiao and Doughty, Jacob Arthur and Savelka, Jaromir and Sakr, Majd",Understanding the Role of Temperature in Diverse Question Generation by GPT-4,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635608,10.1145/3626253.3635608,"We conduct a preliminary study of the effect of GPT's temperature parameter on the diversity of GPT4-generated questions. We find that using higher temperature values leads to significantly higher diversity, with different temperatures exposing different types of similarity between generated sets of questions. We also demonstrate that diverse question generation is especially difficult for questions targeting lower levels of Bloom's Taxonomy.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1550–1551,2,"automated content generation, automatic generation, course design automation, curricular development, gpt-4, large language models, learning objectives, llms","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi",Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580919,10.1145/3544548.3580919,"AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,23,"AI Coding Assistants, AI-Assisted Pair-Programming, ChatGPT, Copilot, GPT-3, Introductory Programming, K-12 Computer Science Education, Large Language Models, OpenAI Codex","Hamburg, Germany",CHI '23,inproceedings,455,,,,,,,,,
"Woodrow, Juliette and Malik, Ali and Piech, Chris","AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course",2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630773,10.1145/3626252.3630773,"Teaching students how to write code that is elegant, reusable, and comprehensible is a fundamental part of CS1 education. However, providing this ",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,1442–1448,7,"cs1, deployed at scale, gpt, llms, real time, style feedback","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Barletta, Vita Santa and Caruso, Federica and Di Mascio, Tania and Greco, Francesco and Islam, Tasmina and Rossano, Veronica and Xiao, Hannan",CyberSecurity Education for Industry and Academia (CSE4IA 2024),2024,9798400717642,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3656650.3660536,10.1145/3656650.3660536,"The cybersecurity domain faces a critical disparity between the escalating demand for skilled professionals and the limited talent pool. This gap is primarily driven by the surge in cyberattacks perpetrated by malicious actors seeking financial gain or disruption. These attacks, encompassing tactics like Distributed Denial-of-Service (DDoS) and ransomware, pose significant threats to data security and public safety. To bridge this gap, several challenges must be addressed. We need to prioritize initiatives that enhance people’s awareness and education in cybersecurity. Additionally, exploring innovative training methods and leveraging technology to equip cybersecurity professionals with the necessary skillsets is crucial. Like the last edition, the goal of this workshop remains to empower individuals to make informed decisions regarding cybersecurity education, navigate diverse career paths, and recognize the alignment between their acquired skills and industry demands. These novel educational methodologies will also equip professionals with a deeper understanding of cybersecurity risks and the expertise required to develop robust and secure technological solutions. Thinking about students, teachers, and professionals as the people who need to learn about cybersecurity, the aim of this workshop is to talk about how we can better match the companies’ demand (workplace, recruitment) and supply (qualification, training). We aim to raise awareness among these learners, help identify the crucial skills that are required for their work and encourage a more unified approach to teaching and training in cybersecurity.",Proceedings of the 2024 International Conference on Advanced Visual Interfaces,,4,"Awareness, Cybersecurity, Education, Training","Arenzano, Genoa, Italy",AVI '24,inproceedings,121,,,,,,,,,
"Song, Yewei and Ezzini, Saad and Tang, Xunzhu and Lothritz, Cedric and Klein, Jacques and Bissyande, Tegawende and Boytsov, Andrey and Ble, Ulrick and Goujon, Anne",Enhancing Text-to-SQL Translation for Financial System Design,2024,9798400705014,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639477.3639732,10.1145/3639477.3639732,"Text-to-SQL, the task of translating natural language questions into SQL queries, is part of various business processes. Its automation, which is an emerging challenge, will empower software practitioners to seamlessly interact with relational databases using natural language, thereby bridging the gap between business needs and software capabilities.In this paper, we consider Large Language Models (LLMs), which have achieved state of the art for various NLP tasks. Specifically, we benchmark Text-to-SQL performance, the evaluation methodologies, as well as input optimization (e.g., prompting). In light of the empirical observations that we have made, we propose two novel metrics that were designed to adequately measure the similarity between SQL queries.Overall, we share with the community various findings, notably on how to select the right LLM on Text-to-SQL tasks. We further demonstrate that a tree-based edit distance constitutes a reliable metric for assessing the similarity between generated SQL queries and the oracle for benchmarking Text2SQL approaches. This metric is important as it relieves researchers from the need to perform computationally expensive experiments such as executing generated queries as done in prior works. Our work implements financial domain use cases and, therefore contributes to the advancement of Text2SQL systems and their practical adoption in this domain.",Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice,252–262,11,,"Lisbon, Portugal",ICSE-SEIP '24,inproceedings,,,,,,,,,,
"Sheard, Judy and Denny, Paul and Hellas, Arto and Leinonen, Juho and Malmi, Lauri and Simon",Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630880,10.1145/3626252.3630880,"Much of the recent work investigating large language models and AI Code Generation tools in computing education has focused on assessing their capabilities for solving typical programming problems and for generating resources such as code explanations and exercises. If progress is to be made toward the inevitable lasting pedagogical change, there is a need for research that explores the instructor voice, seeking to understand how instructors with a range of experiences plan to adapt. In this paper, we report the results of an interview study involving 12 instructors from Australia, Finland and New Zealand, in which we investigate educators' current practices, concerns, and planned adaptations relating to these tools. Through this empirical study, our goal is to prompt dialogue between researchers and educators to inform new pedagogical strategies in response to the rapidly evolving landscape of AI code generation tools.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,1223–1229,7,"ai code generation, generative ai, instructor perceptions, interview study, large language models, llms, programming education","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Janaka, Nuwan and Cai, Runze and Zhao, Shengdong and Hsu, David",Demonstrating PANDALens: Enhancing Daily Activity Documentation with AI-assisted In-Context Writing on OHMD,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3648644,10.1145/3613905.3648644,"We introduce PANDALens, a Proactive AI Narrative Documentation Assistant built on an Optical See-Through Head-Mounted Display that transforms the in-context writing tool into an intelligent companion during daily activities. PANDALens observes multimodal contextual information from user behaviors and the environment to detect interesting moments and elicit contemplation. It also employs Large Language Models to transform such multimodal information into coherent narratives with significantly reduced user effort. PANDALens was iteratively designed through a formative study identifying the user requirements. We verify its utility in a real-world travel scenario in improving writing quality and travel enjoyment while minimizing user effort.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"AI, HMD, Human-AI collaborative writing, in-context writing, large language model, multimodal information, smart glasses, travel blog","
",CHI EA '24,inproceedings,397,,,,,,,,,
"Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd",A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636256,10.1145/3636243.3636256,"There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models&nbsp;(LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.",Proceedings of the 26th Australasian Computing Education Conference,114–123,10,"Assessments, Automated Content Generation, Automatic Generation, GPT-4, LLMs, LOs, Large Language Models, Learning Objectives, MCQs, Multiple-choice Questions","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
"Lucke, J\","A few Thoughts on the Use of ChatGPT, GPT 3.5, GPT-4 and LLMs in Parliaments: Reflecting on the results of experimenting with LLMs in the parliamentarian context",2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3665333,10.1145/3665333,"Starting in November 2022 with the free provision of ChatGPT, large language models (LLM) are now publicly available. This has significantly increased the number of publications which scopes potential changes caused by the application of generative artificial intelligence (AI) in various societal domains. The private use of AI and the economic integration of generative LLMs have increased significantly. However, for parliamentarians and parliamentary professionals, the technology often remains abstract, impacting everyday work only peripherally. Due to the special responsibility of parliaments, governments, and administrations as the organizational instances of society, and through the inherent legitimations by society itself, there is a necessity to examine the implications of the use of generative LLMs within these institutions and traditional structures as well as their influence on political system logic. The paper analyzes the responses that the generative LLMs GPT 3.5 and GPT 4 have provided via ChatGPT, based on the same input command (prompt) over different times. The responses help to assess how LLMs can be used in the parliamentary context, to reflect what dangers exist as well as to respond to the question on how a business model of an AI department in parliament might look like. Furthermore, it shall be explored whether there are fluctuations in the quality of the responses and how these should be evaluated against the backdrop of the need for accurate and precise workflows in parliamentary operations. Ultimately, the paper aims to provide an answer as to whether the application of ChatGPT together with the LLMs GPT-3.5 and GPT-4 could already deliver this necessary quality and consistency for the parliamentarian working environment today.",,,,"large language model, ChatGPT, GPT 3.5, GPT-4, parliament",,,article,,,,,Digit. Gov.: Res. Pract.,may,,Just Accepted,,
"Ishizue, Ryosuke and Sakamoto, Kazunori and Washizaki, Hironori and Fukazawa, Yoshiaki",Improved Program Repair Methods using Refactoring with GPT Models,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630875,10.1145/3626252.3630875,"Teachers often utilize automatic program repair methods to provide feedback on submitted student code using model answer code. A state-of-the-art tool is Refactory, which achieves a high repair success rate and small patch size (less code repair) by refactoring code to expand the variety of correct code samples that can be referenced. However, Refactory has two major limitations. First, it cannot fix code with syntax errors. Second, it has difficulty fixing code when there are few correct submissions. Herein we propose a new method that combines Refactory and OpenAI's GPT models to address these issues and conduct a performance measurement experiment. The experiment uses a dataset consisting of 5 programming assignment problems and almost 1,800 real-life incorrect Python program submissions from 361 students for an introductory programming course at a large public university. The proposed method improves the repair success rate by 1-21% when the set of correct code samples is sufficient and the patch size is smaller than Refactory alone in 16-45% of the cases. When there was no set of correct code samples at all (only the model answer code was used as a reference for repair), method improves the repair success rate by 1-43% and the patch size is smaller than Refactory alone in 42-68% of the cases.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,569–575,7,"generative ai, program repair, programming assignment","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Mitra, Chancharik and Miroyan, Mihran and Jain, Rishi and Kumud, Vedant and Ranade, Gireeja and Norouzi, Narges",Elevating Learning Experiences: Leveraging Large Language Models as Student-Facing Assistants in Discussion Forums,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635609,10.1145/3626253.3635609,"Recent advancements in instruction-tuned large language models offer new potential for enhancing students' experiences in large-scale classes. Deploying LLMs as student-facing assistants, however, presents challenges. Key issues include integrating class-specific content into responses and applying effective pedagogical techniques. This study addresses these challenges through retrieval and prompting techniques, focusing on mitigating hallucinations in LLM-generated responses, a crucial concern in education. Furthermore, practical deployment brings further challenges related to student data privacy and computational constraints. This research strives to enhance the quality and relevance of LLM responses while addressing practical deployment issues, with an emphasis on creating a versatile system for diverse domains and teaching styles.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1752–1753,2,"discussion forum, educational tools, natural language processing","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Fan, Zhiyu and Gao, Xiang and Mirchev, Martin and Roychoudhury, Abhik and Tan, Shin Hwei",Automated Repair of Programs from Large Language Models,2023,9781665457019,IEEE Press,,https://doi.org/10.1109/ICSE48619.2023.00128,10.1109/ICSE48619.2023.00128,"Large language models such as Codex, have shown the capability to produce code for many programming tasks. However, the success rate of existing models is low, especially for complex programming tasks. One of the reasons is that language models lack awareness of program semantics, resulting in incorrect programs, or even programs which do not compile. In this paper, we systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests. The goal is to study whether APR techniques can enhance reliability in the code produced by large language models. Our study revealed that: (1) automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to fix auto-generated code; (2) given bug location information provided by a statistical fault localization approach, the newly released Codex edit mode, which supports editing code, is similar to or better than existing Java repair tools TBar and Recoder in fixing incorrect solutions. By analyzing the experimental results generated by these tools, we provide several suggestions: (1) enhancing APR tools to surpass limitations in patch space (e.g., introducing more flexible fault localization) is desirable; (2) as large language models can derive more fix patterns by training on more data, future APR tools could shift focus from adding more fix patterns to synthesis/semantics based approaches, (3) combination of language models with APR to curate patch ingredients, is worth studying.",Proceedings of the 45th International Conference on Software Engineering,1469–1481,13,,"Melbourne, Victoria, Australia",ICSE '23,inproceedings,,,,,,,,,,
"Gupta, Rajeev and Srinivasa, Srinath",Workshop on Enterprise Knowledge Graphs using Large Language Models,2023,9798400701245,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3583780.3615301,10.1145/3583780.3615301,"Knowledge graphs are used for organizing and connecting individual entities to integrate the information extracted from different data sources. Typically, knowledge graphs are used to connect various real-world entities like persons, places, things, actions, etc. For the knowledge graphs created using the enterprise data, the knowledge graph entities can be of different types-static entities (e.g., people, projects), communication entities (e.g., emails, meetings, documents), derived entities (e.g., rules, definitions, entities from emails), etc. The graphs are used to connect these entities with enriched context (as edges and node attributes) and used for powering various search and recommendations applications.With the advent of large language models, the whole lifecycle of knowledge graphs involving -information extraction, graph construction, application of graphs, querying knowledge graphs, using the graph for recommendations, etc., - is impacted. With large language models such as GPT, LLaMA, PALM, etc., entity and relationship extraction can be improved. Similarly, one can answer different types of queries with the help of LLMs which were very difficult without them. This workshop is about improving the enterprise knowledge graphs and its applications using large language models.Enterprise graphs can be of different scopes-whether they contain data from individual users/customers, a sub-organization, or the whole enterprise. This workshop will also cover various privacy and access control related issues which are typical for any enterprise graph. These include privacy preserving federated learning, using LLMs to extract information from private data, querying the knowledge graph in a privacy preserving manner, etc.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,5271–5272,2,"entity extraction, knowledge graph, large language model, recommendations, relationship extraction","Birmingham, United Kingdom",CIKM '23,inproceedings,,,,,,,,,,
"Jiang, Xue and Dong, Yihong and Wang, Lecheng and Zheng, Fang and Shang, Qiwei and Li, Ge and Jin, Zhi and Jiao, Wenpin",Self-planning Code Generation with Large Language Models,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3672456,10.1145/3672456,"Although large language models (LLMs) have demonstrated impressive ability in code generation, they are still struggling to address the complicated intent provided by humans. It is widely acknowledged that humans typically employ planning to decompose complex problems and schedule solution steps prior to implementation. To this end, we introduce planning into code generation to help the model understand complex intent and reduce the difficulty of problem-solving. This paper proposes a self-planning code generation approach with large language models, which consists of two phases, namely planning phase and implementation phase. Specifically, in the planning phase, LLM plans out concise solution steps from the intent combined with few-shot prompting. Subsequently, in the implementation phase, the model generates code step by step, guided by the preceding solution steps. We conduct extensive experiments on various code-generation benchmarks across multiple programming languages. Experimental results show that self-planning code generation achieves a relative improvement of up to 25.4% in Pass@1 compared to direct code generation, and up to 11.9% compared to Chain-of-Thought of code generation. Moreover, our self-planning approach also enhances the quality of the generated code with respect to correctness, readability, and robustness, as assessed by humans.",,,,,,,article,,,,,ACM Trans. Softw. Eng. Methodol.,jun,1049-331X,Just Accepted,,
"Hou, Xinying and Ericson, Barbara J. and Wang, Xu",Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635606,10.1145/3626253.3635606,"Novice programmers need to write basic code as part of the learning process, but they often face difficulties. To assist struggling students, we recently implemented personalized Parsons problems, which are code puzzles where students arrange blocks of code to solve them, as pop-up scaffolding. Students found them to be more engaging and preferred them for learning, instead of simply receiving the correct answer, such as the response they might get from generative AI tools like ChatGPT. However, a drawback of using Parsons problems as scaffolding is that students may be able to put the code blocks in the correct order without fully understanding the rationale of the correct solution. As a result, the learning benefits of scaffolding are compromised. Can we improve the understanding of personalized Parsons scaffolding by providing textual code explanations? In this poster, we propose a design that incorporates multiple levels of textual explanations for the Parsons problems. This design will be used for future technical evaluations and classroom experiments. These experiments will explore the effectiveness of adding textual explanations to Parsons problems to improve instructional benefits.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1686–1687,2,"code explanations, code writing, hint, introductory programming, large language models, parsons problems, scaffolding","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
,Teaching Students To Use Programming Error Messages,2023,9798400703744,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3617650.3624950,10.1145/3617650.3624950,"Research shows many students struggle to use programming error and warning messages effectively. Instead of using these messages as aids to debug and fix their code, some students have negative emotional reactions to seeing 'angry red text'. Not utilizing programming error and warning messages effectively, or at all, increases the difficulty of learning to program.As compiler messages can vary by programming language and/or development environment, lessons on reading them are not typically included in mainstream educational materials. We believe this gap can be filled and that students can learn to use error messages to their advantage. Further, we believe that teaching students how to read and use error messages can have a significant impact on the learning experience for novice programmers.The goal of this working group is to develop educational materials to teach students to use programming error messages, and evaluate the use of these materials. An additional goal is to investigate the role that large language models may play in the interpretation of error messages in the educational environment. We will produce guidelines for developing educational materials and strategies informed by feedback obtained from the community and our experimentation.",Proceedings of the ACM Conference on Global Computing Education Vol 2,207–208,2,"computer error messages, computing education, error messages, novice programmers, programming error messages, runtime errors, warning messages","Hyderabad, India",CompEd 2023,inproceedings,,,,,,,,,,
"Leinonen, Juho and Denny, Paul and MacNeil, Stephen and Sarsa, Sami and Bernstein, Seth and Kim, Joanne and Tran, Andrew and Hellas, Arto",Comparing Code Explanations Created by Students and Large Language Models,2023,9798400701382,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587102.3588785,10.1145/3587102.3588785,"Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n ≈ 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,124–130,7,"CS1, ChatGPT, GPT-3, GPT-4, code comprehension, code explanations, foundation models, large language models, natural language generation, resource generation","Turku, Finland",ITiCSE 2023,inproceedings,,,,,,,,,,
"Denny, Paul and Kumar, Viraj and Giacaman, Nasser",Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language,2023,9781450394314,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3545945.3569823,10.1145/3545945.3569823,"GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,1136–1142,7,"artificial intelligence, cs1, foundation models, github copilot, introductory programming, large language models, openai","Toronto ON, Canada",SIGCSE 2023,inproceedings,,,,,,,,,,
,On the Helpfulness of Answering Developer Questions on Discord with Similar Conversations and Posts from the Past,2024,9798400702174,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3597503.3623341,10.1145/3597503.3623341,"A big part of software developers' time is spent finding answers to their coding-task-related questions. To answer their questions, developers usually perform web searches, ask questions on Q&amp;A websites, or, more recently, in chat communities. Yet, many of these questions have frequently already been answered in previous chat conversations or other online communities. Automatically identifying and then suggesting these previous answers to the askers could, thus, save time and effort. In an empirical analysis, we first explored the frequency of repeating questions on the Discord chat platform and assessed our approach to identify them automatically. The approach was then evaluated with real-world developers in a field experiment, through which we received 142 ratings on the helpfulness of the suggestions we provided to help answer 277 questions that developers posted in four Discord communities. We further collected qualitative feedback through 53 surveys and 10 follow-up interviews. We found that the suggestions were considered helpful in 40% of the cases, that suggesting Stack Overflow posts is more often considered helpful than past Discord conversations, and that developers have difficulties describing their problems as search queries and, thus, prefer describing them as natural language questions in online communities.",Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,,13,"developer questions, chat community, semantic similarity","Lisbon, Portugal",ICSE '24,inproceedings,58,,,,,,,,,
"Kimmel, Bailey and Geisert, Austin Lee and Yaro, Lily and Gipson, Brendan and Hotchkiss, Ronald Taylor and Osae-Asante, Sidney Kwame and Vaught, Hunter and Wininger, Grant and Yamaguchi, Chase",Enhancing Programming Error Messages in Real Time with Generative AI,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3647967,10.1145/3613905.3647967,"Generative AI is changing the way that many disciplines are taught, including computer science. Researchers have shown that generative AI tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using generative AI to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via GPT-4. We extend this work by implementing feedback from ChatGPT for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding generative AI to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that GPT-4 provided.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"AI, Artificial Intelligence, Automatic Code Generation, CS1, ChatGPT, Codex, Copilot, GPT-4, GitHub, HCI, Introductory Programming, LLM, Large Language Models, Novice Programming, OpenAI","
",CHI EA '24,inproceedings,608,,,,,,,,,
,GitBug-Actions: Building Reproducible Bug-Fix Benchmarks with GitHub Actions,2024,9798400705021,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639478.3640023,10.1145/3639478.3640023,"Bug-fix benchmarks are fundamental in advancing various sub-fields of software engineering such as automatic program repair (APR) and fault localization (FL). A good benchmark must include recent examples that accurately reflect technologies and development practices of today. To be executable in the long term, a benchmark must feature test suites that do not degrade overtime due to, for example, dependencies that are no longer available. Existing benchmarks fail in meeting both criteria. For instance, Defects4J, one of the foremost Java benchmarks, last received an update in 2020. Moreover, full-reproducibility has been neglected by the majority of existing benchmarks. In this paper, we present GitBug-Actions: a novel tool for building bug-fix benchmarks with modern and fully-reproducible bug-fixes. GitBug-Actions relies on the most popular CI platform, GitHub Actions, to detect bug-fixes and smartly locally execute the CI pipeline in a controlled and reproducible environment. To the best of our knowledge, we are the first to rely on GitHub Actions to collect bug-fixes. To demonstrate our toolchain, we deploy GitBug-Actions to build a proof-of-concept Go bug-fix benchmark containing executable, fully-reproducible bug-fixes from different repositories. A video demonstrating GitBug-Actions is available at: https://youtu.be/aBWwa1sJYBs.",Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings,1–5,5,"software bugs, bug benchmark, bug database, reproducibility, software testing, program analysis, github actions","Lisbon, Portugal",ICSE-Companion '24,inproceedings,,,,,,,,,,
"Jamal, Rifa and Renzella, Jake",Enhancing Formative Feedback at Scale with the Intelligent Feedback Assistant,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635482,10.1145/3626253.3635482,"Formative feedback spans various domains, from education to businesses and creative endeavours. In educational contexts, feedback enriches students' learning and work quality through reflection. However, providing effective feedback at scale is challenging. Students struggle to engage with feedback, often due to lack of feedback literacy. Recent advancements in Natural Language Processing, a branch of Artificial Intelligence, provides opportunities to evaluate how we can support feedback providers in its quality and scale. This poster paper presents an overview of key feedback challenges, attributes of high quality feedback, and introduces the Intelligent Feedback Assistant (IFA), an innovative NLP-based system designed to assist educators in delivering high-quality feedback. IFA operates as an ensemble of machine learning models and non-AI systems to guide educators in refining their feedback, ensuring it embodies attributes of effective feedback - actionable, specific, justified, and positive. IFA is supportive, not generative, ensuring the feedback provider remains central to the feedback provision process. The tool design, and outcomes of IFA offers a promising path for scaleable, high-quality formative feedback in education and beyond.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1692–1693,2,"ai in education, natural language processing, student feedback","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Pinto, Gustavo and Cardoso-Pereira, Isadora and Monteiro, Danilo and Lucena, Danilo and Souza, Alberto and Gama, Kiev",Large Language Models for Education: Grading Open-Ended Questions Using ChatGPT,2023,9798400707872,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613372.3614197,10.1145/3613372.3614197,"As a way of addressing increasingly sophisticated problems, software professionals face the constant challenge of seeking improvement. However, for these individuals to enhance their skills, their process of studying and training must involve feedback that is both immediate and accurate. In the context of software companies, where the scale of professionals undergoing training is large, but the number of qualified professionals available for providing corrections is small, delivering effective feedback becomes even more challenging. To circumvent this challenge, this work presents an exploration of using Large Language Models (LLMs) to support the correction process of open-ended questions in technical training. In this study, we utilized ChatGPT to correct open-ended questions answered by 42 industry professionals on two topics. Evaluating the corrections and feedback provided by ChatGPT, we observed that it is capable of identifying semantic details in responses that other metrics cannot observe. Furthermore, we noticed that, in general, subject matter experts tended to agree with the corrections and feedback given by ChatGPT.",Proceedings of the XXXVII Brazilian Symposium on Software Engineering,293–302,10,"Automated grading, ChatGPT, Open-ended Questions","Campo Grande, Brazil",SBES '23,inproceedings,,,,,,,,,,
"Lo, Priscilla Y.",An Autoethnographic Reflection of Prompting a Custom GPT Based on Oneself,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3651096,10.1145/3613905.3651096,"What if you could have a chat with yourself? OpenAI’s introduction of custom GPTs in November 2023 provides an opportunity for non-technical users to create specialized generative artificial intelligence chatbots. Users can write prompts in plain language rather than code to instruct how the system should behave. What can one learn from using non-technical methods to develop a specific chatbot persona? To explore this, I conducted an autoethnography of my experience developing and interacting with a custom GPT based on myself. My findings include a discussion of my experiences throughout the process, and its impact on my personal introspection and understanding of prompt engineering. I summarize first-hand challenges and insights intended to inspire further discussion on the topic of generative AI and chatbots.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,9,"autoethnography, chatbot, generative artificial intelligence, large language model, persona","
",CHI EA '24,inproceedings,40,,,,,,,,,
"Cai, Runze and Janaka, Nuwan and Chen, Yang and Wang, Lucia and Zhao, Shengdong and Liu, Can",PANDALens: Towards AI-Assisted In-Context Writing on OHMD During Travels,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642320,10.1145/3613904.3642320,"While effective for recording and sharing experiences, traditional in-context writing tools are relatively passive and unintelligent, serving more like instruments rather than companions. This reduces primary task (e.g., travel) enjoyment and hinders high-quality writing. Through formative study and iterative development, we introduce PANDALens, a Proactive AI Narrative Documentation Assistant built on an Optical See-Through Head Mounted Display that supports personalized documentation in everyday activities. PANDALens observes multimodal contextual information from user behaviors and environment to confirm interests and elicit contemplation, and employs Large Language Models to transform such multimodal information into coherent narratives with significantly reduced user effort. A real-world travel scenario comparing PANDALens with a smartphone alternative confirmed its effectiveness in improving writing quality and travel enjoyment while minimizing user effort. Accordingly, we propose design guidelines for AI-assisted in-context writing, highlighting the potential of transforming them from tools to intelligent companions.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,24,"AI, HMD, Human-AI collaborative writing, in-context writing, large language model, multimodal information, smart glasses, travel blog","Honolulu, HI, USA",CHI '24,inproceedings,1053,,,,,,,,,
"Edwards, Chris",Teaching Transformed,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3637208,10.1145/3637208,The apparent ability of LLMs to write functioning source code has caused celebration over the potential for massive increases in programmer productivity and consternation among teachers.,,12–13,2,,,,article,,February 2024,67,2,Commun. ACM,jan,0001-0782,,,
"McDonald, Jennifer",Interactive Pushdown Automata Animation,2002,1581134738,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/563340.563489,10.1145/563340.563489,"This paper will present the Interactive Pushdown Automata Animation for use in an Automata Theory class. It will present the features of the IPAA as well as the algorithm and data model used. Finally, this article will outline the necessary pieces of a good visual tool and show how they are implemented in the IPAA.",Proceedings of the 33rd SIGCSE Technical Symposium on Computer Science Education,376–380,5,,"Cincinnati, Kentucky",SIGCSE '02,inproceedings,,,,,,,,,,
"Wang, Bo and Li, Ruishi and Li, Mingkai and Saxena, Prateek",TransMap: Pinpointing Mistakes in Neural Code Translation,2023,9798400703270,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3611643.3616322,10.1145/3611643.3616322,"Automated code translation between programming languages can greatly reduce the human effort needed in learning new languages or in migrating code. Recent neural machine translation models, such as Codex, have been shown to be effective on many code generation tasks including translation. However, code produced by neural translators often has semantic mistakes. These mistakes are difficult to eliminate from the neural translator itself because the translator is a black box, which is difficult to interpret or control compared to rule-based transpilers. We propose the first automated approach to pinpoint semantic mistakes in code obtained after neural code translation. Our techniques are implemented in a prototype tool called TransMap which translates Python to JavaScript, both of which are popular scripting languages. On our created micro-benchmarks of Python programs with 648 semantic mistakes in total, TransMap accurately pinpoints the correct location for a fix for 87.96%, often highlighting 1-2 lines for the user to inspect per mistake. We report on our experience in translating 5 Python libraries with up to 1k lines of code with TransMap. Our preliminary user study suggests that TransMap can reduce the time for fixing semantic mistakes by around 70% compared to using a standard IDE with debuggers.",Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,999–1011,13,"Code Translation, Large Language Models, Semantic Mistakes","San Francisco, CA, USA",ESEC/FSE 2023,inproceedings,,,,,,,,,,
"Weber, Jason Lee and Martinez Neda, Barbara and Carbajal Juarez, Kitana and Wong-Ma, Jennifer and Gago-Masague, Sergio and Ziv, Hadar",Measuring CS Student Attitudes Toward Large Language Models,2024,9798400704246,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626253.3635604,10.1145/3626253.3635604,"With the mainstream adoption of Large Language Models (LLMs), members of both academia and the media have raised concerns around their impact on student learning and pedagogy. Many students and educators wonder about the pedagogical fit of this emerging technology. We aim to measure the adoption of and attitudes toward LLMs among the CS student population at an R1 University to determine how students are using these new tools. To this end, we conducted a large survey study targeting two populations participating in computing courses at the university: intro-sequence students (ISS) and experienced students (ES).In our preliminary results from Spring 2023, we've found several significant differences among the views of over 700 respondents across the two groups. Most students reported LLMs' unparalleled potential for quick information access, yet many harbor concerns about the reliability of the LLM responses, and the impact on academic integrity. Additionally, while ES have rapidly integrated LLMs into their learning, ISS remain cautious of the tools, highlighting a stark contrast in adoption rates between the groups.LLMs are clearly going to reshape pedagogical approaches and student engagement. Our study hopes to provide insight on the nuanced student attitudes toward LLMs. For example, the notable reservations expressed by ISS illustrate an imperative for careful, informed, and ethical integration to ensure these tools enhance rather than compromise the educational experience. In the future, we plan to continue tracking student attitudes in order to gain further understanding of the changing perceptions of LLMs and their impact.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,1846–1847,2,"academic integrity, ai tools, chatgpt, faculty perception, generative ai, large language models (llms), student perception","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Reeves, Brent and Sarsa, Sami and Prather, James and Denny, Paul and Becker, Brett A. and Hellas, Arto and Kimmel, Bailey and Powell, Garrett and Leinonen, Juho",Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations,2023,9798400701382,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587102.3588805,10.1145/3587102.3588805,"The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,299–305,7,"CS1, GPT-3, GitHub, ML, academic integrity, ai, artificial intelligence, chatgpt, code generation, code writing, codex, computer programming, copilot, deep learning, generative ai, introductory programming, large language models, machine learning, natural language processing, neural networks, novice programming, openAI","Turku, Finland",ITiCSE 2023,inproceedings,,,,,,,,,,
"Chen, John and Lu, Xi and Du, Yuzhou and Rejtig, Michael and Bagley, Ruth and Horn, Mike and Wilensky, Uri",Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642377,10.1145/3613904.3642377,"Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"Agent-based Modeling, ChatGPT, LLM Companion, Learning with LLMs, NetLogo Chat, Programming Assistant","Honolulu, HI, USA",CHI '24,inproceedings,141,,,,,,,,,
"Buryakov, Daniil and Kovacs, Mate and Serd\",A Multi-Label Classifier for Online Petition Systems,2024,9798400709883,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3657054.3657250,10.1145/3657054.3657250,"Online petitions are an important means for citizens to express their concerns and to interact with government entities. Due to the increase in the number of petitions, manually attributing them to the competent unit in public administration creates a bottleneck, leading to response delays, and potentially even errors. To address this problem, a multi-label classifier using fine-tuned BERT model is suggested. The proposed model, trained on a dataset from the Taiwanese Join Platform, performs reasonably well in predicting the governmental departments in charge of petitions, even when trained on an imbalanced and rather small dataset. The obtained model manages to effectively process petitions and predicts responsible departments, achieving F1 score of 0.61 averaged over 12 categories. The proposed approach would potentially improve government responsiveness, optimize resource allocation, and facilitate online petition processing. Future work would focus on improving the model’s generalization capabilities.",Proceedings of the 25th Annual International Conference on Digital Government Research,156–164,9,"E-Governance, Large Language Model, Machine Learning, Multi-Labeling, Online Petitions","Taipei, Taiwan",dg.o '24,inproceedings,,,,,,,,,,
"Huang, Qing and Zhu, Jiahui and Li, Zhilong and Xing, Zhenchang and Wang, Changjing and Xu, Xiwei",PCR-Chain: Partial Code Reuse Assisted by Hierarchical Chaining of Prompts on Frozen Copilot,2023,9798350322637,IEEE Press,,https://doi.org/10.1109/ICSE-Companion58688.2023.00013,10.1109/ICSE-Companion58688.2023.00013,"API documentation, technical blogs and programming Q&amp;A sites contain a large amount of partial code that can be reused in programming tasks. However, due to unresolved simple names and last-mile syntax errors, such partial code is frequently not compilable. To facilitate partial code reuse, we develop PCR-Chain for resolving FQNs and fixing last-mile syntax errors in partial code based on a giant pre-trained code model (e.g., Copilot). Methodologically, PCR-Chain is backed up by the underlying global-level prompt architecture (which combines three design ideas: hierarchical task breakdown, prompt composition including sequential and conditional structures, and a mix of prompt-based AI and non-AI units) and the local-level prompt design. Technically, we propose PCR-Chain, which employs in-context learning rather than supervised fine-tuning with gradient updates on downstream task data. This approach enables the frozen, giant pre-trained code model to learn the desired behavior for a specific task through behavior-describing prompts and imitate it to complete the task. Experimental results show that PCR-Chain automatically resolves the FQNs and fixes last-mile syntax errors in 50 partial code samples collected from Stack Overflow with high success rates, without requiring any program analysis. The correct execution of the unit, module, and PCR-Chain demonstrates the effectiveness of the prompt design, prompt composition, and prompt architecture.Website:https://github.com/SE-qinghuang/PCR-ChainDemo Video: https://youtu.be/6HGRNdc2_JE",Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings,1–5,5,"in-context learning, pre-trained language model, frozen copilot, AI chain, hierarchical prompts","Melbourne, Victoria, Australia",ICSE '23,inproceedings,,,,,,,,,,
"Wester, Joel and Schrills, Tim and Pohl, Henning and van Berkel, Niels","“As an AI language model, I cannot”: Investigating LLM Denials of User Requests",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642135,10.1145/3613904.3642135,"Users ask large language models (LLMs) to help with their homework, for lifestyle advice, or for support in making challenging decisions. Yet LLMs are often unable to fulfil these requests, either as a result of their technical inabilities or policies restricting their responses. To investigate the effect of LLMs denying user requests, we evaluate participants’ perceptions of different denial styles. We compare specific denial styles (baseline, factual, diverting, and opinionated) across two studies, respectively focusing on LLM’s technical limitations and their social policy restrictions. Our results indicate significant differences in users’ perceptions of the denials between the denial styles. The baseline denial, which provided participants with brief denials without any motivation, was rated significantly higher on frustration and significantly lower on usefulness, appropriateness, and relevance. In contrast, we found that participants generally appreciated the diverting denial style. We provide design recommendations for LLM denials that better meet peoples’ denial expectations.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,14,"Breakdowns, Denials, Errors, GPT-4, Large Language Models","Honolulu, HI, USA",CHI '24,inproceedings,979,,,,,,,,,
"Amoozadeh, Matin and Daniels, David and Nam, Daye and Kumar, Aayush and Chen, Stella and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Mohammad Amin",Trust in Generative AI among Students: An exploratory study,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630842,10.1145/3626252.3630842,"Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,67–73,7,"generative ai, novice programmers, trust","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
"Li, Tiffany Wenting and Hsu, Silas and Fowler, Max and Zhang, Zhilin and Zilles, Craig and Karahalios, Karrie","Am I Wrong, or Is the Autograder Wrong? Effects of AI Grading Mistakes on Learning",2023,9781450399760,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3568813.3600124,10.1145/3568813.3600124,"Errors in AI grading and feedback often have an intractable set of causes and are, by their nature, difficult to completely avoid. Since inaccurate feedback potentially harms learning, there is a need for designs and workflows that mitigate these harms. To better understand the mechanisms by which erroneous AI feedback impacts students’ learning, we conducted surveys and interviews that recorded students’ interactions with a short-answer AI autograder for “Explain in Plain English” code reading problems. Using causal modeling, we inferred the learning impacts of wrong answers marked as right (false positives, FPs) and right answers marked as wrong (false negatives, FNs). We further explored explanations for the learning impacts, including errors influencing participants’ engagement with feedback and assessments of their answers’ correctness, and participants’ prior performance in the class. FPs harmed learning in large part due to participants’ failures to detect the errors. This was due to participants not paying attention to the feedback after being marked as right, and an apparent bias against admitting one’s answer was wrong once marked right. On the other hand, FNs harmed learning only for survey participants, suggesting that interviewees’ greater behavioral and cognitive engagement protected them from learning harms. Based on these findings, we propose ways to help learners detect FPs and encourage deeper reflection on FNs to mitigate the learning harms of AI errors.",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,159–176,18,"AI error, Bayesian modeling, EiPE, autograder, automated short answer grading, computer science education, explain in plain English, formative feedback, human-AI interaction","Chicago, IL, USA",ICER '23,inproceedings,,,,,,,,,,
"Jamil, Hasan M.",Smart Science Needs Linked Open Data with a Dash of Large Language Models and Extended Relations,2024,9798400706806,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3663742.3663971,10.1145/3663742.3663971,"Quality scientific inquiries depend on access to data distributed over the entire globe. Linked open data (LOD) and FAIRness play major roles in ensuring access to data that scientists need to answer interesting questions. However, a data model and a query language to compute responses to complex scientific inquiries remain outstanding. As the recent emergence of large language models (LLM) reshape how we interact with machines, an intriguing prospect of posing scientific inquiries to smart machines suddenly appears realizable in which a natural language ChatBot is empowered with a LOD knowledgebase as its data source. In this paper, we introduce a model for an LLM interpreter, called ProAb, that aims to answer natural language scientific queries using a structured query language called Needle in which the LOD is viewed as a set of tables. We discuss the contours of ProAb, present its preliminary and experimental design, and highlight its salient features using an illustrative example. It should be apparent that a full automation of ProAb is feasible with further research.",Proceedings of the Seventh International Workshop on Exploiting Artificial Intelligence Techniques for Data Management,,11,"Extended Relational Model, Intelligent User Interface, Large Language Model, Query Processing, Structured Query Language","Santiago, AA, Chile",aiDM '24,inproceedings,1,,,,,,,,,
"Ash, Elliott and Kesari, Aniket and Naidu, Suresh and Song, Lena and Stammbach, Dominik",Translating Legalese: Enhancing Public Understanding of Court Opinions with Legal Summarizers,2024,9798400703331,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3614407.3643700,10.1145/3614407.3643700,"Judicial opinions are written to be persuasive and could build public trust in court decisions, yet they can be difficult for non-experts to understand. We present a pipeline for using an AI assistant to generate simplified summaries of judicial opinions. Compared to existing expert-written summaries, these AI-generated simple summaries are more accessible to the public and more easily understood by non-experts. We show in a survey experiment that the AI summaries help respondents understand the key features of a ruling, and have higher perceived quality, especially for respondents with less formal education.",Proceedings of the Symposium on Computer Science and Law,136–157,22,,"Boston, MA, USA",CSLAW '24,inproceedings,,,,,,,,,,
"Sharma, Nikhil and Liao, Q. Vera and Xiao, Ziang",Generative Echo Chamber? Effect of LLM-Powered Search Systems on Diverse Information Seeking,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642459,10.1145/3613904.3642459,"Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search. However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers—limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search. We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user’s view change the effect. Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias. These results present critical implications for the development of LLMs and conversational search systems, and the policy governing these technologies.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"Confirmation Bias, Conversational Search, Echo Chamber Effect, Generative AI, Information Diversity, Information Seeking, Large Language Models","Honolulu, HI, USA",CHI '24,inproceedings,1033,,,,,,,,,
,MSR4P&amp;S 2022: Proceedings of the 1st International Workshop on Mining Software Repositories Applications for Privacy and Security,2022,9781450394574,Association for Computing Machinery,"New York, NY, USA",,,"On behalf of the Program Committee, we are pleased to present the proceedings of the 1st International Workshop on Mining Software Repositories for Privacy and Security (MSR4P&amp;S 2022). MSR4P&amp;S is co-located with the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE). This year, because of the Covid-19 pandemic, MSR4P&amp;S (as part of ESEC/FSE) is held virtually with an adapted program that will bring together international researchers to exchange ideas, share experiences, investigate problems, and propose promising solutions concerning the application of Mining Software Repositories (MSR) to investigate the different stages of privacy and security. The workshop topics cover a wide range of MSR applications for cybersecurity research, including empirical and mixed-method approaches, as well as datasets and tools.",,,,,"Singapore, Singapore",,proceedings,,,,,,,,,,
"Akgun, Mahir and Sharma, Priya and Li, Qiyuan",Can Lexical Sophistication and Cohesion Automatically Differentiate Student Engagement in Socio-technical Platforms?,2024,9798400704239,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626252.3630800,10.1145/3626252.3630800,"This work aims to better analyze student engagement in socio-technical platforms by investigating whether the language students produce in online discussions is an indication of their cognitive engagement in collaborative activities. Primarily, this study evaluates whether a combination of linguistic features related to lexical sophistication and cohesion can capture students' cognitive engagement levels in an online course. We downloaded and annotated posts from the online platform for an undergraduate information sciences and technology course to create the human-coded dataset. Then, we assessed the lexical sophistication and cohesion of human-annotated posts and used lexical sophistication and cohesion indices in multivariate analysis of variance (MANOVA). A subsequent analysis using discriminant function analysis (DFA) suggested that the discriminant functions obtained from the human-annotated posts indicate a distinction between cognitive engagement categories. While the DFA model developed using cohesion indices shows a clear separation between cognitive engagement categories, the model built on lexical sophistication indices provides a partial separation. Study results suggest a promising approach for the application of linguistic features to support the categorization of discourse based on cognitive engagement.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,25–31,7,"cognitive engagement, cohesion, collaborative learning, lexical sophistication, linguistic features","Portland, OR, USA",SIGCSE 2024,inproceedings,,,,,,,,,,
,Towards Using Few-Shot Prompt Learning for Automating Model Completion,2023,9798350300390,IEEE Press,,https://doi.org/10.1109/ICSE-NIER58687.2023.00008,10.1109/ICSE-NIER58687.2023.00008,We propose a simple yet a novel approach to improve completion in domain modeling activities. Our approach exploits the power of large language models by using few-shot prompt learning without the need to train or fine-tune those models with large datasets that are scarce in this field. We implemented our approach and tested it on the completion of static and dynamic domain diagrams. Our initial evaluation shows that such an approach is effective and can be integrated in different ways during the modeling activities.,Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results,7–12,6,"language models, few-shot learning, prompt learning, domain modeling, model completion","Melbourne, Australia",ICSE-NIER '23,inproceedings,,,,,,,,,,
"Kazemitabaar, Majeed and Hou, Xinying and Henley, Austin and Ericson, Barbara Jane and Weintrop, David and Grossman, Tovi",How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment,2024,9798400716539,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3631802.3631806,10.1145/3631802.3631806,"As Large Language Models (LLMs) gain in popularity, it is important to understand how novice programmers use them and the effect they have on learning to code. We present the results of a thematic analysis on a data set from 33 learners, aged 10-17, as they independently learned Python by working on 45 code-authoring tasks with access to an AI Code Generator based on OpenAI Codex. We explore several important questions related to how learners used LLM-based AI code generators, and provide an analysis of the properties of the written prompts and the resulting AI generated code. Specifically, we explore (A) the context in which learners use Codex, (B) what learners are asking from Codex in terms of syntax and logic, (C) properties of prompts written by learners in terms of relation to task description, language, clarity, and prompt crafting patterns, (D) properties of the AI-generated code in terms of correctness, complexity, and accuracy, and (E) how learners utilize AI-generated code in terms of placement, verification, and manual modifications. Furthermore, our analysis reveals four distinct coding approaches when writing code with an AI code generator: AI Single Prompt, where learners prompted Codex once to generate the entire solution to a task; AI Step-by-Step, where learners divided the problem into parts and used Codex to generate each part; Hybrid, where learners wrote some of the code themselves and used Codex to generate others; and Manual coding, where learners wrote the code themselves. Our findings reveal consistently positive trends between learners’ utilization of the Hybrid coding approach and their post-test evaluation scores, while showing consistent negative trends between the AI Single Prompt and the post-test evaluation scores. Furthermore, we offer insights into novice learners’ use of AI code generators in a self-paced learning environment, highlighting signs of over-reliance, self-regulation, and opportunities for enhancing AI-assisted learning tools.",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,,12,"ChatGPT, Copilot, Introductory Programming, Large Language Models, OpenAI Codex, Self-paced Learning, Self-regulation","Koli, Finland",Koli Calling '23,inproceedings,3,,,,,,,,,
"Hedderich, Michael A. and Bazarova, Natalie N. and Zou, Wenting and Shim, Ryun and Ma, Xinda and Yang, Qian",A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642379,10.1145/3613904.3642379,"Cyberbullying harms teenagers’ mental health, and teaching them upstanding intervention is crucial. Wizard-of-Oz studies show chatbots can scale up personalized and interactive cyberbullying education, but implementing such chatbots is a challenging and delicate task. We created a no-code chatbot design tool for K-12 teachers. Using large language models and prompt chaining, our tool allows teachers to prototype bespoke dialogue flows and chatbot utterances. In offering this tool, we explore teachers’ distinctive needs when designing chatbots to assist their teaching, and how chatbot design tools might better support them. Our findings reveal that teachers welcome the tool enthusiastically. Moreover, they see themselves as playwrights guiding both the students’ and the chatbot’s behaviors, while allowing for some improvisation. Their goal is to enable students to rehearse both desirable and undesirable reactions to cyberbullying in a safe environment. We discuss the design opportunities LLM-Chains offer for empowering teachers and the research opportunities this work opens up.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"chatbot, cyberbullying, education, large language models, teachers","Honolulu, HI, USA",CHI '24,inproceedings,668,,,,,,,,,
"Zhang, Zhiping and Jia, Michelle and Lee, Hao-Ping (Hank) and Yao, Bingsheng and Das, Sauvik and Lerner, Ada and Wang, Dakuo and Li, Tianshi","“It's a Fair Game”, or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642385,10.1145/3613904.3642385,"The widespread use of Large Language Model (LLM)-based conversational agents (CAs), especially in high-stakes domains, raises many privacy concerns. Building ethical LLM-based CAs that respect user privacy requires an in-depth understanding of the privacy risks that concern users the most. However, existing research, primarily model-centered, does not provide insight into users’ perspectives. To bridge this gap, we analyzed sensitive disclosures in real-world ChatGPT conversations and conducted semi-structured interviews with 19 LLM-based CA users. We found that users are constantly faced with trade-offs between privacy, utility, and convenience when using LLM-based CAs. However, users’ erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks. Additionally, the human-like interactions encouraged more sensitive disclosures, which complicated users’ ability to navigate the trade-offs. We discuss practical design guidelines and the needs for paradigm shifts to protect the privacy of LLM-based CA users.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,26,"Artificial general intelligence (AGI), Chatbots, Contextual integrity, Conversational agents, Empirical studies, Interviews, Large language models (LLM), Privacy, Privacy risks, Privacy-enhancing technologies","Honolulu, HI, USA",CHI '24,inproceedings,156,,,,,,,,,
"Keelawat, Panayu",NBGuru: Generating Explorable Data Science Flowcharts to Facilitate Asynchronous Communication in Interdisciplinary Data Science Teams,2023,9798400701290,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3584931.3607020,10.1145/3584931.3607020,"Data scientists typically work with domain experts in a Data Science (DS) project, resulting in knowledge gaps between roles. Communication holds an immense and difficult workload due to the complicated content, limited meeting time, vast audience backgrounds, etc. Thus, it is almost impossible to build a common ground within the team. Taking a step back, flowcharts and program descriptions have shown to help programmers learn algorithms. However, drawing a flowchart or writing a description takes time and effort. The novel AI-powered search engines can generate elaborate grounded responses with citations. It is then possible to generate flowcharts with text descriptions from code. Therefore, we studied 92 DS flowcharts and 173 code descriptions from top-voted Kaggle notebooks. We propose NBGuru, a flowchart-based communication tool. Users can explore computation steps asynchronously with generated texts and citations. Furthermore, we also discuss the possibility of AI in other collaborative roles.",Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing,6–11,6,"artificial intelligence, asynchronous communication, collaboration, computational notebooks, data science, flowchart, interdisciplinary, large language model, on-the-job training","Minneapolis, MN, USA",CSCW '23 Companion,inproceedings,,,,,,,,,,
"Molodtsov, Fillip and Nikiforova, Anastasija",An Integrated Usability Framework for Evaluating Open Government Data Portals: Comparative Analysis of EU and GCC Countries,2024,9798400709883,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3657054.3657159,10.1145/3657054.3657159,"This study explores the critical role of open government data (OGD) portals in fostering transparency and collaboration between diverse stakeholders. Recognizing the challenges of usability, communication with diverse populations, and strategic value creation, this paper develops an integrated framework for evaluating OGD portal effectiveness that accommodates user diversity (regardless of their data literacy and language), evaluates collaboration and participation, and opportunities to explore and understand the data provided through them. The framework is validated by applying it to 33 national portals across European Union and Gulf Cooperation Council (GCC) countries, as a result of which we rank OGD portals, identify some good practices that lower-performing portals can learn from, and common shortcomings. The study unveils the competitive and innovative nature of GCC OGD portals, pinpointing specific improvement areas such as multilingual support and data understandability. The findings underscore the growing trend of exposing data quality metrics and advocate for enhanced two-way communication channels between users and portal representatives. Overall, the study contributes to accelerating the development of user-friendly, collaborative, and sustainable OGD portals while addressing gaps identified in previous research.",Proceedings of the 25th Annual International Conference on Digital Government Research,899–908,10,"European Union, Framework, GCC, Gulf Cooperation Council, OGD portal, Open data, Open data ecosystem, Open data portal, Open government data, Open government data portal, Sustainability, Usability","Taipei, Taiwan",dg.o '24,inproceedings,,,,,,,,,,
,CompEd 2023: Proceedings of the ACM Conference on Global Computing Education Vol 2,2023,9798400703744,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to welcome participants to the 2nd ACM Global Conference on Computing Education (ACM CompEd 2023) being held in Hyderabad, India, 7th-9th December, 2023 with the Working Groups meetings being held on 5th and 6th December 2023.ACM CompEd is a recent addition to the list of ACM sponsored conferences devoted to research in all aspects of computing education, including education at the school and college levels. The Hyderabad edition is only the second in this promising series. The long hiatus due to Covid-19 pushed this conference by two years, but we are glad that it is finally here!This edition of ACM CompEd partly overlaps with COMPUTE 2023, ACM India's flagship conference on Computing Education. Having the two conferences adjacent to each other is a great way to build synergy between the Indian computing education community and the global community of computing education researchers.",,,,,"Hyderabad, India",,proceedings,,,,,,,,,,
"Ferrara, Carmine and Casillo, Francesco and Gravino, Carmine and De Lucia, Andrea and Palomba, Fabio",ReFAIR: Toward a Context-Aware Recommender for Fairness Requirements Engineering,2024,9798400702174,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3597503.3639185,10.1145/3597503.3639185,"Machine learning (ML) is increasingly being used as a key component of most software systems, yet serious concerns have been raised about the fairness of ML predictions. Researchers have been proposing novel methods to support the development of fair machine learning solutions. Nonetheless, most of them can only be used in late development stages, e.g., during model training, while there is a lack of methods that may provide practitioners with early fairness analytics enabling the treatment of fairness throughout the development lifecycle. This paper proposes ReFair, a novel context-aware requirements engineering framework that allows to classify sensitive features from User Stories. By exploiting natural language processing and word embedding techniques, our framework first identifies both the use case domain and the machine learning task to be performed in the system being developed; afterward, it recommends which are the context-specific sensitive features to be considered during the implementation. We assess the capabilities of ReFair by experimenting it against a synthetic dataset---which we built as part of our research---composed of 12,401 User Stories related to 34 application domains. Our findings showcase the high accuracy of ReFair, other than highlighting its current limitations.",Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,,12,"software fairness, machine learning, requirements engineering","Lisbon, Portugal",ICSE '24,inproceedings,213,,,,,,,,,
,Towards Understanding the Geospatial Skills of ChatGPT: Taking a Geographic Information Systems (GIS) Exam,2023,9798400703485,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3615886.3627745,10.1145/3615886.3627745,"This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and ability to grasp geospatial concepts by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3% (GPT-3.5) and 88.3% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.",Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery,85–94,10,"ChatGPT, GIS, Generative AI, Large Language Models, education, foundation model, geospatial","Hamburg, Germany",GeoAI '23,inproceedings,,,,,,,,,,
"Steenstra, Ian and Murali, Prasanth and Perkins, Rebecca B. and Joseph, Natalie and Paasche-Orlow, Michael K and Bickmore, Timothy",Engaging and Entertaining Adolescents in Health Education Using LLM-Generated Fantasy Narrative Games and Virtual Agents,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650983,10.1145/3613905.3650983,"Games have been successfully used to provide engaging health interventions for adolescents. However, translating health education goals into a playable game has historically taken many person-months of effort, involving game designers, scriptwriters, and artists. This work presents an exploratory study into rapidly developing physician-validated health education games for adolescents using virtual agents and LLMs. We evaluated this approach in an intervention to promote Human Papillomavirus (HPV) vaccination among adolescents, as lack of knowledge and vaccine hesitancy contribute to suboptimal HPV vaccination rates.We conducted a between-subjects randomized study comparing a fantasy narrative game to a non-gamified pedagogical virtual agent, with both interventions conveying the same HPV information. Among our study’s 9-12-year-old adolescent participants, our findings demonstrate large pre-to-post improvements in HPV knowledge for both conditions. The gamified intervention showed higher engagement and entertainment than the pedagogical agent based on participant interviews, demonstrating that gamification enriched the educational experience for adolescents.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,8,"Adolescents, ChatGPT, Gamification, Image Generation, Large Language Models (LLMs), Midjourney, Serious Games, Vaccination Promotion, Virtual Agents","
",CHI EA '24,inproceedings,126,,,,,,,,,
"Todd, Liam and Grundy, John and Treude, Christoph",GitHubInclusifier: Finding and fixing non-inclusive language in GitHub Repositories,2024,9798400705021,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639478.3640025,10.1145/3639478.3640025,"Non-inclusive language in software artefacts has been recognised as a serious problem. We describe a tool to find and fix non-inclusive language in a variety of GitHub repository artefacts. These include various README files, PDFs, code comments, and code. A wide variety of non-inclusive language including racist, ageist, ableist, violent and others are located and issues created, tagging the artefacts for checking. Suggested fixes can be generated using third-party LLM APIs, and approved changes made to documents, including code refactorings, and committed to the repository.The tool and evaluation data are available from: https://github.com/LiamTodd/github-inclusifierThe demo video is available at: https://www.youtube.com/watch?v=1z1QKdQg-nM",Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings,89–93,5,"inclusive language, refactoring, biased language, inappropriate language, software documentation, software maintenance tools","Lisbon, Portugal",ICSE-Companion '24,inproceedings,,,,,,,,,,
"Weidele, Daniel Karl I. and Martino, Mauro and Valente, Abel N. and Rossiello, Gaetano and Strobelt, Hendrik and Franke, Loraine and Alvero, Kathryn and Misko, Shayenna and Auer, Robin and Bagchi, Sugato and Mihindukulasooriya, Nandana and Chowdhury, Faisal and Bramble, Gregory and Samulowitz, Horst and Gliozzo, Alfio and Amini, Lisa",Empirical Evidence on Conversational Control of GUI in Semantic Automation,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645172,10.1145/3640543.3645172,"This research explores integration of a Large Language Model (LLM) fine-tuned to conversationally control the user interface (UI) for a Semantic Automation Layer (SAL). We condense SAL capabilities from prior work and prioritize with business analysts and data engineers via a Kano model, before implementing a prototypical UI. We augment the UI with our conversational engine and propose In-situ Prompt Engineering and learn from Human Feedback to smoothen the interaction and manipulation of UI through natural language commands. To evaluate the efficacy and usability of conversational control in various use-case scenarios, we conduct and report on an empirical interaction design user study. Our findings provide evidence supporting enhanced user engagement and satisfaction. We also observe significant increase of trust in AI after working with our conversational UI. This work generates areas for further refinement and research towards more intelligent, highly-integrated conversational UIs even beyond our application within Semantic Automation. We discuss our findings and point out next steps paving the way for future research and development in creating more intuitive and adaptive user interfaces.",Proceedings of the 29th International Conference on Intelligent User Interfaces,869–885,17,"Conversational Graphical User Interface, Empirical Interaction Design User Study, Fine-tuned large language model, In-situ Prompt Engineering for UI Control, Semantic Automation Layer","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
"Zhou, Jiawei and Zhang, Yixuan and Luo, Qianni and Parker, Andrea G and De Choudhury, Munmun",Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581318,10.1145/3544548.3581318,"Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work first examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found significant linguistic differences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a significant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,20,"AI-generated misinformation, COVID-19, GPT, generative AI, large language model, misinformation, responsible AI","Hamburg, Germany",CHI '23,inproceedings,436,,,,,,,,,
"Lee, Katherine and Cooper, A. Feder and Grimmelmann, James",Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain (The Short Version),2024,9798400703331,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3614407.3643696,10.1145/3614407.3643696,,Proceedings of the Symposium on Computer Science and Law,48–63,16,,"Boston, MA, USA",CSLAW '24,inproceedings,,,,,,,,,,
"Wang, Weizheng and Qiao, Hong",How Natural Language Processing Enables AIGC Recognition? --Latest Trends and Future Prospects,2024,9798400709197,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3647722.3647738,10.1145/3647722.3647738,"As the technology behind large language models advances rapidly, AI-generated content (AIGC) pervades our daily lives. Classifiers that identify AIGC play a crucial role in distinguishing between text generated by humans and that generated by artificial intelligence. In order to better prevent the abuse of AIGC and reduce the emergence of issues such as false information, academic misconduct, and deceptive comments, we introduced the task of AIGC classifiers, emphasizing the necessity of classifier development in this era. The essence of AIGC identification tasks lies in binary classification, aiming to discern whether a piece of content is created by artificial intelligence. In recent years, white-box and black-box methods as classifiers for identifying AIGC have made significant strides. In this paper, we curated the main research achievements in the field of AIGC identification, emphasizing the crucial role of comprehensive and excellent datasets in constructing AIGC recognition classifiers. Additionally, we explored the limitations and development goals of current popular datasets, as well as potential datasets. Furthermore, we analyzed paradigms of various classifiers, addressing challenges such as multidomain recognition tasks, cross-language recognition tasks, and data ambiguity issues. Finally, we proposed pathways for the future development of AIGC identification. This study aims to provide a clear overview for relevant researchers and offer constructive suggestions for constructing more stable and efficient classifiers.",Proceedings of the 2024 7th International Conference on Software Engineering and Information Management,103–109,7,"AIGC, Black box test, Deep learning, Machine -generated content detection, white box test","Suva, Fiji",ICSIM '24,inproceedings,,,,,,,,,,
"Turri, Violet and Dzombak, Rachel",Why We Need to Know More: Exploring the State of AI Incident Documentation Practices,2023,9798400702310,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3600211.3604700,10.1145/3600211.3604700,"To enable the development and use of safe and equitable artificial intelligence (AI) systems, AI engineers must monitor deployed AI systems and learn from past AI incidents where failures have occurred. Around the world, public databases for cataloging AI systems and resulting harms are instrumental in promoting awareness of potential AI harms among policymakers, researchers, and the public. However, despite growing recognition of the potential of AI systems to produce harms, causes of AI systems failure remain elusive and AI incidents continue to occur. For example, incidents of AI bias are frequently reported and discussed, yet biased systems continue to be developed and deployed. This raises the question – how are we learning from documented incidents? What information do we need to analyze AI incidents and develop new AI engineering best practices? This paper examines reporting techniques from a variety of AI stakeholders and across different industries, identifies requirements towards the design of effective AI incident documentation, and proposes policy recommendations for augmenting current practice.","Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",576–583,8,Explainable Artificial Intelligence,,AIES '23,inproceedings,,,,,,,,,,
"Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho",Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models,2022,9781450391948,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3501385.3543957,10.1145/3501385.3543957,"This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.",Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1,27–43,17,"Automated feedback, CS1, Code explanations, Exercise generation, GPT-3, Large language models, Natural language generation, OpenAI Codex, Programming exercises, Resource generation, Robosourcing","Lugano and Virtual Event, Switzerland",ICER '22,inproceedings,,,,,,,,,,
,PyDex: Repairing Bugs in Introductory Python Assignments using LLMs,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3649850,10.1145/3649850,"Students often make mistakes in their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex (a version of GPT), to build an APR system -- PyDex -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate PyDex on 286 real student programs and compare to three baselines, including one that combines a state-of-the-art Python syntax repair engine, BIFI, and a state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that PyDex can fix more programs and produce smaller patches on average.",,,25,"AI for programming education, automated program repair, large language models",,,article,133,April 2024,8,OOPSLA1,Proc. ACM Program. Lang.,apr,,,,
,CompEd 2023: Proceedings of the ACM Conference on Global Computing Education Vol 1,2023,9798400700484,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to welcome participants to the 2nd ACM Global Conference on Computing Education (ACM CompEd 2023) being held in Hyderabad, India, 7th-9th December, 2023 with the Working Groups meetings being held on 5th and 6th December 2023.ACM CompEd is a recent addition to the list of ACM sponsored conferences devoted to research in all aspects of computing education, including education at the school and college levels. The Hyderabad edition is only the second in this promising series. The long hiatus due to Covid-19 pushed this conference by two years, but we are glad that it is finally here!This edition of ACM CompEd partly overlaps with COMPUTE 2023, ACM India's flagship conference on Computing Education. Having the two conferences adjacent to each other is a great way to build synergy between the Indian computing education community and the global community of computing education researchers.",,,,,"Hyderabad, India",,proceedings,,,,,,,,,,
"Manley, Eric D.",Getting Started with Large Language Models for the CS Curriculum,2024,,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,"With the introduction of ChatGPT in late 2022, popular interest in language-based Artificial Intelligence has exploded. Employers are looking to hire computer scientists who can leverage large language models (LLMs) [2], and student demand for learning about them at many higher education institutions has followed. This one-hour workshop will help computer science educators respond to this demand by introducing the Python transformers library and its associated LLM ecosystem [1]. We will discuss how LLMs can be integrated into college computer science curricula from CS 1 through advanced courses in Artificial Intelligence, Machine Learning, or Natural Language Processing. Specific topics include• Using the transformers library with pre-trained models for inference tasks like sentiment analysis, text classification, summarization, translation, and question answering in only a few lines of code• Searching for and using hundreds of thousands of different pre-trained language models hosted by Hugging Face along with datasets that they can be tested on• Utilizing conversational models to build chat bots",,116–117,2,,,,article,,April 2024,39,6,J. Comput. Sci. Coll.,may,1937-4771,,,
"Santos, Eddie Antonio and Prasad, Prajish and Becker, Brett A.",Always Provide Context: The Effects of Code Context on Programming Error Message Enhancement,2023,9798400700484,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3576882.3617909,10.1145/3576882.3617909,"Programming error messages (PEMs) are notoriously difficult for novice programmers to utilise. Many efforts have been made to enhance PEMs such that they are reworded to explain problems in terms that novices can understand. However, the effectiveness of these efforts to enhance PEMs has been weak or inconclusive. This work seeks to determine the role that code context has on programming error message enhancement. Erroneous Java code written by novices was sampled from the Blackbox Mini dataset. The erroneous code was presented to expert raters with four different PEM variants: javac (control), Decaf -- an error message enhancing IDE -- and two variants generated using GPT-4: one that enhanced just the javac error message alone, and one that incorporates the code context in the prompt. We find that providing code context to LLMs increases the likelihood of correct explanations for underlying errors, produces more specific fixes for erroneous programs, and produces fixes that are more likely to be correct. In large language models, the community now has a resource that is capable of taking code context into account, to the benefit of novice programmers.",Proceedings of the ACM Conference on Global Computing Education Vol 1,147–153,7,"Blackbox, BlueJ, CS1, GPT-4, Java, compiler error messages, computing education, debugging, feedback, large language models, novice programmers, programming error messages","Hyderabad, India",CompEd 2023,inproceedings,,,,,,,,,,
"Manley, Eric D. and Urness, Timothy and Migunov, Andrei and Reza, Md. Alimoor",Examining Student Use of AI in CS1 and CS2,2024,,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,"The launch of ChatGPT in November 2022 marked a seismic disruption to many disciplines and industries, including higher education. For the first time, students everywhere have widely available access to a Large Language Model (LLM) capable of generating content - including solutions to programming assignments in CS1 and CS2 - that can pass as the work of a high-achieving student while making traditional plagiarism-detection obsolete. This has spurred various responses in higher education, including a shift to more in-class and unplugged assessments. At the same time, LLMs are transforming the way that many people work, including professional software developers, and students similarly might be able to use them to enhance their learning. In this paper, we report on our experiences with a permissive policy towards the use of ChatGPT and other artificial intelligence (AI) tools for assisting students with their programming assignments in CS1 and CS2 courses in the Spring 2023 semester. Students were allowed to use these tools however they wished as long as they submitted a form which included a transcript of their chat and a reflection on what they learned, if anything, through the interaction. We found that students largely approached the AI in positive ways and that they seemed to genuinely learn from the experience. We also document some things that did not go well and that remain challenges to using AI in programming courses, along with our recommendations on how these might be dealt with in the future.",,41–51,11,,,,article,,April 2024,39,6,J. Comput. Sci. Coll.,may,1937-4771,,,
"Soygazi, Fatih and Oguz, Damla",An Analysis of Large Language Models and LangChain in Mathematics Education,2024,9798400708985,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3633598.3633614,10.1145/3633598.3633614,"The development of large language models (LLMs) has led to the consideration of new approaches, particularly in education. Word problems, especially in subjects like mathematics, and the need to solve these problems by collectively addressing specific stages of reasoning, have raised the question of whether LLMs can be successful in this area as well. In our study, we conducted analyses by asking mathematics questions especially related to word problems using ChatGPT, which is based on the latest language models like Generative Pretrained Transformer (GPT). Additionally, we compared the correct and incorrect answers by posing the same questions to LLMMathChain, a mathematics-specific LLM based on the latest language models like LangChain. It was observed that the answers obtained were more successful with ChatGPT (GPT 3.5), particularly in the field of mathematics. However, both language models were found to be below expectations, particularly in word problems, and suggestions for improvement were provided.",Proceedings of the 2023 7th International Conference on Advances in Artificial Intelligence,92–97,6,"ChatGPT, LangChain, Large Language Models (LLMs), Mathematics Education","Istanbul, Turkiye",ICAAI '23,inproceedings,,,,,,,,,,
"Zhang, Paul and Jaipersaud, Brandon and Ba, Jimmy and Petersen, Andrew and Zhang, Lisa and Zhang, Michael R.",Classifying Course Discussion Board Questions using LLMs,2023,9798400701399,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587103.3594202,10.1145/3587103.3594202,"Large language models (LLMs) can be used to answer student questions on course discussion boards, but there is a risk of LLMs answering questions they are unable to address. We propose and evaluate an LLM-based system that classifies student questions into one of four types: conceptual, homework, logistics, and not answerable. We then prompt an LLM using a type-specific prompt. Using GPT-3, we achieve 81% classification accuracy across the four categories. Furthermore, we achieve 93% accuracy on classifying not answerable questions. This indicates that our system effectively ignores questions that it cannot address.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2,658,1,"course discussion board, gpt-3, large language models, machine learning, natural language processing, question answering","Turku, Finland",ITiCSE 2023,inproceedings,,,,,,,,,,
"Angert, Tyler and Suzara, Miroslav and Han, Jenny and Pondoc, Christopher and Subramonyam, Hariharan",Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606719,10.1145/3586183.3606719,"Creative coding tasks are often exploratory in nature. When producing digital artwork, artists usually begin with a high-level semantic construct such as a “stained glass filter” and programmatically implement it by varying code parameters such as shape, color, lines, and opacity to produce visually appealing results. Based on interviews with artists, it can be effortful to translate semantic constructs to program syntax, and current programming tools don’t lend well to rapid creative exploration. To address these challenges, we introduce Spellburst, a large language model (LLM) powered creative-coding environment. Spellburst provides (1) a node-based interface that allows artists to create generative art and explore variations through branching and merging operations, (2) expressive prompt-based interactions to engage in semantic programming, and (3) dynamic prompt-driven interfaces and direct code editing to seamlessly switch between semantic and syntactic exploration. Our evaluation with artists demonstrates Spellburst’s potential to enhance creative coding practices and inform the design of computational creativity tools that bridge semantic and syntactic spaces.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,22,"creative coding, exploratory programming, generative art, large language models, prompt engineering","San Francisco, CA, USA",UIST '23,inproceedings,100,,,,,,,,,
"Qi, Jinhu",The Impact of Large Language Models on Social Media Communication,2024,9798400709197,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3647722.3647749,10.1145/3647722.3647749,"This article explores the impact of large language models (LLMs) on social media communication, with a focus on the spread of misinformation and cyberbullying. As social media becomes an integral part of modern life, challenges such as the rapid spread of misinformation and unethical online behavior continue to escalate. In this paper, the lab's main research delves into how large language models can improve the accuracy of information dissemination on platforms such as Twitter with their advanced capabilities and larger parameters. It also highlights the application of LLMs in identifying and filtering misinformation, as well as potential ethical and privacy considerations associated with their use. The studies mentioned here also explore the impact of LLMs in shaping social media communications, addressing technological advancements, and attendant social responsibilities.",Proceedings of the 2024 7th International Conference on Software Engineering and Information Management,165–170,6,,"Suva, Fiji",ICSIM '24,inproceedings,,,,,,,,,,
"Wu, Jiahui and Lu, Chengjie and Arrieta, Aitor and Yue, Tao and Ali, Shaukat",Reality Bites: Assessing the Realism of Driving Scenarios with Large Language Models,2024,9798400706097,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3650105.3652296,10.1145/3650105.3652296,"Large Language Models (LLMs) are demonstrating outstanding potential for tasks such as text generation, summarization, and classification. Given that such models are trained on a humongous amount of online knowledge, we hypothesize that LLMs can assess whether driving scenarios generated by autonomous driving testing techniques are realistic, i.e., being aligned with real-world driving conditions. To test this hypothesis, we conducted an empirical evaluation to assess whether LLMs are effective and robust in performing the task. This reality check is an important step towards devising LLM-based autonomous driving testing techniques. For our empirical evaluation, we selected 64 realistic scenarios from DeepScenario-an open driving scenario dataset. Next, by introducing minor changes to them, we created 512 additional realistic scenarios, to form an overall dataset of 576 scenarios. With this dataset, we evaluated three LLMs (GPT-3.5, Llama2-13B, and Mistral-7B) to assess their robustness in assessing the realism of driving scenarios. Our results show that: (1) Overall, GPT-3.5 achieved the highest robustness compared to Llama2-13B and Mistral-7B, consistently throughout almost all scenarios, roads, and weather conditions; (2) Mistral-7B performed the worst consistently; (3) Llama2-13B achieved good results under certain conditions; and (4) roads and weather conditions do influence the robustness of the LLMs.",Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering,40–51,12,"large language models, realistic driving scenarios, robustness","Lisbon, Portugal",FORGE '24,inproceedings,,,,,,,,,,
"Odede, Julius and Frommholz, Ingo",JayBot -- Aiding University Students and Admission with an LLM-based Chatbot,2024,9798400704345,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627508.3638293,10.1145/3627508.3638293,"This demo paper presents JayBot, an LLM-based chatbot system aimed at enhancing the user experience of prospective and current students, faculty, and staff at a UK university. The objective of JayBot is to provide information to users on general enquiries regarding course modules, duration, fees, entry requirements, lecturers, internship, career paths, course employability and other related aspects. Leveraging the use cases of generative artificial intelligence (AI), the chatbot application was built using OpenAI’s advanced large language model (GPT-3.5 turbo); to tackle issues such as hallucination as well as focus and timeliness of results, an embedding transformer model has been combined with a vector database and vector search. Prompt engineering techniques were employed to enhance the chatbot’s response abilities. Preliminary user studies indicate JayBot’s effectiveness and efficiency. The demo will showcase JayBot in a university admission use case and discuss further application scenarios.",Proceedings of the 2024 Conference on Human Information Interaction and Retrieval,391–395,5,"Artificial Intelligence, Chatbot, Interactive Information Retrieval, Large Language Models, Machine Learning, Retrieval Augmented Generation, Vector Database","Sheffield, United Kingdom",CHIIR '24,inproceedings,,,,,,,,,,
"Balse, Rishabh and Kumar, Viraj and Prasad, Prajish and Warriem, Jayakrishnan Madathil",Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs,2023,9798400708404,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627217.3627233,10.1145/3627217.3627233,"When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30&nbsp;buggy student solutions across 6&nbsp;code-writing problems. First, in a study with 5&nbsp;undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30&nbsp;buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations.",Proceedings of the 16th Annual ACM India Compute Conference,49–54,6,"Explanation, GPT-3.5-Turbo, Large language models (LLMs), Logical Errors, Python Programming","Hyderabad, India",COMPUTE '23,inproceedings,,,,,,,,,,
"Shoufan, Abdulhadi",Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3628162,10.1145/3628162,"With the immense interest in ChatGPT worldwide, education has seen a mix of both excitement and skepticism. To properly evaluate its impact on education, it is crucial to understand how far it can help students without prior knowledge answer assessment questions. This study aims to address this question as well as the impact of the question type. We conducted multiple experiments with computer engineering students (experiment group: n=41 to 56), who were asked to use ChatGPT to answer previous test questions before learning about the related topics. Their scores were then compared with the scores of previous-term students who answered the same questions in a quiz or exam setting (control group: n=24 to 61). The results showed a wide range of effect sizes, from -2.55 to 1.23, depending on the question type and content. The experiment group performed best answering code analysis and conceptual questions but struggled with code completion and questions that involved images. However, the performance in code generation tasks was inconsistent. Overall, the ChatGPT group’s answers lagged slightly behind the control group’s answers with an effect size of -0.16. We conclude that ChatGPT, at least in the field of this study, is not yet ready to rely on by students who do not have sufficient background to evaluate generated answers. We suggest that educators try using ChatGPT and educate students on effective questioning techniques and how to assess the generated responses. This study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.",,,29,"ChatGPT, large language models",,,article,45,December 2023,23,4,ACM Trans. Comput. Educ.,dec,,,,
"Gehringer, Edward F. and Wang, Jianxun George and Jilla, Sharan Kumar",Dual-Submission Homework in Parallel Computer Architecture: An Exploratory Study in the Age of LLMs,2024,9798400702532,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3605507.3610629,10.1145/3605507.3610629,"The traditional model of assigning textbook problems for homework is endangered by the ability of students to find answers to almost any published problem on the web. An alternative is a dual-submission approach, where students submit their work, then receive the solutions, and submit a second metacognitive reflection, explaining any errors they made. Students’ scores can depend on the quality of their second submissions alone or the combined quality of their first and second submissions. We tried this approach in a class on parallel computer architecture. We report students’ personal experience based on their questionnaires responses. In addition, we quantitatively compare students’ performance on test questions related to dual-submission homework against their performance on other questions and previous semesters’ student performance on similar questions. Students overwhelmingly preferred this approach and thought they learned more from it, but evidence about whether it improved their learning was inconclusive. We also analyze the continued viability of this approach in the era of large language models.",Proceedings of the Workshop on Computer Architecture Education,41–47,7,,"Orlando, FL, USA",WCAE '23,inproceedings,,,,,,,,,,
"Huh, Mina and Peng, Yi-Hao and Pavel, Amy",GenAssist: Making Image Generation Accessible,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606735,10.1145/3586183.3606735,"Blind and low vision (BLV) creators use images to communicate with sighted audiences. However, creating or retrieving images is challenging for BLV creators as it is difficult to use authoring tools or assess image search results. Thus, creators limit the types of images they create or recruit sighted collaborators. While text-to-image generation models let creators generate high-fidelity images based on a text description (i.e. prompt), it is difficult to assess the content and quality of generated images. We present GenAssist, a system to make text-to-image generation accessible. Using our interface, creators can verify whether generated image candidates followed the prompt, access additional details in the image not specified in the prompt, and skim a summary of similarities and differences between image candidates. To power the interface, GenAssist uses a large language model to generate visual questions, vision-language models to extract answers, and a large language model to summarize the results. Our study with 12 BLV creators demonstrated that GenAssist enables and simplifies the process of image selection and generation, making visual authoring more accessible to all.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,17,"Accessibility, Creativity Support Tools, Generative AI, Image Generation","San Francisco, CA, USA",UIST '23,inproceedings,38,,,,,,,,,
,ICER '23: Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,9781450399753,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chicago, IL, USA",,proceedings,,,2,,,,,,,
"Ustymenko, Stanislav and Phadke, Abhishek",Promise and Challenges of Generative AI in Healthcare Information Systems,2024,9798400702372,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3603287.3651196,10.1145/3603287.3651196,"Large Language Models (LLMs) based on pretrained transformer architectures, such as Generative Pretrained Transformer 4 (GPT-4) from OpenAI, are on the cutting age of artificial intelligence research. Along with generating abundant academic literature, these models are the basis of numerous practical systems widely utilized by end users and organizations. In healthcare information systems, there are many case studies and research prototypes demonstrating the promise of applying GPT-like programs to numerous practical natural language processing tasks. At the same time, current limitations of LLMs prevent their safe deployments in professional environments. In this study, we give an overview of capabilities, limitations, and risks associated with current iterations of LLMs. We provide an overview of literature on using LLMs in healthcare context. Finally, we present a framework of generic healthcare IT system utilizing LLMs, and discuss avenues for future research.",Proceedings of the 2024 ACM Southeast Conference,223–228,6,"GPT, Healthcare IT, Large Language Models, Software Engineering","Marietta, GA, USA",ACM SE '24,inproceedings,,,,,,,,,,
"Biancofiore, Giovanni Maria and Deldjoo, Yashar and Noia, Tommaso Di and Di Sciascio, Eugenio and Narducci, Fedelucio",Interactive Question Answering Systems: Literature Review,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3657631,10.1145/3657631,"Question-answering systems are recognized as popular and frequently effective means of information seeking on the web. In such systems, information seekers can receive a concise response to their queries by presenting their questions in natural language. Interactive question answering is a recently proposed and increasingly popular solution that resides at the intersection of question answering and dialogue systems. On the one hand, the user can ask questions in normal language and locate the actual response to her inquiry; on the other hand, the system can prolong the question-answering session into a dialogue if there are multiple probable replies, very few, or ambiguities in the initial request. By permitting the user to ask more questions, interactive question answering enables users to interact with the system and receive more precise results dynamically.This survey offers a detailed overview of the interactive question-answering methods that are prevalent in current literature. It begins by explaining the foundational principles of question-answering systems, hence defining new notations and taxonomies to combine all identified works inside a unified framework. The reviewed published work on interactive question-answering systems is then presented and examined in terms of its proposed methodology, evaluation approaches, and dataset/application domain. We also describe trends surrounding specific tasks and issues raised by the community, so shedding light on the future interests of scholars. Our work is further supported by a GitHub page synthesizing all the major topics covered in this literature study.",,,38,"Question answering, natural language processing, interactive systems, human-computer interaction, artificial intelligence, large language model",,,article,239,September 2024,56,9,ACM Comput. Surv.,may,0360-0300,,,
"Gumina, Sharon and Dalton, Travis and Gerdes, John",Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models,2023,9798400701306,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3585059.3611409,10.1145/3585059.3611409,"This paper argues for the inclusion of tools that utilize Artificial Intelligence (AI) Large Language Models (LLMs) in information technology (IT) undergraduate courses that teach the fundamentals of software. LLM tools have become widely available and disrupt traditional methods for teaching software concepts. Learning objectives are compromised when students submit AI-generated code for a classroom assignment without comprehending or validating the code. Since LLM tools including OpenAI Codex, Copilot by GitHub, and ChatGPT are being used in industry for software development, students need to be familiar with their use without compromising student learning. Incorporating LLM tools into the curriculum prepares students for real-world software development. However, students still need to understand software fundamentals including how to write and debug code. There are many challenges associated with the inclusion of AI tools into the IT curriculum that need to be addressed and mitigated. This paper presents strategies and techniques to integrate student use of LLM tools, assist students’ interaction with the tools, and help prepare students for careers that increasingly use AI tools to design, develop, and maintain software.",Proceedings of the 24th Annual Conference on Information Technology Education,60–65,6,,"Marietta, GA, USA",SIGITE '23,inproceedings,,,,,,,,,,
"Prpa, Mirjana and Troiano, Giovanni Maria and Wood, Matthew and Coady, Yvonne",Challenges and Opportunities of LLM-Based Synthetic Personae and Data in HCI,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3636293,10.1145/3613905.3636293,"Synthetic personae and data powered by artificial intelligence (AI) are emerging in many HCI areas, including education and training, gaming, and piloting research studies. Recently, Large Language Models (LLMs) have shown promise for synthetic AI personae, experimenting with human and social simulacra and producing synthetic data. This presents challenges and opportunities for extending HCI research via LLMs and AI. In this proposed workshop, we engage HCI researchers interested in working with LLMs, synthetic personae, and synthetic data through speculative design and producing visions, desiderata, and requirements for future HCI research engaging with synthetic personae/data. The outcomes of this workshop may be disseminated to the HCI community through scientific publications or special issues to facilitate continued discussion and advance knowledge on a timely HCI topic.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,5,"AI, Large Language Models, sketching, speculative design, synthetic data, synthetic personae","
",CHI EA '24,inproceedings,461,,,,,,,,,
"Englhardt, Zachary and Li, Richard and Nissanka, Dilini and Zhang, Zhihan and Narayanswamy, Girish and Breda, Joseph and Liu, Xin and Patel, Shwetak and Iyer, Vikram",Exploring and Characterizing Large Language Models for Embedded System Development and Debugging,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650764,10.1145/3613905.3650764,"Large language models (LLMs) have shown remarkable abilities to generate code. However, their ability to develop software for physical computing and embedded systems, which requires cross-domain hardware and software knowledge, has not been thoroughly studied. We observe through our experiments and a 15-user pilot study that even when LLMs fail to produce working code, they can generate helpful reasoning about embedded design tasks, as well as specific debugging suggestions for both novice and expert developers. These results highlight the potential to develop AI assistants to dramatically lower the barrier to entry for working with hardware. To evaluate the capabilities and limitations of LLMs, we develop an automated testbench to quantify LLM performance on embedded programming tasks and perform 450 trials. We leverage these findings to analyze how programmers interact with these tools including their productivity and sense of fulfillment and outline a human-AI collaborative workflow for developing and debugging embedded systems.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,9,"Embedded Systems Development, GPT, Large Language Models","
",CHI EA '24,inproceedings,150,,,,,,,,,
"Sonkar, Shashank and Chen, Xinghe and Le, Myco and Liu, Naiming and Basu Mallick, Debshila and Baraniuk, Richard",Code Soliloquies for Accurate Calculations in Large Language Models,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636889,10.1145/3636555.3636889,"High-quality conversational datasets are crucial for the successful development of Intelligent Tutoring Systems (ITS) that utilize a Large Language Model (LLM) backend. Synthetic student-teacher dialogues, generated using advanced GPT-4 models, are a common strategy for creating these datasets. However, subjects like physics that entail complex calculations pose a challenge. While GPT-4 presents impressive language processing capabilities, its limitations in fundamental mathematical reasoning curtail its efficacy for such subjects. To tackle this limitation, we introduce in this paper an innovative stateful prompt design. Our design orchestrates a mock conversation where both student and tutorbot roles are simulated by GPT-4. Each student response triggers an internal monologue, or ‘code soliloquy’ in the GPT-tutorbot, which assesses whether its subsequent response would necessitate calculations. If a calculation is deemed necessary, it scripts the relevant Python code and uses the Python output to construct a response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. The preliminary Subject Matter Expert evaluations reveal that our Higgs model, a fine-tuned LLaMA model, effectively uses Python for computations, which significantly enhances the accuracy and computational reliability of Higgs’ responses.",Proceedings of the 14th Learning Analytics and Knowledge Conference,828–835,8,,"Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
"Dunder, Nora and Lundborg, Saga and Wong, Jacqueline and Viberg, Olga",Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636882,10.1145/3636555.3636882,"AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT’s ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.",Proceedings of the 14th Learning Analytics and Knowledge Conference,821–827,7,"Academic Integrity, Automated Grading, ChatGPT, Programming Education","Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
"Wehmeier, Colter and Artopoulos, Georgios",MetaFraming: A Methodology for Democratizing Heritage Interpretation Through Wiki Surveys,2023,9798400708367,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3623462.3623465,10.1145/3623462.3623465,,Proceedings of the 20th International Conference on Culture and Computer Science: Code and Materiality,,9,"MetaFraming, Modern Architectural Heritage, Participatory Heritage, Wiki Surveys","Lisbon, Portugal",KUI '23,inproceedings,4,,,,,,,,,
"Sergeyuk, Agnia and Lvova, Olga and Titov, Sergey and Serova, Anastasiia and Bagirov, Farid and Kirillova, Evgeniia and Bryksin, Timofey",Reassessing Java Code Readability Models with a Human-Centered Approach,2024,9798400705861,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3643916.3644435,10.1145/3643916.3644435,"To ensure that Large Language Models (LLMs) effectively support user productivity, they need to be adjusted. Existing Code Readability (CR) models can guide this alignment. However, there are concerns about their relevance in modern software engineering since they often miss the developers' notion of readability and rely on outdated code. This research assesses existing Java CR models for LLM adjustments, measuring the correlation between their and developers' evaluations of AI-generated Java code. Using the Repertory Grid Technique with 15 developers, we identified 12 key code aspects influencing CR that were consequently assessed by 390 programmers when labeling 120 AI-generated snippets. Our findings indicate that when AI generates concise and executable code, it's often considered readable by CR models and developers. However, a limited correlation between these evaluations underscores the importance of future research on learning objectives for adjusting LLMs and on the aspects influencing CR evaluations included in predictive models.",Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension,225–235,11,"code readability, code readability models, repertory grid technique, AI-generated code, human-computer interaction","Lisbon, Portugal",ICPC '24,inproceedings,,,,,,,,,,
,CEP '24: Proceedings of the 8th Conference on Computing Education Practice,2024,9798400709326,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Durham, United Kingdom",,proceedings,,,,,,,,,,
"Huang, Tao and Sun, Zhihong and Jin, Zhi and Li, Ge and Lyu, Chen",Knowledge-Aware Code Generation with Large Language Models,2024,9798400705861,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3643916.3644418,10.1145/3643916.3644418,"Large Language Models (LLMs) perform well on basic programming problems. However, they encounter challenges when dealing with complex tasks involving the use of diverse algorithmic and data structure skills, particularly programming competition-level problems. Notably, ChatGPT exhibits proficient performance on problems it has encountered during its pre-training phase, but this performance deteriorates when faced with novel problems. Consequently, enhancing the ability of LLMs to address unfamiliar problems has emerged as a pivotal research focus. The problem-solving process of LLMs mirrors human programmers' approach to a certain extent. When confronted with new programming tasks, human programmers engage in task planning and code writing with the previously acquired knowledge about algorithms and data structures. Despite having learned such knowledge, LLMs struggle to effectively apply it when faced with specific new problems. To address this issue, we constructed a novel dataset, CodeF, which contains a portion of programming problems that ChatGPT has not previously encountered. Furthermore, we developed a Knowledge Library tailored for Python programming contest problems and introduced the concept of Knowledge-Aware Code Generation (KareCoder). KareCoder bolsters the models' understanding and problem-solving capabilities by integrating prompt and knowledge from the library into the LLMs' code generation reasoning process, especially on Pass@1 metrics. Upon testing on the CodeF and APPS datasets, KareCoder demonstrated outstanding performance in handling novel problems previously unencountered by LLMs. In contrast with the code directly generated by ChatGPT, KareCoder achieved a relative improvement of 23.3% on the Pass@1 metric on the CodeF post2021-9 dataset. Additionally, it performs well compared to other methods when dealing with problems that LLMs have previously encountered. Our dataset and experiment data are open-sourced and can be accessed at https://github.com/CodeGeneration3/KareCoder.",Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension,52–63,12,"code generation, large language models, knowledge library","Lisbon, Portugal",ICPC '24,inproceedings,,,,,,,,,,
"Nowrin, Sadia and Vertanen, Keith",Programming by Voice: Exploring User Preferences and Speaking Styles,2023,9798400700149,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3571884.3597130,10.1145/3571884.3597130,"Programming by voice is a potentially useful method for individuals with motor impairments. Spoken programs can be challenging for a standard speech recognizer with a language model trained on written text mined from sources such as web pages. Having an effective language model that captures the variability in spoken programs may be necessary for accurate recognition. In this work, we explore how novice and expert programmers speak code without requiring them to adhere to strict grammar rules. We investigate two approaches to collect data by having programmers speak either highlighted or missing lines of code. We observed that expert programmers spoke more naturally, while novice programmers spoke more syntactically. A commercial speech recognizer had a high error rate on our spoken programs. However, by adapting the recognizer’s language model with our spoken code transcripts, we were able to substantially reduce the error rate by 27% relative to the baseline on unseen spoken code.",Proceedings of the 5th International Conference on Conversational User Interfaces,,13,"Accessibility, Speech Recognition, Voice Programming, Voice User Interfaces","Eindhoven, Netherlands",CUI '23,inproceedings,20,,,,,,,,,
"Laney, Mason and Dewan, Prasun",Human-AI Collaboration in a Student Discussion Forum,2024,9798400705090,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640544.3645215,10.1145/3640544.3645215,"The recent public releases of AI tools such as ChatGPT have forced computer science educators to reconsider how they teach. These tools have demonstrated considerable ability to generate code and answer conceptual questions, rendering them incredibly useful for completing CS coursework. While overreliance on AI tools could hinder students’ learning, we believe they have the potential to be a helpful resource for both students and instructors alike. We propose a novel system for instructor-mediated GPT interaction in a class discussion board. By automatically generating draft responses to student forum posts, GPT can help Teaching Assistants (TAs) respond to student questions in a more timely manner, giving students an avenue to receive fast, quality feedback on their solutions without turning to ChatGPT directly. Additionally, since they are involved in the process, instructors can ensure that the information students receive is accurate, and can provide students with incremental hints that encourage them to engage critically with the material, rather than just copying an AI-generated snippet of code. We utilize Piazza—a popular educational forum where TAs help students via text exchanges—as a venue for GPT-assisted TA responses to student questions. These student questions are sent to GPT-4 alongside assignment instructions and a customizable prompt, both of which are stored in editable instructor-only Piazza posts. We demonstrate an initial implementation of this system, and provide examples of student questions that highlight its benefits.",Companion Proceedings of the 29th International Conference on Intelligent User Interfaces,74–77,4,,"Greenville, SC, USA",IUI '24 Companion,inproceedings,,,,,,,,,,
,SIGITE '23: Proceedings of the 24th Annual Conference on Information Technology Education,2023,9798400701306,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Marietta, GA, USA",,proceedings,,,,,,,,,,
"Li, Cong and Zhou, Zhe and Zheng, Size and Zhang, Jiaxi and Liang, Yun and Sun, Guangyu",SpecPIM: Accelerating Speculative Inference on PIM-Enabled System via Architecture-Dataflow Co-Exploration,2024,9798400703867,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3620666.3651352,10.1145/3620666.3651352,,"Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3",950–965,16,"near-memory processing, large language models, speculative inference, domain-specific accelerator","La Jolla, CA, USA",ASPLOS '24,inproceedings,,,,,,,,,,
"Tania, Nishat Ara and Masud, Md Rayhanul and Rokon, Md Omar Faruk and Zhang, Qian and Faloutsos, Michalis",Who is Creating Malware Repositories on GitHub and Why?,2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3651582,10.1145/3589335.3651582,"Recent studies have found thousands of malware source code repositories on GitHub. For the first time, we propose to understand the origins and motivations behind the creation of such malware repositories. For that, we collect and profile the authors of malware repositories using a three-fold systematic approach. First, we identify 14K users in GitHub who have authored at least one malware repository. Second, we leverage a pretrained large language model (LLM) to estimate the likelihood of malicious intent of these authors. This innovative approach led us to categorize 3339 as Malicious, 3354 as Likely Malicious, and 7574 as Benign authors. Further, to validate the accuracy and reliability of our classification, we conduct a manual review of 200 randomly selected authors. Third, our analysis provides insights into the authors' profiles and motivations. We find that Malicious authors often have sparse profiles and focus on creating and spreading malware, while Benign authors typically have complete profiles with a focus on cybersecurity research and education. Likely Malicious authors show varying levels of engagement and ambiguous intentions. We see our study as a key step towards understanding the ecosystem of malware authorship on GitHub.",Companion Proceedings of the ACM on Web Conference 2024,955–958,4,"classification, github, hacker, llm, malware, repository, user","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
,Leveraging Large Language Models to Boost Dafny’s Developers Productivity,2024,9798400705892,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3644033.3644374,10.1145/3644033.3644374,"This research idea paper proposes leveraging Large Language Models (LLMs) to enhance the productivity of Dafny developers. Although the use of verification-aware languages, such as Dafny, has increased considerably in the last decade, these are still not widely adopted. Often the cost of using such languages is too high, due to the level of expertise required from the developers and challenges that they often face when trying to prove a program correct. Even though Dafny automates a lot of the verification process, sometimes there are steps that are too complex for Dafny to perform on its own. One such case is that of missing lemmas, i.e. Dafny is unable to prove a result without being given further help in the form of a theorem that can assist it in the proof of the step.In this paper, we describe preliminary work on using LLMs to assist developers by generating suggestions for relevant lemmas that Dafny is unable to discover and use. Moreover, for the lemmas that cannot be proved automatically, we attempt to provide accompanying calculational proofs. We also discuss ideas for future work by describing a research agenda on using LLMs to increase the adoption of verification-aware languages in general, by increasing developers productivity and by reducing the level of expertise required for crafting formal specifications and proving program properties.",Proceedings of the 2024 IEEE/ACM 12th International Conference on Formal Methods in Software Engineering (FormaliSE),138–142,5,"verification-aware languages, dafny, large language models, generative AI, software productivity, software verification, lemma inference, proof inference, automated program repair","Lisbon, Portugal",FormaliSE '24,inproceedings,,,,,,,,,,
,BLIP: Facilitating the Exploration of Undesirable Consequences of Digital Technologies,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642054,10.1145/3613904.3642054,"Digital technologies have positively transformed society, but they have also led to undesirable consequences not anticipated at the time of design or development. We posit that insights into past undesirable consequences can help researchers and practitioners gain awareness and anticipate potential adverse effects. To test this assumption, we introduce Blip, a system that extracts real-world undesirable consequences of technology from online articles, summarizes and categorizes them, and presents them in an interactive, web-based interface. In two user studies with 15 researchers in various computer science disciplines, we found that Blip substantially increased the number and diversity of undesirable consequences they could list in comparison to relying on prior knowledge or searching online. Moreover, Blip helped them identify undesirable consequences relevant to their ongoing projects, made them aware of undesirable consequences they “had never considered,” and inspired them to reflect on their own experiences with technology.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"NLP, computer ethics, societal impacts, undesirable consequences","Honolulu, HI, USA",CHI '24,inproceedings,290,,,,,,,,,
,WCCCE '23: Proceedings of the 25th Western Canadian Conference on Computing Education,2023,9798400707896,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Vancouver, BC, Canada",,proceedings,,,,,,,,,,
"Xia, Boming and Lu, Qinghua and Zhu, Liming and Lee, Sung Une and Liu, Yue and Xing, Zhenchang",Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for AI Accountability,2024,9798400705915,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3644815.3644959,10.1145/3644815.3644959,"Artificial Intelligence (AI), particularly through the advent of large-scale generative AI (GenAI) models such as Large Language Models (LLMs), has become a transformative element in contemporary technology. While these models have unlocked new possibilities, they simultaneously present significant challenges, such as concerns over data privacy and the propensity to generate misleading or fabricated content. Current frameworks for Responsible AI (RAI) often fall short in providing the granular guidance necessary for tangible application, especially for Accountability---a principle that is pivotal for ensuring transparent and auditable decision-making, bolstering public trust, and meeting increasing regulatory expectations. This study bridges the Accountability gap by introducing our effort towards a comprehensive metrics catalogue, formulated through a systematic multivocal literature review (MLR) that integrates findings from both academic and grey literature. Our catalogue delineates process metrics that underpin procedural integrity, resource metrics that provide necessary tools and frameworks, and product metrics that reflect the outputs of AI systems. This tripartite framework is designed to operationalize Accountability in AI, with a special emphasis on addressing the intricacies of GenAI.",Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI,100–111,12,"responsible AI, accountable AI, risk assessment, generative AI","Lisbon, Portugal",CAIN '24,inproceedings,,,,,,,,,,
"Shih, Jasmine Y and Mohanty, Vishal and Katsis, Yannis and Subramonyam, Hari",Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3651115,10.1145/3613905.3651115,"Domain experts can play a crucial role in guiding data scientists to optimize machine learning models while ensuring contextual relevance for downstream use. However, in current workflows, such collaboration is challenging due to differing expertise, abstract documentation practices, and lack of access and visibility into low-level implementation artifacts. To address these challenges and enable domain expert participation, we introduce CellSync, a collaboration framework comprising (1) a Jupyter Notebook extension that continuously tracks changes to dataframes and model metrics and (2) a Large Language Model powered visualization dashboard that makes those changes interpretable to domain experts. Through CellSync’s cell-level dataset visualization with code summaries, domain experts can interactively examine how individual data and modeling operations impact different data segments. The chat features enable data-centric conversations and targeted feedback to data scientists. Our preliminary evaluation shows that CellSync provides transparency and promotes critical discussions about the intents and implications of data operations.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,11,"Collaborative ML, computational notebooks, data subset visualization, prompt engineering, tabular datasets","
",CHI EA '24,inproceedings,223,,,,,,,,,
"Ko, Hyung-Kwon and Jeon, Hyeon and Park, Gwanmo and Kim, Dae Hyun and Kim, Nam Wook and Kim, Juho and Seo, Jinwook",Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642943,10.1145/3613904.3642943,"We introduce VL2NL, a Large Language Model (LLM) framework that generates rich and diverse NL datasets using Vega-Lite specifications as input, thereby streamlining the development of Natural Language Interfaces (NLIs) for data visualization. To synthesize relevant chart semantics accurately and enhance syntactic diversity in each NL dataset, we leverage 1) a guided discovery incorporated into prompting so that LLMs can steer themselves to create faithful NL datasets in a self-directed manner; 2) a score-based paraphrasing to augment NL syntax along with four language axes. We also present a new collection of 1,981 real-world Vega-Lite specifications that have increased diversity and complexity than existing chart collections. When tested on our chart collection, VL2NL extracted chart semantics and generated L1/L2 captions with 89.4% and 76.0% accuracy, respectively. It also demonstrated generating and paraphrasing utterances and questions with greater diversity compared to the benchmarks. Last, we discuss how our NL datasets and framework can be utilized in real-world scenarios. The codes and chart collection are available at https://github.com/hyungkwonko/chart-llm.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,22,"Vega-Lite, data visualization, framework, large language models, natural language datasets, natural language interfaces","Honolulu, HI, USA",CHI '24,inproceedings,843,,,,,,,,,
"Khurana, Anjali and Subramonyam, Hariharan and Chilana, Parmit K",Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645200,10.1145/3640543.3645200,"Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software. LLMs use vast training data from domain-specific texts, software manuals, and code repositories to mimic human-like interactions, offering tailored assistance, including step-by-step instructions. In this work, we investigated LLM-generated software guidance through a within-subject experiment with 16 participants and follow-up interviews. We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts. We assessed task completion, perceived accuracy, relevance, and trust. Surprisingly, although SoftAIBot outperformed the baseline LLM, our results revealed no significant difference in LLM usage and user perceptions with or without prompt guidelines and the integration of domain context. Most users struggled to understand how the prompt’s text related to the LLM’s responses and often followed the LLM’s suggestions verbatim, even if they were incorrect. This resulted in difficulties when using the LLM’s advice for software tasks, leading to low task completion rates. Our detailed analysis also revealed that users remained unaware of inaccuracies in the LLM’s responses, indicating a gap between their lack of software expertise and their ability to evaluate the LLM’s assistance. With the growing push for designing domain-specific LLM assistants, we emphasize the importance of incorporating explainable, context-aware cues into LLMs to help users understand prompt-based interactions, identify biases, and maximize the utility of LLM assistants.",Proceedings of the 29th International Conference on Intelligent User Interfaces,288–303,16,"feature-rich software, help-seeking, large language models, prompt-based interactions","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
"Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.",Generative Agents: Interactive Simulacra of Human Behavior,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606763,10.1145/3586183.3606763,"Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,22,"Human-AI interaction, agents, generative AI, large language models","San Francisco, CA, USA",UIST '23,inproceedings,2,,,,,,,,,
"Park, Joon Sung and Popowski, Lindsay and Cai, Carrie and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.",Social Simulacra: Creating Populated Prototypes for Social Computing Systems,2022,9781450393201,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3526113.3545616,10.1145/3526113.3545616,"Social computing prototypes probe the social behaviors that may arise in an envisioned system design. This prototyping practice is currently limited to recruiting small groups of people. Unfortunately, many challenges do not arise until a system is populated at a larger scale. Can a designer understand how a social system might behave when populated, and make adjustments to the design before the system falls prey to such challenges? We introduce social simulacra, a prototyping technique that generates a breadth of realistic social interactions that may emerge when a social computing system is populated. Social simulacra take as input the designer’s description of a community’s design—goal, rules, and member personas—and produce as output an instance of that design with simulated behavior, including posts, replies, and anti-social behaviors. We demonstrate that social simulacra shift the behaviors that they generate appropriately in response to design changes, and that they enable exploration of “what if?” scenarios where community members or moderators intervene. To power social simulacra, we contribute techniques for prompting a large language model to generate thousands of distinct community members and their social interactions with each other; these techniques are enabled by the observation that large language models’ training data already includes a wide variety of positive and negative behavior on social media platforms. In evaluations, we show that participants are often unable to distinguish social simulacra from actual community behavior and that social computing designers successfully refine their social computing designs when using social simulacra.",Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology,,18,"prototyping, social computing","Bend, OR, USA",UIST '22,inproceedings,74,,,,,,,,,
"Chen, Liuqing and Jiang, Zhaojun and Xia, Duowei and Cai, Zebin and Sun, Lingyun and Childs, Peter and Zuo, Haoyu",BIDTrainer: An LLMs-driven Education Tool for Enhancing the Understanding and Reasoning in Bio-inspired Design,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642887,10.1145/3613904.3642887,"Bio-inspired design (BID) fosters innovations in engineering. Learning BID is crucial for developing multidisciplinary innovation skills of designers and engineers. Current BID education aims to enhance learners’ understanding and analogical reasoning skills. However, it often heavily relies on the teachers’ expertise. When learners pursue independent learning using some educational tools, they face challenges in understanding and reasoning practice within this multidisciplinary field. Additionally, evaluating their learning outcomes comprehensively becomes problematic. Addressing these challenges, we introduce a LLMs-driven BID education method based on a structured ontology and three strategies: enhancing understanding through LLMs-enpowered ",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"Analogy training, Bio-inspired design, Design education, Design evaluation","Honolulu, HI, USA",CHI '24,inproceedings,676,,,,,,,,,
"Han, Ariel and Zhou, Xiaofei and Cai, Zhenyao and Han, Shenshen and Ko, Richard and Corrigan, Seth and Peppler, Kylie A","Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642438,10.1145/3613904.3642438,"The viral launch of new generative AI (GAI) systems, such as ChatGPT and Text-to-Image (TTL) generators, sparked questions about how they can be effectively incorporated into writing education. However, it is still unclear how teachers, parents, and students perceive and suspect GAI systems in elementary school settings. We conducted a workshop with twelve families (parent-child dyads) with children ages 8-12 and interviewed sixteen teachers in order to understand each stakeholder’s perspectives and opinions on GAI systems for learning and teaching writing. We found that the GAI systems could be beneficial in generating adaptable teaching materials for teachers, enhancing ideation, and providing students with personalized, timely feedback. However, there are concerns over authorship, students’ agency in learning, and uncertainty concerning bias and misinformation. In this article, we discuss design strategies to mitigate these constraints by implementing an adults-oversight system, balancing AI-role allocation, and facilitating customization to enhance students’ agency over writing projects.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"Artificial Intelligence, Generative AI, K-12 Education","Honolulu, HI, USA",CHI '24,inproceedings,678,,,,,,,,,
"Roest, Lianne and Keuning, Hieke and Jeuring, Johan",Next-Step Hint Generation for Introductory Programming Using Large Language Models,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636259,10.1145/3636243.3636259,"Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student’s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.",Proceedings of the 26th Australasian Computing Education Conference,144–153,10,"Generative AI, Large Language Models, Next-step hints, automated feedback, learning programming","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
,"Onward! 2023: Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software",2023,9798400703881,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward! 2023), the premier multidisciplinary conference focused on everything to do with programming and software, including processes, methods, languages, communities and applications. Onward! is more radical, more visionary, and more open than other conferences to ideas that are well-argued but not yet fully proven. We welcome different ways of thinking about, approaching, and reporting on programming language and software engineering research.  

Onward! 2023 is co-located with SPLASH 2023, running from Sunday 22nd of October till Friday 27th of October, in Cascais, Portugal. We are delighted to have Felienne Hermans giving the Onward! keynote, on Wednesday 25th of October, on ",,,,,"Cascais, Portugal",,proceedings,,,,,,,,,,
,ACE '24: Proceedings of the 26th Australasian Computing Education Conference,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
"Fischer, Joel E",Generative AI Considered Harmful,2023,9798400700149,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3571884.3603756,10.1145/3571884.3603756,"The recent months have seen an explosion of interest, hype, and concern about generative AI, driven by the release of ChatGPT. In this article I seek to explicate some potential and actual harms of the engineering and use of generative AI such as ChatGPT. With this I also suggest a reframing for researchers with an interest in interaction. With this reframing I seek to provoke researchers to consider studying the settings of ChatGPT development and use as active sites of production. Research should focus on the organisational, technological and interactional practices and contexts in and through which generative AI and its outputs—harmful and otherwise—are produced, by whom, to what end, and with what consequences on societies.",Proceedings of the 5th International Conference on Conversational User Interfaces,,5,"ChatGPT, GPT-3, GPT-4, LLM, Large Language Models, NLG, NLP, generative AI, natural language, text generation","Eindhoven, Netherlands",CUI '23,inproceedings,7,,,,,,,,,
"Alabood, Lorans and Dow, Travis and Feeley, Kaylyn B and Jaswal, Vikram K. and Krishnamurthy, Diwakar",From Letterboards to Holograms: Advancing Assistive Technology for Nonspeaking Autistic Individuals with the HoloBoard,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642626,10.1145/3613904.3642626,"About one-third of autistic individuals are nonspeaking, i.e., they cannot use speech to convey their thoughts reliably. Many in this population communicate via spelling, a process in which they point to letters on a letterboard held upright in their field of view by a trained Communication and Regulation Partner (CRP). This paper focuses on transitioning such individuals to more independent, digital spelling that requires less support from the CRP, a goal most nonspeakers we consulted with desire. To enable this transition, we followed an approach that mimics an environment familiar to the nonspeaker and that harnesses the skills they already possess from physical letterboard training. Using this approach, we developed HoloBoard, a system that allows a nonspeaker, their CRP, and others, e.g., researchers, to share a common Augmented Reality (AR) environment containing a virtual letterboard. We configured the system to offer a brief (less than 10 minutes, on average) training module with graduated spelling tasks on the virtual letterboard. In a study involving 23 participants, 16 completed the entire module. These participants were able to spell words on the virtual letterboard without the CRP holding that board, an outcome we had not expected. When offered the opportunity to continue interacting with the virtual letterboard after the training module, 14 performed more complicated tasks than we had anticipated, spelling full sentences, or even offering feedback on the HoloBoard using solely the virtual board. Furthermore, five of these participants used the system solo, i.e., with the CRP and researchers absent from the virtual environment. These results suggest that training with the HoloBoard can lay the foundation for more independent communication, providing new social and educational opportunities for this marginalized population.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"Cross-reality, accessibility, assistive technology, extended reality, nonspeaking autistic people","Honolulu, HI, USA",CHI '24,inproceedings,71,,,,,,,,,
"Wang, Dejiang and Zhai, Zhuoran and Cheong, Ngai and Peng, Li",Script-Generated Picture Book Technology Based on Large Language Models and AIGC,2023,9798400708527,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626686.3626704,10.1145/3626686.3626704,"This paper mainly discusses how to use the large language models such as GPT and Ernie model combined with the AIGC tools represented by stable diffusion, which uses a random story script to generate images with fixed style, character characteristics, and continuous plots. The article provides a detailed introduction to how to build an assembly line, using a large language model and a story script to generate the prompt words required for stable diffusion. Subsequently, by comparing the characteristics of traditional picture book production and the image results of using language models word prompts, summarize the limitations of text to images. This leads to a supervised multi round iterative LoRA model scheme that utilizes the CLIP to achieve character IP fixation. Simultaneously using the ControlNet model and inpainting to preprocess and reprocess the image can achieve controllable character poses and fixed backgrounds in the picture book. Finally, we will evaluate and summarize the new scheme and analyze its strengths in picture book creation accordingly.",Proceedings of the 7th International Conference on Digital Technology in Education,104–108,5,,"Hangzhou, China",ICDTE '23,inproceedings,,,,,,,,,,
"Hirzel, Martin",Low-Code Programming Models,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3587691,10.1145/3587691,Low-code has the potential to empower more people to automate tasks by creating computer programs.,,76–85,10,,,,article,,October 2023,66,10,Commun. ACM,sep,0001-0782,,,
"Hamel, Emma and Kani, Nickvash",Factors That Influence Automatic Recognition of African-American Vernacular English in Machine-Learning Models,2023,,IEEE Press,,https://doi.org/10.1109/TASLP.2023.3331139,10.1109/TASLP.2023.3331139,"Racial bias is a well-documented problem in natural language processing (NLP). The dialectal language used by marginalized groups is often misclassified or mischaracterized by language models, which in turn can further disenfranchise these populations. Previous works have noted that some popular language identification (LID) models perform worse when classifying tweets that contain African-American Vernacular English (AAVE) than when classifying tweets that contain White-Aligned English (WAE). This work examines the factors that contribute to racial bias in language models for the LID task. The contributions of this work are two-fold. First, a thorough analysis demonstrates that a lack of “unique” language-specific n-gram features in an LID model can lead to poor performance on dialectal data, especially on shorter-length inputs like those typically found on social media. Second, based on these findings, this work introduces and illustrates the efficacy of two simple yet accurate solutions: i.) mining “unique” n-gram features and ii.) including examples of dialectal English in training data. These solutions mitigate the accuracy gap between WAE and AAVE which some language identification models demonstrate when classifying shorter inputs. Mining for unique features and training with a more diverse dataset can improve the disparity on short-length sequences by 6% and 9.8% respectively.",,509–516,8,,,,article,,2024,32,,"IEEE/ACM Trans. Audio, Speech and Lang. Proc.",nov,2329-9290,,,
"Tanprasert, Thitaree and Fels, Sidney S and Sinnamon, Luanne and Yoon, Dongwook",Debate Chatbots to Facilitate Critical Thinking on YouTube: Social Identity and Conversational Style Make A Difference,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642513,10.1145/3613904.3642513,"Exposure to diverse perspectives is helpful for bursting the filter bubble in online public video platforms. The recent advancement of Large Language Models (LLMs) illuminates the potential of creating a debate chatbot that prompts users to critically examine their stances on a topic formed by watching videos. However, whether the viewer is influenced by the chatbot may depend on its persona. In this paper, we investigated the effect of two relevant persona attributes - social identity and rhetorical styles - on critical thinking. In a mixed-methods study (n=36), we found that chatbots with outgroup (vs. ingroup) identity (t(33)=-2.33, p=0.03) and persuasive (vs. eristic) rhetoric (t(44)=1.98, p=0.05) induced critical thinking most effectively, making participants re-examine their arguments. However, participants’ stances remain largely unaffected, likely due to the chatbot’s lack of contextual knowledge and human touch. Our paper provides empirical groundwork for designing chatbot persona for remedying filter bubbles in online communities.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,24,"agent personas, conversational agents, critical thinking, filter bubble, online public videos","Honolulu, HI, USA",CHI '24,inproceedings,805,,,,,,,,,
"Moore, Dylan Edward and Moore, Sophia R. R. and Ireen, Bansharee and Iskandar, Winston P. and Artazyan, Grigory and Murnane, Elizabeth L.",Teaching artificial intelligence in extracurricular contexts through narrative-based learnersourcing,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642198,10.1145/3613904.3642198,"Collaborative technology provides powerful opportunities to engage young people in active learning experiences that are inclusive, immersive, and personally meaningful. In particular, interactive narratives have proven to be effective scaffolds for learning, and learnersourcing has emerged as a promising student-driven approach to enable personalized education and quality control at-scale. We introduce the first synthesis of these ideas in the context of teaching artificial intelligence (AI), which is now seen as a critical component of 21st-century education. Specifically, we explore the design of a narrative-based learnersourcing platform where engagement is centered around a learner-made choose-your-own-adventure story. In grounding our approach, we draw from pedagogical literature, digital storytelling, and recent work on learnersourcing. We report on our iterative, learner-centered design process as well as our study findings that demonstrate the platform’s positive effects on knowledge gains, interest in AI concepts, and the overall user experience of narrative-based learnersourcing technology.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,28,"AI literacy, STEM education, collaborative learning, digital narratives, learnersourcing, online learning tools, storytelling","Honolulu, HI, USA",CHI '24,inproceedings,270,,,,,,,,,
,ICER '23: Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,2023,9781450399760,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chicago, IL, USA",,proceedings,,,1,,,,,,,
"Shaikh, Omar and Chai, Valentino Emil and Gelfand, Michele and Yang, Diyi and Bernstein, Michael S.",Rehearsal: Simulating Conflict to Teach Conflict Resolution,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642159,10.1145/3613904.3642159,"Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill—one that can be learned through deliberate practice—but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual “what if?” scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"conflict resolution, interests-rights-power, large language models","Honolulu, HI, USA",CHI '24,inproceedings,920,,,,,,,,,
"Godoy, William and Valero-Lara, Pedro and Teranishi, Keita and Balaprakash, Prasanna and Vetter, Jeffrey",Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation,2023,9798400708428,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3605731.3605886,10.1145/3605731.3605886,"We evaluate AI-assisted generative capabilities on fundamental numerical kernels in high-performance computing (HPC), including AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG. We test the generated kernel codes for a variety of language-supported programming models, including (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). We use the GitHub Copilot capabilities powered by the GPT-based OpenAI Codex available in Visual Studio Code as of April 2023 to generate a vast amount of implementations given simple &lt;kernel&gt; + &lt;programming model&gt; + &lt;optional hints&gt; prompt variants. To quantify and compare the results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. Results suggest that the OpenAI Codex outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general-purpose Python can benefit from adding code keywords, while Julia prompts perform acceptably well for its mature programming models (e.g., Threads and CUDA.jl). We expect for these benchmarks to provide a point of reference for each programming model’s community. Overall, understanding the convergence of large language models, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human-computer interactions.",Proceedings of the 52nd International Conference on Parallel Processing Workshops,136–144,9,"GPT, GitHub Copilot, HPC, LLM, OpenAI Codex, generative AI, high-performance computing, large language models, numerical kernels, programming models","Salt Lake City, UT, USA",ICPP Workshops '23,inproceedings,,,,,,,,,,
"Liu, Yiren and Chen, Si and Cheng, Haocong and Yu, Mengxia and Ran, Xiao and Mo, Andrew and Tang, Yiliu and Huang, Yun",How AI Processing Delays Foster Creativity: Exploring Research Question Co-Creation with an LLM-based Agent,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642698,10.1145/3613904.3642698,"Developing novel research questions (RQs) often requires extensive literature reviews, especially in interdisciplinary fields. To support RQ development through human-AI co-creation, we leveraged Large Language Models (LLMs) to build an LLM-based agent system named CoQuest. We conducted an experiment with 20 HCI researchers to examine the impact of two interaction designs: breadth-first and depth-first RQ generation. The findings revealed that participants perceived the breadth-first approach as more creative and trustworthy upon task completion. Conversely, during the task, participants considered the depth-first generated RQs as more creative. Additionally, we discovered that AI processing delays allowed users to reflect on multiple RQs simultaneously, leading to a higher quantity of generated RQs and an enhanced sense of control. Our work makes both theoretical and practical contributions by proposing and evaluating a mental model for human-AI co-creation of RQs. We also address potential ethical issues, such as biases and over-reliance on AI, advocating for using the system to improve human research creativity rather than automating scientific inquiry. The system’s source is available at: https://github.com/yiren-liu/coquest.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,25,"Co-creation Systems, Large Language Models, Mixed-initiative Design, Scientifc Discovery","Honolulu, HI, USA",CHI '24,inproceedings,17,,,,,,,,,
"Chen, Qing and Shuai, Wei and Zhang, Jiyao and Sun, Zhida and Cao, Nan",Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642480,10.1145/3613904.3642480,"Unfamiliar measurements usually hinder readers from grasping the scale of the numerical data, understanding the content, and feeling engaged with the context. To enhance data comprehension and communication, we leverage analogies to bridge the gap between abstract data and familiar measurements. In this work, we first conduct semi-structured interviews with design experts to identify design problems and summarize design considerations. Then, we collect an analogy dataset of 138 cases from various online sources. Based on the collected dataset, we characterize a design space for creating data analogies. Next, we build a prototype system, AnalogyMate, that automatically suggests data analogies, their corresponding design solutions, and generated visual representations powered by generative AI. The study results show the usefulness of AnalogyMate in aiding the creation process of data analogies and the effectiveness of data analogy in enhancing data comprehension and communication.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,14,"creativity support, interview, lab study, prototyping/implementation, qualitative methods, quantitative methods","Honolulu, HI, USA",CHI '24,inproceedings,377,,,,,,,,,
,Koli Calling '23: Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2023,9798400716539,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Koli, Finland",,proceedings,,,,,,,,,,
"Lau, Sam and Guo, Philip",From ,2023,9781450399760,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3568813.3600138,10.1145/3568813.3600138,"Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,106–121,16,"AI coding tools, ChatGPT, Copilot, LLM, instructor perspectives","Chicago, IL, USA",ICER '23,inproceedings,,,,,,,,,,
"Wen, Hao and Li, Yuanchun and Liu, Guohong and Zhao, Shanhui and Yu, Tao and Li, Toby Jia-Jun and Jiang, Shiqi and Liu, Yunhao and Zhang, Yaqin and Liu, Yunxin",AutoDroid: LLM-powered Task Automation in Android,2024,9798400704895,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636534.3649379,10.1145/3636534.3649379,"Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or endusers. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system capable of handling arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection techniques that augment the app-specific domain knowledge of LLM, and a multi-granularity query optimization module that reduces the cost of model inference. We integrate AutoDroid with off-the-shelf LLMs including online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a new benchmark for memory-augmented Android task automation with 158 common tasks. The results demonstrated that AutoDroid is able to precisely generate actions with an accuracy of 90.9%, and complete tasks with a success rate of 71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%.",Proceedings of the 30th Annual International Conference on Mobile Computing and Networking,543–557,15,"task automation, large language models, app analysis","Washington D.C., DC, USA",ACM MobiCom '24,inproceedings,,,,,,,,,,
"Wu, Zihan",Investigating the Effectiveness of Variations of Micro Parsons Problems,2023,9781450399753,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3568812.3603447,10.1145/3568812.3603447,"Parsons problems have been used to provide scaffolding for introductory learners. Instead of asking learners to write from scratch, Parsons problems provide blocks of mixed-up code, and ask learners to rearrange them into the correct order. In traditional Parsons problems, each block would contain one or more lines of code. While traditional Parsons problems have been widely used, there is an untapped potential to adapt them to practice to write a single line of code. My research builds upon the design of traditional Parsons problems and introduces micro Parsons problems – problems that focus on assembling code fragments within a single line. The primary goal of my research is to evaluate the effectiveness of variations of micro Parsons problems to support introductory computer science education. Specifically, I aim to investigate the effects of text entry practice versus: 1) micro Parsons problems for creating SQL and Regular Expressions, 2) personalized micro Parsons problems for just-in-time learning after learners make a mistake, and 3) adaptive micro Parsons problems for fading scaffolding as learners’ skill develops.",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,120–122,3,"Parsons problems, adaptive learning systems, introductory programming, micro Parsons problems","Chicago, IL, USA",ICER '23,inproceedings,,,,,,,,,,
"Soale, Jenifer and Collins, Tracy",Harnessing the Disruption of New Technologies to Maintain Effective Assessment Strategies in Information Technology Education,2023,9798400701306,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3585059.3611413,10.1145/3585059.3611413,"Technology tools have always been readily available to help students learn. From calculators to search engines to Artificial Intelligence (AI) tools, it has always been a challenge for educators to maintain assessments that effectively assess student learning on their merit. Adopting a continuous improvement mindset, reflecting on student outcomes, and utilizing research in assessment development can assist in this process. This paper will make recommendations on how to develop assessments in the world of AI that will promote and effectively assess student learning in Information Technology education.",Proceedings of the 24th Annual Conference on Information Technology Education,176–177,2,"Academic Integrity, Artificial Intelligence, Information Technology Education, Student Assessment","Marietta, GA, USA",SIGITE '23,inproceedings,,,,,,,,,,
"Mouli, Chandra and Kotteti, Madhav and Lal, Ratan and Chetti, Prasad",Coding Integrity Unveiled: Exploring the Pros and Cons of Detecting Plagiarism in Programming Assignments Using Copyleaks,2024,,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,"Before the advent of generative Artificial Intelligence (AI) tools, for example, ChatGPT, students traditionally approached assignment development authentically by employing libraries and by referring to textbooks. However, with the widespread reliance on powerful AI tools for assignment completion, the process has become more convenient. Unfortunately, this ease of use has led to a potential detriment in students' genuine understanding of subjects, as well as a decline in their problem-solving and innovative thinking skills. Moreover, AI tools like ChatGPT will evolve as technology advances such that the need to detect AI-generated content is even more crucial in educational setting to reinforce the value of original work [5]. This paper aims to address this issue by focusing on the detection of plagiarism in student assignments through the utilization of the Copyleaks1 tool, specifically designed to identify AI-generated code. The accuracy of the tool is systematically evaluated by submitting various pairs of codes, each with similar functionality, wherein one is generated by AI and the other by humans.",,61–69,9,,,,article,,April 2024,39,6,J. Comput. Sci. Coll.,may,1937-4771,,,
"Acher, Mathieu and Martinez, Jabier",Generative AI for Reengineering Variants into Software Product Lines: An Experience Report,2023,9798400700927,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3579028.3609016,10.1145/3579028.3609016,"The migration and reengineering of existing variants into a software product line (SPL) is an error-prone and time-consuming activity. Many extractive approaches have been proposed, spanning different activities from feature identification and naming to the synthesis of reusable artefacts. In this paper, we explore how large language model (LLM)-based assistants can support domain analysts and developers. We revisit four illustrative cases of the literature where the challenge is to migrate variants written in different formalism (UML class diagrams, Java, GraphML, statecharts). We systematically report on our experience with ChatGPT-4, describing our strategy to prompt LLMs and documenting positive aspects but also failures. We compare the use of LLMs with state-of-the-art approach, BUT4Reuse. While LLMs offer potential in assisting domain analysts and developers in transitioning software variants into SPLs, their intrinsic stochastic nature and restricted ability to manage large variants or complex structures necessitate a semiautomatic approach, complete with careful review, to counteract inaccuracies.",Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume B,57–66,10,,"Tokyo, Japan",SPLC '23,inproceedings,,,,,,,,,,
"Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun",VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606800,10.1145/3586183.3606800,"In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confirmed the usability and effectiveness of VISAR in facilitating the argumentative writing planning process.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,30,"creativity support, human-AI collaboration, writing support","San Francisco, CA, USA",UIST '23,inproceedings,5,,,,,,,,,
"Baldassarre, Maria Teresa and Caivano, Danilo and Fernandez Nieto, Berenice and Gigante, Domenico and Ragone, Azzurra",The Social Impact of Generative AI: An Analysis on ChatGPT,2023,9798400701160,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3582515.3609555,10.1145/3582515.3609555,"In recent months, the impact of Artificial Intelligence (AI) on citizens’ lives has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a citizen-centric AI.",Proceedings of the 2023 ACM Conference on Information Technology for Social Good,363–373,11,"Trustable AI, Generative AI Social Impact, Citizen-centric AI","Lisbon, Portugal",GoodIT '23,inproceedings,,,,,,,,,,
"Sane, Aamod and Albuquerque, Melwina and Gupta, Madhav and Valadi, Jayaraman","ChatGPT Didn't Take Me Very Far, Did It?",2023,9798400703744,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3617650.3624947,10.1145/3617650.3624947,"The effect of ChatGPT (CG) on teachers, assessment and other matters have been discussed in many works, but no one appears to have studied how students are actually using it. We study how students use CG for coursework, a semester long project, and summer internships. We discover that from a student's perspective, CG responses fall into three classes: it is immediately helpful, it needs user help, or it leads to unhelpful frustration. We are developing a classification of these uses as a prelude to understanding how CG can contribute to improving student learning outcomes.",Proceedings of the ACM Conference on Global Computing Education Vol 2,204,1,"learning technologies, large language models, LLM, ChatGPT, CS education","Hyderabad, India",CompEd 2023,inproceedings,,,,,,,,,,
"Prather, James and Reeves, Brent N. and Denny, Paul and Becker, Brett A. and Leinonen, Juho and Luxton-Reilly, Andrew and Powell, Garrett and Finnie-Ansley, James and Santos, Eddie Antonio",“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3617367,10.1145/3617367,"Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.",,,31,"OpenAI, novice programming, LLM, large language models, introductory programming, HCI, GPT-3, GitHub, CS1, Copilot, Codex, automatic code generation, Artificial Intelligence, AI",,,article,4,February 2024,31,1,ACM Trans. Comput.-Hum. Interact.,nov,1073-0516,,,
"Jin, Hyoungwook and Lee, Seonghee and Shin, Hyungyu and Kim, Juho",Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642349,10.1145/3613904.3642349,"This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs’ expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs’ knowledge and makes them initiate “why” and “how” questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo’s problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo’s questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,28,"AI and Education, Generative AI, Human-AI interaction, LLM agents","Honolulu, HI, USA",CHI '24,inproceedings,652,,,,,,,,,
"Cerkez, Paul S. and Hummel, Joseph Edward and Mejias, Marlon and Pruitt, William","ChatGPT: To Use or Not to Use, That is the Question: Panel Discussion",2023,,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,"ChatGPT, from OpenAI (AI - artificial intelligence), and the many similar Large Language Models (LLM) appear to have taken the world by storm with some for it, some against it. In simple terms, these products are a great tool for the experienced domain user, however, precisely because of their capability, there is a lot of controversy surrounding student's use.",,175–176,2,,,,article,,November 2023,39,5,J. Comput. Sci. Coll.,nov,1937-4771,,,
,Programming-by-Demonstration for Long-Horizon Robot Tasks,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3632860,10.1145/3632860,"The goal of programmatic Learning from Demonstration (LfD) is to learn a policy in a programming language that can be used to control a robot’s behavior from a set of user demonstrations. This paper presents a new programmatic LfD algorithm that targets long-horizon robot tasks which require synthesizing programs with complex control flow structures, including nested loops with multiple conditionals. Our proposed method first learns a program sketch that captures the target program’s control flow and then completes this sketch using an LLM-guided search procedure that incorporates a novel technique for proving unrealizability of programming-by-demonstration problems. We have implemented our approach in a new tool called PROLEX and present the results of a comprehensive experimental evaluation on 120 benchmarks involving complex tasks and environments. We show that, given a 120 second time limit, PROLEX can find a program consistent with the demonstrations in 80% of the cases. Furthermore, for 81% of the tasks for which a solution is returned, PROLEX is able to find the ground truth program with just one demonstration. In comparison, CVC5, a syntax-guided synthesis tool, is only able to solve 25% of the cases even when given the ground truth program sketch, and an LLM-based approach, GPT-Synth, is unable to solve any of the tasks due to the environment complexity.",,,34,"Abstract Interpretation, Learning from Demonstrations, Program Synthesis",,,article,18,January 2024,8,POPL,Proc. ACM Program. Lang.,jan,,,,
"Malaise, Yoshi and Signer, Beat",Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper),2024,9798400716539,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3631802.3631816,10.1145/3631802.3631816,"We introduce the Explorotron Visual Studio Code extension for guided and independent code exploration and learning. Explorotron is a continuation of earlier work to explore how we can enable small organisations with limited resources to provide pedagogically sound learning experiences in programming. We situate Explorotron in the field of Computing Education Research&nbsp;(CER) and envision it to initiate a discussion around different topics, including how to balance the optimisation between the researcher-student-teacher trifecta that is inherent in CER, how to ethically and responsibly use large language models&nbsp;(LLMs) in the independent learning and exploration by students, and how to define better learning sessions over coding content that students obtained on their own. We further reflect on the question raised by Begel and Ko whether technology should “structure learning for learners” or whether learners should “be taught how to structure their own independent learning” outside of the classroom.",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,,8,"PRIMM, Programming Education, Study Lenses","Koli, Finland",Koli Calling '23,inproceedings,24,,,,,,,,,
"Bhattacharjee, Ananya and Zeng, Yuchen and Xu, Sarah Yi and Kulzhabayeva, Dana and Ma, Minyi and Kornfield, Rachel and Ahmed, Syed Ishtiaque and Mariakakis, Alex and Czerwinski, Mary P and Kuzminykh, Anastasia and Liut, Michael and Williams, Joseph Jay",Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642081,10.1145/3613904.3642081,"Traditional interventions for academic procrastination often fail to capture the nuanced, individual-specific factors that underlie them. Large language models (LLMs) hold immense potential for addressing this gap by permitting open-ended inputs, including the ability to customize interventions to individuals’ unique needs. However, user expectations and potential limitations of LLMs in this context remain underexplored. To address this, we conducted interviews and focus group discussions with 15 university students and 6 experts, during which a technology probe for generating personalized advice for managing procrastination was presented. Our results highlight the necessity for LLMs to provide structured, deadline-oriented steps and enhanced user support mechanisms. Additionally, our results surface the need for an adaptive approach to questioning based on factors like busyness. These findings offer crucial design implications for the development of LLM-based tools for managing procrastination while cautioning the use of LLMs for therapeutic guidance.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"ChatGPT, Education, GPT-4, Large Language Models, Personalized Reflections, Procrastination","Honolulu, HI, USA",CHI '24,inproceedings,15,,,,,,,,,
"Nguyen, Sydney and Babe, Hannah McLean and Zi, Yangtian and Guha, Arjun and Anderson, Carolyn Jane and Feldman, Molly Q",How Beginning Programmers and Code LLMs (Mis)read Each Other,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642706,10.1145/3613904.3642706,"Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,26,,"Honolulu, HI, USA",CHI '24,inproceedings,651,,,,,,,,,
,ICETC '23: Proceedings of the 15th International Conference on Education Technology and Computers,2023,9798400709111,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Barcelona, Spain",,proceedings,,,,,,,,,,
"Ma, Ruilong and Wang, Jingyu and Qi, Qi and Yang, Xiang and Sun, Haifeng and Zhuang, Zirui and Liao, Jianxin",Poster: PipeLLM: Pipeline LLM Inference on Heterogeneous Devices with Sequence Slicing,2023,9798400702365,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3603269.3610856,10.1145/3603269.3610856,"Large Language Models (LLMs) has fostered the creation of innovative requirements. Locally deployed LLMs for micro-enterprise mitigates potential issues such as privacy infringements and sluggish response. However, they are hampered by the limitations in computing capability and memory space of possessed devices. We introduce PipeLLM, which allocates the model across devices commensurate with their computing capabilities. It enables the parallel execution of layers with slicing input sequence along the token dimension. PipeLLM demonstrates the potential to accelerate LLM inference with heterogeneity devices, offering a solution for LLM deployment in micro-enterprise hardware environment.",Proceedings of the ACM SIGCOMM 2023 Conference,1126–1128,3,"LLM inference acceleration, pipeline inference, model deployment","New York, NY, USA",ACM SIGCOMM '23,inproceedings,,,,,,,,,,
"Paul, Soumen and Majumdar, Srijoni and Bandyopadhyay, Ayan and Dave, Bhargav and Chattopadhyay, Samiran and Das, Partha and Clough, Paul D and Majumder, Prasenjit",Efficiency of Large Language Models to scale up Ground Truth: Overview of the IRSE Track at Forum for Information Retrieval 2023,2024,9798400716324,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3632754.3633480,10.1145/3632754.3633480,"The Software Engineering Information Retrieval (IRSE) track aims to devise solutions for the automated evaluation of code comments within a machine learning framework, with labels generated by both humans and large language models. Within this track, there is a binary classification task: discerning comments as either useful or not useful. The dataset includes 9,048 pairs of code comments and surrounding code snippets drawn from open-source C-based projects on GitHub and an additional dataset generated by teams employing large language models. In total, 17 teams representing various universities and software companies have contributed 56 experiments. These experiments were assessed through quantitative metrics, primarily the F1-Score, and qualitative evaluations based on the features developed, the supervised learning models employed, and their respective hyperparameters. It is worth noting that labels generated by large language models introduce bias into the prediction model but lead to less over-fitted results.",Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation,16–18,3,"Abstract syntax tree, Bert, GPT-2, Neural networks, Stanford POS Tagging","Panjim, India",FIRE '23,inproceedings,,,,,,,,,,
"McIntosh, Timothy R. and Liu, Tong and Susnjak, Teo and Watters, Paul and Halgamuge, Malka N.",A Reasoning and Value Alignment Test to Assess Advanced GPT Reasoning,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3670691,10.1145/3670691,"In response to diverse perspectives on Artificial General Intelligence (AGI), ranging from potential safety and ethical concerns to more extreme views about the threats it poses to humanity, this research presents a generic method to gauge the reasoning capabilities of Artificial Intelligence (AI) models as a foundational step in evaluating safety measures. Recognizing that AI reasoning measures cannot be wholly automated, due to factors such as cultural complexity, we conducted an extensive examination of five commercial Generative Pre-trained Transformers (GPTs), focusing on their comprehension and interpretation of culturally intricate contexts. Utilizing our novel “Reasoning and Value Alignment Test”, we assessed the GPT models’ ability to reason in complex situations and grasp local cultural subtleties. Our findings have indicated that, although the models have exhibited high levels of human-like reasoning, significant limitations remained, especially concerning the interpretation of cultural contexts. This paper also explored potential applications and use-cases of our Test, underlining its significance in AI training, ethics compliance, sensitivity auditing, and AI-driven cultural consultation. We concluded by emphasizing its broader implications in the AGI domain, highlighting the necessity for interdisciplinary approaches, wider accessibility to various GPT models, and a profound understanding of the interplay between GPT reasoning and cultural sensitivity.",,,,"Large Language Model (LLM), Cultural Sensitivity, Reasoning and Value Alignment Test, AI Training and Assessment, Cross-Cultural AI Applications, AI Model Limitations",,,article,,,,,ACM Trans. Interact. Intell. Syst.,jun,2160-6455,Just Accepted,,
"Maity, Subhankar and Deroy, Aniket and Sarkar, Sudeshna",Harnessing the Power of Prompt-based Techniques for Generating School-Level Questions using Large Language Models,2024,9798400716324,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3632754.3632755,10.1145/3632754.3632755,"Designing high-quality educational questions is a challenging and time-consuming task. In this work, we propose a novel approach that utilizes prompt-based techniques to generate descriptive and reasoning-based questions. However, current question-answering (QA) datasets are inadequate for conducting our experiments on prompt-based question generation (QG) in an educational setting. Therefore, we curate a new QG dataset called EduProbe for school-level subjects, by leveraging the rich content of NCERT textbooks. We carefully annotate this dataset as quadruples of 1) Context: a segment upon which the question is formed; 2) Long Prompt: a long textual cue for the question (i.e., a longer sequence of words or phrases, covering the main theme of the context); 3) Short Prompt: a short textual cue for the question (i.e., a condensed representation of the key information or focus of the context); 4) Question: a deep question that aligns with the context and is coherent with the prompts. We investigate several prompt-based QG methods by fine-tuning pre-trained transformer-based large language models (LLMs), namely PEGASUS, T5, MBART, and BART. Moreover, we explore the performance of two general-purpose pre-trained LLMs such as Text-Davinci-003 and GPT-3.5-Turbo without any further training. By performing automatic evaluation, we show that T5 (with long prompt) outperforms all other models, but still falls short of the human baseline. Under human evaluation criteria, Text-Davinci-003 usually shows better results than other models under various prompt settings. Even in the case of human evaluation criteria, QG models mostly fall short of the human baseline. Our code and dataset are available at: https://github.com/my625/PromptQG",Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation,30–39,10,"Education, Large Language Models (LLMs), Prompt, Question Generation","Panjim, India",FIRE '23,inproceedings,,,,,,,,,,
"Hua, Wenyue and Li, Lei and Xu, Shuyuan and Chen, Li and Zhang, Yongfeng",Tutorial on Large Language Models for Recommendation,2023,9798400702419,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3604915.3609494,10.1145/3604915.3609494,"Foundation Models such as Large Language Models (LLMs) have significantly advanced many research areas. In particular, LLMs offer significant advantages for recommender systems, making them valuable tools for personalized recommendations. For example, by formulating various recommendation tasks such as rating prediction, sequential recommendation, straightforward recommendation, and explanation generation into language instructions, LLMs make it possible to build universal recommendation engines that can handle different recommendation tasks. Additionally, LLMs have a remarkable capacity for understanding natural language, enabling them to comprehend user preferences, item descriptions, and contextual information to generate more accurate and relevant recommendations, leading to improved user satisfaction and engagement. This tutorial introduces Foundation Models such as LLMs for recommendation. We will introduce how recommender system advanced from shallow models to deep models and to large models, how LLMs enable generative recommendation in contrast to traditional discriminative recommendation, and how to build LLM-based recommender systems. We will cover multiple perspectives of LLM-based recommendation, including data preparation, model design, model pre-training, fine-tuning and prompting, multi-modality and multi-task learning, as well as trustworthy perspectives of LLM-based recommender systems such as fairness and transparency.",Proceedings of the 17th ACM Conference on Recommender Systems,1281–1283,3,"Recommendation, Large Language Models, Foundation Models","Singapore, Singapore",RecSys '23,inproceedings,,,,,,,,,,
"Fontana De Vargas, Mauricio and Yu, Christina and Shane, Howard C. and Moffatt, Karyn",Co-Designing QuickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642080,10.1145/3613904.3642080,"Traditional topic-specific communication boards for Augmentative and Alternative Communication (AAC) require manual programming of relevant symbolic vocabulary, which is time-consuming and often impractical even for experienced Speech-Language Pathologists (SLPs). While recent research has demonstrated the potential to automatically generate these boards from photographs using artificial intelligence, there has been no exploration on how to design such tools to support the specific needs of AAC-based language instruction. This paper introduces QuickPic, a mobile AAC application co-designed with SLPs and special educators, aimed at enhancing language learning for non-speaking individuals, such as autistic children. Through a 17-month design process, we uncover the unique design features required to provide timely language support in therapy and special education contexts. We present emerging evidence on the overall satisfaction of SLPs using QuickPic, and on the advantages of large language model-based generation compared to the existing technique for automated vocabulary from photographs for AAC.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Augmentative and Alternative Communication, LLM, assistive technology, autism, just-in-time","Honolulu, HI, USA",CHI '24,inproceedings,910,,,,,,,,,
"Tang, Ruixiang and Chuang, Yu-Neng and Hu, Xia",The Science of Detecting LLM-Generated Text,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3624725,10.1145/3624725,"While many detection methods have been proposed, understanding the challenges is far more daunting.",,50–59,10,,,,article,,April 2024,67,4,Commun. ACM,mar,0001-0782,,,
"Cheng, Alan Y. and Guo, Meng and Ran, Melissa and Ranasaria, Arpit and Sharma, Arjun and Xie, Anthony and Le, Khuyen N. and Vinaithirthan, Bala and Luan, Shihe (Tracy) and Wright, David Thomas Henry and Cuadra, Andrea and Pea, Roy and Landay, James A.","Scientific and Fantastical: Creating Immersive, Culturally Relevant Learning Experiences with Augmented Reality and Large Language Models",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642041,10.1145/3613904.3642041,"Motivating children to learn is a major challenge in education. One way to inspire motivation to learn is through immersion. We combine the immersive potential of augmented reality (AR), narrative, and large language models (LLMs) to bridge fantasy with reality in a mobile application, Moon Story, that teaches elementary schoolers astronomy and environmental science. Our system also builds upon learning theories such as culturally-relevant pedagogy. Using our application, a child embarks on a journey inspired by Chinese mythology, engages in real-world AR activities, and converses with a fictional character powered by an LLM. We conducted a controlled experiment (N = 50) with two conditions: one using an LLM and one that was hard-coded. Both conditions resulted in learning gains, high engagement levels, and increased science learning motivation. Participants in the LLM condition also wrote more relevant answers. Finally, participants of both Chinese and non-Chinese heritage found the culturally-based narrative compelling.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,23,"Artifact or System, Children/Parents, Education/Learning","Honolulu, HI, USA",CHI '24,inproceedings,275,,,,,,,,,
"Arawjo, Ian and Swoopes, Chelse and Vaithilingam, Priyan and Wattenberg, Martin and Glassman, Elena L.",ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642016,10.1145/3613904.3642016,"Evaluating outputs of large language models (LLMs) is challenging, requiring making—and making sense of—many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"auditing, language models, prompt engineering, toolkits, visual programming environments","Honolulu, HI, USA",CHI '24,inproceedings,304,,,,,,,,,
"Kumar, Harsh and Wang, Yiyi and Shi, Jiakai and Musabirov, Ilya and Farb, Norman A. S. and Williams, Joseph Jay",Exploring the Use of Large Language Models for Improving the Awareness of Mindfulness,2023,9781450394222,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544549.3585614,10.1145/3544549.3585614,"Teachable self-help techniques, such as mindfulness, can reduce anxiety and improve mental well-being outcomes. However, people lack proper awareness of such techniques. In this work, we explore the design space of using online dissemination channels to help people learn about mindfulness. We investigate the potential benefits of using Large Language Models (LLMs) to improve awareness and willingness to practice these techniques, building on a video-based intervention to introduce mindfulness. We designed a pilot between subjects randomized factorial experiment of 2 (Informational Chatbot: present vs. absent) x 2 (Tutorial Video: present vs. absent) x 2 (Reflection Chatbot: present vs. absent). Our preliminary findings suggest that interaction with either of the chatbots improved the participants’ intent to practice Mindfulness again, and the tutorial video improved the participants’ reported overall experience of the exercise. This highlights the potential promise and outlines the directions for exploring the use of LLM-based chatbots for awareness-related interventions.",Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,,7,"GPT-3, factorial experiment, large language models, mental well-being","Hamburg, Germany",CHI EA '23,inproceedings,129,,,,,,,,,
"Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd",Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses,2023,9781450399760,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3568813.3600142,10.1145/3568813.3600142,"This paper studies recent developments in large language models’ (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class’ assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4’s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,78–92,15,"programming knowledge assessment, introductory and intermediate programming, generative pre-trained transformers, coding exercises, Python course, Multiple-choice question answering, MCQ, GitHub Copilot, GPT, Codex, ChatGPT, AlphaCode, AI code generation","Chicago, IL, USA",ICER '23,inproceedings,,,,,,,,,,
"Wazzan, Albatool and MacNeil, Stephen and Souvenir, Richard",Comparing Traditional and LLM-based Search for Image Geolocation,2024,9798400704345,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627508.3638305,10.1145/3627508.3638305,"Web search engines have long served as indispensable tools for information retrieval; user behavior and query formulation strategies have been well studied. The introduction of search engines powered by large language models (LLMs) suggested more conversational search and new types of query strategies. In this paper, we compare traditional and LLM-based search for the task of image geolocation, i.e., determining the location where an image was captured. Our work examines user interactions, with a particular focus on query formulation strategies. In our study, 60 participants were assigned either traditional or LLM-based search engines as assistants for geolocation. Participants using traditional search more accurately predicted the location of the image compared to those using the LLM-based search. Distinct strategies emerged between users depending on the type of assistant. Participants using the LLM-based search issued longer, more natural language queries, but had shorter search sessions. When reformulating their search queries, traditional search participants tended to add more terms to their initial queries, whereas participants using the LLM-based search consistently rephrased their initial queries.",Proceedings of the 2024 Conference on Human Information Interaction and Retrieval,291–302,12,,"Sheffield, United Kingdom",CHIIR '24,inproceedings,,,,,,,,,,
"Ma, Junxia and Rong, Lu and Zhang, Yazhou and Tiwari, Prayag",Moving From Narrative to Interactive Multi-Modal Sentiment Analysis: A Survey,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3610288,10.1145/3610288,"A growing number of individuals are expressing their opinions and engaging in interactive communication with others through various modalities, including natural language (text), facial gestures (vision), acoustic behaviors (audio), and more. Within the realms of natural language processing (NLP) and artificial intelligence (AI), multi-modal sentiment analysis has consistently remained a fundamental research area. Building upon recent advancements, this survey aims to provide researchers with a comprehensive overview of the state-of-the-art techniques in multi-modal sentiment analysis, specifically focusing on various sentiment interaction tasks. It is worth noting that the existing literature on multi-modal sentiment analysis has rarely delved into the realm of sentiment interaction. This survey presents a novel perspective by outlining the progression of multi-modal sentiment analysis from narrative sentiment to interactive sentiment. Furthermore, it discusses the research background, problem definition, and various approaches in multi-modal sentiment analysis. Additionally, this survey provides insights into the development of multi-modal sarcasm recognition, emphasizing the shift from narrativity to interactivity. Lastly, we summarize the current scientific challenges related to interaction modeling and highlight future development trends in the field.",,,,"artificial intelligence, deep learning, natural language processing, interactive dialogue, multi-modal sentiment analysis",,,article,,,,,ACM Trans. Asian Low-Resour. Lang. Inf. Process.,jul,2375-4699,Just Accepted,,
"Fang, Wenhao and Xie, Jiayuan and Liu, Hongfei and Chen, Jiali and Cai, Yi",Diverse Visual Question Generation Based on Multiple Objects Selection,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640014,10.1145/3640014,"Visual question generation task aims at generating high-quality questions about a given image. To make this tak applicable to various scenarios, e.g., the growing demand for exams, it is important to generate diverse questions. The existing methods for this task control diverse question generation based on different question types, e.g., “what” and “when.” Although different question types lead to description diversity, they cannot guarantee semantic diversity when asking the same objects. Research in the field of psychology shows that humans pay attention to different objects in an image based on their preferences, which is beneficial to constructing semantically diverse questions. According to the research, we propose a multi-selector visual question generation (MS-VQG) model that aims to focus on different objects to generate diverse questions. Specifically, our MS-VQG model employs multiple selectors to imitate different humans to select different objects in a given image. Based on these different selected objects, our MS-VQG model can generate diverse questions corresponding to each selector. Extensive experiments on two datasets show that our proposed model outperforms the baselines in generating diverse questions.",,,22,"Multimodal, visual question generation, mixture of experts",,,article,161,June 2024,20,6,ACM Trans. Multimedia Comput. Commun. Appl.,mar,1551-6857,,,
"Alhamadani, Abdulaziz and Althubiti, Khadija and Sarkar, Shailik and He, Jianfeng and Alkulaib, Lulwah and Behal, Srishti and Khan, Mahmood and Lu, Chang-Tien",From Guest to Family: An Innovative Framework for Enhancing Memorable Experiences in the Hotel Industry,2024,9798400704093,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3625007.3632331,10.1145/3625007.3632331,"This paper presents an innovative framework developed to identify, analyze, and generate memorable experiences in the hotel industry. People prefer memorable experiences over traditional services or products in today's ever-changing consumer world. As a result, the hospitality industry has shifted its focus toward creating unique and unforgettable experiences rather than just providing essential services. Despite the inherent subjectivity and difficulties in quantifying experiences, the quest to capture and understand these critical elements in the hospitality context has persisted. However, traditional methods have proven inadequate due to their reliance on objective surveys or limited social media data, resulting in a lack of diversity and potential bias. Our framework addresses these issues, offering a holistic solution that effectively identifies and extracts memorable experiences from online customer reviews, discerns trends on a monthly or yearly basis, and utilizes a local LLM to generate potential, unexplored experiences. As the first successfully deployed, fast, and accurate product of its kind in the industry, This framework significantly contributes to the hotel industry's efforts to enhance services and create compelling, personalized experiences for its customers.",Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,492–501,10,"hotel industry, memorable experience, keyword extraction, text generation, social media data mining","Kusadasi, Turkiye",ASONAM '23,inproceedings,,,,,,,,,,
"Yin, Michael and Wang, Emi and Ng, Chuoxi and Xiao, Robert","Lies, Deceit, and Hallucinations: Player Perception and Expectations Regarding Trust and Deception in Games",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642253,10.1145/3613904.3642253,"Lying and deception are important parts of social interaction; when applied to storytelling mediums such as video games, such elements can add complexity and intrigue. We developed a game, “AlphaBetaCity”, in which non-playable characters (NPCs) made various false statements, and used this game to investigate perceptions of deceptive behaviour. We used a mix of human-written dialogue incorporating deliberate falsehoods and LLM-written scripts with (human-approved) hallucinated responses. The degree of falsehoods varied between believable but untrue statements to outright fabrications. 29 participants played the game and were interviewed about their experiences. Participants discussed methods for developing trust and gauging NPC truthfulness. Whereas perceived intentional false statements were often attributed towards narrative and gameplay effects, seemingly unintentional false statements generally mismatched participants’ mental models and lacked inherent meaning. We discuss how the perception of intentionality, the audience demographic, and the desire for meaning are major considerations when designing video games with falsehoods.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,15,"LLM hallucinations, large language models, lying, player experience, video games","Honolulu, HI, USA",CHI '24,inproceedings,781,,,,,,,,,
"Chrysilla, Grace Naomi and Joyner, David",Utilizing Neural Network to Predict Students Aptitudes for Teaching Assistant Roles,2023,9798400700255,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3573051.3596168,10.1145/3573051.3596168,"The emerging field of affordable degrees at scale relies in large part on a linear relationship between the number of students who enroll and the number of teaching assistants who are employed. As programs grow, however, identifying good candidates can become untenable: research has found that the fraction of students who apply for TA roles far exceeds the number of actual available roles, forcing instructors to comb through hundreds of applications for a tiny number of positions. Most of these applicants are themselves former students in the class as well, meaning that there is abundant data from their assignments, grades, peer review behaviors, and forum participation to evaluate candidates, but navigating and using this data requires significant time.In this work, we utilize machine learning to predict students' aptitudes for teaching assistant roles. We train a neural network model on the available data and aggregate meaningful features to determine if a student possesses the qualities associated with being a good TA. This paper covers implementation details of the training dataset, neural network model training, model result and analysis. We also present a verification method and suggest future improvements.",Proceedings of the Tenth ACM Conference on Learning @ Scale,262–266,5,"teaching assistant, online learning, neural network, machine learning, higher education, education, distance learning, artificial intelligence","Copenhagen, Denmark",L@S '23,inproceedings,,,,,,,,,,
"Kulkarni, Chinmay and Wu, Tongshuang and Holstein, Kenneth and Liao, Q. Vera and Lee, Min Kyung and Lee, Mina and Subramonyam, Hariharan",LLMs and the Infrastructure of CSCW,2023,9798400701290,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3584931.3608438,10.1145/3584931.3608438,"Large Language Models have made many completing many previously difficult to achieve artificial intelligence tasks approachable to more programmers and non-programmers alike. More recently, open-source versions of large language models and the creation of new finetuning methods have been developed. These models and their decvelopment models lead this panel to discuss how the infrastructure of CSCW will influence LLM model development. It will also discuss how open source LLMs might influence CSCW research, and how they might allow the CSCW community to have new input into trust, safety, and responsibility in AI.",Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing,408–410,3,"open source, large language models, collaboration","Minneapolis, MN, USA",CSCW '23 Companion,inproceedings,,,,,,,,,,
"Benharrak, Karim and Zindulka, Tim and Lehmann, Florian and Heuer, Hendrik and Buschek, Daniel",Writer-Defined AI Personas for On-Demand Feedback Generation,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642406,10.1145/3613904.3642406,"Compelling writing is tailored to its audience. This is challenging, as writers may struggle to empathize with readers, get feedback in time, or gain access to the target group. We propose a concept that generates on-demand feedback, based on writer-defined AI personas of any target audience. We explore this concept with a prototype (using GPT-3.5) in two user studies (N=5 and N=11): Writers appreciated the concept and strategically used personas for getting different perspectives. The feedback was seen as helpful and inspired revisions of text and personas, although it was often verbose and unspecific. We discuss the impact of on-demand feedback, the limited representativity of contemporary AI systems, and further ideas for defining AI personas. This work contributes to the vision of supporting writers with AI by expanding the socio-technical perspective in AI tool design: To empower creators, we also need to keep in mind their relationship to an audience.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"Human-AI interaction, Large language models, Personas, Text feedback, Writing assistance","Honolulu, HI, USA",CHI '24,inproceedings,1049,,,,,,,,,
,Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636846,10.1145/3636555.3636846,"Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a “tutor” model to generate hints – it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a “student” model to further validate the hint quality – it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.",Proceedings of the 14th Learning Analytics and Knowledge Conference,12–23,12,"ChatGPT, Feedback Generation, GPT4, Generative AI, Programming Education","Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
"Kendon, Tyson and Wu, Leanne and Aycock, John",AI-Generated Code Not Considered Harmful,2023,9798400707896,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3593342.3593349,10.1145/3593342.3593349,"Recent developments in AI-generated code are merely the latest in a series of challenges to traditional computer science education. AI code generators, along with the plethora of available code on the Internet and sites that facilitate contract cheating, are a striking contrast to the heroic notion of programmers toiling away to create artisanal code from whole cloth. We need not interpret this to mean that more, potentially automated, policing of student assignments is necessary: automated policing of student work is already fraught with complications and ethical concerns. We argue that instructors should instead reconsider assessment design in their pedagogy in light of recent developments, with a focus on how students build knowledge, practice skills, and develop processes. How can these new tools support students and the way they learn, and support the way that computer scientists will work in the years to come? This is an opportunity to revisit how computer science is taught, how it is assessed, how we think about and present academic integrity, and the role of the computer scientist in general.",Proceedings of the 25th Western Canadian Conference on Computing Education,,7,"tool-generated code, copy-paste, contract cheating, assessments, academic integrity, AI-generated code","Vancouver, BC, Canada",WCCCE '23,inproceedings,3,,,,,,,,,
"Liu, Kaibo and Han, Yudong and Zhang, Jie M. and Chen, Zhenpeng and Sarro, Federica and Harman, Mark and Huang, Gang and Ma, Yun",Who Judges the Judge: An Empirical Study on Online Judge Tests,2023,9798400702211,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3597926.3598060,10.1145/3597926.3598060,"Online Judge platforms play a pivotal role in education, competitive programming, recruitment, career training, and large language model training. They rely on predefined test suites to judge the correctness of submitted solutions. It is therefore important that the solution judgement is reliable and free from potentially misleading false positives (i.e., incorrect solutions that are judged as correct). In this paper, we conduct an empirical study of 939 coding problems with 541,552 solutions, all of which are judged to be correct according to the test suites used by the platform, finding that 43.4% of the problems include false positive solutions (3,440 bugs are revealed in total). We also find that test suites are, nevertheless, of high quality according to widely-studied test effectiveness measurements: 88.2% of false positives have perfect (100%) line coverage, 78.9% have perfect branch coverage, and 32.5% have a perfect mutation score. Our findings indicate that more work is required to weed out false positive solutions and to further improve test suite effectiveness. We have released the detected false positive solutions and the generated test inputs to facilitate future research.",Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,334–346,13,"test assessment, software testing, Online judge platform","Seattle, WA, USA",ISSTA 2023,inproceedings,,,,,,,,,,
,Development of chatbots connected to Learning Management Systems for the support and formative assessment of students,2024,9798400708732,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3637989.3637998,10.1145/3637989.3637998,"This work discusses the development of chatbots connected to Learning Management Systems for the support and formative assessment of students in higher education. Because of the diversity of students, and limited time for teaching and evaluation, teachers are facing issues in terms of personalized learning and individualized attention. We present a system connected to a Learning Management System for retrieving course documents, that we use for feeding a chatbot that uses Large Language Model (LLM) in the background for supporting students. The architecture allows students to ask questions against an LLM model, and the response text uses a knowledge base built using the content of the notes and documents that teachers have uploaded to the educational platform as context and sources of information. This allows the answers to be specific and updated, providing insights on how chatbots can be used to enhance the learning experience of students in higher education.",Proceedings of the 2023 7th International Conference on Education and E-Learning,14–18,5,"artificial intelligence, chatbot, e-learning, large language models, learning bots, learning management system","Tokyo, Japan",ICEEL '23,inproceedings,,,,,,,,,,
"Gero, Katy Ilonka and Liu, Vivian and Chilton, Lydia",Sparks: Inspiration for Science Writing using Language Models,2022,9781450393584,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3532106.3533533,10.1145/3532106.3533533,"Large-scale language models are rapidly improving, performing well on a wide variety of tasks with little to no customization. In this work we investigate how language models can support science writing, a challenging writing task that is both open-ended and highly constrained. We present a system for generating “sparks”, sentences related to a scientific concept intended to inspire writers. We find that our sparks are more coherent and diverse than a competitive language model baseline, and approach a human-written gold standard. We run a user study with 13 STEM graduate students writing on topics of their own selection and find three main use cases of sparks—inspiration, translation, and perspective—each of which correlates with a unique interaction pattern. We also find that while participants were more likely to select higher quality sparks, the average quality of sparks seen by a given participant did not correlate with their satisfaction with the tool. We end with a discussion about what impacts human satisfaction with AI support tools, considering participant attitudes towards influence, their openness to technology, as well as issues of plagiarism, trustworthiness, and bias in AI.",Proceedings of the 2022 ACM Designing Interactive Systems Conference,1002–1019,18,"co-creativity, creativity support tools, natural language processing, science writing, writing support","Virtual Event, Australia",DIS '22,inproceedings,,,,,,,,,,
"Karanikolas, Nikitas and Manga, Eirini and Samaridi, Nikoletta and Tousidou, Eleni and Vassilakopoulos, Michael",Large Language Models versus Natural Language Understanding and Generation,2024,9798400716263,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3635059.3635104,10.1145/3635059.3635104,"In recent years, the process humans adopt to learn a foreign language has moved from the strict ",Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics,278–290,13,"Large Language Models, Natural Language Generation, Natural Language Processing, Natural Language Understanding","Lamia, Greece",PCI '23,inproceedings,,,,,,,,,,
"Ying, Lu and Wu, Aoyu and Li, Haotian and Deng, Zikun and Lan, Ji and Wu, Jiang and Wang, Yong and Qu, Huamin and Deng, Dazhen and Wu, Yingcai",VAID: Indexing View Designs in Visual Analytics System,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642237,10.1145/3613904.3642237,"Visual analytics (VA) systems have been widely used in various application domains. However, VA systems are complex in design, which imposes a serious problem: although the academic community constantly designs and implements new designs, the designs are difficult to query, understand, and refer to by subsequent designers. To mark a major step forward in tackling this problem, we index VA designs in an expressive and accessible way, transforming the designs into a structured format. We first conducted a workshop study with VA designers to learn user requirements for understanding and retrieving professional designs in VA systems. Thereafter, we came up with an index structure VAID to describe advanced and composited visualization designs with comprehensive labels about their analytical tasks and visual designs. The usefulness of VAID was validated through user studies. Our work opens new perspectives for enhancing the accessibility and reusability of professional visualization designs.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,15,"Visual Analytics, Visualization Design, Visualization Retrieval","Honolulu, HI, USA",CHI '24,inproceedings,198,,,,,,,,,
"Lam, Michelle S. and Teoh, Janice and Landay, James A. and Heer, Jeffrey and Bernstein, Michael S.",Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642830,10.1145/3613904.3642830,"Data analysts have long sought to turn unstructured text data into meaningful concepts. Though common, topic modeling and clustering focus on lower-level keywords and require significant interpretative work. We introduce concept induction, a computational process that instead produces high-level concepts, defined by explicit inclusion criteria, from unstructured text. For a dataset of toxic online comments, where a state-of-the-art BERTopic model outputs “women, power, female,” concept induction produces high-level concepts such as “Criticism of traditional gender roles” and “Dismissal of women’s concerns.” We present LLooM, a concept induction algorithm that leverages large language models to iteratively synthesize sampled text and propose human-interpretable concepts of increasing generality. We then instantiate LLooM in a mixed-initiative text analysis tool, enabling analysts to shift their attention from interpreting topics to engaging in theory-driven analysis. Through technical evaluations and four analysis scenarios ranging from literature review to content moderation, we find that LLooM’s concepts improve upon the prior art of topic models in terms of quality and data coverage. In expert case studies, LLooM helped researchers to uncover new insights even from familiar datasets, for example by suggesting a previously unnoticed concept of attacks on out-party stances in a political social media dataset.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,28,"data visualization, human-AI interaction, large language models, topic modeling, unstructured text analysis","Honolulu, HI, USA",CHI '24,inproceedings,766,,,,,,,,,
"Sharpe, James S. and Dougherty, Ryan E. and Smith, Sarah J.",Can ChatGPT Pass a CS1 Python Course?,2024,,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,In this paper we determine whether an LLM-ChatGPT in this case-can successfully complete the assignments in our CS1 course as if it were a ,,128–142,15,,,,article,,April 2024,39,8,J. Comput. Sci. Coll.,may,1937-4771,,,
"Mustafa, Gulam B. and G, Kadhiravan and Vijay C, Venkatesh and S, Malathi and S, Subburaj and Paranthaman, Ashwan",Bridging the Skill Gap Between Academia and Industry in Punjab: A Case Study,2021,9781450388276,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3436756.3437052,10.1145/3436756.3437052,"Over the past years, the number of students going abroad for higher studies and settling abroad has increased a lot in northern states of India mainly in Punjab whereas it's significantly less in south India. The purpose of this research is to find the reasons for the brain drain also analyzing the strategies used by south Indian universities so that those ideas can be implemented in Punjab so that the brain drain can be reduced. Using a credits composition analysis for two universities, this study analyzed that the College in Punjab had more credits towards practical and college in South India had more credit composition towards theory. This analysis gave us a result that Panimalar Engineering College has found a sweet spot in the composition of credits along with some other factors. Using a comparative analysis of various factors for various south Indian Universities along with Punjab University, we have found out that there are many other factors that also influence's the brain drains along with Industry Institute Relationship. We have found out the methodologies used by south Indian universities to prevent brain drain. This study definitively answers the question regarding reasons for brain drain in Punjab along with the solutions to overcome it. Further Detailed studies are needed along with the implementation of these ideas to develop preventative measures.",Proceedings of the 12th International Conference on Education Technology and Computers,239–245,7,"Strategies or approaches, Higher education, Employability skills, Employability, Curriculum","London, United Kingdom",ICETC '20,inproceedings,,,,,,,,,,
,Stargazer: An Interactive Camera Robot for Capturing How-To Videos Based on Subtle Instructor Cues,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580896,10.1145/3544548.3580896,"Live and pre-recorded video tutorials are an effective means for teaching physical skills such as cooking or prototyping electronics. A dedicated cameraperson following an instructor’s activities can improve production quality. However, instructors who do not have access to a cameraperson’s help often have to work within the constraints of static cameras. We present Stargazer, a novel approach for assisting with tutorial content creation with a camera robot that autonomously tracks regions of interest based on instructor actions to capture dynamic shots. Instructors can adjust the camera behaviors of Stargazer with subtle cues, including gestures and speech, allowing them to fluidly integrate camera control commands into instructional activities. Our user study with six instructors, each teaching a distinct skill, showed that participants could create dynamic tutorial videos with a diverse range of subjects, camera framing, and camera angle combinations using Stargazer.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,16,"cameras, instructional videos, robots","Hamburg, Germany",CHI '23,inproceedings,800,,,,,,,,,
"Jiang, Yue and Lu, Yuwen and Knearem, Tiffany and Kliman-Silver, Clara E and Lutteroth, Christof and Li, Toby Jia-Jun and Nichols, Jeffrey and Stuerzlinger, Wolfgang","Computational Methodologies for Understanding, Automating, and Evaluating User Interfaces",2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3636316,10.1145/3613905.3636316,"Building on the success of the first two workshops on user interfaces (UIs) at CHI 2022 and CHI 2023, this workshop aims to advance the research field by further exploring current research trends, such as applying large language models and visual language models. Previous work has explored computational approaches to understanding and adapting UIs using constraint-based optimization models and machine learning-based data-driven approaches. In addition to further delving into these established UI research areas, we aim to trigger the exploration into the application of the latest advancements in general-purpose large language and vision-language models within the UI domain. We will encourage participants to explore novel methods for understanding, automating, and evaluating UIs. The proposed workshop seeks to bring together academic researchers and industry practitioners interested in computational approaches for UIs to discuss the needs and opportunities for future user interface algorithms, models, and applications.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,,"
",CHI EA '24,inproceedings,462,,,,,,,,,
"Tao, Wei and Zhou, Yucheng and Wang, Yanlin and Zhang, Hongyu and Wang, Haofen and Zhang, Wenqiang",KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3643675,10.1145/3643675,"Commit messages are natural language descriptions of code changes, which are important for software evolution such as code understanding and maintenance. However, previous methods are trained on the entire dataset without considering the fact that a portion of commit messages adhere to good practice (i.e., good-practice commits), while the rest do not. On the basis of our empirical study, we discover that training on good-practice commits significantly contributes to the commit message generation. Motivated by this finding, we propose a novel knowledge-aware denoising learning method called KADEL. Considering that good-practice commits constitute only a small proportion of the dataset, we align the remaining training samples with these good-practice commits. To achieve this, we propose a model that learns the commit knowledge by training on good-practice commits. This knowledge model enables supplementing more information for training samples that do not conform to good practice. However, since the supplementary information may contain noise or prediction errors, we propose a dynamic denoising training method. This method composes a distribution-aware confidence function and a dynamic distribution list, which enhances the effectiveness of the training process. Experimental results on the whole MCMD dataset demonstrate that our method overall achieves state-of-the-art performance compared with previous methods.",,,32,"Commit message generation, knowledge introducing, denoising training",,,article,133,June 2024,33,5,ACM Trans. Softw. Eng. Methodol.,jun,1049-331X,,,
"Vossen, Wout and Szymanski, Maxwell and Verbert, Katrien",The effect of personalizing a psychotherapy conversational agent on therapeutic bond and usage intentions,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645195,10.1145/3640543.3645195,"While 33.6% of college students suffer from mental health problems, only 24.6% of these students with symptoms would seek professional help due to their personal attitudes or costs associated with therapy. Psychotherapy chatbots may offer a solution as they are always available, anonymous, and cost-effective. Research has shown that these chatbots can significantly reduce symptoms of anxiety and depression. However, there is a lack of understanding about the personalization preferences of users and the effects of personalization on health outcomes. To investigate this, we developed a personalizable psychotherapy chatbot designed to provide personalized help. In a randomized controlled trial (n = 54), participants were either assigned to a personalizable condition or a non-personalizable control condition. After 1 week of usage, participants had a significantly higher therapeutic bond with the personalized version compared to the baseline. In fact, the therapeutic bond was similar to that between a psychologist and his client. This is a promising result, as a high therapeutic bond has been linked to therapeutic success in psychotherapy. Participants reported that the therapy style, personality, and avatar were the most important personalizable aspects of the chatbot. Participants also liked the chatbot’s usage of their name and the transparency about what the chatbot had learned about them. These features are likely important for establishing a strong therapeutic bond with users. However, the ability to personalize the chatbot had no impact on the usage intentions of the participants. This can be explained by the fact that users from both conditions equally reported that the chatbot was able to help them with their mental health. 53 participants also indicated that they would be willing to use a psychotherapy chatbot when integrated with a human therapist. These findings indicate the potential of psychotherapy chatbots and the need for further research on their integration with traditional psychotherapy.",Proceedings of the 29th International Conference on Intelligent User Interfaces,761–771,11,"affective computing, conversational interfaces and assistants, generative ai, personalization","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
,Prompt-Gaming: A Pilot Study on LLM-Evaluating Agent in a Meaningful Energy Game,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650774,10.1145/3613905.3650774,"Building on previous work on incorporating large language models (LLM) in gaming, we investigate the possibility of implementing LLM as evaluating agents of open-ended challenges in serious games and its potential to facilitate a meaningful experience for the player. We contribute with a sustainability game prototype in a single natural language prompt about energy communities and we tested it with 13 participants inside ChatGPT-3.5. Two participants were already aware of energy communities before the game, and eight of the remaining 11 gained valuable knowledge about the specific topic. Comparing ChatGPT-3.5 evaluations of players’ interaction with an expert’s assessment, ChatGPT-3.5 correctly evaluated 81% of player’s answers. Our results are encouraging and show the potential of using LLMs as mediating agents in educational games, while also allowing easy prototyping of games through natural language prompts.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,12,"Energy Communities, Game-based Learning, Large Language Models (LLMs), Natural Language Processing (NLP), Serious Games, Sustainability","
",CHI EA '24,inproceedings,272,,,,,,,,,
"Li, Brenna and Gross, Ofek and Crampton, Noah and Kapoor, Mamta and Tauseef, Saba and Jain, Mohit and Truong, Khai N. and Mariakakis, Alex",Beyond the Waiting Room: Patient's Perspectives on the Conversational Nuances of Pre-Consultation Chatbots,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641913,10.1145/3613904.3641913,"Pre-consultation serves as a critical information exchange between healthcare providers and patients, streamlining visits and supporting patient-centered care. Human-led pre-consultations offer many benefits, yet they require significant time and energy from clinical staff. In this work, we identify design goals for pre-consultation chatbots given their potential to carry out human-like conversations and autonomously adapt their line of questioning. We conducted a study with 33 walk-in clinic patients to elicit design considerations for pre-consultation chatbots. Participants were exposed to one of two study conditions: an LLM-powered AI agent and a Wizard-of-Oz agent simulated by medical professionals. Our study found that both conditions were equally well-received and demonstrated comparable conversational capabilities. However, the extent of the follow-up questions and the amount of empathy impacted the chatbot’s perceived thoroughness and sincerity. Patients also highlighted the importance of setting expectations for the chatbot before and after the pre-consultation experience.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,24,"LLMs, chatbots, information gathering, patient intake, primary care","Honolulu, HI, USA",CHI '24,inproceedings,438,,,,,,,,,
"Du, Wantong and Zhu, Zhiying and Xu, Xinhui and Che, Haoyuan and Chen, Shi",CareerSim: Gamification Design Leveraging LLMs For Career Development Reflection,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650928,10.1145/3613905.3650928,"Graduates often struggle with challenges in their careers stemming from a lack of self-construction and decisive decision-making. The HCI community increasingly focuses on gamification as a means to foster reflection, with the emerging developments in LLM providing new opportunities for personalized gamified experiences. However, existing solutions fall short in terms of personalization and real-world data references. In response, our research introduces CareerSim, a role-playing game that leverages LLM’s generation and reasoning capabilities. By integrating these with real-world based databases and game mechanics, we delve into gamification’s role in reflective self-construction and decision-making. We aim to inspire designers to effectively incorporate LLMs in gamification design.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"Career development, Gamification design, Large Language Models","
",CHI EA '24,inproceedings,71,,,,,,,,,
"Ge, Yingqiang and Liu, Shuchang and Fu, Zuohui and Tan, Juntao and Li, Zelong and Xu, Shuyuan and Li, Yunqi and Xian, Yikun and Zhang, Yongfeng",A Survey on Trustworthy Recommender Systems,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652891,10.1145/3652891,"Recommender systems (RS), serving at the forefront of Human-centered AI, are widely deployed in almost every corner of the web and facilitate the human decision-making process. However, despite their enormous capabilities and potential, RS may also lead to undesired effects on users, items, producers, platforms, or even the society at large, such as compromised user trust due to non-transparency, unfair treatment of different consumers, or producers, privacy concerns due to extensive use of user’s private data for personalization, just to name a few. All of these create an urgent need for Trustworthy Recommender Systems (TRS) so as to mitigate or avoid such adverse impacts and risks. In this survey, we will introduce techniques related to trustworthy recommendation, including but not limited to explainable recommendation, fairness in recommendation, privacy-aware recommendation, robustness in recommendation, user-controllable recommendation, as well as the relationship between these different perspectives in terms of trustworthy recommendation. Through this survey, we hope to deliver readers with a comprehensive view of the research area and raise attention to the community about the importance, existing research achievements, and future research directions on trustworthy recommendation.",,,,,,,article,,,,,ACM Trans. Recomm. Syst.,apr,,Just Accepted,,
"Hassany, Mohammad and Ke, Jiaze and Brusilovsky, Peter and Lekshmi Narayanan, Arun Balajiee and Akhuseyinoglu, Kamil",Authoring Worked Examples for JAVA Programming with Human AI Collaboration,2024,9798400702433,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3605098.3636160,10.1145/3605098.3636160,"Worked examples are among the most popular types of learning content in programming classes. However, instructors rarely have time to provide line-by-line explanations for a large number of examples typically used in a programming class. In this paper, we explore and assess a human-AI collaboration approach to authoring worked examples for Java programming. We introduce an authoring system for creating Java worked examples that generates a starting version of code explanations and presents it to the instructor to edit if necessary. We also present a study that assesses the quality of explanations created with this approach.",Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,101–103,3,"code examples, authoring tool, human-AI collaboration","Avila, Spain",SAC '24,inproceedings,,,,,,,,,,
"Shi, Bin and Shen, Haiying and Dong, Bo and Zheng, Qinghua",Memory/Disk Operation Aware Lightweight VM Live Migration,2022,,IEEE Press,,https://doi.org/10.1109/TNET.2022.3155935,10.1109/TNET.2022.3155935,"Live virtual machine migration technique allows migrating an entire OS with running applications from one physical host to another, while keeping all services available without interruption. It provides a flexible and powerful way to balance system load, save power, and tolerate faults in data centers. Meanwhile, with the stringent requirements of latency, scalability, and availability, an increasing number of applications are deployed across distributed data-centers. However, existing live migration approaches still suffer from long downtime and serious performance degradation in cross data-center scenes due to the mass of dirty retransmission, which limits the ability of cross data-center scheduling. In this paper, we propose a system named Memory/disk operation aware Lightweight VM Live Migration across data-centers with low performance impact (MLLM). It significantly improves the cross data-center migration performance by reducing the amount of dirty data in the migration process. In MLLM, we predict disk read workingset (i.e., more frequently read contents) and memory write workingset (i.e., more frequently write contents) based on the access sequence traces. And then we adjust the migration models and data transfer sequence by the workingset information. We further proposed an improved algorithm for workingset estimation. Moreover, we discussed the potential use of machine learning (ML) to enhance the performance of the VM migration and also propose a two-level hierarchical network model to make the ML-based prediction more efficient. We implement MLLM and its improved versions on the QEMU/KVM platform and conduct several experiments. The experimental results show that 1) MLLM averagely reduces 62.9% of total migration time and 36.0% service downtime over existing methods; 2) The improved workingset estimation algorithm reduces 9.32% memory pre-copy time on average over the original algorithm.",,1895–1910,16,,,,article,,Aug. 2022,30,4,IEEE/ACM Trans. Netw.,mar,1063-6692,,,
"Gu, Ken and Grunde-McLaughlin, Madeleine and McNutt, Andrew and Heer, Jeffrey and Althoff, Tim",How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641891,10.1145/3613904.3641891,"Data analysis is challenging as analysts must navigate nuanced decisions that may yield divergent conclusions. AI assistants have the potential to support analysts in planning their analyses, enabling more robust decision making. Though AI-based assistants that target code execution (e.g., Github Copilot) have received significant attention, limited research addresses assistance for both analysis execution and planning. In this work, we characterize helpful planning suggestions and their impacts on analysts’ workflows. We first review the analysis planning literature and crowd-sourced analysis studies to categorize suggestion content. We then conduct a Wizard-of-Oz study (n=13) to observe analysts’ preferences and reactions to planning assistance in a realistic scenario. Our findings highlight subtleties in contextual factors that impact suggestion helpfulness, emphasizing design implications for supporting different abstractions of assistance, forms of initiative, increased engagement, and alignment of goals between analysts and assistants.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,22,"Analysis Planning, Analysis Tools, Artificial Intelligence, Code Assistant, Computational Notebooks, Copilot, Data Analysis, Data Science Assistant, Human-AI Collaboration, Human-AI Interaction, Human-Centered Data Science, Human-LLM Interaction, Statistical Analysis, Wizard of Oz","Honolulu, HI, USA",CHI '24,inproceedings,1015,,,,,,,,,
"Chen, Zhenpeng and Zhang, Jie M. and Hort, Max and Harman, Mark and Sarro, Federica",Fairness Testing: A Comprehensive Survey and Analysis of Trends,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652155,10.1145/3652155,"Unfair behaviors of Machine Learning (ML) software have garnered increasing attention and concern among software engineers. To tackle this issue, extensive research has been dedicated to conducting fairness testing of ML software, and this article offers a comprehensive survey of existing studies in this field. We collect 100 papers and organize them based on the testing workflow (i.e., how to test) and testing components (i.e., what to test). Furthermore, we analyze the research focus, trends, and promising directions in the realm of fairness testing. We also identify widely adopted datasets and open-source tools for fairness testing.",,,59,"Machine learning, fairness testing, survey, analysis, trends",,,article,137,June 2024,33,5,ACM Trans. Softw. Eng. Methodol.,jun,1049-331X,,,
"Chen, Weihao and Yu, Chun and Wang, Huadong and Wang, Zheng and Yang, Lichen and Wang, Yukun and Shi, Weinan and Shi, Yuanchun",From Gap to Synergy: Enhancing Contextual Understanding through Human-Machine Collaboration in Personalized Systems,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606741,10.1145/3586183.3606741,"This paper presents LangAware, a collaborative approach for constructing personalized context for context-aware applications. The need for personalization arises due to significant variations in context between individuals based on scenarios, devices, and preferences. However, there is often a notable gap between humans and machines in the understanding of how contexts are constructed, as observed in trigger-action programming studies such as IFTTT. LangAware enables end-users to participate in establishing contextual rules in-situ using natural language. The system leverages large language models (LLMs) to semantically connect low-level sensor detectors to high-level contexts and provide understandable natural language feedback for effective user involvement. We conducted a user study with 16 participants in real-life settings, which revealed an average success rate of 87.50% for defining contextual rules in a variety of 12 campus scenarios, typically accomplished within just two modifications. Furthermore, users reported a better understanding of the machine’s capabilities by interacting with LangAware.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,15,"Context-Aware Systems, End User Context Construction, Large Language Models, Personalization","San Francisco, CA, USA",UIST '23,inproceedings,110,,,,,,,,,
"Kao, Wei-Yu and Yen, An-Zi",How We Refute Claims: Automatic Fact-Checking through Flaw Identification and Explanation,2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3651521,10.1145/3589335.3651521,"Automated fact-checking is a crucial task in the governance of internet content. Although various studies utilize advanced models to tackle this issue, a significant gap persists in addressing complex real-world rumors and deceptive claims. To address this challenge, this paper explores the novel task of flaw-oriented fact-checking, including aspect generation and flaw identification. We also introduce RefuteClaim, a new framework designed specifically for this task. Given the absence of an existing dataset, we present FlawCheck, a dataset created by extracting and transforming insights from expert reviews into relevant aspects and identified flaws. The experimental results underscore the efficacy of RefuteClaim, particularly in classifying and elucidating false claims.",Companion Proceedings of the ACM on Web Conference 2024,758–761,4,"claim refutation, explainable fact-checking, flaw identification","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Varde, Aparna S. and De Melo, Gerard and Dong, Boxiang",Temporal Ordinance Mining for Event-Driven Social Media Reaction Analytics,2023,9781450394192,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3543873.3587674,10.1145/3543873.3587674,"As a growing number of policies are adopted to address the substantial rise in urbanization, there is a significant push for smart governance, endowing transparency in decision-making and enabling greater public involvement. The thriving concept of smart governance goes beyond just cities, ultimately aiming at a smart planet. Ordinances (local laws) affect our life with regard to health, business, etc. This is particularly notable during major events such as the recent pandemic, which may lead to rapid changes in ordinances, pertaining for instance to public safety, disaster management, and recovery phases. However, many citizens view ordinances as impervious and complex. This position paper proposes a research agenda enabling novel forms of ordinance content analysis over time and temporal web question answering (QA) for both legislators and the broader public. Along with this, we aim to analyze social media posts so as to track the public opinion before and after the introduction of ordinances. Challenges include addressing concepts changing over time and infusing subtle human reasoning in mining, which we aim to address by harnessing terminology evolution methods and commonsense knowledge sources, respectively. We aim to make the results of the historical ordinance mining and event-driven analysis seamlessly accessible, relying on a robust semantic understanding framework to flexibly support web QA.",Companion Proceedings of the ACM Web Conference 2023,1225–1227,3,"Commonsense knowledge, NLP, historical data, local laws, machine learning, smart governance, social media, terminology evolution, text mining, urban policy, web Q&amp;A","Austin, TX, USA",WWW '23 Companion,inproceedings,,,,,,,,,,
"Maceda, Lany Laguna and Llovido, Jennifer Laraya and Artiaga, Miles Biago and Abisado, Mideth Balawiswis",Classifying Sentiments on Social Media Texts: A GPT-4 Preliminary Study,2024,9798400709227,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639233.3639353,10.1145/3639233.3639353,"In today's digital age, social media has become a hub for people to express their thoughts and feelings. Sentiment classification discerns public opinions and trends to understand their sentiments towards a certain topic. Often, achieving accurate sentiment classifications in large datasets necessitate the use of human-annotated training data which can be costly and time-consuming. Large Language Models (LLMs) like the Generative Pre-trained models by OpenAI have surged in popularity due to its capabilities in understanding the given tasks. In this preliminary study, we report the performance of the latest OpenAI GPT-4 using zero- and one-shot learning approaches on classifying sentiments when fed with social media dataset. Notably, the latter approach written in English which mimics the instructions designed for human annotators, achieved a substantial agreement (k = 0.77) with human annotations, displaying high accuracy, precision, and recall accordingly even without explicit training data. Meanwhile, the fine-tuned mBERT resulted to lower evaluation scores than the GPT-4. Our findings provide foundational insights into the strengths and limitations of GPT-4 for sentiment classification in a social media dataset, setting the groundwork for broad future research in this field.",Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval,19–24,6,"GPT-4, LLM Prompting, Sentiment Annotation, Social Media Data","Seoul, Republic of Korea",NLPIR '23,inproceedings,,,,,,,,,,
"Cuadra, Andrea and Wang, Maria and Stein, Lynn Andrea and Jung, Malte F. and Dell, Nicola and Estrin, Deborah and Landay, James A.",The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642336,10.1145/3613904.3642336,"From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"AI, Affective Computing, Automation, Autonomous Agents, Chatbots, Conversational Agents, Conversational User Interfaces, Disability, Emotion, Empathy, Ethics, Gender, Health, Human-AI Interaction, Human-Computer Interaction, Identity, LLMs, Marginalization, Mental Health, Natural Language Processing, Personalization, Power and Privilege, Religion, Social Robots, Technological Harm, Ubiquitous Computing, User Experience Design, Values in Design, Voice Assistants, Wellbeing","Honolulu, HI, USA",CHI '24,inproceedings,446,,,,,,,,,
"Wang, Xin and Zhou, Yuwei and Chen, Hong and Zhu, Wenwu","Curriculum Learning: Theories, Approaches, Applications, Tools, and Future Directions in the Era of Large Language Models",2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3641257,10.1145/3589335.3641257,"This tutorial focuses on curriculum learning (CL), an important topic in machine learning, which gains an increasing amount of attention in the research community. CL is a learning paradigm that enables machines to learn from easy data to hard data, imitating the meaningful procedure of human learning with curricula. As an easy-to-use plug-in, CL has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision, natural language processing, data mining, reinforcement learning, etc. Therefore, it is essential introducing CL to more scholars and researchers in the machine learning community. However, there have been no tutorials on CL so far, motivating the organization of our tutorial on CL at WWW 2024. To give a comprehensive tutorial on CL, we plan to organize it from the following aspects: (1) theories, (2) approaches, (3) applications, (4) tools and (5) future directions. First, we introduce the motivations, theories and insights behind CL. Second, we advocate novel, high-quality approaches, as well as innovative solutions to the challenging problems in CL. Then we present the applications of CL in various scenarios, followed by some relevant tools. In the end, we discuss open questions and the future direction in the era of large language models. We believe this topic is at the core of the scope of WWW and is attractive to the audience interested in machine learning from both academia and industry.",Companion Proceedings of the ACM on Web Conference 2024,1306–1310,5,"curriculum learning, large language models, machine learning library and tool, machine learning paradigm, training strategy","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Wang, Xu and Yu, Hongwei and Meng, Xiangxin and Cao, Hongliang and Zhang, Hongyu and Sun, Hailong and Liu, Xudong and Hu, Chunming",MTL-TRANSFER: Leveraging Multi-task Learning and Transferred Knowledge for Improving Fault Localization and Program Repair,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3654441,10.1145/3654441,"Fault localization (FL) and automated program repair (APR) are two main tasks of automatic software debugging. Compared with traditional methods, deep learning-based approaches have been demonstrated to achieve better performance in FL and APR tasks. However, the existing deep learning-based FL methods ignore the deep semantic features or only consider simple code representations. And for APR tasks, existing template-based APR methods are weak in selecting the correct fix templates for more effective program repair, which are also not able to synthesize patches via the embedded end-to-end code modification knowledge obtained by training models on large-scale bug-fix code pairs. Moreover, in most of FL and APR methods, the model designs and training phases are performed separately, leading to ineffective sharing of updated parameters and extracted knowledge during the training process. This limitation hinders the further improvement in the performance of FL and APR tasks. To solve the above problems, we propose a novel approach called MTL-TRANSFER, which leverages a multi-task learning strategy to extract deep semantic features and transferred knowledge from different perspectives. First, we construct a large-scale open-source bug datasets and implement 11 multi-task learning models for bug detection and patch generation sub-tasks on 11 commonly used bug types, as well as one multi-classifier to learn the relevant semantics for the subsequent fix template selection task. Second, an MLP-based ranking model is leveraged to fuse spectrum-based, mutation-based and semantic-based features to generate a sorted list of suspicious statements. Third, we combine the patches generated by the neural patch generation sub-task from the multi-task learning strategy with the optimized fix template selecting order gained from the multi-classifier mentioned above. Finally, the more accurate FL results, the optimized fix template selecting order, and the expanded patch candidates are combined together to further enhance the overall performance of APR tasks. Our extensive experiments on widely-used benchmark Defects4J show that MTL-TRANSFER outperforms all baselines in FL and APR tasks, proving the effectiveness of our approach. Compared with our previously proposed FL method TRANSFER-FL (which is also the state-of-the-art statement-level FL method), MTL-TRANSFER increases the faults hit by 8/11/12 on Top-1/3/5 metrics (92/159/183 in total). And on APR tasks, the number of successfully repaired bugs of MTL-TRANSFER under the perfect localization setting reaches 75, which is 8 more than our previous APR method TRANSFER-PR. Furthermore, another experiment to simulate the actual repair scenarios shows that MTL-TRANSFER can successfully repair 15 and 9 more bugs (56 in total) compared with TBar and TRANSFER, which demonstrates the effectiveness of the combination of our optimized FL and APR components.",,,,"Fault localization, automated program repair, deep neural networks, transfer learning, multi-task learning, neural machine translation",,,article,,,,,ACM Trans. Softw. Eng. Methodol.,mar,1049-331X,Just Accepted,,
"Reza, Mohi and Laundry, Nathan M and Musabirov, Ilya and Dushniku, Peter and Yu, Zhi Yuan “Michael” and Mittal, Kashish and Grossman, Tovi and Liut, Michael and Kuzminykh, Anastasia and Williams, Joseph Jay",ABScribe: Rapid Exploration &amp; Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641899,10.1145/3613904.3641899,"Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers’ flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p &lt; 0.001), enhances user perceptions of the revision process (d = 2.41, p &lt; 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"datasets, gaze detection, neural networks, text tagging","Honolulu, HI, USA",CHI '24,inproceedings,1042,,,,,,,,,
"Van Daele, Tess and Iyer, Akhil and Zhang, Yuning and Derry, Jalyn C and Huh, Mina and Pavel, Amy",Making Short-Form Videos Accessible with Hierarchical Video Summaries,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642839,10.1145/3613904.3642839,"Short videos on platforms such as TikTok, Instagram Reels, and YouTube Shorts (i.e. short-form videos) have become a primary source of information and entertainment. Many short-form videos are inaccessible to blind and low vision (BLV) viewers due to their rapid visual changes, on-screen text, and music or meme-audio overlays. In our formative study, 7 BLV viewers who regularly watched short-form videos reported frequently skipping such inaccessible content. We present &nbsp;ShortScribe, a system that provides hierarchical visual summaries of short-form videos at three levels of detail to support BLV viewers in selecting and understanding short-form videos. ShortScribe allows BLV users to navigate between video descriptions based on their level of interest. To evaluate &nbsp;ShortScribe, we assessed description accuracy and conducted a user study with 10 BLV participants comparing &nbsp;ShortScribe to a baseline interface. When using ShortScribe, participants reported higher comprehension and provided more accurate summaries of video content.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"Accessibility, Short-Form Video, Summaries, Video Description","Honolulu, HI, USA",CHI '24,inproceedings,895,,,,,,,,,
"Masikisiki, Baphumelele and Marivate, Vukosi and Hlophe, Yvette",Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thought Prompting,2024,9798400708879,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3628096.3628747,10.1145/3628096.3628747,"Large Language Models, such as Generative Pre-trained Transformer 3 (aka. GPT-3), have been developed to understand language through the analysis of extensive text data, allowing them to identify patterns and connections between words. While LLMs have demonstrated impressive performance across various text-related tasks, they encounter challenges in tasks associated with reasoning. To address this challenge, Chain of Thought (CoT) prompting method has been proposed as a means to enhance LLMs’ proficiency in complex reasoning tasks like solving math word problems and answering questions based on logical argumentative reasoning. The primary aim of this research is to assess how well four language models can grade reflective essays of third-year medical students. The assessment will specifically target the evaluation of critical thinking skills using CoT prompting. The research will provide the following contributions; to introduce and educate on the process of instructing models to evaluate reflective essays from a dataset they have not been previously trained on; to illustrate the use of CoT prompting as an instructional approach for training large models to carry out particular tasks. Our results suggest that among all the models, Llama-7b performs the least effectively, displaying the highest mean squared error. Conversely, ChatGPT emerges as the superior model, boasting a higher Cohen kappa score value of 0.53. Lastly, it’s important to note that the selected models do prioritise user privacy by allowing users to delete their own conducted conversations.",Proceedings of the 4th African Human Computer Interaction Conference,44–49,6,"Automation Grading, Chain of thought prompting, Large Models","East London, South Africa",AfriCHI '23,inproceedings,,,,,,,,,,
"Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian",Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581388,10.1145/3544548.3581388,"Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,21,"design tools, end-users, language models","Hamburg, Germany",CHI '23,inproceedings,437,,,,,,,,,
,ICPC '24: Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension,2024,9798400705861,Association for Computing Machinery,"New York, NY, USA",,,ICPC is the premier (CORE A) venue for research on program comprehension. Research on program comprehension encompasses both human activities for comprehending the software and technologies for supporting such comprehension.,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
,Measuring and Clustering Heterogeneous Chatbot Designs,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3637228,10.1145/3637228,"Conversational agents, or chatbots, have become popular to access all kind of software services. They provide an intuitive natural language interface for interaction, available from a wide range of channels including social networks, web pages, intelligent speakers or cars. In response to this demand, many chatbot development platforms and tools have emerged. However, they typically lack support to statically measure properties of the chatbots being built, as indicators of their size, complexity, quality or usability. Similarly, there are hardly any mechanisms to compare and cluster chatbots developed with heterogeneous technologies.To overcome this limitation, we propose a suite of 21 metrics for chatbot designs, as well as two clustering methods that help in grouping chatbots along their conversation topics and design features. Both the metrics and the clustering methods are defined on a neutral chatbot design language, becoming independent of the implementation platform. We provide automatic translations of chatbots defined on some major platforms into this neutral notation to perform the measurement and clustering. The approach is supported by our tool Asymob, which we have used to evaluate the metrics and the clustering methods over a set of 259 Dialogflow and Rasa chatbots from open-source repositories. The results open the door to incorporating the metrics within chatbot development processes for the early detection of quality issues, and to exploit clustering to organise large collections of chatbots into significant groups to ease chatbot comprehension, search and comparison.",,,43,"Chatbot design, metrics, clustering, quality assurance, model-driven engineering",,,article,90,May 2024,33,4,ACM Trans. Softw. Eng. Methodol.,apr,1049-331X,,,
"Kabir, Samia and Li, Lixiang and Zhang, Tianyi",STILE: Exploring and Debugging Social Biases in Pre-trained Text Representations,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642111,10.1145/3613904.3642111,"The recent success of Natural Language Processing (NLP) relies heavily on pre-trained text representations such as word embeddings. However, pre-trained text representations may exhibit social biases and stereotypes, e.g., disproportionately associating gender with occupations. Though prior work presented various bias detection algorithms, they are limited to pre-defined biases and lack effective interaction support. In this work, we propose Stile, an interactive system that supports mixed-initiative bias discovery and debugging in pre-trained text representations. Stile provides users the flexibility to interactively define and customize biases to detect based on their interests. Furthermore, it provides a bird’s-eye view of detected biases in a Chord diagram and allows users to dive into the training data to investigate how a bias was developed. Our lab study and expert review confirm the usefulness and usability of Stile as an effective aid in identifying and understanding biases in pre-trained text representations.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"AI Fairness, Natural Language Processing, Word Embedding","Honolulu, HI, USA",CHI '24,inproceedings,293,,,,,,,,,
"Buros, Scott",Increase Student Viewership with Striking Titles,2009,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/1595385.1555397,10.1145/1595385.1555397,,,,,,,,article,3,March 2009,2009,3,ELearn,mar,,,,
"Goswami, Lahari and Zeinoddin, Pegah Sadat and Estier, Thibault and Cherubini, Mauro",Supporting Collaboration in Introductory Programming Classes Taught in Hybrid Mode: A Participatory Design Study,2023,9781450398930,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3563657.3596042,10.1145/3563657.3596042,"Hybrid learning modalities, where learners can attend a course in-person or remotely, have gained particular significance in post-pandemic educational settings. In introductory programming courses, novices’ learning behaviour in the collaborative context of classrooms differs in hybrid mode from that of a traditional setting. Reflections from conducting an introductory programming course in hybrid mode led us to recognise the need for re-designing programming tools to support students’ collaborative learning practices. We conducted a participatory design study with nine students, directly engaging them in design to understand their interaction needs in hybrid pedagogical setups to enable effective collaboration during learning. Our findings first highlighted the difficulties that learners face in hybrid modes. The results then revealed learners’ preferences for design functionalities to enable collective notions, communication, autonomy, and regulation. Based on our findings, we discuss design principles and implications to inform the future design of collaborative programming environments for hybrid modes.",Proceedings of the 2023 ACM Designing Interactive Systems Conference,1248–1262,15,"collaboration, hybrid classroom, participatory design, programming environment","Pittsburgh, PA, USA",DIS '23,inproceedings,,,,,,,,,,
,WCCCE '24: Proceedings of the 26th Western Canadian Conference on Computing Education,2024,9798400709975,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Kelowna, BC, Canada",,proceedings,,,,,,,,,,
"Gordon, Mitchell L. and Lam, Michelle S. and Park, Joon Sung and Patel, Kayur and Hancock, Jeff and Hashimoto, Tatsunori and Bernstein, Michael S.",Jury Learning: Integrating Dissenting Voices into Machine Learning Models,2022,9781450391573,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3491102.3502004,10.1145/3491102.3502004,"Whose labels should a machine learning (ML) algorithm learn to emulate? For ML tasks ranging from online comment toxicity to misinformation detection to medical diagnosis, different groups in society may have irreconcilable disagreements about ground truth labels. Supervised ML today resolves these label disagreements implicitly using majority vote, which overrides minority groups’ labels. We introduce jury learning, a supervised ML approach that resolves these disagreements explicitly through the metaphor of a jury: defining which people or groups, in what proportion, determine the classifier’s prediction. For example, a jury learning model for online toxicity might centrally feature women and Black jurors, who are commonly targets of online harassment. To enable jury learning, we contribute a deep learning architecture that models every annotator in a dataset, samples from annotators’ models to populate the jury, then runs inference to classify. Our architecture enables juries that dynamically adapt their composition, explore counterfactuals, and visualize dissent. A field evaluation finds that practitioners construct diverse juries that alter 14% of classification outcomes.",Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems,,19,,"New Orleans, LA, USA",CHI '22,inproceedings,115,,,,,,,,,
"Sabnis, Nihar and Nagashima, Tomohiro",Empowering Learners: Chatbot-Mediated 'Learning-by-Teaching',2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650754,10.1145/3613905.3650754,"Chatbots and online learning platforms provide synthesized information to learners. However, research shows learning is particularly effective when learners themselves teach someone. Prior work has explored an interactive instructional approach called ‘Learning-by-teaching’, but this approach traditionally relies on human counterparts, limiting it to their interest and co-located settings. To overcome these limitations, we investigated whether we can empower learners using chatbot-mediated ‘learning-by-teaching.’ We designed an agnostic, open-source chatbot replicating a virtual student, to which learners teach to learn. We conducted an experiment involving 24 students to evaluate the effectiveness of chatbot-mediated teaching compared to textbook-based problem-solving practice. Results indicate that teaching the chatbot benefits student learning than textbook-based problem-solving. This work highlights the effectiveness of chatbots, envisioning their design as virtual students to mediate ‘learning-by-teaching’.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,9,"Learning-by-Teaching, chatbots, teachable agents, virtual students","
",CHI EA '24,inproceedings,122,,,,,,,,,
"Zhao, Yichun and Nacenta, Miguel A and Sukhai, Mahadeo A. and Somanath, Sowmya",TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision People,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642222,10.1145/3613904.3642222,"Diagrams often appear as node-link representations in contexts such as taxonomies, mind maps and networks in textbooks. Despite their pervasiveness, they present accessibility challenges for blind and low-vision people. To address this challenge, we introduce Touch-and-Audio-based Diagram Access (TADA), a tablet-based interactive system that makes diagram exploration accessible through musical tones and speech. We designed TADA informed by an interview study with 15 participants who shared their challenges and strategies with diagrams. TADA enables people to access a diagram by: i) engaging in open-ended touch-based explorations, ii) searching for nodes, iii) navigating between nodes and iv) filtering information. We evaluated TADA with 25 participants and found it useful for gaining different perspectives on diagrammatic information.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"Accessibility, Artifact or System, Assistive Technologies, Gestures, Haptics, Individuals with Disabilities, Pointing, Touch","Honolulu, HI, USA",CHI '24,inproceedings,45,,,,,,,,,
"Idowu, Samuel and Sens, Yorick and Berger, Thorsten and Krueger, Jacob and Vierhauser, Michael",A Large-Scale Study of ML-Related Python Projects,2024,9798400702433,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3605098.3636056,10.1145/3605098.3636056,"The rise of machine learning (ML) for solving current and future problems increased the production of ML-enabled software systems. Unfortunately, standardized tool chains for developing, employing, and maintaining such projects are not yet mature, which can mainly be attributed to a lack of understanding of the properties of ML-enabled software. For instance, it is still unclear how to manage and evolve ML-specific assets together with other software-engineering assets. In particular, ML-specific tools and processes, such as those for managing ML experiments, are often perceived as incompatible with practitioners' software engineering tools and processes. To design new tools for developing ML-enabled software, it is crucial to understand the properties and current problems of developing these projects by eliciting empirical data from real projects, including the evolution of the different assets involved. Moreover, while studies in this direction have recently been conducted, identifying certain types of ML-enabled projects (e.g., experiments, libraries and software systems) remains a challenge for researchers. We present a large-scale study of over 31,066 ML projects found on GitHub, with an emphasis on their development stages and evolution. Our contributions include a dataset, together with empirical data providing an overview of the existing project types and analysis of the projects' properties and characteristics, especially regarding the implementation of different ML development stages and their evolution. We believe that our results support researchers, practitioners, and tool builders conduct follow-up studies and especially build novel tools for managing ML projects, ideally unified with traditional software-engineering tools.",Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,1272–1281,10,"machine learning, ml-enabled systems, evolution, mining study, open-source projects, large-scale study, tensorflow, scikit-learn","Avila, Spain",SAC '24,inproceedings,,,,,,,,,,
"Wang, Sitong and Menon, Samia and Long, Tao and Henderson, Keren and Li, Dingzeyu and Crowston, Kevin and Hansen, Mark and Nickerson, Jeffrey V and Chilton, Lydia B",ReelFramer: Human-AI Co-Creation for News-to-Video Translation,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642868,10.1145/3613904.3642868,"Short videos on social media are the dominant way young people consume content. News outlets aim to reach audiences through news reels—short videos conveying news—but struggle to translate traditional journalistic formats into short, entertaining videos. To translate news into social media reels, we support journalists in reframing the narrative. In literature, narrative framing is a high-level structure that shapes the overall presentation of a story. We identified three narrative framings for reels that adapt social media norms but preserve news value, each with a different balance of information and entertainment. We introduce ReelFramer, a human-AI co-creative system that helps journalists translate print articles into scripts and storyboards. ReelFramer supports exploring multiple narrative framings to find one appropriate to the story. AI suggests foundational narrative details, including characters, plot, setting, and key information. ReelFramer also supports visual framing; AI suggests character and visual detail designs before generating a full storyboard. Our studies show that narrative framing introduces the necessary diversity to translate various articles into reels, and establishing foundational details helps generate scripts that are more relevant and coherent. We also discuss the benefits of using narrative framing and foundational details in content retargeting.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"creativity support tools, generative AI, narratives, scriptwriting, short videos, storyboarding","Honolulu, HI, USA",CHI '24,inproceedings,169,,,,,,,,,
"Hoque, Md Naimul and Mashiat, Tasfia and Ghai, Bhavya and Shelton, Cecilia D. and Chevalier, Fanny and Kraus, Kari and Elmqvist, Niklas",The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641895,10.1145/3613904.3641895,"The use of Large Language Models (LLMs) for writing has sparked controversy both among readers and writers. On one hand, writers are concerned that LLMs will deprive them of agency and ownership, and readers are concerned about spending their time on text generated by soulless machines. On the other hand, AI-assistance can improve writing as long as writers can conform to publisher policies, and as long as readers can be assured that a text has been verified by a human. We argue that a system that captures the provenance of interaction with an LLM can help writers retain their agency, conform to policies, and communicate their use of AI to publishers and readers transparently. Thus we propose HaLLMark, a tool for visualizing the writer’s interaction with the LLM. We evaluated HaLLMark with 13 creative writers, and found that it helped them retain a sense of control and ownership of the text.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,15,"Creative writing, LLMs, agency, co-writing, visualization.","Honolulu, HI, USA",CHI '24,inproceedings,1045,,,,,,,,,
"Gero, Katy Ilonka and Long, Tao and Chilton, Lydia B",Social Dynamics of AI Support in Creative Writing,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580782,10.1145/3544548.3580782,"Recently, large language models have made huge advances in generating coherent, creative text. While much research focuses on how users can interact with language models, less work considers the social-technical gap that this technology poses. What are the social nuances that underlie receiving support from a generative AI? In this work we ask when and why a creative writer might turn to a computer versus a peer or mentor for support. We interview 20 creative writers about their writing practice and their attitudes towards both human and computer support. We discover three elements that govern a writer’s interaction with support actors: 1) what writers desire help with, 2) how writers perceive potential support actors, and 3) the values writers hold. We align our results with existing frameworks of writing cognition and creativity support, uncovering the social dynamics which modulate user responses to generative technologies.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,15,"creative writing, human-AI collaboration, language models, writing assistants, writing support tools","Hamburg, Germany",CHI '23,inproceedings,245,,,,,,,,,
"Mozannar, Hussein and Bansal, Gagan and Fourney, Adam and Horvitz, Eric",Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641936,10.1145/3613904.3641936,"Code-recommendation systems, such as Copilot and CodeWhisperer, have the potential to improve programmer productivity by suggesting and auto-completing code. However, to fully realize their potential, we must understand how programmers interact with these systems and identify ways to improve that interaction. To seek insights about human-AI collaboration with code recommendations systems, we studied GitHub Copilot, a code-recommendation system used by millions of programmers daily. We developed CUPS, a taxonomy of common programmer activities when interacting with Copilot. Our study of 21 programmers, who completed coding tasks and retrospectively labeled their sessions with CUPS, showed that CUPS can help us understand how programmers interact with code-recommendation systems, revealing inefficiencies and time costs. Our insights reveal how programmers interact with Copilot and motivate new interface designs and metrics.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"AI-assisted Programming, Copilot, User State Model","Honolulu, HI, USA",CHI '24,inproceedings,142,,,,,,,,,
"Ding, Yangruibo and Min, Marcus J. and Kaiser, Gail and Ray, Baishakhi",CYCLE: Learning to Self-Refine the Code Generation,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3649825,10.1145/3649825,"Pre-trained code language models have achieved promising performance in code generation and improved the programming efficiency of human developers. However, their self-refinement capability is typically overlooked by the existing evaluations of code LMs, which focus only on the accuracy of the one-time prediction. For the cases when code LMs fail to implement the correct program, developers actually find it hard to debug and fix the faulty prediction since it is not written by the developers themselves. Unfortunately, our study reveals that code LMs cannot efficiently self-refine their faulty generations as well. In this paper, we propose CYCLE framework, learning to self-refine the faulty generation according to the available feedback, such as the execution results reported by the test suites. We evaluate CYCLE on three popular code generation benchmarks, HumanEval, MBPP, and APPS. The results reveal that CYCLE successfully maintains, sometimes improves, the quality of one-time code generation, while significantly improving the self-refinement capability of code LMs. We implement four variants of CYCLE with varied numbers of parameters across 350M, 1B, 2B, and 3B, and the experiments show that CYCLE consistently boosts the code generation performance, by up to 63.5",,,27,"Code Generation, Code Language Models, Iterative Programming, Source Code Modeling",,,article,108,April 2024,8,OOPSLA1,Proc. ACM Program. Lang.,apr,,,,
"Lam, Michelle S. and Ma, Zixian and Li, Anne and Freitas, Izequiel and Wang, Dakuo and Landay, James A. and Bernstein, Michael S.",Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581290,10.1145/3544548.3581290,"Machine learning practitioners often end up tunneling on low-level technical details like model architectures and performance metrics. Could early model development instead focus on high-level questions of which factors a model ought to pay attention to? Inspired by the practice of sketching in design, which distills ideas to their minimal representation, we introduce model sketching: a technical framework for iteratively and rapidly authoring functional approximations of a machine learning model’s decision-making logic. Model sketching refocuses practitioner attention on composing high-level, human-understandable concepts that the model is expected to reason over (e.g., profanity, racism, or sarcasm in a content moderation task) using zero-shot concept instantiation. In an evaluation with 17 ML practitioners, model sketching reframed thinking from implementation to higher-level exploration, prompted iteration on a broader range of model designs, and helped identify gaps in the problem formulation—all in a fraction of the time ordinarily required to build a model.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,24,,"Hamburg, Germany",CHI '23,inproceedings,741,,,,,,,,,
,Statslator: Interactive Translation of NHST and Estimation Statistics Reporting Styles in Scientific Documents,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606762,10.1145/3586183.3606762,"Inferential statistics are typically reported using p-values (NHST) or confidence intervals on effect sizes (estimation). This is done using a range of styles, but some readers have preferences about how statistics should be presented and others have limited familiarity with alternatives. We propose a system to interactively translate statistical reporting styles in existing documents, allowing readers to switch between interval estimates, p-values, and standardized effect sizes, all using textual and graphical reports that are dynamic and user customizable. Forty years of CHI papers are examined. Using only the information reported in scientific documents, equations are derived and validated on simulated datasets to show that conversions between p-values and confidence intervals are accurate. The system helps readers interpret statistics in a familiar style, compare reports that use different styles, and even validate the correctness of reports. Code and data: https://osf.io/x4ue7",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,14,"estimation, explorable explanation, interactive system, nhst, reading interface, statistics, transparent statistics","San Francisco, CA, USA",UIST '23,inproceedings,91,,,,,,,,,
"Chakrabarty, Tuhin and Laban, Philippe and Agarwal, Divyansh and Muresan, Smaranda and Wu, Chien-Sheng",Art or Artifice? Large Language Models and the False Promise of Creativity,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642731,10.1145/3613904.3642731,"Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT) [64], which measures creativity as a process, we use the Consensual Assessment Technique [3] and propose Torrance Test of Creative Writing (TTCW) to evaluate creativity as product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,34,"Creativity, Design Methods, Evaluation, Human-AI collaboration, Large Language Models, Natural Language Generation, StoryTelling","Honolulu, HI, USA",CHI '24,inproceedings,30,,,,,,,,,
"Subramonyam, Hari and Pea, Roy and Pondoc, Christopher and Agrawala, Maneesh and Seifert, Colleen",Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642754,10.1145/3613904.3642754,"Large language models (LLMs) exhibit dynamic capabilities and appear to comprehend complex and ambiguous natural language prompts. However, calibrating LLM interactions is challenging for interface designers and end-users alike. A central issue is our limited grasp of how human cognitive processes begin with a goal and form intentions for executing actions, a blindspot even in established interaction models such as Norman’s gulfs of execution and evaluation. To address this gap, we theorize how end-users ‘envision’ translating their goals into clear intentions and craft prompts to obtain the desired LLM response. We define a process of Envisioning by highlighting three misalignments on not knowing: (1) what the task should be, (2) how to instruct the LLM to do the task, and (3) what to expect for the LLM’s output in meeting the goal. Finally, we make recommendations to narrow the gulf of envisioning in human-LLM interactions.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,19,"cognitive psychology, large language models, prompt-based interactions","Honolulu, HI, USA",CHI '24,inproceedings,1039,,,,,,,,,
"Denny, Paul and Prather, James and Becker, Brett A. and Finnie-Ansley, James and Hellas, Arto and Leinonen, Juho and Luxton-Reilly, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami",Computing Education in the Era of Generative AI,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3624720,10.1145/3624720,Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.,,56–67,12,,,,article,,February 2024,67,2,Commun. ACM,jan,0001-0782,,,
"Xiao, Ziang and Deng, Wesley Hanwen and Lam, Michelle S. and Eslami, Motahhare and Kim, Juho and Lee, Mina and Liao, Q. Vera",Human-Centered Evaluation and Auditing of Language Models,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3636302,10.1145/3613905.3636302,"The recent advancements in Large Language Models (LLMs) have significantly impacted numerous, and will impact more, real-world applications. However, these models also pose significant risks to individuals and society. To mitigate these issues and guide future model development, responsible evaluation and auditing of LLMs are essential. This workshop aims to address the current “evaluation crisis” in LLM research and practice by bringing together HCI and AI researchers and practitioners to rethink LLM evaluation and auditing from a human-centered perspective. The workshop will explore topics around understanding stakeholders’ needs and goals with evaluation and auditing LLMs, establishing human-centered evaluation and auditing methods, developing tools and resources to support these methods, building community and fostering collaboration. By soliciting papers, organizing invited keynote and panel, and facilitating group discussions, this workshop aims to develop a future research agenda for addressing the challenges in LLM evaluation and auditing.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,6,"Audit, Evaluation, Generative AI, Large Language Models","
",CHI EA '24,inproceedings,476,,,,,,,,,
"Itagaki, Toma and Li, Richard",Smart-Pikachu: Extending Interactivity of Stuffed Animals with Large Language Models,2023,9798400700965,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586182.3625219,10.1145/3586182.3625219,"We propose Smart-Pikachu, a stuffed animal equipped with sensing and actuation to explore the use of large language models (LLM’s) with sensor data inputs. The augmentation of pressure sensing will allow for the LLM to interpret various interactions such as hugs and handshakes with the user. Furthermore, the actuation capabilities will extend our system’s interactivity by providing physical feedback to the user. We will also incorporate text-to-speech output from the LLM to add another mode of interaction between the system and user. In this Student Innovation Challenge, we intend to explore applications at the intersection of sensing and interaction through LLM’s and demonstrate an extension of LLMs’ multimodal capabilities.",Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,2,"Empathetic Computing, Prompt Design","San Francisco, CA, USA",UIST '23 Adjunct,inproceedings,114,,,,,,,,,
"Castro, Roberto L. and Ivanov, Andrei and Andrade, Diego and Ben-Nun, Tal and Fraguela, Basilio B. and Hoefler, Torsten",VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores,2023,9798400701092,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3581784.3607087,10.1145/3581784.3607087,,"Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis",,14,"sparse tensor cores, CUDA, GPGPU, pruning, neural networks","Denver, CO, USA",SC '23,inproceedings,72,,,,,,,,,
"Chilton, Lydia",Designing with AI,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3596926,10.1145/3596926,How I came to love design and used AI to alleviate the most frustrating parts of the process.,,20–25,6,,,,article,,Summer 2023,29,4,XRDS,jun,1528-4972,,,
,Koli Calling '22: Proceedings of the 22nd Koli Calling International Conference on Computing Education Research,2022,9781450396165,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Koli, Finland",,proceedings,,,,,,,,,,
"Dai, Chih-Pu and Ke, Fengfeng and Zhang, Nuodi and Barrett, Alex and West, Luke and Bhowmik, Saptarshi and Southerland, Sherry A. and Yuan, Xin",Designing Conversational Agents to Support Student Teacher Learning in Virtual Reality Simulation: A Case Study,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3637145,10.1145/3613905.3637145,"Maximizing educational impacts with learning technologies is one of the areas that researchers and practitioners are concerned about in the field of Human-Computer Interaction (HCI) and human-centered artificial intelligence (HCAI). In this case study, we report user experiences and lessons learned of the Enactive Virtual Environment for teaching practice (EVETeach) with AI-powered virtual student agents called Evelyn. We conducted a user study with a case study research design. We collected multiple sources of data from 24 student teachers, including participatory observations, field notes, semi-structured interviews, computer-based conversation logs, audio-, video-, and screen-recordings, and a cognitive walkthrough. We identified the following salient emerging findings as lessons learned: 1) Student teachers value and relate to the teaching practices in virtual reality simulation with AI-powered conversational agents, 2) AI-powered conversational agents inject humor to facilitate situational and social teaching practice, and 3) AI-powered conversational student agents maintain authentic discourse to promote student teachers’ pedagogical reasoning.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,8,"Artificial intelligence, Conversational agents, Teacher education, Virtual reality","
",CHI EA '24,inproceedings,513,,,,,,,,,
"Hourcade, Juan Pablo and Bonsignore, Elizabeth and Clegg, Tamara and Currin, Flannery and Fails, Jerry A and Jin, Georgie Qiao and Schmuecker, Summer R and Yarosh, Lana",Ethics of Emerging Communication and Collaboration Technologies for Children,2023,9798400701290,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3584931.3606957,10.1145/3584931.3606957,"This SIG will provide child-computer interaction researchers and practitioners, as well as other interested CSCW attendees, an opportunity to discuss topics related to the ethics of emerging communication and collaboration technologies for children. The child-computer interaction community has conducted many discussions on ethical issues, including a recent SIG at CHI 2023. However, the angle of communication and collaboration has not been a focus, even though emerging technologies could affect these aspects in significant ways. Hence, there is a need to consider emerging technologies, such as extended reality, and how they may impact the way children communicate and collaborate in face-to-face, remote, and hybrid (mixed-presence) contexts. This SIG will be an opportunity to discuss methods to consider these ethical concerns, properties of emerging technologies that may affect communication and collaboration, considerations for deployment of these emerging technologies, and future scenarios to ponder.",Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing,560–562,3,"participatory methods, extended reality, ethics, emerging technologies, children","Minneapolis, MN, USA",CSCW '23 Companion,inproceedings,,,,,,,,,,
"Chulpongsatorn, Neil and Lunding, Mille Skovhus and Soni, Nishan and Suzuki, Ryo",Augmented Math: Authoring AR-Based Explorable Explanations by Augmenting Static Math Textbooks,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606827,10.1145/3586183.3606827,"We introduce Augmented Math, a machine learning-based approach to authoring AR explorable explanations by augmenting static math textbooks without programming. To augment a static document, our system first extracts mathematical formulas and figures from a given document using optical character recognition (OCR) and computer vision. By binding and manipulating these extracted contents, the user can see the interactive animation overlaid onto the document through mobile AR interfaces. This empowers non-technical users, such as teachers or students, to transform existing math textbooks and handouts into on-demand and personalized explorable explanations. To design our system, we first analyzed existing explorable math explanations to identify common design strategies. Based on the findings, we developed a set of augmentation techniques that can be automatically generated based on the extracted content, which are 1) dynamic values, 2) interactive figures, 3) relationship highlights, 4) concrete examples, and 5) step-by-step hints. To evaluate our system, we conduct two user studies: preliminary user testing and expert interviews. The study results confirm that our system allows more engaging experiences for learning math concepts.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,16,"Augmented Reality, Augmented Textbook, Authoring Interfaces, Explorable Explanations, Interactive Paper","San Francisco, CA, USA",UIST '23,inproceedings,92,,,,,,,,,
"Chakrabarty, Tuhin and Padmakumar, Vishakh and Brahman, Faeze and Muresan, Smaranda",Creativity Support in the Age of Large Language Models: An Empirical Study Involving Professional Writers,2024,9798400704857,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3635636.3656201,10.1145/3635636.3656201,"The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions has led to increased interest in their use across various support tools. We investigate the effectiveness of contemporary LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing &nbsp;[17]. This allows writers to obtain model help in each of the three non-linear cognitive activities in the writing process: planning, translating and reviewing. Participants write short fiction/non-fiction with model help and are subsequently asked to submit a post-completion survey to provide qualitative feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while seeking help across all three types of cognitive activities, writers find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research directions in creative writing assistance using LLMs.",Proceedings of the 16th Conference on Creativity &amp; Cognition,132–155,24,"Co-Creativity, Computational Creativity, Creativity, Evaluation, Human-AI collaboration, Large Language Models, Natural Language Generation, StoryTelling","Chicago, IL, USA",C&amp;C '24,inproceedings,,,,,,,,,,
,Large Language Models to generate meaningful feature model instances,2023,9798400700910,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3579027.3608973,10.1145/3579027.3608973,Feature models are the ,Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A,15–26,12,"universal variability language, synthetic models, large language models, deep learning","Tokyo, Japan",SPLC '23,inproceedings,,,,,,,,,,
"Xiao, Ziang and Li, Tiffany Wenting and Karahalios, Karrie and Sundaram, Hari",Inform the Uninformed: Improving Online Informed Consent Reading with an AI-Powered Chatbot,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581252,10.1145/3544548.3581252,"Informed consent is a core cornerstone of ethics in human subject research. Through the informed consent process, participants learn about the study procedure, benefits, risks, and more to make an informed decision. However, recent studies showed that current practices might lead to uninformed decisions and expose participants to unknown risks, especially in online studies. Without the researcher’s presence and guidance, online participants must read a lengthy form on their own with no answers to their questions. In this paper, we examined the role of an AI-powered chatbot in improving informed consent online. By comparing the chatbot with form-based interaction, we found the chatbot improved consent form reading, promoted participants’ feelings of agency, and closed the power gap between the participant and the researcher. Our exploratory analysis further revealed the altered power dynamic might eventually benefit study response quality. We discussed design implications for creating AI-powered chatbots to offer effective informed consent in broader settings.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,17,"AI-powered chatbot, conversational agents, human-AI interaction, informed consent, power dynamic","Hamburg, Germany",CHI '23,inproceedings,112,,,,,,,,,
"Szymanski, Annalisa and Wimer, Brianna L and Anuyah, Oghenemaro and Eicher-Miller, Heather A and Metoyer, Ronald A",Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant with Refined Template Instructions,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641924,10.1145/3613904.3641924,"Large Language Models (LLMs) have the potential to contribute to the fields of nutrition and dietetics in generating food product explanations that facilitate informed food selections. However, the extent to which these models offer effective and accurate information remains unverified. In collaboration with registered dietitians (RDs), we evaluate the strengths and weaknesses of LLMs in providing accurate and personalized nutrition information. Through a mixed-methods approach, RDs validated GPT-4 outputs at various levels of prompt specificity, which led to the development of design guidelines used to prompt LLMs for nutrition information. We tested these guidelines by creating a GPT prototype, The Food Product Nutrition Assistant, tailored for food product explanations. This prototype was refined and evaluated in focus groups with RDs. We find that the implementation of these dietitian-reviewed template instructions enhance the generation of detailed food product descriptions and tailored nutrition information.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,22,"Artificial Intelligence, Food Recommendations, Large Language Models","Honolulu, HI, USA",CHI '24,inproceedings,992,,,,,,,,,
"Wang, Huanchen and Zhao, Minzhu and Hu, Wanyang and Ma, Yuxin and Lu, Zhicong",Critical Heritage Studies as a Lens to Understand Short Video Sharing of Intangible Cultural Heritage on Douyin,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642138,10.1145/3613904.3642138,"Intangible Cultural Heritage (ICH) faces numerous threats that can lead to its destruction. While the emergence of short video platforms provides opportunities for fostering innovation and communication among ICH practitioners and viewers, it is still understudied how different stakeholders present, explain, and manage ICH via short videos. To address this, we conduct a mixed-method study of ICH-related videos on Douyin, a popular short video platform in China with an extensive user base and wealth of ICH content. By adopting the Critical Heritage Studies (CHS) framework, we propose a taxonomy of frames that construct the landscape of ICH short videos and then investigate the interactions among different groups regarding power, identity, and knowledge. Additionally, we analyze viewer responses to different frames and groups based on audience metrics (e.g., # of likes and comments) and comments. Our research reveals that government-affiliated and indigenous groups dominate the promotion and presentation of ICH on Douyin. Contrary to previous literature, viewer responses show a preference for videos from external ICH groups and ordinary individuals, suggesting a tendency to counter authority and exclusivity associated with ICH. Moreover, it highlights a lack of sustainable debates and negotiations among different groups involved in ICH discourse. Situated within CHS, we provide design implications for ICH safeguarding and sustainability through short videos and online media.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,21,"Intangible cultural heritage, critical theory, online video platforms","Honolulu, HI, USA",CHI '24,inproceedings,613,,,,,,,,,
"Choe, Kiroong and Park, Seokhyeon and Jung, Seokweon and Kim, Hyeok and Yang, Ji Won and Hong, Hwajung and Seo, Jinwook",Supporting Novice Researchers to Write Literature Review using Language Models,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650787,10.1145/3613905.3650787,"A literature review requires more than summarization. While language model-based services and systems increasingly assist in analyzing accurate content in papers, their role in supporting novice researchers to develop independent perspectives on literature remains underexplored. We propose the design and evaluation of a system that supports the writing of argumentative narratives from literature. Based on the barriers faced by novice researchers before, during, and after writing, identified through semi-structured interviews, we propose a prototype of a language-model-assisted academic writing system that scaffolds the literature review writing process. A series of workshop studies revealed that novice researchers found the support valuable as they could initiate writing, co-create satisfying contents, and develop agency and confidence through a long-term dynamic partnership with the AI.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,9,"human-AI collaboration, literature review, novice researcher","
",CHI EA '24,inproceedings,307,,,,,,,,,
"Schneider, Nadav and Kadosh, Tal and Hasabnis, Niranjan and Mattson, Timothy and Pinter, Yuval and Oren, Gal",MPI-RICAL: Data-Driven MPI Distributed Parallelism Assistance with Transformers,2023,9798400707858,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3624062.3624063,10.1145/3624062.3624063,"Computational science has made rapid progress in recent years, leading to ever increasing demand for supercomputing resources. For scientific applications that leverage such resources, Message Passing Interface (MPI) plays a crucial role in enabling distributed memory parallelization across multiple nodes. However, parallelizing MPI code manually, and specifically, performing domain decomposition, is a challenging and error-prone task. In this paper, we address this problem by developing MPI-rical, a novel data-driven, programming-assistance tool that assists programmers in writing domain decomposition based distributed memory parallelization code using MPI. Specifically, we leverage Transformer architecture — the invention that led to advancements in the field of natural language processing (NLP) — with a supervised language model to suggest MPI functions and their proper locations in the code on the fly. In addition to the novel model for MPI-based parallel programming, in this paper, we also introduce MPICodeCorpus, the first publicly-available corpus of MPI-based parallel programs that is created by mining more than 15,000 open-source repositories on GitHub. Experimental results demonstrate the effectiveness of MPI-rical on both dataset from MPICodeCorpus and more importantly, on a compiled benchmark of MPI-based parallel programs for numerical computations that represent real-world scientific applications. Specifically, MPI-rical achieves F1 scores between 0.87-0.91 on these programs, demonstrating its accuracy in suggesting correct MPI functions at appropriate code locations. The source code used in this work, as well as other relevant sources, are available at: https://github.com/Scientific-Computing-Lab-NRCN/MPI-rical.","Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis",2–10,9,"Transformer, SPT-Code, MPICodeCorpus, MPI-rical, MPI, LLM, Domain Decomposition","Denver, CO, USA",SC-W '23,inproceedings,,,,,,,,,,
"Jin, Yucheng and Cai, Wanling and Chen, Li and Zhang, Yizhe and Doherty, Gavin and Jiang, Tonglin",Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642800,10.1145/3613904.3642800,"Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults’ attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"Generative AI, Human-AI Interaction, Music-based Reminiscence, Older Adults, Reminiscence","Honolulu, HI, USA",CHI '24,inproceedings,1012,,,,,,,,,
"Gallo, Simone and Paterno, Fabio and Malizia, Alessio","Conversational Interfaces in IoT Ecosystems: Where We Are, What Is Still Missing",2023,9798400709210,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626705.3627775,10.1145/3626705.3627775,"In the last few years, text and voice-based conversational agents have become more and more popular all over the world as virtual assistants for a variety of tasks. In addition, the deployment on the market of many smart objects connected with these agents has introduced the possibility of controlling and personalising the behaviour of several connected objects using natural language. This has the potential to allow people, also those without a technical background, to effectively control and use the wide variety of connected objects and services. In this paper, we present an analysis of how conversational agents have been used to interact with smart environments (such as smart homes). For this purpose, we have carried out a systematic literature review considering publications selected from the ACM and IEEE digital libraries to investigate the technologies used to design and develop conversational agents for IoT settings, including Artificial Intelligence techniques, the purpose that they have been used for, and the level of user involvement in such studies. The resulting analysis is useful to better understand how this field is evolving and indicate the challenges still open in this area that should be addressed in future research work to allow people to completely benefit from this type of solution.",Proceedings of the 22nd International Conference on Mobile and Ubiquitous Multimedia,279–293,15,"Conversational Agents, Internet of Things, User Experience","Vienna, Austria",MUM '23,inproceedings,,,,,,,,,,
"Wan, Ruyuan and Gebreegziabher, Simret Araya and Li, Toby Jia-Jun and Badillo-Urquiola, Karla",CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with Intelligent Agents,2024,9798400704857,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3635636.3664260,10.1145/3635636.3664260,"In recent years, there has been a growing interest in employing intelligent agents in writing. Previous work emphasizes the evaluation of the quality of end product—whether it was coherent and polished, overlooking the journey that led to the product, which is an invaluable dimension of the creative process. To understand how to recognize human efforts in co-writing with intelligent writing systems, we adapt Flower and Hayes’ cognitive process theory of writing and propose CoCo Matrix, a two-dimensional taxonomy of entropy and information gain, to depict the new human-agent co-writing model. We define four quadrants and situate thirty-four published systems within the taxonomy. Our research found that low entropy and high information gain systems are under-explored, yet offer promising future directions in writing tasks that benefit from the agent’s divergent planning and the human’s focused translation. CoCo Matrix, not only categorizes different writing systems but also deepens our understanding of the cognitive processes in human-agent co-writing. By analyzing minimal changes in the writing process, CoCo Matrix serves as a proxy for the writer’s mental model, allowing writers to reflect on their contributions. This reflection is facilitated through the measured metrics of information gain and entropy, which provide insights irrespective of the writing system used.",Proceedings of the 16th Conference on Creativity &amp; Cognition,504–511,8,"Collaborative Interaction, Creativity, Interaction Paradigms, Writing","Chicago, IL, USA",C&amp;C '24,inproceedings,,,,,,,,,,
"Jit, Sophia S and Spinney, Jennifer and Chandra, Priyank and Chilton, Lydia B and Soden, Robert",Writing out the Storm: Designing and Evaluating Tools for Weather Risk Messaging,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641926,10.1145/3613904.3641926,"Communicating risk to the public in the lead-up to and during severe weather events has the potential to reduce the impacts of these events on lives and property. Globally, these events are anticipated to increase due to climate change, rendering effective risk communication an integral component of climate adaptation policies. Research in risk communications literature has developed substantial knowledge and best practices for the design of risk messaging. This study considers the potential for quantifying the compliance of severe weather risk messages with these best practices, individually and at scale, and developing tools to improve risk communication messaging. The current work makes two contributions. First, we develop a string-matching approach to evaluate whether messaging complies with best practices and suggest areas for improvement. Second, we conduct an interview study with risk communication professionals to inform the design space of authoring tools and other technologies to support severe weather risk communicators.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Creativity Support, Crisis/Disaster, Empirical study that tells us about how people use a system","Honolulu, HI, USA",CHI '24,inproceedings,502,,,,,,,,,
"Teng, Shang-Hua",“Intelligent Heuristics Are the Future of Computing”,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627708,10.1145/3627708,"Back in 1988, the partial game trees explored by computer chess programs were among the largest search structures in real-world computing. Because the game tree is too large to be fully evaluated, chess programs must make heuristic strategic decisions based on partial information, making it an illustrative subject for teaching AI search. In one of his lectures that year on AI search for games and puzzles, Professor Hans Berliner—a pioneer of computer chess programs1—stated:As a student in the field of the theory of computation, I was naturally perplexed but fascinated by this perspective. I had been trained to believe that “Algorithms and computational complexity theory are the foundation of computer science.” However, as it happens, my attempts to understand heuristics in computing have subsequently played a significant role in my career as a theoretical computer scientist. I have come to realize that Berliner’s postulation is a far-reaching worldview, particularly in the age of big, rich, complex, and multifaceted data and models, when computing has ubiquitous interactions with science, engineering, humanity, and society. In this article,2I will share some of my experiences on the subject of heuristics in computing, presenting examples of theoretical attempts to understand the behavior of heuristics on real data, as well as efforts to design practical heuristics with desirable theoretical characterizations. My hope is that these theoretical insights from past heuristics—such as spectral partitioning, multilevel methods, evolutionary algorithms, and simplex methods—can shed light on and further inspire a deeper understanding of the current and future techniques in AI and data mining.",,,39,"network centrality, network influence, Shapley value, dimensionality reduction, spectral graph sparsification, PageRank, binary decision diagram, game trees, robust statistics, local clustering, evolutionary algorithm, linear programming, axiomatic approach, beyond worst-cast analysis, smoothed analysis, multilevel methods, spectral graph theory, deep learning, data analysis, network analysis, AI, data mining, Heuristics in computing",,,article,96,December 2023,14,6,ACM Trans. Intell. Syst. Technol.,nov,2157-6904,,,
"Okolo, Chinasa T.",Beyond AI Hype: A Hands-on Workshop Series for Enhancing AI Literacy in Middle and High School Students,2024,9798400706264,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3653666.3656075,10.1145/3653666.3656075,"The increasing usage of AI in high-stakes decision-making underscores a pressing need for various stakeholders to understand AI, learn how to identify AI-generated content, and become aware of its societal risks. We detail outcomes from engaging underrepresented secondary school students in a 5-day workshop series consisting of brief lectures, hands-on activities, and short research assignments. We find that the workshop improved students' knowledge about AI and the ethical implications of using these technologies. Our work highlights policy implications and outlines actionable efforts needed to advance AI literacy, with the workshop content being developed into an open-source AI literacy curriculum.",Proceedings of the 2024 on RESPECT Annual Conference,86–93,8,"ai literacy, ai pedagogy, computing education, equity, generative ai, human-centered ai, technology ethics","Atlanta, GA, USA",RESPECT 2024,inproceedings,,,,,,,,,,
"Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark","Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators",2023,9798400700149,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3571884.3604316,10.1145/3571884.3604316,"Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI’s ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as ‘open source’, many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.",Proceedings of the 5th International Conference on Conversational User Interfaces,,6,"survey, open source, large language models, chatGPT, RLHF","Eindhoven, Netherlands",CUI '23,inproceedings,47,,,,,,,,,
,ICDTE '23: Proceedings of the 7th International Conference on Digital Technology in Education,2023,9798400708527,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hangzhou, China",,proceedings,,,,,,,,,,
,AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas,2024,9798400710179,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3663384.3663398,10.1145/3663384.3663398,"The introduction of generative AI into multi-user applications raises novel considerations for the future of collaborative work. How might collaborative work practices change? How might we incorporate generative AI into shared tools with users’ needs at the forefront? We examine these questions in the context of a remote team conducting ideation tasks – an example of collaborative work enabled by a shared digital workspace. We conducted a user study with 17 professionals experienced with virtual group ideation workshops. Our study examined their use of the Collaborative Canvas, a virtual canvas tool with integrated generative AI capabilities that we created as a probe. Participants saw value in using generative AI to assist with group facilitation and to augment perspectives and ideas. However, they worried about losing human perspectives and critical thinking, as well as reputational harms resulting from harmful AI outputs. Participants shared suggestions for appropriate ways to incorporate generative AI capabilities within multi-user applications and identified needs for transparency of content ownership, private digital spaces, and specialized AI capabilities. Based on participants’ insights, we share implications and opportunities for the incorporation of generative AI into collaborative work in ways that place user needs at the forefront.",Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work,,14,"Brainstorming, Future of work, Generative AI, Group ideation, Mixed initiative, Shared virtual canvas","Newcastle upon Tyne, United Kingdom",CHIWORK '24,inproceedings,9,,,,,,,,,
"Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan",More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636263,10.1145/3636243.3636263,"Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.",Proceedings of the 26th Australasian Computing Education Conference,182–191,10,"Artificial Intelligence, Assessment, Computer Graphics, Computing Education, Evaluation, GPT-4, Large Language Models","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
"Kim, Taewook and Han, Hyomin and Adar, Eytan and Kay, Matthew and Chung, John Joon Young",Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642529,10.1145/3613904.3642529,"Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author’s vision to the audience’s context and taste at scale. However, it is unclear what the authors’ values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors’ concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors’ values.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Authorial control, Creative language arts, Creative writing, Generative AI, Large language models, Scalable personalization","Honolulu, HI, USA",CHI '24,inproceedings,31,,,,,,,,,
,RESPECT 2024: Proceedings of the 2024 on RESPECT Annual Conference,2024,9798400706264,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to RESPECT 2024! The Conference on Research in Equity and Sustained Participation in Engineering, Computing, and Technology is the premier venue for research on equity, inclusion, and justice in computing and computing education. This volume contains the papers presented at RESPECT 2024, the ninth edition of this conference, held on May 16-17, 2024 at the Georgia Tech Conference Center and Hotel in Atlanta, Georgia.As researchers, especially those of us focused on equity, freedom, and justice, our job is to give language to and make meaning of the joy, trauma, and unwavering spirit of the most vulnerable and marginalized among us. We don't do this simply to shed light but to influence change. We stand when others are forced to sit and speak when others are silenced. For many of us, the past several years have rendered our usual tools ineffective, and often we find ourselves seated, scared to stand, and essentially silenced as we search for new language to describe old problems. We increasingly, and rightfully, feel frustrate... powerles... angry. Unfortunately, we sometimes allow these feelings to lead us to inaction. However, as the Black feminist scholar Audre Lorde wrote in her masterpiece, Sister Outsider, anger, directed in productive ways, can be transformative.",,,,,"Atlanta, GA, USA",,proceedings,,,,,,,,,,
"Wang, Bryan",Democratizing Content Creation and Consumption through Human-AI Copilot Systems,2023,9798400700965,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586182.3616707,10.1145/3586182.3616707,"Content creation and consumption play vital roles in our lives. However, creating high-quality content can be challenging for beginners, while navigating through and consuming vast amounts of media content can be overwhelming and cumbersome. My Ph.D. research focuses on democratizing content creation and improving content consumption experiences for everyday users. I achieve this by designing and evaluating interactive AI systems that serve as copilots, assisting users with tedious tasks. I explore various media modalities, such as video, audio, text, and images, and investigate how their interplay can address problems in individual modalities. This paper offers a comprehensive overview of my research agenda, including recent contributions, on-going progress, and future directions.",Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,4,"Content Creation and Consumption, Creativity Support Tools., Human-AI Copilot System","San Francisco, CA, USA",UIST '23 Adjunct,inproceedings,105,,,,,,,,,
,WCAE '23: Proceedings of the Workshop on Computer Architecture Education,2023,9798400702532,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Orlando, FL, USA",,proceedings,,,,,,,,,,
"Endow, Shreyosi",Experiential Tutorials: Designing Tutorial Authoring Tools to Facilitate Tacit Knowledge Exchange in Creative Practices,2024,9798400704857,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3635636.3664624,10.1145/3635636.3664624,"Tutorials serve as a fundamental mechanism for disseminating knowledge within creative practices. Yet, tutorials struggle to convey tacit knowledge, a type of knowledge that practitioners internalize over time and experience. The subconscious nature of tacit knowledge often causes experienced practitioners to inadvertently omit fundamental actions in their instructions, which poses significant challenges for novices attempting to grasp the basics. However, no two novices are alike, making it challenging and burdensome for the tutorial author to align their tutorials with the audiences’ expertise. My doctoral research aims to create a more bespoke learning experience where tutorials are adapted to learners’ experiences without burdening the tutorial author. My contributions towards this goal include a tutorial concept extraction method that identifies the core vocabulary of a practice to inform authors of their audiences’ language, a typology that aids authors to identify key characteristics of tacit knowledge to enable richer instructions, and a framework that enables authors to use the tutorial medium effectively to maximize tacit knowledge transfer. I am currently working towards a tutorial authoring tool that leverages large language models to extract a learner’s unique and relevant experiences to create a personal knowledge inventory. Future work would combine this inventory with previous contributions to augment tutorials to be experiential, or aligned with learners’ experiences.",Proceedings of the 16th Conference on Creativity &amp; Cognition,30–34,5,"creative practices, tacit knowledge, tutorial authoring tools, tutorials","Chicago, IL, USA",C&amp;C '24,inproceedings,,,,,,,,,,
,"BCB '23: Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics",2023,9798400701269,Association for Computing Machinery,"New York, NY, USA",,,"ACM-BCB is the flagship conference of the ACM SIGBio, the ACM Special Interest Group in Bioinformatics, Computational Biology, and Biomedical Informatics. Continuing the annual tradition, the conference focuses on interdisciplinary research linking computer science, mathematics, statistics, biology, bioinformatics, biomedical informatics, and health informatics.",,,,,"Houston, TX, USA",,proceedings,,,,,,,,,,
,AST '24: Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024),2024,9798400705885,Association for Computing Machinery,"New York, NY, USA",,,"AST continues to be a venue for researchers and practitioners where they can discuss high quality research contributions on methods for software test automation, and various case studies reporting practices in this field. Indeed, software test automation is a discipline that has produced noteworthy research in the last decade.The special theme of AST 2024 is ",,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"Chin, Jenna H and Lee, Seungwook and Ashraf, Mohsena and Zago, Matt and Xie, Yun and Wolfgram, Elizabeth A and Yeh, Tom and Kim, Pilyoung",Young Children's Creative Storytelling with ChatGPT vs. Parent: Comparing Interactive Styles,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650770,10.1145/3613905.3650770,"Creative storytelling with parents plays an important role in child development including language skills, social competence, and emotional understanding. Recognizing the challenges parents face in finding time for storytelling due to work and home responsibilities, we explore the feasibility of ChatGPT for engaging children in creative storytelling. This study investigates the use of ChatGPT, a conversational agent powered by GPT-4, in creative storytelling with children aged 5-6, comparing its interaction styles with those of parents. The current study included eight child-parent dyads. We found that children were engaged in shorter and more frequent interactions with parents compared to ChatGPT. ChatGPT and parents asked different types of questions, and ChatGPT more frequently provided positive feedback compared to parents. More children selected the interactions with ChatGPT as their favorite interactions. The study provides preliminary evidence on ChatGPT's interaction styles and insights into its potential role in supporting families in creative storytelling activities.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"ChatGPT, Children, Parents, Storytelling","
",CHI EA '24,inproceedings,379,,,,,,,,,
"Sechayk, Yotam and Shamir, Ariel and Igarashi, Takeo",SmartLearn: Visual-Temporal Accessibility for Slide-based e-learning Videos,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650883,10.1145/3613905.3650883,"In the realm of e-learning, video-based content is increasingly prevalent but brings with it unique accessibility challenges. Our research, beginning with a formative study involving 53 participants, has pinpointed the primary accessibility barriers in video-based e-learning: mismatches in user pace, complex visual arrangements leading to unclear focus, and difficulties in navigating content. To tackle these barriers, we introduced SmartLearn (SL), an innovative tool designed to enhance the accessibility of video content. SL utilizes advanced video analysis techniques to address issues of focus, navigation, and pacing, enabling users to interact with video segments more effectively through a web interface. A subsequent evaluation demonstrated that SL significantly enhances user engagement, ease of access, and learnability over existing approaches. We conclude by presenting design guidelines derived from our study, aiming to promote future efforts in research and development towards a more inclusive digital education landscape.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,11,"Accessibility, E-learning, Online learning, Temporal Accessibility, Universal Design, Video Accessibility, Visual Accessibility","
",CHI EA '24,inproceedings,294,,,,,,,,,
"Gould, Sandy J. J.",Stochastic Machine Witnesses at Work: Today's Critiques of Taylorism are Inadequate for Workplace Surveillance Epistemologies of the Future,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642206,10.1145/3613904.3642206,"I argue that epistemologies of workplace surveillance are shifting in fundamental ways, and so critiques must shift accordingly. I begin the paper by relating Scientific Management to Human-Centred Computing’s ways of knowing through a study of ‘metaverse’ virtual reality workplaces. From this, I develop two observations. The first is that today’s workplace measurement science does not resemble the science that Taylor developed for Scientific Management. Contemporary workplace science is more passive, more intermediated and less controlled. The second observation is that new forms of workplace measurement challenge the norms of empirical science. Instead of having credentialed human witnesses observe phenomena and agree facts about them, we instead make outsourced, uncredentialed stochastic machine witnesses responsible for producing facts about work. With these observations in mind, I assert that critiques of workplace surveillance still framed by Taylorism will not be fit for interrogating workplace surveillance practices of the future.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,12,"Metaverse, Neo-Taylorism, Scientific Management, Taylorism, Ubiquitous Computing, Work Measurement, Workplace Surveillance","Honolulu, HI, USA",CHI '24,inproceedings,578,,,,,,,,,
"Smith, Julie M.",,2024,9798400706264,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3653666.3656065,10.1145/3653666.3656065,"Research Questions: (1) Is there a pattern of racial bias in student advising recommendations made by generative AI? (2) What safeguards can promote equity when using generative AI in high-stakes decision-making? Methodology: Using lists of names associated with various ethnic/racial groups, we asked ChatGPT and Claude AI for recommendations for colleges and majors for each student. Results: ChatGPT was more likely to recommend STEM majors to some student groups. ChatGPT did not show systematic bias in various metrics of school quality, but Claude AI did. There were also overall differences in the colleges recommended by Claude AI and ChatGPT. Implications: We provide cautions and recommendations for using generative AI in high-stakes tasks.",Proceedings of the 2024 on RESPECT Annual Conference,75–80,6,"artificial intelligence, generative ai, large language models, quity, racism, student advising","Atlanta, GA, USA",RESPECT 2024,inproceedings,,,,,,,,,,
,ACM SE '24: Proceedings of the 2024 ACM Southeast Conference,2024,9798400702372,Association for Computing Machinery,"New York, NY, USA",,,"We are pleased to welcome you to the 2024 ACM Southeast Conference (ACMSE 2024) sponsored by ACM and the College of Computing and Software Engineering (CCSE) at Kennesaw State University, Marietta, Georgia, USA. ACMSE 2024 continues the ACM Southeast Conference tradition of participation in all areas of computing disciplines. We hope this conference will be an excellent opportunity to share current and future hot research trends amongst researchers from around the world.",,,,,"Marietta, GA, USA",,proceedings,,,,,,,,,,
"Lu, Xinyi and Fan, Simin and Houghton, Jessica and Wang, Lu and Wang, Xu",ReadingQuizMaker: A Human-NLP Collaborative System that Supports Instructors to Design High-Quality Reading Quiz Questions,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580957,10.1145/3544548.3580957,"Despite that reading assignments are prevalent, methods to encourage students to actively read are limited. We propose a system ReadingQuizMaker that supports instructors to conveniently design high-quality questions to help students comprehend readings. ReadingQuizMaker adapts to instructors’ natural workflows of creating questions, while providing NLP-based process-oriented support. ReadingQuizMaker enables instructors to decide when and which NLP models to use, select the input to the models, and edit the outcomes. In an evaluation study, instructors found the resulting questions to be comparable to their previously designed quizzes. Instructors praised ReadingQuizMaker for its ease of use, and considered the NLP suggestions to be satisfying and helpful. We compared ReadingQuizMaker with a control condition where instructors were given automatically generated questions to edit. Instructors showed a strong preference for the human-AI teaming approach provided by ReadingQuizMaker. Our findings suggest the importance of giving users control and showing an immediate preview of AI outcomes when providing AI support.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,18,"Active Learning, Automatic Question Generation, Human-AI Teaming, Reading Quiz","Hamburg, Germany",CHI '23,inproceedings,454,,,,,,,,,
"Misback, Edward and Chan, Caleb C. and Saiki, Brett and Jun, Eunice and Tatlock, Zachary and Panchekha, Pavel",Odyssey: An Interactive Workbench for Expert-Driven Floating-Point Expression Rewriting,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606819,10.1145/3586183.3606819,"In recent years, researchers have proposed a number of automated tools to identify and improve floating-point rounding error in mathematical expressions. However, users struggle to effectively apply these tools. In this paper, we work with novices, experts, and tool developers to investigate user needs during the expression rewriting process. We find that users follow an iterative design process. They want to compare expressions on multiple input ranges, integrate and guide various rewriting tools, and understand where errors come from. We organize this investigation’s results into a three-stage workflow and implement that workflow in a new, extensible workbench dubbed Odyssey. Odyssey enables users to: (1) diagnose problems in an expression, (2) generate solutions automatically or by hand, and (3) tune their results. Odyssey tracks a working set of expressions and turns a state-of-the-art automated tool “inside out,” giving the user access to internal heuristics, algorithms, and functionality. In a user study, Odyssey enabled five expert numerical analysts to solve challenging rewriting problems where state-of-the-art automated tools fail. In particular, the experts unanimously praised Odyssey’s novel support for interactive range modification and local error visualization.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,15,"Debugging, Developer Tools, Dynamic Analysis, Expert Programming, Floating Point, Term Rewriting","San Francisco, CA, USA",UIST '23,inproceedings,77,,,,,,,,,
"Barkhordar, Ehsan and Atsizelti, Sukru",Assessing the Predictive Power of Social Media Data-Fed Large Language Models on Vote Preference,2024,9798400704536,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630744.3659831,10.1145/3630744.3659831,,Companion Publication of the 16th ACM Web Science Conference,53–55,3,"large language models, predictive analytics, social media, voter behavior","Stuttgart, Germany",Websci Companion '24,inproceedings,,,,,,,,,,
"Suraworachet, Wannapon and Seon, Jennifer and Cukurova, Mutlu",Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636905,10.1145/3636555.3636905,"Effective collaboration requires groups to strategically regulate themselves to overcome challenges. Research has shown that groups may fail to regulate due to differences in members’ perceptions of challenges which may benefit from external support. In this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ML) model and a Large Language model (LLM), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical/other challenges) from student discourse, was investigated. The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts. The paper provides an extensive discussion of the three approaches’ performance for automated detection and support of students’ challenge moments in collaborative learning activities. It argues that, although LLMs provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation. We conclude the paper with a discussion on additional considerations, including model transparency to explore feasible and meaningful analytical feedback for students and educators using LLMs.",Proceedings of the 14th Learning Analytics and Knowledge Conference,473–485,13,"Challenge moments, Collaborative learning, Discourse analysis, Natural language processing","Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
"Davis, Ernest",Benchmarks for Automated Commonsense Reasoning: A Survey,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3615355,10.1145/3615355,"More than one hundred benchmarks have been developed to test the commonsense knowledge and commonsense reasoning abilities of artificial intelligence (AI) systems. However, these benchmarks are often flawed, and many aspects of common sense remain untested. Consequently, there is currently no reliable way of measuring to what extent existing AI systems have achieved these abilities.This article surveys the development and uses of AI commonsense benchmarks. It enumerates 139 commonsense benchmarks that have been developed: 102 text-based, 18 image-based, 12 video-based, and 7 based in simulated physical environments. It gives more detailed descriptions of twelve of these, three from each category. It surveys the various methods used to construct commonsense benchmarks. It discusses the nature of common sense, the role of common sense in AI, the goals served by constructing commonsense benchmarks, desirable features of commonsense benchmarks, and flaws and gap in existing benchmarks. It concludes with a number of recommendations for future development of commonsense AI benchmarks; most importantly, that the creators of benchmarks invest the work needed to ensure that benchmark examples are consistently high quality.",,,41,"evaluation, benchmarks, commonsense reasoning, commonsense knowledge, Common sense",,,article,81,April 2024,56,4,ACM Comput. Surv.,oct,0360-0300,,,
"Zhou, Tongyu and Huang, Jeff and Chan, Gromit Yeuk-Yin",Epigraphics: Message-Driven Infographics Authoring,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642172,10.1145/3613904.3642172,"The message a designer wants to convey plays a pivotal role in directing the design of an infographic, yet most authoring workflows start with creating the visualizations or graphics first without gauging whether they fit the message. To address this gap, we propose Epigraphics, a web-based authoring system that treats an “epigraph” as the first-class object, and uses it to guide infographic asset creation, editing, and syncing. The system uses the text-based message to recommend visualizations, graphics, data filters, color palettes, and animations. It further supports between-asset interactions and fine-tuning such as recoloring, highlighting, and animation syncing that enhance the aesthetic cohesiveness of the assets. A gallery and case studies show that our system can produce infographics inspired by existing popular ones, and a task-based usability study with 10 designers show that a text-sourced workflow can standardize content, empower users to think more about the big picture, and facilitate rapid prototyping.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"data visualization, infographics authoring, visual storytelling","Honolulu, HI, USA",CHI '24,inproceedings,200,,,,,,,,,
H\,Sobotify: A Framework for Turning Robots into Social Robots,2024,9798400703225,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3610977.3637482,10.1145/3610977.3637482,"Sobotify is a software framework, which aims at simplifying the process of using robots in the field of social robotics. This paper delineates the design and usage of the framework. With Sobotify, even non-technical people should be enabled to use robots for their specific purposes, such as teachers in a classroom, therapists in a physiological or psychological therapy or childcare workers in kindergarten. During the development process of Sobotify, feedback from teachers at a vocational school have been taken into account in order to adjust the tools to their needs. The framework is designed to work with different robots including both humanoid (NAO and Pepper) and non-humanoid robots such as toy robots (Cozmo) with advanced abilities as well as very simple toy robots (MyKeepon). The framework was tested by two research works which proved that Sobotify is applicable in different setups. Further development is already planned for the next months, e.g. integration of additional robots and extension of tools.",Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,910–914,5,"hri, social robotics, software tools","Boulder, CO, USA",HRI '24,inproceedings,,,,,,,,,,
"Zhang, Ruipeng and Xie, Mengjun",A Knowledge Graph Question Answering Approach to IoT Forensics,2023,9798400700378,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3576842.3589161,10.1145/3576842.3589161,"Internet of Things (IoT) forensics has been a particularly challenging task for forensic practitioners due to the heterogeneity of IoT environments as well as the complexity and volume of IoT data. With the advent of artificial intelligence, question-answering (QA) systems have emerged as a potential solution for users to access sophisticated forensic knowledge and data. In this light, we present a novel IoT forensics framework that employs knowledge graph question answering (KGQA). Our framework enables investigators to access forensic artifacts and cybersecurity knowledge using natural language questions facilitated by a deep-learning-powered KGQA model. The proposed framework demonstrates high efficacy in answering natural language questions over the experimental IoT forensic knowledge graph.",Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation,446–447,2,"Digital Forensics, Internet of Things, Knowledge Graph, Ontology Design, Question Answering","San Antonio, TX, USA",IoTDI '23,inproceedings,,,,,,,,,,
"Wallat, Jonas and Jatowt, Adam and Anand, Avishek",Temporal Blind Spots in Large Language Models,2024,9798400703713,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3616855.3635818,10.1145/3616855.3635818,"Large language models (LLMs) have recently gained significant attention due to their unparalleled zero-shot performance on various natural language processing tasks. However, the pre-training data utilized in LLMs is often confined to a specific corpus, resulting in inherent freshness and temporal scope limitations. Consequently, this raises concerns regarding the effectiveness of LLMs for tasks involving temporal intents. In this study, we aim to investigate the underlying limitations of general-purpose LLMs when deployed for tasks that require a temporal understanding. We pay particular attention to handling factual temporal knowledge through three popular temporal QA datasets. Specifically, we observe low performance on detailed questions about the past and, surprisingly, for rather new information. In manual and automatic testing, we find multiple temporal errors and characterize the conditions under which QA performance deteriorates. Our analysis contributes to understanding LLM limitations and offers valuable insights into developing future models that can better cater to the demands of temporally-oriented tasks. The code is available https://github.com/jwallat/temporalblindspots.",Proceedings of the 17th ACM International Conference on Web Search and Data Mining,683–692,10,"large language models, question answering, temporal information retrieval, temporal query intents","Merida, Mexico",WSDM '24,inproceedings,,,,,,,,,,
"Barricelli, Barbara Rita and Fischer, Gerhard and Fogli, Daniela and Morch, Anders and Piccinno, Antonio and Valtolina, Stefano",Differentiating and Deepening the Concept of End User in the Digital Age (CoPDA 2024),2024,9798400717642,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3656650.3660533,10.1145/3656650.3660533,"Recent developments in Artificial Intelligence and meta-design challenge the understanding of the concept of “end user”. The 8th edition of a workshop in the series “Cultures of Participation in the Digital Age” (CoPDA 2024) aims to critically differentiate, dissect, and deepen the roles, experiences, and demands of end users considering contributions from different perspectives.",Proceedings of the 2024 International Conference on Advanced Visual Interfaces,,4,"Cultures of participation, Design trade-offs, End-User Development, Human-centered Artificial Intelligence, Large Language Models, Meta-design, Quality of Life","Arenzano, Genoa, Italy",AVI '24,inproceedings,118,,,,,,,,,
"Sarkar, Advait",Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?,2023,9798400703881,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3622758.3622882,10.1145/3622758.3622882,"The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which ","Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software",153–167,15,"self-efficacy, prompt engineering, live programming, learning barriers, generative shift hypothesis, end-user software customization, attention investment model","Cascais, Portugal",Onward! 2023,inproceedings,,,,,,,,,,
"Hu, Jiaxiong and Li, Junze and Zeng, Yuhang and Yang, Dongjie and Liang, Danxuan and Meng, Helen and Ma, Xiaojuan",Designing Scaffolding Strategies for Conversational Agents in Dialog Task of Neurocognitive Disorders Screening,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642960,10.1145/3613904.3642960,"Regular screening is critical for individuals at risk of neurocognitive disorders (NCDs) to receive early intervention. Conversational agents (CAs) have been adopted to administer dialog-based NCD screening tests for their scalability compared to human-administered tests. However, unique communication skills are required for CAs during NCD screening, e.g., clinicians often apply scaffolding to ensure subjects’ understanding of and engagement in screening tests. Based on scaffolding theories and analysis of clinicians’ practices from human-administered test recordings, we designed a scaffolding framework for the CA. In an exploratory wizard-of-Oz study, the CA empowered by ChatGPT administered tasks in the Grocery Shopping Dialog Task with 15 participants (10 diagnosed with NCDs). Clinical experts verified the quality of the CA’s scaffolding and we explored its effects on task understanding of the participants. Moreover, we proposed implications for the future design of CAs that enable scaffolding for scalable NCD screening.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,21,"Aging, Conversational Agent, Health, Neurocognitive Disorder Screening, Scaffolding","Honolulu, HI, USA",CHI '24,inproceedings,70,,,,,,,,,
"Tan, Felicia Fang-Yi and Xu, Peisen and Ram, Ashwin and Suen, Wei Zhen and Zhao, Shengdong and Huang, Yun and Hurter, Christophe",AudioXtend: Assisted Reality Visual Accompaniments for Audiobook Storytelling During Everyday Routine Tasks,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642514,10.1145/3613904.3642514,"The rise of multitasking in contemporary lifestyles has positioned audio-first content as an essential medium for information consumption. We present AudioXtend, an approach to augment audiobook experiences during daily tasks by integrating glanceable, AI-generated visuals through optical see-through head-mounted displays (OHMDs). Our initial study showed that these visual augmentations not only preserved users’ primary task efficiency but also dramatically enhanced immediate auditory content recall by 33.3% and 7-day recall by 32.7%, alongside a marked improvement in narrative engagement. Through participatory design workshops involving digital arts designers, we crafted a set of design principles for visual augmentations that are attuned to the requirements of multitaskers. Finally, a 3-day take-home field study further revealed new insights for everyday use, underscoring the potential of assisted reality (aR) to enhance heads-up listening and incidental learning experiences.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,22,"Assisted Reality, Audiobook Augmentation, Heads-Up Computing, Incidental learning, Optical See-Through Head-Mounted Displays, Recall Enhancement, Smart-glasses, Visual Storytelling","Honolulu, HI, USA",CHI '24,inproceedings,83,,,,,,,,,
"Shaer, Orit and Cooper, Angelora and Mokryn, Osnat and Kun, Andrew L and Ben Shoshan, Hagit",AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642414,10.1145/3613904.3642414,"The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process – the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implications for HCI education and practice.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"Brainwriting, LLM, human-AI collaboration","Honolulu, HI, USA",CHI '24,inproceedings,1050,,,,,,,,,
"Bird, Jordan J. and Wright, David and Sumich, Alexander and Lotfi, Ahmad",Generative AI in Psychological Therapy: Perspectives on Computational Linguistics and Large Language Models in Written Behaviour Monitoring,2024,9798400717604,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652037.3663893,10.1145/3652037.3663893,"Technological intervention to support care areas that some people may not have access to is of paramount importance to promote sustainable development of good health and wellbeing. This study aims to explore the linguistic similarities and differences between human professionals and Generative Artificial Intelligence (AI) conversational agents in therapeutic dialogues. Initially, the MISTRAL-7B Large Language Model (LLM) is instructed to generate responses to patient queries to form a synthetic equivalent to a publicly available psychology dataset. A large set of linguistic features (e.g., text metrics, lexical diversity and richness, readability scores, sentiment, emotions, and named entities) is extracted and studied from both the expert and synthetically-generated text. The results suggest a significantly richer vocabulary in humans than the LLM approach. Similarly, the use of sentiment was significantly different between the two, suggesting a difference in the supportive or objective language used and that synthetic linguistic expressions of emotion may differ from those expressed by an intelligent being. However, no statistical significance was observed between human professionals and AI in the use of function words, pronouns and several named entities; possibly reflecting an increased proficiency of LLMs in modelling some language patterns, even in a specialised context (i.e., therapy). However, current findings do not support the similarity in sentimental nuance and emotional expression, which limits the effectiveness of contemporary LLMs as standalone agents. Further development is needed towards clinically validated algorithms.",Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments,322–328,7,"AI, Computational Linguistics, Generative Artificial Intelligence, LLMs, Large Language Models, Psychology","Crete, Greece",PETRA '24,inproceedings,,,,,,,,,,
"Agarwal, Nimisha and Kumar, Viraj and Raman, Arun and Karkare, Amey",A Bug's New Life: Creating Refute Questions from Filtered CS1 Student Code Snapshots,2023,9798400700484,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3576882.3617916,10.1145/3576882.3617916,"In an introductory programming (CS1) context, a Refute question asks students for a counter-example which proves that a given code fragment is an incorrect solution for a given task. Such a question can be used as an assessment item to (formatively) develop or (summatively) demonstrate a student's abilities to comprehend the task and the code well enough to recognize a mismatch. These abilities assume greater significance with the emergence of generative AI technologies capable of writing code that is plausible (at least to novice programmers) but not always correct.Instructors must address three concerns while designing an effective Refute question, each influenced by their specific teaching-learning context: (1) Is the task comprehensible? (2) Is the incorrect code a plausible solution for the task? (3) Is the complexity of finding a counter-example acceptable? While the first concern can often be addressed by reusing tasks from previous code writing questions, addressing the latter concerns may require substantial instructor effort. We therefore investigate whether concerns (2) and (3) can be addressed by buggy student solutions for the corresponding code writing question from a previous course offering. For 6 code writing questions (from a Fall 2015 C programming course), our automated evaluation system logged 13,847 snapshots of executable student code, of which 10,574 were buggy (i.e., they failed at least one instructor-supplied test case). Code selected randomly from this pool rarely addresses these concerns, and manual selection is infeasible. Our paper makes three contributions. First, we propose an automated mechanism to filter this pool to a more manageable number of snapshots from which appropriate code can be selected manually. Second, we evaluate our semi-automated mechanism with respect to concerns (2) and (3) by surveying a diverse set of 56 experienced participants (instructors, tutors, and teaching assistants). Third, we use this mechanism to seed a public repository of Refute questions and provide a template to create additional questions using a public resource (CodeCheck).",Proceedings of the ACM Conference on Global Computing Education Vol 1,7–14,8,"refute questions, assessment, CS1","Hyderabad, India",CompEd 2023,inproceedings,,,,,,,,,,
"Fan, Ruchao and Chu, Wei and Chang, Peng and Alwan, Abeer",A CTC Alignment-Based Non-Autoregressive Transformer for End-to-End Automatic Speech Recognition,2023,,IEEE Press,,https://doi.org/10.1109/TASLP.2023.3263789,10.1109/TASLP.2023.3263789,"Recently, end-to-end models have been widely used in automatic speech recognition (ASR) systems. Two of the most representative approaches are connectionist temporal classification (CTC) and attention-based encoder-decoder (AED) models. Autoregressive transformers, variants of AED, adopt an autoregressive mechanism for token generation and thus are relatively slow during inference. In this article, we present a comprehensive study of a CTC Alignment-based Single-Step Non-Autoregressive Transformer (CASS-NAT) for end-to-end ASR. In CASS-NAT, word embeddings in the autoregressive transformer (AT) are substituted with token-level acoustic embeddings (TAE) that are extracted from encoder outputs with the acoustical boundary information offered by the CTC alignment. TAE can be obtained in parallel, resulting in a parallel generation of output tokens. During training, Viterbi-alignment is used for TAE generation, and multiple training strategies are further explored to improve the word error rate (WER) performance. During inference, an error-based alignment sampling method is investigated in depth to reduce the alignment mismatch in the training and testing processes. Experimental results show that the CASS-NAT has a WER that is close to AT on various ASR tasks, while providing a &lt;inline-formula&gt;&lt;tex-math notation=",,1436–1448,13,,,,article,,2023,31,,"IEEE/ACM Trans. Audio, Speech and Lang. Proc.",mar,2329-9290,,,
"Snyder, Caitlin and Hutchins, Nicole M and Cohn, Clayton and Fonteles, Joyce Horn and Biswas, Gautam",Analyzing Students Collaborative Problem-Solving Behaviors in Synergistic STEM+C Learning,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636912,10.1145/3636555.3636912,"This study introduces a methodology to investigate students’ collaborative behaviors as they work in pairs to build computational models of scientific processes. We expand the Self-Regulated Learning (SRL) framework—specifically, Planning, Enacting, and Reflection—proposed in the literature, applying it to examine students’ collaborative problem-solving (CPS) behaviors in a computational modeling task. We analyze these behaviors by employing a Markov Chain (MC) modeling approach that scrutinizes students’ model construction and model debugging behaviors during CPS. This involves interpreting their actions in the system collected through computer logs and analyzing their conversations using a Large Language Model (LLM) as they progress through their modeling task in segments. Our analytical framework assesses the behaviors of high- and low-performing students by evaluating their proficiency in completing the specified computational model for a kinematics problem. We employ a mixed-methods approach, combining Markov Chain analysis of student problem-solving transitions with qualitative interpretations of their conversation segments. The results highlight distinct differences in behaviors between high- and low-performing groups, suggesting potential for developing adaptive scaffolds in future work to enhance support for students in collaborative problem-solving.",Proceedings of the 14th Learning Analytics and Knowledge Conference,540–550,11,"SRL, STEM, collaboration, learning analytics","Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
"Wang, Zijie J. and Kulkarni, Chinmay and Wilcox, Lauren and Terry, Michael and Madaio, Michael",Farsight: Fostering Responsible AI Awareness During AI Application Prototyping,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642335,10.1145/3613904.3642335,"Prompt-based interfaces for Large Language Models (LLMs) have made prototyping and building AI-powered applications easier than ever before. However, identifying potential harms that may arise from AI applications remains a challenge, particularly during prompt-based prototyping. To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping. Based on a user’s prompt, Farsight highlights news articles about relevant AI incidents and allows users to explore and edit LLM-generated use cases, stakeholders, and harms. We report design insights from a co-design study with 10 AI prototypers and findings from a user study with 42 AI prototypers. After using Farsight, AI prototypers in our user study are better able to independently identify potential harms associated with a prompt and find our tool more useful and usable than existing resources. Their qualitative feedback also highlights that Farsight encourages them to focus on end-users and think beyond immediate harms. We discuss these findings and reflect on their implications for designing AI prototyping experiences that meaningfully engage with AI harms. Farsight is publicly accessible at: https://pair-code.github.io/farsight.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,40,"Human-AI Collaboration, Large Language Models, Responsible AI","Honolulu, HI, USA",CHI '24,inproceedings,976,,,,,,,,,
"Holk, Simon and Marta, Daniel and Leite, Iolanda",PREDILECT: Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning,2024,9798400703225,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3610977.3634970,10.1145/3610977.3634970,"Preference-based reinforcement learning (RL) has emerged as a new field in robot learning, where humans play a pivotal role in shaping robot behavior by expressing preferences on different sequences of state-action pairs. However, formulating realistic policies for robots demands responses from humans to an extensive array of queries. In this work, we approach the sample-efficiency challenge by expanding the information collected per query to contain both preferences and optional text prompting. To accomplish this, we leverage the zero-shot capabilities of a large language model (LLM) to reason from the text provided by humans. To accommodate the additional query information, we reformulate the reward learning objectives to contain flexible highlights -- state-action pairs that contain relatively high information and are related to the features processed in a zero-shot fashion from a pretrained LLM. In both a simulated scenario and a user study, we reveal the effectiveness of our work by analyzing the feedback and its implications. Additionally, the collective feedback collected serves to train a robot on socially compliant trajectories in a simulated social navigation landscape. We provide video examples of the trained policies at https://sites.google.com/view/rl-predilect",Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,259–268,10,"human-in-the-loop learning, interactive learning, preference learning, reinforcement learning","Boulder, CO, USA",HRI '24,inproceedings,,,,,,,,,,
,"SPLASH 2023: Companion Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity",2023,9798400703843,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to SPLASH 2023, the 38th ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity, held in the peaceful town of Cascais, half an hour from Lisbon, Portugal. SPLASH usually takes place over six days, Sunday to Friday, and this year is no exception: Cascais welcomes SPLASH from the 22nd to the 27th October.",,,,,"Cascais, Portugal",,proceedings,,,,,,,,,,
"Jhaver, Shagun and Rathi, Himanshu and Saha, Koustuv",Bystanders of Online Moderation: Examining the Effects of Witnessing Post-Removal Explanations,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642204,10.1145/3613904.3642204,"Prior research on transparency in content moderation has demonstrated the benefits of offering post-removal explanations to sanctioned users. In this paper, we examine whether the influence of such explanations transcends those who are moderated to the bystanders who witness such explanations. We conduct a quasi-experimental study on two popular Reddit communities (r/AskReddit and r/science) by collecting their data spanning 13 months—a total of 85.5M posts made by 5.9M users. Our causal-inference analyses show that bystanders significantly increase their posting activity and interactivity levels as compared to their matched control set of users. In line with previous applications of Deterrence Theory on digital platforms, our findings highlight that understanding the rationales behind sanctions on other users significantly shapes observers’ behaviors. We discuss the theoretical implications and design recommendations of this research, focusing on how investing more efforts in post-removal explanations can help build thriving online communities.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,9,"causal-inference, content moderation, social media, transparency","Honolulu, HI, USA",CHI '24,inproceedings,191,,,,,,,,,
"Sharma, Ashish and Rushton, Kevin and Lin, Inna Wanyin and Nguyen, Theresa and Althoff, Tim",Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642761,10.1145/3613904.3642761,"Self-guided mental health interventions, such as “do-it-yourself” tools to learn and practice coping strategies, show great promise to improve access to mental health care. However, these interventions are often cognitively demanding and emotionally triggering, creating accessibility barriers that limit their wide-scale implementation and adoption. In this paper, we study how human-language model interaction can support self-guided mental health interventions. We take cognitive restructuring, an evidence-based therapeutic technique to overcome negative thinking, as a case study. In an IRB-approved randomized field study on a large mental health website with 15,531 participants, we design and evaluate a system that uses language models to support people through various steps of cognitive restructuring. Our findings reveal that our system positively impacts emotional intensity for 67% of participants and helps 65% overcome negative thoughts. Although adolescents report relatively worse outcomes, we find that tailored interventions that simplify language model generations improve overall effectiveness and equity.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,29,"cognitive restructuring, field study, human-AI collaboration, language models, mental health, randomized trial","Honolulu, HI, USA",CHI '24,inproceedings,700,,,,,,,,,
"Ha, Juhye and Jeon, Hyeon and Han, Daeun and Seo, Jinwook and Oh, Changhoon","CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642472,10.1145/3613904.3642472,"Large language models (LLMs) have facilitated significant strides in generating conversational agents, enabling seamless, contextually relevant dialogues across diverse topics. However, the existing LLM-driven conversational agents have fixed personalities and functionalities, limiting their adaptability to individual user needs. Creating personalized agent personas with distinct expertise or traits can address this issue. Nonetheless, we lack knowledge of how people customize and interact with agent personas. In this research, we investigated how users customize agent personas and their impact on interaction quality, diversity, and dynamics. To this end, we developed CloChat, an interface supporting easy and accurate customization of agent personas in LLMs. We conducted a study comparing how participants interact with CloChat and ChatGPT. The results indicate that participants formed emotional bonds with the customized agents, engaged in more dynamic dialogues, and showed interest in sustaining interactions. These findings contribute to design implications for future systems with conversational agents using LLMs.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,24,"Conversational Agents, Large Language Models, Persona, Persona Customization","Honolulu, HI, USA",CHI '24,inproceedings,305,,,,,,,,,
"Cuadra, Andrea and Bethune, Jessica and Krell, Rony and Lempel, Alexa and H\",Designing Voice-First Ambient Interfaces to Support Aging in Place,2023,9781450398930,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3563657.3596104,10.1145/3563657.3596104,"We focus on the stories of five older adults who became voice assistant users through our study, and with whom we speculated about future interfaces through two design probes, one for health data reporting and one for positive reminiscing. We delivered a voice-first ambient interface (VFAI) to each participant, and closely observed participants’ journeys through periodic themed interviews (16 hours, 21 minutes of transcribed recordings), usage log reviews (4,657 entries), and phone and text support. Participants’ lived experiences impacted their perceptions and interactions with their VFAI, fueling rich insights about how to design for diverse needs. For example, while one participant saw increased potential in the VFAI after interacting with the design probe for health data reporting, another was skeptical of using it to communicate with her doctor. We contribute an in-depth exploration of VFAIs to support aging in place, implications for design, and areas for future work for tailoring VFAIs towards enabling continuity of care in people’s homes.",Proceedings of the 2023 ACM Designing Interactive Systems Conference,2189–2205,17,"Alexa, Older adults, aging in place, design probes, empirical study, field study, home health, inclusive design, internet of things, interviews, prototyping/implementation, qualitative methods, smart speakers, voice assistants, voice-first ambient interfaces, wellbeing","Pittsburgh, PA, USA",DIS '23,inproceedings,,,,,,,,,,
"Chen, Yuyan and Fu, Qiang and Yuan, Yichen and Wen, Zhihao and Fan, Ge and Liu, Dayiheng and Zhang, Dongmei and Li, Zhixu and Xiao, Yanghua",Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models,2023,9798400701245,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3583780.3614905,10.1145/3583780.3614905,"Large language models (LLMs) have gained widespread adoption in various natural language processing tasks, including question answering and dialogue systems. However, a major drawback of LLMs is the issue of hallucination, where they generate unfaithful or inconsistent content that deviates from the input source, leading to severe consequences. In this paper, we propose a robust discriminator named RelD to effectively detect hallucination in LLMs' generated answers. RelD is trained on the constructed RelQA, a bilingual question-answering dialogue dataset along with answers generated by LLMs and a comprehensive set of metrics. Our experimental results demonstrate that the proposed RelD successfully detects hallucination in the answers generated by diverse LLMs. Moreover, it performs well in distinguishing hallucination in LLMs' generated answers from both in-distribution and out-of-distribution datasets. Additionally, we also conduct a thorough analysis of the types of hallucinations that occur and present valuable insights. This research significantly contributes to the detection of reliable answers generated by LLMs and holds noteworthy implications for mitigating hallucination in the future work.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,245–255,11,"reliable answers, large language models, hallucination detection","Birmingham, United Kingdom",CIKM '23,inproceedings,,,,,,,,,,
,ICIEAI '23: Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence,2023,9798400716157,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Xiamen, China",,proceedings,,,,,,,,,,
"Amer-Yahia, Sihem and Bonifati, Angela and Chen, Lei and Li, Guoliang and Shim, Kyuseok and Xu, Jianliang and Yang, Xiaochun",From Large Language Models to Databases and Back: A Discussion on Research and Education,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3631504.3631518,10.1145/3631504.3631518,"In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.",,49–56,8,,,,article,,September 2023,52,3,SIGMOD Rec.,nov,0163-5808,,,
"Robinson, Raquel Breejon and Alvarez, Alberto and Mekler, Elisa D.",How to write a CHI paper (asking for a friend),2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3644051,10.1145/3613905.3644051,"Writing and genre conventions are extant to any scientific community, and CHI is no different. In this paper, we present the early phases of an AI tool called KITSUNE, which takes text and adapts it toward the writing conventions of a CHI paper. We describe the development of the tool with the intent to promote discussion around how writing conventions are upheld and unquestioned by the CHI community, and how this translates to the work produced. In addition, we bring up questions surrounding how the introduction of LLMs into academic writing will fundamentally change how conventions will be upheld now and in the future.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,8,"CHI, LLMs, artificial intelligence, writing conventions","
",CHI EA '24,inproceedings,558,,,,,,,,,
"Joshi, Purvika and Sati, Subhangi and Sar, Ayan and Aich, Sumit and Choudhury, Tanupriya and Kotecha, Ketan and Ozseven, Turgut",An End-to-End Framework for Multi-Docs Chatbot using Llama2,2024,9798400716928,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3660853.3660921,10.1145/3660853.3660921,"The evolution of conversational agents, in particular the case with chatbots, has experienced huge boosts in recent years, enabling a variety of tasks and allowing users to enjoy much more interaction. This research presents a sequential model for a Chatbot of multiple documents that is based on the best of the Llama2 mod-el. The document classification framework intends to offer a user-oriented as well as a versatile conversational approach that draws on data from several fields. Through proper implementation of state-of-the-art natural language processing technology, the chatbot can understand users' inquiries, retrieve the required in-formation from the uploaded files, and respond fluently and understandably. It provides document management processes, like file handling of PDF, DOCX, etc., which enables the user to work with almost all file types and formats. And that directly uses Hugging Face Transformers in such processes as text embed-ding and conversational generation. One of the key components of the system is the FAISS tool that allows for vector storage and retrieval keeping the chatbot operating efficiently in the process of searching and retrieving information from vast document collections. In summary, the work provided here lays out the foundations of the multi-doc system which is a powerful tool that can be used to improve the deployments and information search tasks, with the effect of boost-ing user engagement and productivity.",Proceedings of the Cognitive Models and Artificial Intelligence Conference,232–236,5,"Chatbot, Generative AI, LLM, Natural Language Processing","undefinedstanbul, Turkiye",AICCONF '24,inproceedings,,,,,,,,,,
,In-Page Navigation Aids for Screen-Reader Users with Automatic Topicalisation and Labelling,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3649223,10.1145/3649223,"Navigation aids such as headers and internal links provide vital support for screen-reader users on web documents to grasp a document’s structure. However, when such navigation aids are unavailable or not appropriately marked up, this situation can cause serious difficulties. This paper presents the design and evaluation of a tool for automatically generating navigation aids with headers and internal links for screen readers with topicalisation and labelling algorithms. The proposed tool uses natural language processing techniques to divide a web document into topic segments and label each segment in two cycles based on its content. We conducted an initial user study in the first cycle with eight blind and partially-sighted screen reader users. The evaluation involved tasks with questions answered by participants with information from texts with and without automatically generated headers. The results in the first cycle provided preliminary indicators of performance improvement and cognitive load reduction. The second cycle involved co-designing an improved version with two blind experts in web accessibility, resulting in a browser extension which injects automatically generated headers and in-page navigation with internal links, along with improvements in the generation of labels using OpenAI’s ChatGPT. The browser extension was evaluated by seven blind participants using the same four texts used to evaluate the preliminary prototype developed in the first cycle. With the two development cycles, the study provided important insights into the design of navigation aids for screen-reader users using natural language processing techniques, including the potential use of generative artificial intelligence for assistive technologies and limitations that need to be explored in future research.",,,,"Accessibility, natural language processing, screen readers, topic segmentation and labelling, large language models, assistive technologies",,,article,,,,,ACM Trans. Access. Comput.,feb,1936-7228,Just Accepted,,
"Pillutla, Krishna and Liu, Lang and Thickstun, John and Welleck, Sean and Swayamdipta, Swabha and Zellers, Rowan and Oh, Sewoong and Choi, Yejin and Harchaoui, Zaid",MAUVE scores for generative models: theory and practice,2024,,JMLR.org,,,,"Generative artificial intelligence has made significant strides, producing text indistinguishable from human prose and remarkably photorealistic images. Automatically measuring how close the generated data distribution is to the target distribution is central to diagnosing existing models and developing better ones. We present MAUVE, a family of comparison measures between pairs of distributions such as those encountered in the generative modeling of text or images. These scores are statistical summaries of divergence frontiers capturing two types of errors in generative modeling. We explore three approaches to statistically estimate these scores: vector quantization, non-parametric estimation, and classifier-based estimation. We provide statistical bounds for the vector quantization approach.Empirically, we find that the proposed scores paired with a range of f-divergences and statistical estimation methods can quantify the gaps between the distributions of humanwritten text and those of modern neural language models by correlating with human judgments and identifying known properties of the generated texts. We demonstrate in the vision domain that MAUVE can identify known properties of generated images on par with or better than existing metrics. In conclusion, we present practical recommendations for using MAUVE effectively with language and image modalities.",,,92,"generative models, evaluation, divergence frontiers, neural text generation, large language models, f-divergences, statistical estimation",,,article,356,January 2023,24,1,J. Mach. Learn. Res.,mar,1532-4435,,,
"Petridis, Savvas and Diakopoulos, Nicholas and Crowston, Kevin and Hansen, Mark and Henderson, Keren and Jastrzebski, Stan and Nickerson, Jeffrey V and Chilton, Lydia B",AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580907,10.1145/3544548.3580907,"News media often leverage documents to find ideas for stories, while being critical of the frames and narratives present. Developing angles from a document such as a press release is a cognitively taxing process, in which journalists critically examine the implicit meaning of its claims. Informed by interviews with journalists, we developed AngleKindling, an interactive tool which employs the common sense reasoning of large language models to help journalists explore angles for reporting on a press release. In a study with 12 professional journalists, we show that participants found AngleKindling significantly more helpful and less mentally demanding to use for brainstorming ideas, compared to a prior journalistic angle ideation tool. AngleKindling helped journalists deeply engage with the press release and recognize angles that were useful for multiple types of stories. From our findings, we discuss how to help journalists customize and identify promising angles, and extending AngleKindling to other knowledge-work domains.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,16,"Brainstorming, Generative AI, Ideation, Journalism, Large Language Models","Hamburg, Germany",CHI '23,inproceedings,225,,,,,,,,,
"Li, Haotian and Wang, Yun and Qu, Huamin",Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642726,10.1145/3613904.3642726,"Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans’ and AI’s advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,19,"Data storytelling, human-AI collaboration","Honolulu, HI, USA",CHI '24,inproceedings,845,,,,,,,,,
"Hoque, Md Naimul and Mahfuz, Ayman A and Kindi, Mayukha Sridhatri and Hassan, Naeemul",Towards Designing a Question-Answering Chatbot for Online News: Understanding Questions and Perspectives,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642007,10.1145/3613904.3642007,"Large Language Models (LLMs) have created opportunities for designing chatbots that can support complex question-answering (QA) scenarios and improve news audience engagement. However, we still lack an understanding of what roles journalists and readers deem fit for such a chatbot in newsrooms. To address this gap, we first interviewed six journalists to understand how they answer questions from readers currently and how they want to use a QA chatbot for this purpose. To understand how readers want to interact with a QA chatbot, we then conducted an online experiment (N=124) where we asked each participant to read three news articles and ask questions to either the author(s) of the articles or a chatbot. By combining results from the studies, we present alignments and discrepancies between how journalists and readers want to use QA chatbots and propose a framework for designing effective QA chatbots in newsrooms.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"LLMs, Online news, chatbots, question-answering","Honolulu, HI, USA",CHI '24,inproceedings,154,,,,,,,,,
"Venkatasubramanian, Krishna and Ranalli, Tina-Marie",Leveraging technology for post-abuse peer support for people with intellectual and developmental disabilities,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650993,10.1145/3613905.3650993,"Our aim in this paper is to leverage technology to facilitate peer support for abuse survivors with intellectual and developmental disabilities (I/DD). In this regard, we talked to staff from a trauma services agency in the US that has experience providing post-abuse peer-support work. We found that: originally peer support sessions were exclusively in-person sessions that enabled the establishment of a productive connection and building trust between the survivor and the peer leader. However, since COVID-19, peer support sessions has also been provided online via teleconferencing and structured presentations. These online sessions have the advantage that they make it easier for survivors to participate in peer support. However, they often end up diminishing the peer-survivor connection that in-person sessions enabled. Based on these findings, we suggest design of technologies that can enable online peer support to establish a productive connection between survivors and peers as in-person sessions do.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"design, developmental disability, intellectual disability, peer-support, trauma","
",CHI EA '24,inproceedings,225,,,,,,,,,
"Bauer, Christine and Carterette, Ben and Ferro, Nicola and Fuhr, Norbert and Beel, Joeran and Breuer, Timo and Clarke, Charles L. A. and Crescenzi, Anita and Demartini, Gianluca and Di Nunzio, Giorgio Maria and Dietz, Laura and Faggioli, Guglielmo and Ferwerda, Bruce and Fr\",Report on the Dagstuhl Seminar on Frontiers of Information Access Experimentation for Research and Education,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636341.3636351,10.1145/3636341.3636351,This report documents the program and the outcomes of Dagstuhl Seminar 23031 ,,,28,,,,article,7,June 2023,57,1,SIGIR Forum,dec,0163-5840,,,
"Wang, Xue and Su, Zixiong and Rekimoto, Jun and Zhang, Yang",Watch Your Mouth: Silent Speech Recognition with Depth Sensing,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642092,10.1145/3613904.3642092,"Silent speech recognition is a promising technology that decodes human speech without requiring audio signals, enabling private human-computer interactions. In this paper, we propose Watch Your Mouth, a novel method that leverages depth sensing to enable accurate silent speech recognition. By leveraging depth information, our method provides unique resilience against environmental factors such as variations in lighting and device orientations, while further addressing privacy concerns by eliminating the need for sensitive RGB data. We started by building a deep-learning model that locates lips using depth data. We then designed a deep learning pipeline to efficiently learn from point clouds and translate lip movements into commands and sentences. We evaluated our technique and found it effective across diverse sensor locations: On-Head, On-Wrist, and In-Environment. Watch Your Mouth outperformed the state-of-the-art RGB-based method, demonstrating its potential as an accurate and reliable input technique.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,15,"Deep Learning, Depth Sensing, Input Techniques, Lip Reading, Silent Speech Recognition, Visual Speech Recognition","Honolulu, HI, USA",CHI '24,inproceedings,323,,,,,,,,,
"Omrani Sabbaghi, Shiva and Wolfe, Robert and Caliskan, Aylin",Evaluating Biased Attitude Associations of Language Models in an Intersectional Context,2023,9798400702310,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3600211.3604666,10.1145/3600211.3604666,"Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model that we study is also more biased as it effectively captures bias embedded in sociocultural data. We validate the bias evaluation method by overperforming on an intrinsic valence evaluation task. The approach enables us to measure complex intersectional biases as they are known to manifest in the outputs and applications of language models that perpetuate historical biases. Moreover, our approach contributes to design justice as it studies the associations of groups underrepresented in language such as transgender and homosexual individuals.","Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",542–553,12,"psycholinguistics, language models, intersectional bias, contextualized word embeddings, AI bias",,AIES '23,inproceedings,,,,,,,,,,
"Xiao, Ziang and Liao, Q. Vera and Zhou, Michelle and Grandison, Tyrone and Li, Yunyao",Powering an AI Chatbot with Expert Sourcing to Support Credible Health Information Access,2023,9798400701061,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3581641.3584031,10.1145/3581641.3584031,"During a public health crisis like the COVID-19 pandemic, a credible and easy-to-access information portal is highly desirable. It helps with disease prevention, public health planning, and misinformation mitigation. However, creating such an information portal is challenging because 1) domain expertise is required to identify and curate credible and intelligible content, 2) the information needs to be updated promptly in response to the fast-changing environment, and 3) the information should be easily accessible by the general public; which is particularly difficult when most people do not have the domain expertise about the crisis. In this paper, we presented an expert-sourcing framework and created Jennifer, an AI chatbot, which serves as a credible and easy-to-access information portal for individuals during the COVID-19 pandemic. Jennifer was created by a team of over 150 scientists and health professionals around the world, deployed in the real world and answered thousands of user questions about COVID-19. We evaluated Jennifer from two key stakeholders’ perspectives, expert volunteers and information seekers. We first interviewed experts who contributed to the collaborative creation of Jennifer to learn about the challenges in the process and opportunities for future improvement. We then conducted an online experiment that examined Jennifer’s effectiveness in supporting information seekers in locating COVID-19 information and gaining their trust. We share the key lessons learned and discuss design implications for building expert-sourced and AI-powered information portals, along with the risks and opportunities of misinformation mitigation and beyond.",Proceedings of the 28th International Conference on Intelligent User Interfaces,2–18,17,"AI-powered chatbot, COVID-19, crisis informatics, expert sourcing, information access, information seeking, misinformation","Sydney, NSW, Australia",IUI '23,inproceedings,,,,,,,,,,
"Yoo, Taewon and Lee, Hyunmin and Oh, SeungYoung and Kwon, Hyosun and Jung, Hyunggu",Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub,2023,9798400701290,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3584931.3606959,10.1145/3584931.3606959,"The increasing performance of machine learning (ML) models necessitates greater computing resources, contributing to rising carbon intensity in ML computing and raising concerns about computational equity. Previous studies focused on developing tools that enable model developers to view the carbon intensity of the ML models in the training process. Still, little is known about how to support ML developers in online communities to explore the carbon intensity of ML models during inference. We developed MIEV, a model inference emission visualizer, that supports ML developers on TensorFlow Hub to explore the carbon intensity of image domain models during the model Inference phase. We also provide insights into designing technologies that promote collaborative work among ML developers to drive sustainable AI development processes. To the best of our knowledge, this is the first attempt to interactively visualize the carbon intensity of ML models in online communities during the Inference phase.",Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing,206–211,6,"online communities, inference, carbon intensity, TensorFlow Hub","Minneapolis, MN, USA",CSCW '23 Companion,inproceedings,,,,,,,,,,
,ICEEL '23: Proceedings of the 2023 7th International Conference on Education and E-Learning,2023,9798400708732,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Tokyo, Japan",,proceedings,,,,,,,,,,
"Cooray, Sankha and Hettiarachchi, Chathuranga and Nanayakkara, Vishaka and Matthies, Denys and Samaradivakara, Yasith and Nanayakkara, Suranga",Kavy: Fostering Language Speaking Skills and Self-Confidence Through Conversational AI,2024,9798400709807,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652920.3652944,10.1145/3652920.3652944,"Cognitive augmentation is the process of enhancing one’s abilities, including learning a new language. For this, we could utilize conversational chatbots. Conventional chatbots such as Siri, have predominantly been based on the question-and-answer model, where a communicator seeks a specific answer to accomplish a specific task. The conversational capabilities of chatbots offer great potential to promote English language learning, particularly in developing countries, such as Sri Lanka, where many young adults lack confidence in speaking English. This is due to limited exposure to conversational-style learning and a lack of opportunity to practice without social anxiety which is often rooted in the fear of making mistakes. In this paper, we developed a conversational chatbot, Kavy, as a companion to help them practice English. We investigated, in a study with 40 users, if Kavy could improve a communicator’s proficiency (e.g., verbal expression, conversation length, quality of speech) and self-confidence using both poetic and non-poetic conversational styles. We found that the users were highly motivated by the poetic version, with its use resulting in a significant increase in vocabulary. Nevertheless, a poetic chatbot may present challenges, with several users reporting that they find the poetic version confusing. We see this pioneering work as a first and promising approach that should be continued to be investigated in the future.",Proceedings of the Augmented Humans International Conference 2024,226–236,11,"Artificial Intelligence, Cognitive Augmentation, Conversational AI Agents, Language Studies, Poetry, Self Confidence, Social chatbots, Voice Interfaces","Melbourne, VIC, Australia",AHs '24,inproceedings,,,,,,,,,,
"Prasad, Siddhartha and Greenman, Ben and Nelson, Tim and Krishnamurthi, Shriram",Generating Programs Trivially: Student Use of Large Language Models,2023,9798400700484,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3576882.3617921,10.1145/3576882.3617921,"Educators have been concerned about the capability of large language models to automatically generate programs in response to textual prompts. However, little is known about whether and how students actually use these tools.In the context of an upper-level formal methods course, we gave students access to large language models. They were told they could use the models freely. We built a Visual Studio Code extension to simplify access to these models. We also paid for an account so students could use the models for free without worrying about cost.In this experience report we analyze the outcomes. We see how students actually do and do not use the models. We codify the different uses they make. Most of all, we notice that students actually do not use them very much at all, and provide insight into the many reasons why not. We believe such experiments can help rebalance some of the public narrative about such tools.",Proceedings of the ACM Conference on Global Computing Education Vol 1,126–132,7,"testing, properties, large language models, formal methods","Hyderabad, India",CompEd 2023,inproceedings,,,,,,,,,,
"Ikeda, Bryce and Szafir, Daniel",PRogramAR: Augmented Reality End-User Robot Programming,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640008,10.1145/3640008,"The field of end-user robot programming seeks to develop methods that empower non-expert programmers to task and modify robot operations. In doing so, researchers may enhance robot flexibility and broaden the scope of robot deployments into the real world. We introduce PRogramAR (Programming Robots using Augmented Reality), a novel end-user robot programming system that combines the intuitive visual feedback of augmented reality (AR) with the simplistic and responsive paradigm of trigger-action programming (TAP) to facilitate human-robot collaboration. Through PRogramAR, users are able to rapidly author task rules and desired reactive robot behaviors, while specifying task constraints and observing program feedback contextualized directly in the real world. PRogramAR provides feedback by simulating the robot’s intended behavior and providing instant evaluation of TAP rule executability to help end users better understand and debug their programs during development. In a system validation, 17 end users ranging from ages 18 to 83 used PRogramAR to program a robot to assist them in completing three collaborative tasks. Our results demonstrate how merging the benefits of AR and TAP using elements from prior robot programming research into a single novel system can successfully enhance the robot programming process for non-expert users.",,,20,"End-user robot programming, Trigger-Action Programming (TAP), Augmented Reality (AR), Human-Robot Interaction (HRI), Human-Robot Collaboration (HRC)",,,article,15,March 2024,13,1,J. Hum.-Robot Interact.,mar,,,,
"Beurer-Kellner, Luca and Fischer, Marc and Vechev, Martin",Prompting Is Programming: A Query Language for Large Language Models,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3591300,10.1145/3591300,"Large language models have demonstrated outstanding performance on a wide range of tasks such as question answering and code generation.  
On a high level, given an input, a language model can be used to automatically complete the sequence in a statistically-likely way. Based on this, users prompt these models with language instructions or examples, to implement a variety of downstream tasks. Advanced prompting methods can even imply interaction between the language model, a user, and external tools such as calculators. However, to obtain state-of-the-art performance or adapt language models for specific tasks, complex task- and model-specific programs have to be implemented, which may still require ad-hoc interaction.  

Based on this, we present the novel idea of Language Model Programming (LMP). LMP generalizes language model prompting from pure text prompts to an intuitive combination of text prompting and scripting. Additionally, LMP allows constraints to be specified over the language model output. This enables easy adaption to many tasks while abstracting language model internals and providing high-level semantics.  

To enable LMP, we implement LMQL (short for Language Model Query Language), which leverages the constraints and control flow from an LMP prompt to generate an efficient inference procedure that minimizes the number of expensive calls to the underlying language model.  

We show that LMQL can capture a wide range of state-of-the-art prompting methods in an intuitive way, especially facilitating interactive flows that are challenging to implement with existing high-level APIs. Our evaluation shows that we retain or increase the accuracy on several downstream tasks, while also significantly reducing the required amount of computation or cost in the case of pay-to-use APIs (26-85% cost savings).",,,24,"prompt programming, language model programming",,,article,186,June 2023,7,PLDI,Proc. ACM Program. Lang.,jun,,,,
"Cossairt, Travis J. and LaViola, Joseph J.",SetPad: a sketch-based tool for exploring discrete math set problems,2012,9783905674422,Eurographics Association,"Goslar, DEU",,,"We present SetPad, a new application prototype that lets computer science students explore discrete math problems by sketching set expressions using pen-based input. Students can manipulate the expressions interactively with the tool via pen or multi-touch interface. Likewise, discrete mathematics instructors can use SetPad to display and work through set problems via a projector to better demonstrate the solutions to the students. We discuss the implementation and feature set of the application, as well as results from a formal user study measuring the effectiveness of the tool for students solving set proof problems. The results indicate that SetPad allows for efficient solutions to proof problems, and has the potential to have a positive impact when used as an individual student application or as an instructional tool.",Proceedings of the International Symposium on Sketch-Based Interfaces and Modeling,47–56,10,,"Annecy, France",SBIM '12,inproceedings,,,,,,,,,,
"Staufer, Dimitri and Pallas, Frank and Berendt, Bettina","Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization Tool for Mitigating the Risk of Whistleblower Re-Identification",2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630106.3658936,10.1145/3630106.3658936,"Whistleblowing is essential for ensuring transparency and accountability in both public and private sectors. However, (potential) whistleblowers often fear or face retaliation, even when reporting anonymously. The specific content of their disclosures and their distinct writing style may re-identify them as the source. Legal measures, such as the EU Whistleblower Directive, are limited in their scope and effectiveness. Therefore, computational methods to prevent re-identification are important complementary tools for encouraging whistleblowers to come forward. However, current text sanitization tools follow a one-size-fits-all approach and take an overly limited view of anonymity. They aim to mitigate identification risk by replacing typical high-risk words (such as person names and other labels of named entities) and combinations thereof with placeholders. Such an approach, however, is inadequate for the whistleblowing scenario since it neglects further re-identification potential in textual features, including the whistleblower’s writing style. Therefore, we propose, implement, and evaluate a novel classification and mitigation strategy for rewriting texts that involves the whistleblower in the assessment of the risk and utility. Our prototypical tool semi-automatically evaluates risk at the word/term level and applies risk-adapted anonymization techniques to produce a grammatically disjointed yet appropriately sanitized text. We then use a Large Language Model (LLM) that we fine-tuned for paraphrasing to render this text coherent and style-neutral. We evaluate our tool’s effectiveness using court cases from the European Court of Human Rights (ECHR) and excerpts from a real-world whistleblower testimony and measure the protection against authorship attribution attacks and utility loss statistically using the popular IMDb62 movie reviews dataset, which consists of 62 individuals. Our method can significantly reduce authorship attribution accuracy from 98.81% to 31.22%, while preserving up to 73.1% of the original content’s semantics, as measured by the established cosine similarity of sentence embeddings.","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",733–745,13,"Authorship Obfuscation, Fine-tuning Language Models, LLM-based Rephrasing, Text Sanitization, Whistleblower Anonymity","Rio de Janeiro, Brazil",FAccT '24,inproceedings,,,,,,,,,,
"Weerts, Hilde and Kelly-Lyth, Aislinn and Binns, Reuben and Adams-Prassl, Jeremias",Unlawful Proxy Discrimination: A Framework for Challenging Inherently Discriminatory Algorithms,2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630106.3659010,10.1145/3630106.3659010,"Emerging scholarship suggests that the EU legal concept of direct discrimination - where a person is given different treatment on grounds of a protected characteristic - may apply to various algorithmic decision-making contexts. This has important implications: unlike indirect discrimination, there is generally no ‘objective justification’ stage in the direct discrimination framework, which means that the deployment of directly discriminatory algorithms will usually be unlawful per se. In this paper, we focus on the most likely candidate for direct discrimination in the algorithmic context, termed inherent direct discrimination, where a proxy is inextricably linked to a protected characteristic. We draw on computer science literature to suggest that, in the algorithmic context, ‘treatment on the grounds of’ needs to be understood in terms of two steps: proxy capacity and proxy use. Only where both elements can be made out can direct discrimination be said to be ‘on grounds of’ a protected characteristic. We analyse the legal conditions of our proposed proxy capacity and proxy use tests. Based on this analysis, we discuss technical approaches and metrics that could be developed or applied to identify inherent direct discrimination in algorithmic decision-making.","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",1850–1860,11,"EU non-discrimination law, algorithmic fairness, direct discrimination, disparate treatment, machine learning, proxy discrimination","Rio de Janeiro, Brazil",FAccT '24,inproceedings,,,,,,,,,,
,FlashFill++: Scaling Programming by Example by Cutting to the Chase,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3571226,10.1145/3571226,Programming-by-Examples (PBE) involves synthesizing an ,,,30,"string transformations, programming by example, domain-specific languages",,,article,33,January 2023,7,POPL,Proc. ACM Program. Lang.,jan,,,,
,ICEMT '23: Proceedings of the 7th International Conference on Education and Multimedia Technology,2023,9798400709142,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Tokyo, Japan",,proceedings,,,,,,,,,,
"Yu, Zhengyan and Namkung, Hun and Guo, Jiang and Milner, Henry and Goldfoot, Joel and Wang, Yang and Sekar, Vyas",SEAM-EZ: Simplifying Stateful Analytics through Visual Programming,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642055,10.1145/3613904.3642055,"Across many domains (e.g., media/entertainment, mobile apps, finance, IoT, cybersecurity), there is a growing need for stateful analytics over streams of events to meet key business outcomes. Stateful analytics over event streams entails carefully modeling the sequence, timing, and contextual correlations of events to dynamic attributes. Unfortunately, existing frameworks and languages (e.g., SQL, Flink, Spark) entail significant code complexity and expert effort to express such stateful analytics because of their dynamic and stateful nature. Our overarching goal is to simplify and democratize stateful analytics. Through an iterative design and evaluation process including a foundational user study and two rounds of formative evaluations with 15 industry practitioners, we created SEAM-EZ, a no-code visual programming platform for quickly creating and validating stateful metrics. SEAM-EZ features a node-graph editor, interactive tooltips, embedded data views, and auto-suggestion features to facilitate the creation and validation of stateful analytics. We then conducted three real-world case studies of SEAM-EZ with 20 additional practitioners. Our results suggest that practitioners who previously could not or had to spend significant effort to create stateful metrics using traditional tools such as SQL or Spark can now easily and quickly create and validate such metrics using SEAM-EZ.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,23,"data analytics, metrics, stateful computation, visual programming","Honolulu, HI, USA",CHI '24,inproceedings,1041,,,,,,,,,
,WWW '19: The World Wide Web Conference,2019,9781450366748,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to welcome you to The Web Conference 2019. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.",,,,,"San Francisco, CA, USA",,proceedings,,,,,,,,,,
"Chandran, Prasanth and Huang, Yifeng and Munsell, Jeremy and Howatt, Brian and Wallace, Brayden and Wilson, Lindsey and D'Mello, Sidney and Hoai, Minh and Rebello, N. Sanjay and Loschky, Lester C","Characterizing Learners' Complex Attentional States During Online Multimedia Learning Using Eye-tracking, Egocentric Camera, Webcam, and Retrospective recalls",2024,9798400706073,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3649902.3653939,10.1145/3649902.3653939,"As online learning becomes increasingly ubiquitous, a key challenge is maintaining learners’ sustained attention. Using eye-tracking, together with observing and interviewing learners, we can characterize both 1) whether they are looking at their learning materials, and 2) whether they are thinking about them. Critically, eye-tracking only speaks to the first distinction, not the second. To overcome this limitation, we supplemented eye-tracking with an egocentric camera, a webcam, a retrospective recall, and mind-wandering probes to capture a 2x2 matrix of attentional/cognitive states. We then categorized N=101 learners’ attentional/cognitive states while they completed a multimedia physics module. This meets two goals: 1) allowing basic research to understand the relationship between attentional/cognitive states and behavioral outcomes; and 2) facilitating applied research by generating rich ground truth for future use in training machine learning to categorize this 2x2 set of attentional states, for which eye-tracking is necessary, but not sufficient.",Proceedings of the 2024 Symposium on Eye Tracking Research and Applications,,7,"Attentional States, Eye-tracking, Multimodal data, Online learning","Glasgow, United Kingdom",ETRA '24,inproceedings,68,,,,,,,,,
"Li, Junze and He, Changyang and Hu, Jiaxiong and Jia, Boyang and Halevy, Alon Y and Ma, Xiaojuan",DiaryHelper: Exploring the Use of an Automatic Contextual Information Recording Agent for Elicitation Diary Study,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642853,10.1145/3613904.3642853,"Elicitation diary studies, a type of qualitative, longitudinal research method, involve participants to self-report aspects of events of interest at their occurrences as memory cues for providing details and insights during post-study interviews. However, due to time constraints and lack of motivation, participants’ diary entries may be vague or incomplete, impairing their later recall. To address this challenge, we designed an automatic contextual information recording agent, DiaryHelper, based on the theory of episodic memory. DiaryHelper can predict five dimensions of contextual information and confirm with participants. We evaluated the use of DiaryHelper in both the recording period and the elicitation interview through a within-subject study (N=12) over a period of two weeks. Our results demonstrated that DiaryHelper can assist participants in capturing abundant and accurate contextual information without significant burden, leading to a more detailed recall of recorded events and providing greater insights.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Diary Study Methods, Elicitation Diary Study, Episodic Memory, Generative AI Techniques","Honolulu, HI, USA",CHI '24,inproceedings,818,,,,,,,,,
"Gharibian, Sevag",Guest Column: The 7 faces of quantum NP,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639528.3639535,10.1145/3639528.3639535,"When it comes to NP, its natural definition, its wide applicability across scientific disciplines, and its timeless relevance, the writing is on the wall: There can be only one. Quantum NP, on the other hand, is clearly the apple that fell far from the tree of NP. Two decades since the first definitions of quantum NP started rolling in, quantum complexity theorists face a stark reality: There's QMA, QCMA, QMA1, QMA(2), StoqMA, and NQP. In this article aimed at a general theoretical computer science audience, I survey these various definitions of quantum NP, their strengths and weaknesses, and why most of them, for better or worse, actually appear to fit naturally into the complexity zoo.",,54–91,38,,,,article,,December 2023,54,4,SIGACT News,jan,0163-5700,,,
"Zhan, Xiao and Xu, Yifan and Sarkadi, Stefan",Deceptive AI Ecosystems: The Case of ChatGPT,2023,9798400700149,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3571884.3603754,10.1145/3571884.3603754,"ChatGPT, an AI chatbot, has gained popularity for its capability in generating human-like responses. However, this feature carries several risks, most notably due to its deceptive behaviour such as offering users misleading or fabricated information that could further cause ethical issues. To better understand the impact of ChatGPT on our social, cultural, economic, and political interactions, it is crucial to investigate how ChatGPT operates in the real world where various societal pressures influence its development and deployment. This paper emphasizes the need to study ChatGPT ",Proceedings of the 5th International Conference on Conversational User Interfaces,,6,"Deceptive AI, Conversational Agents, ChatGPT, Artificial Intelligence","Eindhoven, Netherlands",CUI '23,inproceedings,3,,,,,,,,,
,ICPE '24 Companion: Companion of the 15th ACM/SPEC International Conference on Performance Engineering,2024,9798400704451,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to present the ICPE 2024 workshops program. ICPE workshops extend the main conference by providing a forum to foster discussion on hot and emerging topics from the broad field of performance engineering. They offer a highly dynamic venue to exchange ideas, establish new collaborations, and bootstrap debates on novel techniques, methodologies, and their associated early research results. Workshops feature various presentation formats, including research paper presentations, panel discussions, and keynote talks. Through these presentations and discussions with peer researchers, ICPE workshops help shape future research and identify promising research directions for performance engineering.",,,,,"London, United Kingdom",,proceedings,,,,,,,,,,
"Srinivasan, Arvind and Chan, Joel",Improving Selection of Analogical Inspirations through Chunking and Recombination,2024,9798400704857,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3635636.3656207,10.1145/3635636.3656207,"Analogies can be a powerful source of new ideas; however, creators often fail to recognize and harness potentially beneficial analogical leads, especially from other problem domains. In this paper, we introduce AnalogiLead, an interactive interface designed to reduce premature dismissal of analogies by facilitating playful exploration of analogical leads. Drawing on cognitive mechanisms of conceptual chunking and recombination, AnalogiLead scaffolds users to engage with meaningful chunks of problems and analogies and recombine them into inspiring brainstorming questions. In a within-subjects experiment, participants (N=23) who used AnalogiLead dismissed analogies 4x less often, with 12x fewer decision changes, compared to a baseline interface with no chunking or recombination. This reduction in premature dismissal was associated with &nbsp;64% longer processing time. Through qualitative analysis of video and think-aloud data, we describe how the chunking and recombination mechanisms facilitated playful engagement with analogies. These findings highlight opportunities and challenges for improving analogical innovation through careful theory-driven design of interfaces for selecting analogical leads.",Proceedings of the 16th Conference on Creativity &amp; Cognition,374–397,24,"Analogy, Creativity Support Tools, Large Language Models","Chicago, IL, USA",C&amp;C '24,inproceedings,,,,,,,,,,
"Pillis, Daniel and Pataranutaporn, Pat and Maes, Pattie and Sra, Misha",AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645213,10.1145/3640543.3645213,"Despite significant historical progress, discrimination and social stigma continue to impact the lives of LGBTQIA+ individuals. The use of AI-generated virtual characters offers a unique opportunity to facilitate advocacy by engaging individuals in simulated conversations that can foster understanding, education, and empathy. This paper explores the potential of AI simulations to help individuals practice LGBTQIA+ advocacy, while also acknowledging the need for ethical considerations and addressing concerns about oversimplification or perpetuation of stereotypes. By combining technological innovation with a commitment to inclusivity, we aim to contribute to the ongoing struggle for equality in both the legal framework and the hearts and minds of the community. We present a study evaluating virtual characters driven by generative conversational AI simulating the social interactions surrounding “coming out of the closet”, a rite of passage associated with LGBTQIA+ communities. In our study, virtual characters embodied as queer individuals engage with users in a text-based conversation simulation paired with visual representations. We investigate how the interactions between the virtual characters and a user influence the user’s comfort, confidence, empathy and sympathy. The AI simulation includes distinct visual personas deployed in a series of conditions. We present findings from our deployments involving 307 users. Finally, we discuss the design implications of our work on the potential future of embodied, self-actuated and openly LGBTQIA+ intelligent agents.",Proceedings of the 29th International Conference on Intelligent User Interfaces,686–698,13,LGBTQIA+ · Drama Management · AI Actor · Virtual Characters · Player Modelling · Believable Characters · Choice-Based Narrative · Interactive Theatre,"Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
"Gong, Xun and Wu, Yu and Li, Jinyu and Liu, Shujie and Zhao, Rui and Chen, Xie and Qian, Yanmin",Advanced Long-Content Speech Recognition With Factorized Neural Transducer,2024,,IEEE Press,,https://doi.org/10.1109/TASLP.2024.3350893,10.1109/TASLP.2024.3350893,"Long-content automatic speech recognition (ASR) has obtained increasing interest in recent years, as it captures the relationship among consecutive historical utterances while decoding the current utterance. In this paper, we propose two novel approaches, which integrate long-content information into the factorized neural transducer (FNT) based architecture in both non-streaming (referred to as &lt;italic&gt;LongFNT&lt;/italic&gt;) and streaming (referred to as &lt;italic&gt;SLongFNT&lt;/italic&gt;) scenarios. We first investigate whether long-content transcriptions can improve the vanilla conformer transducer (C-T) models. Our experiments indicate that the vanilla C-T models do not exhibit improved performance when utilizing long-content transcriptions, possibly due to the predictor network of C-T models not functioning as a pure language model. Instead, FNT shows its potential in utilizing long-content information, where we propose the &lt;italic&gt;LongFNT&lt;/italic&gt; model and explore the impact of long-content information in both text (LongFNT-Text) and speech (LongFNT-Speech). The proposed LongFNT-Text and LongFNT-Speech models further complement each other to achieve better performance, with transcription history proving more valuable to the model. The effectiveness of our LongFNT approach is evaluated on LibriSpeech and GigaSpeech corpora, and obtains relative 19% and 12% word error rate reduction, respectively. Furthermore, we extend the LongFNT model to the streaming scenario, which is named &lt;italic&gt;SLongFNT&lt;/italic&gt;, consisting of SLongFNT-Text and SLongFNT-Speech approaches to utilize long-content text and speech information. Experiments show that the proposed SLongFNT model achieves relative 26% and 17% WER reduction on LibriSpeech and GigaSpeech respectively while keeping a good latency, compared to the FNT baseline. Overall, our proposed &lt;italic&gt;LongFNT&lt;/italic&gt; and &lt;italic&gt;SLongFNT&lt;/italic&gt; highlight the significance of considering long-content speech and transcription knowledge for improving both non-streaming and streaming speech recognition systems.",,1803–1815,13,,,,article,,2024,32,,"IEEE/ACM Trans. Audio, Speech and Lang. Proc.",jan,2329-9290,,,
"Rismani, Shalaleh and Moon, AJung",What does it mean to be a responsible AI practitioner: An ontology of roles and skills,2023,9798400702310,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3600211.3604702,10.1145/3600211.3604702,"With the growing need to regulate AI systems across a wide variety of application domains, a new set of occupations has emerged in the industry. The so-called responsible Artificial Intelligence (AI) practitioners or AI ethicists are generally tasked with interpreting and operationalizing best practices for ethical and safe design of AI systems. Due to the nascent nature of these roles, however, it is unclear to future employers and aspiring AI ethicists what specific function these roles serve and what skills are necessary to serve the functions. Without clarity on these, we cannot train future AI ethicists with meaningful learning objectives. In this work, we examine what responsible AI practitioners do in the industry and what skills they employ on the job. We propose an ontology of existing roles alongside skills and competencies that serve each role. We created this ontology by examining the job postings for such roles over a two-year period (2020-2022) and conducting expert interviews with fourteen individuals who currently hold such a role in the industry. Our ontology contributes to business leaders looking to build responsible AI teams and provides educators with a set of competencies that an AI ethics curriculum can prioritize.","Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",584–595,12,"Responsible AI Practitioner, Education, Competency Framework",,AIES '23,inproceedings,,,,,,,,,,
"Rajan, Briana and Carradini, Stephen and Lauer, Claire",The Arizona Water Chatbot: Helping Residents Navigate a Water Uncertain Future One Response at a Time,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650919,10.1145/3613905.3650919,"The Southwestern US is a water-scarce region experiencing a megadrought more exceptional than any in the past 1200 years. It is also among the most rapidly growing, urbanizing, and diversifying areas in the country. To help people engage with the information they need to assist their communities in making decisions about water and drought preparedness, our interdisciplinary research team developed the Arizona Water Chatbot, an OpenAI-powered chatbot that uses retrieval-augmented generation to deliver information about Arizona's water situation to Arizona residents. The chatbot uses a distinctive architecture that implements guardrails to mitigate malicious content generation, ensuring the delivery of context-sensitive, relevant, accurate, and user-friendly responses. In this paper we discuss how a custom architecture provides fine-grained control of answers and increased ability to run multiple security checks that make a custom bot preferable to an OpenAI-hosted GPT for some requirements and situations. We also discuss how Waterbot is trained to incorporate Indigenous perspectives about water from the 22 American Indian tribal communities in Arizona to provide a more accurate and holistic view of the important historical, spiritual, and ecological role that water plays in the lives of Arizonans. Finally, we deliver insights on what other teams need to consider when building similar bots for public use.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,10,"Artificial intelligence, Chatbot, Indigenous tribes, Water","
",CHI EA '24,inproceedings,313,,,,,,,,,
"Gu, Ziwei and Arawjo, Ian and Li, Kenneth and Kummerfeld, Jonathan K. and Glassman, Elena L.",An AI-Resilient Text Rendering Technique for Reading and Skimming Documents,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642699,10.1145/3613904.3642699,"Readers find text difficult to consume for many reasons. Summarization can address some of these difficulties, but introduce others, such as omitting, misrepresenting, or hallucinating information, which can be hard for a reader to notice. One approach to addressing this problem is to instead modify how the original text is rendered to make important information more salient. We introduce Grammar-Preserving Text Saliency Modulation (GP-TSM), a text rendering method with a novel means of identifying what to de-emphasize. Specifically, GP-TSM uses a recursive sentence compression method to identify successive levels of detail beyond the core meaning of a passage, which are de-emphasized by rendering words in successively lighter but still legible gray text. In a lab study (n=18), participants preferred GP-TSM over pre-existing word-level text rendering methods and were able to answer GRE reading comprehension questions more efficiently.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,22,"human-AI interaction, natural language processing, text visualization","Honolulu, HI, USA",CHI '24,inproceedings,898,,,,,,,,,
"Mai, Gengchen and Huang, Weiming and Sun, Jin and Song, Suhang and Mishra, Deepak and Liu, Ninghao and Gao, Song and Liu, Tianming and Cong, Gao and Hu, Yingjie and Cundy, Chris and Li, Ziyuan and Zhu, Rui and Lao, Ni",On the Opportunities and Challenges of Foundation Models for GeoAI (Vision Paper),2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3653070,10.1145/3653070,"Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial domains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, the task-agnostic LLMs can outperform task-specific fully-supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image-based urban noise intensity classification, and remote sensing image scene classification), existing foundation models still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing a foundation model for GeoAI is to address the multimodality nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal foundation model which can reason over various types of geospatial data through geospatial alignments. We conclude this paper by discussing the unique risks and challenges to develop such a model for GeoAI.",,,,"Foundation Models, Geospatial Artificial Intelligence, Multimodal Learning",,,article,,,,,ACM Trans. Spatial Algorithms Syst.,mar,2374-0353,Just Accepted,,
"Smolansky, Adele and Cram, Andrew and Raduescu, Corina and Zeivots, Sandris and Huber, Elaine and Kizilcec, Rene F.",Educator and Student Perspectives on the Impact of Generative AI on Assessments in Higher Education,2023,9798400700255,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3573051.3596191,10.1145/3573051.3596191,"The sudden popularity and availability of generative AI tools, such as ChatGPT that can write compelling essays on any topic, code in various programming languages, and ace standardized tests across domains, raises questions about the sustainability of traditional assessment practices. To seize this opportunity for innovation in assessment practice, we conducted a survey to understand both the educators' and students' perspectives on the issue. We measure and compare attitudes of both stakeholders across various assessment scenarios, building on an established framework for examining the quality of online assessments along six dimensions. Responses from 389 students and 36 educators across two universities indicate moderate usage of generative AI, consensus for which types of assessments are most impacted, and concerns about academic integrity. Educators prefer adapted assessments that assume AI will be used and encourage critical thinking, but students' reaction is mixed, in part due to concerns about a loss of creativity. The findings show the importance of engaging educators and students in assessment reform efforts to focus on the process of learning over its outputs, higher-order thinking, and authentic applications.",Proceedings of the Tenth ACM Conference on Learning @ Scale,378–382,5,"survey, students, generative AI, educators, assessment, ChatGPT","Copenhagen, Denmark",L@S '23,inproceedings,,,,,,,,,,
"Elahimanesh, Sina and Mohammadi, Iman and Mosayebi, Mohammad and Zahedi Movahed, Sara and Hasani, Hosein and Rohban, Mohammad Hossein","User Voices, Platform Choices: Social Media Policy Puzzle with Decentralization Salt",2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650799,10.1145/3613905.3650799,"In the current digital era, social media platforms wield crucial influence, with the potential for biased content moderation. Considering this risk, we propose a decentralized social media policy-making in this work. The noticeable difference between people’s preferences and X’s established policies in a preliminary study motivates us to design a similar website to collect more comprehensive data in a diverse community. Consequently, N=110 individuals from diverse backgrounds participated in our primary experiment to decide about content moderation on social media. For this purpose, 546 tweets in 3 categories are investigated, 3032 records are captured, and the effect of personal favor on content moderation is analyzed. Furthermore, we propose a novel AI-based method to learn the recommended policy of participants and achieve an accuracy of 79%. Also, by considering the suggested policy of 5 Large Language Models, it is illustrated that they cannot be the decision-makers on democratic social media platforms.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,10,"Content Censorship, Decentralization, Decentralized Policy, Social Media, Social Network","
",CHI EA '24,inproceedings,360,,,,,,,,,
"Chung, Andy and Tanaka-Ishii, Kumiko",Predictability of Post-Earnings Announcement Drift with Textual and Contextual Factors of Earnings Calls,2023,9798400702402,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3604237.3626861,10.1145/3604237.3626861,"Post-Earnings Announcement Drift (PEAD), a well-known anomaly in financial markets, describes the tendency of cumulative stock returns to drift in the direction of an earnings surprise for a prolonged period following an earnings announcement. Numerous studies have used a supervised learning approach to predict PEAD, using earnings, fundamental and technical factors. However, there is a lack of study on how the context of the earnings call can be used for the PEAD prediction task. This paper uses computational linguistics techniques and large language models to examine the effectiveness of incorporating textual and contextual features from earnings calls for the PEAD prediction task. Our proposed supervised model includes four categories of features: 1) textual features, 2) contextual features, 3) earnings features, and 4) fundamental and technical features. We study the proposed model using earnings from 2010/01/01 to 2022/12/31 of all point-in-time S&amp;P500 constituents in the US stock market. Our results show that contextual features provide information unexplained by earnings, fundamental and technical features, improving the average returns per trade of a hypothetical long-short portfolio against baseline solution in out-of-sample across all four different abnormal return calculations, ranging from 53 to 354 basis points and 16.9% to 108.5% improvement from baseline model, which uses only earnings, fundamental and technical features.",Proceedings of the Fourth ACM International Conference on AI in Finance,401–408,8,"Post-earnings announcement drift, computational linguistics, earnings call, large language models, machine learning","Brooklyn, NY, USA",ICAIF '23,inproceedings,,,,,,,,,,
"Fok, Raymond and Lipka, Nedim and Sun, Tong and Siu, Alexa F",Marco: Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641969,10.1145/3613904.3641969,"Knowledge workers often need to extract and analyze information from a collection of documents to solve complex information tasks in the workplace, e.g., hiring managers reviewing resumes or analysts assessing risk in contracts. However, foraging for relevant information can become tedious and repetitive over many documents and criteria of interest. We introduce Marco, a mixed-initiative workspace supporting sensemaking over diverse business document collections. Through collection-centric assistance, Marco reduces the cognitive costs of extracting and structuring information, allowing users to prioritize comparative synthesis and decision making processes. Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection. Findings from a usability study (n=16) demonstrate that when using Marco, users complete sensemaking tasks 16% more quickly, with less effort, and without diminishing accuracy. A design probe with seven domain experts identifies how Marco can benefit various real-world workflows.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"business document workflows, document collections, large language models, mixed-initiative systems, sensemaking","Honolulu, HI, USA",CHI '24,inproceedings,842,,,,,,,,,
"Mackenzie, Joel and Moffat, Alistair",Lossy Compression Options for Dense Index Retention,2023,9798400704086,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3624918.3625316,10.1145/3624918.3625316,"Dense indexes derived from whole-of-document neural models are now more effective at locating likely-relevant documents than are conventional term-based inverted indexes. That effectiveness comes at a cost, however: inverted indexes require less than a byte per posting to store, whereas dense indexes store a fixed-length vector of floating point coefficients (typically 768) for each document, making them potentially an order of magnitude larger. In this paper we consider compression of indexes employing dense vectors. Only limited space savings can be achieved via lossless compression techniques, but we demonstrate that dense indexes are responsive to lossy techniques that sacrifice controlled amounts of numeric resolution in order to gain compressibility. We describe suitable schemes, and, via experiments on three different collections, show that substantial space savings can be achieved with minimal loss of ranking fidelity. These techniques further boost the attractiveness of dense indexes for practical use.",Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region,185–194,10,"lossy compression, dense indexing, Index compression","Beijing, China",SIGIR-AP '23,inproceedings,,,,,,,,,,
"Zamfirescu-Pereira, J.D. and Wei, Heather and Xiao, Amy and Gu, Kitty and Jung, Grace and Lee, Matthew G and Hartmann, Bjoern and Yang, Qian",Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3,2023,9781450398930,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3563657.3596138,10.1145/3563657.3596138,"Prompting Large Language Models (LLMs) is an exciting new approach to designing chatbots. But can it improve LLM’s user experience (UX) reliably enough to power chatbot products? Our attempt to design a robust chatbot by prompting GPT-3/4 alone suggests: not yet. Prompts made achieving “80%” UX goals easy, but not the remaining 20%. Fixing the few remaining interaction breakdowns resembled herding cats: We could not address one UX issue or test one design solution at a time; instead, we had to handle everything everywhere all at once. Moreover, because no prompt could make GPT reliably say “I don’t know” when it should, the user-GPT conversations had no guardrails after a breakdown occurred, often leading to UX downward spirals. These risks incentivized us to design highly prescriptive prompts and scripted bots, counter to the promises of LLM-powered chatbots. This paper describes this case study, unpacks prompting’s fickleness and its impact on UX design processes, and discusses implications for LLM-based design methods and tools.",Proceedings of the 2023 ACM Designing Interactive Systems Conference,2206–2220,15,"GPT., Prompt engineering, UX, conversational user interface","Pittsburgh, PA, USA",DIS '23,inproceedings,,,,,,,,,,
"Park, Hyanghee and Ahn, Daehwan","The Promise and Peril of ChatGPT in Higher Education: Opportunities, Challenges, and Design Implications",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642785,10.1145/3613904.3642785,"A growing number of students in higher education are using ChatGPT for various educational purposes, ranging from seeking information to writing essays. Although many universities have officially banned the use of ChatGPT because of its potential harm and unintended consequences, it is still important to uncover how students leverage ChatGPT for learning, what challenges emerge, and how we can make better use of ChatGPT in higher education. Thus, we conducted focus group workshops and a series of participatory design sessions with thirty students who have actively interacted with ChatGPT for one semester in university and with other five stakeholders (e.g., professors, AI experts). Based on these, this paper identifies real opportunities and challenges of utilizing and designing ChatGPT for higher education.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,21,"AI in Education, ChatGPT, Higher education, Large Language Models","Honolulu, HI, USA",CHI '24,inproceedings,271,,,,,,,,,
"Wang, Zeyu and Shi, Yuanchun and Wang, Yuntao and Yao, Yuchen and Yan, Kun and Wang, Yuhan and Ji, Lei and Xu, Xuhai and Yu, Chun",G-VOILA: Gaze-Facilitated Information Querying in Daily Scenarios,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3659623,10.1145/3659623,"Modern information querying systems are progressively incorporating multimodal inputs like vision and audio. However, the integration of gaze --- a modality deeply linked to user intent and increasingly accessible via gaze-tracking wearables --- remains underexplored. This paper introduces a novel gaze-facilitated information querying paradigm, named G-VOILA, which synergizes users' gaze, visual field, and voice-based natural language queries to facilitate a more intuitive querying process. In a user-enactment study involving 21 participants in 3 daily scenarios (p = 21, scene = 3), we revealed the ambiguity in users' query language and a gaze-voice coordination pattern in users' natural query behaviors with G-VOILA. Based on the quantitative and qualitative findings, we developed a design framework for the G-VOILA paradigm, which effectively integrates the gaze data with the in-situ querying context. Then we implemented a G-VOILA proof-of-concept using cutting-edge deep learning techniques. A follow-up user study (p = 16, scene = 2) demonstrates its effectiveness by achieving both higher objective score and subjective score, compared to a baseline without gaze data. We further conducted interviews and provided insights for future gaze-facilitated information querying systems.",,,33,"gaze tracking, information query, information retrieval, large language models, smart glasses",,,article,78,May 2024,8,2,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,may,,,,
"Tran, Nghia D. and May, James J. and Ho, Nguyen and Ngo, Linh B.",Exploring ChatGPT's Ability to Solve Programming Problems with Complex Context,2023,,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,"This paper presents a preliminary study on ChatGPT's ability to generate a working solution from a complex programming problem's textual description. Utilizing an online competitive programming platform's problem statements and its respective difficulty measures, we were able to examine ChatGPT's capabilities using the platform's solution status as a performance indicator. The experimental results show a strong relationship between the problem's perceived difficulty level, as provided by the platform, and the final solution status. Various techniques were used to measure the readability level of the problems' text, and we also found statistical relationship among several of them regarding the final status. The results also hint at a potential limitation of ChatGPT to understand complex programming problem context.",,195–209,15,,,,article,,October 2023,39,3,J. Comput. Sci. Coll.,oct,1937-4771,,,
"Franceschelli, Giorgio and Musolesi, Mirco","Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges",2024,,AI Access Foundation,"El Segundo, CA, USA",https://doi.org/10.1613/jair.1.15278,10.1613/jair.1.15278,"Generative Artificial Intelligence (AI) is one of the most exciting developments in Computer Science of the last decade. At the same time, Reinforcement Learning (RL) has emerged as a very successful paradigm for a variety of machine learning tasks. In this survey, we discuss the state of the art, opportunities and open research questions in applying RL to generative AI. In particular, we will discuss three types of applications, namely, RL as an alternative way for generation without specified objectives; as a way for generating outputs while concurrently maximizing an objective function; and, finally, as a way of embedding desired characteristics, which cannot be easily captured by means of an objective function, into the generative process. We conclude the survey with an in-depth discussion of the opportunities and challenges in this fascinating emerging area.",,,30,,,,article,,Apr 2024,79,,J. Artif. Int. Res.,feb,1076-9757,,,
"Yilma, Bereket A. and Kim, Chan Mi and Cupchik, Gerald C. and Leiva, Luis A.",Artful Path to Healing: Using Machine Learning for Visual Art Recommendation to Prevent and Reduce Post-Intensive Care Syndrome (PICS),2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642636,10.1145/3613904.3642636,"Staying in the intensive care unit (ICU) is often traumatic, leading to post-intensive care syndrome (PICS), which encompasses physical, psychological, and cognitive impairments. Currently, there are limited interventions available for PICS. Studies indicate that exposure to visual art may help address the psychological aspects of PICS and be more effective if it is personalized. We develop Machine Learning-based Visual Art Recommendation Systems (VA RecSys) to enable personalized therapeutic visual art experiences for post-ICU patients. We investigate four state-of-the-art VA RecSys engines, evaluating the relevance of their recommendations for therapeutic purposes compared to expert-curated recommendations. We conduct an expert pilot test and a large-scale user study (n=150) to assess the appropriateness and effectiveness of these recommendations. Our results suggest all recommendations enhance temporal affective states. Visual and multimodal VA RecSys engines compare favourably with expert-curated recommendations, indicating their potential to support the delivery of personalized art therapy for PICS prevention and treatment.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,19,"Artwork, Health, Machine Learning, Personalization, Recommendation, User Experience, intensive care unit, rehabilitation","Honolulu, HI, USA",CHI '24,inproceedings,447,,,,,,,,,
,ICMR '24: Proceedings of the 2024 International Conference on Multimedia Retrieval,2024,9798400706196,Association for Computing Machinery,"New York, NY, USA",,,"We are pleased to present the 2024 edition of the ACM International Conference on Multimedia Retrieval, ACM ICMR 2024, that took place from 10-14 June 2024, in Phuket, Thailand.Effectively and efficiently retrieving information from multimedia collections (e.g., text, image, video, audio, sensor data, 3D) based on user needs is one of the most exciting areas in multimedia research. The Annual ACM International Conference on Multimedia Retrieval (ICMR) offers a great opportunity for exchanging leading-edge multimedia retrieval ideas among researchers, practitioners, and other potential users of multimedia retrieval systems. ACM ICMR was created in 2011 in a merger of ACM CIVR (International Conference on Image and Video Retrieval) and ACM MIR (International Conference on Multimedia Information Retrieval). ACM ICMR serves to illuminate the state of the art in multimedia retrieval. ACM ICMR 2024 in Phuket follows the successful previous editions of ICMR in Trento, Italy 2011; Hong Kong, China 2012; Dallas, USA 2013; Glasgow, UK 2014; Shanghai, China 2015; New York, USA 2016; Bucharest, Romania 2017; Yokohama, Japan 2018; Ottawa, Canada 2019; Dublin, Ireland 2020 (online); Taipei, Taiwan 2021 (online); Newark, USA 2022 (hybrid); and Thessaloniki, Greece 2023 (hybrid).",,,,,"Phuket, Thailand",,proceedings,,,,,,,,,,
"Sun, Yuqian and Tang, Yuying and Gao, Ze and Pan, Zhijun and Xu, Chuyan and Chen, Yurou and Qian, Kejiang and Wang, Zhigang and Braud, Tristan and Lee, Chang Hee and Asadipour, Ali",AI N\,2023,9798400703201,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3610591.3616427,10.1145/3610591.3616427,This paper presents “AI N\,SIGGRAPH Asia 2023 Art Papers,,7,"Language Emergence, Computational Linguistics, Chinese Cultural Heritage, AI N\","Sydney, NSW, Australia",SA '23,inproceedings,4,,,,,,,,,
"Muller, Michael and Chilton, Lydia B and Kantosalo, Anna and Liao, Q. Vera and Maher, Mary Lou and Martin, Charles Patrick and Walsh, Greg",GenAICHI 2023: Generative AI and HCI at CHI 2023,2023,9781450394222,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544549.3573794,10.1145/3544549.3573794,"This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following a successful workshop in 2022, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.",Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,,7,"Bias, Design, Generative AI, Uncertainty.","Hamburg, Germany",CHI EA '23,inproceedings,350,,,,,,,,,
"Mildner, Thomas and Cooney, Orla and Meck, Anna-Maria and Bartl, Marion and Savino, Gian-Luca and Doyle, Philip R and Garaialde, Diego and Clark, Leigh and Sloan, John and Wenig, Nina and Malaka, Rainer and Niess, Jasmin",Listening to the Voices: Describing Ethical Caveats of Conversational User Interfaces According to Experts and Frequent Users,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642542,10.1145/3613904.3642542,"Advances in natural language processing and understanding have led to a rapid growth in the popularity of conversational user interfaces (CUIs). While CUIs introduce novel benefits, they also yield risks that may exploit people’s trust. Although research looking at unethical design deployed through graphical user interfaces (GUIs) established a thorough understanding of so-called dark patterns, there is a need to continue this discourse within the CUI community to understand potentially problematic interactions. Addressing this gap, we interviewed 27 participants from three cohorts: researchers, practitioners, and frequent users of CUIs. Applying thematic analysis, we construct five themes reflecting each cohort’s insights about ethical design challenges and introduce the CUI Expectation Cycle, bridging system capabilities and user expectations while considering each theme’s ethical caveats. This research aims to inform future development of CUIs to consider ethical constraints while adopting a human-centred approach.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"CUI, chatbots, conversational agents, conversational user interfaces, dark patterns, deceptive design patterns, ethical design, thematic analysis, voice agents","Honolulu, HI, USA",CHI '24,inproceedings,307,,,,,,,,,
"Gmeiner, Frederic and Conlin, Jamie Lynn and Tang, Eric Handa and Martelaro, Nikolas and Holstein, Kenneth",An Evidence-based Workflow for Studying and Designing Learning Supports for Human-AI Co-creation,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650763,10.1145/3613905.3650763,"Generative artificial intelligence (GenAI) systems introduce new possibilities for enhancing professionals’ workflows, enabling novel forms of human–AI co-creation. However, professionals often struggle to learn to work with GenAI systems effectively. While research has begun to explore the design of interfaces that support users in learning to co-create with GenAI, we lack systematic approaches to investigate the effectiveness of these supports. In this paper, we present a systematic approach for studying how to support learning to co-create with GenAI systems, informed by methods and concepts from the learning sciences. Through an experimental case study, we demonstrate how our approach can be used to study and compare the impacts of different types of learning supports in the context of text-to-image GenAI models. Reflecting on these results, we discuss directions for future work aimed at improving interfaces for human–AI co-creation.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,15,"Case Study, Generative AI, Human–AI Co-creation, Human–AI Interaction, Learning, Study Method, Support Interfaces","
",CHI EA '24,inproceedings,42,,,,,,,,,
"Gao, Jie and Guo, Yuchen and Lim, Gionnieve and Zhang, Tianqin and Zhang, Zheng and Li, Toby Jia-Jun and Perrault, Simon Tangi","CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642002,10.1145/3613904.3642002,"Collaborative Qualitative Analysis (CQA) can enhance qualitative analysis rigor and depth by incorporating varied viewpoints. Nevertheless, ensuring a rigorous CQA procedure itself can be both complex and costly. To lower this bar, we take a theoretical perspective to design a one-stop, end-to-end workflow, CollabCoder, that integrates Large Language Models (LLMs) into key inductive CQA stages. In the independent open coding phase, CollabCoder offers AI-generated code suggestions and records decision-making data. During the iterative discussion phase, it promotes mutual understanding by sharing this data within the coding team and using quantitative metrics to identify coding (dis)agreements, aiding in consensus-building. In the codebook development phase, CollabCoder provides primary code group suggestions, lightening the workload of developing a codebook from scratch. A 16-user evaluation confirmed the effectiveness of CollabCoder, demonstrating its advantages over the existing CQA platform. All related materials of CollabCoder, including code and further extensions, will be included in: https://gaojie058.github.io/CollabCoder/.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,29,"Collaborative Qualitative Analysis, Grounded Theory, Inductive Qualitative Coding, Large Language Models","Honolulu, HI, USA",CHI '24,inproceedings,11,,,,,,,,,
,GPCE 2023: Proceedings of the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences,2023,9798400704062,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts &amp; Experiences (GPCE’23). GPCE is the premiere venue for researchers and practitioners interested in techniques that use program generation to increase programmer productivity, improve software quality, and shorten the time-to-market of software products. In addition to exploring cutting-edge techniques of generative software, GPCE seeks to foster cross-fertilization between the programming languages research communities.",,,,,"Cascais, Portugal",,proceedings,,,,,,,,,,
"Erlei, Alexander and Sharma, Abhinav and Gadiraju, Ujwal",Understanding Choice Independence and Error Types in Human-AI Collaboration,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641946,10.1145/3613904.3641946,"The ability to make appropriate delegation decisions is an important prerequisite of effective human-AI collaboration. Recent work, however, has shown that people struggle to evaluate AI systems in the presence of forecasting errors, falling well short of relying on AI systems appropriately. We use a pre-registered crowdsourcing study (N = 611) to extend this literature by two underexplored crucial features of human AI decision-making: choice independence and error type. Subjects in our study repeatedly complete two prediction tasks and choose which predictions they want to delegate to an AI system. For one task, subjects receive a decision heuristic that allows them to make informed and relatively accurate predictions. The second task is substantially harder to solve, and subjects must come up with their own decision rule. We systematically vary the AI system’s performance such that it either provides the best possible prediction for both tasks or only for one of the two. Our results demonstrate that people systematically violate choice independence by taking the AI’s performance in an unrelated second task into account. Humans who delegate predictions to a superior AI in their own expertise domain significantly reduce appropriate reliance when the model makes systematic errors in a complementary expertise domain. In contrast, humans who delegate predictions to a superior AI in a complementary expertise domain significantly increase appropriate reliance when the model systematically errs in the human expertise domain. Furthermore, we show that humans differentiate between error types and that this effect is conditional on the considered expertise domain. This is the first empirical exploration of choice independence and error types in the context of human-AI collaboration. Our results have broad and important implications for the future design, deployment, and appropriate application of AI systems.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,19,"Algorithm Aversion, Complementary AI Systems, Crowdsourcing Study, Decision Support System, Errors, Human-AI Collaboration, Interaction","Honolulu, HI, USA",CHI '24,inproceedings,308,,,,,,,,,
"Domingo, Cecilia",Recording multimodal pair-programming dialogue for reference resolution by conversational agents,2023,9798400700552,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3577190.3614231,10.1145/3577190.3614231,"Pair programming is a collaborative technique which has proven highly beneficial in terms of the code produced and the learning gains for programmers. With recent advances in Programming Language Processing (PLP), numerous tools have been created that assist programmers in non-collaborative settings (i.e., where the technology provides users with a solution, instead of discussing the problem to develop a solution together). How can we develop AI that can assist in pair programming, a collaborative setting? To tackle this task, we begin by gathering multimodal dialogue data which can be used to train systems in a basic subtask of dialogue understanding: multimodal reference resolution, i.e., understanding which parts of a program are being mentioned by users through speech or by using the mouse and keyboard.",Proceedings of the 25th International Conference on Multimodal Interaction,731–735,5,"reference resolution, pair programming, multimodality, dialogue","Paris, France",ICMI '23,inproceedings,,,,,,,,,,
"Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanp\",Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests,2023,9781450399760,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3568813.3600139,10.1145/3568813.3600139,"Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers’ help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students’ code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,93–105,13,"student questions, large language models, introductory programming education, help seeking, automatic feedback, OpenAI Codex, GPT, CS1","Chicago, IL, USA",ICER '23,inproceedings,,,,,,,,,,
"Wang, Yunlong and Shen, Shuyuan and Lim, Brian Y",RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581402,10.1145/3544548.3581402,"Generative AI models have shown impressive ability to produce images with text prompts, which could benefit creativity in visual art creation and self-expression. However, it is unclear how precisely the generated images express contexts and emotions from the input texts. We explored the emotional expressiveness of AI-generated images and developed RePrompt, an automatic method to refine text prompts toward precise expression of the generated images. Inspired by crowdsourced editing strategies, we curated intuitive text features, such as the number and concreteness of nouns, and trained a proxy model to analyze the feature effects on the AI-generated image. With model explanations of the proxy model, we curated a rubric to adjust text prompts to optimize image generation for precise emotion expression. We conducted simulation and user studies, which showed that RePrompt significantly improves the emotional expressiveness of AI-generated images, especially for negative emotions.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,29,,"Hamburg, Germany",CHI '23,inproceedings,22,,,,,,,,,
"Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos",How Do Information Technology Professionals Use Generative Artificial Intelligence?,2024,9798400709968,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3658321.3658367,10.1145/3658321.3658367,"Context: The emergence of generative Artificial Intelligence (AI) and, more recently, the dissemination of Copilot, ChatGPT-3 and similar tools have broadened the discussion about the possibility of using generative AI tools in many professional segments such as health, education, and technological area. Problem: Although some studies explore the potential of generative AI tools to assist Information Technology (IT) professionals in executing specific tasks, they do not delve into the professionals’ characteristics or collect information about multiple generative AI tools usage. Solution: Considering the possibilities brought by generative AI, this study aims to shed light on the perception of IT professionals about generative AI tools and characterize these professionals’ profiles. IS Theory: This research is based on the Technology Acceptance Model. Method: A survey research was carried out with IT professionals so as to identify how these professionals are using generative AI and gather information about these professionals’ profiles. Results: Results show that 70,5% (43 out of 61) of the respondents use some generative AI tool, the majority of whom are software development professionals, and, despite the problems faced when using these tools, 86% of these professionals recommend using them. Contribution: In this study the profile of the IT professionals using generative AI was identified, it was then possible to evaluate the acceptance of such tools among these professionals and identify the main reasons why some of them are not yet using generative AI.",Proceedings of the 20th Brazilian Symposium on Information Systems,,9,"Generative AI, IT Professional, Survey","Juiz de Fora, Brazil",SBSI '24,inproceedings,56,,,,,,,,,
"Kim, Hyunwoo and Le, Khanh Duy and Lim, Gionnieve and Kim, Dae Hyun and Hong, Yoo Jin and Kim, Juho",DataDive: Supporting Readers' Contextualization of Statistical Statements with Data Exploration,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645155,10.1145/3640543.3645155,"Statistical statements that refer to data to support narratives or claims are commonly used to inform readers about the magnitude of social issues. While contextualizing statistical statements with relevant data supports readers in building their own interpretation of statements, the complexity of finding contextual information on the web and linking statistical statements with it impedes readers’ efforts to do so. We present DataDive, an interactive tool for contextualizing statistical statements for the readers of online texts. Based on users’ selections of statistical statements, our tool uses an LLM-powered pipeline to generate candidates of relevant contexts and poses them as guiding questions to the user as potential contexts for exploration. When the user selects a question, DataDive employs visualizations to further help the user compare and explore contextually relevant data. A technical evaluation shows that DataDive generates important and diverse questions that facilitate exploration around statistical statements and retrieves relevant data for comparison. Moreover, a user study with 21 participants suggests that DataDive facilitates users to explore diverse contexts and to be more aware of how statistical data could relate to the text.",Proceedings of the 29th International Conference on Intelligent User Interfaces,623–639,17,"Contextualization, Data visualization, Reader support","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
"Hoq, Muntasir and Chilla, Sushanth Reddy and Ahmadi Ranjbar, Melika and Brusilovsky, Peter and Akram, Bita",SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction,2023,9798400701245,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3583780.3615047,10.1145/3583780.3615047,"Automated analysis of programming data using code representation methods offers valuable services for programmers, from code completion to clone detection to bug detection. Recent studies show the effectiveness of Abstract Syntax Trees (AST), pre-trained Transformer-based models, and graph-based embeddings in programming code representation. However, pre-trained large language models lack interpretability, while other embedding-based approaches struggle with extracting important information from large ASTs. This study proposes a novel Subtree-based Attention Neural Network (SANN) to address these gaps by integrating different components: an optimized sequential subtree extraction process using Genetic algorithm optimization, a two-way embedding approach, and an attention network. We investigate the effectiveness of SANN by applying it to two different tasks: program correctness prediction and algorithm detection on two educational datasets containing both small and large-scale code snippets written in Java and C, respectively. The experimental results show SANN's competitive performance against baseline models from the literature, including code2vec, ASTNN, TBCNN, CodeBERT, GPT-2, and MVG, regarding accurate predictive power. Finally, a case study is presented to show the interpretability of our model prediction and its application for an important human-centered computing application, student modeling. Our results indicate the effectiveness of the SANN model in capturing important syntactic and semantic information from students' code, allowing the construction of accurate student models, which serve as the foundation for generating adaptive instructional support such as individualized hints and feedback.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,783–792,10,"static analysis, program correctness prediction, program analysis, code representation, algorithm detection","Birmingham, United Kingdom",CIKM '23,inproceedings,,,,,,,,,,
"Goel, Toshali and Shaer, Orit and Delcourt, Catherine and Gu, Quan and Cooper, Angel",Preparing Future Designers for Human-AI Collaboration in Persona Creation,2023,9798400708077,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3596671.3598574,10.1145/3596671.3598574,"This paper presents findings from an exploratory study investigating the use of AI text-generation tools to support novice designers in persona creation. We conducted a workshop with 22 undergraduate students enrolled in an introductory human-computer interaction course, who were instructed to use GPT-3 in the creation of personas. These novice designers were able to use GPT-3 to iterate to produce satisfactory personas, particularly when providing detailed prompts. Our findings suggest that personas created with GPT-3 assistance were mostly comparable to those created manually but rated lower on some evaluation dimensions. The study also reveals merits and concerns of using GPT-3 for persona creation. Based on our findings, we propose recommendations for novice designers on how to use text-generative AIs to create personas effectively and responsibly.",Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work,,14,"personas, novice designers, natural-language generation, large language models, human-AI collaboration, education","Oldenburg, Germany",CHIWORK '23,inproceedings,4,,,,,,,,,
"Mittal, Shravika and De Choudhury, Munmun",Moral Framing of Mental Health Discourse and Its Relationship to Stigma: A Comparison of Social Media and News,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580834,10.1145/3544548.3580834,"Mental health discussions on public forums influence the perceptions of people. Negative consequences may result from hostile and “othering” portrayals of people with mental disorders. Adopting the lens of Moral Foundation Theory (MFT), we study framings of mental health discourse on Twitter and News, and how moral underpinnings abate or exacerbate stigma. We adopted a large language model based representation framework to score 13,277,115 public tweets and 21,167 news articles against MFT’s five foundations. We found discussions on Twitter to demonstrate compassion, justice and equity-centered moral values for those suffering from mental illness, in contrast to those on News. That said, stigmatized discussions appeared on both Twitter and News, with news articles being more stigmatizing than tweets. We discuss implications for public health authorities to refine measures for safe reporting of mental health, and for social media platforms to design affordances that enable empathetic discourse.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,19,"BERT, mental health discourse, moral foundation theory, news media, stigma, twitter","Hamburg, Germany",CHI '23,inproceedings,484,,,,,,,,,
Z\,In Silico Human Mobility Data Science: Leveraging Massive Simulated Mobility Data (Vision Paper),2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3672557,10.1145/3672557,"Human mobility data science using trajectories or check-ins of individuals has many applications. Recently, we have seen a plethora of research efforts that tackle these applications. However, research progress in this field is limited by a lack of large and representative datasets. The largest and most commonly used dataset of individual human trajectories captures fewer than 200 individuals while data sets of individual human check-ins capture fewer than 100 check-ins per city per day. Thus, it is not clear if findings from the human mobility data science community would generalize to large populations. Since obtaining massive, representative, and individual-level human mobility data is hard to come by due to privacy considerations, the vision of this paper is to embrace the use of data generated by large-scale socially realistic microsimulations. Informed by both real data and leveraging social and behavioral theories, massive spatially explicit microsimulations may allow us to simulate entire megacities at the person level. The simulated worlds, which do not capture any identifiable personal information, allow us to perform “in silico” experiments using the simulated world as a sandbox in which we have perfect information and perfect control without jeopardizing the privacy of any actual individual. In silico experiments have become commonplace in other scientific domains such as chemistry and biology, permitting experiments that foster the understanding of concepts without any harm to individuals. This work describes challenges and opportunities for leveraging massive and realistic simulated alternate worlds for in silico human mobility data science.",,,,"Spatial Simulation, Mobility Data Science, Trajectory Data, Location Based Social Network Data, In Silico",,,article,,,,,ACM Trans. Spatial Algorithms Syst.,jun,2374-0353,Just Accepted,,
"Olapade, Mayowa and Hasanli, Tarlan and Ottun, Abdul-Rasheed and Akintola, Adeyinka and Liyanage, Mohan and Flores, Huber",Pervasive Chatbots: Investigating Chatbot Interventions for Multi-Device Applications,2024,9798400704338,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627043.3659570,10.1145/3627043.3659570,"The inherent social characteristics of humans make them prone to adopting distributed and collaborative applications easily. Although fundamental methods and technologies have been defined and developed over the years to construct these applications, their adoption in practice is uncommon because end-users may be puzzled about how to use them without much hassle. Indeed, commonly, these applications require a certain level of technical expertise and awareness to use them correctly. Fortunately, AI-chatbot interventions are envisioned to assist and support various human tasks. In this paper, we contribute pervasive chatbots as a solution that fosters a more transparent and user-friendly interconnection of devices in distributed and collaborative environments. Through two rigorous user studies, firstly, we quantify the perception of users toward distributed and collaborative applications (N = 56 participants). Secondly, we analyze the benefits of adopting pervasive chatbots when compared with the chatbot reference model designed for assistance and recommendations (N = 24 participants). Our results suggest that pervasive chatbots can significantly enhance the practicability of distributed and collaborative applications, reducing the time and effort needed for collaboration with surrounding devices by 57%. With this information, we then provide design and development implications to integrate pervasive chatbot interventions in distributed and collaborative environments. Moreover, challenges and opportunities are also provided to highlight the remaining issues that need to be addressed to realize the full vision of pervasive chatbots for any multi-device application. Our work paves the way towards the proliferation of sophisticated and highly decentralized computing environments that are easily interconnected.","Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",290–300,11,"Decentralized infrastructures, collaborative computing, distributed computing, opportunistic networks","Cagliari, Italy",UMAP '24,inproceedings,,,,,,,,,,
,Workshop on Trust and Reliance in AI-Human Teams (TRAIT),2023,9781450394222,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544549.3573831,10.1145/3544549.3573831,"As humans increasingly interact (and even collaborate) with AI systems during decision-making, creative exercises, and other tasks, appropriate trust and reliance are necessary to ensure proper usage and adoption of these systems. Specifically, people should understand when to trust or rely on an algorithm’s outputs and when to override them. Significant research focus has aimed to define and measure trust in human-AI interaction, and design and implement interactions that promote and calibrate trust. However, conceptualizing trust and reliance, and identifying the best ways to measure these constructs and effectively shape them in human-AI interactions remains a challenge, especially across contexts and domains. This workshop aims to establish building appropriate trust and reliance on (imperfect) AI systems as a vital, yet under-explored research problem. The workshop will provide a venue for exploring three broad aspects related to human-AI trust: (1) How do we clarify definitions and frameworks relevant to human-AI trust and reliance (e.g., what does trust mean in different contexts)? (2) How do we measure trust and reliance? And, (3) How do we shape trust and reliance? The workshop will build on the success from running it at CHI 2022,1 with a focus on “Learning from Practice",Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,,6,"human-centered artificial intelligence, reliance, trust, uncertainty","Hamburg, Germany",CHI EA '23,inproceedings,371,,,,,,,,,
"Schnitzer, Benjamin and Vural, Umut Can and Schnitzer, Bastian and Sardar, Muhammad Usman and Fuerst, Oren and Korn, Oliver",Prototyping a Zoomorphic Interactive Robot Companion with Emotion Recognition and Affective Voice Interaction for Elderly People,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3660244,10.1145/3660244,"An aging society paired with a skilled labor shortage, particularly in European countries, requires a rethinking of deprecated structures. Intelligent assistive technologies, specifically socially assistive robots, addressing the gap between caretakers and elderly people in need of care have moved into the focus of debate due to their potentials to reduce costs, improve independence, and eventually raise quality of life. In this work, we outline the potentials of zoomorphic robot companions combining intelligent conversational abilities and emotion recognition. We then describe the prototyping of an emotion-sensing zoomorphic interactive robot companion including the development and implementation of a multimodal emotion recognition framework. This framework uses speech emotion recognition, sentiment analysis, and affective voice interaction based on a large language model. The prototyping has been accompanied by two studies on elderly peoples' design preferences regarding the proposed feature set as well as different embodiments to find the appropriate casing for the robot companion. This work provides valuable insights into the prototyping and can thus support future research endeavors in this area.",,,32,"Affective Computing, Elderly People, Health, Intelligent Assistive Technology, Socially Assistive Robots, Speech Emotion Recognition, Zoomorphic Embodiment",,,article,242,June 2024,8,EICS,Proc. ACM Hum.-Comput. Interact.,jun,,,,
"Edenberg, Elizabeth and Wood, Alexandra",Disambiguating Algorithmic Bias: From Neutrality to Justice,2023,9798400702310,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3600211.3604695,10.1145/3600211.3604695,"As algorithms have become ubiquitous in consequential domains, societal concerns about the potential for discriminatory outcomes have prompted urgent calls to address algorithmic bias. In response, a rich literature across computer science, law, and ethics is rapidly proliferating to advance approaches to designing fair algorithms. Yet computer scientists, legal scholars, and ethicists are often not speaking the same language when using the term ‘bias.’ Debates concerning whether society can or should tackle the problem of algorithmic bias are hampered by conflations of various understandings of bias, ranging from neutral deviations from a standard to morally problematic instances of injustice due to prejudice, discrimination, and disparate treatment. This terminological confusion impedes efforts to address clear cases of discrimination. In this paper, we examine the promises and challenges of different approaches to disambiguating bias and designing for justice. While both approaches aid in understanding and addressing clear algorithmic harms, we argue that they also risk being leveraged in ways that ultimately deflect accountability from those building and deploying these systems. Applying this analysis to recent examples of generative AI, our argument highlights unseen dangers in current methods of evaluating algorithmic bias and points to ways to redirect approaches to addressing bias in generative AI at its early stages in ways that can more robustly meet the demands of justice.","Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",691–704,14,"vision-language models, philosophy, law, large language models, justice, generative AI, fairness, discrimination, bias, algorithms",,AIES '23,inproceedings,,,,,,,,,,
"Park, Jeongeon and Ko, Eun-Young and Park, Yeon Su and Yim, Jinyeong and Kim, Juho",DynamicLabels: Supporting Informed Construction of Machine Learning Label Sets with Crowd Feedback,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645157,10.1145/3640543.3645157,"Label set construction—deciding on a group of distinct labels—is an essential stage in building a supervised machine learning (ML) application, as a badly designed label set negatively affects subsequent stages, such as training dataset construction, model training, and model deployment. Despite its significance, it is challenging for ML practitioners to come up with a well-defined label set, especially when no external references are available. Through our formative study (n=8), we observed that even with the help of external references or domain experts, ML practitioners still need to go through multiple iterations to gradually improve the label set. In this process, there exist challenges in collecting helpful feedback and utilizing it to make optimal refinement decisions. To support informed refinement, we present DynamicLabels, a system that aims to support a more informed label set-building process with crowd feedback. Crowd workers provide annotations and label suggestions to the ML practitioner’s label set, and the ML practitioner can review the feedback through multi-aspect analysis and refine the label set with crowd-made labels. Through a within-subjects study (n=16) using two datasets, we found that DynamicLabels enables better understanding and exploration of the collected feedback and supports a more structured and flexible refinement process. The crowd feedback helped ML practitioners explore diverse perspectives, spot current weaknesses, and shop from crowd-generated labels. Metrics and label suggestions in DynamicLabels helped in obtaining a high-level overview of the feedback, gaining assurance, and spotting surfacing conflicts and edge cases that could have been overlooked.",Proceedings of the 29th International Conference on Intelligent User Interfaces,209–228,20,"artifact or system, crowdsourcing, label set construction, machine learning","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
,Tackling Language Modelling Bias in Support of Linguistic Diversity,2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630106.3658925,10.1145/3630106.3658925,"Current AI-based language technologies—language models, machine translation systems, multilingual dictionaries and corpora—are known to focus on the world’s 2–3% most widely spoken languages. Research efforts of the past decade have attempted to expand this coverage to ‘under-resourced languages.’ The goal of our paper is to bring attention to a corollary phenomenon that we call language modelling bias: multilingual language processing systems often exhibit a hardwired, yet usually involuntary and hidden representational preference towards certain languages. We define language modelling bias as uneven per-language performance under similar test conditions. We show that bias stems not only from technology but also from ethically problematic research and development methodologies that disregard the needs of language communities. Moving towards diversity-aware alternatives, we present an initiative that aims at reducing language modelling bias within lexical resources through both technology design and methodology, based on an eye-level collaboration with local communities.","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",562–572,11,"language modeling bias, linguistic diversity, low-resource languages, natural language processing, value-sensitive design","Rio de Janeiro, Brazil",FAccT '24,inproceedings,,,,,,,,,,
,PPoPP '24: Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming,2024,9798400704352,Association for Computing Machinery,"New York, NY, USA",,,"PPoPP is the foremost platform for showcasing groundbreaking research in both the practical and theoretical aspects of parallel computing. In today's technological landscape, parallelism is ubiquitous, encompassing everything from microscale devices to vast cloud infrastructures, and from fundamental software layers to advanced applications in artificial intelligence and beyond. The PPoPP community is at the forefront of expanding our understanding and capabilities in these diverse fields.",,,,,"Edinburgh, United Kingdom",,proceedings,,,,,,,,,,
"Fu, Yue and Foell, Sami and Xu, Xuhai and Hiniker, Alexis",From Text to Self: Users’ Perception of AIMC Tools on Interpersonal Communication and Self,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641955,10.1145/3613904.3641955,"In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users’ perceptions of these tools’ ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, finding precise language to express their thoughts, and navigating linguistic and cultural barriers. However, our findings also show current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. We identify four key communication spaces delineated by communication stakes (high or low) and relationship dynamics (formal or informal) that differentially predict users’ attitudes toward AIMC tools. Specifically, participants report that these tools are more suitable for communicating in formal relationships than informal ones and more beneficial in high-stakes than low-stakes communication.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"computer mediated communication, diary study","Honolulu, HI, USA",CHI '24,inproceedings,977,,,,,,,,,
"Weike, Michel and Ruske, Kai and Gerndt, Reinhard and Doernbach, Tobias",Enabling Untrained Users to Shape Real-World Robot Behavior Using an Intuitive Visual Programming Tool in Human-Robot Interaction Scenarios,2024,9798400716614,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3648536.3648541,10.1145/3648536.3648541,"For untrained users, programming a robot that interacts with humans in a real-world scenario is challenging to impossible. However, in order to make interactive robots available in a wide range of domains and connect them with other smart devices, it must be possible to change their behavior in a simple and intuitive way. We present a visual programming tool that builds on top of the open-source Node-RED software and enables users to quickly and easily connect robots with Internet of Things (IoT) devices in order to build scenarios that include human interaction. The tool, called Node-(RED)² (Node-RED-based Robotics Empowerment Designer) is available online and currently supports the humanoid robot Pepper, but is extendable to other robots with very little effort. We demonstrate two real-world use cases of our tool that include Pepper and IoT devices and evaluate the utility of Node-(RED)² via a user study.",Proceedings of the 2024 International Symposium on Technological Advances in Human-Robot Interaction,38–46,9,"Human-Robot Interaction, Real-World Robotics, Robot Behavior Planning, Visual Programming","Boulder, CO, USA",TAHRI '24,inproceedings,,,,,,,,,,
,Trust and Reliance in Evolving Human-AI Workflows (TREW),2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3636319,10.1145/3613905.3636319,"State-of-the-art AIs, including Large Language Models (LLMs) like GPT-4, now possess capabilities once unique to humans, such as coding, idea generation, and planning. Advanced AIs are now integrated into a plethora of platforms and tools, including GitHub Copilot, Bing Chat, Bard, ChatGPT, and Advanced Data Analytics. In contrast to conventional, specialized AIs that typically offer singular solutions, these LLMs redefine human-AI dynamics, with a growing trend toward humans viewing them as collaborative counterparts. This shift leads to enhanced dialogues, negotiations, and task delegation between humans and AI. With these rapid advancements, the nature of human roles in the AI collaboration spectrum is evolving. While our previous workshops CHI TRAIT 2022 and 2023 delved into the trust and reliance concerning traditional AIs, the pressing question now is: how should we measure trust and reliance with these emerging AI technologies? As these systems witness widespread adoption, there’s also a need to assess their impact on human skill development. Does AI assistance amplify human skill progression, or does it inadvertently inhibit it? Considering the multifaceted challenges and solutions that revolve around human-AI interactions, we invite experts from diverse fields, including HCI, AI, ML, psychology, and social science. Our aim is to bridge communication gaps and facilitate rich collaborations across these domains.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,6,"human-centered artificial intelligence, reliance, trust, uncertainty","
",CHI EA '24,inproceedings,496,,,,,,,,,
,"ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3",2024,9798400703867,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the third volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is mostly dedicated to the 2024 fall cycle but also provides some statistics summarizing all three cycles.We introduced several notable changes to ASPLOS this year, most of which were discussed in our previous messages from program chairs in Volume 1 and 2, including: (1) significantly increasing the program committee size to over 220 members (more than twice the size of last year); (2) foregoing synchronous program committee (PC) meetings and instead making all decisions online; (3) overhauling the review assignment process; (4) developing an automated submission format violation identifier script that uncovers, e.g., disallowed vertical space manipulations that ",,,,,"La Jolla, CA, USA",,proceedings,,,3,,,,,,,
"Chen, Si and Waller, James and Seita, Matthew and Vogler, Christian and Kushalnagar, Raja and Wang, Qi",Towards Co-Creating Access and Inclusion: A Group Autoethnography on a Hearing Individual's Journey Towards Effective Communication in Mixed-Hearing Ability Higher Education Settings,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642017,10.1145/3613904.3642017,"We present a group autoethnography detailing a hearing student’s journey in adopting communication technologies at a mixed-hearing ability summer research camp. Our study focuses on how this student, a research assistant with emerging American Sign Language (ASL) skills, (in)effectively communicates with deaf and hard-of-hearing (DHH) peers and faculty during the ten-week program. The DHH members also reflected on their communication with the hearing student. We depict scenarios and analyze the (in)effectiveness of how emerging technologies like live automatic speech recognition (ASR) and typing are utilized to facilitate communication. We outline communication strategies to engage everyone with diverse signing skills in conversations - directing visual attention, pause-for-attention-and-proceed, and back-channeling via expressive body. These strategies promote inclusive collaboration and leverage technology advancements. Furthermore, we delve into the factors that have motivated individuals to embrace more inclusive communication practices and provide design implications for accessible communication technologies within the mixed-hearing ability context.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,14,"American Sign Language, DHH, Higher Education, Mixed-Ability","Honolulu, HI, USA",CHI '24,inproceedings,55,,,,,,,,,
"Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen",More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636247,10.1145/3636243.3636247,"Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.",Proceedings of the 26th Australasian Computing Education Conference,29–38,10,"Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
"Rong, Huan and Chen, Zhongfeng and Lu, Zhenyu and Xu, Fan and Sheng, Victor S",Multization: Multi-Modal Summarization Enhanced by Multi-Contextually Relevant and Irrelevant Attention Alignment,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3651983,10.1145/3651983,"This article focuses on the task of Multi-Modal Summarization with Multi-Modal Output for China JD.COM e-commerce product description containing both source text and source images. In the context learning of multi-modal (text and image) input, there exists a semantic gap between text and image, especially in the cross-modal semantics of text and image. As a result, capturing shared cross-modal semantics earlier becomes crucial for multi-modal summarization. However, when generating the multi-modal summarization, based on the different contributions of input text and images, the relevance and irrelevance of multi-modal contexts to the target summary should be considered, so as to optimize the process of learning cross-modal context to guide the summary generation process and to emphasize the significant semantics within each modality. To address the aforementioned challenges, Multization has been proposed to enhance multi-modal semantic information by multi-contextually relevant and irrelevant attention alignment. Specifically, a Semantic Alignment Enhancement mechanism is employed to capture shared semantics between different modalities (text and image), so as to enhance the importance of crucial multi-modal information in the encoding stage. Additionally, the IR-Relevant Multi-Context Learning mechanism is utilized to observe the summary generation process from both relevant and irrelevant perspectives, so as to form a multi-modal context that incorporates both text and image semantic information. The experimental results in the China JD.COM e-commerce dataset demonstrate that the proposed Multization method effectively captures the shared semantics between the input source text and source images, and highlights essential semantics. It also successfully generates the multi-modal summary (including image and text) that comprehensively considers the semantics information of both text and image.",,,29,"Business intelligence, multi-modal summarization, semantic enhancement and attention, multi-modal cross learning",,,article,69,May 2024,23,5,ACM Trans. Asian Low-Resour. Lang. Inf. Process.,may,2375-4699,,,
"Dhillon, Paramveer S. and Molaei, Somayeh and Li, Jiaqi and Golub, Maximilian and Zheng, Shaochun and Robert, Lionel Peter",Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642134,10.1145/3613904.3642134,"Advances in language modeling have paved the way for novel human-AI co-writing experiences. This paper explores how varying levels of scaffolding from large language models (LLMs) shape the co-writing process. Employing a within-subjects field experiment with a Latin square design, we asked participants (N=131) to respond to argumentative writing prompts under three randomly sequenced conditions: no AI assistance (control), next-sentence suggestions (low scaffolding), and next-paragraph suggestions (high scaffolding). Our findings reveal a U-shaped impact of scaffolding on writing quality and productivity (words/time). While low scaffolding did not significantly improve writing quality or productivity, high scaffolding led to significant improvements, especially benefiting non-regular writers and less tech-savvy users. No significant cognitive burden was observed while using the scaffolded writing tools, but a moderate decrease in text ownership and satisfaction was noted. Our results have broad implications for the design of AI-powered writing tools, including the need for personalized scaffolding mechanisms.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"Generative AI, Human-AI collaboration, co-writing, writing assistants","Honolulu, HI, USA",CHI '24,inproceedings,1044,,,,,,,,,
,SA '23: SIGGRAPH Asia 2023 Courses,2023,9798400703096,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
"Lee, Hao-Ping (Hank) and Yang, Yu-Ju and Von Davier, Thomas Serban and Forlizzi, Jodi and Das, Sauvik","Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642116,10.1145/3613904.3642116,"Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,19,"AI incidents, Human-centered AI, Privacy, Privacy risks, Privacy taxonomy","Honolulu, HI, USA",CHI '24,inproceedings,775,,,,,,,,,
,SAMANTHA: A chatbot to assist users in training tasks to prevent workplace hazards,2024,9798400717871,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3657242.3658587,10.1145/3657242.3658587,"In businesses, preventing workplace hazards becomes crucial. In order to limit negative effects on people, society, and the economy, it is crucial for both the organization and its employees to reduce accidents and occupational illnesses. Staff training programs are essential to a company’s preventative system. In this paper, we introduce SAMANTHA, an AI chatbot that helps reduce occupational dangers in the mining industry. Using pre-trained Large Language Models (LLMs), SAMANTHA assists users with training as well as daily work tasks, aiming to help employees in any circumstance to enhance well-being at work. Despite SAMANTHA’s concentration on the mining industry, its framework is sufficiently general to be readily applied to other industries. When SAMANTHA’s learning model is compared to the pre-trained ChatGPT3.5 model, it is clear that the suggested chatbot can accurately respond to users, and the evaluation conducted with real users indicates that they are satisfied with it.",Proceedings of the XXIV International Conference on Human Computer Interaction,,8,"AI-powered Chatbot, ChatGPT, Large Language Models, Prevention of occupational risks",,,inproceedings,11,,,,,,,,,
"Mack, Kelly Avery and Qadri, Rida and Denton, Remi and Kane, Shaun K. and Bennett, Cynthia L.",“They only care to show us the wheelchair”: disability representation in text-to-image AI models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642166,10.1145/3613904.3642166,"This paper reports on disability representation in images output from text-to-image (T2I) generative AI systems. Through eight focus groups with 25 people with disabilities, we found that models repeatedly presented reductive archetypes for different disabilities. Often these representations reflected broader societal stereotypes and biases, which our participants were concerned to see reproduced through T2I. Our participants discussed further challenges with using these models including the current reliance on prompt engineering to reach satisfactorily diverse results. Finally, they offered suggestions for how to improve disability representation with solutions like showing multiple, heterogeneous images for a single prompt and including the prompt with images generated. Our discussion reflects on tensions and tradeoffs we found among the diverse perspectives shared to inform future research on representation-oriented generative AI system evaluation metrics and development processes.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,23,"AI harms, algorithmic harms, disability representation, generative AI, human-centered AI, text-to-image models","Honolulu, HI, USA",CHI '24,inproceedings,288,,,,,,,,,
"Jakesch, Maurice and Bhat, Advait and Buschek, Daniel and Zalmanson, Lior and Naaman, Mor",Co-Writing with Opinionated Language Models Affects Users’ Views,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581196,10.1145/3544548.3581196,"If large language models like GPT-3 preferably produce a particular point of view, they may influence people’s opinions on an unknown scale. This study investigates whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write – and what they think. In an online experiment, we asked participants (N=1,506) to write a post discussing whether social media is good for society. Treatment group participants used a language-model-powered writing assistant configured to argue that social media is good or bad for society. Participants then completed a social media attitude survey, and independent judges (N=500) evaluated the opinions expressed in their writing. Using the opinionated language model affected the opinions expressed in participants’ writing and shifted their opinions in the subsequent attitude survey. We discuss the wider implications of our results and argue that the opinions built into AI language technologies need to be monitored and engineered more carefully.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,15,"Co-writing, GPT-3, opinion change, risks of large language models","Hamburg, Germany",CHI '23,inproceedings,111,,,,,,,,,
"Macneil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne",Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636245,10.1145/3636243.3636245,"Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior – in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.",Proceedings of the 26th Australasian Computing Education Conference,11–18,8,"bug detection, computing education, generative AI, large language models, programming errors","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
"Imgrund, Erik and Ganz, Tom and H\",Broken Promises: Measuring Confounding Effects in Learning-based Vulnerability Discovery,2023,9798400702600,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3605764.3623915,10.1145/3605764.3623915,"Several learning-based vulnerability detection methods have been proposed to assist developers during the secure software development life-cycle. In particular, recent learning-based large transformer networks have shown remarkably high performance in various vulnerability detection and localization benchmarks. However, these models have also been shown to have difficulties accurately locating the root cause of flaws and generalizing to out-of-distribution samples. In this work, we investigate this problem and identify spurious correlations as the main obstacle to transferability and generalization, resulting in performance losses of up to 30% for current models. We propose a method to measure the impact of these spurious correlations on learning models and estimate their true, unbiased performance. We present several strategies to counteract the underlying confounding bias, but ultimately our work highlights the limitations of evaluations in the laboratory for complex learning tasks such as vulnerability discovery.",Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security,149–160,12,"vulnerability discovery, overfitting, large language models, confounding effect, causal learning","Copenhagen, Denmark",AISec '23,inproceedings,,,,,,,,,,
,"ApPLIED 2023: Proceedings of the 5th workshop on Advanced tools, programming languages, and PLatforms for Implementing and Evaluating algorithms for Distributed systems",2023,9798400701283,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Orlando, FL, USA",,proceedings,,,,,,,,,,
"Jung, Hyunggu and Seo, Woosuk and Song, Seokwoo and Na, Sungmin",Toward Value Scenario Generation Through Large Language Models,2023,9798400701290,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3584931.3606960,10.1145/3584931.3606960,"We propose a method of generating value scenarios for design research by leveraging ChatGPT, an AI-powered chatbot based on large language models. Identifying the needs of a vulnerable population, such as North Korean defectors, is challenging for researchers. To address this, we introduce ChatGPT-generated value scenarios, an extension of scenario-based design that supports critical, systemic, long-term thinking in current design practice, technology development, and deployment. Using our proposed method, we created a prompt to generate value scenarios on ChatGPT. Based on our analysis of the generated scenarios, we identified that ChatGPT could generate plausible information about Value Implications. However, it lacks details on Pervasiveness and Systemic Effects. After discussing the limitations and opportunities of ChatGPT in generating value scenarios, we conclude with suggestions for how ChatGPT might be better used to generate value scenarios.",Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing,212–220,9,"value scenarios, large language models, ChatGPT","Minneapolis, MN, USA",CSCW '23 Companion,inproceedings,,,,,,,,,,
,"ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2",2024,9798400703850,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the second volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is dedicated to the 2024 summer review cycle.We introduced several notable changes to ASPLOS this year, many of which were discussed in the previous message from program chairs in Volume 1. Here, to avoid repetition, we assume that readers have already read the latter message and will only describe differences between the current cycle and the previous one. These include: (1) developing and utilizing an automated format violation identifier script focused on uncovering disallowed vertical space manipulations that ",,,,,"La Jolla, CA, USA",,proceedings,,,2,,,,,,,
,WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining,2024,9798400703713,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to welcome you to the 17th ACM International Conference on Web Search and Data Mining - WSDM 2024. WSDM is one of the premier conferences in the fields of web search and data mining, with a dynamic and growing community from academia and industry. After two years of virtual conferences and in-person conferences in Singapore, the 2024 edition is an in-person conference with virtual elements. We hope you enjoy the conference at the ",,,,,"Merida, Mexico",,proceedings,,,,,,,,,,
"Schmidt, Douglas C. and Spencer-Smith, Jesse and Fu, Quchen and White, Jules",Towards a Catalog of Prompt Patterns to Enhance the Discipline of Prompt Engineering,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3672359.3672364,10.1145/3672359.3672364,"The rapid advent of Large Language Models (LLMs), such as ChatGPT and Claude, is revolutionizing various fields, from education and healthcare to the engineering of reliable software systems. These LLMs operate through ",,43–51,9,,,,article,,December 2023,43,2,Ada Lett.,jun,1094-3641,,,
"Chang, Yosun",PhysicsAR: Problem Set Reality,2023,9798400701566,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3588427.3595359,10.1145/3588427.3595359,"PhysicsAR is an augmented reality (AR) application that transcends traditional teaching methods by enabling users to delve into the intricacies of physics through interactions with real-world objects. By seamlessly integrating AR technology with advanced physics concepts, PhysicsAR offers an unparalleled learning experience. This paper presents a comprehensive overview of PhysicsAR, emphasizing its ability to turn real world objects into interactive problems, and the potential it holds for physics education.",ACM SIGGRAPH 2023 Appy Hour,,2,"Physics Education, Computer Vision Object Detection Frameworks","Los Angeles, CA, USA",SIGGRAPH '23,inproceedings,5,,,,,,,,,
"Kuang, Emily and Li, Minghao and Fan, Mingming and Shinohara, Kristen",Enhancing UX Evaluation Through Collaboration with Conversational AI Assistants: Effects of Proactive Dialogue and Timing,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642168,10.1145/3613904.3642168,"Usability testing is vital for enhancing the user experience (UX) of interactive systems. However, analyzing test videos is complex and resource-intensive. Recent AI advancements have spurred exploration into human-AI collaboration for UX analysis, particularly through natural language. Unlike user-initiated dialogue, our study investigated the potential of proactive conversational assistants to aid UX evaluators through automatic suggestions at three distinct times: before, in sync with, and after potential usability problems. We conducted a hybrid Wizard-of-Oz study involving 24 UX evaluators, using ChatGPT to generate automatic problem suggestions and a human actor to respond to impromptu questions. While timing did not significantly impact analytic performance, suggestions appearing after potential problems were preferred, enhancing trust and efficiency. Participants found the automatic suggestions useful, but they collectively identified more than twice as many problems, underscoring the irreplaceable role of human expertise. Our findings also offer insights into future human-AI collaborative tools for UX evaluation.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Human-AI collaboration, Proactive conversational assistants, Usability testing, User experience","Honolulu, HI, USA",CHI '24,inproceedings,3,,,,,,,,,
"Fok, Raymond and Kambhamettu, Hita and Soldaini, Luca and Bragg, Jonathan and Lo, Kyle and Hearst, Marti and Head, Andrew and Weld, Daniel S",Scim: Intelligent Skimming Support for Scientific Papers,2023,9798400701061,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3581641.3584034,10.1145/3581641.3584034,"Scholars need to keep up with an exponentially increasing flood of scientific papers. To aid this challenge, we introduce Scim, a novel intelligent interface that helps experienced researchers skim – or rapidly review – a paper to attain a cursory understanding of its contents. Scim supports the skimming process by highlighting salient paper contents in order to direct a reader’s attention. The system’s highlights are faceted by content type, evenly distributed across a paper, and have a density configurable by readers at both the global and local level. We evaluate Scim with both an in-lab usability study and a longitudinal diary study, revealing how its highlights facilitate the more efficient construction of a conceptualization of a paper. We conclude by discussing design considerations and tensions for the design of future intelligent skimming tools.",Proceedings of the 28th International Conference on Intelligent User Interfaces,476–490,15,"Intelligent reading interfaces, highlights, scientific papers, skimming","Sydney, NSW, Australia",IUI '23,inproceedings,,,,,,,,,,
,"ASPLOS 2023: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2",2023,9781450399166,Association for Computing Machinery,"New York, NY, USA",,,"It is our pleasure to introduce Volume II of ASPLOS ’23. For the first time, ASPLOS has embarked on a new multi-deadline review model. ASPLOS ’23 features 3 deadlines spaced throughout the year and papers will be published in three volumes. Multiple deadlines are meant to encourage authors to submit their papers when ready and to facilitate the selection of some papers for revision. For this volume of ASPLOS ’23, we discontinued the use of the 2-page extended abstract submissions that were used in ASPLOS ’21 and ASPLOS ’22. We found the extended abstract offered limited filtering and moved to a more traditional two phase review process. Each paper received 3 reviews in phase 1 and papers with positive scores advanced to the second round and received up to 2 more reviews. In our preface to Volume III, we will give a more detailed rundown of how the process worked.",,,,,"Vancouver, BC, Canada",,proceedings,,,,,,,,,,
,"ASPLOS 2023: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3",2023,9781450399180,Association for Computing Machinery,"New York, NY, USA",,,"It is our pleasure to introduce the third and final volume of ASPLOS&nbsp;’23. For the first time, ASPLOS has embarked on a new multi-deadline review model. ASPLOS&nbsp;’23 featured 3 deadlines spaced throughout the year and published papers in three volumes. Multiple deadlines are meant to encourage authors to submit their papers when ready and to facilitate the selection of some papers for revision. In this, our final program chairs’ message, we will provide details on the execution of the third submission cycle along with a detailed discussion of the entire ASPLOS&nbsp;’23 process.",,,,,"Vancouver, BC, Canada",,proceedings,,,,,,,,,,
,SPLASH-E 2023: Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E,2023,9798400703904,Association for Computing Machinery,"New York, NY, USA",,,"The SPLASH-E symposium is a forum for researchers and educators to discuss  
the intersection of education and the core SPLASH research areas: systems, programming languages, and their applications. We investigate how to deliver systems  
and programming language concepts to students, how systems and languages can  
aid in education broadly, and how to prepare students to apply these concepts to  
their later work in industry or academia.",,,,,"Cascais, Portugal",,proceedings,,,,,,,,,,
,COMPUTE '23: Proceedings of the 16th Annual ACM India Compute Conference,2023,9798400708404,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hyderabad, India",,proceedings,,,,,,,,,,
,ISSTA 2023: Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,2023,9798400702211,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to welcome you to ISSTA 2023, the 32nd edition of the International Symposium on Software Testing and Analysis, to be held on July 18–20, 2023 in Seattle, USA. The symposium has become a premier scientific event in the expanding area of software testing and analysis, with a strong appeal to researchers from all continents.",,,,,"Seattle, WA, USA",,proceedings,,,,,,,,,,
"Ara, Zinat and Salemi, Hossein and Hong, Sungsoo Ray and Senarath, Yasas and Peterson, Steve and Hughes, Amanda Lee and Purohit, Hemant",Closing the Knowledge Gap in Designing Data Annotation Interfaces for AI-powered Disaster Management Analytic Systems,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645214,10.1145/3640543.3645214,"Data annotation interfaces predominantly leverage ground truth labels to guide annotators toward accurate responses. With the growing adoption of Artificial Intelligence (AI) in domain-specific professional tasks, it has become increasingly important to help beginning annotators identify how their early-stage knowledge can lead to inaccurate answers, which in turn, helps to ensure quality annotations at scale. To investigate this issue, we conducted a formative study involving eight individuals from the field of disaster management, each possessing varying levels of expertise. The goal was to understand the prevalent factors contributing to disagreements among annotators when classifying Twitter messages related to disasters and to analyze their respective responses. Our analysis identified two primary causes of disagreement between expert and beginner annotators: 1) a lack of contextual knowledge or uncertainty about the situation, and 2) the absence of visual or supplementary cues. Based on these findings, we designed a Context interface, which generates aids that help beginners identify potential mistakes and provide the hidden context of the presented tweet. The summative study compares Context design with two widely used designs in data annotation UI, Highlight and Reasoning-based interfaces. We found significant differences between these designs in terms of attitudinal and behavioral data. We conclude with implications for designing future interfaces aiming at closing the knowledge gap among annotators.",Proceedings of the 29th International Conference on Intelligent User Interfaces,405–418,14,"Data Annotation, Emergency Management, Group Work, Knowledge gap, Transportation","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
"Zhang, Jinyi and Su, Ke and Li, Haowei and Mao, Jiannan and Tian, Ye and Wen, Feng and Guo, Chong and Matsumoto, Tadahiro",Neural Machine Translation for Low-Resource Languages from a Chinese-centric Perspective: A Survey,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3665244,10.1145/3665244,"Machine translation–the automatic transformation of one natural language (source language) into another (target language) through computational means–occupies a central role in computational linguistics and stands as a cornerstone of research within the field of Natural Language Processing (NLP). In recent years, the prominence of Neural Machine Translation (NMT) has grown exponentially, offering an advanced framework for machine translation research. It is noted for its superior translation performance, especially when tackling the challenges posed by low-resource language pairs that suffer from a limited corpus of data resources. This article offers an exhaustive exploration of the historical trajectory and advancements in NMT, accompanied by an analysis of the underlying foundational concepts. It subsequently provides a concise demarcation of the unique characteristics associated with low-resource languages and presents a succinct review of pertinent translation models and their applications, specifically within the context of languages with low-resources. Moreover, this article delves deeply into machine translation techniques, highlighting approaches tailored for Chinese-centric low-resource languages. Ultimately, it anticipates upcoming research directions in the realm of low-resource language translation.",,,60,"Low-resource languages, neural machine translation, unsupervised learning, transfer learning, multilingual translation, large language models, Chinese-centric languages",,,article,80,June 2024,23,6,ACM Trans. Asian Low-Resour. Lang. Inf. Process.,jun,2375-4699,,,
"Mai, Tai Tan and Tran, Quang-Linh and Tran, Ly-Duyen and Ninh, Tu and Dang-Nguyen, Duc-Tien and Gurrin, Cathal",The First ACM Workshop on AI-Powered Question Answering Systems for Multimedia,2024,9798400706196,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652583.3658890,10.1145/3652583.3658890,"The advent of large language models (LLMs) has energised research in Question-Answering (QA) tasks, enabling responses across varied domains like economics and mathematics. Despite their capabilities, LLMs often lack explainability due to their complex parameter embeddings. Additionally, integrating multimedia data into QA systems introduces challenges in processing and interpreting diverse data types such as text, images, audio, and video. This necessitates sophisticated algorithms for accurate information retrieval across media while ensuring the reliability of the data and responses remains a significant challenge. The AIQAM workshop aims to bring together researchers and practitioners to address these challenges and enhance QA systems with multimedia data. The focus is on promoting innovations that improve the accuracy, explainability, and trustworthiness of QA systems, contributing to the development of the field.",Proceedings of the 2024 International Conference on Multimedia Retrieval,1328–1329,2,"artificial intelligence, large language models, multimedia, question answering systems","Phuket, Thailand",ICMR '24,inproceedings,,,,,,,,,,
,"ApPLIED'24: Proceedings of the 2024 Workshop on Advanced Tools, Programming Languages, and PLatforms for Implementing and Evaluating algorithms for Distributed systems",2024,9798400706707,Association for Computing Machinery,"New York, NY, USA",,,ApPLIED aims to bring together distributed system designers and practitioners from academia and industry to share their experiences and perspectives in designing and building distributed systems.,,,,,"Nantes, France",,proceedings,,,,,,,,,,
"Kukreja, Sanjay and Kumar, Tarun and Purohit, Amit and Dasgupta, Abhijit and Guha, Debashis",A Literature Survey on Open Source Large Language Models,2024,9798400716652,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3647782.3647803,10.1145/3647782.3647803,"Since the 1950s, post the Turing test, humans have been striving hard to make machines learn the art of mastering linguistic intelligence. Language being a complex and intricate tool of expression used by humans, poses a large number of challenges for AI enabled algorithms to grasp its understanding in entirety. Over the past few years, a chain of efforts have been made to make machines understand linguistic intricacies. Small scale models such as BERT and pre-trained language models (PLMs) have demonstrated strong capabilities in understanding and solving various language based tasks. Over the period of years, it is also observed that by increasing the parameters scale to larger size, large language models show a significant improvement in performance and showcase abilities to understand context. For the PLMs of a humongous size i.e in the tune of tens or hundreds of billions of parameters, and to understand the large parametric scales, the scientific community introduced the term LLMs - large language models. The whole world witnessed the launch and quick adoption of ChatGPT, an AI chatbot built on LLMs. As the usage of AI algorithms changes the way the scientific community, society and industry works, it is imperative to review the advances of LLMs. Since 2022, almost daily nearly a dozen LLMs are released. These LLMs are categorized as open and closed source. This paper aims to focus on major aspects of open source LLMs - pre-training covering data collection and pre-processing, model architecture and training. We will select open source models released in June, July and August 2023 with training parameters greater than 70 billion parameters and provide a comprehensive survey on the mentioned aspects. As new models are released on daily / weekly basis in the LLM space, in order to keep the survey concise and targeted to important models, we chose to select time-box of 3 months and a large parameter range of 70 billion in our literature survey. We will also cover historical evolution of LLMs and list open items for future directions.",Proceedings of the 2024 7th International Conference on Computers in Management and Business,133–143,11,"Generative AI, Large Language Models, Open Source LLMs","Singapore, Singapore",ICCMB '24,inproceedings,,,,,,,,,,
"Wang, Zhan and Yuan, Lin-Ping and Wang, Liangwei and Jiang, Bingchuan and Zeng, Wei",VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642235,10.1145/3613904.3642235,"Tour guidance in virtual museums encourages multi-modal interactions to boost user experiences, concerning engagement, immersion, and spatial awareness. Nevertheless, achieving the goal is challenging due to the complexity of comprehending diverse user needs and accommodating personalized user preferences. Informed by a formative study that characterizes guidance-seeking contexts, we establish a multi-modal interaction design framework for virtual tour guidance. We then design VirtuWander, a two-stage innovative system using domain-oriented large language models to transform user inquiries into diverse guidance-seeking contexts and facilitate multi-modal interactions. The feasibility and versatility of VirtuWander are demonstrated with virtual guiding examples that encompass various touring scenarios and cater to personalized preferences. We further evaluate VirtuWander through a user study within an immersive simulated museum. The results suggest that our system enhances engaging virtual tour experiences through personalized communication and knowledgeable assistance, indicating its potential for expanding into real-world scenarios.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"large language models, multi-modal feedback, virtual museum","Honolulu, HI, USA",CHI '24,inproceedings,612,,,,,,,,,
,May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes,2024,9798400717154,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3638067.3638100,10.1145/3638067.3638100,"Using ChatGPT in education presents challenges for evaluating students. It requires distinguishing between original ideas and those generated by the model, assessing critical thinking skills, and gauging subject mastery accurately, which can impact fair assessment practices. The Human-Computer Interaction course described in this experience report has enabled consultation with textbooks, slides and other materials for over five years. This experience report describes reflections regarding using ChatGPT as a source of consultation in a written HCI exam in 2023. The paper describes experiences with analysis of the types of questions ChatGPT was able to solve immediately without mediation and the types of questions that could benefit from ChatGPT’s assistance without compromising the assessment of higher-level learning outcomes that professors want to analyse in teaching HCI. The paper uses Bloom’s taxonomy to analyse different questions and abilities to be evaluated and how they can be solved solely by using ChatGPT. The paper discusses questions that need mediation, previous lived experience in class and understanding of the knowledge acquired in class that cannot be answered directly by copying and pasting questions into ChatGPT. The discussions can raise reflections on the learning outcomes that can be assessed in HCI written exams and how professors should reflect upon their experiences and expectations for exams in the age of growing generative artificial intelligence resources.",Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems,,11,"ChatGPT, HCI education, evaluation, open-book exams",,IHC '23,inproceedings,6,,,,,,,,,
"Han, Ariel and Cai, Zhenyao",Design implications of generative AI systems for visual storytelling for young learners,2023,9798400701313,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3585088.3593867,10.1145/3585088.3593867,"The study examines the design implications of leveraging generative AI tools such as ChatGPT, Stable Diffusion, Midjourney for literacy development and creative expression for children [6, 8, 18]. We sought to elicit insights on the applicability of generative AI for educational purposes from various stakeholders (i.e., parents, teachers, and AI researchers). We recruited nine participants to elicit their perspectives on designing a visual narrative app with generative AI. We examined the opportunities and limitations of the current generative AI tools. Using the implications from our evaluation, we propose AIStory, an AI-powered visual storytelling application prototype that can be used for children’s creative expression, storytelling, and literacy development.",Proceedings of the 22nd Annual ACM Interaction Design and Children Conference,470–474,5,"AI for education, AI literacy, Creativity, Storytelling","Chicago, IL, USA",IDC '23,inproceedings,,,,,,,,,,
"Oelen, Allard and Auer, S\",Leveraging Large Language Models for Realizing Truly Intelligent User Interfaces,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650949,10.1145/3613905.3650949,"The number of published scholarly articles is growing at a significant rate, making scholarly knowledge organization increasingly important. Various approaches have been proposed to organize scholarly information, including describing scholarly knowledge semantically leveraging knowledge graphs. Transforming unstructured knowledge, presented within articles, to structured and semantically represented knowledge generally requires human intelligence and labor since natural language processing methods alone typically do not render sufficient precision and recall for many applications. With the recent developments of Large Language Models (LLMs), it becomes increasingly possible to provide truly intelligent user interfaces guiding humans in the transformation process. We present an approach to integrate non-intrusive LLMs guidance into existing user interfaces. More specifically, we integrate LLM-supported user interface components into an existing scholarly knowledge infrastructure. Additionally, we provide our experiences with LLM integration, detailing best practices and obstacles. Finally, we evaluate the approach using a small-scale user evaluation with domain experts.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,8,"Intelligent User Interface, LLM Interface, Scholarly Knowledge Graphs","
",CHI EA '24,inproceedings,222,,,,,,,,,
"Wu, Chuhao and Wang, Xinyu and Carroll, John and Rajtmajer, Sarah",Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit,2024,9798400703348,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3614419.3644014,10.1145/3614419.3644014,"Generative Artificial intelligence (GenAI) such as ChatGPT has elicited strong reactions from almost all stakeholders across the education system. Education-oriented and academic social media communities provide an important venue for these stakeholders to share experiences and exchange ideas about GenAI, which is constructive for developing human-centered policies. This study examines early user reactions to GenAI, consisting of 725 Reddit threads between 06/2022 and 05/2023. Through natural language processing (NLP) and content analysis, we observe an increasingly negative sentiment in the discussion and identify six main categories of student and faculty experiences of GenAI in education. These experiences reflect concerns about academic integrity and AI’s negative impact on the values of traditional education. Our analysis also highlights the tension and burden imposed by new technologies. Our findings suggest that dialogue between stakeholders in the education community is critical and can mitigate sources of tension between students and faculty.",Proceedings of the 16th ACM Web Science Conference,103–113,11,"Generative AI, Higher Education, Social Media, Topic Modeling","Stuttgart, Germany",WEBSCI '24,inproceedings,,,,,,,,,,
"Ragab, Mohamed and Savateeve, Yury and Wang, Wenjie and Moosaei, Reza and Tiropanis, Thanassis and Poulovassilis, Alexandra and Chapman, Adriane and Oliver, Helen and Roussos, George",The 1st Workshop on Decentralised Search and Recommendation,2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3641302,10.1145/3589335.3641302,"The DESERE Workshop, our First Workshop on Decentralised Search and Recommendation, offers a platform for researchers to explore and share innovative ideas on decentralised web services, mainly focusing on three major topics: (i) societal impact of decentralised systems: their effects on privacy, policy, and regulation; (ii) decen- tralising applications: algorithmic and performance challenges that arise from decentralisation; and (iii) infrastructure to support de- centralised systems and services: peer-to-peer networks, routing, and performance evaluation tools.",Companion Proceedings of the ACM on Web Conference 2024,1705–1708,4,"decentralised web, distributed search, distributed systems, network algorithms, recommendation systems","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Desikan, Rajagopalan and Burger, Doug and Keckler, Stephen W.",Measuring experimental error in microprocessor simulation,2001,1581133588,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/375212.379271,10.1145/375212.379271,,Proceedings of the 2001 Symposium on Software Reusability: Putting Software Reuse in Context,266–277,12,,"Toronto, Ontario, Canada",SSR '01,inproceedings,,,,,,,,,,
"Gooch, Daniel and Waugh, Kevin and Richards, Mike and Slaymaker, Mark and Woodthorpe, John",Exploring the Profile of University Assessments Flagged as Containing AI-Generated Material,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3656478,10.1145/3656478,,,39–47,9,,,,article,,June 2024,15,2,ACM Inroads,may,2153-2184,,,
"Chen, Jiahao and Liu, Zitao and Huang, Shuyan and Huang, Yaying and Zhao, Xiangyu and Gao, Boyu and Luo, Weiqi",Assessing Student Performance with Multi-granularity Attention from Online Classroom Dialogue,2023,9798400701245,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3583780.3615143,10.1145/3583780.3615143,"Accurately judging students' ongoing performance is very crucial for real-world educational scenarios. In this work, we focus on the task of automatically predicting students' levels of mastery of math questions from teacher-student classroom dialogue data in the online learning environment. We propose a novel neural network armed with a multi-granularity attention mechanism to capture the personalized pedagogical instructions from the very noisy teacher-student dialogue transcriptions. We conduct experiments on a real-world educational dataset and the results demonstrate the superiority and availability of our model in terms of various evaluation metrics.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,3798–3802,5,"student modeling, classroom dialogue, assessment, ai in education","Birmingham, United Kingdom",CIKM '23,inproceedings,,,,,,,,,,
"Greengard, Samuel",Computational Linguistics Finds its Voice,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3575666,10.1145/3575666,Advances in artificial intelligence permit computers to converse with humans in seemingly realistic ways.,,18–20,3,,,,article,,February 2023,66,2,Commun. ACM,jan,0001-0782,,,
"Yazici, Aybars and Meija-Domenzain, Paola and Frej, Jibril and K\",GELEX: Generative AI-Hybrid System for Example-Based Learning,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650900,10.1145/3613905.3650900,"Traditional example-based learning methods are often limited by static, expert-created content. Hence, they face challenges in scalability, engagement, and effectiveness, as some learners might struggle to relate to the examples or find them relevant. To address these challenges, we introduce GELEX (GEnerative-AI Learning through EXamples), a hybrid Artificial Intelligence (AI) system enhancing example-based learning by using large language models (LLMs). Our hybrid system incorporates mechanisms to control and evaluate the AI output, acknowledging and addressing the potential factual inaccuracies of LLMs. We instantiate our system in the cooking domain. Our approach utilizes association rule mining on a large database of recipes to identify key patterns. When learners submit a recipe for feedback, a LLM enriches it by integrating these patterns. Then, learners are prompted to actively process the example by highlighting the changes and critically assessing the modifications. This strategy transforms traditional example-based learning into a dynamic, scalable, interactive educational tool.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,10,"Example-based Learning, Generative AI, Procedural Writing","
",CHI EA '24,inproceedings,171,,,,,,,,,
,Developing Time Series Forecasting Models with Generative Large Language Models,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3663485,10.1145/3663485,"Nowadays, Generative Large Language Models (GLLMs) have made a significant impact in the field of Artificial Intelligence (AI). One of the domains extensively explored for these models is their ability as generators of functional source code for software projects. Nevertheless, their potential as assistants to write the code needed to generate and model Machine Learning (ML) or Deep Learning (DL) architectures has not been fully explored to date. For this reason, this work focuses on evaluating the extent to which different tools based on GLLMs, such as ChatGPT or Copilot, are able to correctly define the source code necessary to generate viable predictive models. The use case defined is the forecasting of a time series that reports the indoor temperature of a greenhouse. The results indicate that, while it is possible to achieve good accuracy metrics with simple predictive models generated by GLLMs, the composition of predictive models with complex architectures using GLLMs is still far from improving the accuracy of predictive models generated by human data scientists.",,,,"Deep Learning, Generative Large Language Models (GLLMs), ChatGPT, Copilot, Time series forecasting",,,article,,,,,ACM Trans. Intell. Syst. Technol.,may,2157-6904,Just Accepted,,
"Faruk, Lawal Ibrahim Dutsinma and Rohan, Rohani and Ninrutsirikun, Unhawa and Pal, Debajyoti",University Students’ Acceptance and Usage of Generative AI (ChatGPT) from a Psycho-Technical Perspective,2023,9798400708497,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3628454.3629552,10.1145/3628454.3629552,"The emergence of ChatGPT as a generative AI tool has revolutionized the educational scenario by bringing in unprecedented changes. In this respect exploring the factors that affect the adoption and acceptance of ChatGPT services for educational purpose is of utmost importance. Accordingly, in this work we take a hybrid psycho-technical approach by considering the technological (perceived usefulness, ease of use and facilitating conditions), contextual (perceived humanness and novelty value), and psychological (agreeableness, extraversion, openness, conscientiousness, and neuroticism) gratifications of ChatGPT use. Data is collected from a sample of university students who use ChatGPT regularly across two Asian countries. The data analysis is done using Partial Least Squares Structural Equation Modelling. Results indicate that among the technical factors only perceived usefulness successfully predicts ChatGPT usage. Both the contextual factors of humanness and novelty use significantly explain ChatGPT usage. Finally, among the psychological factors’ openness, agreeableness, and neuroticism determine the usage scenario, however, the later two are found to be negatively associated with ChatGPT usage.",Proceedings of the 13th International Conference on Advances in Information Technology,,8,"ChatGPT, higher education, novelty value, perceived humanness, personality","Bangkok, Thailand",IAIT '23,inproceedings,15,,,,,,,,,
"Woodruff, Allison and Shelby, Renee and Kelley, Patrick Gage and Rousso-Schindler, Steven and Smith-Loud, Jamila and Wilcox, Lauren",How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642700,10.1145/3613904.3642700,"Generative AI is expected to have transformative effects in multiple knowledge industries. To better understand how knowledge workers expect generative AI may affect their industries in the future, we conducted participatory research workshops for seven different industries, with a total of 54 participants across three US cities. We describe participants’ expectations of generative AI’s impact, including a dominant narrative that cut across the groups’ discourse: participants largely envision generative AI as a tool to perform menial work, under human review. Participants do not generally anticipate the disruptive changes to knowledge industries currently projected in common media and academic narratives. Participants do however envision generative AI may amplify four social forces currently shaping their industries: deskilling, dehumanization, disconnection, and disinformation. We describe these forces, and then we provide additional detail regarding attitudes in specific knowledge industries. We conclude with a discussion of implications and research challenges for the HCI community.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,26,"generative AI, industries, knowledge work","Honolulu, HI, USA",CHI '24,inproceedings,641,,,,,,,,,
"Kim, Yunsung and Piech, Chris",High-Resolution Course Feedback: Timely Feedback Mechanism for Instructors,2023,9798400700255,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3573051.3593391,10.1145/3573051.3593391,"We study the problem of minimizing the delay between when an issue comes up in a course and when instructors get feedback about it. The widespread practice of obtaining midterm and end-of-term feedback from students is suboptimal in this regard, especially for large courses: it over-samples at a specific point in the course and can be biased by factors irrelevant to the teaching process. As a solution, we release High Resolution Course Feedback (HRCF), an open-source student feedback mechanism that builds on a surprisingly simple idea: survey each student on random weeks exactly twice per term. Despite the simplicity of its core idea, when deployed to 31 courses totaling a cumulative 6,835 students, HRCF was able to detect meaningful mood changes in courses and significantly improve timely feedback without asking for extra work from students compared to the common practice. An interview with the instructors revealed that HRCF provided constructive and useful feedback about their courses early enough to be acted upon, which would have otherwise been unobtainable through other survey methods. We also explore the possibility of using Large Language Models to flexibly and intuitively organize large volumes of student feedback at scale and discuss how HRCF can be further improved.",Proceedings of the Tenth ACM Conference on Learning @ Scale,81–91,11,"timely feedback, student feedback on teaching, student evaluations of teaching, course survey, course improvement","Copenhagen, Denmark",L@S '23,inproceedings,,,,,,,,,,
"Cohn, Michelle and Pushkarna, Mahima and Olanubi, Gbolahan O. and Moran, Joseph M. and Padgett, Daniel and Mengesha, Zion and Heldreth, Courtney",Believing Anthropomorphism: Examining the Role of Anthropomorphic Cues on Trust in Large Language Models,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650818,10.1145/3613905.3650818,"People now regularly interface with Large Language Models (LLMs) via speech and text (e.g., Bard) interfaces. However, little is known about the relationship between how users anthropomorphize an LLM system (i.e., ascribe human-like characteristics to a system) and how they trust the information the system provides. Participants (n=2,165; ranging in age from 18-90 from the United States) completed an online experiment, where they interacted with a pseudo-LLM that varied in modality (text only, speech + text) and grammatical person (“I” vs. “the system”) in its responses. Results showed that the “speech + text” condition led to higher anthropomorphism of the system overall, as well as higher ratings of accuracy of the information the system provides. Additionally, the first-person pronoun (“I”) led to higher information accuracy and reduced risk ratings, but only in one context. We discuss these findings for their implications for the design of responsible, human–generative AI experiences.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,15,"anthropomorphism, first-person pronoun ","
",CHI EA '24,inproceedings,54,,,,,,,,,
"Mao, Haitao and Zhao, Jianan and He, Xiaoxin and Chen, Zhikai and Huang, Qian and Zhu, Zhaocheng and Tang, Jian and Bronstein, Micheal and Bresson, Xavier and Hooi, Bryan and Zhang, Haiyang and Tang, Xianfeng and Chen, Luo and Tang, Jiliang",The 1st International Workshop on Graph Foundation Models (GFM),2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3641306,10.1145/3589335.3641306,"Foundation models such as GPT-4 for natural language processing (NLP), Flamingo for computer vision (CV), have set new benchmarks in AI by delivering state-of-the-art results across various tasks with minimal task-specific data. Despite their success, the application of these models to the graph domain is challenging due to the relational nature of graph-structured data. To address this gap, we propose the Graph Foundation Model (GFM) Workshop, the first workshop for GFMs, dedicated to exploring the adaptation and development of foundation models specifically designed for graph data. The GFM workshop focuses on two critical questions: (1) How can the underlying capabilities of existing foundation models be effectively applied to graph data? (2) What foundational principles should guide the creation of models tailored to the graph domain? Through a curated set of panel sections, keynote talks, and paper presentations, our workshop intends to catalyze innovative approaches and theoretical frameworks for Graph Foundation Models (GFMs). We target a broad audience, encompassing researchers, practitioners, and students, and aim to lay the groundwork for the next wave of breakthroughs in integrating graph data with foundation models.",Companion Proceedings of the ACM on Web Conference 2024,1789–1792,4,"data mining, foundation model, graph machine learning","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
,SOAP 2024: Proceedings of the 13th ACM SIGPLAN International Workshop on the State Of the Art in Program Analysis,2024,9798400706219,Association for Computing Machinery,"New York, NY, USA",,,"The 13th ACM SIGPLAN International Workshop on the State Of the Art in Pro-
 
gram Analysis (SOAP’24) is co-located with the 45th ACM SIGPLAN International
 
Conference on Programming Language Design and Implementation (PLDI’24). In
 
line with past workshops, SOAP’24 aims to bring together members of the program
 
analysis community to share new developments and shape innovations in program
 
analysis.",,,,,"Copenhagen, Denmark",,proceedings,,,,,,,,,,
"Crichton, Will and Gray, Gavin and Krishnamurthi, Shriram",A Grounded Conceptual Model for Ownership Types in Rust,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3622841,10.1145/3622841,"Programmers learning Rust struggle to understand ownership types, Rust’s core mechanism for ensuring memory safety without garbage collection. This paper describes our attempt to systematically design a pedagogy for ownership types. First, we studied Rust developers’ misconceptions of ownership to create the Ownership Inventory, a new instrument for measuring a person’s knowledge of ownership. We found that Rust learners could not connect Rust’s static and dynamic semantics, such as determining why an ill-typed program would (or would not) exhibit undefined behavior. Second, we created a conceptual model of Rust’s semantics that explains borrow checking in terms of flow-sensitive permissions on paths into memory. Third, we implemented a Rust compiler plugin that visualizes programs under the model. Fourth, we integrated the permissions model and visualizations into a broader pedagogy of ownership by writing a new ownership chapter for The Rust Programming Language, a popular Rust textbook. Fifth, we evaluated an initial deployment of our pedagogy against the original version, using reader responses to the Ownership Inventory as a point of comparison. Thus far, the new pedagogy has improved learner scores on the Ownership Inventory by an average of 9",,,29,"program state visualization, ownership types, concept inventory, Rust",,,article,265,October 2023,7,OOPSLA2,Proc. ACM Program. Lang.,oct,,,,
,SAST '23: Proceedings of the 8th Brazilian Symposium on Systematic and Automated Software Testing,2023,9798400716294,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Campo Grande, MS, Brazil",,proceedings,,,,,,,,,,
"Zhao, Yijun and Pan, Jiangyu and Dong, Yan and Dong, Tianshu and Wang, Guanyun and Ying, Fangtian and Shen, Qihang and Cao, Jiacheng",Language Urban Odyssey: A Serious Game for Enhancing Second Language Acquisition through Large Language Models,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3651112,10.1145/3613905.3651112,"Traditional second language acquisition (SLA) often lacks deep immersion in authentic environments, presenting high learning and resource challenges. To overcome this, we introduced ",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"Educational Games, Human-AI Interaction, Large Language Models, Second Language Acquisition","
",CHI EA '24,inproceedings,219,,,,,,,,,
"Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing",A Survey on Evaluation of Large Language Models,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3641289,10.1145/3641289,"Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at:",,,45,"Large language models, evaluation, model assessment, benchmark",,,article,39,June 2024,15,3,ACM Trans. Intell. Syst. Technol.,mar,2157-6904,,,
"Venkatesh, Varshini and Venkatesh, Vaishnavi and Kumar, Viraj",Evaluating Copilot on CS1 Code Writing Problems with Suppressed Specifications,2023,9798400708404,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627217.3627235,10.1145/3627217.3627235,"Code writing problems in introductory programming (CS1) courses typically ask students to write simple functions or programs based on detailed natural-language specifications. These details can be leveraged by large language models (LLMs), accessible to students via tools such as GitHub Copilot, to generate solutions that are often correct. CS1 instructors who are unwilling or unable to prohibit such usage must consider variants of traditional code writing problems that align with their learning objectives but are more difficult for LLMs to solve. Since LLMs are sensitive to the level of details in their prompts, it is natural to consider variants where details are progressively trimmed from the specifications of traditional code writing problems, and consequent ambiguities are clarified via examples. We consider an extreme variant, where all natural language is suppressed except for meaningful names of functions and their arguments. We evaluate the performance of Copilot on suppressed specification versions of 153 such problems drawn from the CodeCheck repository. If Copilot initially fails to generate a correct solution, we augment each suppressed specification with as few clarifying examples as possible to obtain a correct solution. Copilot solves 134 problems (87%) with just 0.7 examples on average, requiring no examples in 78 instances. Thus, modifying traditional code-writing problems by merely trimming specification details is unlikely to thwart sophisticated LLMs such as GitHub Copilot.",Proceedings of the 16th Annual ACM India Compute Conference,104–107,4,"CS1, code writing, large language models","Hyderabad, India",COMPUTE '23,inproceedings,,,,,,,,,,
"Hou, Irene and Mettille, Sophia and Man, Owen and Li, Zhuo and Zastudil, Cynthia and MacNeil, Stephen",The Effects of Generative AI on Computing Students’ Help-Seeking Preferences,2024,9798400716195,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636243.3636248,10.1145/3636243.3636248,"Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.",Proceedings of the 26th Australasian Computing Education Conference,39–48,10,"ChatGPT, Generative AI, computing education, help-seeking","Sydney, NSW, Australia",ACE '24,inproceedings,,,,,,,,,,
,An automatic linking service of document images reducing the effects of OCR errors with latent semantics,2010,9781605586397,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/1774088.1774092,10.1145/1774088.1774092,"Robust Information Retrieval (IR) systems have been demanded due to the widespread and multipurpose use of document images, and the high number of document images repositories available nowadays. This paper presents a novel approach to support the automatic generation of relationships among document images by exploiting Latent Semantic Indexing (LSI) and Optical Character Recognition (OCR). The LinkDI service extracts and indexes document images content, obtains its latent semantics, and defines relationships among images as hyperlinks. LinkDI was experimented with document images repositories, and its performance was evaluated by comparing the quality of the relationships created among textual documents and among their respective document images. Results show the feasibility of LinkDI relating OCR output with high degradation.",Proceedings of the 2010 ACM Symposium on Applied Computing,13–17,5,,"Sierre, Switzerland",SAC '10,inproceedings,,,,,,,,,,
,EICS '23 Companion: Companion Proceedings of the 2023 ACM SIGCHI Symposium on Engineering Interactive Computing Systems,2023,9798400702068,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Swansea, United Kingdom",,proceedings,,,,,,,,,,
"Markel, Julia M. and Opferman, Steven G. and Landay, James A. and Piech, Chris",GPTeach: Interactive TA Training with GPT-based Students,2023,9798400700255,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3573051.3593393,10.1145/3573051.3593393,"Interactive and realistic teacher training is hard to scale. This is a key issue for learning at scale, as inadequate preparation can negatively impact both students and teachers. What if we could make the teacher training experience more engaging and, as a downstream effect, reduce the potential for harm that teachers-in-training could inflict on students? We present GPTeach, an interactive chat-based teacher training tool that allows novice teachers to practice with simulated students. We performed two studies to evaluate GPTeach: one think-aloud study and one A/B test between our tool and a baseline. Participants took the role of a teaching assistant conducting office hours with two GPT-simulated students. We found that our tool provides the opportunity for teachers to get valuable teaching practice without the pressures of affecting real students, allowing them to iterate their responses both during and across sessions. Additionally, participants enjoyed flexibility in tailoring their responses according to the varied personas, needs, and learning goals. In this paper, we provide quantitative results and qualitative observations to inform future work in this area. We conclude with a discussion of actionable design ideas for such systems, as well as other ways to use this tool for evaluating teachers and students. GPTeach has recently been deployed into the teacher training component of an online course with over 800 novice teachers.",Proceedings of the Tenth ACM Conference on Learning @ Scale,226–236,11,"scalable teacher training, GPT-simulated students","Copenhagen, Denmark",L@S '23,inproceedings,,,,,,,,,,
"Koutcheme, Charles",Towards Open Natural Language Feedback Generation for Novice Programmers using Large Language Models,2022,9781450396165,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3564721.3565955,10.1145/3564721.3565955,"Automated feedback on programming exercises has traditionally focused on correctness of submitted exercises. The correctness has been inferred, for example, based on a set of unit tests. Recent advances in the area of providing feedback have suggested relying on large language models for building feedback. In this poster, we present an approach for automatically constructed formative feedback, written in natural language, that builds on two streams of research: (1) automatic program repair, and (2) automatically generating descriptions of programs. Building on combining these two streams, we propose a new approach for constructing written formative feedback on programming exercise submissions.",Proceedings of the 22nd Koli Calling International Conference on Computing Education Research,,2,"program repair, natural language processing, machine learning, large language models, feedback","Koli, Finland",Koli Calling '22,inproceedings,29,,,,,,,,,
"Poria, Soujanya","Understanding, Leveraging, and Improving Large Language Models",2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3653009,10.1145/3589335.3653009,"The emergence of Large Language Models (LLMs) has marked a substantial advancement in Natural Language Processing (NLP), contributing significantly to enhanced task performance both within and outside specific domains. However, amidst these achievements, three key questions remain unanswered: 1) The mechanism through which LLMs accomplish their tasks and their limitations, 2) Effectively harnessing the power of LLMs across diverse domains, and 3) Strategies for enhancing the performance of LLMs. This talk aims to delve into our research group's endeavors to address these pivotal questions. Firstly, I will outline our approach, which involves utilizing ontology-guided prompt perturbations to unravel the primary limitations of LLMs in solving mathematical problems. Moving on to the second question, we will explore the utilization of synthetic data generated by LLMs to bolster challenging downstream tasks, particularly focusing on structured prediction where LLMs face persistent challenges. I will elaborate on our initiatives aimed at improving LLMs by incorporating highly effective retrieval strategies, specifically addressing the prevalent challenge of hallucinations that often plagues contemporary LLMs. Finally, I will present a technique on LLM realignment to restore safety lost during fine-tuning.",Companion Proceedings of the ACM on Web Conference 2024,1805,1,keynote,"Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Kim, Yoonsu and Lee, Jueon and Kim, Seoyoung and Park, Jaehyuk and Kim, Juho","Understanding Users’ Dissatisfaction with ChatGPT Responses: Types, Resolving Tactics, and the Effect of Knowledge Level",2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645148,10.1145/3640543.3645148,"Large language models (LLMs) with chat-based capabilities, such as ChatGPT, are widely used in various workflows. However, due to a limited understanding of these large-scale models, users struggle to use this technology and experience different kinds of dissatisfaction. Researchers have introduced several methods, such as prompt engineering, to improve model responses. However, they focus on enhancing the model’s performance in specific tasks, and little has been investigated on how to deal with the user dissatisfaction resulting from the model’s responses. Therefore, with ChatGPT as the case study, we examine users’ dissatisfaction along with their strategies to address the dissatisfaction. After organizing users’ dissatisfaction with LLM into seven categories based on a literature review, we collected 511 instances of dissatisfactory ChatGPT responses from 107 users and their detailed recollections of dissatisfactory experiences, which we released as a publicly accessible dataset. Our analysis reveals that users most frequently experience dissatisfaction when ChatGPT fails to grasp their intentions, while they rate the severity of dissatisfaction related to accuracy the highest. We also identified four tactics users employ to address their dissatisfaction and their effectiveness. We found that users often do not use any tactics to address their dissatisfaction, and even when using tactics, 72% of dissatisfaction remained unresolved. Moreover, we found that users with low knowledge of LLMs tend to face more dissatisfaction on accuracy while they often put minimal effort in addressing dissatisfaction. Based on these findings, we propose design implications for minimizing user dissatisfaction and enhancing the usability of chat-based LLM.",Proceedings of the 29th International Conference on Intelligent User Interfaces,385–404,20,"Chat-based LLM, ChatGPT, Knowledge-level, Large Language Models, Resolving tactics, User-side dissatisfaction, datasets","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
"Feldman, Molly Q and Anderson, Carolyn Jane",Non-Expert Programmers in the Generative AI Future,2024,9798400710179,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3663384.3663393,10.1145/3663384.3663393,"Generative AI is rapidly transforming the practice of programming. At the same time, our understanding of who writes programs, for what purposes, and how they program, has been evolving. By facilitating natural-language-to-code interactions, large language models for code have the potential to open up programming work to a broader range of workers. While existing work finds productivity benefits for expert programmers, interactions with non-experts are less well-studied. In this paper, we consider the future of programming for non-experts through a controlled study of 67 non-programmers. Our study reveals multiple barriers to effective use of large language models of code for non-experts, including several aspects of technical communication. Comparing our results to a prior study of beginning programmers illuminates the ways in which a traditional introductory programming class does and does not equip students to effectively work with generative AI. Drawing on our empirical findings, we lay out a vision for how to empower non-expert programmers to leverage generative AI for a more equitable future of programming.",Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work,,19,"CS1, Code LLMs, Generative AI, mixed methods, non-experts","Newcastle upon Tyne, United Kingdom",CHIWORK '24,inproceedings,15,,,,,,,,,
"Richards Maldonado, Liam and Abouzied, Azza and Gleason, Nancy W.",ReaderQuizzer: Augmenting Research Papers with Just-In-Time Learning Questions to Facilitate Deeper Understanding,2023,9798400701290,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3584931.3607494,10.1145/3584931.3607494,"Academic reading is a key component of higher education, and serves as a basis for critical thinking, knowledge acquisition and effective communication. Research shows many students struggle with comprehension and analysis tasks with academic texts, despite the central importance of academic reading to success in higher education. Undergraduates and researchers need to internalize dense literature to scaffold their own work upon it. This reading task is time-consuming and difficult to do. Oftentimes, students struggle to actively and critically engage and as a result attain merely a cursory understanding of a paper’s contents, or worse, incorrectly interpret the text. How, then, can we provide a means to more easily digest a text while also facilitating meaningful, critical engagement and understanding? This paper locates itself within the broader field of augmented reading interfaces to implement an augmented reading interface that leverages the power of large language models (LLM) to intelligently generate and co-locate comprehension and analysis questions in an academic paper, thereby making the paper more digestible with the end goal of facilitating deeper understanding, and developing critical reading skills.",Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing,391–394,4,"reading comprehension, augmented reading interfaces, academic papers","Minneapolis, MN, USA",CSCW '23 Companion,inproceedings,,,,,,,,,,
"Roychowdhury, Sohini",Journey of Hallucination-minimized Generative AI Solutions for Financial Decision Makers,2024,9798400703713,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3616855.3635737,10.1145/3616855.3635737,"Generative AI has significantly reduced the entry barrier to the domain of AI owing to the ease of use and core capabilities of automation, translation, and intelligent actions in our day to day lives. Currently, Large language models (LLMs) that power such chatbots are being utilized primarily for their automation capabilities on a limited scope. One major limitation of the currently evolving family of LLMs is hallucinations, wherein inaccurate responses are reported as factual. Hallucinations are primarily caused by biased training data, ambiguous prompts and inaccurate LLM parameters, and they majorly occur while combining mathematical facts with language-based context. In this work we present the three major stages in the journey of designing hallucination-minimized LLM-based solutions that are specialized for the decision makers of the financial domain, namely: prototyping, scaling and LLM evolution using human feedback. These three stages and the novel data to answer generation modules presented in this work are necessary to ensure that the Generative AI products are reliable and high-quality to aid key decision-making processes.",Proceedings of the 17th ACM International Conference on Web Search and Data Mining,1180–1181,2,"hallucinations, llmops, llms, prompt engineering","Merida, Mexico",WSDM '24,inproceedings,,,,,,,,,,
,SBSI '24: Proceedings of the 20th Brazilian Symposium on Information Systems,2024,9798400709968,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Juiz de Fora, Brazil",,proceedings,,,,,,,,,,
"Grudin, Jonathan and Brinkman, Donald",HCI History and the Trajectory to Generative AI,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3636273,10.1145/3613905.3636273,"This course examines HCI history broadly, then conversational AI history from ELIZA to generative AI. A study of an LLM predecessor illuminates possibilities. With rapid change comes rising uncertainty. Not all history is relevant, but unchanging human nature abides. Some digital dreams become digital nightmares. Social media can deliver disinformation, malware, negative self-image, and polarization that undermines communities. Generative AI provides value but raises employment and career questions, education challenges, and empowers bad actors. We benefit from understanding the forces, the trajectories that brought us here, and how unanticipated consequences arose. Past events that shaped the present have become evident.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,3,"Conversational Agents, Design, Future, Generative AI, HCI, History, Human Factors, Information Science, Information Systems","
",CHI EA '24,inproceedings,597,,,,,,,,,
"Singhal, Shreya and Kumar, Viraj",Creating Thorough Tests for AI-Generated Code is Hard,2023,9798400708404,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627217.3627238,10.1145/3627217.3627238,"Before implementing a function, programmers are encouraged to write a suite of test cases that specify its intended behaviour on several inputs. A suite of tests is thorough if any buggy implementation fails at least one of these tests. We posit that as the proportion of code generated by Large Language Models (LLMs) grows, so must the ability of students to create test suites that are thorough enough to detect subtle bugs in such code. Our paper makes two contributions. First, we demonstrate how difficult it can be to create thorough tests for LLM-generated code by evaluating 27&nbsp;test suites from a public dataset (EvalPlus). Second, by identifying deficiencies in these test suites, we propose strategies for improving the ability of students to develop thorough test suites for LLM-generated code.",Proceedings of the 16th Annual ACM India Compute Conference,108–111,4,,"Hyderabad, India",COMPUTE '23,inproceedings,,,,,,,,,,
"Sheel, Shreya and Anastasopoulos, Ioannis and Pardos, Zach A.",Comparing Authoring Experiences with Spreadsheet Interfaces vs GUIs,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636919,10.1145/3636555.3636919,"There is little consensus over whether graphical user interfaces (GUIs) or programmatic systems are better for word processing. Even less is known about each interfaces’ affordances and limitations in the context of creating content for adaptive tutoring systems. In order to afford instructors the use of such systems with their own or adapted pedagogies, we must study their experiences in inputting their content. In this study, we conduct a between-subjects A/B test with two content authoring interfaces, a GUI and spreadsheet, to explore 32 instructors’ experiences in authoring algebra content with hints, scaffolds, images, and special characters. We study their experiences by measuring time taken, accuracy, and their perceptions of each interfaces’ usability. Our findings indicate no significant relationship between interface used and time taken authoring problems but significantly more accuracy in authoring problems in the spreadsheet interface over the GUI. Although both interfaces performed reasonably well in time taken and accuracy, both were perceived as average to low in usability, highlighting a dissonance between instructors’ perceptions and actual performances. Since both interfaces are reasonable in authoring content, other factors can be explored, such as cost and author incentive, when deciding which interface approach to take for authoring tutor content.",Proceedings of the 14th Learning Analytics and Knowledge Conference,598–607,10,"A/B testing, adaptive tutoring systems, content authoring, human-computer interaction, usability","Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
"Pawagi, Mrigank and Kumar, Viraj",GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements,2023,9798400708404,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3627217.3627234,10.1145/3627217.3627234,"Before implementing a function, programmers are encouraged to write a purpose statement i.e., a short, natural-language explanation of what the function computes. A purpose statement may be ambiguous i.e., it may fail to specify the intended behaviour when two or more inequivalent computations are plausible on certain inputs. Our paper makes four contributions. First, we propose a novel heuristic that suggests such inputs using Large Language Models (LLMs). Using these suggestions, the programmer may choose to clarify the purpose statement (e.g., by providing a functional example that specifies the intended behaviour on such an input). Second, to assess the quality of inputs suggested by our heuristic, and to facilitate future research, we create an open dataset of purpose statements with known ambiguities. Third, we compare our heuristic against GitHub Copilot’s Chat feature, which can suggest similar inputs when prompted to generate unit tests. Fourth, we provide an open-source implementation of our heuristic as an extension to Visual Studio Code for the Python programming language, where purpose statements and functional examples are specified as docstrings and doctests respectively. We believe that this tool will be particularly helpful to novice programmers and instructors.",Proceedings of the 16th Annual ACM India Compute Conference,55–60,6,"CS1, function design, purpose statement","Hyderabad, India",COMPUTE '23,inproceedings,,,,,,,,,,
"Klein, Lauren and D'Ignazio, Catherine",Data Feminism for AI,2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630106.3658543,10.1145/3630106.3658543,"This paper presents a set of intersectional feminist principles for conducting equitable, ethical, and sustainable AI research. In Data Feminism (2020), we offered seven principles for examining and challenging unequal power in data science. Here, we present a rationale for why feminism remains deeply relevant for AI research, rearticulate the original principles of data feminism with respect to AI, and introduce two potential new principles related to environmental impact and consent. Together, these principles help to 1) account for the unequal, undemocratic, extractive, and exclusionary forces at work in AI research, development, and deployment; 2) identify and mitigate predictable harms in advance of unsafe, discriminatory, or otherwise oppressive systems being released into the world; and 3) inspire creative, joyful, and collective ways to work towards a more equitable, sustainable world in which all of us can thrive.","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",100–112,13,"ai ethics, data feminism, data justice, feminism, responsible ai","Rio de Janeiro, Brazil",FAccT '24,inproceedings,,,,,,,,,,
"Qiu, Shihan and Xie, Yuhan and Li, Shuowen and Guo, Wei and Gao, Xiaoyue and Guo, Yijie",Embo: A Wearable Robot Transforming Child-Directed Verbal Aggression into Tactile Feedback,2024,9798400703232,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3610978.3640616,10.1145/3610978.3640616,"Verbal aggression in child development is a pervasive issue, impacting both victims and aggressors profoundly. Traditional approaches, such as cognitive education and reactive strategies, lack practicality and intuitive understanding, presenting limitations in addressing this problem effectively. In response, we propose an innovative solution: ",Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,857–861,5,"child development, empathy, innovative intervention, verbal aggression, wearable technology","Boulder, CO, USA",HRI '24,inproceedings,,,,,,,,,,
"Pirttinen, Nea and Leinonen, Juho",Could ChatGPT Be Used for Reviewing Learnersourced Exercises?,2024,9798400716539,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3631802.3631845,10.1145/3631802.3631845,"Large language models and tools based on large language models such as ChatGPT have received intense attention in the past year in computing education. In this work, we explore whether ChatGPT could be used to review learnersourced exercises. One of the major downsides of learnersourcing is the dubious quality of the created content, leading to many systems using peer review for curating the content. Our results suggest that ChatGPT is not yet ready for this task.",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,,2,"ChatGPT, LLMs, crowdsourcing, generative AI, large language models, learnersourcing, reviews","Koli, Finland",Koli Calling '23,inproceedings,42,,,,,,,,,
,RACS '23: Proceedings of the 2023 International Conference on Research in Adaptive and Convergent Systems,2023,9798400702280,Association for Computing Machinery,"New York, NY, USA",,,"With the expansion of both the Internet and the advanced information technology development profession, reliable and convergent computing has attracted increasing interest in both academia and industry. To cope with this important problem, the Research in Adaptive and Convergent Systems (RACS) provides a forum for exchanging highly original ideas about an important class of computing systems. The RACS aims primarily at researchers who have experience in reliable and convergent computing systems and are engaged in the design and implementation of new computing applications. Each year RACS brings together engineers and scientists from diverse communities with interests in practical computing technologies and creates an environment for them to discuss and report experimental results, novel designs, work-in-progress, experiences, case studies, and trend-setting ideas.",,,,,"Gdansk, Poland",,proceedings,,,,,,,,,,
"Hutt, Stephen and DePiro, Allison and Wang, Joann and Rhodes, Sam and Baker, Ryan S and Hieb, Grayson and Sethuraman, Sheela and Ocumpaugh, Jaclyn and Mills, Caitlin",Feedback on Feedback: Comparing Classic Natural Language Processing and Generative AI to Evaluate Peer Feedback,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636850,10.1145/3636555.3636850,"Peer feedback can be a powerful tool as it presents learning opportunities for both the learner receiving feedback as well as the learner providing feedback. Despite its utility, it can be difficult to implement effectively, particularly for younger learners, who are often novices at providing feedback. It can be difficult for students to learn what constitutes “good” feedback – particularly in open-ended problem-solving contexts. To address this gap, we investigate both classical natural language processing techniques and large language models, specifically ChatGPT, as potential approaches to devise an automated detector of feedback quality (including both student progress towards goals and next steps needed). Our findings indicate that the classical detectors are highly accurate and, through feature analysis, we elucidate the pivotal elements influencing its decision process. We find that ChatGPT is less accurate than classical NLP but illustrate the potential of ChatGPT in evaluating feedback, by generating explanations for ratings, along with scores. We discuss how the detector can be used for automated feedback evaluation and to better scaffold peer feedback for younger learners.",Proceedings of the 14th Learning Analytics and Knowledge Conference,55–65,11,"Generative AI, Language Analytics, Large Language Models, Natural Language Processing, Peer Feedback","Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
,PCI '23: Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics,2023,9798400716263,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lamia, Greece",,proceedings,,,,,,,,,,
"Coscia, Adam and Holmes, Langdon and Morris, Wesley and Choi, Joon Suh and Crossley, Scott and Endert, Alex",iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645142,10.1145/3640543.3645142,"The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods. To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction. To validate our approach, we deployed iScore with three learning engineers over the course of a month. We present a case study where interacting with iScore led a learning engineer to improve their LLM’s score accuracy by three percentage points. Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment.",Proceedings of the 29th International Conference on Intelligent User Interfaces,787–802,16,"Data visualization, educational technology, explainable AI, large language models, visual analytics","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
,SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,2024,9798400702433,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Avila, Spain",,proceedings,,,,,,,,,,
,The User Experience of ChatGPT: Findings from a Questionnaire Study of Early Users,2023,9798400700149,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3571884.3597144,10.1145/3571884.3597144,"The launch of ChatGPT has attracted significant attention and showcased the potentially game-changing capabilities of conversational AI. These capabilities, and lack of user research, highlight the need to investigate how users experience interactions with conversational AIs like ChatGPT. Therefore, we conducted a questionnaire study with ChatGPT users (N=194), inquiring about their good and poor experiences with ChatGPT. The user reports were analyzed by a thematic analysis and systematized through a pragmatic-hedonic framework. Our results demonstrate how user experience is influenced by pragmatic attributes such as ChatGPT providing useful and detailed information and easing work- or school-related tasks. Additionally, user experience is impacted by hedonic attributes, such as entertainment and creative interactions, and interactions leaving the user impressed or surprised. Our study underscores that user experience concerning conversational AI like ChatGPT is assessed by useful and productive interactions even in early phase of uptake, suggesting the importance of pragmatic attributes.",Proceedings of the 5th International Conference on Conversational User Interfaces,,10,"User experience, Pragmatic-hedonic framework, Conversational AI, ChatGPT","Eindhoven, Netherlands",CUI '23,inproceedings,2,,,,,,,,,
"Drosos, Ian and Sarkar, Advait and Xu, Xiaotong and Negreanu, Carina and Rintel, Sean and Tankelevitch, Lev",,2024,9798400710179,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3663384.3663389,10.1145/3663384.3663389,"Generative AI tools can help users with many tasks. One such task is data analysis, which is notoriously challenging for non-expert end-users due to its expertise requirements, and where AI holds much potential, such as finding relevant data sources, proposing analysis strategies, and writing analysis code. To understand how data analysis workflows can be assisted or impaired by generative AI, we conducted a study (n=15) using Bing Chat via participatory prompting. Participatory prompting is a recently developed methodology in which users and researchers reflect together on tasks through co-engagement with generative AI. In this paper we demonstrate the value of the participatory prompting method. We found that generative AI benefits the information foraging and sensemaking loops of data analysis in specific ways, but also introduces its own barriers and challenges, arising from the difficulties of query formulation, specifying context, and verifying results.",Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work,,21,,"Newcastle upon Tyne, United Kingdom",CHIWORK '24,inproceedings,16,,,,,,,,,
"Manzano, Mila and O'Donnell, Kristen and Espinosa, Eden and Yoon, Sejong",MiRODES: Mini Intelligent Robot for On-campus Domain-specific Event Support,2024,9798400703232,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3610978.3641272,10.1145/3610978.3641272,"Life with robots in everyday life is no longer a picture of science fictions. Robots are expected to interact with people in more natural, real-world contexts, such as crowded indoor spaces beyond controlled environments. This paper introduces our ongoing project of building a robot tour guide that aims to cope with crowds of visitors during on-campus recruiting events. We present a user interface that can effectively interact with guests while answering domain specific questions. Additionally, we discuss challenges in our robot system design with the aim of safely navigating through crowded indoor environments.",Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,1245–1248,4,"TurtleBot4, UX design, generative model, speech recognition","Boulder, CO, USA",HRI '24,inproceedings,,,,,,,,,,
"Tsai, Chun-Hua and Nandy, Gargi and House, Deanna and Carroll, John",Ensuring Transparency in Using ChatGPT for Public Sentiment Analysis,2024,9798400709883,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3657054.3657128,10.1145/3657054.3657128,"The advancement of generative AI, involving the utilization of large language models (LLMs) like ChatGPT to assess public opinion and sentiment, has become increasingly prevalent. However, this upsurge in usage raises significant questions about the transparency and interpretability of the predictions made by these LLM Models. Hence, this paper explores the imperative of ensuring transparency in the application of ChatGPT for public sentiment analysis. To tackle these challenges, we propose using a lexicon-based model as a surrogate to approximate both global and local predictions. Through case studies, we demonstrate how transparency mechanisms, bolstered by the lexicon-based model, can be seamlessly integrated into ChatGPT’s deployment for sentiment analysis. Drawing on the results of our study, we further discuss the implications for future research involving the utilization of LLMs in governmental functions, policymaking, and public engagement.",Proceedings of the 25th Annual International Conference on Digital Government Research,627–636,10,"AI Ethics and Governance, CDC, COVID, Civic Engagement","Taipei, Taiwan",dg.o '24,inproceedings,,,,,,,,,,
"Song, Jaeyong and Yim, Jinkyu and Jung, Jaewon and Jang, Hongsun and Kim, Hyung-Jin and Kim, Youngsok and Lee, Jinho",Optimus-CC: Efficient Large NLP Model Training with 3D Parallelism Aware Communication Compression,2023,9781450399166,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3575693.3575712,10.1145/3575693.3575712,"In training of modern large natural language processing (NLP) models, it has become a common practice to split models using 3D parallelism to multiple GPUs. Such technique, however, suffers from a high overhead of inter-node communication. Compressing the communication is one way to mitigate the overhead by reducing the inter-node traffic volume; however, the existing compression techniques have critical limitations to be applied for NLP models with 3D parallelism in that 1) only the data parallelism traffic is targeted, and 2) the existing compression schemes already harm the model quality too much.  

In this paper, we present Optimus-CC, a fast and scalable distributed training framework for large NLP models with aggressive communication compression. Optimus-CC differs from existing communication compression frameworks in the following ways: First, we compress pipeline parallel (inter-stage) traffic. In specific, we compress the inter-stage backpropagation and the embedding synchronization in addition to the existing data-parallel traffic compression methods. Second, we propose techniques to avoid the model quality drop that comes from the compression. We further provide mathematical and empirical analyses to show that our techniques can successfully suppress the compression error. Lastly, we analyze the pipeline and opt to selectively compress those traffic lying on the critical path. This further helps reduce the compression error. We demonstrate our solution on a GPU cluster, and achieve superior speedup from the baseline state-of-the-art solutions for distributed training without sacrificing the model quality.","Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2",560–573,14,"Systems for Machine Learning, Pipeline Parallelism, Large-scale NLP Training, Gradient Compression, Distributed Systems, Communication Optimization, 3D Parallelism","Vancouver, BC, Canada",ASPLOS 2023,inproceedings,,,,,,,,,,
"He, Zhenhua and Saluja, Aditi and Lawrence, Richard and Chakravorty, Dhruva and Dang, Francis and Perez, Lisa and Liu, Honggao",Performance of Distributed Deep Learning Workloads on a Composable Cyberinfrastructure,2023,9781450399852,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3569951.3593601,10.1145/3569951.3593601,"The next generation of computing systems are likely to rely on disaggregated resources that can be dynamically reconfigured and customized for researchers to support scientific and engineering workflows that require different cyberinfrastructure (CI) technologies. These resources would include memory, accelerators, co-processors among other technologies. This would represent a significant shift in High Performance Computing (HPC) from the now typical model of clusters that have these resources permanently connected to a single server. While composing hardware frameworks with disaggregated resources holds promise, we need to understand how to situate workflows on these resources and evaluate the impact of this approach on workflow performance against “traditional” clusters.&nbsp; Toward developing this knowledge framework, we study the applicability and performance of deep learning workloads on GPU-enabled composable and traditional HPC computing platforms. Results from tests performed using the Horovod framework with TensorFlow and PyTorch models on these HPC environments are presented here.",Practice and Experience in Advanced Research Computing,60–67,8,"T4, ResNet50, Grace, GPU (Graphics Processing Unit), FASTER (Fostering Accelerated Sciences Transformation Education and Research), BERT-Large, Accelerators, A100","Portland, OR, USA",PEARC '23,inproceedings,,,,,,,,,,
"Ricci, Alessandro and Mariani, Stefano and Zambonelli, Franco and Burattini, Samuele and Castelfranchi, Cristiano",The Cognitive Hourglass: Agent Abstractions in the Large Models Era,2024,9798400704864,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,,"Recent advances in AI are driving an unprecedented and fast-paced development of myriads of powerful agent tools and applications, mostly based on generative AI technologies such as Large Language/Multi-modal/Agent Models. However, despite many proposals in that direction, the lack of a sound set of usable engineering abstractions hinders the possibility of methodically engineering complex agent-based applications, also due to the gap between cognitive agent-based concepts and LLMs' behavioural patterns. We argue that such a set of abstractions should constitute the ",Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems,2706–2711,6,"agent systems engineering, cognition, hourglass model, llms","Auckland, New Zealand",AAMAS '24,inproceedings,,,,,,,,,,
,IUI '23 Companion: Companion Proceedings of the 28th International Conference on Intelligent User Interfaces,2023,9798400701078,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
"Jiang, Wenqi and Korolija, Dario and Alonso, Gustavo",Data Processing with FPGAs on Modern Architectures,2023,9781450395076,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3555041.3589410,10.1145/3555041.3589410,"Trends in hardware, the prevalence of the cloud, and the rise of highly demanding applications have ushered an era of specialization that is quickly changing the way data is processed at scale. These changes are likely to continue and accelerate in the next years as new technologies are adopted and deployed: smart NICs, smart storage, smart memory, disaggregated storage, disaggregated memory, specialized accelerators (GPUS, TPUs, FPGAs), as well as a wealth of ASICS specifically created to deal with computationally expensive tasks (e.g., cryptography or compression). In this tutorial we focus on data processing on FPGAs, a technology that has received less attention than, e.g., TPUs or GPUs but that is, however, increasingly being deployed in the cloud for data processing tasks due to the architectural flexibility of FPGAs and their ability to process data at line rate, something not possible with other type of processors or accelerators. In the tutorial we will cover what are FPGAs, their characteristics, their advantages and disadvantages over other design options, as well as examples from deployments in industry and how they are used in a variety of data processing tasks. Then we will provide a brief introduction to FPGA programming with High Level Synthesis (HLS) tools as well as briefly describe resources available to researchers in the form of academic clusters and open source systems that simplify the first steps. The tutorial will also include several case studies borrowed from research done in collaboration with companies that illustrate both the potential of FPGAs in data processing but also how software and hardware architectures are evolving to take advantage of the possibilities offered by FPGAs.",Companion of the 2023 International Conference on Management of Data,77–82,6,"data management, data processing, fpga, hardware acceleration","Seattle, WA, USA",SIGMOD '23,inproceedings,,,,,,,,,,
"Savage, Neil",Can ChatGPT Learn Chinese or Swahili?,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640351,10.1145/3640351,Considering how large language models might act differently if trained in different languages.,,29–31,3,,,,article,,May 2024,67,5,Commun. ACM,may,0001-0782,,,
,AIQAM '24: Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia,2024,9798400705472,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Phuket, Thailand",,proceedings,,,,,,,,,,
,CHI EA '24: Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"
",,proceedings,,,,,,,,,,
,VaMoS '24: Proceedings of the 18th International Working Conference on Variability Modelling of Software-Intensive Systems,2024,9798400708770,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bern, Switzerland",,proceedings,,,,,,,,,,
"Wei, Jing and Kim, Sungdong and Jung, Hyunhoon and Kim, Young-Ho",Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3637364,10.1145/3637364,"Large language models (LLMs) provide a new way to build chatbots by accepting natural language prompts. Yet, it is unclear how to design prompts to power chatbots to carry on naturalistic conversations while pursuing a given goal such as collecting self-report data from users. We explore what design factors of prompts can help steer chatbots to talk naturally and collect data reliably. To this aim, we formulated four prompt designs with different structures and personas. Through an online study (N = 48) where participants conversed with chatbots driven by different designs of prompts, we assessed how prompt designs and conversation topics affected the conversation flows and users' perceptions of chatbots. Our chatbots covered 79% of the desired information slots during conversations, and the designs of prompts and topics significantly influenced the conversation flows and the data collection performance. We discuss the opportunities and challenges of building chatbots with LLMs.",,,35,"chatbots, conversational agents, dialogue acts, large language models",,,article,87,April 2024,8,CSCW1,Proc. ACM Hum.-Comput. Interact.,apr,,,,
"Wu, Yuxia and Dai, Tianhao and Zheng, Zhedong and Liao, Lizi",Active Discovering New Slots for Task-Oriented Conversation,2024,,IEEE Press,,https://doi.org/10.1109/TASLP.2024.3374060,10.1109/TASLP.2024.3374060,"Existing task-oriented conversational systems heavily rely on domain ontologies with pre-defined slots and candidate values. In practical settings, these prerequisites are hard to meet, due to the emerging new user requirements and ever-changing scenarios. To mitigate these issues for better interaction performance, there are efforts working towards detecting out-of-vocabulary values or discovering new slots under unsupervised or semi-supervised learning paradigms. However, overemphasizing on the conversation data patterns alone induces these methods to yield noisy and arbitrary slot results. To facilitate the pragmatic utility, real-world systems tend to provide a stringent amount of human labeling quota, which offers an authoritative way to obtain accurate and meaningful slot assignments. Nonetheless, it also brings forward the high requirement of utilizing such quota efficiently. Hence, we formulate a general new slot discovery task in an information extraction fashion and incorporate it into an active learning framework to realize human-in-the-loop learning. Specifically, we leverage existing language tools to extract value candidates where the corresponding labels are further leveraged as weak supervision signals. Based on these, we propose a bi-criteria selection scheme which incorporates two major strategies, namely, uncertainty-based and diversity-based sampling to efficiently identify terms of interest. We conduct extensive experiments on several public datasets and compare with a bunch of competitive baselines to demonstrate the effectiveness of our method.",,2062–2072,11,,,,article,,2024,32,,"IEEE/ACM Trans. Audio, Speech and Lang. Proc.",mar,2329-9290,,,
"Wang, Zijie J. and Munechika, David and Lee, Seongmin and Chau, Duen Horng",SuperNOVA: Design Strategies and Opportunities for Interactive Visualization in Computational Notebooks,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650848,10.1145/3613905.3650848,"Computational notebooks, such as Jupyter Notebook, have become data scientists’ de facto programming environments. Many visualization researchers and practitioners have developed interactive visualization tools that support notebooks, yet little is known about the appropriate design of these tools. To address this critical research gap, we investigate the design strategies in this space by analyzing 163 notebook visualization tools. Our analysis encompasses 64 systems from academic papers and 105 systems sourced from a pool of 55k notebooks containing interactive visualizations that we obtain via scraping 8.6 million notebooks on GitHub. Through this study, we identify key design implications and trade-offs, such as leveraging multimodal data in notebooks as well as balancing the degree of visualization-notebook integration. Furthermore, we provide empirical evidence that tools compatible with more notebook platforms have a greater impact. Finally, we develop SuperNOVA, an open-source interactive browser to help researchers explore existing notebook visualization tools. SuperNOVA is publicly accessible at: https://poloclub.github.io/supernova/.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,17,"Computational Notebook, Cross-Platform Visualization, Data Science, Design, Interactive Visualization, Systematic Review","
",CHI EA '24,inproceedings,304,,,,,,,,,
"Jiang, Ellen and Olson, Kristen and Toh, Edwin and Molina, Alejandra and Donsbach, Aaron and Terry, Michael and Cai, Carrie J",PromptMaker: Prompt-based Prototyping with Large&nbsp;Language&nbsp;Models,2022,9781450391566,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3491101.3503564,10.1145/3491101.3503564,"Prototyping is notoriously difficult to do with machine learning (ML), but recent advances in large language models may lower the barriers to people prototyping with ML, through the use of natural language prompts. This case study reports on the real-world experiences of industry professionals (e.g. designers, program managers, front-end developers) prototyping new ML-powered feature ideas via prompt-based prototyping. Through interviews with eleven practitioners during a three-week sprint and a workshop, we find that prompt-based prototyping reduced barriers of access by substantially broadening who can prototype with ML, sped up the prototyping process, and grounded communication between collaborators. Yet, it also introduced new challenges, such as the need to reverse-engineer prompt designs, source example data, and debug and evaluate prompt effectiveness. Taken together, this case study provides important implications that lay the groundwork toward a new future of prototyping with ML.",Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems,,8,,"New Orleans, LA, USA",CHI EA '22,inproceedings,35,,,,,,,,,
"Perera, Minoli",Enhancing Productivity Applications for People who are Blind using AI Assistants,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3638180,10.1145/3613905.3638180,"Productivity applications, such as word processors, spreadsheets and presentations, have become indispensable tools in the workplace, higher education, and personal settings. These applications are primarily accessed by blind users through the use of screen readers, which face numerous accessibility and usability challenges that hinder productivity and independence. My research aims to understand the severity of these challenges, explore the design space for potential AI-based Assistants, and propose design guidelines for more accessible and usable applications. The research employs a Design Thinking and Co-design approach, with the active involvement of blind users throughout the project. I have conducted a survey and a user study to gain insights into blind users’ experiences with productivity applications. The next phase of the project will delve into AI assistant capabilities and interaction techniques aimed at enhancing blind users’ productivity and independence.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,6,"AI assistants, accessibility, assistive technology, blind, generative AI, productivity applications, screen readers, virtual assistants, voice assistants","
",CHI EA '24,inproceedings,432,,,,,,,,,
,CHIIR '24: Proceedings of the 2024 Conference on Human Information Interaction and Retrieval,2024,9798400704345,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sheffield, United Kingdom",,proceedings,,,,,,,,,,
,ETRA '23: Proceedings of the 2023 Symposium on Eye Tracking Research and Applications,2023,9798400701504,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Tubingen, Germany",,proceedings,,,,,,,,,,
,IUI '24 Companion: Companion Proceedings of the 29th International Conference on Intelligent User Interfaces,2024,9798400705090,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Greenville, SC, USA",,proceedings,,,,,,,,,,
"Pinelli, Fabio and Tolomei, Gabriele and Trappolini, Giovanni",FLIRT: Federated Learning for Information Retrieval,2023,9781450394086,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3539618.3591926,10.1145/3539618.3591926,"A wide range of core information retrieval (IR) tasks, such as searching, ranking, and filtering, to name a few, have seen tremendous improvements thanks to machine learning (ML) and artificial intelligence (AI). The traditional centralized approach to training AI/ML models is still predominant: large volumes of data generated by end users must be transferred from their origins and shared with remote locations for processing. However, this centralized paradigm suffers from significant privacy issues and does not take full advantage of the computing power of client devices like modern smartphones. A possible answer to this need is provided by federated learning (FL), which enables collaborative training of predictive models among a set of cooperating edge devices without disclosing any private local data. Unfortunately, FL is still far from being fully exploited in the IR ecosystem.In this workshop proposal, we have the ambition to start filling this gap. More specifically, the first workshop on ''Federated Learning for Information ReTrieval'' (FLIRT) is willing to provide an open forum for researchers and practitioners where they can exchange ideas, identify key challenges, and define the roadmap toward a successful application of FL in the broad IR area.",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,3472–3475,4,"federated learning, information retrieval","Taipei, Taiwan",SIGIR '23,inproceedings,,,,,,,,,,
,,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641964,10.1145/3613904.3641964,"Large language models (LLMs) like ChatGPT have been widely adopted in work contexts. We explore the impact of ChatGPT on young professionals’ perception of productivity and sense of accomplishment. We collected LLMs’ main use cases in knowledge work through a preliminary study, which served as the basis for a two-week diary study with 21 young professionals reflecting on their ChatGPT use. Findings indicate that ChatGPT enhanced some participants’ perceptions of productivity and accomplishment by enabling greater creative output and satisfaction from efficient tool utilization. Others experienced decreased perceived productivity and accomplishment, driven by a diminished sense of ownership, perceived lack of challenge, and mediocre results. We found that the suitability of task delegation to ChatGPT varies strongly depending on the task nature. It’s especially suitable for comprehending broad subject domains, generating creative solutions, and uncovering new information. It’s less suitable for research tasks due to hallucinations, which necessitate extensive validation.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Generative AI, knowledge work, productivity, self-efficacy, sense of accomplishment","Honolulu, HI, USA",CHI '24,inproceedings,1018,,,,,,,,,
"Yin, Junqi and Dash, Sajal and Wang, Feiyi and Shankar, Mallikarjun",FORGE: Pre-Training Open Foundation Models for Science,2023,9798400701092,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3581784.3613215,10.1145/3581784.3613215,"Large language models (LLMs) are poised to revolutionize the way we conduct scientific research. However, both model complexity and pre-training cost are impeding effective adoption for the wider science community. Identifying suitable scientific use cases, finding the optimal balance between model and data sizes, and scaling up model training are among the most pressing issues that need to be addressed. In this study, we provide practical solutions for building and using LLM-based foundation models targeting scientific research use cases. We present an end-to-end examination of the effectiveness of LLMs in scientific research, including their scaling behavior and computational requirements on Frontier, the first Exascale supercomputer. We have also developed for release to the scientific community a suite of open foundation models called FORGE with up to 26B parameters using 257B tokens from over 200M scientific articles, with performance either on par or superior to other state-of-the-art comparable models. We have demonstrated the use and effectiveness of FORGE on scientific downstream tasks. Our research establishes best practices that can be applied across various fields to take advantage of LLMs for scientific discovery.","Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis",,13,,"Denver, CO, USA",SC '23,inproceedings,81,,,,,,,,,
"Zheng, Chengbo and Yuan, Kangyu and Guo, Bingcan and Hadi Mogavi, Reza and Peng, Zhenhui and Ma, Shuai and Ma, Xiaojuan",Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642807,10.1145/3613904.3642807,"Students’ increasing use of Artificial Intelligence (AI) presents new challenges for assessing their mastery of knowledge and skills in project-based learning (PBL). This paper introduces a co-design study to explore the potential of students’ AI usage data as a novel material for PBL assessment. We conducted workshops with 18 college students, encouraging them to speculate an alternative world where they could freely employ AI in PBL while needing to report this process to assess their skills and contributions. Our workshops yielded various scenarios of students’ use of AI in PBL and ways of analyzing such usage grounded by students’ vision of how educational goals may transform. We also found that students with different attitudes toward AI exhibited distinct preferences in how to analyze and understand their use of AI. Based on these findings, we discuss future research opportunities on student-AI interactions and understanding AI-enhanced learning.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,19,"AI for education, co-design, generative AI, project-based learning, qualitative study","Honolulu, HI, USA",CHI '24,inproceedings,94,,,,,,,,,
"Williams, Tom and Matuszek, Cynthia and Jokinen, Kristiina and Korpan, Raj and Pustejovsky, James and Scassellati, Brian",Voice in the Machine: Ethical Considerations for Language-Capable Robots,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3604632,10.1145/3604632,Parsing the promise of language-capable robots.,,20–23,4,,,,article,,August 2023,66,8,Commun. ACM,jul,0001-0782,,,
"Popa, Raluca Ada",Confidential Computing or Cryptographic Computing? Tradeoffs between cryptography and hardware enclaves,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3664295,10.1145/3664295,"Secure computation via MPC/homomorphic encryption versus hardware enclaves presents tradeoffs involving deployment, security, and performance. Regarding performance, it matters a lot which workload you have in mind. For simple workloads such as simple summations, low-degree polynomials, or simple machine-learning tasks, both approaches can be ready to use in practice, but for rich computations such as complex SQL analytics or training large machine-learning models, only the hardware enclave approach is at this moment practical enough for many real-world deployment scenarios.",,108–132,25,,,,article,,March/April 2024,22,2,Queue,may,1542-7730,,,
"Palani, Srishti and Ramos, Gonzalo",Evolving Roles and Workflows of Creative Practitioners in the Age of Generative AI,2024,9798400704857,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3635636.3656190,10.1145/3635636.3656190,"Creative practitioners (like designers, software developers, and architects) have started to employ Generative AI models (GenAI) to produce text, images, and assets comparable to those made by people. While HCI research explores specific GenAI models and creativity support tools, little is known about practitioners’ evolving roles and workflows with GenAI models across a project’s stages. This knowledge is key to guide the development of the new generation of Creativity Support Tools. We contribute to this knowledge by employing a triangulated method to capture interviews, videos, and survey responses of creative practitioners reflecting on projects they completed with GenAI. Our observations let us derive a set of factors that capture practitioners’ perceived roles, challenges, benefits, and interaction patterns when creating with GenAI. From these factors, we offer insights and propose design opportunities and priorities that serve to encourage reflection from the wider community of Creativity Support Tools and GenAI stakeholders such as systems creators, researchers, and educators on how to develop systems that meet the needs of creatives in human-centered ways.",Proceedings of the 16th Conference on Creativity &amp; Cognition,170–184,15,"Creative Practitioners, Creativity, Generative AI","Chicago, IL, USA",C&amp;C '24,inproceedings,,,,,,,,,,
"Tseng, Yu-Min and Chen, Chung-Chi and Huang, Hen-Hsen and Chen, Hsin-Hsi",DynamicESG: A Dataset for Dynamically Unearthing ESG Ratings from News Articles,2023,9798400701245,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3583780.3615118,10.1145/3583780.3615118,"This paper introduces the DynamicESG dataset, a unique resource for dynamically extracting ESG ratings from news articles. The ESG rating, a novel metric employed annually to gauge a company's sustainability, relies heavily on corporate disclosure and other external information, especially news narratives. Our dataset, comprising a wide spectrum of news over a twelve-year span, annotates articles in accordance with MSCI ESG ratings methodology and SASB standards, with relevance to ESG issues. DynamicESG provides a comprehensive means of investigating the relationship between public discourse, ESG-related events, and subsequent ESG rating adjustments. We detail our data collection, curation, annotation procedure, and inter-rater agreement, ensuring high data quality and usability. Importantly, our dataset includes a temporal dimension, enabling the analysis of longitudinal trends in ESG ratings and their correlation with news coverage. Moreover, the dataset incorporates an opportunity/risk tendency, thus permitting analysis from diverse perspectives to discern if the news is beneficial or detrimental to the company. We believe this dataset will serve as a valuable resource for researchers in fields such as corporate social responsibility, sustainable investing, machine learning, and natural language processing. Initial analysis using the dataset underscores its potential to facilitate new insights into the dynamics of ESG ratings and the influence of news media on these ratings.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,5412–5416,5,"social good, ESG rating, ESG","Birmingham, United Kingdom",CIKM '23,inproceedings,,,,,,,,,,
"Wei, Jing and Kim, Young-Ho and Chan, Samantha W. T. and Dingler, Tilman",Design and Prototype Conversational Agents for Research Data Collection,2022,9781450393560,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3532104.3571467,10.1145/3532104.3571467,"Conversational agents have gained increasing interest from researchers as a tool to collect data and administer interventions. They provide a natural user interface through conversations and hence have the potential to reach a wide population in their homes and on the go. Several developer tools and commercial as well as open-source frameworks allow for the deployment of both text-based chatbots and voice assistants. In this 90 min tutorial, participants will learn how to choose an appropriate platform, how to design and deploy their conversational agents, and how to transform traditional surveys through conversation agents.",Companion Proceedings of the 2022 Conference on Interactive Surfaces and Spaces,57–58,2,"conversational user interface, conversational agents, chatbots, ESM","Wellington, New Zealand",ISS '22,inproceedings,,,,,,,,,,
,,2024,9798400717871,Association for Computing Machinery,"New York, NY, USA",,,,,,,,,,proceedings,,,,,,,,,,
"Salminen, Joni and Liu, Chang and Pian, Wenjing and Chi, Jianxing and H\",Deus Ex Machina and Personas from Large Language Models: Investigating the Composition of AI-Generated Persona Descriptions,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642036,10.1145/3613904.3642036,"Large language models (LLMs) can generate personas based on prompts that describe the target user group. To understand what kind of personas LLMs generate, we investigate the diversity and bias in 450 LLM-generated personas with the help of internal evaluators (n=4) and subject-matter experts (SMEs) (n=5). The research findings reveal biases in LLM-generated personas, particularly in age, occupation, and pain points, as well as a strong bias towards personas from the United States. Human evaluations demonstrate that LLM persona descriptions were informative, believable, positive, relatable, and not stereotyped. The SMEs rated the personas slightly more stereotypical, less positive, and less relatable than the internal evaluators. The findings suggest that LLMs can generate consistent personas perceived as believable, relatable, and informative while containing relatively low amounts of stereotyping.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,20,"AI, HCI, LLMs, evaluation, user personas","Honolulu, HI, USA",CHI '24,inproceedings,510,,,,,,,,,
"Shah, Chirag and Bender, Emily M.",Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web?,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3649468,10.1145/3649468,"We observe a recent trend toward applying large language models (LLMs) in search and positioning them as effective information access systems. While the interfaces may look appealing and the apparent breadth of applicability is exciting, we are concerned that the field is rushing ahead with a technology without sufficient study of the uses it is meant to serve, how it would be used, and what its use would mean. We argue that it is important to reassert the central research focus of the field of information retrieval, because information access is not merely an application to be solved by the so-called ‘AI’ techniques du jour. Rather, it is a key human activity, with impacts on both individuals and society. As information scientists, we should be asking what do people and society want and need from information access systems and how do we design and build systems to meet those needs? With that goal, in this conceptual article we investigate fundamental questions concerning information access from user and societal viewpoints. We revisit foundational work related to information behavior, information seeking, information retrieval, information filtering, and information access to resurface what we know about these fundamental questions and what may be missing. We then provide our conceptual framing about how we could fill this gap, focusing on methods as well as experimental and evaluation frameworks. We consider the Web as an information ecosystem and explore the ways in which synthetic media, produced by LLMs and otherwise, endangers that ecosystem. The primary goal of this conceptual article is to shed light on what we still do not know about the potential impacts of LLM-based information access systems, how to advance our understanding of user behaviors, and where the next generations of students, scholars, and developers could fruitfully invest their energies.",,,24,"Information access systems, large language models, information ecosystem",,,article,33,August 2024,18,3,ACM Trans. Web,apr,1559-1131,,,
,RSP '23: Proceedings of the 34th International Workshop on Rapid System Prototyping,2023,9798400704109,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hamburg, Germany",,proceedings,,,,,,,,,,
D\,SchemaPile: A Large Collection of Relational Database Schemas,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3654975,10.1145/3654975,"Access to fine-grained schema information is crucial for understanding how relational databases are designed and used in practice, and for building systems that help users interact with them. Furthermore, such information is required as training data to leverage the potential of large language models (LLMs) for improving data preparation, data integration and natural language querying. Existing single-table corpora such as GitTables provide insights into how tables are structured in-the-wild, but lack detailed schema information about how tables relate to each other, as well as metadata like data types or integrity constraints. On the other hand, existing multi-table (or database schema) datasets are rather small and attribute-poor, leaving it unclear to what extent they actually represent typical real-world database schemas.In order to address these challenges, we present SchemaPile, a corpus of 221,171 database schemas, extracted from SQL files on GitHub. It contains 1.7 million tables with 10 million column definitions, 700 thousand foreign key relationships, seven million integrity constraints, and data content for more than 340 thousand tables. We conduct an in-depth analysis on the millions of schema metadata properties in our corpus, as well as its highly diverse language and topic distribution. In addition, we showcase the potential of corpus to improve a variety of data management applications, e.g., fine-tuning LLMs for schema-only foreign key detection, improving CSV header detection and evaluating multi-dialect SQL parsers. We publish the code and data for recreating SchemaPile and a permissively licensed subset SchemaPile-Perm.",,,25,"csv parsing, dataset, foreign key detection, large language models, relational database schemas, sql parsing",,,article,172,June 2024,2,3,Proc. ACM Manag. Data,may,,,,
,SIGUCCS '24: Proceedings of the 2024 ACM SIGUCCS Annual Conference,2024,9798400702266,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chicago, IL, USA",,proceedings,,,,,,,,,,
"Biswas, Pradipta and Sharma, Vinay Krishna and Pena-Rios, Anasol and Whitworth, Eryn and Orero, Pilar",Intelligent User Interface for Metaverse,2024,9798400705090,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640544.3645252,10.1145/3640544.3645252,"Recent research in eXtended Reality (XR) Technologies, Computer Vision and AI are redefining interaction with electronic media in new ways which was not thought before. From its inception at the 1956 Dartmouth Workshop, Artificial Intelligence (AI) revitalized itself many times by finding new theories and applications. The newly popularized concept of Metaverse can be an apt platform to merge AI and XR technologies together. This workshop is planned to investigate user interface and interaction issues with Metaverse and scoping the use of AI tools and technology for improving UI/UX for Metaverse. As part of the workshop, the very concept of Metaverse will be explored in details with members from academia, industry and standardization bodies. Paper and poster submissions will be solicited and interactive demonstration sessions will be organized to explore various use cases and related UI/UX challenges in Metaverse.",Companion Proceedings of the 29th International Conference on Intelligent User Interfaces,116–118,3,"Artificial Intelligence, Augmented Reality, Metaverse, Virtual Reality","Greenville, SC, USA",IUI '24 Companion,inproceedings,,,,,,,,,,
"Englhardt, Zachary and Ma, Chengqian and Morris, Margaret E. and Chang, Chun-Cheng and Xu, Xuhai ",From Classification to Clinical Insights: Towards Analyzing and Reasoning About Mobile and Behavioral Health Data With Large Language Models,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3659604,10.1145/3659604,"Passively collected behavioral health data from ubiquitous sensors could provide mental health professionals valuable insights into patient's daily lives, but such efforts are impeded by disparate metrics, lack of interoperability, and unclear correlations between the measured signals and an individual's mental health. To address these challenges, we pioneer the exploration of large language models (LLMs) to synthesize clinically relevant insights from multi-sensor data. We develop chain-of-thought prompting methods to generate LLM reasoning on how data pertaining to activity, sleep and social interaction relate to conditions such as depression and anxiety. We then prompt the LLM to perform binary classification, achieving accuracies of 61.1%, exceeding the state of the art. We find models like GPT-4 correctly reference numerical data 75% of the time.While we began our investigation by developing methods to use LLMs to output binary classifications for conditions like depression, we find instead that their greatest potential value to clinicians lies not in diagnostic classification, but rather in rigorous analysis of diverse self-tracking data to generate natural language summaries that synthesize multiple data streams and identify potential concerns. Clinicians envisioned using these insights in a variety of ways, principally for fostering collaborative investigation with patients to strengthen the therapeutic alliance and guide treatment. We describe this collaborative engagement, additional envisioned uses, and associated concerns that must be addressed before adoption in real-world contexts.",,,25,"Passive sensing, clinical insights, large-language-models, mental health",,,article,56,May 2024,8,2,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,may,,,,
"Rubio-Medrano, Carlos E. and Kotak, Akash and Wang, Wenlu and Sohr, Karsten",Pairing Human and Artificial Intelligence: Enforcing Access Control Policies with LLMs and Formal Specifications,2024,9798400704918,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3649158.3657032,10.1145/3649158.3657032,"Large Language Models (LLMs), such as ChatGPT and Google Bard, have performed interestingly well when assisting developers on computer programming tasks, a.k.a., coding, thus potentially resulting in convenient and faster software constructions. This new approach significantly enhances efficiency but also presents challenges in unsupervised code construction with limited security guarantees. LLMs excel in producing code with accurate grammar, yet they are not specifically trained to guarantee the security of the code. In this paper, we provide an initial exploration into using formal software specifications as a starting point for software construction, allowing developers to translate descriptions of security-related behavior into natural language instructions for LLMs, a.k.a., prompts. In addition, we leveraged automated verification tools to evaluate the code produced against the aforementioned specifications , following a modular, step-by-step software construction process. For our study, we leveraged Role-based Access Control (RBAC), a mature security model, and the Java Modeling Language (JML), a behavioral specification language for Java. We test our approach on different publicly-available LLMs, namely, OpenAI ChatGPT 4.0, Google Bard, and Microsoft CoPilot. We provide a description of two applications-a security-sensitive Banking application employing RBAC and an RBAC API module itself-, the corresponding JML specifications, as well as a description of the prompts, the generated code, the verification results, as well as a series of interesting insights for practitioners interested in further exploring the use of LLMs for securely constructing applications.",Proceedings of the 29th ACM Symposium on Access Control Models and Technologies,105–116,12,"chatgpt, formal specifications, large language models, prompt engineering, software construction. java modeling language","San Antonio, TX, USA",SACMAT 2024,inproceedings,,,,,,,,,,
,PETRA '24: Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments,2024,9798400717604,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Crete, Greece",,proceedings,,,,,,,,,,
,EICS '24 Companion: Companion Proceedings of the 16th ACM SIGCHI Symposium on Engineering Interactive Computing Systems,2024,9798400706516,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Cagliari, Italy",,proceedings,,,,,,,,,,
"Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.",“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580817,10.1145/3544548.3580817,"Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user’s natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users’ understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,31,"Human-AI Interaction, Large Language Models, Natural Language Programming, Spreadsheets","Hamburg, Germany",CHI '23,inproceedings,598,,,,,,,,,
"Lawley, Lane and Maclellan, Christopher",VAL: Interactive Task Learning with GPT Dialog Parsing,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3641915,10.1145/3613904.3641915,"Machine learning often requires millions of examples to produce static, black-box models. In contrast, interactive task learning (ITL) emphasizes incremental knowledge acquisition from limited instruction provided by humans in modalities such as natural language. However, ITL systems often suffer from brittle, error-prone language parsing, which limits their usability. Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally. We present VAL, an ITL system with a new philosophy for LLM/symbolic integration. By using LLMs only for specific tasks—such as predicate and argument selection—within an algorithmic framework, VAL reaps the benefits of LLMs to support interactive learning of hierarchical task knowledge from natural language. Acquired knowledge is human interpretable and generalizes to support execution of novel tasks without additional training. We studied users’ interactions with VAL in a video game setting, finding that most users could successfully teach VAL using language they felt was natural.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,18,"GPT, hierarchical task networks, hybrid AI, large language models (LLMs), neuro-symbolic AI","Honolulu, HI, USA",CHI '24,inproceedings,5,,,,,,,,,
"Choudhuri, Akash and Jang, Hankyu and Segre, Alberto M. and Polgreen, Philip M. and Jha, Kishlay and Adhikari, Bijaya",Continually-Adaptive Representation Learning Framework for Time-Sensitive Healthcare Applications,2023,9798400701245,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3583780.3615464,10.1145/3583780.3615464,"Continual learning has emerged as a powerful approach to address the challenges of non-stationary environments, allowing machine learning models to adapt to new data while retaining the previously acquired knowledge. In time-sensitive healthcare applications, where entities such as physicians, hospital rooms, and medications exhibit continuous changes over time, continual learning holds great promise, yet its application remains relatively unexplored. This paper aims to bridge this gap by proposing a novel framework, i.e., Continually-Adaptive Representation Learning, designed to adapt representations in response to changing data distributions in evolving healthcare applications. Specifically, the proposed approach develops a continual learning strategy wherein the context information (e.g., interactions) of healthcare entities is exploited to continually identify and retrain the representations of those entities whose context evolved over time. Moreover, different from existing approaches, the proposed approach leverages the valuable patient information present in clinical notes to generate accurate and robust healthcare embeddings. Notably, the proposed continually-adaptive representations have practical benefits in low-resource clinical settings where it is difficult to training machine learning models from scratch to accommodate the newly available data streams. Experimental evaluations on real-world healthcare datasets demonstrate the effectiveness of our approach in time-sensitive healthcare applications such as Clostridioides difficile (C.diff) Infection (CDI) incidence prediction task and medical intensive care unit transfer prediction task.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,4538–4544,7,"electronic healthcare records, dynamic embeddings, continual learning, clinical notes","Birmingham, United Kingdom",CIKM '23,inproceedings,,,,,,,,,,
,CHIGREECE '23: Proceedings of the 2nd International Conference of the ACM Greek SIGCHI Chapter,2023,9798400708886,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Athens, Greece",,proceedings,,,,,,,,,,
"Belghith, Yasmine and Mahdavi Goloujeh, Atefeh and Magerko, Brian and Long, Duri and Mcklin, Tom and Roberts, Jessica","Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642332,10.1145/3613904.3642332,"As generative AI rapidly enters everyday life, educational interventions for teaching about AI need to cater to how young people, in particular middle schoolers who are at a critical age for reasoning skills and identity formation, conceptualize and interact with AI. We conducted nine focus groups with 24 middle school students to elicit their interests, conceptions of, and approaches to a popular generative AI tool, ChatGPT. We highlight a) personally and culturally-relevant topics to this population, b) three distinct approaches in students’ open-ended interactions with ChatGPT: AI testing-oriented, AI socializing-oriented, and content exploring-oriented, and 3) an improved understanding of youths’ conceptions and misconceptions of generative AI. While misconceptions highlight gaps in understanding what generative AI is and how it works, most learners show interest in learning about what AI is and what it can do. We discuss the implications of these conceptions for designing AI literacy interventions in museums.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,17,"AI literacy, ChatGPT, Child-AI Interaction, Conceptions of AI, Conversational Agents (CAs), Generative AI, Informal Learning, Large Language Models (LLMs)","Honolulu, HI, USA",CHI '24,inproceedings,276,,,,,,,,,
,LAK '24: Proceedings of the 14th Learning Analytics and Knowledge Conference,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Kyoto, Japan",,proceedings,,,,,,,,,,
"Cusumano, Michael A.",Generative AI as a New Innovation Platform,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3615859,10.1145/3615859,Considering the stability and longevity of a potential new foundational technology.,,18–21,4,,,,article,,October 2023,66,10,Commun. ACM,sep,0001-0782,,,
,HRI '24: Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,2024,9798400703232,Association for Computing Machinery,"New York, NY, USA",,,"Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is ",,,,,"Boulder, CO, USA",,proceedings,,,,,,,,,,
,Internetware '23: Proceedings of the 14th Asia-Pacific Symposium on Internetware,2023,9798400708947,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hangzhou, China",,proceedings,,,,,,,,,,
,FIRE '23: Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation,2023,9798400716324,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Panjim, India",,proceedings,,,,,,,,,,
"York, Eric",Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy,2023,9798400703362,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3615335.3623035,10.1145/3615335.3623035,"The advent of widely-accessible generative AI tools and their rapid adoption across industry and education is necessitating large-scale revisions to user experience design and web development pedagogies and curricula, a process that will take some time. This report describes a series of initial experiments using generative AI tools as a student or junior designer or web developer might, sometimes na\",Proceedings of the 41st ACM International Conference on Design of Communication,197–201,5,"Artificial Intelligence, Pedagogy, User experience (UX) design, Web development","Orlando, FL, USA",SIGDOC '23,inproceedings,,,,,,,,,,
,EdgeFM '24: Proceedings of the Workshop on Edge and Mobile Foundation Models,2024,9798400706639,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Minato-ku, Tokyo, Japan",,proceedings,,,,,,,,,,
"Jiang, Yuwei and Johnson, David",Data Discovery for the SDGs: A Systematic Rule-based Approach,2023,9798400701160,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3582515.3609557,10.1145/3582515.3609557,"In 2015, the United Nations put forward 17 Sustainable Development Goals (SDGs) to be achieved by 2030, where data has been promoted as a focus to innovating sustainable development and as a means to measuring progress towards achieving the SDGs. In this study, we propose a systematic approach towards discovering data types and sources that can be used for SDG research. The proposed method integrates a systematic mapping approach using manual qualitative coding over a corpus of SDG-related research literature followed by an automated process that applies rules to perform data entity extraction computationally. This approach is exemplified by an analysis of literature relating to SDG 7, the results of which are also presented in this paper. The paper concludes with a discussion of the approach and suggests future work to extend the method with more advanced NLP and machine learning techniques.",Proceedings of the 2023 ACM Conference on Information Technology for Social Good,384–391,8,"systematic mapping, sustainable development, named entity extraction, knowledge discovery, data use, SDG","Lisbon, Portugal",GoodIT '23,inproceedings,,,,,,,,,,
,UIST '23 Adjunct: Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,2023,9798400700965,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"San Francisco, CA, USA",,proceedings,,,,,,,,,,
,CHIWORK '24: Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work,2024,9798400710179,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Newcastle upon Tyne, United Kingdom",,proceedings,,,,,,,,,,
"Burtch, Gordon and Lee, Dokyun and Chen, Zhichen",Generative AI Degrades Online Communities,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3624732,10.1145/3624732,How large language models are influencing online communities.,,40–42,3,,,,article,,March 2024,67,3,Commun. ACM,feb,0001-0782,,,
,SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing,2023,9781450395175,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Tallinn, Estonia",,proceedings,,,,,,,,,,
"Raji, Inioluwa Deborah and Kumar, I. Elizabeth and Horowitz, Aaron and Selbst, Andrew",The Fallacy of AI Functionality,2022,9781450393522,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3531146.3533158,10.1145/3531146.3533158,"Deployed AI systems often do not work. They can be constructed haphazardly, deployed indiscriminately, and promoted deceptively. However, despite this reality, scholars, the press, and policymakers pay too little attention to functionality. This leads to technical and policy solutions focused on “ethical” or value-aligned deployments, often skipping over the prior question of whether a given system functions, or provides any benefits at all. To describe the harms of various types of functionality failures, we analyze a set of case studies to create a taxonomy of known AI functionality issues. We then point to policy and organizational responses that are often overlooked and become more readily available once functionality is drawn into focus. We argue that functionality is a meaningful AI policy challenge, operating as a necessary first step towards protecting affected communities from algorithmic harm.","Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",959–972,14,,"Seoul, Republic of Korea",FAccT '22,inproceedings,,,,,,,,,,
"Davies, Michael and McDougall, Ian and Anandaraj, Selvaraj and Machchhar, Deep and Jain, Rithik and Sankaralingam, Karthikeyan","A Journey of a 1,000 Kernels Begins with a Single Step: A Retrospective of Deep Learning on GPUs",2024,9798400703850,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3620665.3640367,10.1145/3620665.3640367,"We are in age of AI, with rapidly changing algorithms and a somewhat synergistic change in hardware. MLPerf is a recent benchmark suite that serves as a way to compare and evaluate hardware. However it has several drawbacks - it is dominated by CNNs and does a poor job of capturing the diversity of AI use cases, and only represents a sliver of production AI use cases. This paper performs a longitudinal study of state-of-art AI applications spanning vision, physical simulation, vision synthesis, language and speech processing, and tabular data processing, across three generations of hardware to understand how the AI revolution has panned out. We call this collection of applications and execution scaffolding the CaSiO suite. The paper reports on data gathered at the framework level, device API level, and hardware and microarchitecture level. The paper provides insights on the hardware-software revolution with pointers to future trends.","Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2",20–36,17,,"La Jolla, CA, USA",ASPLOS '24,inproceedings,,,,,,,,,,
,"ICGJ '23: Proceedings of the 7th International Conference on Game Jams, Hackathons and Game Creation Events",2023,9798400708794,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Virtual Event, Ukraine",,proceedings,,,,,,,,,,
"Baecker, Ronald M. and Grudin, Jonathan",Digital Dreams Have Become Nightmares: What We Must Do,2024,9798400717703,Association for Computing Machinery,"New York, NY, USA",,,"This book offers a compelling discussion of the digital dreams that have come true, their often unintended side effects (nightmares), and what must be done to counteract the nightmares. It is intended as an impetus to further conversation not only in homes and workplaces, but in academic courses and even legislative debates. Equally importantly, the book is a presentation of what digital technology professionals need to know about these topics and the actions they should undertake individually and in support of other citizens, societal initiatives, and government. The author begins by introducing the amazing progress made in digital technologies over the past 80 years. Pioneering engineers dreamed of potential uses of technology through their writing and technical achievements, further inspiring thousands of researchers to bring the dreams to life, and to dream new dreams as well. The second part of the book describes the myriad adverse side effects and unanticipated challenges that arose as those dreams were pursued and achieved. Examples include rampant misinformation on social media, ransomware, autonomous weapons, and the premature use of AI before it is reliable and safe.The book closes with a positive call to action, outlining ways to address the challenges through ethical career choices, careful analysis, thoughtful design, research, citizen engagement, legislation/regulation, and careful consideration of how bad actors may use technology. Readers of Digital Dreams Have Become Nightmares should become more knowledgeable, wiser, and also cautiously optimistic, determined to affect positive changes through their design, creation, and use of technology.“Are you feeling happy about the role of information technology in the world today? You should read this book for a dose of reality. Are you in despair about it? This book is the prescription for that condition, too! Nobody else could cover the landscape as Ron Baecker does.” - Clayton Lewis, Emeritus Professor, University of Colorado Boulder“This book is a captivating review of important computing developments. Many things talked about as new today have been around for a long time. Much can be learned from the past. The book also teaches a careful and consistent method that enables the reader to do this kind of work as the need arises. The book suggests the need will arise.” - John Leslie King, Emeritus Professor, University of Michigan",,,,,,,book,,,56,,,,,,2,
,CSCW '23 Companion: Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing,2023,9798400701290,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Minneapolis, MN, USA",,proceedings,,,,,,,,,,
,Editor's note,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3625384.3625385,10.1145/3625384.3625385,"In this issue of the Reproducibility Retro from the EIG on Reproducibility and Replicability, we're interested in exploring the intersection of trust and reproducibility. We're in part inspired by the ACM's recent TechBrief (our first 'to be read' item below), which starts with a strong problem statement: ",,,5,,,,article,1,September 2023,1,2,Reprod. Retro!,sep,,,,
,aiDM '23: Proceedings of the Sixth International Workshop on Exploiting Artificial Intelligence Techniques for Data Management,2023,9798400701931,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Seattle, WA, USA",,proceedings,,,,,,,,,,
,Report on the 1st Workshop on Generative Information Retrieval (Gen-IR 2023) at SIGIR 2023,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3642979.3642995,10.1145/3642979.3642995,"The first edition of the workshop on Generative Information Retrieval (Gen-IR 2023) took place in July 2023 in a hybrid fashion, co-located with the ACM SIGIR Conference 2023 in Taipei (SIGIR 2023). The aim was to bring information retrieval researchers together around the topic of generative AI that gathered attention in 2022 and 2023 with large language models and diffusion models. Given the novelty of the topic, the workshop was focused around multi-sided discussions, namely panels and poster sessions of the accepted proceedings papers. Two main research outcomes are the proceedings of the workshop1 and the potential research directions discussed in this report.Date: 27 July 2023.Website: https://coda.io/@sigir/gen-ir.",,,23,,,,article,13,December 2023,57,2,SIGIR Forum,jan,0163-5840,,,
,ISPD '24: Proceedings of the 2024 International Symposium on Physical Design,2024,9798400704178,Association for Computing Machinery,"New York, NY, USA",,,"On behalf of the organizing committee, we are delighted to welcome you to the 33rd ACM International Symposium on Physical Design (ISPD). After the COVID-19 pandemic, we return to a fully in-person ISPD, held in Taipei, Taiwan for the first time. We continue the great tradition established by its thirtytwo predecessors, providing a premier forum to exchange ideas, highlight key technology challenges, present leading-edge theoretical and experimental contributions, and identify future research directions in this field. We extend the good practice, adopted during the pandemic, of having a YouTube channel to view the talks during the symposium and afterwards, improving access to the presentations.Across three days, ISPD 2024 has 3 keynotes, 18 accepted papers, 16 invited talks; one panel on Wednesday with 6 panelists; and 4 speakers with longer talks in Professor Martin D. F. Wong's commemorative session, and finally the ISPD 2024 contest results. ISPD 2024 is co-located with the 25th Workshop on Synthesis and System Integration of Mixed Information technologies (SASIMI). This year, we received a total of 62 abstracts and we received 48 full manuscripts, from which 18 were selected - a 37.5% acceptance rate. The regular papers in the ISPD 2024 program were selected, after a rigorous month-long double-blind review process and virtual meetings, by the Technical Program Committee with 20 outstanding international professionals from both academia and industry. These papers exhibit the latest advancements in a variety of topics in physical design, including partitioning and clustering; mixed cell-height placement and legalization; macro placement; global placement; standard cell design automation; timing and power optimization; reliability (IR drop); quantum circuits and quantum computing systems; and mask optimization in lithography. A number of these papers utilize advanced mathematical programming, satisfiability problem solving, GPU acceleration, and machine learning techniques.",,,,,"Taipei, Taiwan",,proceedings,,,,,,,,,,
"Leiser, Florian and Eckhardt, Sven and Leuthe, Valentin and Knaeble, Merlin and M\",HILL: A Hallucination Identifier for Large Language Models,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642428,10.1145/3613904.3642428,"Large language models (LLMs) are prone to hallucinations, i.e., nonsensical, unfaithful, and undesirable text. Users tend to overrely on LLMs and corresponding hallucinations which can lead to misinterpretations and errors. To tackle the problem of overreliance, we propose HILL, the ",Proceedings of the CHI Conference on Human Factors in Computing Systems,,13,"Artifact Development, Artificial Hallucinations, ChatGPT, Large Language Models, Wizard of Oz","Honolulu, HI, USA",CHI '24,inproceedings,482,,,,,,,,,
,ACM TURC '23: Proceedings of the ACM Turing Award Celebration Conference - China 2023,2023,9798400702334,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Wuhan, China",,proceedings,,,,,,,,,,
"Brachman, Michelle and El-Ashry, Amina and Dugan, Casey and Geyer, Werner",How Knowledge Workers Use and Want to Use LLMs in an Enterprise Context,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3650841,10.1145/3613905.3650841,"Large Language Models (LLMs) have introduced a paradigm shift in interaction with AI technology, enabling knowledge workers to complete tasks by specifying their desired outcome in natural language. LLMs have the potential to increase productivity and reduce tedious tasks in an unprecedented way. A systematic study of LLM adoption for work can provide insight into how LLMs can best support these workers. To explore knowledge workers’ current and desired usage of LLMs, we ran a survey (n=216). Workers described tasks they already used LLMs for, like generating code or improving text, but imagined a future with LLMs integrated into their workflows and data. We discuss implications for adoption and design of generative AI technologies for knowledge work.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,8,"adoption, knowledge workers, large language models, survey","
",CHI EA '24,inproceedings,189,,,,,,,,,
,AICCONF '24: Proceedings of the Cognitive Models and Artificial Intelligence Conference,2024,9798400716928,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"undefinedstanbul, Turkiye",,proceedings,,,,,,,,,,
"Xu, Dongsheng and Zhao, Wenye and Cai, Yi and Huang, Qingbao",Zero-TextCap: Zero-shot Framework for Text-based Image Captioning,2023,9798400701085,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3581783.3612571,10.1145/3581783.3612571,"Text-based image captioning is a vital but under-explored task, which aims to describe images by captions containing scene text automatically. Recent studies have made encouraging progress, but they are still suffering from two issues. Firstly, current models cannot capture and generate scene text in non-Latin script languages, which severely limits the objectivity and the information completeness of generated captions. Secondly, current models tend to describe images with monotonous and templated style, which greatly limits the diversity of the generated captions. Although the above-mentioned issues can be alleviated through carefully designed annotations, this process is undoubtedly laborious and time-consuming. To address the above issues, we propose a Zero-shot Framework for Text-based Image Captioning (Zero-TextCap). Concretely, to generate candidate sentences starting from the prompt 'Image of' and iteratively refine them to improve the quality and diversity of captions, we introduce a Hybrid-sampling masked language model (H-MLM). To read multi-lingual scene text and model the relationships between them, we introduce a robust OCR system. To ensure that the captions generated by H-MLM contain scene text and are highly relevant to the image, we propose a CLIP-based generation guidance module to insert OCR tokens and filter candidate sentences. Our Zero-TextCap is capable of generalizing captions containing multi-lingual scene text and boosting the diversity of captions. Sufficient experiments demonstrate the effectiveness of our proposed Zero-TextCap. Our codes are available at https://github.com/Gemhuang79/Zero_TextCap.",Proceedings of the 31st ACM International Conference on Multimedia,4949–4957,9,"zero-shot, text-based image captioning, language bias, diversity","Ottawa ON, Canada",MM '23,inproceedings,,,,,,,,,,
,ICETM '23: Proceedings of the 2023 6th International Conference on Educational Technology Management,2023,9798400716676,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Guangzhou, China",,proceedings,,,,,,,,,,
"Casas, Llogari and Mitchell, Kenny",Intermediated Reality with an AI 3D Printed Character,2023,9798400701580,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3588430.3597251,10.1145/3588430.3597251,"We introduce live character conversational interactions in Intermediated Reality to bring real-world objects to life in Augmented Reality (AR) and Artificial Intelligence (AI). The AI recognizes live speech and generates short character responses, syncing the character’s facial expressions with speech audio. The Intermediated Reality AR warping technique allows for a high degree of realism in the animated facial expressions and movements reusing live video optical appearance direct from the device’s embedded camera. The proposed applications of Intermediated Reality with AI are exemplified through the captivating fusion of these technologies in toy interactive storytelling broadcasts and social telepresence scenarios. This innovative combination allows individuals to engage with AI characters in a natural and intuitive manner, creating new opportunities for social engagement and entertainment.",ACM SIGGRAPH 2023 Real-Time Live!,,2,"Intermediated Reality, Augmented Reality, Artificial Intelligence","Los Angeles, CA, USA",SIGGRAPH '23,inproceedings,5,,,,,,,,,
,IUI '24: Proceedings of the 29th International Conference on Intelligent User Interfaces,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Greenville, SC, USA",,proceedings,,,,,,,,,,
,IHC '23: Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems,2023,9798400717154,Association for Computing Machinery,"New York, NY, USA",,,,,,,,,,proceedings,,,,,,,,,,
"Rayzhekov, Antoni and Murer, Martin",Between This and That is It: Embodied Semantic Space at the Edge,2024,9798400704024,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3623509.3635326,10.1145/3623509.3635326,"This paper describes the interactive artwork “Between This and That is It”: An AI-augmented typewriter that blends several decades of computerized optimization of text production. The artwork employs an offline processing machine learning-based language model embedded in a typical office typewriter from the 1980s. Deliberately diverting from the pervasive conversational user interface, the interaction style is based on a well-defined minimalist pattern of complementing two user-supplied words with a third word that – in the model – lies in the middle of the other two. This constraint interaction invites to explore the limits of the semantic space of language models and poses questions related to the topology of meaning, with respect to truthfulness, biases, and cliches, by creating a semi-intelligent poetic co-performance involving the audience. This project seeks to foster a discussion on the creative collaboration between humans and AI within the constraints of machine learning technologies embedded into objects from the near past. The experience and the perception of the interaction are shaped by a hybrid space shared between the audience members and the AI, the mechanical limitations of the typewriter, the embedded mini-computer’s computational capacity, and the language model itself.","Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction",,4,"AI, AI edge computing, Interactive Art, Language models, graspable AI","Cork, Ireland",TEI '24,inproceedings,101,,,,,,,,,
"Xiang, Qiao and Lin, Yuling and Fang, Mingjun and Huang, Bang and Huang, Siyong and Wen, Ridi and Le, Franck and Kong, Linghe and Shu, Jiwu",Toward Reproducing Network Research Results Using Large Language Models,2023,9798400704154,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626111.3628189,10.1145/3626111.3628189,"Reproducing research results is important for the networking community. The current best practice typically resorts to: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; or (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private ones are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). We first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report our observations and lessons and discuss future open research questions of this proposal.",Proceedings of the 22nd ACM Workshop on Hot Topics in Networks,56–62,7,"Networking systems, Large language models","Cambridge, MA, USA",HotNets '23,inproceedings,,,,,,,,,,
,CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Honolulu, HI, USA",,proceedings,,,,,,,,,,
"Glazko, Kate and Mohammed, Yusuf and Kosa, Ben and Potluri, Venkatesh and Mankoff, Jennifer",Identifying and Improving Disability Bias in GPT-Based Resume Screening,2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630106.3658933,10.1145/3630106.3658933,"As Generative AI rises in adoption, its use has expanded to include domains such as hiring and recruiting. However, without examining the potential of bias, this may negatively impact marginalized populations, including people with disabilities. To address this important concern, we present a resume audit study, in which we ask ChatGPT (specifically, GPT-4) to rank a resume against the same resume enhanced with an additional leadership award, scholarship, panel presentation, and membership that are disability-related. We find that GPT-4 exhibits prejudice towards these enhanced CVs. Further, we show that this prejudice can be quantifiably reduced by training a custom GPTs on principles of DEI and disability justice. Our study also includes a unique qualitative analysis of the types of direct and indirect ableism GPT-4 uses to justify its biased decisions and suggest directions for additional bias mitigation work. Additionally, since these justifications are presumably drawn from training data containing real-world biased statements made by humans, our analysis suggests additional avenues for understanding and addressing human bias.","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",687–700,14,"Ableism, Bias, GPT, Resume Audit","Rio de Janeiro, Brazil",FAccT '24,inproceedings,,,,,,,,,,
,AVI '24: Proceedings of the 2024 International Conference on Advanced Visual Interfaces,2024,9798400717642,Association for Computing Machinery,"New York, NY, USA",,,"AVI 2024 is the 17th edition of the International Conference on Advanced Visual Interfaces, held in Arenzano, Genoa (IT), in cooperation with ACM, ACM SIGCHI, ACM SIGMM, and ACM SIGWEB.Every two years since 1992, AVI has gathered a vast international community of experts with a wide range of backgrounds. Throughout three decades, AVI has gained and holds a prestigious position among International HCI conferences, boasting a dedicated nucleus of returning participants, but also providing a venue for young researchers to show their achievements and establish contacts with senior community members.AVI 2024 presents a broad and sound scientific program covering traditional AVI topics on information and data visualization, interaction with multimodal user interfaces, augmented and virtual reality, while also addressing emerging topics including the application of generative artificial intelligence in HCI design and evaluation.The program features the presentation of 21 long research papers and 28 short papers selected through a rigorous double-blind reviewing process and organized into sessions on 13 main topics. Furthermore, it includes the presentation of 48 poster papers, 9 demo papers, and 11 doctoral consortium papers, selected through a single-blind reviewing process. Finally, the rich and vibrant program includes 3 keynote talks, 3 tutorials, and 10 workshops addressing some of the most exciting issues in HCI.Submissions to AVI 2024 came from 34 different countries distributed in descending order in Europe, Asia, North America, South America, and Africa.",,,,,"Arenzano, Genoa, Italy",,proceedings,,,,,,,,,,
,ICCMB '24: Proceedings of the 2024 7th International Conference on Computers in Management and Business,2024,9798400716652,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Singapore, Singapore",,proceedings,,,,,,,,,,
,AfriCHI '23: Proceedings of the 4th African Human Computer Interaction Conference,2023,9798400708879,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"East London, South Africa",,proceedings,,,,,,,,,,
"Denning, Peter J.",Can Generative AI Bots Be Trusted?,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3592981,10.1145/3592981,It will be a long road to learning how to use generative AI wisely.,,24–27,4,,,,article,,June 2023,66,6,Commun. ACM,may,0001-0782,,,
,HILDA  24: Proceedings of the 2024 Workshop on Human-In-the-Loop Data Analytics,2024,9798400706936,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Santiago, AA, Chile",,proceedings,,,,,,,,,,
"Muller, Michael and Kantosalo, Anna and Maher, Mary Lou and Martin, Charles Patrick and Walsh, Greg",GenAICHI 2024: Generative AI and HCI at CHI 2024,2024,9798400703317,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613905.3636294,10.1145/3613905.3636294,"This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following successful workshops in 2022 and 2023, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.",Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems,,7,"Bias, Design, Generative AI, Uncertainty.","
",CHI EA '24,inproceedings,470,,,,,,,,,
,CCEAI '24: Proceedings of the 2024 8th International Conference on Control Engineering and Artificial Intelligence,2024,9798400707971,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Shanghai, China",,proceedings,,,,,,,,,,
"Grigis, Paolo and De Angeli, Antonella","Playwriting with Large Language Models: Perceived Features, Interaction Strategies and Outcomes",2024,9798400717642,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3656650.3656688,10.1145/3656650.3656688,"Large Language Models (LLMs) are sparking debates about creativity, intellectual property, and artistic integrity. This paper focuses on creativity, defined as consensual agreement among domain experts. It presents an inductive analysis of seven semi-structured interviews with professional playwrights who engaged in a longitudinal project with the aim of writing a theatre script using commercial systems. Overall, participants regarded LLMs as unsuitable for playwrighting. However, they enjoyed the experience and identified utility for editorial tasks and brainstorming. A significant obstacle was associated with the politics embedded in LLMs. Not only did these systems avoid a language that could offend sensibilities, but they also refused to engage in taboos and conflicts, which are the core of dramaturgy. Other system features (speed, exploitation, and unpredictability) were sometimes considered conducive and sometimes detrimental to creativity. Participants experienced difficulties and tried to build common ground by trial and error. Often, this strategy evolved into role play: the playwright instructed the LLM to enact characters. The interaction provided hints of inspiration and fostered suspension of disbelief and ontological reflection. However, it often led to technology rejection. Comparing and contrasting our insights with related work, we conclude by opening new directions for research at the boundaries of HCI and AI.",Proceedings of the 2024 International Conference on Advanced Visual Interfaces,,9,"Creative AI, Creativity, Roleplay, Suspension of Disbelief, Theatre, Unpredictability","Arenzano, Genoa, Italy",AVI '24,inproceedings,38,,,,,,,,,
"Weber, Christoph Johannes and Burgkart, Sebastian and Rothe, Sylvia",wr-AI-ter: Enhancing Ownership Perception in AI-Driven Script Writing,2024,9798400705038,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3639701.3656325,10.1145/3639701.3656325,"The integration of artificial intelligence (AI) into creative domains is increasing, presenting both challenges and opportunities. In screenwriting, personal artistic expression is a fundamental aspect of the creator’s identity and work. The current use of AI in such creative processes can sometimes overshadow the creator’s vision and lead to a reduced sense of ownership over the final product. We introduce wr-AI-ter, an interactive application consisting of four basic stages: Ideation, Structure, Refinement, and Export. While some related work focuses on experts The application is intended to aid users with varying levels of screenwriting proficiency in generating screenplays using artificial intelligence, while preserving their sense of authorship. We conducted a user study with 23 participants, who had different expertise (screenwriting, documentary filmmaking, and VFX artistry). The results indicate that AI has the potential to accelerate the screenwriting process and improve the quality of scripts without compromising the sense of ownership.",Proceedings of the 2024 ACM International Conference on Interactive Media Experiences,145–156,12,"computational creativity, human-computer interaction, natural language evaluation, natural language generation, ownership, screenplay","Stockholm, Sweden",IMX '24,inproceedings,,,,,,,,,,
"Murali, Prasanth and Steenstra, Ian and Yun, Hye Sun and Shamekhi, Ameneh and Bickmore, Timothy",Improving Multiparty Interactions with a Robot Using Large Language Models,2023,9781450394222,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544549.3585602,10.1145/3544549.3585602,"Speaker diarization is a key component of systems that support multiparty interactions of co-located users, such as meeting facilitation robots. The goal is to identify who spoke what, often to provide feedback, moderate participation, and personalize responses by the robot. Current systems use a combination of acoustic (e.g. pitch differences) and visual features (e.g. gaze) to perform diarization, but involve the use of additional sensors or require overhead signal processing efforts. Alternatively, automatic speech recognition (ASR) is a necessary step in the diarization pipeline, and utilizing the transcribed text to directly identify speaker labels in the conversation can eliminate such challenges. With that motivation, we leverage large language models (LLMs) to identify speaker labels from transcribed text and observe an exact match of 77% and a word level accuracy of 90%. We discuss our findings and the potential use of LLMs as a diarization tool for future systems.",Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,,8,"ChatGPT, Diarization, Large Language Models (LLMs), Meeting Facilitation, Social Robots","Hamburg, Germany",CHI EA '23,inproceedings,175,,,,,,,,,
"Phan, Thomas and Guy, Richard and Bagrodia, Rajive","A scalable, distributed middleware service architecture to support mobile internet applications",2001,1581134231,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/381472.381563,10.1145/381472.381563,"Middleware layers placed between user clients and application
servers have been used to perform a variety of functions. In
previous work we have used middleware to perform a new capability,
application session handoff, using a single Middleware Server to
provide all functionality. However, to improve the scalability of
our architecture, we have designed an efficient distributed
Middleware Service layer that properly maintains application
session handoff semantics while being able to service a large
number of clients. We show that this service layer improves the
scalability of general client-to-application server interaction as
well as the specific case of application session handoff. We detail
protocols involved in performing handoff and analyse an
implementation of the architecture that supports the use of a real
medical teaching tool. From experimental results it can be seen
that our Middleware Service effectively provides scalability as a
response to increased workload.",Proceedings of the First Workshop on Wireless Mobile Internet,27–33,7,,"Rome, Italy",WMI '01,inproceedings,,,,,,,,,,
"Qian, Crystal and Wexler, James","Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration",2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645198,10.1145/3640543.3645198,"Although recent developments in generative AI have greatly enhanced the capabilities of conversational agents such as Google’s Bard or OpenAI’s ChatGPT, it’s unclear whether the usage of these agents aids users across various contexts. To better understand how access to conversational AI affects productivity and trust, we conducted a mixed-methods, task-based user study, observing 76 software engineers (N=76) as they completed a programming exam with and without access to Bard. Effects on performance, efficiency, satisfaction, and trust vary depending on user expertise, question type (open-ended ",Proceedings of the 29th International Conference on Intelligent User Interfaces,370–384,15,,"Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
,"ICSLT '23: Proceedings of the 2023 9th International Conference on e-Society, e-Learning and e-Technologies",2023,9798400700415,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Portsmouth, United Kingdom",,proceedings,,,,,,,,,,
,ICIMMI '23: Proceedings of the 5th International Conference on Information Management &amp; Machine Intelligence,2023,9798400709418,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Jaipur, India",,proceedings,,,,,,,,,,
"Prosser, Ellie and Edwards, Matthew",Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention,2024,9798400716515,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3655693.3655694,10.1145/3655693.3655694,"Powerful generative Large Language Models (LLMs) are becoming popular tools amongst the general public as question-answering systems, and are being utilised by vulnerable groups such as children. With children increasingly interacting with these tools, it is imperative for researchers to scrutinise the safety of LLMs, especially for applications that could lead to serious outcomes, such as online child safety queries. In this paper, the efficacy of LLMs for online grooming prevention is explored both for identifying and avoiding grooming through advice generation, and the impact of prompt design on model performance is investigated by varying the provided context and prompt specificity. In results reflecting over 6,000 LLM interactions, we find that no models were clearly appropriate for online grooming prevention, with an observed lack of consistency in behaviours, and potential for harmful answer generation, especially from open-source models. We outline where and how models fall short, providing suggestions for improvement, and identify prompt designs that heavily altered model performance in troubling ways, with findings that can be used to inform best practice usage guides.",Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference,1–10,10,"advice generation, large language models, online child safety, online grooming detection, prompt design, prompt engineering","Xanthi, Greece",EICC '24,inproceedings,,,,,,,,,,
,ICPP Workshops '23: Proceedings of the 52nd International Conference on Parallel Processing Workshops,2023,9798400708428,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Salt Lake City, UT, USA",,proceedings,,,,,,,,,,
,ICAAI '23: Proceedings of the 2023 7th International Conference on Advances in Artificial Intelligence,2023,9798400708985,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Istanbul, Turkiye",,proceedings,,,,,,,,,,
,SACMAT 2024: Proceedings of the 29th ACM Symposium on Access Control Models and Technologies,2024,9798400704918,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to welcome you to the 29th ACM Symposium on Access Control Models and Technologies (SACMAT 2024). This year's symposium continues its tradition of being the premier venue for presenting research results and experience reports on cutting edge advances on access control, including models, systems, applications, and theory, while also embracing an expanded focus on the general area of computer and information security and privacy. The overarching goal of the symposium is to share novel access control and computer security solutions that fulfill the needs of emerging applications and environments, and also to identify new directions for future research and development. ACM SACMAT provides researchers and also practitioners with a unique opportunity to share their perspectives with others interested in the various aspects of access control and computer security.",,,,,"San Antonio, TX, USA",,proceedings,,,,,,,,,,
,HT '23: Proceedings of the 34th ACM Conference on Hypertext and Social Media,2023,9798400702327,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rome, Italy",,proceedings,,,,,,,,,,
,CSET '23: Proceedings of the 16th Cyber Security Experimentation and Test Workshop,2023,9798400707889,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Marina del Rey, CA, USA",,proceedings,,,,,,,,,,
,ISCAI '23: Proceedings of the 2023 2nd International Symposium on Computing and Artificial Intelligence,2023,9798400708954,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Shanghai, China",,proceedings,,,,,,,,,,
"Lian, Jianxun and Lei, Yuxuan and Huang, Xu and Yao, Jing and Xu, Wei and Xie, Xing",RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems,2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3651242,10.1145/3589335.3651242,"This paper introduces RecAI, a practical toolkit designed to augment or even revolutionize recommender systems with the advanced capabilities of Large Language Models (LLMs). RecAI provides a suite of tools, including Recommender AI Agent, Recommendation-oriented Language Models, Knowledge Plugin, RecExplainer, and Evaluator, to facilitate the integration of LLMs into recommender systems from multifaceted perspectives. The new generation of recommender systems, empowered by LLMs, are expected to be more versatile, explainable, conversational, and controllable, paving the way for more intelligent and user-centric recommendation experiences. We hope the open-source of RecAI can help accelerate evolution of new advanced recommender systems. The source code of RecAI is available at https://github.com/microsoft/RecAI.",Companion Proceedings of the ACM on Web Conference 2024,1031–1034,4,"large language models, recommender systems","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
,IH&amp;MMSec '24: Proceedings of the 2024 ACM Workshop on Information Hiding and Multimedia Security,2024,9798400706370,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the 12th ACM Information Hiding and Multimedia Security Workshop - IH&amp;MMSec'24 in Baiona, Galicia, Spain, organized by the Research Group in Signal Processing in Communications (GPSC) at the University of Vigo. GPSC is one of the pioneering research groups in Information Hiding and Multimedia Security with over 25 years of active engagement in this domain. During this time, our field has seen remarkable growth, evolution, and reinvention, yet it continues to preserve the same effervescence of its inception. This vibrancy is reflected in the diverse range of topics covered in this year's program.In response to our call for papers, we received in total 69 submissions. The top five countries with the highest number of submissions (first author) were Germany, China, France, Italy, and the United States. Each submission underwent rigorous evaluation, with a minimum of three independent reviews provided by members of the Program Committee, supplemented by external reviewers as needed. Based on these timely and high-quality reviews, the Technical Program Chairs selected the 33 most outstanding submissions. The acceptance rate of 47.8% (33/69) reflects our commitment to uphold IH&amp;MMSec as a premier scientific venue in the field of Information Hiding and Multimedia Security. The accepted papers cover the fields of forensics, steganography, steganalysis, watermarking, biometrics, anonymity, security and privacy.",,,,,"Baiona, Spain",,proceedings,,,,,,,,,,
,ICCDE '24: Proceedings of the 2024 10th International Conference on Computing and Data Engineering,2024,9798400709319,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bangkok, Thailand",,proceedings,,,,,,,,,,
,MuC '23: Proceedings of Mensch und Computer 2023,2023,9798400707711,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rapperswil, Switzerland",,proceedings,,,,,,,,,,
,ACM SE '23: Proceedings of the 2023 ACM Southeast Conference,2023,9781450399210,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Virtual Event, USA",,proceedings,,,,,,,,,,
"Hope, Tom and Downey, Doug and Weld, Daniel S. and Etzioni, Oren and Horvitz, Eric",A Computational Inflection for Scientific Discovery,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3576896,10.1145/3576896,Enabling researchers to leverage systems to overcome the limits of human cognitive capacity.,,62–73,12,,,,article,,August 2023,66,8,Commun. ACM,jul,0001-0782,,,
,Cleenex: Support for User Involvement during an Iterative Data Cleaning Process,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3648476,10.1145/3648476,"The existence of large amounts of data increases the probability of occurring data quality problems. A data cleaning process that corrects these problems is usually an iterative process, because it may need to be re-executed and refined to produce high-quality data. Moreover, due to the specificity of some data quality problems and the limitation of data cleaning programs to cover all problems, often a user has to be involved during the program executions by manually repairing data. However, there is no data cleaning framework that appropriately supports this involvement in such an iterative process, a form of human-in-the-loop, to clean structured data. Moreover, data preparation tools that somehow involve the user in data cleaning processes have not been evaluated with real users to assess their effort.Therefore, we propose Cleenex, a data cleaning framework with support for user involvement during an iterative data cleaning process, and conduct two data cleaning experimental evaluations: an assessment of the Cleenex components that support the user when manually repairing data with a simulated user; and a comparison, in terms of user involvement, of data preparation tools with real users.Results show that Cleenex components reduce the user effort when manually cleaning data during a data cleaning process, for example, the number of tuples visualized is reduced in 99%. Moreover, when performing data cleaning tasks with Cleenex, real users need less time/effort (e.g., half the clicks) and, based on questionnaires, prefer it to the other tools used for comparison, OpenRefine and Pentaho Data Integration.",,,26,"Data quality, data curation, user involvement, human-in-the-loop",,,article,6,March 2024,16,1,J. Data and Information Quality,mar,1936-1955,,,
,"The Handbook on Socially Interactive Agents: 20 years of Research on Embodied Conversational Agents, Intelligent Virtual Agents, and Social Robotics Volume 2: Interactivity, Platforms, Application",2022,9781450398961,Association for Computing Machinery,"New York, NY, USA",,,"The Handbook on Socially Interactive Agents provides a comprehensive overview of the research fields of Embodied Conversational Agents, Intelligent Virtual Agents, and Social Robotics. Socially Interactive Agents (SIAs), whether virtually or physically embodied, are autonomous agents that are able to perceive an environment including people or other agents, reason, and decide how to interact, and express attitudes such as emotions, engagement, or empathy. They are capable of interacting with people and each other in a socially intelligent manner using multimodal communicative behaviors with the goal to support humans in various domains.Written by international experts in their respective fields, the book summarizes research in the many important research communities pertinent for SIAs, while discussing current challenges and future directions. The handbook provides easy access to modeling and studying SIAs for researchers and students and aims at further bridging the gap between the research communities involved.In two volumes, the book clearly structures the vast body of research. The first volume starts by introducing what is involved in SIAs research, in particular research methodologies and ethical implications of developing SIAs. It further examines research on appearance and behavior, focusing on multimodality. Finally, social cognition for SIAs is investigated by different theoretical models and phenomena such as theory of mind or pro-sociality. The second volume starts with perspectives on interaction, examined from different angles such as interaction in social space, group interaction, or long-term interaction. It also includes an extensive overview summarizing research and systems of human-agent platforms and of some of the major application areas of SIAs such as education, aging support, autism or games.",,,,,,,book,,,48,,,,,,1,"Lugrin, Birgit and Pelachaud, Catherine and Traum, David"
,ASSETS '22: Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility,2022,9781450392587,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Athens, Greece",,proceedings,,,,,,,,,,
"Nishal, Sachita and Sinchai, Jasmine and Diakopoulos, Nicholas",Understanding Practices around Computational News Discovery Tools in the Domain of Science Journalism,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3637419,10.1145/3637419,"Science and technology journalists today face challenges in finding newsworthy leads due to increased workloads, reduced resources, and expanding scientific publishing ecosystems. Given this context, we explore computational methods to aid these journalists' news discovery in terms of their agency and time-efficiency. We prototyped three computational information subsidies into an interactive tool that we used as a probe to better understand how such a tool may offer utility or more broadly shape the practices of professional science journalists. Our findings highlight central considerations around science journalists' user agency, contexts of use, and professional responsibility that such tools can influence and could account for in design. Based on this, we suggest design opportunities for enhancing and extending user agency over the longer-term; incorporating contextual, personal and collaborative notions of newsworthiness; and leveraging flexible interfaces and generative models. Overall, our findings contribute a richer view of the sociotechnical system around computational news discovery tools, and suggest ways to improve such tools to better support the practices of science journalists.",,,36,"computational news discovery, human-ai interaction, large language models, newsworthiness, science communication",,,article,142,April 2024,8,CSCW1,Proc. ACM Hum.-Comput. Interact.,apr,,,,
,PEARC '23: Practice and Experience in Advanced Research Computing,2023,9781450399852,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Portland, OR, USA",,proceedings,,,,,,,,,,
,NetConfEval: Can LLMs Facilitate Network Configuration?,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3656296,10.1145/3656296,"This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices &amp; development of routing algorithms and minimizing errors. We design a set of benchmarks (NetConfEval) to examine the effectiveness of different models in facilitating and automating network configuration. More specifically, we focus on the scenarios where LLMs translate high-level policies, requirements, and descriptions (i.e., specified in natural language) into low-level network configurations &amp; Python code. NetConfEval considers four tasks that could potentially facilitate network configuration, such as (i) generating high-level requirements into a formal specification format, (ii) generating API/function calls from high-level requirements, (iii) developing routing algorithms based on high-level descriptions, and (iv) generating low-level configuration for existing and new protocols based on input documentation. Learning from the results of our study, we propose a set of principles to design LLM-based systems to configure networks. Finally, we present two GPT-4-based prototypes to (i) automatically configure P4-enabled devices from a set of high-level requirements and (ii) integrate LLMs into existing network synthesizers.",,,25,"benchmark, code generation, function calling, large language models (llms), network configuration, network synthesizer, p4, rag, routing algorithms",,,article,7,June 2024,2,CoNEXT2,Proc. ACM Netw.,jun,,,,
,Promote Caution about Using AI Prematurely,2024,9798400717703,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640479.3640496,,"This book offers a compelling discussion of the digital dreams that have come true, their often unintended side effects (nightmares), and what must be done to counteract the nightmares. It is intended as an impetus to further conversation not only in homes and workplaces, but in academic courses and even legislative debates. Equally importantly, the book is a presentation of what digital technology professionals need to know about these topics and the actions they should undertake individually and in support of other citizens, societal initiatives, and government. The author begins by introducing the amazing progress made in digital technologies over the past 80 years. Pioneering engineers dreamed of potential uses of technology through their writing and technical achievements, further inspiring thousands of researchers to bring the dreams to life, and to dream new dreams as well. The second part of the book describes the myriad adverse side effects and unanticipated challenges that arose as those dreams were pursued and achieved. Examples include rampant misinformation on social media, ransomware, autonomous weapons, and the premature use of AI before it is reliable and safe.The book closes with a positive call to action, outlining ways to address the challenges through ethical career choices, careful analysis, thoughtful design, research, citizen engagement, legislation/regulation, and careful consideration of how bad actors may use technology. Readers of Digital Dreams Have Become Nightmares should become more knowledgeable, wiser, and also cautiously optimistic, determined to affect positive changes through their design, creation, and use of technology.“Are you feeling happy about the role of information technology in the world today? You should read this book for a dose of reality. Are you in despair about it? This book is the prescription for that condition, too! Nobody else could cover the landscape as Ron Baecker does.” - Clayton Lewis, Emeritus Professor, University of Colorado Boulder“This book is a captivating review of important computing developments. Many things talked about as new today have been around for a long time. Much can be learned from the past. The book also teaches a careful and consistent method that enables the reader to do this kind of work as the need arises. The book suggests the need will arise.” - John Leslie King, Emeritus Professor, University of Michigan",Digital Dreams Have Become Nightmares: What We Must Do,,,,,,inbook,,,,,,,,,,
,ICBDT '23: Proceedings of the 2023 6th International Conference on Big Data Technologies,2023,9798400707667,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Qingdao, China",,proceedings,,,,,,,,,,
"Evirgen, Noyan and Wang, Ruolin and Chen, Xiang 'Anthony",From Text to Pixels: Enhancing User Understanding through Text-to-Image Model Explanations,2024,9798400705083,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640543.3645173,10.1145/3640543.3645173,"Recent progress in Text-to-Image (T2I) models promises transformative applications in art, design, education, medicine, and entertainment. These models, exemplified by Dall-e, Imagen, and Stable Diffusion, have the potential to revolutionize various industries. However, a primary concern is their operation as a ‘black-box’ for many users. Without understanding the underlying mechanics, users are unable to harness the full potential of these models. This study focuses on bridging this gap by developing and evaluating explanation techniques for T2I models, targeting inexperienced end users. While prior works have delved into Explainable AI (XAI) methods for classification or regression tasks, T2I generation poses distinct challenges. Through formative studies with experts, we identified unique explanation goals and subsequently designed tailored explanation strategies. We then empirically evaluated these methods with a cohort of 473 participants from Amazon Mechanical Turk (AMT) across three tasks. Our results highlight users’ ability to learn new keywords through explanations, a preference for example-based explanations, and challenges in comprehending explanations that significantly shift the image’s theme. Moreover, findings suggest users benefit from a limited set of concurrent explanations. Our main contributions include a curated dataset for evaluating T2I explainability techniques, insights from a comprehensive AMT user study, and observations critical for future T2I model explainability research.",Proceedings of the 29th International Conference on Intelligent User Interfaces,74–87,14,"Explainability Methods, Text-to-Image, User-Study, XAI","Greenville, SC, USA",IUI '24,inproceedings,,,,,,,,,,
"Nguyen, Quang-Tan and Nguyen, Xuan-Quang and Ho, Trong-Bao and Truong, Duc-Thang and Le, Minh-Hoang",Vi-ATISO: An Effective Video Search Engine at AI Challenge HCMC 2023,2023,9798400708916,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3628797.3628997,10.1145/3628797.3628997,"In this paper, we present the first version of Vi-ATISO, a fast and efficient video search engine on medium-scale datasets. The tool provides several search functions based on text-to-image retrieval, text-to-video retrieval, optical character recognition, and object detection algorithms. With diverse algorithms provided, our system can handle a larger amount of data from the AI Challenge HCMC 2023 and achieve good results. In addition, we feel confident that this search engine can be applied in practice because we also consider user experience during the development process.",Proceedings of the 12th International Symposium on Information and Communication Technology,960–965,6,"Interactive retrieval system, Lifelog, Video event retrieval","Ho Chi Minh, Vietnam",SOICT '23,inproceedings,,,,,,,,,,
,GoodIT '23: Proceedings of the 2023 ACM Conference on Information Technology for Social Good,2023,9798400701160,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
,C&amp;C '23: Proceedings of the 15th Conference on Creativity and Cognition,2023,9798400701801,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Virtual Event, USA",,proceedings,,,,,,,,,,
,"CNCIT '23: Proceedings of the 2023 2nd International Conference on Networks, Communications and Information Technology",2023,9798400700620,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Qinghai, China",,proceedings,,,,,,,,,,
"Tsiakas, Konstantinos and Murray-Rust, Dave",Unpacking Human-AI interactions: From interaction primitives to a design space,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3664522,10.1145/3664522,"This paper aims to develop a semi-formal representation for Human-AI (HAI) interactions, by building a set of interaction primitives which can specify the information exchanges between users and AI systems during their interaction. We show how these primitives can be combined into a set of interaction patterns which can capture common interactions between humans and AI/ML models. The motivation behind this is twofold: firstly, to provide a compact generalisation of existing practices for the design and implementation of HAI interactions; and secondly, to support the creation of new interactions by extending the design space of HAI interactions. Taking into consideration frameworks, guidelines and taxonomies related to human-centered design and implementation of AI systems, we define a vocabulary for describing information exchanges based on the model’s characteristics and interactional capabilities. Based on this vocabulary, a message passing model for interactions between humans and models is presented, which we demonstrate can account for existing HAI interaction systems and approaches. Finally, we build this into design patterns which can describe common interactions between users and models, and we discuss how this approach can be used towards a design space for HAI interactions that creates new possibilities for designs as well as keeping track of implementation issues and concerns.",,,,"Human-AI interaction, interaction patterns, explainable AI, human-in-the-loop, hybrid intelligence",,,article,,,,,ACM Trans. Interact. Intell. Syst.,jun,2160-6455,Just Accepted,,
,aiDM '24: Proceedings of the Seventh International Workshop on Exploiting Artificial Intelligence Techniques for Data Management,2024,9798400706806,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Santiago, AA, Chile",,proceedings,,,,,,,,,,
"Lee, Dasheng and Chao, Shih-Lung and Chen, Hui-Min",Development of the AI Implementation Framework in Taipei City,2024,9798400709883,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3657054.3657065,10.1145/3657054.3657065,"Taipei City has been experimenting with the use of Artificial Intelligence (AI) tools to enhance its smart capabilities, aiming to increase citizen satisfaction. This initiative is part of the city's Smart City Proof of Concept (PoC) projects, which have been progressively rolled out since 2015. Most of these projects incorporate AI tools or algorithms, such as the combination of the Internet of Things (IoT) with AI to form AIoT, or the application of Large Language Models (LLMs). The objective is to leverage the latest technological developments to achieve a smarter Taipei. This study analyzes the execution of 302 PoC projects, categorizing them into 22 technological segments that together form an AI framework for smart city construction applications. This framework corresponds to 15 major issues of concern to Taipei's residents, with the potential to address or mitigate 13 of them. According to the IMD Smart City Index Report 2023, Taipei's smart city rating improved from a B in 2021 to an A in 2023, indicating progress. The results demonstrate that the AI framework derived from dissecting multiple PoC projects can effectively enhance the city's smart construction ratings. This framework, aligned with major municipal concerns, proposes solutions driven by AI, guiding Taipei's digital transformation into a smarter city and enabling its citizens to enjoy an improved quality of life.",Proceedings of the 25th Annual International Conference on Digital Government Research,90–103,14,,"Taipei, Taiwan",dg.o '24,inproceedings,,,,,,,,,,
"Kotturi, Yasmine and Anderson, Angel and Ford, Glenn and Skirpan, Michael and Bigham, Jeffrey P",Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642191,10.1145/3613904.3642191,"Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while simultaneously deconstructing the veneer of simplicity to address the many operational skills needed for successful application.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"community-based research, entrepreneurship, generative artificial intelligence","Honolulu, HI, USA",CHI '24,inproceedings,1014,,,,,,,,,
"Jiang, Harry H. and Brown, Lauren and Cheng, Jessica and Khan, Mehtab and Gupta, Abhishek and Workman, Deja and Hanna, Alex and Flowers, Johnathan and Gebru, Timnit",AI Art and its Impact on Artists,2023,9798400702310,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3600211.3604681,10.1145/3600211.3604681,"The last 3 years have resulted in machine learning (ML)-based image generators with the ability to output consistently higher quality images based on natural language prompts as inputs. As a result, many popular commercial “generative AI Art” products have entered the market, making generative AI an estimated $48B industry&nbsp;[125]. However, many professional artists have spoken up about the harms they have experienced due to the proliferation of large scale image generators trained on image/text pairs from the Internet. In this paper, we review some of these harms which include reputational damage, economic loss, plagiarism and copyright infringement. To guard against these issues while reaping the potential benefits of image generators, we provide recommendations such as regulation that forces organizations to disclose their training data, and tools that help artists prevent using their content as training data without their consent.","Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",363–374,12,,,AIES '23,inproceedings,,,,,,,,,,
,IAIT '23: Proceedings of the 13th International Conference on Advances in Information Technology,2023,9798400708497,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bangkok, Thailand",,proceedings,,,,,,,,,,
,C&amp;C '24: Proceedings of the 16th Conference on Creativity &amp; Cognition,2024,9798400704857,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chicago, IL, USA",,proceedings,,,,,,,,,,
,CHItaly '23: Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter,2023,9798400708060,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Torino, Italy",,proceedings,,,,,,,,,,
"Wan, Qian and Hu, Siying and Zhang, Yu and Wang, Piaohong and Wen, Bo and Lu, Zhicong",,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3637361,10.1145/3637361,"Prewriting is the process of discovering and developing ideas before writing a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creative process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in addition to mixed and shifting levels of initiative that exist between humans and LLMs. This research also reports on collaboration breakdowns that occur during this process, user perceptions of using existing LLMs during Human-AI Co-creativity, and discusses design implications to support this co-creativity process.",,,26,"creative writing, creativity support, human-ai collaboration, large language models, prewriting",,,article,84,April 2024,8,CSCW1,Proc. ACM Hum.-Comput. Interact.,apr,,,,
"Moore, Robert J. and An, Sungeun and Marrese, Olivia H.",Understanding is a Two-Way Street: User-Initiated Repair on Agent Responses and Hearing in Conversational Interfaces,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3641026,10.1145/3641026,"Although methods for repairing prior turns in natural conversation are critical for enabling mutual understanding, or successful communication, these methods are seldom built into conversational user interfaces systematically. Chatbots and voice assistants tend to ask users to paraphrase what they said if it was not understood, but users cannot do the same if they encounter trouble in understanding what the agent said. Understanding is a one-way street in most (intent-based) conversation-like interfaces. An exception to this is Moore and Arar (2019), who demonstrate nine types of user-initiated repair on agent responses that are common in natural conversation and who have shown that users will employ these repair features correctly in text-based interfaces if taught. In this small-scale study, we test these user-initiated repairs (in second position) in a voice-based interface. With understanding-oriented repairs, we found that participants employed them much the same way in text and voice. In addition, we examine some hearing- and speaking-oriented repairs that emerged from the use of our novel multi-modal interface. We found that participants used them to manage troubles specific to the voice modality. Analysis of user logs and transcripts suggests that user-initiated repair features are valuable components of conversational interfaces.",,,26,"chatbots, conversational agents, conversational ai, conversational user interfaces, conversational ux, user-initiated repair",,,article,187,April 2024,8,CSCW1,Proc. ACM Hum.-Comput. Interact.,apr,,,,
,"FAccT '24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rio de Janeiro, Brazil",,proceedings,,,,,,,,,,
"Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sashank and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah",PaLM: scaling language modeling with pathways,2024,,JMLR.org,,,,"Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540- billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.",,,113,"large language models, few-shot learning, natural language processing, scalable deep learning",,,article,240,January 2023,24,1,J. Mach. Learn. Res.,mar,1532-4435,,,
"Schmidt, Albrecht and Elagroudy, Passant and Draxler, Fiona and Kreuter, Frauke and Welsch, Robin",Simulating the Human in HCD with ChatGPT: Redesigning Interaction Design with AI,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3637436,10.1145/3637436,,,24–31,8,,,,article,,January - February 2024,31,1,Interactions,jan,1072-5520,,,
,Risky Artificial Intelligence,2024,9798400717703,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640479.3640492,,"This book offers a compelling discussion of the digital dreams that have come true, their often unintended side effects (nightmares), and what must be done to counteract the nightmares. It is intended as an impetus to further conversation not only in homes and workplaces, but in academic courses and even legislative debates. Equally importantly, the book is a presentation of what digital technology professionals need to know about these topics and the actions they should undertake individually and in support of other citizens, societal initiatives, and government. The author begins by introducing the amazing progress made in digital technologies over the past 80 years. Pioneering engineers dreamed of potential uses of technology through their writing and technical achievements, further inspiring thousands of researchers to bring the dreams to life, and to dream new dreams as well. The second part of the book describes the myriad adverse side effects and unanticipated challenges that arose as those dreams were pursued and achieved. Examples include rampant misinformation on social media, ransomware, autonomous weapons, and the premature use of AI before it is reliable and safe.The book closes with a positive call to action, outlining ways to address the challenges through ethical career choices, careful analysis, thoughtful design, research, citizen engagement, legislation/regulation, and careful consideration of how bad actors may use technology. Readers of Digital Dreams Have Become Nightmares should become more knowledgeable, wiser, and also cautiously optimistic, determined to affect positive changes through their design, creation, and use of technology.“Are you feeling happy about the role of information technology in the world today? You should read this book for a dose of reality. Are you in despair about it? This book is the prescription for that condition, too! Nobody else could cover the landscape as Ron Baecker does.” - Clayton Lewis, Emeritus Professor, University of Colorado Boulder“This book is a captivating review of important computing developments. Many things talked about as new today have been around for a long time. Much can be learned from the past. The book also teaches a careful and consistent method that enables the reader to do this kind of work as the need arises. The book suggests the need will arise.” - John Leslie King, Emeritus Professor, University of Michigan",Digital Dreams Have Become Nightmares: What We Must Do,,,,,,inbook,,,,,,,,,,
,"SC-W '23: Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis",2023,9798400707858,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Denver, CO, USA",,proceedings,,,,,,,,,,
,CODS-COMAD '23: Proceedings of the 6th Joint International Conference on Data Science &amp; Management of Data (10th ACM IKDD CODS and 28th COMAD),2023,9781450397971,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Mumbai, India",,proceedings,,,,,,,,,,
,CUI '23: Proceedings of the 5th International Conference on Conversational User Interfaces,2023,9798400700149,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Eindhoven, Netherlands",,proceedings,,,,,,,,,,
"Anderson, Mark W. R. and Millard, David E.",Seven Hypertexts,2023,9798400702327,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3603163.3609048,10.1145/3603163.3609048,"What is Hypertext? It has been studied and explored for over 50 years but a complete definition seems ever more elusive. The term is invoked in multiple communities, and applied in radically different domains, but if we cannot reconcile the different perspectives then we will be unable to learn from our shared history, or from each other in the future. In this paper we argue that the longevity and variety of hypertext work makes a simple definition impractical. Instead we suggest different contexts in which hypertext work has been conducted, and then attempt to draw out the relationships and commonalities between them. We describe seven contexts drawn from the literature: Hypertext as a Tool for Thought, as Knowledge Representation, as Social Fabric, as Literature, as Games, as Infrastructure, and as Interface. We argue that these are connected by a common requirement for non-regularity, driven by post-structuralist philosophy, and enshrining existentialist values in our technology. It is the application of these ideas to different problems that gives rise to current Hypertext, as we see the same technical features, and engineering and creative challenges, manifest in otherwise quite different digital domains.",Proceedings of the 34th ACM Conference on Hypertext and Social Media,,15,"tools for thought, stretchtext, social networks, narrative, metadata, linkbases, knowledge representation, knowledge management, knowledge bases, interface, interactive fiction, infrastucture, hypertext literature, hypertext, hypermedia, hyperfilm, games, blogs, PKM","Rome, Italy",HT '23,inproceedings,42,,,,,,,,,
,AICCC '23: Proceedings of the 2023 6th Artificial Intelligence and Cloud Computing Conference,2023,9798400716225,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Kyoto, Japan",,proceedings,,,,,,,,,,
,AIBDF '23: Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum,2023,9798400716362,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Guangzhou, China",,proceedings,,,,,,,,,,
,"IoTAAI '23: Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence",2023,9798400716485,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Nanchang, China",,proceedings,,,,,,,,,,
,CI '23: Proceedings of The ACM Collective Intelligence Conference,2023,9798400701139,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Delft, Netherlands",,proceedings,,,,,,,,,,
"Bendersky, Michael and Li, Cheng and Mei, Qiaozhu and Murdock, Vanessa and Tang, Jie and Wang, Hongning and Zamani, Hamed and Zhang, Mingyang","WSDM 2024 Workshop on Large Language Models for Individuals, Groups, and Society",2024,9798400703713,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3616855.3635726,10.1145/3616855.3635726,"This workshop discusses the cutting-edge developments in research and applications of personalizing large language models (LLMs) and adapting them to the demands of diverse user populations and societal needs. The full-day workshop includes several keynotes and invited talks, a poster session and a panel discussion.",Proceedings of the 17th ACM International Conference on Web Search and Data Mining,1206–1207,2,"large language models, personalization, workshop","Merida, Mexico",WSDM '24,inproceedings,,,,,,,,,,
,ICCPR '23: Proceedings of the 2023 12th International Conference on Computing and Pattern Recognition,2023,9798400707988,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Qingdao, China",,proceedings,,,,,,,,,,
"Hou, Chenyu and Zhu, Gaoxia and Zheng, Juan and Zhang, Lishan and Huang, Xiaoshan and Zhong, Tianlong and Li, Shan and Du, Hanxiang and Ker, Chin Lee",Prompt-based and Fine-tuned GPT Models for Context-Dependent and -Independent Deductive Coding in Social Annotation,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636910,10.1145/3636555.3636910,"GPT has demonstrated impressive capabilities in executing various natural language processing (NLP) and reasoning tasks, showcasing its potential for deductive coding in social annotations. This research explored the effectiveness of prompt engineering and fine-tuning approaches of GPT for deductive coding of context-dependent and context-independent dimensions. Coding context-dependent dimensions (i.e., Theorizing, Integration, Reflection) requires a contextualized understanding that connects the target comment with reading materials and previous comments, whereas coding context-independent dimensions (i.e., Appraisal, Questioning, Social, Curiosity, Surprise) relies more on the comment itself. Utilizing strategies such as prompt decomposition, multi-prompt learning, and a codebook-centered approach, we found that prompt engineering can achieve fair to substantial agreement with expert-labeled data across various coding dimensions. These results affirm GPT's potential for effective application in real-world coding tasks. Compared to context-independent coding, context-dependent dimensions had lower agreement with expert-labeled data. To enhance accuracy, GPT models were fine-tuned using 102 pieces of expert-labeled data, with an additional 102 cases used for validation. The fine-tuned models demonstrated substantial agreement with ground truth in context-independent dimensions and elevated the inter-rater reliability of context-dependent categories to moderate levels. This approach represents a promising path for significantly reducing human labor and time, especially with large unstructured datasets, without sacrificing the accuracy and reliability of deductive coding tasks in social annotation. The study marks a step toward optimizing and streamlining coding processes in social annotation. Our findings suggest the promise of using GPT to analyze qualitative data and provide detailed, immediate feedback for students to elicit deepening inquiries.&nbsp;",Proceedings of the 14th Learning Analytics and Knowledge Conference,518–528,11,"Context-Dependent, Fine-tuning, GPT, Prompt Engineering, Social Annotation, deductive coding","Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
,ASONAM '23: Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,2023,9798400704093,Association for Computing Machinery,"New York, NY, USA",,,The ASONAM conference series brings together researchers from around the world to share the latest advances in the attractive field of Social Networks Analysis and Mining.,,,,,"Kusadasi, Turkiye",,proceedings,,,,,,,,,,
"Fok, Raymond and Soldaini, Luca and Trier, Cassidy and Bransom, Erin and MacMillan, Kelsey and Cheng, Evie and Kambhamettu, Hita and Bragg, Jonathan and Lo, Kyle and Hearst, Marti A. and Head, Andrew and Weld, Daniel S.",Accelerating Scientific Paper Skimming with Augmented Intelligence Through Customizable Faceted Highlights,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3665648,10.1145/3665648,"Scholars need to keep up with an exponentially increasing flood of scientific papers. To aid this challenge, we introduce Scim, a novel intelligent interface that helps scholars skim papers to rapidly review and gain a cursory understanding of its contents. Scim supports the skimming process by highlighting salient content within a paper, directing a scholar’s attention. These automatically-extracted highlights are faceted by content type, evenly distributed across a paper, and have a density configurable by scholars. We evaluate Scim with an in-lab usability study and a longitudinal diary study, revealing how its highlights facilitate the more efficient construction of a conceptualization of a paper. Finally, we describe the process of scaling highlights from their conception within Scim, a research prototype, to production on over 521,000 papers within the Semantic Reader, a publicly-available augmented reading interface for scientific papers. We conclude by discussing design considerations and tensions for the design of future skimming tools with augmented intelligence.",,,,"Intelligent reading interfaces, skimming, highlights, scientific papers",,,article,,,,,ACM Trans. Interact. Intell. Syst.,may,2160-6455,Just Accepted,,
,WSC '23: Proceedings of the Winter Simulation Conference,2023,9798350369663,IEEE Press,,,,,,,,,"San Antonio, Texas, USA",,proceedings,,,,,,,,,,
,"ARES '23: Proceedings of the 18th International Conference on Availability, Reliability and Security",2023,9798400707728,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Benevento, Italy",,proceedings,,,,,,,,,,
,SIGMOD/PODS '24: Companion of the 2024 International Conference on Management of Data,2024,9798400704222,Association for Computing Machinery,"New York, NY, USA",,,"On behalf of the SIGMOD 2024 organizing committee, it is our distinct honor, as General Chairs, to welcome you to the 2024 ACM International Conference on Management of Data - SIGMOD 2024. We are thrilled to be hosting this prestigious event for the very first time in Latin America, and specifically in Santiago de Chile, a recognized leader in data technology within the region. This marks a significant milestone for the SIGMOD community, and we are honored to have you join us for a fully in-person experience in this vibrant and innovative city.",,,,,"Santiago AA, Chile",,proceedings,,,,,,,,,,
,ICSCA '24: Proceedings of the 2024 13th International Conference on Software and Computer Applications,2024,9798400708329,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bali Island, Indonesia",,proceedings,,,,,,,,,,
,Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud,2024,9798400704222,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3626246.3653378,10.1145/3626246.3653378,"Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.",Companion of the 2024 International Conference on Management of Data,241–254,14,"containers, kubernetes, resource optimization, vertical auto-scaling","Santiago AA, Chile",SIGMOD/PODS '24,inproceedings,,,,,,,,,,
,NLPIR '23: Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval,2023,9798400709227,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Seoul, Republic of Korea",,proceedings,,,,,,,,,,
"Kelly, Markelle and Kumar, Aakriti and Smyth, Padhraic and Steyvers, Mark",Capturing Humans’ Mental Models of AI: An Item Response Theory Approach,2023,9798400701924,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3593013.3594111,10.1145/3593013.3594111,"Improving our understanding of how humans perceive AI teammates is an important foundation for our general understanding of human-AI teams. Extending relevant work from cognitive science, we propose a framework based on item response theory for modeling these perceptions. We apply this framework to real-world experiments, in which each participant works alongside another person or an AI agent in a question-answering setting, repeatedly assessing their teammate’s performance. Using this experimental data, we demonstrate the use of our framework for testing research questions about people’s perceptions of both AI agents and other people. We contrast mental models of AI teammates with those of human teammates as we characterize the dimensionality of these mental models, their development over time, and the influence of the participants’ own self-perception. Our results indicate that people expect AI agents’ performance to be significantly better on average than the performance of other humans, with less variation across different types of problems. We conclude with a discussion of the implications of these findings for human-AI interaction.","Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",1723–1734,12,"human-AI interaction, mental models, theory of mind","Chicago, IL, USA",FAccT '23,inproceedings,,,,,,,,,,
"Singh, Anjali and Brooks, Christopher and Wang, Xu and Li, Warren and Kim, Juho and Wilson, Deepti",Bridging Learnersourcing and AI: Exploring the Dynamics of Student-AI Collaborative Feedback Generation,2024,9798400716188,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3636555.3636853,10.1145/3636555.3636853,"This paper explores the space of optimizing feedback mechanisms in complex domains such as data science, by combining two prevailing approaches: Artificial Intelligence (AI) and learnersourcing. Towards addressing the challenges posed by each approach, this work compares traditional learnersourcing with an AI-supported approach. We report on the results of a randomized controlled experiment conducted with 72 Master’s level students in a data visualization course, comparing two conditions: students writing hints independently versus revising hints generated by GPT-4. The study aimed to evaluate the quality of learnersourced hints, examine the impact of student performance on hint quality, gauge learner preference for writing hints with versus without AI support, and explore the potential of the student-AI collaborative exercise in fostering critical thinking about LLMs. Based on our findings, we provide insights for designing learnersourcing activities leveraging AI support and optimizing students’ learning as they interact with LLMs.",Proceedings of the 14th Learning Analytics and Knowledge Conference,742–748,7,"Data Visualization, Feedback Generation, GPT-4, Learnersourcing","Kyoto, Japan",LAK '24,inproceedings,,,,,,,,,,
"Lazar, Jonathan",Let's strengthen the HCI community by taking a gap year!,2017,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3155054,10.1145/3155054,,,20–21,2,,,,article,,January + February 2018,25,1,Interactions,dec,1072-5520,,,
,NetAISys '24: Proceedings of the 2nd International Workshop on Networked AI Systems,2024,9798400706615,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Minato-ku, Tokyo, Japan",,proceedings,,,,,,,,,,
"He, Jingrui and Kang, Jian and Nargesian, Fatemeh and Wang, Haohui and Zhang, An and Zhou, Dawei",TrustLOG: The Second Workshop on Trustworthy Learning on Graphs,2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3641305,10.1145/3589335.3641305,"Learning on graphs (LOG) has a profound impact on various high-impact domains, such as information retrieval, social network analysis, computational chemistry and transportation. Despite decades of theoretical development, algorithmic advancements, and open-source systems that answers what the optimal learning results are, concerns about the trustworthiness of state-of-the-art LOG techniques have emerged in practical applications. Consequently, crucial research questions arise: why are LOG techniques untrustworthy with respect to critical social aspects like fairness, transparency, privacy, and security? How can we ensure the trustworthiness of learning algorithms on graphs? To address the increasingly important safety and ethical challenges in learning on graphs, it is essential to achieve a paradigm shift from solely addressing what questions to understanding how and why questions. Building upon the success of the first TrustLOG workshop in 2022, the second TrustLOG workshop aims to bring together researchers and practitioners to present, discuss, and advance cutting-edge research in the realm of trustworthy learning on graphs. The workshop serves as a platform to stimulate the TrustLOG community, fostering the identification of new research challenges, and shedding light on potential future directions.",Companion Proceedings of the ACM on Web Conference 2024,1785–1788,4,"graph learning, graph mining, trustworthy machine learning","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
,ISAIMS '23: Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science,2023,9798400708138,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chengdu, China",,proceedings,,,,,,,,,,
,SIGMIS-CPR '24: Proceedings of the 2024 Computers and People Research Conference,2024,9798400704772,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Murfreesboro, TN, USA",,proceedings,,,,,,,,,,
"Retzlaff, Carl Orge and Das, Srijita and Wayllace, Christabel and Mousavi, Payam and Afshari, Mohammad and Yang, Tianpei and Saranti, Anna and Angerschmid, Alessa and Taylor, Matthew E. and Holzinger, Andreas","Human-in-the-Loop Reinforcement Learning: A Survey and Position on Requirements, Challenges, and Opportunities",2024,,AI Access Foundation,"El Segundo, CA, USA",https://doi.org/10.1613/jair.1.15348,10.1613/jair.1.15348,"Artificial intelligence (AI) and especially reinforcement learning (RL) have the potential to enable agents to learn and perform tasks autonomously with superhuman performance. However, we consider RL as fundamentally a Human-in-the-Loop (HITL) paradigm, even when an agent eventually performs its task autonomously.&nbsp;
In cases where the reward function is challenging or impossible to define, HITL approaches are considered particularly advantageous.
The application of Reinforcement Learning from Human Feedback (RLHF) in systems such as ChatGPT demonstrates the effectiveness of optimizing for user experience and integrating their feedback into the training loop. In HITL RL, human input is integrated during the agent’s learning process, allowing iterative updates and fine-tuning based on human feedback, thus enhancing the agent’s performance. Since the human is an essential part of this process, we argue that human-centric approaches are the key to successful RL, a fact that has not been adequately considered in the existing literature. This paper aims to inform readers about current explainability methods in HITL RL. It also shows how the application of explainable AI (xAI) and specific improvements to existing explainability approaches can enable a better human-agent interaction in HITL RL for all types of users, whether for lay people, domain experts, or machine learning specialists.
Accounting for the workflow in HITL RL and based on software and machine learning methodologies, this article identifies four phases for human involvement for creating HITL RL systems: (1) Agent Development, (2) Agent Learning, (3) Agent Evaluation, and (4) Agent Deployment. We highlight human involvement, explanation requirements, new challenges, and goals for each phase.
We furthermore identify low-risk, high-return opportunities for explainability research in HITL RL and present long-term research goals to advance the field. Finally, we propose a vision of human-robot collaboration that allows both parties to reach their full potential and cooperate effectively.",,,57,,,,article,,Apr 2024,79,,J. Artif. Int. Res.,jan,1076-9757,,,
"Salehzadeh Niksirat, Kavous and Goswami, Lahari and S. B. Rao, Pooja and Tyler, James and Silacci, Alessandro and Aliyu, Sadiq and Aebli, Annika and Wacharamanotham, Chat and Cherubini, Mauro","Changes in Research Ethics, Openness, and Transparency in Empirical Studies between CHI 2017 and CHI 2022",2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580848,10.1145/3544548.3580848,"In recent years, various initiatives from within and outside the HCI field have encouraged researchers to improve research ethics, openness, and transparency in their empirical research. We quantify how the CHI literature might have changed in these three aspects by analyzing samples of 118 CHI 2017 and 127 CHI 2022 papers—randomly drawn and stratified across conference sessions. We operationalized research ethics, openness, and transparency into 45&nbsp; criteria and manually annotated the sampled papers. The results show that the CHI 2022 sample was better in 18 criteria, but in the rest of the criteria, it has no improvement. The most noticeable improvements were related to research transparency (10 out of 17 criteria). We also explored the possibility of assisting the verification process by developing a proof-of-concept screening system. We tested this tool with eight criteria. Six of them achieved high accuracy and F1 score. We discuss the implications for future research practices and education. This paper and all supplementary materials are freely available at&nbsp;https://doi.org/10.17605/osf.io/n25d6.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,23,"CHI, data availability, ethics, open science, replicability, reproducibility, transparency","Hamburg, Germany",CHI '23,inproceedings,505,,,,,,,,,
"Zhang, Jizhi and Bao, Keqin and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan",Large Language Models for Recommendation: Progresses and Future Directions,2024,9798400701726,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3589335.3641247,10.1145/3589335.3641247,"Large language models (LLMs) have significantly influenced recommender systems. Both academia and industry have shown growing interest in developing LLMs for recommendation purposes, an approach commonly referred to as LLM4Rec. This involves efforts such as utilizing LLMs for generative item retrieval and ranking, along with the potential for creating universal LLMs for varied recommendation tasks, signaling a possible paradigm shift in recommender systems. This tutorial is designed to review the progression of LLM4Rec and provide an in-depth analysis of the prevailing studies. We will discuss how LLMs advance recommender systems in model architecture, learning paradigms, and capabilities like conversation, generalization, planning, and content generation. Additionally, the tutorial will highlight open problems and challenges in this nascent field, addressing concerns related to trustworthiness, efficiency, online training, and recommendation data modeling. Concluding with a summary of the takeaways from previous research, the tutorial will suggest avenues for future investigations. Our aim is to help the audience grasp the developments in LLM4Rec, as well as to spark inspiration for further research. By doing so, we expect to contribute to the growth and success of LLM4Rec, possibly leading to a fundamental change in recommender paradigms.",Companion Proceedings of the ACM on Web Conference 2024,1268–1271,4,"generative models, generative recommendation, large language models, recommender systems","Singapore, Singapore",WWW '24,inproceedings,,,,,,,,,,
"Bao, Keqin and Zhang, Jizhi and Zhang, Yang and Wenjie, Wang and Feng, Fuli and He, Xiangnan",Large Language Models for Recommendation: Progresses and Future Directions,2023,9798400704086,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3624918.3629550,10.1145/3624918.3629550,"The powerful large language models (LLMs) have played a pivotal role in advancing recommender systems. Recently, in both academia and industry, there has been a surge of interest in developing LLMs for recommendation, referred to as LLM4Rec. This includes endeavors like leveraging LLMs for generative item retrieval and ranking, as well as the exciting possibility of building universal LLMs for diverse open-ended recommendation tasks. These developments hold the potential to reshape the traditional recommender paradigm, paving the way for the next-generation recommender systems. In this tutorial, we aim to retrospect the evolution of LLM4Rec and conduct a comprehensive review of existing research. In particular, we will clarify how recommender systems benefit from LLMs through a variety of perspectives, including the model architecture, learning paradigm, and the strong abilities of LLMs such as chatting, generalization, planning, and generation. Furthermore, we will discuss the critical challenges and open problems in this emerging field, for instance, the trustworthiness, efficiency, and model retraining issues. Lastly, we will summarize the implications of previous work and outline future research directions. We believe that this tutorial will assist the audience in better understanding the progress and prospects of LLM4Rec, inspiring them for future exploration. This, in turn, will drive the prosperity of LLM4Rec, possibly fostering a paradigm shift in recommendation systems.",Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region,306–309,4,"Recommender Systems, Large Language Models, Generative Recommendation, Generative Models","Beijing, China",SIGIR-AP '23,inproceedings,,,,,,,,,,
"Atzenbeck, Claus",Interview with Mariusz Pisarski,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3643603.3643606,10.1145/3643603.3643606,"Dr Mariusz Pisarski is a hypertext scholar, translator, publisher, the chief editor of ",,,5,,,,article,3,Winter 2024,2024,Winter,SIGWEB Newsl.,feb,1931-1745,,,
,GeoAI '23: Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery,2023,9798400703485,Association for Computing Machinery,"New York, NY, USA",,,"Emerging advances from artificial intelligence, hardware accelerators, and data processing architectures continue to reach the geospatial information sciences, with a transformative impact in many societal challenges. Recent breakthroughs in deep learning have brought forward an automated capability to learn hierarchical representational features from massive and complex data, including text, images, and videos. In tandem, rapid innovations in sensing technologies are supporting the collection of geospatial data in even higher resolution and throughput, supporting the observation, mapping, and analysis of different events/phenomena over the earth's surface with unprecedented detail. Combined, these developments are offering potential for breakthroughs in geographic knowledge discovery, impacting decision making in areas such as humanitarian mapping, intelligent transport systems, urban expansion analysis, health data analysis and epidemiology, the study of climate change, handling natural disasters, and the general monitoring of the Earth's surface.",,,,,"Hamburg, Germany",,proceedings,,,,,,,,,,
,ICMLCA '23: Proceedings of the 2023 4th International Conference on Machine Learning and Computer Application,2023,9798400709449,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hangzhou, China",,proceedings,,,,,,,,,,
,C&amp;T '23: Proceedings of the 11th International Conference on Communities and Technologies,2023,9798400707582,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lahti, Finland",,proceedings,,,,,,,,,,
,EICC '24: Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference,2024,9798400716515,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Xanthi, Greece",,proceedings,,,,,,,,,,
"Wang, Qiaosi and Madaio, Michael and Kane, Shaun and Kapania, Shivani and Terry, Michael and Wilcox, Lauren",Designing Responsible AI: Adaptations of UX Practice to Meet Responsible AI Challenges,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581278,10.1145/3544548.3581278,"Technology companies continue to invest in efforts to incorporate responsibility in their Artificial Intelligence (AI) advancements, while efforts to audit and regulate AI systems expand. This shift towards Responsible AI (RAI) in the tech industry necessitates new practices and adaptations to roles—undertaken by a variety of practitioners in more or less formal positions, many of whom focus on the user-centered aspects of AI. To better understand practices at the intersection of user experience (UX) and RAI, we conducted an interview study with industrial UX practitioners and RAI subject matter experts, both of whom are actively involved in addressing RAI concerns throughout the early design and development of new AI-based prototypes, demos, and products, at a large technology company. Many of the specific practices and their associated challenges have yet to be surfaced in the literature, and distilling them offers a critical view into how practitioners’ roles are adapting to meet present-day RAI challenges. We present and discuss three emerging practices in which RAI is being enacted and reified in UX practitioners’ everyday work. We conclude by arguing that the emerging practices, goals, and types of expertise that surfaced in our study point to an evolution in praxis, with associated challenges that suggest important areas for further research in HCI.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,16,"UX, industry practice, interview, responsible AI","Hamburg, Germany",CHI '23,inproceedings,249,,,,,,,,,
,IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces,2023,9798400701061,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
"Antony, Victor Nikhil and Huang, Chien-Ming",ID.8: Co-Creating Visual Stories with Generative AI,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3672277,10.1145/3672277,"Storytelling is an integral part of human culture and significantly impacts cognitive and socio-emotional development and connection. Despite the importance of interactive visual storytelling, the process of creating such content requires specialized skills and is labor-intensive. This paper introduces ID.8, an open-source system designed for the co-creation of visual stories with generative AI. We focus on enabling an inclusive storytelling experience by simplifying the content creation process and allowing for customization. Our user evaluation confirms a generally positive user experience in domains such as enjoyment and exploration, while highlighting areas for improvement, particularly in immersiveness, alignment, and partnership between the user and the AI system. Overall, our findings indicate promising possibilities for empowering people to create visual stories with generative AI. This work contributes a novel content authoring system, ID.8, and insights into the challenges and potential of using generative AI for multimedia content creation.",,,,"Storytelling, Generative AI, Creativity",,,article,,,,,ACM Trans. Interact. Intell. Syst.,jun,2160-6455,Just Accepted,,
,IDC '23: Proceedings of the 22nd Annual ACM Interaction Design and Children Conference,2023,9798400701313,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chicago, IL, USA",,proceedings,,,,,,,,,,
,‘We Do Not Have the Capacity to Monitor All Media’: A Design Case Study on Cyber Situational Awareness in Computer Emergency Response Teams,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642368,10.1145/3613904.3642368,"Computer Emergency Response Teams (CERTs) provide advisory, preventive and reactive cybersecurity services for authorities, citizens, and businesses. However, their responsibility of monitoring, analyzing, and communicating cyber threats have become challenging due to the growing volume and varying quality of information disseminated through public channels. Based on a design case study conducted from 2021 to 2023, this paper combines three iterations of expert interviews, design workshops and cognitive walkthroughs to design an automated, cross-platform and real-time cybersecurity dashboard. By adopting the notion of cyber situational awareness, the study extracts user requirements and design heuristics for enhanced threat awareness and mission awareness in CERTs, discussing the aspects of source integration, data management, customizable visualization, relationship awareness, information assessment, software integration, (inter-)organizational collaboration, and communication of stakeholder warnings.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Computer Emergency Response Teams, Cyber Situational Awareness, Design Case Studies, Security and Privacy","Honolulu, HI, USA",CHI '24,inproceedings,580,,,,,,,,,
,ICBTA '23: Proceedings of the 2023 6th International Conference on Blockchain Technology and Applications,2023,9798400708671,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Xi'an, China",,proceedings,,,,,,,,,,
,MobileHCI '23 Companion: Proceedings of the 25th International Conference on Mobile Human-Computer Interaction,2023,9781450399241,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Athens, Greece",,proceedings,,,,,,,,,,
,Health and Medicine,2024,9798400717703,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3640479.3640483,,"This book offers a compelling discussion of the digital dreams that have come true, their often unintended side effects (nightmares), and what must be done to counteract the nightmares. It is intended as an impetus to further conversation not only in homes and workplaces, but in academic courses and even legislative debates. Equally importantly, the book is a presentation of what digital technology professionals need to know about these topics and the actions they should undertake individually and in support of other citizens, societal initiatives, and government. The author begins by introducing the amazing progress made in digital technologies over the past 80 years. Pioneering engineers dreamed of potential uses of technology through their writing and technical achievements, further inspiring thousands of researchers to bring the dreams to life, and to dream new dreams as well. The second part of the book describes the myriad adverse side effects and unanticipated challenges that arose as those dreams were pursued and achieved. Examples include rampant misinformation on social media, ransomware, autonomous weapons, and the premature use of AI before it is reliable and safe.The book closes with a positive call to action, outlining ways to address the challenges through ethical career choices, careful analysis, thoughtful design, research, citizen engagement, legislation/regulation, and careful consideration of how bad actors may use technology. Readers of Digital Dreams Have Become Nightmares should become more knowledgeable, wiser, and also cautiously optimistic, determined to affect positive changes through their design, creation, and use of technology.“Are you feeling happy about the role of information technology in the world today? You should read this book for a dose of reality. Are you in despair about it? This book is the prescription for that condition, too! Nobody else could cover the landscape as Ron Baecker does.” - Clayton Lewis, Emeritus Professor, University of Colorado Boulder“This book is a captivating review of important computing developments. Many things talked about as new today have been around for a long time. Much can be learned from the past. The book also teaches a careful and consistent method that enables the reader to do this kind of work as the need arises. The book suggests the need will arise.” - John Leslie King, Emeritus Professor, University of Michigan",Digital Dreams Have Become Nightmares: What We Must Do,,,,,,inbook,,,,,,,,,,
,AHs '24: Proceedings of the Augmented Humans International Conference 2024,2024,9798400709807,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Melbourne, VIC, Australia",,proceedings,,,,,,,,,,
"Kraljic, Tanya and Lahav, Michal",From Prompt Engineering to Collaborating: A Human-Centered Approach to AI Interfaces,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3652622,10.1145/3652622,,,30–35,6,,,,article,,May - June 2024,31,3,Interactions,may,1072-5520,,,
"Lee, Yoonjoo and Kim, Tae Soo and Kim, Sungdong and Yun, Yohan and Kim, Juho",DAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children’s Why and How Questions,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581369,10.1145/3544548.3581369,"Children acquire an understanding of the world by asking “why” and “how” questions. Conversational agents (CAs) like smart speakers or voice assistants can be promising respondents to children’s questions as they are more readily available than parents or teachers. However, CAs’ answers to “why” and “how” questions are not designed for children, as they can be difficult to understand and provide little interactivity to engage the child. In this work, we propose design guidelines for creating interactive dialogues that promote children’s engagement and help them understand explanations. Applying these guidelines, we propose DAPIE, a system that answers children’s questions through interactive dialogue by employing an AI-based pipeline that automatically transforms existing long-form answers from online sources into such dialogues. A user study (N=16) showed that, with DAPIE, children performed better in an immediate understanding assessment while also reporting higher enjoyment than when explanations were presented sentence-by-sentence.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,22,"Children, Conversational Agents, Dialogue, Natural Language, Question Answering","Hamburg, Germany",CHI '23,inproceedings,450,,,,,,,,,
,HotNets '23: Proceedings of the 22nd ACM Workshop on Hot Topics in Networks,2023,9798400704154,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Cambridge, MA, USA",,proceedings,,,,,,,,,,
,RecSys '23: Proceedings of the 17th ACM Conference on Recommender Systems,2023,9798400702419,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Singapore, Singapore",,proceedings,,,,,,,,,,
,"CCRIS '23: Proceedings of the 2023 4th International Conference on Control, Robotics and Intelligent System",2023,9798400708190,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Guangzhou, China",,proceedings,,,,,,,,,,
,HRI '24: Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,2024,9798400703225,Association for Computing Machinery,"New York, NY, USA",,,"Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is ",,,,,"Boulder, CO, USA",,proceedings,,,,,,,,,,
"Maeda, Takuya and Quan-Haase, Anabel",When Human-AI Interactions Become Parasocial: Agency and Anthropomorphism in Affective Design,2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630106.3658956,10.1145/3630106.3658956,"With the continuous improvement of large language models (LLMs), chatbots can produce coherent and continuous word sequences that mirror natural human language. While the use of natural language and human-like conversation styles enables the use of chatbots within a range of everyday settings, these usability-enhancing features can also have unintended consequences, such as making fallible information seem trustworthy by emphasizing friendliness and closeness. This can have serious implications for information retrieval tasks performed with chatbots. In this paper, we provide an overview of the literature on parasociality, social affordance, and trust to bridge these concepts within human-AI interactions. We critically examine how chatbot “roleplaying” and user role projection co-produce a pseudo-interactive, technologically-mediated space with imbalanced dynamics between users and chatbots. Based on the review of the literature, we develop a conceptual framework of parasociality in chatbots that describes interactions between humans and anthropomorphized chatbots. We dissect how chatbots use personal pronouns, conversational conventions, affirmations, and similar strategies to position the chatbots as users’ companions or assistants, and how these tactics induce trust-forming behaviors in users. Finally, based on the conceptual framework, we outline a set of ethical concerns that emerge from parasociality, including illusions of reciprocal engagement, task misalignment, and leaks of sensitive information. This paper argues that these possible consequences arise from a positive feedback cycle wherein anthropomorphized chatbot features encourage users to fill in the context around predictive outcomes.","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",1068–1077,10,"anthropomorphism, chatbots, design, ethics, human-AI interactions, parasociality, trust","Rio de Janeiro, Brazil",FAccT '24,inproceedings,,,,,,,,,,
"WANG, CHANGSHENG and Ye, Jianbai and Wang, Wenjie and Gao, Chongming and Feng, Fuli and He, Xiangnan",RecAD: Towards A Unified Library for Recommender Attack and Defense,2023,9798400702419,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3604915.3609490,10.1145/3604915.3609490,"In recent years, recommender systems have become a ubiquitous part of our daily lives, while they suffer from a high risk of being attacked due to the growing commercial and social values. Despite significant research progress in recommender attack and defense, there is a lack of a widely-recognized benchmarking standard in the field, leading to unfair performance comparison and limited credibility of experiments. To address this, we propose RecAD, a unified library aiming at establishing an open benchmark for recommender attack and defense. RecAD takes an initial step to set up a unified benchmarking pipeline for reproducible research by integrating diverse datasets, standard source codes, hyper-parameter settings, running logs, attack knowledge, attack budget, and evaluation results. The benchmark is designed to be comprehensive and sustainable, covering both attack, defense, and evaluation tasks, enabling more researchers to easily follow and contribute to this promising field. RecAD will drive more solid and reproducible research on recommender systems attack and defense, reduce the redundant efforts of researchers, and ultimately increase the credibility and practical value of recommender attack and defense. The project is released at https://github.com/gusye1234/recad.",Proceedings of the 17th ACM Conference on Recommender Systems,234–244,11,"Shilling Attack and Defense, Recommender Systems, Benchmark","Singapore, Singapore",RecSys '23,inproceedings,,,,,,,,,,
,UIST '23: Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"San Francisco, CA, USA",,proceedings,,,,,,,,,,
,CC 2024: Proceedings of the 33rd ACM SIGPLAN International Conference on Compiler Construction,2024,9798400705076,Association for Computing Machinery,"New York, NY, USA",,,"It is with great pleasure that we welcome you to the 33rd ACM SIGPLAN International Conference on Compiler Construction (CC 2024), held in Edinburgh, Scotland, UK over March 2-3, 2024. As has been the case for the last 9 years, CC is part of a co-located cluster together with IEEE HPCA, IEEE/ACM CGO, and ACM PPoPP. The co-location brings together researchers with complementary expertises in compilation, architecture, and parallel programming, creating a thriving and unique ecosystem for scientific discovery and advancement.",,,,,"Edinburgh, United Kingdom",,proceedings,,,,,,,,,,
,BDSIC '23: Proceedings of the 2023 5th International Conference on Big-data Service and Intelligent Computation,2023,9798400708923,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Singapore, Singapore",,proceedings,,,,,,,,,,
,"AIES '23: Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",2023,9798400702310,Association for Computing Machinery,"New York, NY, USA",,,,,,,,,,proceedings,,,,,,,,,,
"Suresh, Harini and Tseng, Emily and Young, Meg and Gray, Mary and Pierson, Emma and Levy, Karen",Participation in the age of foundation models,2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630106.3658992,10.1145/3630106.3658992,"Growing interest and investment in the capabilities of foundation models has positioned such systems to impact a wide array of services, from banking to healthcare. Alongside these opportunities is the risk that these systems reify existing power imbalances and cause disproportionate harm to historically marginalized groups. The larger scale and domain-agnostic manner in which these models operate further heightens the stakes: any errors or harms are liable to reoccur across use cases. In AI &amp; ML more broadly, participatory approaches hold promise to lend agency and decision-making power to marginalized stakeholders, leading to systems that better benefit justice through equitable and distributed governance. But existing approaches in participatory AI/ML are typically grounded in a specific application and set of relevant stakeholders, and it is not straightforward how to apply these lessons to the context of foundation models. Our paper aims to fill this gap. First, we examine existing attempts at incorporating participation into foundation models. We highlight the tension between participation and scale, demonstrating that it is intractable for impacted communities to meaningfully shape a foundation model that is intended to be universally applicable. In response, we develop a blueprint for participatory foundation models that identifies more local, application-oriented opportunities for meaningful participation. In addition to the “foundation” layer, our framework proposes the “subfloor” layer, in which stakeholders develop shared technical infrastructure, norms and governance for a grounded domain such as clinical care, journalism, or finance, and the “surface” (or application) layer, in which affected communities shape the use of a foundation model for a specific downstream task. The intermediate “subfloor” layer scopes the range of potential harms to consider, and affords communities more concrete avenues for deliberation and intervention. At the same time, it avoids duplicative effort by scaling input across relevant use cases. Through three case studies in clinical care, financial services, and journalism, we illustrate how this multi-layer model can create more meaningful opportunities for participation than solely intervening at the foundation layer.","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",1609–1621,13,"Foundation models, communities, governance, public participation, stakeholders","Rio de Janeiro, Brazil",FAccT '24,inproceedings,,,,,,,,,,
"Faggioli, Guglielmo and Dietz, Laura and Clarke, Charles L. A. and Demartini, Gianluca and Hagen, Matthias and Hauff, Claudia and Kando, Noriko and Kanoulas, Evangelos and Potthast, Martin and Stein, Benno and Wachsmuth, Henning",Who Determines What Is Relevant? Humans or AI? Why Not Both?,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3624730,10.1145/3624730,A spectrum of human-artificial intelligence collaboration in assessing relevance.,,31–34,4,,,,article,,April 2024,67,4,Commun. ACM,mar,0001-0782,,,
,CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,2023,9781450394222,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hamburg, Germany",,proceedings,,,,,,,,,,
,,2024,9798400703225,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3610977.3634979,10.1145/3610977.3634979,"Participatory robot design projects with older adults often use multiple sessions to encourage design feedback and active participation from users. Prior projects have, however, not analyzed the learning outcomes for older adults across co-design sessions and how they support constructive design feedback and meaningful participation. To bridge this gap, we examined the learning outcomes within a ",Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,283–292,10,"co-design, design-learning, older adults, participatory design, photograph, social robots","Boulder, CO, USA",HRI '24,inproceedings,,,,,,,,,,
,ETRA '24: Proceedings of the 2024 Symposium on Eye Tracking Research and Applications,2024,9798400706073,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Glasgow, United Kingdom",,proceedings,,,,,,,,,,
,MLNLP '23: Proceedings of the 2023 6th International Conference on Machine Learning and Natural Language Processing,2023,9798400709241,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sanya, China",,proceedings,,,,,,,,,,
"Zhao, Zhuo and Zhou, Guangyou and Xie, Zhiwen and Wu, Lingfei and Huang, Jimmy Xiangji",CGKPN: Cross-Graph Knowledge Propagation Network with Adaptive Connection for Reasoning-Based Machine Reading Comprehension,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3658673,10.1145/3658673,"The task of machine reading comprehension (MRC) is to enable machine to read and understand a piece of text, and then answer the corresponding question correctly. This task requires machine to not only be able to perform semantic understanding, but also possess logical reasoning capabilities. Just like human reading, it involves thinking about the text from two interacting perspectives of semantics and logic. However, previous methods based on reading comprehension either consider only the logical structure of the text or only the semantic structure of the text, and cannot simultaneously balance semantic understanding and logical reasoning. This single form of reasoning cannot make the machine fully understand the meaning of the text. Additionally, the issue of sparsity in composition presents a significant challenge for models that rely on graph-based reasoning. To this end, a cross-graph knowledge propagation network (CGKPN) with adaptive connection is presented to address the above issues. The model first performs self-view node embedding on the constructed logical graph and semantic graph to update the representations of the graphs. Specifically, relevance matrix between nodes is introduced to adaptively adjust node connections in response to the challenge posed by sparse graph. Subsequently, CGKPN conducts cross-graph knowledge propagation on nodes that are identical in both graphs, effectively resolving conflicts arising from identical nodes in different views, and enabling the model to better integrate the logical and semantic relationships of the text through efficient interaction. Experiments on the two MRC datasets ReClor and LogiQA indicate the superior performance of our proposed model CGKPN compared to other existing baselines.",,,,"machine reading comprehension, logical reasoning, cross-graph knowledge propagation, adaptive connection",,,article,,,,,ACM Trans. Intell. Syst. Technol.,apr,2157-6904,Just Accepted,,
,CHI EA '21: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems,2021,9781450380959,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Yokohama, Japan",,proceedings,,,,,,,,,,
,HAI '23: Proceedings of the 11th International Conference on Human-Agent Interaction,2023,9798400708244,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Gothenburg, Sweden",,proceedings,,,,,,,,,,
,"LDT '24: Proceedings of the 2024 Symposium on Learning, Design and Technology",2024,9798400717222,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Delft, Netherlands",,proceedings,,,,,,,,,,
,JCRAI '23: Proceedings of the 2023 International Joint Conference on Robotics and Artificial Intelligence,2023,9798400707704,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Shanghai, China",,proceedings,,,,,,,,,,
"Crisan, Anamaria and Drouhard, Margaret and Vig, Jesse and Rajani, Nazneen",Interactive Model Cards: A Human-Centered Approach to Model Documentation,2022,9781450393522,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3531146.3533108,10.1145/3531146.3533108,"Deep learning models for natural language processing (NLP) are increasingly adopted and deployed by analysts without formal training in NLP or machine learning (ML). However, the documentation intended to convey the model’s details and appropriate use is tailored primarily to individuals with ML or NLP expertise. To address this gap, we conduct a design inquiry into interactive model cards, which augment traditionally static model cards with affordances for exploring model documentation and interacting with the models themselves. Our investigation consists of an initial conceptual study with experts in ML, NLP, and AI Ethics, followed by a separate evaluative study with non-expert analysts who use ML models in their work. Using a semi-structured interview format coupled with a think-aloud protocol, we collected feedback from a total of 30 participants who engaged with different versions of standard and interactive model cards. Through a thematic analysis of the collected data, we identified several conceptual dimensions that summarize the strengths and limitations of standard and interactive model cards, including: stakeholders; design; guidance; understandability &amp; interpretability; sensemaking &amp; skepticism; and trust &amp; safety. Our findings demonstrate the importance of carefully considered design and interactivity for orienting and supporting non-expert analysts using deep learning models, along with a need for consideration of broader sociotechnical contexts and organizational dynamics. We have also identified design elements, such as language, visual cues, and warnings, among others, that support interactivity and make non-interactive content accessible. We summarize our findings as design guidelines and discuss their implications for a human-centered approach towards AI/ML documentation.","Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",427–439,13,"human centered design, interactive data visualization, model cards","Seoul, Republic of Korea",FAccT '22,inproceedings,,,,,,,,,,
,GLSVLSI '24: Proceedings of the Great Lakes Symposium on VLSI 2024,2024,9798400706059,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Clearwater, FL, USA",,proceedings,,,,,,,,,,
,ICAIL '23: Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law,2023,9798400701979,Association for Computing Machinery,"New York, NY, USA",,,"It is my great pleasure to present to you the proceedings of the Nineteenth International Conference on Artificial Intelligence and Law (ICAIL 2023). The conference will be held June 19-23 at the Universidade do Minho in Braga, Portugal. It has been organized by the International Association for Artificial Intelligence and Law (IAAIL) and is held in cooperation with AAAI and ACM SIGAI. IAAIL's mission is to facilitate research, collaboration, and interdisciplinary communication at the intersection of law and the technical disciplines belonging to the field of artificial intelligence. The first ICAIL conference was held in 1987 and its 2023 iteration is the first to be held in person again after the Covid-19 pandemic.",,,,,"Braga, Portugal",,proceedings,,,,,,,,,,
"Anderson, Andrew and Noa Guevara, Jimena and Moussaoui, Fatima and Li, Tianyi and Vorvoreanu, Mihaela and Burnett, Margaret",Measuring User Experience Inclusivity in Human-AI Interaction via Five User Problem-Solving Styles,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3663740,10.1145/3663740,"Motivations: Recent research has emerged on generally how to improve AI products’ Human-AI Interaction (HAI) User Experience (UX), but relatively little is known about HAI-UX inclusivity. For example, what kinds of users are supported, and who are left out? What product changes would make it more inclusive?Objectives: To help fill this gap, we present an approach to measuring what kinds of diverse users an AI product leaves out and how to act upon that knowledge. To bring actionability to the results, the approach focuses on users’ problem-solving diversity. Thus, our specific objectives were: (1) to show how the measure can reveal which participants with diverse problem-solving styles were left behind in a set of AI products; and (2) to relate participants’ problem-solving diversity to their demographic diversity, specifically gender and age.Methods: We performed 18 experiments, discarding two that failed manipulation checks. Each experiment was a 2x2 factorial experiment with online participants, comparing two AI products: one deliberately violating one of 18 HAI guideline and the other applying the same guideline. For our first objective, we used our measure to analyze how much each AI product gained/lost HAI-UX inclusivity compared to its counterpart, where inclusivity meant supportiveness to participants with particular problem-solving styles. For our second objective, we analyzed how participants’ problem-solving styles aligned with their gender identities and ages.Results &amp; Implications: Participants’ diverse problem-solving styles revealed six types of inclusivity results: (1) the AI products that followed an HAI guideline were almost always more inclusive across diversity of problem-solving styles than the products that did not follow that guideline—but “who” got most of the inclusivity varied widely by guideline and by problem-solving style; (2) when an AI product had risk implications, four variables’ values varied in tandem: participants’ feelings of control, their (lack of) suspicion, their trust in the product, and their certainty while using the product; (3) the more control an AI product offered users, the more inclusive it was; (4) whether an AI product was learning from “my” data or other people’s affected how inclusive that product was; (5) participants’ problem-solving styles skewed differently by gender and age group; and (6) almost all of the results suggested actions that HAI practitioners could take to improve their products’ inclusivity further. Together, these results suggest that a key to improving the demographic inclusivity of an AI product (e.g., across a wide range of genders, ages, etc.) can often be obtained by improving the product’s support of diverse problem-solving styles.",,,,"Intelligent User Interfaces, Human-Computer Interaction",,,article,,,,,ACM Trans. Interact. Intell. Syst.,may,2160-6455,Just Accepted,,
"Sun, Yuan and Jang, Eunchae and Ma, Fenglong and Wang, Ting","Generative AI in the Wild: Prospects, Challenges, and Strategies",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642160,10.1145/3613904.3642160,"Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects – GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges – Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies – In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"Generative AI, Human-AI Collaboration, Transparency, User Agency","Honolulu, HI, USA",CHI '24,inproceedings,747,,,,,,,,,
"Ghaffarzadegan, Shabnam and Boril, Hynek and Hansen, John H. L. and Ghaffarzadegan, Shabnam and Boril, Hynek and Hansen, John H. L. and Ghaffarzadegan, Shabnam and Hansen, John H. L. and Boril, Hynek",Generative Modeling of Pseudo-Whisper for Robust Whispered Speech Recognition,2016,,IEEE Press,,https://doi.org/10.1109/TASLP.2016.2580944,10.1109/TASLP.2016.2580944,"Whisper is a common means of communication used to avoid disturbing individuals or to exchange private information. As a vocal style, whisper would be an ideal candidate for human-handheld/computer interactions in open-office or public area scenarios. Unfortunately, current speech technology is predominantly focused on modal neutral speech and completely breaks down when exposed to whisper. One of the major barriers for successful whisper recognition engines is the lack of available large transcribed whispered speech corpora. This study introduces two strategies that require only a small amount of untranscribed whisper samples to produce excessive amounts of whisper-like pseudo-whisper utterances from easily accessible modal speech recordings. Once generated, the pseudo-whisper samples are used to adapt modal acoustic models of a speech recognizer toward whisper. The first strategy is based on Vector Taylor Series VTS where a whisper “background” model is first trained to capture a rough estimate of global whisper characteristics from a small amount of actual whisper data. Next, that background model is utilized in the VTS to establish specific broad phone classes' unvoiced/voiced phones transformations from each input modal utterance to its pseudo-whispered version. The second strategy generates pseudo-whisper samples by means of denoising autoencoders DAE. Two generative models are investigated-one produces pseudo-whisper cepstral features on a frame-by-frame basis, while the second generates pseudo-whisper statistics for whole phone segments. It is shown that word error rates of a TIMIT-trained speech recognizer are considerably reduced for a whisper recognition task with a constrained lexicon after adapting the acoustic model toward the VTS or DAE pseudo-whisper samples, compared to model adaptation on an available small whisper set.",,1705–1720,16,,,,article,,October 2016,24,10,"IEEE/ACM Trans. Audio, Speech and Lang. Proc.",oct,2329-9290,,,
,IMX '23: Proceedings of the 2023 ACM International Conference on Interactive Media Experiences,2023,9798400700286,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Nantes, France",,proceedings,,,,,,,,,,
"Arakawa, Riku and Yakura, Hiromu and Goto, Masataka",CatAlyst: Domain-Extensible Intervention for Preventing Task Procrastination Using Large Generative Models,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3581133,10.1145/3544548.3581133,"CatAlyst uses generative models to help workers’ progress by influencing their task engagement instead of directly contributing to their task outputs. It prompts distracted workers to resume their tasks by generating a continuation of their work and presenting it as an intervention that is more context-aware than conventional (predetermined) feedback. The prompt can function by drawing their interest and lowering the hurdle for resumption even when the generated continuation is insufficient to substitute their work, while recent human-AI collaboration research aiming at work substitution depends on a stable high accuracy. This frees CatAlyst from domain-specific model-tuning and makes it applicable to various tasks. Our studies involving writing and slide-editing tasks demonstrated CatAlyst’s effectiveness in helping workers swiftly resume tasks with a lowered cognitive load. The results suggest a new form of human-AI collaboration where large generative models publicly available but imperfect for each individual domain can contribute to workers’ digital well-being.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,19,"behavior change, large generative models, procrastination, task engagement","Hamburg, Germany",CHI '23,inproceedings,157,,,,,,,,,
,"ACAI '23: Proceedings of the 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence",2023,9798400709203,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sanya, China",,proceedings,,,,,,,,,,
,ISS '22: Companion Proceedings of the 2022 Conference on Interactive Surfaces and Spaces,2022,9781450393560,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Wellington, New Zealand",,proceedings,,,,,,,,,,
"Mukherjee, Avirup and Murali, Kousshik and Jha, Shivam Kumar and Ganguly, Niloy and Chatterjee, Rahul and Mondal, Mainack",MASCARA : Systematically Generating Memorable And Secure Passphrases,2023,9798400700989,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3579856.3582839,10.1145/3579856.3582839,"Passwords are the most common mechanism for authenticating users online. However, studies have shown that users find it difficult to create and manage secure passwords. To that end, passphrases are often recommended as a usable alternative to passwords, which would potentially be easy to remember and hard to guess. However, as we show, user-chosen passphrases fall short of being secure, while state-of-the-art machine-generated passphrases are difficult to remember. In this work, we aim to tackle the drawbacks of the systems that generate passphrases for practical use. In particular, we address the problem of generating secure and memorable passphrases and compare them against user chosen passphrases in use. We identify and characterize 72, 999 user-chosen in-use unique English passphrases from prior leaked password databases. Then we leverage this understanding to create a novel framework for measuring memorability and guessability of passphrases. Utilizing our framework, we design MASCARA, which follows a constrained Markov generation process to create passphrases that optimize for both memorability and guessability. Our evaluation of passphrases shows that MASCARA -generated passphrases are harder to guess than in-use user-generated passphrases, while being easier to remember compared to state-of-the-art machine-generated passphrases. We conduct a two-part user study with crowdsourcing platform Prolific to demonstrate that users have highest memory-recall (and lowest error rate) while using MASCARA passphrases. Moreover, for passphrases of length desired by the users, the recall rate is 60-100% higher for MASCARA-generated passphrases compared to current system-generated ones.",Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security,524–538,15,"passphrases, memorability, guessability, dataset, authentication","Melbourne, VIC, Australia",ASIA CCS '23,inproceedings,,,,,,,,,,
,GECCO '23 Companion: Proceedings of the Companion Conference on Genetic and Evolutionary Computation,2023,9798400701207,Association for Computing Machinery,"New York, NY, USA",,,"GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).",,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"Chien, Jennifer and Danks, David",Beyond Behaviorist Representational Harms: A Plan for Measurement and Mitigation,2024,9798400704505,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3630106.3658946,10.1145/3630106.3658946,"Algorithmic harms are commonly categorized as either allocative or representational. This study specifically addresses the latter, examining current definitions of representational harms to discern what is included and what is not. This analysis motivates our expansion beyond behavioral definitions to encompass harms to cognitive and affective states. The paper outlines high-level requirements for measurement: identifying the necessary expertise to implement this approach and illustrating it through a case study. Our work highlights the unique vulnerabilities of large language models to perpetrating representational harms, particularly when these harms go unmeasured and unmitigated. The work concludes by presenting proposed mitigations and delineating when to employ them. The overarching aim of this research is to establish a framework for broadening the definition of representational harms and to translate insights from fairness research into practical measurement and mitigation praxis.","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",933–946,14,,"Rio de Janeiro, Brazil",FAccT '24,inproceedings,,,,,,,,,,
"Cao, Jie and Ganesh, Ananya and Cai, Jon and Southwell, Rosy and Perkoff, E. Margaret and Regan, Michael and Kann, Katharina and Martin, James H. and Palmer, Martha and D'Mello, Sidney",A Comparative Analysis of Automatic Speech Recognition Errors in Small Group Classroom Discourse,2023,9781450399326,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3565472.3595606,10.1145/3565472.3595606,"In collaborative learning environments, effective intelligent learning systems need to accurately analyze and understand the collaborative discourse between learners (i.e., group modeling) to provide adaptive support. We investigate how automatic speech recognition&nbsp;(ASR) errors influence discourse models of small group collaboration in noisy real-world classrooms. Our dataset consisted of 30 students recorded by consumer off-the-shelf microphones&nbsp;(Yeti Blue) while engaging in dyadic- and triadic- collaborative learning in a multi-day STEM curriculum unit. We found that two state-of-the-art ASR systems (Google Speech and OpenAI Whisper) yielded very high word error rates (0.822, 0.847) but very different profiles of error with Google being more conservative, rejecting 38% of utterances instead of 12% for Whisper. Next, we examined how these ASR errors influenced down-stream small group modeling based on pre-trained large language models for three tasks: Abstract Meaning Representation parsing&nbsp;(AMRParsing), on-task/off-task detection&nbsp;(OnTask), and Accountable Productive Talk prediction&nbsp;(TalkMove). As expected, models trained on clean human transcripts yielded degraded performance on all three tasks, measured by the transfer ratio&nbsp;(TR). However, the TR of the specific sentence-level AMRParsing &nbsp;task&nbsp;(.39 - .62) was much lower than that of the abstract discourse-level OnTask &nbsp;(.63- .94) and TalkMove &nbsp; tasks&nbsp;(.64-.72). Furthermore, different training strategies that incorporated ASR transcripts alone or as augmentations of human transcripts increased accuracy for the discourse-level tasks&nbsp;(OnTask &nbsp;and TalkMove) but not AMRParsing. Simulation experiments suggested that the models were tolerant of missing utterances in the dialog context, and that jointly improving ASR accuracy on important word classes&nbsp;(e.g., verbs and nouns) can improve performance across all tasks. Overall, our results provide insights into how different types of NLP-based tasks might be tolerant of ASR errors under extremely noisy conditions and provide suggestions for how to improve accuracy in small group modeling settings for a more equitable, engaging, and adaptive collaborative learning environment.","Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization",250–262,13,"Text Tagging, Group Discourse Analysis, Collaborative Learning, Automatic Speech Recognition","Limassol, Cyprus",UMAP '23,inproceedings,,,,,,,,,,
,BDEIM '23: Proceedings of the 2023 4th International Conference on Big Data Economy and Information Management,2023,9798400716669,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Zhengzhou, China",,proceedings,,,,,,,,,,
,ASPDAC '24: Proceedings of the 29th Asia and South Pacific Design Automation Conference,2024,9798350393545,IEEE Press,,,,"ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) area like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer-Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunity to know the recent advanced technologies on LSI design and design automation areas, and to communicate each other for researchers and designers around Asia and South Pacific regions.",,,,,"Incheon, Republic of Korea",,proceedings,,,,,,,,,,
,"UMAP '23 Adjunct: Adjunct Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization",2023,9781450398916,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Limassol, Cyprus",,proceedings,,,,,,,,,,
,NLPIR '22: Proceedings of the 2022 6th International Conference on Natural Language Processing and Information Retrieval,2022,9781450397629,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bangkok, Thailand",,proceedings,,,,,,,,,,
"Niu, Tong and Zhang, Weihao and Zhao, Rong",Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning,2024,9798400704864,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,,"Agent-based models (ABMs) stand as an essential paradigm for proposing and validating hypothetical solutions or policies aimed at addressing challenges posed by complex systems and achieving various objectives. This process demands labor-intensive endeavors and multidisciplinary expertise. Large language models (LLMs) encapsulating cross-domain knowledge and programming proficiency could potentially alleviate the difficulty of this process. However, LLMs excel in handling sequential information, making it challenging for analyzing the intricate interactions and nonlinear dynamics inherent in ABMs. Additionally, due to the lack of self-evaluation capability of LLMs, relying solely on LLMs is insufficient to effectively accomplish this process. In this paper, we present SAGE, a general solution-oriented ABM generation framework designed for automatic modeling and generating solutions for targeted problems. Unlike approaches reliant on expert handcrafting or resource-intensive neural network training, SAGE establishes a verifier-assisted iterative in-context learning process employing large language models (LLMs) to leverages their inherent cross-domain knowledge for tackling intricate demands from diverse domain scenarios. In SAGE, we introduce an semi-structured conceptual representation expliciting the intricate structures of ABMs and an objective representation to guide LLMs in modeling scenarios and proposing hypothetical solutions through in-context learning. To ensure the model executability and solution feasibility, SAGE devises a two-level verifier with chain-of-thought prompting tailored to the complex interactions and non-linear dynamics of ABMs, driving the iterative generation optimization. Moreover, we construct an evaluation dataset of solution-oriented ABMs from open sources. It contains practical models across various domains, completed with scenario descriptions and executable agent-based solutions. Evaluations by various LLMs demonstrate that SAGE leads to an average improvement of 18.7% in modeling quality and 38.1% in solution generation effectiveness. This work advances our understanding and ability in tackling complex real-world challenges across diverse domains through the application of ABM methodologies.",Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems,1473–1481,9,"automatic verification and generation, chain-of-thought prompting, iterative in-context learning, large language models, solution-oriented agent-based modeling","Auckland, New Zealand",AAMAS '24,inproceedings,,,,,,,,,,
,dg.o '24: Proceedings of the 25th Annual International Conference on Digital Government Research,2024,9798400709883,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Taipei, Taiwan",,proceedings,,,,,,,,,,
,IDC '24: Proceedings of the 23rd Annual ACM Interaction Design and Children Conference,2024,9798400704420,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Delft, Netherlands",,proceedings,,,,,,,,,,
"Liao, Q. Vera and Subramonyam, Hariharan and Wang, Jennifer and Wortman Vaughan, Jennifer",Designerly Understanding: Information Needs for Model Transparency to Support Design Ideation for AI-Powered User Experience,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580652,10.1145/3544548.3580652,"Despite the widespread use of artificial intelligence (AI), designing user experiences (UX) for AI-powered systems remains challenging. UX designers face hurdles understanding AI technologies, such as pre-trained language models, as design materials. This limits their ability to ideate and make decisions about whether, where, and how to use AI. To address this problem, we bridge the literature on AI design and AI transparency to explore whether and how frameworks for transparent model reporting can support design ideation with pre-trained models. By interviewing 23 UX practitioners, we find that practitioners frequently work with pre-trained models, but lack support for UX-led ideation. Through a scenario-based design task, we identify common goals that designers seek model understanding for and pinpoint their model transparency information needs. Our study highlights the pivotal role that UX designers can play in Responsible AI and calls for supporting their understanding of AI limitations through model transparency and interrogation.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,21,"AI design, AI documentation, AI transparency, explainability, pre-trained models","Hamburg, Germany",CHI '23,inproceedings,9,,,,,,,,,
,CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hamburg, Germany",,proceedings,,,,,,,,,,
"Tankelevitch, Lev and Kewenig, Viktor and Simkute, Auste and Scott, Ava Elizabeth and Sarkar, Advait and Sellen, Abigail and Rintel, Sean",The Metacognitive Demands and Opportunities of Generative AI,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642902,10.1145/3613904.3642902,"Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,24,"Generative AI, Human-AI interaction, Metacognition, System Usability, User Experience Design","Honolulu, HI, USA",CHI '24,inproceedings,680,,,,,,,,,
,SIGDOC '23: Proceedings of the 41st ACM International Conference on Design of Communication,2023,9798400703362,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Orlando, FL, USA",,proceedings,,,,,,,,,,
,SOICT '23: Proceedings of the 12th International Symposium on Information and Communication Technology,2023,9798400708916,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Ho Chi Minh, Vietnam",,proceedings,,,,,,,,,,
,ICMLC '24: Proceedings of the 2024 16th International Conference on Machine Learning and Computing,2024,9798400709234,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Shenzhen, China",,proceedings,,,,,,,,,,
,Mindtrek '23: Proceedings of the 26th International Academic Mindtrek Conference,2023,9798400708749,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Tampere, Finland",,proceedings,,,,,,,,,,
,ICFNDS '23: Proceedings of the 7th International Conference on Future Networks and Distributed Systems,2023,9798400709036,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Dubai, United Arab Emirates",,proceedings,,,,,,,,,,
,CNML '23: Proceedings of the 2023 International Conference on Communication Network and Machine Learning,2023,9798400716683,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Zhengzhou, China",,proceedings,,,,,,,,,,
,OASIS '23: Proceedings of the 3rd International Workshop on Open Challenges in Online Social Networks,2023,9798400702259,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rome, Italy",,proceedings,,,,,,,,,,
,CHIWORK '23: Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work,2023,9798400708077,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Oldenburg, Germany",,proceedings,,,,,,,,,,
,"UMAP '23: Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization",2023,9781450399326,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Limassol, Cyprus",,proceedings,,,,,,,,,,
"Zavolokina, Liudmila and Sprenkamp, Kilian and Katashinskaya, Zoya and Jones, Daniel Gordon and Schwabe, Gerhard","Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool",2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642805,10.1145/3613904.3642805,"In today's digital age, characterized by rapid news consumption and increasing vulnerability to propaganda, fostering citizens' critical thinking is crucial for stable democracies. This paper introduces the design of ClarifAI, a novel automated propaganda detection tool designed to nudge readers towards more critical news consumption by activating the analytical mode of thinking, following Kahneman's dual-system theory of cognition. Using Large Language Models, ClarifAI detects propaganda in news articles and provides context-rich explanations, enhancing users' understanding and critical thinking. Our contribution is threefold: first, we propose the design of ClarifAI; second, in an online experiment, we demonstrate that this design effectively encourages news readers to engage in more critical reading; and third, we emphasize the value of explanations for fostering critical thinking. The study thus offers both a practical tool and useful design knowledge for mitigating propaganda in digital news.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,24,"digital nudging, dual-system thinking, propaganda detection","Honolulu, HI, USA",CHI '24,inproceedings,491,,,,,,,,,
,"AISNS '23: Proceedings of the 2023 International Conference on Artificial Intelligence, Systems and Network Security",2023,9798400716966,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Mianyang, China",,proceedings,,,,,,,,,,
"Cassell, Justine",Socially Interactive Agents as Peers,2022,9781450398961,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3563659.3563670,,,"The Handbook on Socially Interactive Agents: 20 Years of Research on Embodied Conversational Agents, Intelligent Virtual Agents, and Social Robotics Volume 2: Interactivity, Platforms, Application",331–366,36,,,,inbook,,,,,,,,,1,
,FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language,2023,,VLDB Endowment,,https://doi.org/10.14778/3632093.3632111,10.14778/3632093.3632111,"Formatting is an important property in tables for visualization, presentation, and analysis. Spreadsheet software allows users to automatically format their tables by writing data-dependent conditional formatting (CF) rules. Writing such rules is often challenging for users as it requires understanding and implementing the underlying logic. We present FormaT5, a transformer-based model that can generate a CF rule given the target table and a natural language description of the desired formatting logic. We find that user descriptions for these tasks are often under-specified or ambiguous, making it harder for code generation systems to accurately learn the desired rule in a single step. To tackle this problem of under-specification and minimise argument errors, FormaT5 learns to predict placeholders though an abstention objective. These placeholders can then be filled by a second model or, when examples of rows that should be formatted are available, by a programming-by-example system. To evaluate FormaT5 on diverse and real scenarios, we create an extensive benchmark of 1053 CF tasks, containing real-world descriptions collected from four different sources. We release our benchmarks to encourage research in this area. Abstention and filling allow FormaT5 to outperform 8 different neural approaches on our benchmarks, both with and without examples. Our results illustrate the value of building domain-specific learning systems.",,497–510,14,,,,article,,November 2023,17,3,Proc. VLDB Endow.,nov,2150-8097,,,
,ASSETS '23: Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility,2023,9798400702204,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"New York, NY, USA",,proceedings,,,,,,,,,,
,ICITEE '23: Proceedings of the 6th International Conference on Information Technologies and Electrical Engineering,2023,9798400708299,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Changde, Hunan, China",,proceedings,,,,,,,,,,
,IVA '23: Proceedings of the 23rd ACM International Conference on Intelligent Virtual Agents,2023,9781450399944,Association for Computing Machinery,"New York, NY, USA",,,This volume contains the papers presented at the 23nd International Conference on Intelligent Virtual Agents (IVA 2023) located in W\,,,,,W\,,proceedings,,,,,,,,,,
,K-CAP '23: Proceedings of the 12th Knowledge Capture Conference 2023,2023,9798400701412,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to welcome you to the 12th ACM International Conference on Knowledge Capture: K-CAP 2023, held in person on December 5th - 7th in Pensacola, Florida, US.Driven by the increasing demands for knowledge-based applications and the unprecedented availability of information from heterogeneous data sources, the study of knowledge capture is of crucial importance. Knowledge capture involves the extraction of useful knowledge from vast and diverse data sources as well as its acquisition directly from human experts.Nowadays knowledge is derived from an increasingly diverse set of data resources that differ with regard to their domain, format, quality, coverage, specificity, viewpoint, bias, and most importantly, consumers and producers of data. The heterogeneity, amount and complexity of data allow us to answer complex questions that could not be answered in isolation, requiring the interaction of different scientific fields and technologies. A goal of K-CAP is to develop such synergies using systematic and rigorous methodologies.The call for papers attracted 105 submissions from all over the world, covering a diverse range of topics spanning knowledge mining, large language models for information extraction, neuro-symbolic approaches for knowledge capture, knowledge engineering, question-answering, knowledge graphs, natural language processing, reasoning, entity linking, querying and knowledge-based applications. From a competitive set of high-quality submissions, we accepted 27 long research papers, 5 short papers, and 1 vision paper. The high-quality program is divided into 7 research sessions, in addition to 3 tutorials reflecting novel topics of interest in Knowledge Capture.We encourage everyone to attend the keynote talks that we have planned for K-CAP 2023. The highly anticipated talks by Dr. Robert R. Hoffman (Florida Institute for Human and Machine Cognition) and Dr. Jane Pinelis (Johns Hopkins University Applied Physics Laboratory) will guide us to a better understanding of the future of knowledge capture and explainable, resilient AI ecosystems, as they become commonplace in real world applications.",,,,,"Pensacola, FL, USA",,proceedings,,,,,,,,,,
,ICMI '23 Companion: Companion Publication of the 25th International Conference on Multimodal Interaction,2023,9798400703218,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Paris, France",,proceedings,,,,,,,,,,
,IWOCL '24: Proceedings of the 12th International Workshop on OpenCL and SYCL,2024,9798400717901,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chicago, IL, USA",,proceedings,,,,,,,,,,
,SA '23: SIGGRAPH Asia 2023 Art Papers,2023,9798400703201,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
,"FAccT '23: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",2023,9798400701924,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chicago, IL, USA",,proceedings,,,,,,,,,,
,IMX '24: Proceedings of the 2024 ACM International Conference on Interactive Media Experiences,2024,9798400705038,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Stockholm, Sweden",,proceedings,,,,,,,,,,
,TAHRI '24: Proceedings of the 2024 International Symposium on Technological Advances in Human-Robot Interaction,2024,9798400716614,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Boulder, CO, USA",,proceedings,,,,,,,,,,
,"GUIDE-AI '24: Proceedings of the Conference on Governance, Understanding and Integration of Data for Effective and Responsible AI",2024,9798400706943,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Santiago, AA, Chile",,proceedings,,,,,,,,,,
,GECCO '23: Proceedings of the Genetic and Evolutionary Computation Conference,2023,9798400701191,Association for Computing Machinery,"New York, NY, USA",,,"GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).",,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
,UbiComp/ISWC '23 Adjunct: Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing &amp; the 2023 ACM International Symposium on Wearable Computing,2023,9798400702006,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Cancun, Quintana Roo, Mexico",,proceedings,,,,,,,,,,
,SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles,2023,9798400702297,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP 2023). This year's program includes 43 papers that reflect today's broad range of topics that comprise modern computer systems research. The program committee carefully reviewed submitted papers and worked closely with the authors of selected papers to produce the collection of high-quality, readable papers presented here. We hope that you enjoy the program!",,,,,"Koblenz, Germany",,proceedings,,,,,,,,,,
,AIMLSystems '23: Proceedings of the Third International Conference on AI-ML Systems,2023,9798400716492,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bangalore, India",,proceedings,,,,,,,,,,
"Rogers, David S.",Book Review: Understanding Large Language Models: Learning Their Underlying Concepts and Technologies,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3655032.3655036,10.1145/3655032.3655036,"Understanding Large Language Models: Learning Their Underlying Concepts and Technologies is written by Thimira Amaratunga and published by Apress, ©2023, paperback, ISBN-13 (pbk): 979-8-8688-0016-0, 156 pp., $44.99.",,26–27,2,,,,article,,March 2024,10,1,AI Matters,may,,,,
"Agarwal, Vibhav and Ghosh, Sourav and BSS, Harichandana and Arora, Himanshu and Raja, Barath Raj Kandur",TrICy: Trigger-Guided Data-to-Text Generation With Intent Aware Attention-Copy,2024,,IEEE Press,,https://doi.org/10.1109/TASLP.2024.3353574,10.1109/TASLP.2024.3353574,"Data-to-text (D2T) generation is a crucial task in many natural language understanding (NLU) applications and forms the foundation of task-oriented dialog systems. In the context of conversational AI solutions that can work directly with local data on the user's device, architectures utilizing large pre-trained language models (PLMs) are impractical for on-device deployment due to a high memory footprint. To this end, we propose TrICy, a novel lightweight framework for an enhanced D2T task that generates text sequences based on the intent in context and may further be guided by user-provided triggers. We leverage an attention-copy mechanism to predict out-of-vocabulary (OOV) words accurately. Performance analyses on E2E NLG dataset [Novikova et al. 2017] (BLEU: 66.43%, ROUGE-L: 70.14%), WebNLG dataset [Gardent et al. 2017] (BLEU: &lt;italic&gt;Seen&lt;/italic&gt; 64.08%, &lt;italic&gt;Unseen&lt;/italic&gt; 52.35%), and our Custom dataset related to text messaging applications, showcase our architecture's effectiveness. Moreover, we show that by leveraging an optional trigger input, data-to-text generation quality increases significantly and achieves the new SOTA score of 69.29% BLEU for E2E NLG. Furthermore, our analyses show that TrICy achieves at least 24% and 3% improvement in BLEU and METEOR respectively over LLMs like GPT-3, ChatGPT, and Llama 2. We also demonstrate that in some scenarios, performance improvement due to triggers is observed even when they are absent in training.",,1173–1184,12,,,,article,,2024,32,,"IEEE/ACM Trans. Audio, Speech and Lang. Proc.",jan,2329-9290,,,
"Perera, Minoli and Lee, Bongshin and Choe, Eun Kyoung and Marriott, Kim",Visual Cues for Data Analysis Features Amplify Challenges for Blind Spreadsheet Users,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642753,10.1145/3613904.3642753,"Spreadsheets are widely used for storing, manipulating, analyzing, and visualizing data. Features such as conditional formatting, formulas, sorting, and filtering play an important role when understanding and analyzing data in spreadsheets. They employ visual cues, but we have little understanding of the experiences of blind screen reader (SR) users with such features. We conducted a study with 12 blind SR users to gain insights into their challenges, workarounds, and strategies in understanding and extracting information from a spreadsheet consisting of multiple tables that incorporated data analysis features. We identified five factors that impact blind SR users’ experiences: cognitive overload, time-information trade-off, lack of awareness and expertise, inadequate system feedback, and delayed and absent SR responses. Drawn from these findings, we discuss design suggestions and future research agenda to improve SR users’ spreadsheet experiences.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,16,"accessibility, assistive technology, blind, data analysis, screen readers., spreadsheets, tables","Honolulu, HI, USA",CHI '24,inproceedings,42,,,,,,,,,
"Bartoldson, Brian R. and Kailkhura, Bhavya and Blalock, Davis",Compute-efficient deep learning: algorithmic trends and opportunities,2024,,JMLR.org,,,,"Although deep learning has made great progress in recent years, the exploding economic and environmental costs of training neural networks are becoming unsustainable. To address this problem, there has been a great deal of research on algorithmically-efficient deep learning, which seeks to reduce training costs not at the hardware or implementation level, but through changes in the semantics of the training program. In this paper, we present a structured and comprehensive overview of the research in this field. First, we formalize the algorithmic speedup problem, then we use fundamental building blocks of algorithmically efficient training to develop a taxonomy. Our taxonomy highlights commonalities of seemingly disparate methods and reveals current research gaps. Next, we present evaluation best practices to enable comprehensive, fair, and reliable comparisons of speedup techniques. To further aid research and applications, we discuss common bottlenecks in the training pipeline (illustrated via experiments) and offer taxonomic mitigation strategies for them. Finally, we highlight some unsolved research challenges and present promising future directions.",,,77,"deep learning, training speedup, computational efficiency, carbon emission",,,article,122,January 2023,24,1,J. Mach. Learn. Res.,mar,1532-4435,,,
,EuroMPI '23: Proceedings of the 30th European MPI Users' Group Meeting,2023,9798400709135,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bristol, United Kingdom",,proceedings,,,,,,,,,,
"Tang, Ruixiang and Feng, Qizhang and Liu, Ninghao and Yang, Fan and Hu, Xia",Did You Train on My Dataset? Towards Public Dataset Protection with CleanLabel Backdoor Watermarking,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3606274.3606279,10.1145/3606274.3606279,"The huge supporting training data on the Internet has been a key factor in the success of deep learning models. However, this abundance of public-available data also raises concerns about the unauthorized exploitation of datasets for commercial purposes, which is forbidden by dataset licenses. In this paper, we propose a backdoor-based watermarking approach that serves as a general framework for safeguarding publicavailable data. By inserting a small number of watermarking samples into the dataset, our approach enables the learning model to implicitly learn a secret function set by defenders. This hidden function can then be used as a watermark to track down third-party models that use the dataset illegally. Unfortunately, existing backdoor insertion methods often entail adding arbitrary and mislabeled data to the training set, leading to a significant drop in performance and easy detection by anomaly detection algorithms. To overcome this challenge, we introduce a clean-label backdoor watermarking framework that uses imperceptible perturbations to replace mislabeled samples. As a result, the watermarking samples remain consistent with the original labels, making them difficult to detect. Our experiments on text, image, and audio datasets demonstrate that the proposed framework effectively safeguards datasets with minimal impact on original task performance. We also show that adding just 1% of watermarking samples can inject a traceable watermarking function and that our watermarking samples are stealthy and look benign upon visual inspection.",,43–53,11,"ip protection, dataset watermarking, backdoor insertion",,,article,,June 2023,25,1,SIGKDD Explor. Newsl.,jul,1931-0145,,,
,MLNLP '22: Proceedings of the 2022 5th International Conference on Machine Learning and Natural Language Processing,2022,9781450399067,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sanya, China",,proceedings,,,,,,,,,,
,ICAIF '23: Proceedings of the Fourth ACM International Conference on AI in Finance,2023,9798400702402,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Brooklyn, NY, USA",,proceedings,,,,,,,,,,
,IoT '23: Proceedings of the 13th International Conference on the Internet of Things,2023,9798400708541,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Nagoya, Japan",,proceedings,,,,,,,,,,
,CHI PLAY Companion '23: Companion Proceedings of the Annual Symposium on Computer-Human Interaction in Play,2023,9798400700293,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Stratford, ON, Canada",,proceedings,,,,,,,,,,
"Kitamura, Kenta and Irvan, Mhd and Shigetomi Yamaguchi, Rie",XAI for Medicine by ChatGPT Code interpreter,2024,9798400708923,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3633624.3633629,10.1145/3633624.3633629,"In recent years, with the prevalence of Artificial Intelligence (AI), the interpretability of AI outputs has become a significant issue. Especially the interpretability of large language models (LLMs), including ChatGPT, has emerged as a major challenge. Consequently, there is a growing interest in the research of Explainable Artificial Intelligence (XAI), which seeks to elucidate the decision-making processes of AI in a manner that humans can comprehend. In the medical field, where trust and transparency are important, the use of AI becomes challenging when its decisions are unclear. Therefore, XAI techniques become critically important in the medical field. In this study, we propose the prompt named Code Base Prompt (CBP) to make the ChatGPT's decision-making process on medical texts explainable by using the Python code execution function of Chat GPT Code interpreter. In CBP, the medical decision-making algorithm is rewritten as Python code. Moreover, we propose an explainability evaluation system named Medical Algorithm Presentation Criteria (MAPC) for medical algorithm application tasks to medical text. MAPC is evaluated by five factors to align the human understanding process. To compare CBP with a Text Base Prompt (TBP), we conducted an experiment applying the heart failure classification algorithm to heart failure case report texts in three medical articles. With CBP, the results showed that the ChatGPT Code interpreter executed the Python code in all three cases and met all the five MAPC factors. In contrast, with TBP, no Python code execution was observed in any of the three cases, validating only one factor of MAPC. This study presents a new method for implementing XAI in the use of ChatGPT for medical tasks.",Proceedings of the 2023 5th International Conference on Big-Data Service and Intelligent Computation,28–34,7,"ChatGPT, ChatGPT Code interpreter, XAI, health care, medicine","Singapore, Singapore",BDSIC '23,inproceedings,,,,,,,,,,
,PETRA '23: Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments,2023,9798400700699,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Corfu, Greece",,proceedings,,,,,,,,,,
"Das Swain, Vedant and Saha, Koustuv","Teacher, Trainer, Counsel, Spy: How Generative AI can Bridge or Widen the Gaps in Worker-Centric Digital Phenotyping of Wellbeing",2024,9798400710179,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3663384.3663401,10.1145/3663384.3663401,"The increasing integration of computing technologies in the workplace has also seen the conceptualization and development of data-driven and algorithmic tools that aim to improve workers’ wellbeing and performance. However, both research and practice have revealed several gaps in the effectiveness and deployment of these tools. Meanwhile, the recent advances in generative AI have highlighted the tremendous capabilities of large language models (LLMs) in processing large volumes of data in producing human-interactive natural language content. This paper explores the opportunities for LLMs in facilitating worker-centered design for Wellbeing Assessment Tools (WATs). In particular, we map features of LLMs against known challenges of WAT. We highlight how the LLMs can bridge or even widen the gaps in worker-centeric WAT. This paper aims to inspire new research directions focused on empowering workers and anticipating harms in integrating LLMs with workplace technologies.",Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work,,13,"LLMs, generative AI, large language models, worker performance, worker wellbeing, workplace","Newcastle upon Tyne, United Kingdom",CHIWORK '24,inproceedings,3,,,,,,,,,
,ICIT '23: Proceedings of the 2023 11th International Conference on Information Technology: IoT and Smart City,2023,9798400709043,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Kyoto, Japan",,proceedings,,,,,,,,,,
,"BDCAT '23: Proceedings of the IEEE/ACM 10th International Conference on Big Data Computing, Applications and Technologies",2023,9798400704734,Association for Computing Machinery,"New York, NY, USA",,,"The IEEE/ACM International Conference on Big Data Computing, Applications, and Technologies (BDCAT) is a premier annual conference series aiming to provide a platform for researchers from both academia and industry to present new discoveries in the broad area of big data computing and applications.",,,,,"Taormina (Messina), Italy",,proceedings,,,,,,,,,,
,ICS '24: Proceedings of the 38th ACM International Conference on Supercomputing,2024,9798400706103,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Kyoto, Japan",,proceedings,,,,,,,,,,
,WoSC '23: Proceedings of the 9th International Workshop on Serverless Computing,2023,9798400704550,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bologna, Italy",,proceedings,,,,,,,,,,
,Are Large Language Models the New Interface for Data Pipelines?,2024,9798400706790,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3663741.3664785,10.1145/3663741.3664785,"A Language Model is a term that encompasses various types of models designed to understand and generate human communication. Large Language Models (LLMs) have gained significant attention due to their ability to process text with human-like fluency and coherence, making them valuable for a wide range of data-related tasks fashioned as pipelines. The capabilities of LLMs in natural language understanding and generation, combined with their scalability, versatility, and state-of-the-art performance, enable innovative applications across various AI-related fields, including eXplainable Artificial Intelligence (XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG). Furthermore, we believe these models can extract valuable insights and make data-driven decisions at scale, a practice commonly referred to as Big Data Analytics (BDA). In this position paper, we provide some discussions in the direction of unlocking synergies among these technologies, which can lead to more powerful and intelligent AI solutions, driving improvements in data pipelines across a wide range of applications and domains integrating humans, computers, and knowledge.",Proceedings of the International Workshop on Big Data in Emergent Distributed Environments,,6,"Automated Machine Learning, Big Data Analytic, Human-Computer Interaction, Knowledge Graphs, Natural Language Understanding, eXplainable Artificial Intelligence","Santiago, AA, Chile",BiDEDE '24,inproceedings,6,,,,,,,,,
,MMAsia '23 Workshops: Proceedings of the 5th ACM International Conference on Multimedia in Asia Workshops,2023,9798400703263,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Tainan, Taiwan",,proceedings,,,,,,,,,,
"Garcia, Kimberly and Vontobel, Jonathan and Mayer, Simon",A Digital Companion Architecture for Ambient Intelligence,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3659610,10.1145/3659610,"Ambient Intelligence (AmI) focuses on creating environments capable of proactively and transparently adapting to users and their activities. Traditionally, AmI focused on the availability of computational devices, the pervasiveness of networked environments, and means to interact with users. In this paper, we propose a renewed AmI architecture that takes into account current technological advancements while focusing on proactive adaptation for assisting and protecting users. This architecture consist of four phases: Perceive, Interpret, Decide, and Interact. The AmI systems we propose, called Digital Companions (DC), can be embodied in a variety of ways (e.g., through physical robots or virtual agents) and are structured according to these phases to assist and protect their users. We further categorize DCs into Expert DCs and Personal DCs, and show that this induces a favorable separation of concerns in AmI systems, where user concerns (including personal user data and preferences) are handled by Personal DCs and environment concerns (including interfacing with environmental artifacts) are assigned to Expert DCs; this separation has favorable privacy implications as well. Herein, we introduce this architecture and validate it through a prototype in an industrial scenario where robots and humans collaborate to perform a task.",,,26,"ambient intelligence, architecture, connected devices, digital companion systems, industrial environments, knowledge graph, mixed reality, scene graph generation algorithm",,,article,66,May 2024,8,2,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,may,,,,
,"ICBAR '23: Proceedings of the 2023 3rd International Conference on Big Data, Artificial Intelligence and Risk Management",2023,9798400716478,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Chengdu, China",,proceedings,,,,,,,,,,
"Fernandez, Raul Castro and Elmore, Aaron J. and Franklin, Michael J. and Krishnan, Sanjay and Tan, Chenhao",How Large Language Models Will Disrupt Data Management,2023,,VLDB Endowment,,https://doi.org/10.14778/3611479.3611527,10.14778/3611479.3611527,"Large language models (LLMs), such as GPT-4, are revolutionizing software's ability to understand, process, and synthesize language. The authors of this paper believe that this advance in technology is significant enough to prompt introspection in the data management community, similar to previous technological disruptions such as the advents of the world wide web, cloud computing, and statistical machine learning. We argue that the disruptive influence that LLMs will have on data management will come from two angles. (1) A number of hard database problems, namely, entity resolution, schema matching, data discovery, and query synthesis, hit a ceiling of automation because the system does not fully understand the semantics of the underlying data. Based on large training corpora of natural language, structured data, and code, LLMs have an unprecedented ability to ground database tuples, schemas, and queries in real-world concepts. We will provide examples of how LLMs may completely change our approaches to these problems. (2) LLMs blur the line between predictive models and information retrieval systems with their ability to answer questions. We will present examples showing how large databases and information retrieval systems have complementary functionality.",,3302–3309,8,,,,article,,July 2023,16,11,Proc. VLDB Endow.,jul,2150-8097,,,
,BiDEDE '24: Proceedings of the International Workshop on Big Data in Emergent Distributed Environments,2024,9798400706790,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Santiago, AA, Chile",,proceedings,,,,,,,,,,
,ICEGOV '23: Proceedings of the 16th International Conference on Theory and Practice of Electronic Governance,2023,9798400707421,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Belo Horizonte, Brazil",,proceedings,,,,,,,,,,
,WebMedia '23: Proceedings of the 29th Brazilian Symposium on Multimedia and the Web,2023,9798400709081,Association for Computing Machinery,"New York, NY, USA",,,,,,,,,,proceedings,,,,,,,,,,
,"SC '23: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis",2023,9798400701092,Association for Computing Machinery,"New York, NY, USA",,,"Started in 1988, the SC Conference has become the annual nexus for researchers and practitioners from academia, industry and government to share information and foster collaborations to advance the state of the art in High Performance Computing (HPC), Networking, Storage, and Analysis.",,,,,"Denver, CO, USA",,proceedings,,,,,,,,,,
"Bakhtin, Anton and Deng, Yuntian and Gross, Sam and Ott, Myle and Ranzato, Marc'Aurelio and Szlam, Arthur",Residual energy-based models for text,2021,,JMLR.org,,,,"Current large-scale auto-regressive language models (Radford et al., 2019; Liu et al., 2018; Graves, 2013) display impressive fluency and can generate convincing text. In this work we start by asking the question: Can the generations of these models be reliably distinguished from real text by statistical discriminators? We find experimentally that the answer is affirmative when we have access to the training data for the model, and guardedly affirmative even if we do not.This suggests that the auto-regressive models can be improved by incorporating the (globally normalized) discriminators into the generative process. We give a formalism for this using the Energy-Based Model framework, and show that it indeed improves the results of the generative models, measured both in terms of perplexity and in terms of human evaluation.",,,41,"real/fake discrimination, generalization, importance sampling, negative sampling, text generation, energy-based models",,,article,40,January 2021,22,1,J. Mach. Learn. Res.,jan,1532-4435,,,
,SIGSIM-PADS '24: Proceedings of the 38th ACM SIGSIM Conference on Principles of Advanced Discrete Simulation,2024,9798400703638,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Atlanta, GA, USA",,proceedings,,,,,,,,,,
,HotCarbon '23: Proceedings of the 2nd Workshop on Sustainable Computer Systems,2023,9798400702426,Association for Computing Machinery,"New York, NY, USA",,,"Hot Carbon focuses on understanding and addressing the negative environmental impacts of computing's success and computing's proliferation. The objective of the workshop is to foster insights and discussions as well as a growing community that focuses on sustainability of computer systems. We expect this includes innovative approaches to how we build, deploy, operate, and retire our creations, but perhaps even more. For example, software-driven hardware obsolescence that increases E-waste and embodied carbon suggests we must challenge computing's endemic upgrade and throwaway practices, and mindset.",,,,,"Boston, MA, USA",,proceedings,,,,,,,,,,
,WWW '22: Companion Proceedings of the Web Conference 2022,2022,9781450391306,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Virtual Event, Lyon, France",,proceedings,,,,,,,,,,
,Websci Companion '24: Companion Publication of the 16th ACM Web Science Conference,2024,9798400704536,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Stuttgart, Germany",,proceedings,,,,,,,,,,
"Franco, Mirko and Gaggi, Ombretta and Palazzi, Claudio E.",Analyzing the Use of Large Language Models for Content Moderation with ChatGPT Examples,2023,9798400702259,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3599696.3612895,10.1145/3599696.3612895,"Content moderation systems are crucial in Online Social Networks (OSNs). Indeed, their role is to keep platforms and their users safe from malicious activities. However, there is an emerging consensus that such systems are unfair to fragile users and minorities. Furthermore, content moderation systems are difficult to personalize and lack effective communication between users and platforms. In this context, we propose an enhancement of the current framework of content moderation, integrating Large Language Models (LLMs) in the enforcing pipeline.",Proceedings of the 3rd International Workshop on Open Challenges in Online Social Networks,1–8,8,"large language models, harmful content, content moderation","Rome, Italy",OASIS '23,inproceedings,,,,,,,,,,
,ICCIP '23: Proceedings of the 2023 9th International Conference on Communication and Information Processing,2023,9798400708909,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lingshui, China",,proceedings,,,,,,,,,,
,WDC '23: Proceedings of the 2nd Workshop on Security Implications of Deepfakes and Cheapfakes,2023,9798400702037,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Melbourne, VIC, Australia",,proceedings,,,,,,,,,,
,"IVSP '24: Proceedings of the 2024 6th International Conference on Image, Video and Signal Processing",2024,9798400716829,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Ikuta, Japan",,proceedings,,,,,,,,,,
"Kim, Tae Soo and Lee, Yoonjoo and Chang, Minsuk and Kim, Juho","Cells, Generators, and Lenses: Design Framework for Object-Oriented Interaction with Large Language Models",2023,9798400701320,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3586183.3606833,10.1145/3586183.3606833,"Large Language Models (LLMs) have become the backbone of numerous writing interfaces with the goal of supporting end-users across diverse writing tasks. While LLMs reduce the effort of manual writing, end-users may need to experiment and iterate with various generation configurations (e.g., inputs and model parameters) until results meet their goals. However, these interfaces are not designed for experimentation and iteration, and can restrict how end-users track, compare, and combine configurations. In this work, we present “cells, generators, and lenses”, a framework to designing interfaces that support interactive objects that embody configuration components (i.e., input, model, output). Interface designers can apply our framework to produce interfaces that enable end-users to create variations of these objects, combine and recombine them into new configurations, and compare them in parallel to efficiently iterate and experiment with LLMs. To showcase how our framework generalizes to diverse writing tasks, we redesigned three different interfaces—story writing, copywriting, and email composing—and, to demonstrate its effectiveness in supporting end-users, we conducted a comparative study (N=18) where participants used our interactive objects to generate and experiment more. Finally, we investigate the usability of the framework through a workshop with designers (N=3) where we observed that our framework served as both bootstrapping and inspiration in the design process.",Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,18,"Generative Models, Large Language Models, Reification, Writing-Support Tool","San Francisco, CA, USA",UIST '23,inproceedings,4,,,,,,,,,
,SIGGRAPH '23: ACM SIGGRAPH 2023 Appy Hour,2023,9798400701566,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Los Angeles, CA, USA",,proceedings,,,,,,,,,,
,FDG '23: Proceedings of the 18th International Conference on the Foundations of Digital Games,2023,9781450398558,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Lisbon, Portugal",,proceedings,,,,,,,,,,
"Ul Haq, Muhammad Uzair and Frazzetto, Paolo and Sperduti, Alessandro and Da San Martino, Giovanni",Improving Soft Skill Extraction via Data Augmentation and Embedding Manipulation,2024,9798400702433,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3605098.3636010,10.1145/3605098.3636010,"Soft skills (SS) are important for Human Resource Management when recruiting suitable candidates for a job. Nowadays, enterprises aim to automatically extract such information from documents, curriculum vitae (CVs) and job descriptions, to speed up their recruitment process. State-of-the-art Large Language Models (LLMs) have been successful in Natural Language Processing (NLP) by fine-tuning them to the domain-specific task. However, annotated data for the task is very limited and costly to obtain, since it requires domain experts. Moreover, SS consists of complex long entities which are difficult to extract given few annotated examples. As a consequence, the performance of the LLMs on soft skill detection still needs improvement before being used in a real-world context. In this paper, we introduce data augmentation based entity extraction approach which shows promising performance when the entity length is long (i.e more than three tokens). Moreover, we explore the performance of pre-trained LLMs to generate synthetic data for training. The pre-trained models are used to generate contextual augmentation of the baseline dataset. We further analyse the embeddings generated by these models in aiding the extraction process of entities. We develop an Embedding Manipulation (EM) approach to further improve the performance of baseline models. We evaluated our approach on the only publicly available dataset for soft skills (SKILLSPAN), and on three Entity Extraction datasets (GUM, WNUT-2017 and CoNLL-2003) to assess the proposed approach. Empirical evidence shows that the proposed approach allows us to get 6.52% increased F1 over the baseline model for the soft skills.",Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,987–996,10,"skill extraction, data augmentation, human resource, embeddings, NER","Avila, Spain",SAC '24,inproceedings,,,,,,,,,,
"Ivanovich, Milosh and Zukerman, Moshe and Cameron, Fraser",A study of deadlock models for a multiservice medium access protocol employing a Slotted Aloha signalling channel,2000,,IEEE Press,,https://doi.org/10.1109/90.893875,10.1109/90.893875,,,800–811,12,"protocol, deadlock, contention resolution, MAC, HFC, p-persistence",,,article,,Dec. 2000,8,6,IEEE/ACM Trans. Netw.,dec,1063-6692,,,
"Ganguli, Deep and Hernandez, Danny and Lovitt, Liane and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Dassarma, Nova and Drain, Dawn and Elhage, Nelson and El Showk, Sheer and Fort, Stanislav and Hatfield-Dodds, Zac and Henighan, Tom and Johnston, Scott and Jones, Andy and Joseph, Nicholas and Kernian, Jackson and Kravec, Shauna and Mann, Ben and Nanda, Neel and Ndousse, Kamal and Olsson, Catherine and Amodei, Daniela and Brown, Tom and Kaplan, Jared and McCandlish, Sam and Olah, Christopher and Amodei, Dario and Clark, Jack",Predictability and Surprise in Large Generative Models,2022,9781450393522,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3531146.3533229,10.1145/3531146.3533229,"Large-scale pre-training has recently emerged as a technique for creating capable, general-purpose, generative models such as GPT-3, Megatron-Turing NLG, Gopher, and many others. In this paper, we highlight a counterintuitive property of such models and discuss the policy implications of this property. Namely, these generative models have a paradoxical combination of predictable loss on a broad training distribution (as embodied in their ”scaling laws”), and unpredictable specific capabilities, inputs, and outputs. We believe that the high-level predictability and appearance of useful capabilities drives rapid development of such models, while the unpredictable qualities make it difficult to anticipate the consequences of model deployment. We go through examples of how this combination can lead to socially harmful behavior with examples from the literature and real world observations, and we also perform two novel experiments to illustrate our point about harms from unpredictability. Furthermore, we analyze how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment. We conclude with a list of possible interventions the AI community may take to increase the chance of these models having a beneficial impact. We intend for this paper to be useful to policymakers who want to understand and regulate AI systems, technologists who care about the potential policy impact of their work, funders who want to support work addressing these challenges, and academics who want to analyze, critique, and potentially develop large generative models.","Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",1747–1764,18,,"Seoul, Republic of Korea",FAccT '22,inproceedings,,,,,,,,,,
,"TEI '24: Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction",2024,9798400704024,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Cork, Ireland",,proceedings,,,,,,,,,,
,CODS-COMAD '24: Proceedings of the 7th Joint International Conference on Data Science &amp; Management of Data (11th ACM IKDD CODS and 29th COMAD),2024,9798400716348,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Bangalore, India",,proceedings,,,,,,,,,,
,OzCHI '23: Proceedings of the 35th Australian Computer-Human Interaction Conference,2023,9798400717079,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Wellington, New Zealand",,proceedings,,,,,,,,,,
,ICMI '23: Proceedings of the 25th International Conference on Multimodal Interaction,2023,9798400700552,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Paris, France",,proceedings,,,,,,,,,,
,"UMAP '24: Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,9798400704338,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Cagliari, Italy",,proceedings,,,,,,,,,,
,BDMIP '23: Proceedings of the 2023 International Conference on Big Data Mining and Information Processing,2023,9798400709166,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Xiamen City, China, China",,proceedings,,,,,,,,,,
,VINCI '23: Proceedings of the 16th International Symposium on Visual Information Communication and Interaction,2023,9798400707513,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Guangzhou, China",,proceedings,,,,,,,,,,
,"MobiHoc '23: Proceedings of the Twenty-fourth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing",2023,9781450399265,Association for Computing Machinery,"New York, NY, USA",,,ACM MobiHoc is a premier international annual conference with a highly selective single-track technical program dedicated to addressing the challenges emerging from networked systems that must operate in the face of dynamics.,,,,,"Washington, DC, USA",,proceedings,,,,,,,,,,
,ICSeB '23: Proceedings of the 2023 7th International Conference on Software and e-Business,2023,9798400717239,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Osaka, Japan",,proceedings,,,,,,,,,,
,"LCTES 2024: Proceedings of the 25th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems",2024,9798400706165,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES 2024), the 25th edition of this longstanding conference! This year’s conference is co-located with PLDI 2024, bringing together affiliated research conferences and workshops into a week-long joint meeting in Copenhagen, Denmark. The mission of LCTES is to provide a link between languages, compilers, and tools for embedded systems, bringing together scientists and engineers from these communities. LCTES offers a forum for researchers and developers from either area to come together, interact, share insights, and collaborate on developing novel solutions.",,,,,"Copenhagen, Denmark",,proceedings,,,,,,,,,,
,ACSAC '23: Proceedings of the 39th Annual Computer Security Applications Conference,2023,9798400708862,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Austin, TX, USA",,proceedings,,,,,,,,,,
"Varanasi, Rama Adithya and Goyal, Nitesh",“It is currently hodgepodge”: Examining AI/ML Practitioners’ Challenges during Co-production of Responsible AI Values,2023,9781450394215,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3544548.3580903,10.1145/3544548.3580903,"Recently, the AI/ML research community has indicated an urgent need to establish Responsible AI (RAI) values and practices as part of the AI/ML lifecycle. Several organizations and communities are responding to this call by sharing RAI guidelines. However, there are gaps in awareness, deliberation, and execution of such practices for multi-disciplinary ML practitioners. This work contributes to the discussion by unpacking co-production challenges faced by practitioners as they align their RAI values. We interviewed 23 individuals, across 10 organizations, tasked to ship AI/ML based products while upholding RAI norms and found that both top-down and bottom-up institutional structures create burden for different roles preventing them from upholding RAI values, a challenge that is further exacerbated when executing conflicted values. We share multiple value levers used as strategies by the practitioners to resolve their challenges. We end our paper with recommendations for inclusive and equitable RAI value-practices, creating supportive organizational structures and opportunities to further aid practitioners.",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,,17,"FAT, RAI, Responsible AI, XAI, accountability, co-production, collaboration, ethical AI, explainability, fairness, transparency, value levers","Hamburg, Germany",CHI '23,inproceedings,251,,,,,,,,,
,AISec '23: Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security,2023,9798400702600,Association for Computing Machinery,"New York, NY, USA",,,"It is our pleasure to welcome you to the 16th ACM Workshop on Artificial Intelligence and Security - AISec 2023. AISec, having been annually co-located with CCS for 16 consecutive years, is the premier meeting place for researchers interested in the intersection of security, privacy, AI, and machine learning. Its role as a venue has been to merge practical security problems with advances in AI and machine learning. In doing so, researchers have also been developing theories and analytics unique to this domain and have explored diverse topics such as learning in gametheoretic adversarial environments, privacy-preserving learning, and applications to malware, spam, and intrusion detection. AISec 2022 received 64 submissions, of which 21 (35%) were selected for publication and presentation as full papers. Submissions arrived from researchers in many different countries, and from a wide variety of institutions, both academic and corporate.",,,,,"Copenhagen, Denmark",,proceedings,,,,,,,,,,
,"EAAMO '23: Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization",2023,9798400703812,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Boston, MA, USA",,proceedings,,,,,,,,,,
,"CACML '24: Proceedings of the 2024 3rd Asia Conference on Algorithms, Computing and Machine Learning",2024,9798400716416,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Shanghai, China",,proceedings,,,,,,,,,,
,BiDEDE '23: Proceedings of the International Workshop on Big Data in Emergent Distributed Environments,2023,9798400700934,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Seattle, WA, USA",,proceedings,,,,,,,,,,
,ICMR '23: Proceedings of the 2023 ACM International Conference on Multimedia Retrieval,2023,9798400701788,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Thessaloniki, Greece",,proceedings,,,,,,,,,,
,ACM MobiCom '24: Proceedings of the 30th Annual International Conference on Mobile Computing and Networking,2024,9798400704895,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Washington D.C., DC, USA",,proceedings,,,,,,,,,,
,MUM '23: Proceedings of the 22nd International Conference on Mobile and Ubiquitous Multimedia,2023,9798400709210,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Vienna, Austria",,proceedings,,,,,,,,,,
"Parraga, Otavio and More, Martin D. and Oliveira, Christian M. and Gavenski, Nathan S. and Kupssinsk\",Fairness in Deep Learning: A Survey on Vision and Language Research,2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3637549,10.1145/3637549,"Despite being responsible for state-of-the-art results in several computer vision and natural language processing tasks, neural networks have faced harsh criticism due to some of their current shortcomings. One of them is that neural networks are correlation machines prone to model biases within the data instead of focusing on actual useful causal relationships. This problem is particularly serious in application domains affected by aspects such as race, gender, and age. To prevent models from incurring unfair decision-making, the AI community has concentrated efforts on correcting algorithmic biases, giving rise to the research area now widely known as fairness in AI. In this survey paper, we provide an in-depth overview of the main debiasing methods for fairness-aware neural networks in the context of vision and language research. We propose a novel taxonomy that builds upon previous proposals but is tailored for deep learning research to better organize the literature on debiasing methods for fairness. We review all important neural-based methods and evaluation metrics while discussing the current challenges, trends, and important future work directions for the interested researcher and practitioner.",,,,"deep learning, natural language processing, computer vision, bias mitigation, neural networks, fairness",,,article,,,,,ACM Comput. Surv.,dec,0360-0300,Just Accepted,,
,CHCHI '23: Proceedings of the Eleventh International Symposium of Chinese CHI,2023,9798400716454,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Denpasar, Bali, Indonesia",,proceedings,,,,,,,,,,
,ICMVA '24: Proceedings of the 2024 7th International Conference on Machine Vision and Applications,2024,9798400716553,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Singapore, Singapore",,proceedings,,,,,,,,,,
,e-Energy '24: Proceedings of the 15th ACM International Conference on Future and Sustainable Energy Systems,2024,9798400704802,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Singapore, Singapore",,proceedings,,,,,,,,,,
,"CMLDS '24: Proceedings of the International Conference on Computing, Machine Learning and Data Science",2024,9798400716393,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Singapore, Singapore",,proceedings,,,,,,,,,,
"LC, RAY and Tang, Yuying",Speculative Design with Generative AI: Applying Stable Diffusion and ChatGPT to imagining climate change futures,2024,9798400708725,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3632776.3632827,10.1145/3632776.3632827,"Policy mandates in addressing climate change are hindered by a lack of intrinsic motivation amongst participants to take collective action. Instead of overt persuasion, this study applied generative AI tools to speculative imagining of future climate scenarios and their adaptation strategies, using a workshop to encourage participants to align themselves with climate action. Participants used text-to-image tools to generate visions of the future in speculative scenarios, then prompted ChatGPT for potential solutions in these scenarios. They then asked text-to-image again to visualize the ChatGPT suggestions. Participants encountered difficulties editing or removing visual elements, dealt with the lack of transparency in the generation process by specifying the physical layout as opposed to the semantics, and collaboratively developed linguistic strategies for visual depiction of novel artifacts. This work shows how generative tools can be used to prototype future scenarios and envision designs that serve social purposes.",Proceedings of the 11th International Conference on Digital and Interactive Arts,,8,"ChatGPT, Stable diffusion, climate change, co-design workshop, prompt design, speculative design","Faro, Portugal",ARTECH '23,inproceedings,36,,,,,,,,,
,WEBSCI '24: Proceedings of the 16th ACM Web Science Conference,2024,9798400703348,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Stuttgart, Germany",,proceedings,,,,,,,,,,
,SIGSPATIAL '23: Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems,2023,9798400701689,Association for Computing Machinery,"New York, NY, USA",,,"The conference started as a series of workshops and symposia back in 1993 with the aim of promoting interdisciplinary discussions among researchers, developers, users, and practitioners and fostering research in all aspects of geographic information systems, especially in relation to novel systems based on geospatial data and knowledge. It continues to provide a forum for original research contributions covering all conceptual, design and implementation aspects of geospatial data ranging from applications, user interfaces and visualization, to data storage, query processing, indexing, machine learning and data mining. The conference is the premier annual event of the ACM Special Interest Group on Spatial Information (ACM SIGSPATIAL).",,,,,"Hamburg, Germany",,proceedings,,,,,,,,,,
,SBGames '23: Proceedings of the 22nd Brazilian Symposium on Games and Digital Entertainment,2023,9798400716270,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rio Grande (RS), Brazil",,proceedings,,,,,,,,,,
,dg.o '23: Proceedings of the 24th Annual International Conference on Digital Government Research,2023,9798400708374,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Gda?sk, Poland",,proceedings,,,,,,,,,,
,APNET '23: Proceedings of the 7th Asia-Pacific Workshop on Networking,2023,9798400707827,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hong Kong, China",,proceedings,,,,,,,,,,
,"MobiSys '23: Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services",2023,9798400701108,Association for Computing Machinery,"New York, NY, USA",,,"On behalf of the entire organizing committee, it is with immense pleasure that we welcome you to the 21st ACM International Conference on Mobile Systems, Applications, and Services (ACM MobiSys 2023) hosted in Helsinki, Finland on June 18 - 22, 2023. ACM MobiSys is the leading conference in research on mobile systems, applications and services, and a flagship conference of ACM SIGMOBILE.",,,,,"Helsinki, Finland",,proceedings,,,,,,,,,,
"Murray, John T. and Murray, Jack and Salter, Anastasia",Playing with AI Chat: Positioning “Dangerous” Language Model Futures through Interactive Fiction,2023,9798400703362,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3615335.3623015,10.1145/3615335.3623015,"Large language models (LLMs) use statistical models to predict the next sequence of tokens and have capabilities previously considered unattainable outside of human intelligence. Communication design can benefit from a close examination of the ongoing conversations around the adoption and use of LLMs, both the public discourse and the specific language and rhetoric used in the initial set of application interfaces and prompts. Through a survey of existing practices and a case study of how AI is used within the interactive fiction community, where procedural content generation has played with expectations and personas, this paper offers a foundation for future critique of these models as they are embedded in the digital tools we rely upon for daily communication and work.",Proceedings of the 41st ACM International Conference on Design of Communication,82–88,7,"AI Dungeon, Bard, Bing Chat, Chat Interfaces, ChatGPT, GPT-4, Large-Language Models","Orlando, FL, USA",SIGDOC '23,inproceedings,,,,,,,,,,
,EuroSys '24: Proceedings of the Nineteenth European Conference on Computer Systems,2024,9798400704376,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Athens, Greece",,proceedings,,,,,,,,,,
,ChatGeppetto - an AI-powered Storyteller,2024,9798400716270,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3631085.3631302,10.1145/3631085.3631302,"In this paper we introduce a novel highly interactive process to generate natural language narratives on the basis of our ongoing work on semiotic relations. To the two basic components of interactive systems, namely, a software tool and a user interface, we add a third component – AI agents, understood as an upgraded rendition of software agents. Our semiotic relations approach considers four ways of composing new narratives from existing narratives. Along what semioticians call the horizontal syntagmatic axis, one can form the new narrative by combining two or more previous narratives. Along the vertical paradigmatic axis, the new narrative may emerge as a similar version, which imitates the previous one, possibly in a different context. Along the depth meronymic axis, the hierarchic narrative levels, such as plot, event, and scene, are explored, allowing either expansion or summarization. Lastly, the antithetic consideration, rather than adding a dimension, aims at some form of reversal, through the adoption of opposite values. A fully operational prototype is described. Its name, ChatGeppetto, conflates the skilled Geppetto, who fashioned Pinocchio, an early case of artisanship-produced human level intelligence, with ChatGPT, which operates as the main AI agent component. To run the experiments, we concentrated on book narratives.",Proceedings of the 22nd Brazilian Symposium on Games and Digital Entertainment,28–37,10,"Artificial Intelligence, Book Narratives, ChatGPT, Chatbots, Interactive Story Composition, Semiotic Relations, Storyboards","Rio Grande (RS), Brazil",SBGames '23,inproceedings,,,,,,,,,,
,AIPR '22: Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition,2022,9781450396899,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Xiamen, China",,proceedings,,,,,,,,,,
"Weisz, Justin D. and He, Jessica and Muller, Michael and Hoefer, Gabriela and Miles, Rachel and Geyer, Werner",Design Principles for Generative AI Applications,2024,9798400703300,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3613904.3642466,10.1145/3613904.3642466,"Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.",Proceedings of the CHI Conference on Human Factors in Computing Systems,,22,"Generative AI, design principles, foundation models, human-centered AI","Honolulu, HI, USA",CHI '24,inproceedings,378,,,,,,,,,
,N-gram-based Machine Translation,2006,,MIT Press,"Cambridge, MA, USA",https://doi.org/10.1162/coli.2006.32.4.527,10.1162/coli.2006.32.4.527,"This article describes in detail an n-gram approach to statistical machine translation. This approach consists of a log-linear combination of a translation model based on n-grams of bilingual units, which are referred to as tuples, along with four specific feature functions. Translation performance, which happens to be in the state of the art, is demonstrated with Spanish-to-English and English-to-Spanish translations of the European Parliament Plenary Sessions (EPPS).",,527–549,23,,,,article,,December 2006,32,4,Comput. Linguist.,dec,0891-2017,,,
,MMAsia '23: Proceedings of the 5th ACM International Conference on Multimedia in Asia,2023,9798400702051,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Tainan, Taiwan",,proceedings,,,,,,,,,,
,SUI '23: Proceedings of the 2023 ACM Symposium on Spatial User Interaction,2023,9798400702815,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
"Freedman, Richard G.",2025 EAAI Mentored Undergraduate Research Challenge: Playing Word Association Games,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3655032.3655035,10.1145/3655032.3655035,"The topic for EAAI 2025's Mentored Undergraduate Research Challenge is PlayingWord Association Games. What does that mean? Where are the applications? How can you get started? We break down the topic, discuss applications, and explore project ideas in this column.",,16–25,10,,,,article,,March 2024,10,1,AI Matters,may,,,,
,ICIGP '24: Proceedings of the 2024 7th International Conference on Image and Graphics Processing,2024,9798400716720,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Beijing, China",,proceedings,,,,,,,,,,
,AIPR '23: Proceedings of the 2023 6th International Conference on Artificial Intelligence and Pattern Recognition,2023,9798400707674,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Xiamen, China",,proceedings,,,,,,,,,,
"Kelley, Dean",Technical Report Column,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3674159.3674162,10.1145/3674159.3674162,"Welcome to the Technical Reports Column. If your institution publishes technical reports that you'd like to have included here, please contact me at the email address above.",,25–37,13,,,,article,,June 2024,55,2,SIGACT News,jun,0163-5700,,,
,WiSec '24: Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks,2024,9798400705823,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to the 2024 ACM Conference on Security and Privacy in Wireless and Mobile Networks (ACM WiSec)!Now in its 17th year, WiSec continues to be the premier venue for research on all aspects of security and privacy in wireless and mobile networks, their systems, and their applications. We are hosted by the Korea Institute of Information Security &amp; Cryptology, located in the city center of Seoul, Korea - a city known for its dynamic mix of 600-year-old palaces and the contemporary urban landscape characterized by towering skyscrapers.We begin our exciting three-day main conference program on May 27th with single-track technical paper sessions, a poster and demo session, two excellent keynotes from telecommunication security expert Prof. Jean-Pierre Seifert (TU Berlin) and wireless security expert Mathy Vanhoef (KU Leuven), and a panel on wireless security and AI. Three invited talks named ",,,,,"Seoul, Republic of Korea",,proceedings,,,,,,,,,,
,SA '15: SIGGRAPH Asia 2015 Technical Briefs,2015,9781450339308,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Kobe, Japan",,proceedings,,,,,,,,,,
,SenSys '22: Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems,2022,9781450398862,Association for Computing Machinery,"New York, NY, USA",,,"Welcome to ACM SenSys 2022, the 20th ACM Conference on Embedded Networked Sensor Systems, the premier computer systems conference focused on networked sensing systems and applications.",,,,,"Boston, Massachusetts",,proceedings,,,,,,,,,,
"Jia, Qi and Liu, Yizhu and Ren, Siyu and Zhu, Kenny Q.","Taxonomy of Abstractive Dialogue Summarization: Scenarios, Approaches, and Future Directions",2023,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3622933,10.1145/3622933,"Abstractive dialogue summarization generates a concise and fluent summary covering the salient information in a dialogue among two or more interlocutors. It has attracted significant attention in recent years based on the massive emergence of social communication platforms and an urgent requirement for efficient dialogue information understanding and digestion. Different from news or articles in traditional document summarization, dialogues bring unique characteristics and additional challenges, including different language styles and formats, scattered information, flexible discourse structures, and unclear topic boundaries. This survey provides a comprehensive investigation of existing work for abstractive dialogue summarization from scenarios, approaches to evaluations. It categorizes the task into two broad categories according to the type of input dialogues, i.e., open-domain and task-oriented, and presents a taxonomy of existing techniques in three directions, namely, injecting dialogue features, designing auxiliary training tasks, and using additional data. A list of datasets under different scenarios and widely accepted evaluation metrics are summarized for completeness. After that, the trends of scenarios and techniques are summarized, together with deep insights into correlations between extensively exploited features and different scenarios. Based on these analyses, we recommend future directions, including more controlled and complicated scenarios, technical innovations and comparisons, publicly available datasets in special domains, and so on.",,,38,"abstractive summarization, dialogue context modeling, Dialogue summarization",,,article,67,March 2024,56,3,ACM Comput. Surv.,oct,0360-0300,,,
"Rohan, Rohani and Faruk, Lawal Ibrahim Dutsinma and Puapholthep, Kittiphan and Pal, Debajyoti",Unlocking the Black Box: Exploring the use of Generative AI (ChatGPT) in Information Systems Research,2023,9798400708497,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3628454.3629998,10.1145/3628454.3629998,"With the gaining popularity of generative AI tools like ChatGPT and their usage across several domains and disciplines, the question that naturally arises is how it can help the Information Systems (IS) researchers? Measuring hidden or latent constructs is one critical and primitive aspects of the IS domain that has always been challenging due to its abstractness. How good or bad these specially trained AI-based models are with respect to their conceptual understanding capabilities of specific IS constructs together with their usage for the purpose of testing IS theories is an unknown area. We set out to explore these unknown aspects in this work by conducting two separate experiments with ChatGPT using the already proven and robust Technology Acceptance Model (TAM) as the reference. Our results suggest that ChatGPT has good conceptual understanding of the presented latent constructs, although there might be certain validity issues in case of complex models. Therefore, it shows promise in the broader aspect of testing theories, but not without its limitations that we present in this research.",Proceedings of the 13th International Conference on Advances in Information Technology,,9,"ChatGPT, information systems, latent constructs, scale, technology acceptance model","Bangkok, Thailand",IAIT '23,inproceedings,17,,,,,,,,,
,"MOBISYS '24: Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services",2024,9798400705816,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Minato-ku, Tokyo, Japan",,proceedings,,,,,,,,,,
,ARTECH '23: Proceedings of the 11th International Conference on Digital and Interactive Arts,2023,9798400708725,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Faro, Portugal",,proceedings,,,,,,,,,,
,SocialTruth Project Approach to Online Disinformation (Fake News) Detection and Mitigation,2019,9781450371643,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3339252.3341497,10.1145/3339252.3341497,"The extreme growth and adoption of Social Media, in combination with their poor governance and the lack of quality control over the digital content being published and shared, has led information veracity to a continuous deterioration. Current approaches entrust content verification to a single centralised authority, lack resilience towards attempts to successfully ","Proceedings of the 14th International Conference on Availability, Reliability and Security",,10,"security, safety, pattern recognition, networks, fake news, detection","Canterbury, CA, United Kingdom",ARES '19,inproceedings,68,,,,,,,,,
,"RAID '23: Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses",2023,9798400707650,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Hong Kong, China",,proceedings,,,,,,,,,,
,MMVE '24: Proceedings of the 16th International Workshop on Immersive Mixed and Virtual Environment Systems,2024,9798400706189,Association for Computing Machinery,"New York, NY, USA",,,"We are pleased to present the technical program of the 16th ACM International Workshop on Immersive Mixed and Virtual Environment systems (MMVE) 2024. This workshop has always embraced a multidisciplinary approach, exploring not only the evolution of immersive experiences but also the crossroads where immersive technology intersects with diverse domains. Co-located with ACM Multimedia Systems Conference (MMSys) 2024, MMVE allows the gathering and interaction of researchers in the field of immersive technology, from both academia and industry, with multimedia system researchers.",,,,,"Bari, Italy",,proceedings,,,,,,,,,,
,IoTDI '23: Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation,2023,9798400700378,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"San Antonio, TX, USA",,proceedings,,,,,,,,,,
,"Seminal Graphics Papers: Pushing the Boundaries, Volume 2",2023,9798400708978,Association for Computing Machinery,"New York, NY, USA",,,"When we began planning how to celebrate 50 years of SIGGRAPH Conferences, there was unanimous agreement that one of the projects should be publishing a second volume of Seminal Graphics Papers. The first volume was published in 1998 as part of the celebration of the 25th SIGGRAPH conference. Seminal Graphics Papers Volume 2, perhaps more than any other activity undertaken in this milestone year, celebrates ACM SIGGRAPH's origins and continued success as a Technical and Professional Society. This collection of papers typifies the ground-breaking research that has been the conference's hallmark since 1974. A quick scan of the chapter and the paper titles shows just how far SIGGRAPH research has pushed the boundaries of our discipline and contributed to its evolution.The ACM Digital Library team has been supportive of this Seminal Graphics Papers project from the beginning. I am pleased to let you know that both Volumes 1 and 2 of Seminal Graphics Papers are freely available from the ACM Digital Library at these URLs: Volume 1: https://dl.acm.org/doi/book/10.1145/280811Volume 2: https://dl.acm.org/doi/book/10.1145/3596711",,,,,,,book,,,Volume 2,,,,,,1,"Whitton, Mary C."
,ICS '23: Proceedings of the 37th ACM International Conference on Supercomputing,2023,9798400700569,Association for Computing Machinery,"New York, NY, USA",,,ICS is a well-known and outstanding forum for the presentation of significant research in high performance computing.,,,,,"Orlando, FL, USA",,proceedings,,,,,,,,,,
,ISCA '23: Proceedings of the 50th Annual International Symposium on Computer Architecture,2023,9798400700958,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Orlando, FL, USA",,proceedings,,,,,,,,,,
,Discriminative Phrase-Based Models for Arabic Machine Translation,2009,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/1644879.1644882,10.1145/1644879.1644882,"A design for an Arabic-to-English translation system is presented. The core of the system implements a standard phrase-based statistical machine translation architecture, but it is extended by incorporating a local discriminative phrase selection model to address the semantic ambiguity of Arabic. Local classifiers are trained using linguistic information and context to translate a phrase, and this significantly increases the accuracy in phrase selection with respect to the most frequent translation traditionally considered. These classifiers are integrated into the translation system so that the global task gets benefits from the discriminative learning. As a result, we obtain significant improvements in the full translation task at the lexical, syntactic, and semantic levels as measured by an heterogeneous set of automatic evaluation metrics.",,,20,"statistical machine translation, discriminative learning, English, Arabic",,,article,15,December 2009,8,4,ACM Transactions on Asian Language Information Processing,dec,1530-0226,,,
,MMSys '24: Proceedings of the 15th ACM Multimedia Systems Conference,2024,9798400704123,Association for Computing Machinery,"New York, NY, USA",,,"Dear MMSys 2024 Participants,On behalf of the organizers, we are very pleased to welcome you to the 15th ACM Multimedia Systems Conference, taking place for the first time in Italy, in the city of Bari.MMSys is a premier conference dedicated to the exciting and multidisciplinary field of multimedia, with a specific focus on its systems and applications. The conference provides a platform for researchers from both academia and industry to share their latest findings in the multimedia systems research area. Many international researchers, practitioners, engineers, and students from academia, industry, standardization bodies, and government agencies join the MMSys conference each year.",,,,,"Bari, Italy",,proceedings,,,,,,,,,,
,EuroSys '23: Proceedings of the Eighteenth European Conference on Computer Systems,2023,9781450394871,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rome, Italy",,proceedings,,,,,,,,,,
,ASHES '23: Proceedings of the 2023 Workshop on Attacks and Solutions in Hardware Security,2023,9798400702624,Association for Computing Machinery,"New York, NY, USA",,,"It is our great pleasure to welcome you to the Seventh Workshop on Attacks and Solutions in Hardware Security 2023 (ASHES 2023), a post-conference satellite workshop of the ACM Conference on Computer and Communications Security 2023 (CCS 2023).ASHES deals with all theoretical and practical aspects of hardware security and welcomes any contributions to this area. Besides being a mainstream platform for disseminating fundamental research, the workshop also encourages and promotes emerging and new ideas. This includes diverse topics such as physical attacks, secure hardware designs and implementations, lightweight secure systems, post-quantum security, as well as emerging topics at the intersection of nanotechnology and security, such as physical unclonable functions (PUFs). The workshop also puts a particular focus on recent applications like the internet of things, automotive security, smart homes, or pervasive and wearable computing. ASHES thereby aims at giving researchers and practitioners a unique opportunity to share their perspectives.",,,,,"Copenhagen, Denmark",,proceedings,,,,,,,,,,
,ICPP '23: Proceedings of the 52nd International Conference on Parallel Processing,2023,9798400708435,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Salt Lake City, UT, USA",,proceedings,,,,,,,,,,
,"BuildSys '23: Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation",2023,9798400702303,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Istanbul, Turkey",,proceedings,,,,,,,,,,
,ACM MobiCom '23: Proceedings of the 29th Annual International Conference on Mobile Computing and Networking,2023,9781450399906,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Madrid, Spain",,proceedings,,,,,,,,,,
,SenSys '23: Proceedings of the 21st ACM Conference on Embedded Networked Sensor Systems,2023,9798400704147,Association for Computing Machinery,"New York, NY, USA",,,"SenSys is a highly selective, single-track forum for cutting-edge research on systems issues of sensors and sensor-enabled smart systems. Built on the community's effort over the years, the 21st episode marks the beginning of its 3rd decade.",,,,,"Istanbul, Turkiye",,proceedings,,,,,,,,,,
,SIGSPATIAL '22: Proceedings of the 30th International Conference on Advances in Geographic Information Systems,2022,9781450395298,Association for Computing Machinery,"New York, NY, USA",,,"The conference started as a series of workshops and symposia back in 1993 with the aim of promoting interdisciplinary discussions among researchers, developers, users, and practitioners and fostering research in all aspects of geographic information systems, especially in relation to novel systems based on geospatial data and knowledge. It continues to provide a forum for original research contributions covering all conceptual, design and implementation aspects of geospatial data ranging from applications, user interfaces and visualization, to data storage, query processing, indexing, machine learning and data mining. The conference is the premier annual event of the ACM Special Interest Group on Spatial Information (ACM SIGSPATIAL).",,,,,"Seattle, Washington",,proceedings,,,,,,,,,,
,AutomotiveUI '23 Adjunct: Adjunct Proceedings of the 15th International Conference on Automotive User Interfaces and Interactive Vehicular Applications,2023,9798400701122,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Ingolstadt, Germany",,proceedings,,,,,,,,,,
"Priya, Priyanshu and Firdaus, Mauajama and Ekbal, Asif",Computational Politeness in Natural Language Processing: A Survey,2024,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/3654660,10.1145/3654660,"Computational approach to politeness is the task of automatically predicting and/or generating politeness in text. This is a pivotal task for conversational analysis, given the ubiquity and challenges of politeness in interactions. The computational approach to politeness has witnessed great interest from the conversational analysis community. This article is a compilation of past works in computational politeness in natural language processing. We view four milestones in the research so far, viz. supervised and weakly supervised feature extraction to identify and induce politeness in a given text, incorporation of context beyond the target text, study of politeness across different social factors, and study the relationship between politeness and various socio-linguistic cues. In this article, we describe the datasets, approaches, trends, and issues in computational politeness research. We also discuss representative performance values and provide pointers to future works, as given in the prior works. In terms of resources to understand the state of the art, this survey presents several valuable illustrations—most prominently, a table summarizing the past papers along different dimensions, such as the types of features, annotation techniques, and datasets used.",,,42,"Politeness, (im)politeness, computational politeness, linguistic variations, politeness analysis",,,article,241,September 2024,56,9,ACM Comput. Surv.,may,0360-0300,,,
,MEMSYS '23: Proceedings of the International Symposium on Memory Systems,2023,9798400716447,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Alexandria, VA, USA",,proceedings,,,,,,,,,,
,SA '23: SIGGRAPH Asia 2023 Technical Communications,2023,9798400703140,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
,PODC '24: Proceedings of the 43rd ACM Symposium on Principles of Distributed Computing,2024,9798400706684,Association for Computing Machinery,"New York, NY, USA",,,"PODC is the premier forum for presentation of research on all aspects of distributed computing, including the theory, design, implementation, and applications of distributed algorithms, systems, and networks.",,,,,"Nantes, France",,proceedings,,,,,,,,,,
,ACM SIGCOMM '23: Proceedings of the ACM SIGCOMM 2023 Conference,2023,9798400702365,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"New York, NY, USA",,proceedings,,,,,,,,,,
,SA '23: SIGGRAPH Asia 2023 Conference Papers,2023,9798400703157,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Sydney, NSW, Australia",,proceedings,,,,,,,,,,
,LSC '23: Proceedings of the 6th Annual ACM Lifelog Search Challenge,2023,9798400701887,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Thessaloniki, Greece",,proceedings,,,,,,,,,,
,ASIA CCS '23: Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security,2023,9798400700989,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Melbourne, VIC, Australia",,proceedings,,,,,,,,,,
,"ICVGIP '23: Proceedings of the Fourteenth Indian Conference on Computer Vision, Graphics and Image Processing",2023,9798400716256,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rupnagar, India",,proceedings,,,,,,,,,,
,SIGGRAPH '23: ACM SIGGRAPH 2023 Conference Proceedings,2023,9798400701597,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Los Angeles, CA, USA",,proceedings,,,,,,,,,,
,MICRO '23: Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture,2023,9798400703294,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Toronto, ON, Canada",,proceedings,,,,,,,,,,
,SoCC '23: Proceedings of the 2023 ACM Symposium on Cloud Computing,2023,9798400703874,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Santa Cruz, CA, USA",,proceedings,,,,,,,,,,
,CoNEXT '22: Proceedings of the 18th International Conference on emerging Networking EXperiments and Technologies,2022,9781450395083,Association for Computing Machinery,"New York, NY, USA",,,"CoNEXT is a premier and highly selective venue in computer networking. This year's exciting technical program helps us better understand and improve the performance, reliability and security of networks in all layers.",,,,,"Roma, Italy",,proceedings,,,,,,,,,,
,"MIG '23: Proceedings of the 16th ACM SIGGRAPH Conference on Motion, Interaction and Games",2023,9798400703935,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"Rennes, France",,proceedings,,,,,,,,,,
"Eerkes, Gary L.",Profiling computer science master's programs,1991,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/99977.99999,10.1145/99977.99999,"Master's level computer science programs have experienced significant and sustained growth during the past two decades. According to the U.S. Department of Education's National Center for Education Statistics [4], a total of 1,588 master's degrees were conferred in computer and information sciences in 1971. This figure increased 508% to 8,070 in 1986—a larger percentage increase than any other major discipline. The 1970s and 1980s have also been an era in which computer science has experienced major theoretical and technological advances. The period has been marked by severe faculty shortages which are only now beginning to ease. Complicating matters further, the discipline is so young that it is still in the process of defining its intellectual framework [3]. Considering all of these factors, it is not surprising that there is a considerable amount of diversity and flux among computer science master's programs. What is surprising, however, is that little data is available pertaining to this degree.",,100–109,10,,,,article,,Jan. 1991,34,1,Commun. ACM,jan,0001-0782,,,
"Baruch, Marjory",An experience is worth 1K words,1986,0897911784,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/5600.5696,10.1145/5600.5696,"An introductory computer science course is presented which uses new techniques appropriate for a liberal arts college. Students learn standard topics by means of a series of guided labs in which they are active participants. The students learn to question, analyse, and construct examples, thereby acquiring the means for further inquiry and understanding. Irrelevant stumbling blocks are minimized in the hope that the positive learning process will be something they continue on their own.",Proceedings of the Seventeenth SIGCSE Technical Symposium on Computer Science Education,238–245,8,,"Cincinnati, Ohio, USA",SIGCSE '86,inproceedings,,,,,,,,,,
"Masuda, Gou and Sakamoto, Norihiro and Ushijima, Kazuo",Applying design patterns to decision tree learning system,1998,1581131089,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/288195.288279,10.1145/288195.288279,In this paper we describe an application of design patterns to the development of a decision tree learning system. A decision tree learning system constructs a classifier as a form of tree from a given data set. It is required to be as flexible as possible when used in real application domains. Design patterns help us construct reusable software components and construct flexible and extensible systems. The approach employed in this study is as follows. First we examine several decision tree learning systems and identify hot-spots in the systems at points we anticipate future demand for modification and extension of the system. Second we determine which design pattern to apply to each hot-spot. We evaluate the extensibility of the system experimentally. Our experience shows that using design patterns in object-oriented software design allows the easy construction of flexible systems.,Proceedings of the 6th ACM SIGSOFT International Symposium on Foundations of Software Engineering,111–120,10,"decision tree learning, design pattern, object-oriented software development","Lake Buena Vista, Florida, USA",SIGSOFT '98/FSE-6,inproceedings,,,,,,,,,,
"Lukey, Trevor and Loose, Kenneth and Hill, David R.",Implementation of a debugging aid for logic errors in Pascal programs,1987,0897912179,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/31820.31792,10.1145/31820.31792,"This paper describes a debugging utility with some tutorial capabilities. It is designed to assist novice programmers in finding logic errors in syntactically correct programs. Flow and use analysis techniques are employed to aid in the recognition of some instances of incorrect code sequence, improper variable use and improper nesting of constructs. The utility is menu driven with built in facilities for displaying user source programs and debugging information in a multiple window format.",Proceedings of the Eighteenth SIGCSE Technical Symposium on Computer Science Education,386–390,5,,"St. Louis, Missouri, USA",SIGCSE '87,inproceedings,,,,,,,,,,
"Pargas, Roy P. and Ludwick, Jennifer and Spoon, Steven",Hybrid search algorithms,1997,0897918509,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/331697.331752,10.1145/331697.331752,,Proceedings of the 1997 ACM Symposium on Applied Computing,269–273,5,"dynamical systems, optimization, parallel processing","San Jose, California, USA",SAC '97,inproceedings,,,,,,,,,,
"Banach, Richard and Papadopoulos, George A.",Implementing interaction nets in MONSTR,1997,0897918509,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/331697.332340,10.1145/331697.332340,,Proceedings of the 1997 ACM Symposium on Applied Computing,509–514,6,"MONSTR, distributed systems, interaction nets, term graph rewriting systems","San Jose, California, USA",SAC '97,inproceedings,,,,,,,,,,
"Kay, Alan C.",The early history of Smalltalk,1996,0201895021,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/234286.1057828,,"Most ideas come from previous ideas. The sixties, particularly in the ARPA community, gave rise to a host of notions about ",History of Programming Languages---II,511–598,88,,,,inbook,,,,,,,,,,
"McClure, Polley Ann",Planning for academic departmental systems,1987,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/382270.382425,10.1145/382270.382425,"I want to describe the computing environment at our campus and how departmental computing fits in, the goals that we envisioned for the departmental planning process, and the process that we have developed over the last two years. I'll also describe the model that we are continuing to develop to assist in the estimation of cost and in the negotiation of funding for departmental systems and show you three brief examples of plans which our academic departments have developed. Finally, I want to share my observations about the strengths and weaknesses of this process.",,19–28,10,,,,article,,Sept. 1987,17,3,SIGUCCS Newsl.,sep,0736-6892,,,
"Torrellas, Joseph and Hennessy, John and Weil, Thierry",Analysis of critical architectural and programming parameters in a hierarchical,1990,0897913590,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/98457.98754,10.1145/98457.98754,"Scalable shared-memory multiprocessors are the subject of much current research, but little is known about the performance behavior of these machines. This paper studies the performance effects of two machine characteristics and two program characteristics that seem to be major factors in determining the performance of a hierarchical shared-memory machine. We develop an analytical model of the traffic in a machine loosely based on Stanford's DASH multiprocessor and use program parameters extracted from multiprocessor traces to study its performance. It is shown that both locality in the data reference stream and the amount of data sharing in a program have an important impact on performance. Although less obvious, the bandwidth within each cluster in the hierarchy also has a significant performance effect. Optimizations that improve the intracluster cache coherence protocol or increase the bandwidth within a cluster can be quite effective.",Proceedings of the 1990 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems,163–172,10,,"Univ. of Colorado, Boulder, Colorado, USA",SIGMETRICS '90,inproceedings,,,,,,,,,,
"Gauthier, Michel",What's new for scanning with Ada-95?,1996,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/231188.231190,10.1145/231188.231190,"This paper illustrates how some new Ada-95 features improve the versatility of scanning techniques. It will recall the definition of a scan, how scanning can be implemented in Ada-83, and what problems are associated with scans, notably in passing them as (generic) parameters. After that, we will discuss accesses to subprograms and show that they cannot become a worthwhile solution, and finally show an unexpected solution with tagged types used as a factorisation of properties rather than as an implementation of inheritance mechanisms.From some low-level point of view, both generic and file-like scannings can look like theoretical fashions that have no interest. The real question beyond such scannings is whether we accept the application of these programming principles that have emerged from decades of programming professional practice, such as weak coupling, abstraction and encapsulation. We argue that it is essential to study in depth all the consequences of these programming principles before assessing their interest in real life. We conjecture that encapsulated scans could be of enough interest to be much more widely used in industrial projects.Aside from industrial usages, scanning is a valid illustration of both tagged types and genericity, and we provided some suggested exercises for lecturers who would emphasize factorization of type properties and nested genericity or package parameters.",,57–72,16,,,,article,,July/Aug. 1996,XVI,4,Ada Lett.,jul,1094-3641,,,
"Umpleby, Stuart",Structuring information for a computer-based communications medium,1972,9781450379106,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/1479064.1479124,10.1145/1479064.1479124,"Several years ago Prof. Charles E. Osgood suggested that it might be possible to develop a program for a computer-based education system which would eventually allow the public, possibly at a world's fair, to ","Proceedings of the November 16-18, 1971, Fall Joint Computer Conference",337–350,14,,"Las Vegas, Nevada",AFIPS '71 (Fall),inproceedings,,,,,,,,,,
"Bell, G.",Keynote address: toward a history of (personal) workstations,1988,0201112590,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/61975.66913,,,A History of Personal Workstations,1–50,50,,,,inbook,,,,,,,,,,
"Minker, Jack",Information storage and retrieval: a survey and functional description,1977,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/1095515.1095516,10.1145/1095515.1095516,"Information Storage and Retrieval (IS&amp;R) encompasses a broad scope of topics ranging from basic techniques for accessing data to sophisticated approaches for the analysis of natural language text and the deduction of information. Within the field, three general areas of investigation can be distinguished not only by their subject matter but also by the types of individuals presently interested in them:(1) Document retrieval,(2) Generalized data management, and(3) Question-answering.A functional description which applies to each of the three areas is presented together with a survey of work being conducted. The similarities and differences of the three areas of IS&amp;R are described. Typical systems which incorporate many of the functions and techniques are described in the appendix.",,12–108,97,"automatic indexing, data management, data structures, deductive search, information retrieval, natural language, problem solving, question-answering, relational data systems, theorem proving",,,article,,Fall 1977,12,2,SIGIR Forum,sep,0163-5840,,,
"Moen, William E. and McClure, Charles R.",The government information locator service: a user-based approach to standards,1994,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/202949.202956,10.1145/202949.202956,,,86–95,10,,,,article,,June 1994,2,2,StandardView,jun,1067-9936,,,
"Qiao, Xiangzhen and Gan, Qitao and Liu, Zhiyong and Guo, Xiaotao and Li, Xiaobo",Cache optimization in scientific computations,1999,1581130864,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/298151.298436,10.1145/298151.298436,,Proceedings of the 1999 ACM Symposium on Applied Computing,548–552,5,"FFT, Jacobi, QR, cache optimization, parallel processing","San Antonio, Texas, USA",SAC '99,inproceedings,,,,,,,,,,
"Kuzma, Bernadette and Carson, George S. and Puk, Richard F. and Gebhardt, John","BIIF, VRML and CGM",1999,,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/326460.326494,10.1145/326460.326494,"This edition of the Standards Pipeline consists of three articles that provide an in-depth look at applications of three important international standards. In the first article, Bernadette Kuzma of SEMCOR, Inc. describes the Basic Image Interchange Format (BIIF) formally known as ISO/IEC 12087-5:1998. While BIIF originated in the defense community, it is beginning to find wider applications in areas ranging from electronic libraries to medical imaging. In the second article, Richard F. Puk of Intelligraphics describes the current status and future prospects for the Virtual Reality Modeling Language (VRML) formally known as ISO/IEC 14772-1. In the final article, Lofton Henderson of Inso Corporation and John Gebhardt of InterCAP Graphics Systems, Inc. describe the work of the CGM Open Consortium and in particular the WebCGM profile.",,54–60,7,,,,article,,May 1999,33,2,SIGGRAPH Comput. Graph.,may,0097-8930,,,
"Ivanovich, Milosh and Zukerman, Moshe and Cameron, Fraser",A study of deadlock models for a multiservice medium access protocol employing a Slotted Aloha signalling channel,2000,,IEEE Press,,https://doi.org/10.1109/90.893875,10.1109/90.893875,,,800–811,12,"p-persistence, HFC, MAC, contention resolution, deadlock, protocol",,,article,,Dec. 2000,8,6,IEEE/ACM Trans. Netw.,dec,1063-6692,,,
"Morrison, Forest E. and Page, June A. and Irby, Cynthia B.",Use of a software package for diverse user-developed applications,1981,0897910443,Association for Computing Machinery,"New York, NY, USA",https://doi.org/10.1145/800051.801846,10.1145/800051.801846,"In recent years the technological advances in computer hardware have raced far ahead of the development of software. Computer manufacturers, software firms, government and private industry have all been caught in the dilemma of having the latest in data processing equipment, but lacking the trained personnel to achieve the maximum benefit from this equipment. Low priced mini and micro-computer systems started and are continuing to fuel the rush to decentralization. We see less of the central computer facility and more of small computers being utilized in the offices and laboratories that they serve.In an attempt to compensate for the lack of computer knowledge in end users, computer manufacturers are developing generalized software packages and coupling these with powerful, low priced equipment so that the customer can immediately begin to derive benefits from computerization.",Proceedings of the Eighteenth Annual Computer Personnel Research Conference,14–38,25,,"Washington, D.C., USA",SIGCPR '81,inproceedings,,,,,,,,,,
"Krawczyk, Robert J. and Dudnik, Elliott E.",Space plan: A user oriented package for the evaluation and the generation of spatial inter-relationships,1973,,IEEE Press,,,,"The development and the subsequent exposure of automated space planning methodologies has grown to the point where they are now acceptable and readily available preliminary architectural design tools.This paper describes a system of computer programs which were developed in an attempt to pull together current design methodologies.In summary, the paper describes the general system and discusses the basic assumptions and concepts implemented within it. Each method presented is described and executed with the same specific design problem for the purpose of demonstration and comparison.",Proceedings of the 10th Design Automation Workshop,121–138,18,,,DAC '73,inproceedings,,,,,,,,,,
